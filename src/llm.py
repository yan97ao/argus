import os
import json
from time import sleep, time
import requests
import logging
from typing import List, Dict, Any, Optional, Tuple

from importance_scorer import calculate_importance_score, get_importance_emoji

# å­˜å‚¨å·²ä½¿ç”¨çš„é”šç‚¹ï¼Œç”¨äºæ£€æµ‹é‡å¤
_used_anchors: Dict[str, List[str]] = {}

def analyze_commit(commits, repo_context=None, api_key=None, model=None, config=None):
    """åˆ†ææäº¤å†…å®¹ï¼Œä½¿ç”¨LLMæä¾›æ´å¯Ÿ

    Args:
        commits: GitHubæäº¤å¯¹è±¡åˆ—è¡¨
        repo_context: ä»“åº“ä¸Šä¸‹æ–‡ä¿¡æ¯ (å¯é€‰)
        api_key: APIå¯†é’¥ï¼ˆå¦‚æœä¸ºNoneï¼Œä»LLM_API_KEYç¯å¢ƒå˜é‡è¯»å–ï¼‰
        model: æ¨¡å‹åç§°ï¼ˆå¦‚æœä¸ºNoneï¼Œä»LLM_MODELç¯å¢ƒå˜é‡è¯»å–ï¼‰
        config: é…ç½®å­—å…¸ (å¯é€‰)

    Returns:
        list: LLMåˆ†æç»“æœåˆ—è¡¨ï¼Œæ¯ä¸ªå…ƒç´ åŒ…å« (commit, analysis, importance_info)
    """
    if not commits:
        return []

    # ä»ç¯å¢ƒå˜é‡è¯»å–é…ç½®ï¼ˆå¦‚æœå‚æ•°æœªæä¾›ï¼‰
    if api_key is None:
        api_key = os.getenv("LLM_API_KEY")
    if model is None:
        model = os.getenv("LLM_MODEL")

    results = []
    for commit in commits:
        logging.info(f"åˆ†ææäº¤: {commit.sha}")

        # è®¡ç®—é‡è¦æ€§è¯„åˆ†ï¼ˆä¼ é€’é…ç½®ï¼‰
        importance_info = calculate_importance_score(commit, repo_context, config)
        importance_level = importance_info['level']

        # æ„å»ºæç¤ºè¯
        system_prompt = build_system_prompt(importance_level)
        user_prompt = build_user_prompt_enhanced(commit, repo_context, importance_info)

        # è°ƒç”¨LLMè¿›è¡Œåˆ†æï¼ˆå¸¦é‡è¯•ï¼‰
        max_retries = 3
        for attempt in range(max_retries):
            try:
                output, response_time = call_llm(
                    system_prompt, user_prompt,
                    api_key=api_key, model=model,
                    return_response_time=True
                )
                logging.debug("LLMåˆ†æç»“æœ:")
                logging.debug(output)

                results.append({
                    'commit': commit,
                    'analysis': output,
                    'importance_info': importance_info
                })
                break
            except Exception as e:
                if attempt < max_retries - 1:
                    # æ£€æŸ¥æ˜¯å¦æ˜¯é™æµé”™è¯¯
                    is_rate_limited = "429" in str(e) or "rate limit" in str(e).lower()
                    delay = smart_rate_limit(response_time if 'response_time' in locals() else None,
                                             is_rate_limited,
                                             attempt + 1)
                    logging.warning(f"LLMè°ƒç”¨å¤±è´¥ï¼ˆç¬¬{attempt + 1}æ¬¡å°è¯•ï¼‰: {str(e)}, {delay}ç§’åé‡è¯•...")
                    sleep(delay)
                else:
                    error_msg = f"LLMåˆ†æå¤±è´¥ï¼ˆå·²é‡è¯•{max_retries}æ¬¡ï¼‰: {str(e)}"
                    logging.error(error_msg)
                    results.append({
                        'commit': commit,
                        'analysis': None,
                        'importance_info': importance_info,
                        'error': error_msg
                    })
                    break
        else:
            # æ™ºèƒ½é€Ÿç‡æ§åˆ¶å»¶è¿Ÿï¼ˆæ­£å¸¸æƒ…å†µï¼‰
            delay = smart_rate_limit(None, False, 0)
            if delay > 0:
                sleep(delay)

    return results


def build_system_prompt(importance_level: str = "medium") -> str:
    """æ ¹æ®é‡è¦ç¨‹åº¦ç”Ÿæˆåˆ†çº§ system prompt

    Args:
        importance_level: 'low', 'medium', æˆ– 'high'

    Returns:
        str: system prompt å†…å®¹
    """
    if importance_level == "low":
        # ğŸŸ¢ ä½é‡è¦åº¦ï¼šç®€åŒ–ç‰ˆï¼ˆ3 å­—æ®µï¼‰
        return """ä½ æ˜¯ä¸€ä½ä»£ç å®¡æŸ¥ä¸“å®¶ã€‚è¯·ä¸ºè¿™æ¬¡å˜æ›´æä¾›ç®€æ´çš„åˆ†æã€‚

**ğŸ¯ å˜æ›´ç±»å‹**ï¼š[ä»ä»¥ä¸‹é€‰æ‹©: æ–‡æ¡£æ›´æ–°/é…ç½®è°ƒæ•´/æµ‹è¯•ä¿®æ”¹/ä»£ç é‡æ„/å…¶ä»–]
**âš¡ é‡è¦ç¨‹åº¦**ï¼šğŸŸ¢ä½
**ğŸ“‹ æ‘˜è¦**ï¼š[1-2å¥è¯æ¦‚æ‹¬å˜æ›´å†…å®¹]

è¦æ±‚: ç®€æ´æ˜äº†,ä¸è¶…è¿‡100å­—ã€‚"""

    elif importance_level == "medium":
        # ğŸŸ¡ ä¸­é‡è¦åº¦ï¼šæ ‡å‡†ç‰ˆï¼ˆ5 å­—æ®µï¼‰
        return """ä½ æ˜¯ä¸€ä½ä»£ç å®¡æŸ¥ä¸“å®¶ã€‚è¯·ä¸ºè¿™æ¬¡å˜æ›´æä¾›ä¸­ç­‰æ·±åº¦çš„åˆ†æã€‚

**ğŸ¯ å˜æ›´ç±»å‹**ï¼š[åŠŸèƒ½å¢å¼º/Bugä¿®å¤/æ€§èƒ½ä¼˜åŒ–/é‡æ„/å…¶ä»–]
**âš¡ é‡è¦ç¨‹åº¦**ï¼šğŸŸ¡ä¸­
**ğŸ“‹ å˜æ›´æ‘˜è¦**ï¼š[2-3å¥è¯æ¦‚æ‹¬å˜æ›´å†…å®¹å’Œç›®æ ‡]
**ğŸ¯ å½±å“èŒƒå›´**ï¼š[åˆ—å‡ºå—å½±å“çš„ä¸»è¦æ¨¡å—]
**ğŸ’¡ å…³æ³¨å»ºè®®**ï¼š[ç»™å¼€å‘è€…å’Œç”¨æˆ·çš„å…·ä½“å»ºè®®]

è¦æ±‚: å…³æ³¨æ ¸å¿ƒå˜æ›´,æä¾›å¯æ“ä½œçš„å»ºè®®,200å­—å·¦å³ã€‚"""

    else:
        # ğŸ”´ é«˜é‡è¦åº¦ï¼šå®Œæ•´ç‰ˆï¼ˆ7 å­—æ®µï¼Œå½“å‰æ ¼å¼ï¼‰
        return """ä½ æ˜¯ä¸€ä½èµ„æ·±çš„è½¯ä»¶å·¥ç¨‹å¸ˆå’Œä»£ç å®¡æŸ¥ä¸“å®¶ï¼Œä¸“é—¨åˆ†æå¼€æºé¡¹ç›®çš„ä»£ç å˜æ›´ã€‚

## ä½ çš„ä¸“é•¿
- è¯†åˆ«ä»£ç å˜æ›´çš„æŠ€æœ¯å½±å“å’Œä¸šåŠ¡ä»·å€¼
- è¯„ä¼°å˜æ›´çš„é£é™©ç­‰çº§å’Œå½±å“èŒƒå›´
- ä»æ¶æ„ã€æ€§èƒ½ã€å®‰å…¨ã€å¯ç»´æŠ¤æ€§ç­‰å¤šä¸ªç»´åº¦åˆ†æ
- ä¸ºå¼€å‘è€…æä¾›ç®€æ´è€Œæœ‰ä»·å€¼çš„æŠ€æœ¯æ´å¯Ÿ

## åˆ†æåŸåˆ™
1. å…³æ³¨å˜æ›´çš„å®é™…å½±å“ï¼Œè€Œéè¡¨é¢ç°è±¡
2. è¯†åˆ«æ½œåœ¨çš„é£é™©å’Œæœºä¼š
3. æä¾›å¯æ“ä½œçš„å»ºè®®å’Œæ´å¯Ÿ
4. ä¿æŒå®¢è§‚å’Œä¸“ä¸šçš„åˆ†ææ€åº¦

## è¾“å‡ºæ ¼å¼è¦æ±‚
è¯·ä¸¥æ ¼æŒ‰ç…§ä»¥ä¸‹æ ¼å¼æä¾›åˆ†æï¼Œæ¯ä¸ªéƒ¨åˆ†éƒ½å¿…é¡»å¡«å†™ï¼š

**ğŸ¯ å˜æ›´ç±»å‹**ï¼š[åŠŸèƒ½å¢å¼º/Bugä¿®å¤/æ€§èƒ½ä¼˜åŒ–/é‡æ„/æ¶æ„å˜æ›´/å®‰å…¨ä¿®å¤]
**âš¡ é‡è¦ç¨‹åº¦**ï¼šğŸ”´é«˜
**ğŸ“‹ å˜æ›´æ‘˜è¦**ï¼š[2-3å¥è¯æ¦‚æ‹¬å˜æ›´å†…å®¹ã€ç›®æ ‡å’Œé¢„æœŸæ•ˆæœ]
**ğŸ¯ å½±å“èŒƒå›´**ï¼š[åˆ—å‡ºå—å½±å“çš„ä¸»è¦æ¨¡å—æˆ–ç»„ä»¶]
**ğŸ” æŠ€æœ¯æ´å¯Ÿ**ï¼š
- æ¶æ„å½±å“ï¼š[å¯¹ç³»ç»Ÿæ¶æ„çš„å½±å“]
- æ€§èƒ½å½±å“ï¼š[å¯¹æ€§èƒ½çš„æ½œåœ¨å½±å“]
- å®‰å…¨è€ƒè™‘ï¼š[æ˜¯å¦æ¶‰åŠå®‰å…¨ç›¸å…³å˜æ›´]
**âš ï¸ æ½œåœ¨é£é™©**ï¼š[è¯†åˆ«å¯èƒ½çš„é£é™©ç‚¹]
**ğŸ’¡ å…³æ³¨å»ºè®®**ï¼š[ç»™å¼€å‘è€…å’Œç”¨æˆ·çš„å…·ä½“å»ºè®®]

## å›ç­”è¦æ±‚
- ä½¿ç”¨ä¸­æ–‡å›ç­”
- ä¿æŒç®€æ´ä½†ä¿¡æ¯ä¸°å¯Œ
- é¿å…é‡å¤ä¿¡æ¯ï¼Œæ¯ä¸ªéƒ¨åˆ†åº”æœ‰ç‹¬ç‰¹ä»·å€¼"""


def build_user_prompt_enhanced(commit, repo_context: Optional[Dict] = None, importance_info: Optional[Dict] = None) -> str:
    """ç”Ÿæˆå¢å¼ºçš„ user promptï¼ŒåŒ…å«ä¸Šä¸‹æ–‡ä¿¡æ¯

    Args:
        commit: GitHub commit å¯¹è±¡
        repo_context: ä»“åº“ä¸Šä¸‹æ–‡ä¿¡æ¯ (å¯é€‰)
        importance_info: é‡è¦æ€§è¯„åˆ†ä¿¡æ¯ (å¯é€‰)

    Returns:
        str: user prompt å†…å®¹
    """
    prompt = "## ä»“åº“ä¸Šä¸‹æ–‡\n"
    if repo_context:
        prompt += f"- é¡¹ç›®: {repo_context.get('name', 'Unknown')}\n"
        prompt += f"- ä¸»è¦è¯­è¨€: {repo_context.get('language', 'Unknown')}\n"
        if 'stars' in repo_context:
            prompt += f"- æ˜Ÿæ ‡: {repo_context['stars']}\n"
    prompt += "\n"

    prompt += "## æäº¤ä¿¡æ¯\n"
    prompt += f"- SHA: {commit.sha}\n"
    prompt += f"- ä½œè€…: {commit.commit.author.name}\n"
    prompt += f"- æ¶ˆæ¯: {commit.commit.message}\n"

    # æ·»åŠ é‡è¦æ€§ç›¸å…³ä¿¡æ¯
    if importance_info:
        details = importance_info.get('details', {})
        prompt += f"- ç±»å‹: {details.get('commit_type', 'unknown')}\n"
        prompt += f"- å˜æ›´è§„æ¨¡: {commit.stats.additions if hasattr(commit, 'stats') else 0}+ / {commit.stats.deletions if hasattr(commit, 'stats') else 0}-\n"
        prompt += f"- ä¸»è¦æ–‡ä»¶ç±»å‹: {details.get('primary_file_type', 'unknown')}\n"

    prompt += "\n## ä¿®æ”¹æ–‡ä»¶\n"

    # è·å–æ–‡ä»¶å˜æ›´è¯¦æƒ…
    try:
        for file in commit.files:
            status_desc = {
                'added': 'æ–°å¢',
                'modified': 'ä¿®æ”¹',
                'removed': 'åˆ é™¤',
                'renamed': 'é‡å‘½å',
                'changed': 'å˜æ›´'
            }.get(file.status, file.status)

            prompt += f"  * {status_desc}: {file.filename} (+{file.additions}/-{file.deletions})\n"

            # ä¼˜åŒ–å·®å¼‚æˆªæ–­ï¼š>50KB æˆªæ–­åˆ° 50KB
            if hasattr(file, 'patch') and file.patch:
                if len(file.patch) > 50000:  # 50KB
                    prompt += f"```diff\n{file.patch[:50000]}\n```\n"
                    prompt += f"(å·®å¼‚è¿‡å¤§ï¼Œå·²æˆªæ–­åˆ°å‰50KB)\n"
                else:
                    prompt += f"```diff\n{file.patch}\n```\n"
    except Exception as e:
        prompt += f"  * æ— æ³•è·å–æ–‡ä»¶è¯¦æƒ…: {str(e)}\n"

    # æ·»åŠ åˆ†ææ·±åº¦è¦æ±‚
    prompt += "\n## åˆ†æè¦æ±‚\n"
    if importance_info:
        level = importance_info.get('level', 'medium')
        if level == 'high':
            prompt += "- è¯·æä¾›å…¨é¢æ·±å…¥çš„æŠ€æœ¯åˆ†æ\n"
            prompt += "- å…³æ³¨æ¶æ„ã€æ€§èƒ½ã€å®‰å…¨ç­‰å¤šç»´åº¦å½±å“\n"
        elif level == 'medium':
            prompt += "- è¯·æä¾›ä¸­ç­‰æ·±åº¦çš„åˆ†æ\n"
            prompt += "- å…³æ³¨æ ¸å¿ƒå˜æ›´å’Œå½±å“èŒƒå›´\n"
        else:  # low
            prompt += "- è¯·æä¾›ç®€æ´çš„æ‘˜è¦å³å¯\n"

    prompt += "\n---\n\n"

    logging.debug("=" * 40)
    logging.debug("LLMæç¤ºè¯:")
    logging.debug(prompt)
    logging.debug("-" * 40)
    return prompt


def smart_rate_limit(response_time: Optional[float], is_rate_limited: bool, attempt_num: int) -> int:
    """æ™ºèƒ½é€Ÿç‡æ§åˆ¶

    Args:
        response_time: ä¸Šæ¬¡APIå“åº”æ—¶é—´ï¼ˆç§’ï¼‰
        is_rate_limited: æ˜¯å¦è¢«é™æµ
        attempt_num: å½“å‰é‡è¯•æ¬¡æ•°

    Returns:
        int: éœ€è¦ç­‰å¾…çš„ç§’æ•°
    """
    if is_rate_limited:
        # æŒ‡æ•°é€€é¿ï¼š10s, 20s, 30s
        backoff = min(10 * attempt_num, 30)
        logging.warning(f"æ£€æµ‹åˆ°é™æµï¼Œä½¿ç”¨æŒ‡æ•°é€€é¿: {backoff}ç§’")
        return backoff
    elif response_time is not None:
        if response_time < 1.0:
            # å“åº”å¿«ï¼ŒåŠ é€Ÿåˆ°5ç§’
            return 5
        elif response_time > 5.0:
            # å“åº”æ…¢ï¼Œå‡é€Ÿåˆ°15ç§’
            return 15

    # é»˜è®¤å»¶è¿Ÿ
    return 10


def call_llm(system_prompt: str, user_prompt: str, api_key: str = None, model: str = None,
            return_response_time: bool = False) -> Tuple[str, Optional[float]]:
    """è°ƒç”¨LLM APIè·å–LLMå›å¤

    Args:
        system_prompt: ç³»ç»Ÿæç¤ºè¯
        user_prompt: ç”¨æˆ·æç¤ºè¯
        api_key: APIå¯†é’¥ï¼ˆå¦‚æœä¸ºNoneï¼Œä»LLM_API_KEYç¯å¢ƒå˜é‡è¯»å–ï¼‰
        model: æ¨¡å‹åç§°ï¼ˆå¦‚æœä¸ºNoneï¼Œä»LLM_MODELç¯å¢ƒå˜é‡è¯»å–ï¼‰
        return_response_time: æ˜¯å¦è¿”å›å“åº”æ—¶é—´

    Returns:
        (str, Optional[float]): LLMå›å¤å†…å®¹å’Œå“åº”æ—¶é—´ï¼ˆç§’ï¼‰
    """
    # ä»ç¯å¢ƒå˜é‡è¯»å–é…ç½®ï¼ˆå¦‚æœå‚æ•°æœªæä¾›ï¼‰
    if api_key is None:
        api_key = os.getenv("LLM_API_KEY")
    if model is None:
        model = os.getenv("LLM_MODEL")

    # LLM APIç«¯ç‚¹ï¼ˆä»ç¯å¢ƒå˜é‡è¯»å–ï¼‰
    api_url = os.getenv("LLM_BASE_URL")

    # è¯·æ±‚å¤´
    headers = {
        "Content-Type": "application/json",
        "Authorization": f"Bearer {api_key}",
        "X-Title": "Argus Git Commit Analyzer"  # åº”ç”¨åç§°
    }

    # è¯·æ±‚ä½“
    data = {
        "model": model,
        "messages": [
            {"role": "system", "content": system_prompt},
            {"role": "user", "content": user_prompt}
        ],
        "temperature": 1.0,  # https://api-docs.deepseek.com/zh-cn/quick_start/parameter_settings
        "max_tokens": 2048   # é™åˆ¶å›å¤é•¿åº¦
    }

    try:
        # è®°å½•å¼€å§‹æ—¶é—´
        start_time = time()

        # å‘é€è¯·æ±‚
        response = requests.post(api_url, headers=headers, json=data, timeout=30)

        # è®¡ç®—å“åº”æ—¶é—´
        response_time = time() - start_time

        logging.info("call LLM with %s bytes and got %s bytes in %.2fs",
                    len(response.request.body), len(response.content), response_time)
        response.raise_for_status()  # æ£€æŸ¥HTTPé”™è¯¯

        # è§£æå“åº”
        result = response.json()

        # æå–å›å¤å†…å®¹
        if "choices" in result and len(result["choices"]) > 0:
            content = result["choices"][0]["message"]["content"]
            if return_response_time:
                return content, response_time
            return content
        else:
            raise ValueError(f"æ— æ•ˆçš„APIå“åº”: {json.dumps(result)}")

    except requests.exceptions.RequestException as e:
        raise ConnectionError(f"APIè¯·æ±‚å¤±è´¥: {str(e)}")
    except json.JSONDecodeError:
        raise ValueError(f"æ— æ³•è§£æAPIå“åº”: {response.text}")
    except Exception as e:
        raise RuntimeError(f"è°ƒç”¨LLMæ—¶å‡ºé”™: {str(e)}")
