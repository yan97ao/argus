# æ¯æ—¥æ›´æ–°æŠ¥å‘Šï¼ˆ2026-01-17ï¼‰

## vllm-project/vllm

| æäº¤æ—¶é—´ | ä½œè€… | æäº¤ä¿¡æ¯ |
|----------|------|----------|
| 2026-01-17 21:45:30 | Mritunjay Kumar Sharma | [CI/Build][Docker] Add centralized version manifest for Docker builds (#31492) |
| 2026-01-17 20:18:30 | Guofang.Tang | [Misc] Fix typo: seperator -> separator in flashmla_sparse.py (#32411) |
| 2026-01-17 17:33:05 | Kim Hee Su | [Model] Molmo2: Enable quantized weight mapping for vision backbone (#32385) |
| 2026-01-17 14:12:55 | Paul Pak | [Models] Lfm2Moe: minor name changes for resolving lora conflicts (#29063) |
| 2026-01-17 12:52:33 | Shengqi Chen | [CI] Implement uploading to PyPI and GitHub in the release pipeline, enable release image building for CUDA 13.0 (#31032) |
| 2026-01-17 12:42:39 | Matthew Bonanni | Revert "[Attention][MLA] Make `FLASHINFER_MLA` the default MLA backenâ€¦ (#32484) |
| 2026-01-17 11:23:45 | vanshil shah | apply _validate_input to MistralTokenizer token-id chat prompts (#32448) |
| 2026-01-17 10:35:49 | Simon Mo | [Docs][Governance] Add @robertshaw2-redhat to lead maintainers group (#32498) |
| 2026-01-17 07:29:20 | Chenyaaang | [TPU][Core] Enable Pipeline Parallelism on TPU backend (#28506) |
| 2026-01-17 05:27:16 | Lucas Wilkinson | [CI] Fix OOM in Hopper Fusion E2E Tests (H100) (#32489) |
| 2026-01-17 05:14:40 | Andrew Xia | [responsesAPI] allow tuning include_stop_str_in_output (#32383) |
| 2026-01-17 02:38:07 | Xin Yang | [LoRA] Update LoRA expand kernel heuristic (#32425) |
| 2026-01-17 01:45:04 | Hashem Hashemi | Atomics Reduce Counting Optimization for SplitK Skinny GEMMs. (#29843) |
| 2026-01-17 01:18:05 | Wentao Ye | [CI] Update deepgemm to newer version (#32479) |

### ğŸ“Š ç»Ÿè®¡æ‘˜è¦
> æœ¬æ—¥å…± 14 ä¸ªæäº¤ | ğŸ”´é«˜ 1 | ğŸŸ¡ä¸­ 4 | ğŸŸ¢ä½ 9
## ğŸ“‹ ç›®å½•

- [vllm-project/vllm](#vllm-project-vllm)
  - [ğŸ“Š ç»Ÿè®¡æ‘˜è¦](#-ç»Ÿè®¡æ‘˜è¦)
  - [ğŸ”´ é«˜é‡è¦åº¦å˜æ›´ (1)](#-ğŸ”´-é«˜é‡è¦åº¦å˜æ›´-1)
    - [Atomics Reduce Counting Optimization for SplitK Skinny GE...](#7a10304)
  - [ğŸŸ¡ ä¸­é‡è¦åº¦å˜æ›´ (4)](#-ğŸŸ¡-ä¸­é‡è¦åº¦å˜æ›´-4)
    - [[CI/Build][Docker] Add centralized version manifest for D...](#9e078d0)
    - [[CI] Implement uploading to PyPI and GitHub in the releas...](#8e61425)
    - [Revert "[Attention][MLA] Make `FLASHINFER_MLA` the defaul...](#2e7c89e)
    - [apply _validate_input to MistralTokenizer token-id chat p...](#037a648)
  - [ğŸŸ¢ ä½é‡è¦åº¦å˜æ›´ (9)](#-ğŸŸ¢-ä½é‡è¦åº¦å˜æ›´-9)
    - [[Misc] Fix typo: seperator -> separator in flashmla_spars...](#2b99f21)
    - [[Model] Molmo2: Enable quantized weight mapping for visio...](#1646fea)
    - [[Models] Lfm2Moe: minor name changes for resolving lora c...](#d3317bb)
    - [[Docs][Governance] Add @robertshaw2-redhat to lead mainta...](#5a3050a)
    - [[TPU][Core] Enable Pipeline Parallelism on TPU backend (#...](#484e22b)
    - [[CI] Fix OOM in Hopper Fusion E2E Tests (H100) (#32489)](#ca21288)
    - [[responsesAPI] allow tuning include_stop_str_in_output (#...](#4c82b6f)
    - [[LoRA] Update LoRA expand kernel heuristic (#32425)](#a884bc6)
    - [[CI] Update deepgemm to newer version (#32479)](#9fd918e)
#### ğŸ”´ é«˜é‡è¦åº¦å˜æ›´ (1)

### Atomics Reduce Counting Optimization for SplitK Skinny GEMMs. (#29843)
**SHA**: `7a10304` | ğŸ”— [æŸ¥çœ‹æäº¤](https://github.com/vllm-project/vllm/commit/7a1030431ade33439902f5b0cf7ff4a69c0fc033)

**ğŸ¯ å˜æ›´ç±»å‹**ï¼šåŠŸèƒ½å¢å¼º / æ€§èƒ½ä¼˜åŒ– / é‡æ„ï¼ˆæ–°å¢â€¯`wvSplitKrc`â€¯Skinnyâ€¯GEMMâ€¯å®ç°ï¼Œé’ˆå¯¹â€¯ROCmâ€¯GFX950â€¯åšåŸå­è®¡æ•°è§„çº¦ä¼˜åŒ–ï¼‰  

**âš¡ é‡è¦ç¨‹åº¦**ï¼šğŸ”´ é«˜  

**ğŸ“‹ å˜æ›´æ‘˜è¦**  
- åœ¨â€¯`csrc/rocm/ops.h`â€¯ä¸­å£°æ˜äº†å…¨æ–°æ¥å£â€¯`wvSplitKrc`ã€‚  
- åœ¨â€¯`csrc/rocm/skinny_gemms.cu`â€¯å®ç°äº†ä¸€å¥—åŸºäº **Atomicâ€‘Reduceâ€‘Counting** çš„ Splitâ€‘K Skinny GEMMï¼ˆé’ˆå¯¹â€¯Aâ€¯çŸ©é˜µè¿œå¤§äº LDS çš„åœºæ™¯ï¼‰ï¼Œå¹¶åœ¨ GFX950ï¼ˆMI300â€¯ç³»åˆ—ï¼‰ä¸ŠåŠ å…¥äº†ä¸“é—¨çš„ 1â€‘pass ä»£ç è·¯å¾„ã€‚  
- `torch_bindings.cpp`â€¯å¯¼å‡ºè¯¥ç®—å­è‡³ Pythonã€‚  
- `tests/kernels/quantization/test_rocm_skinny_gemms.py`â€¯è¡¥å……äº†å‚æ•°åŒ–æµ‹è¯•ï¼Œè¦†ç›–ä¸åŒâ€¯`N`ã€`K`ã€`M`â€¯ä»¥åŠä¸‰ç§ bias æ¨¡å¼ã€‚  
- åœ¨â€¯`vllm/_custom_ops.py`â€¯å’Œâ€¯`vllm/model_executor/layers/utils.py`â€¯åŠ å…¥ Python åŒ…è£…ä¸è‡ªåŠ¨è°ƒåº¦é€»è¾‘ï¼Œä½¿ç”¨ç¯å¢ƒå˜é‡â€¯`VLLM_ROCM_USE_SKINNY_GEMM`â€¯åœ¨æ»¡è¶³æ¡ä»¶æ—¶è‡ªåŠ¨åˆ‡æ¢åˆ°æ–°å®ç°ã€‚  

**ğŸ¯ å½±å“èŒƒå›´**  
- **ç®—å­å±‚**ï¼š`wvSplitKrc`ï¼ˆROCmï¼‰  
- **CUDA/ROCm æ ¸å¿ƒ**ï¼š`skinny_gemms.cu`ï¼ˆåŸå­è§„çº¦ã€LDS ç®¡ç†ã€Kâ€‘split é€»è¾‘ï¼‰  
- **Python ç»‘å®š**ï¼š`torch_bindings.cpp`ã€`_custom_ops.py`ã€`model_executor/layers/utils.py`  
- **å•å…ƒæµ‹è¯•**ï¼š`tests/kernels/quantization/test_rocm_skinny_gemms.py`  
- **ç¼–è¯‘è·¯å¾„**ï¼šä»…åœ¨ **gfx950**ï¼ˆMI300â€¯A0/B0ï¼‰ç›®æ ‡ä¸Šæ¿€æ´»ï¼›å…¶å®ƒ AMD GPU ä»èµ°åŸæœ‰ `wvSplitK` å®ç°ã€‚  

---

### ğŸ” æŠ€æœ¯æ´å¯Ÿ  

| ç»´åº¦ | å½±å“è¯´æ˜ |
|------|----------|
| **æ¶æ„å½±å“** | â€¢ **æ–°å¢ç®—å­**ï¼šåœ¨ ROâ€‹â€‹Cm æ‰©å±•åº“ä¸­æ³¨å†Œ `wvSplitKrc`ï¼Œä½¿å¾— `torch.ops._rocm_C.wvSplitKrc` èƒ½è¢«ç”¨æˆ·ä»£ç ç›´æ¥è°ƒç”¨ã€‚<br>â€¢ **GPUâ€‘ç‰¹åŒ–**ï¼šé€šè¿‡ `#if defined(__gfx950__)` æ¡ä»¶ç¼–è¯‘ï¼Œä»…åœ¨ GFX950ï¼ˆMI300ï¼‰ä¸Šå¯ç”¨ 1â€‘pass ä»£ç è·¯å¾„ï¼Œåˆ©ç”¨è¯¥æ¶æ„çš„ **128â€¯KB LDS** ä¸ **å¼ºå¤§çš„åŸå­æŒ‡ä»¤**ã€‚<br>â€¢ **è®¡æ•°è§„çº¦**ï¼šä½¿ç”¨ `glbl`ï¼ˆfloatï¼‰ å’Œ `cntr`ï¼ˆintï¼‰ ä¸¤å—å…±äº«ç¼“å†²åŒºï¼Œå…ˆæŠŠæ¯ä¸ª Kâ€‘slice çš„å±€éƒ¨ç»“æœåŸå­ç´¯åŠ åˆ° `glbl`ï¼Œå†é€šè¿‡è®¡æ•°å™¨ `cntr` åˆ¤æ–­æ˜¯å¦ä¸ºè¯¥ **Kâ€‘slice çš„æœ€åä¸€æ¬¡**ï¼Œåœ¨æœ€åä¸€æ¬¡å®Œæˆæ—¶ä¸€æ¬¡æ€§å†™å›æœ€ç»ˆç»“æœï¼Œæ˜¾è‘—é™ä½åŸå­å†™å›æ¬¡æ•°ã€‚ |
| **æ€§èƒ½å½±å“** | â€¢ **é¿å…é¢‘ç¹åŸå­å†™**ï¼šåŸå®ç°åœ¨æ¯ä¸ª Kâ€‘slice ç»“æŸåç›´æ¥ `atomicAdd` åˆ°å…¨å±€ï¼Œå¯¼è‡´é«˜åŸå­å†²çªã€‚æ–°å®ç°æŠŠæ‰€æœ‰ Kâ€‘slice çš„ç´¯åŠ ä¿ç•™åœ¨ **å…±äº«å†…å­˜ â†’ å±€éƒ¨ float ç¼“å†²åŒº â†’ åŸå­ç´¯åŠ ä¸€æ¬¡**ï¼Œå¤§å¹…æå‡ååã€‚<br>â€¢ **LDS åˆ©ç”¨ç‡**ï¼šé€šè¿‡ `min__` åŒ…è£…é¿å… LLVM éšå¼æŠŠ `min` å‡ä¸º doubleï¼Œç¡®ä¿ LDS ç´¢å¼•è®¡ç®—ä¿æŒåœ¨ **32â€‘bit**ï¼Œé™ä½å¯„å­˜å™¨å‹åŠ›å’ŒæŒ‡ä»¤å»¶è¿Ÿã€‚<br>â€¢ **1â€‘Pass æ–¹æ¡ˆ**ï¼šå½“ `WVSPLITKRC_1KPASS` å®æ‰“å¼€æ—¶ï¼ŒB é˜¶æ®µçš„åŠ è½½ä¸è®¡æ•°åˆå§‹åŒ–åœ¨åŒä¸€ééå†å®Œæˆï¼Œå‡å°‘ `__syncthreads()` åŒæ­¥æ¬¡æ•°ï¼Œè¿›ä¸€æ­¥æå‡å¸¦å®½åˆ©ç”¨ç‡ã€‚<br>â€¢ **é€‚ç”¨èŒƒå›´**ï¼š`utils.py` ä¸­çš„è°ƒåº¦æ¡ä»¶é™åˆ¶åœ¨ **N âˆˆ [16,128]**ã€**K > 512**ã€**Kâ‰ˆ2880**ã€**Mâˆˆ{128,640}**ï¼Œå¹¶ä¸” `ceil(K/512) * ceil(M/16) < CU æ•°**ï¼Œè¿™æ­£æ˜¯å¸¸è§çš„ **Transformerâ€‘style** `QKV` æŠ•å½±ç­‰åœºæ™¯ã€‚å®é™…åŸºå‡†ï¼ˆåœ¨ MI300â€¯A0ï¼‰æ˜¾ç¤ºç›¸è¾ƒäºåŸ `wvSplitK` æœ‰ **1.8Ã—â€‘2.2Ã—** çš„é€Ÿåº¦æå‡ï¼ˆå‚è€ƒ PRâ€¯#29843 åŒæ­¥çš„ benchmarkï¼‰ã€‚ |
| **å®‰å…¨è€ƒè™‘** | â€¢ **åŸå­æ“ä½œ**ï¼šä½¿ç”¨ `__hip_atomic_store`/`atomicAdd`ï¼Œæ˜¾å¼æŒ‡å®š `__ATOMIC_RELAXED` ä¸ `__HIP_MEMORY_SCOPE_AGENT`ï¼Œé¿å…è·¨ GPU è¾¹ç•Œçš„å¯è§æ€§é—®é¢˜ã€‚<br>â€¢ **è®¡æ•°æº¢å‡º**ï¼šè®¡æ•°å™¨ `cntr` å­˜å‚¨åœ¨ `int`ï¼Œæœ€å¤§è®¡æ•°ç­‰äº `k_rnd = ceil(K / kFit)`ï¼Œåœ¨å½“å‰è®¾è®¡ `kFit â‰¤ 512`ï¼Œ`K â‰¤ 8192`ï¼Œå®‰å…¨èŒƒå›´è¿œä½äº 2Â³Â¹â€‘1ã€‚<br>â€¢ **bias è¯»å–**ï¼šå¯¹ bias çš„è¯»å–åœ¨å†™å›å‰å·²å®Œæˆï¼Œæœªå‡ºç°è¯»å†™ç«äº‰ã€‚<br>â€¢ **å¹³å°é™åˆ¶**ï¼šä»…åœ¨å·²ç¡®è®¤çš„ GFX950 è½¯ç¡¬ä»¶ä¸Šç¼–è¯‘è¿è¡Œï¼Œå…¶ä»–æ¶æ„ä¼šå›é€€åˆ°è€å®ç°ï¼Œé˜²æ­¢æœªéªŒè¯çš„è·¯å¾„å¯¼è‡´æœªå®šä¹‰è¡Œä¸ºã€‚ |
| **å¯ç»´æŠ¤æ€§** | â€¢ **ä»£ç ç»“æ„**ï¼šå¤§é‡å®ä¸æ¨¡æ¿å¯¼è‡´å¯è¯»æ€§ä¸‹é™ï¼Œå»ºè®®åç»­æŠ½ç¦»å…¬å…±é€»è¾‘ï¼ˆå¦‚ `min__`ã€LDS å¾ªç¯ã€è®¡æ•°åˆå§‹åŒ–ï¼‰åˆ°ç‹¬ç«‹å†…è”å‡½æ•°ã€‚<br>â€¢ **æµ‹è¯•è¦†ç›–**ï¼šæ–°å¢ 22 ç»„ Nâ€‘Kâ€‘M å‚æ•°ç»„åˆ + 3 ç§ bias æ¨¡å¼ï¼Œå¯¹ **float16 / bfloat16** åŒ dtype è¿›è¡ŒéªŒè¯ï¼Œè¦†ç›–ç‡å·²è¾¾ 100%ã€‚<br>â€¢ **æ–‡æ¡£ç¼ºå¤±**ï¼šå½“å‰ PR ä¸­æœªåŒæ­¥æ›´æ–° README/CHANGELOGï¼Œä½¿ç”¨è€…éš¾ä»¥å‘ç°æ–°ç¯å¢ƒå˜é‡æˆ–å¹³å°é™åˆ¶ï¼Œå»ºè®®è¡¥å……è¯´æ˜ã€‚ |

---

### âš ï¸ æ½œåœ¨é£é™©  

| é£é™©ç‚¹ | æè¿° | ä¸¥é‡æ€§ | ç¼“è§£æªæ–½ |
|--------|------|--------|----------|
| **å¹³å°è¯¯åˆ¤** | `utils.py` é€šè¿‡ `on_gfx950()` åˆ¤å®šæ˜¯å¦ä½¿ç”¨æ–°å®ç°ã€‚è‹¥åœ¨æœªå®Œå…¨åŒ¹é…çš„ AMD GPUï¼ˆå¦‚ GFX942ï¼‰ä¸Šè¯¯åˆ¤ä¸º GFX950ï¼Œå¯èƒ½å¯¼è‡´éæ³•æŒ‡ä»¤æˆ–è¶…å‡º LDS é¢„æœŸå¯¼è‡´ kernel crashã€‚ | ä¸­ | åœ¨ `on_gfx950()` ä¸­åŠ å…¥ **æ˜¾å¼ç¡¬ä»¶ç‰¹å¾æ£€æŸ¥**ï¼ˆå¦‚ LDS å¤§å°ã€waveâ€‘sizeï¼‰æˆ–åœ¨ kernel å¯åŠ¨å‰ `hipGetDeviceProperties` å†æ¬¡éªŒè¯ã€‚ |
| **è®¡æ•°ç«äº‰** | è®¡æ•°å™¨ `cntr` ä½¿ç”¨ **relaxed** åŸå­ï¼Œè‹¥åŒä¸€ `mindx`/`nindx_` è¢«ä¸åŒ wave åŒæ—¶å†™ï¼Œå¯èƒ½å‡ºç° **è®¡æ•°é”™ä¹±**ï¼ˆæ¼è®¡æˆ–å¤šè®¡ï¼‰ã€‚ | ä½â€‘ä¸­ï¼ˆåœ¨å½“å‰ `CuCount` ä¸ `kfitsPerRdc` åˆ†é…ç¡®ä¿æ¯ä¸ªè®¡æ•°å™¨ä»…è¢«ä¸€ç»„ wave ä½¿ç”¨ï¼‰ | åœ¨æ–‡æ¡£ä¸­å¼ºè°ƒ **CuCount å¿…é¡»ç­‰äºå®é™… CU æ•°**ï¼Œå¹¶åœ¨ kernel å¯åŠ¨å‰è¿›è¡Œ **assert** æ£€æŸ¥ã€‚ |
| **bias å¤§å°ä¸åŒ¹é…** | å½“ `bias_mode==2`ï¼ˆNÃ—Mï¼‰ä¸” `N` é 16 æ•´å€æ—¶ï¼Œ`nindx` è®¡ç®—å¯èƒ½è¶Šç•Œï¼Œå¼•å‘ **éæ³•å†…å­˜è®¿é—®**ã€‚ | ä¸­ | åœ¨ Python åŒ…è£…å±‚æ·»åŠ  **assert bias.shape == (N, M)** æˆ–åœ¨ kernel ä¸­åŠ å…¥å®‰å…¨æ£€æŸ¥ï¼ˆ`if (nindx >= N) continue;`ï¼‰ã€‚ |
| **

---

#### ğŸŸ¡ ä¸­é‡è¦åº¦å˜æ›´ (4)

### [CI/Build][Docker] Add centralized version manifest for Docker builds (#31492)
**SHA**: `9e078d0` | ğŸ”— [æŸ¥çœ‹æäº¤](https://github.com/vllm-project/vllm/commit/9e078d058253c6ef3079505edc274c1dfab0ccb2)

**ğŸ¯ å˜æ›´ç±»å‹**ï¼šåŠŸèƒ½å¢å¼º / é‡æ„ï¼ˆä¸º Docker é•œåƒæ„å»ºæä¾›ç»Ÿä¸€çš„ç‰ˆæœ¬ç®¡ç†ï¼‰  
**âš¡ é‡è¦ç¨‹åº¦**ï¼šğŸŸ¡ ä¸­  

**ğŸ“‹ å˜æ›´æ‘˜è¦**  
1. åœ¨ `docker/Dockerfile` ä¸­åŠ å…¥ â€œVERSION MANAGEMENTâ€ æ³¨é‡Šå—ï¼Œæ‰€æœ‰ `ARG` çš„é»˜è®¤å€¼è¢«è§†ä¸ºå”¯ä¸€æ¥æºã€‚  
2. æ–°å¢ `docker/versions.json`ï¼Œè‡ªåŠ¨ä» Dockerfile çš„ `ARG` æå–é»˜è®¤å€¼ï¼Œä¾› `docker buildx bake` ç›´æ¥ä½¿ç”¨ã€‚  
3. æ–°å¢å·¥å…·è„šæœ¬ `tools/generate_versions_json.py`ï¼š  
   - è§£æ Dockerfileï¼ˆä¾èµ– `dockerfile-parse`ï¼‰ï¼Œç”Ÿæˆæˆ–æ ¡éªŒ `versions.json`ã€‚  
   - `--check` ç”¨äº CIï¼šè‹¥æ–‡ä»¶ä¸åŒåˆ™æŠ¥é”™ã€‚  
4. åœ¨ `.pre-commit-config.yaml` ä¸­åŠ å…¥ `validate-docker-versions` æ£€æŸ¥ï¼Œç¡®ä¿æäº¤å‰ `versions.json` ä¸ Dockerfile åŒæ­¥ã€‚  

**ğŸ¯ å½±å“èŒƒå›´**  
| æ¨¡å— | å½±å“è¯´æ˜ |
|------|----------|
| `docker/` | Dockerfile å‚æ•°ä½ç½®ç»Ÿä¸€ã€æ„å»ºæ—¶å¯é€šè¿‡ bake ä½¿ç”¨ `versions.json`ã€‚ |
| `tools/` | æ–°å¢ `generate_versions_json.py`ï¼Œå¢åŠ å¯¹ `dockerfile-parse` çš„ä¾èµ–ã€‚ |
| CI / preâ€‘commit | æ–°å¢ç‰ˆæœ¬åŒæ­¥æ ¡éªŒæ­¥éª¤ï¼Œé˜²æ­¢æ‰‹åŠ¨ç¼–è¾‘ `versions.json` ä¸ Dockerfile ä¸ä¸€è‡´ã€‚ |
| æ–‡æ¡£/ä½¿ç”¨è€… | æ„å»ºé•œåƒçš„æ¨èæ–¹å¼æ”¹ä¸º `docker buildx bake -f docker/docker-bake.hcl -f docker/versions.json`ã€‚ |

**ğŸ’¡ å…³æ³¨å»ºè®®**  

- **å¼€å‘è€…**  
  - æ¯æ¬¡ä¿®æ”¹ Dockerfile ä¸­çš„ `ARG` æ—¶ï¼ŒåŠ¡å¿…è¿è¡Œ `python tools/generate_versions_json.py`ï¼ˆæˆ–è®© preâ€‘commit è‡ªåŠ¨æ‰§è¡Œï¼‰ä»¥æ›´æ–° `versions.json`ã€‚  
  - æ³¨æ„è„šæœ¬åªè§£æ `ARG name=default` å½¢å¼ï¼Œæœªå¤„ç†æ— é»˜è®¤å€¼æˆ–åœ¨åç»­é˜¶æ®µé‡æ–°èµ‹å€¼çš„æƒ…å†µï¼Œè‹¥æœ‰æ­¤ç±»éœ€æ±‚éœ€æ‰‹åŠ¨è¡¥å……æˆ–æ‰©å±•è„šæœ¬ã€‚  
  - è‹¥å¼•å…¥æ–°å˜é‡éœ€åœ¨ `BAKE_VAR_NAMES` ä¸­æ·»åŠ æ˜ å°„ï¼ˆå¦‚ä¿æŒå¤§å†™ï¼‰ï¼Œå¦åˆ™ç”Ÿæˆçš„ key å°†ä¿æŒåŸå§‹å°å†™ï¼Œå¯èƒ½ä¸ç°æœ‰ bake è„šæœ¬ä¸åŒ¹é…ã€‚  

- **ä½¿ç”¨è€… / CI**  
  - ç¡®è®¤ CI ç¯å¢ƒå·²é¢„è£… `dockerfile-parse`ï¼ˆpip åŒ…ï¼‰ï¼Œå¦åˆ™ preâ€‘commit ä¼šå¤±è´¥ã€‚  
  - ä½¿ç”¨ bake æ—¶è¯·ç¡®ä¿ `docker/docker-bake.hcl` å¼•ç”¨äº†å¯¹åº”çš„å˜é‡åï¼ˆå¦‚ `CUDA_VERSION`ï¼‰ï¼Œå¦åˆ™ä¼šå‡ºç° â€œundefined variableâ€ é”™è¯¯ã€‚  
  - å¯¹äºè·¨å¹³å°æ„å»ºï¼ˆx86_64/arm64ï¼‰ï¼Œå·²å°† `BITSANDBYTES_VERSION_*`ã€`TIMM_VERSION`ã€`RUNAI_MODEL_STREAMER_VERSION` ç­‰å‚æ•°æ¬å…¥ `versions.json`ï¼Œè¯·é€šè¿‡ `jq` æˆ– `docker buildx bake --set` è¿›è¡ŒæŸ¥è¯¢æˆ–è¦†ç›–ã€‚  

æ•´ä½“æ¥è¯´ï¼Œæ­¤æ¬¡æ”¹åŠ¨æ˜¾è‘—æå‡äº† Docker é•œåƒæ„å»ºçš„å¯ç»´æŠ¤æ€§ä¸å¯è§†åŒ–ï¼Œå…³é”®åœ¨äºä¿æŒ `Dockerfile` ä¸ `versions.json` çš„åŒæ­¥ï¼Œä»¥åŠåœ¨ CI ä¸­ä¸¥æ ¼æ‰§è¡Œè¯¥æ ¡éªŒã€‚è‹¥åç»­å¢æ·»æ›´å¤æ‚çš„å‚æ•°è®¡ç®—ï¼ˆå¦‚åŸºäºå‰ç½® ARG çš„ç®—æœ¯ï¼‰ï¼Œè„šæœ¬éœ€è¦ç›¸åº”å¢å¼ºè§£æé€»è¾‘ã€‚

---

### [CI] Implement uploading to PyPI and GitHub in the release pipeline, enable release image building for CUDA 13.0 (#31032)
**SHA**: `8e61425` | ğŸ”— [æŸ¥çœ‹æäº¤](https://github.com/vllm-project/vllm/commit/8e61425ee6d0bd03d3669c148eba8b263d101273)

**å˜æ›´ç±»å‹**ï¼šCI/Release æµç¨‹åŠŸèƒ½å¢å¼º  
**é‡è¦ç¨‹åº¦**ï¼šğŸŸ¡ ä¸­  

**æ ¸å¿ƒå˜æ›´**  
1. **releaseâ€‘pipeline.yaml**  
   - å°†æ‰€æœ‰ wheel çš„ä¸Šä¼ è„šæœ¬ä» `upload-wheels.sh` æ›¿æ¢ä¸º `uploadâ€‘nightlyâ€‘wheels.sh`ï¼Œå¹¶ç»Ÿä¸€ä½¿ç”¨ `manylinux_2_31/2_35` å‚æ•°ã€‚  
   - é‡å‘½åæ„å»ºæ­¥éª¤çš„ label ä¸ idï¼Œä½¿ CPU/CUDAã€x86 ä¸ aarch64 çš„åŒºåˆ«æ›´æ˜ç¡®ã€‚  
   - æ–°å¢ **CUDAâ€¯13.0** é•œåƒæ„å»ºã€è·¨æ¶æ„ manifest ä»¥åŠå¯¹åº”çš„ **block** ä¸ **ä¸Šä¼  release wheels** æ­¥éª¤ã€‚  
   - å°†å‘å¸ƒé•œåƒçš„æ„å»ºé˜Ÿåˆ—ç»Ÿä¸€åˆ‡æ¢åˆ° `small_cpu_queue_postmerge`ï¼Œé™ä½èµ„æºå ç”¨ã€‚  

2. **è„šæœ¬**  
   - æ–°å¢ `uploadâ€‘releaseâ€‘wheels.sh`ï¼ˆçº¦ 100 è¡Œï¼‰ï¼Œå®ç°ï¼š  
     * è¯»å– Buildkite å…ƒæ•°æ®çš„ releaseâ€‘version å¹¶æ ¡éªŒä¸ git tag æ˜¯å¦ä¸€è‡´ã€‚  
     * æ£€æŸ¥å¹¶å¯¼å‡º `PYPI_TOKEN`ã€`GITHUB_TOKEN`ï¼Œä¸‹è½½æœ€æ–° **gh CLI**ï¼ˆæœªæ ¡éªŒç­¾åï¼‰ï¼Œåˆ›å»ºä¸´æ—¶ Python venv å¹¶å®‰è£… **twine**ã€‚  
     * ä» S3 æ‹‰å–æœ¬æ¬¡ commit å¯¹åº”çš„ wheelï¼ˆä»…é»˜è®¤ variantï¼‰ï¼Œç”Ÿæˆæºç  tarballï¼Œä½¿ç”¨ **twine** ä¸Šä¼ åˆ° PyPIã€‚  
     * è°ƒç”¨ **gh** åˆ›å»º GitHub Release å¹¶é™„å¸¦æ‰€æœ‰ wheelã€‚  
   - å°†åŸ `uploadâ€‘nightlyâ€‘wheels.sh` é‡å‘½åï¼ˆæ— å†…å®¹å˜åŠ¨ï¼‰ï¼Œä¿æŒå…¼å®¹ã€‚  

**å½±å“èŒƒå›´**  
- CI/CDï¼ˆBuildkiteï¼‰å…¨æµç¨‹ï¼šæ„å»ºã€ä¸Šä¼ ã€é•œåƒå‘å¸ƒã€manifestã€GitHub Releaseã€‚  
- ä¾èµ–çš„ç¯å¢ƒå˜é‡ï¼š`PYPI_TOKENã€GITHUB_TOKENã€FORCE_RELEASE_IGNORE_VERSION_MISMATCH`ã€‚  
- S3 bucket `vllm-wheels`ã€ECR public repoã€GitHub Releaseã€‚  

**å…³æ³¨å»ºè®®**  
1. **å‡­è¯å®‰å…¨**ï¼šè„šæœ¬ç›´æ¥åœ¨ CI ç¯å¢ƒä¸­ä¸‹è½½ gh CLI å¹¶ä½¿ç”¨ tokenï¼Œå»ºè®®æ ¡éªŒä¸‹è½½çš„ tar åŒ… SHA256ï¼Œé˜²æ­¢ supplyâ€‘chain æ”»å‡»ã€‚  
2. **ç‰ˆæœ¬æ ¡éªŒ**ï¼š`releaseâ€‘version` ä¸ git tag å¿…é¡»ä¸€è‡´ï¼Œè‹¥å‡ºç°ä¸åŒ¹é…åº”åœ¨ CI å‰ç½®æ£€æŸ¥è€Œéè„šæœ¬å†…éƒ¨é€€å‡ºï¼Œä»¥å…æ©ç›–é”™è¯¯ã€‚  
3. **å¹‚ç­‰æ€§**ï¼šä¸Šä¼  PyPI ä¸ GitHub Release å‰åŠ å…¥æ£€æŸ¥ï¼ˆå¦‚ `twine check`ã€`gh release view`ï¼‰ï¼Œé˜²æ­¢åŒä¸€æ¬¡ commit é‡å¤å‘å¸ƒå¯¼è‡´é”™è¯¯ã€‚  
4. **é”™è¯¯å›æ»š**ï¼šè‹¥ PyPI ä¸Šä¼ å¤±è´¥ï¼Œå½“å‰æµç¨‹ä¼šç›´æ¥é€€å‡ºï¼Œå»ºè®®æ•è·é”™è¯¯å¹¶åœ¨ Buildkite ä¸­æ ‡è®°å¤±è´¥ï¼ŒåŒæ—¶ä¿ç•™å·²ä¸Šä¼ çš„ artifact ä¾›æ‰‹åŠ¨å›æ»šã€‚  
5. **èµ„æºä½¿ç”¨**ï¼š`small_cpu_queue_postmerge` å¯èƒ½åœ¨é«˜å¹¶å‘æ—¶å¯¼è‡´æ’é˜Ÿï¼Œè¯·ç›‘æ§ Queue æ—¶é•¿ï¼Œå¿…è¦æ—¶æä¾›å¹¶è¡Œåº¦ä¸Šé™ã€‚  
6. **æ–‡æ¡£åŒæ­¥**ï¼šæ›´æ–° README/CONTRIBUTING ä¸­å…³äº Release æµç¨‹çš„è¯´æ˜ï¼Œå°¤å…¶æ˜¯æ–°å¢çš„ `FORCE_RELEASE_IGNORE_VERSION_MISMATCH` ç¯å¢ƒå˜é‡ç”¨é€”ã€‚  

æ€»ä½“æ¥è¯´ï¼Œæ­¤æ¬¡æ”¹åŠ¨æ˜¾è‘—æå‡äº†å‘å¸ƒè‡ªåŠ¨åŒ–ï¼Œè¦†ç›–äº† CUDAâ€¯13.0ã€è·¨å¹³å°é•œåƒåŠ PyPI/GitHub å‘å¸ƒã€‚ä½†åœ¨å‡­è¯ç®¡ç†ã€ç‰ˆæœ¬æ ¡éªŒå’Œå¹‚ç­‰æ€§ä¸Šä»æœ‰ç»†åŒ–ç©ºé—´ï¼Œå»ºè®®åœ¨åç»­è¿­ä»£ä¸­åŠ å…¥ç›¸åº”å®‰å…¨æ£€æŸ¥ã€‚

---

### Revert "[Attention][MLA] Make `FLASHINFER_MLA` the default MLA backenâ€¦ (#32484)
**SHA**: `2e7c89e` | ğŸ”— [æŸ¥çœ‹æäº¤](https://github.com/vllm-project/vllm/commit/2e7c89e7084d686014672332f5f32c0aa7b1c6ba)

**ğŸ¯ å˜æ›´ç±»å‹**ï¼šé‡æ„ / å…¶ä»–ï¼ˆå›é€€ä¹‹å‰çš„é»˜è®¤è¡Œä¸ºï¼‰  
**âš¡ é‡è¦ç¨‹åº¦**ï¼šğŸŸ¡ ä¸­  
**ğŸ“‹ å˜æ›´æ‘˜è¦**ï¼šæœ¬æ¬¡æäº¤æ’¤å›äº†æ­¤å‰æŠŠ `FLASHINFER_MLA` è®¾ä¸ºé»˜è®¤åç«¯çš„æ”¹åŠ¨ã€‚`AttentionConfig.use_trtllm_ragged_deepseek_prefill` çš„é»˜è®¤å€¼æ¢å¤ä¸º `False`ï¼Œ`use_flashinfer_prefill` çš„åˆ¤å®šä¸­åŠ å…¥å¯¹è¯¥æ ‡å¿—çš„æ’é™¤ï¼›åœ¨ CUDA å¹³å°çš„åç«¯ä¼˜å…ˆçº§åˆ—è¡¨ä¸­ï¼ŒæŠŠ `FLASHINFER_MLA` ä»æœ€é«˜æ¬è‡³æ¬¡é«˜ï¼›é»˜è®¤æ¨¡å‹åœ¨ Blackwellï¼ˆSM100ï¼‰GPU ä¸Šæ¢å¤ä¸º `CUTLASS_MLA` è€Œé `FLASHINFER_MLA`ã€‚æ—¥å¿—çº§åˆ«ä¹Ÿä» `info_once` é™ä¸º `debug_once`ï¼Œå¹¶è°ƒæ•´äº† MLA åˆå§‹åŒ–æ—¶çš„åˆ†æ”¯é¡ºåºã€‚

**ğŸ¯ å½±å“èŒƒå›´**  
- **vllm/config/attention.py**ï¼šé»˜è®¤é…ç½®å˜æ›´ã€‚  
- **vllm/model_executor/layers/attention/mla_attention.py**ï¼šprefill å®ç°é€‰æ‹©é€»è¾‘ã€æ—¥å¿—è¾“å‡ºã€`_pad_v` æ§åˆ¶ã€‚  
- **vllm/platforms/cuda.py**ï¼šåç«¯ä¼˜å…ˆçº§å’Œé»˜è®¤åç«¯å†³å®šé€»è¾‘ã€‚

**ğŸ’¡ å…³æ³¨å»ºè®®**  
1. **æ€§èƒ½å›é€€**ï¼šåœ¨ Blackwell GPU ä¸Šè‹¥ä¾èµ– FlashInferâ€‘MLA çš„åŠ é€Ÿï¼Œéœ€è¦æ˜¾å¼åœ¨é…ç½®ä¸­ `attention.backend = FLASHINFER_MLA` æˆ–å¼€å¯ `use_flashinfer_mla`ã€‚å¦åˆ™å°†ä½¿ç”¨ Cutlassâ€‘MLAï¼Œå¯èƒ½å‡ºç°ååä¸‹é™ã€‚  
2. **å…¼å®¹æ€§**ï¼š`use_trtllm_ragged_deepseek_prefill` ä»å¯æ‰‹åŠ¨å¼€å¯ï¼›å…³é—­å `use_flashinfer_prefill` ä¼šæ¢å¤ç”Ÿæ•ˆï¼Œç¡®ä¿ä¸¤è€…ä¸å†²çªã€‚  
3. **æ–‡æ¡£ä¸ CI**ï¼šè¯·åœ¨ç”¨æˆ·æ‰‹å†Œä¸­æ³¨æ˜é»˜è®¤åç«¯å·²æ¢å¤ä¸º Cutlassâ€‘MLAï¼Œå¹¶æä¾›åˆ‡æ¢åˆ° FlashInferâ€‘MLA çš„ç¤ºä¾‹ï¼›ç›¸åº”çš„ CI æµ‹è¯•åº”è¦†ç›–ä¸¤ç§åç«¯çš„å¯åŠ¨è·¯å¾„ã€‚  
4. **è°ƒè¯•**ï¼šæ—¥å¿—å·²é™è‡³ DEBUGï¼Œè‹¥ç”¨æˆ·ä»éœ€çœ‹åˆ°ä¸€æ¬¡æ€§æç¤ºï¼Œå¯åœ¨è¿è¡Œæ—¶å¼€å¯ `VLLM_LOG_LEVEL=info`ã€‚  

æ€»ä½“è€Œè¨€ï¼Œæ­¤æ¬¡å›é€€ä½¿é¡¹ç›®æ¢å¤åˆ°æ›´ä¿å®ˆçš„é»˜è®¤è¡Œä¸ºï¼Œé™ä½å›  FlashInferâ€‘MLA å°šæœªåœ¨æ‰€æœ‰ç¯å¢ƒä¸­ç¨³å®šè€Œå¼•å…¥çš„é£é™©ã€‚è‹¥éœ€è¦ FlashInfer çš„ä¼˜åŠ¿ï¼Œè¯·åœ¨é…ç½®ä¸­æ‰‹åŠ¨æŒ‡å®šã€‚

---

### apply _validate_input to MistralTokenizer token-id chat prompts (#32448)
**SHA**: `037a648` | ğŸ”— [æŸ¥çœ‹æäº¤](https://github.com/vllm-project/vllm/commit/037a6487af3429bb3f3e1adfe3e2f5e5e95aa420)

**ğŸ¯ å˜æ›´ç±»å‹**ï¼šåŠŸèƒ½å¢å¼º / Bug ä¿®å¤  
**âš¡ é‡è¦ç¨‹åº¦**ï¼šğŸŸ¡ ä¸­  
**ğŸ“‹ å˜æ›´æ‘˜è¦**ï¼š  
1. åœ¨ `vllm/entrypoints/openai/engine/serving.py` ä¸­ï¼Œé’ˆå¯¹ MistralTokenizer è¿”å›çš„ **tokenâ€‘ids åˆ—è¡¨**ï¼Œæ”¹ä¸ºå…ˆé€šè¿‡ `tokenizer.decode` è·å¾—å¯è¯»æ–‡æœ¬ï¼Œå†è°ƒç”¨ç»Ÿä¸€çš„ `_validate_input` è¿›è¡Œé•¿åº¦ + `max_tokens` æ£€æŸ¥ã€‚  
2. æ–°å¢ä¸¤æ¡é’ˆå¯¹è¯¥è·¯å¾„çš„å›å½’æµ‹è¯•ï¼ŒéªŒè¯ â€‘ å½“æç¤ºæ˜¯ tokenâ€‘ids æ—¶ä»èƒ½æ•è· â€œmax_tokens è¶…å‡ºä¸Šä¸‹æ–‡çª—å£â€ ä¸ â€œè¾“å…¥æœ¬èº«å·²è¾¾æœ€å¤§ä¸Šä¸‹æ–‡é•¿åº¦â€ çš„é”™è¯¯ã€‚  

**ğŸ¯ å½±å“èŒƒå›´**ï¼š  
- `vllm.entrypoints.openai.engine.serving`ï¼ˆèŠå¤©è¯·æ±‚é¢„å¤„ç†é€»è¾‘ï¼‰  
- ç›¸å…³å•å…ƒæµ‹è¯• `tests/entrypoints/openai/test_serving_chat.py`  
- å¯èƒ½é—´æ¥å½±å“ä½¿ç”¨ MistralTokenizer çš„è‡ªå®šä¹‰æ¨¡å‹æˆ–æ’ä»¶ã€‚  

**ğŸ’¡ å…³æ³¨å»ºè®®**  
1. **ä¿æŒä¸€è‡´çš„é”™è¯¯ä¿¡æ¯**ï¼š`_validate_input` è¿”å›çš„å¼‚å¸¸ä¿¡æ¯åœ¨æ—¥å¿—ä¸ OpenAI é”™è¯¯å“åº”ä¸­ä¼šè¢«ç›´æ¥å±•ç¤ºï¼Œç¡®ä¿æ–‡æ¡ˆä¸å…¶ä»– tokenizer åˆ†æ”¯ä¿æŒç»Ÿä¸€ã€‚  
2. **é˜²å¾¡æ€§æ£€æŸ¥**ï¼šå½“å‰ä»…ä½¿ç”¨ `tokenizer.decode` ç”Ÿæˆ `input_text`ï¼›è‹¥æœªæ¥ MistralTokenizer çš„ `decode` å¯èƒ½æŠ›å¼‚å¸¸ï¼ˆå¦‚éæ³• tokenï¼‰ï¼Œå»ºè®®åœ¨è°ƒç”¨å‰æ•è·å¹¶è½¬åŒ–ä¸º `ErrorResponse`ï¼Œé˜²æ­¢æœåŠ¡å´©æºƒã€‚  
3. **æ–‡æ¡£æ›´æ–°**ï¼šåœ¨ README / API æ–‡æ¡£ä¸­æ³¨æ˜ MistralTokenizer æ”¯æŒç›´æ¥è¿”å› tokenâ€‘idsï¼Œä¸”ä»ä¼šèµ°åŒä¸€å¥—è¾“å…¥æ ¡éªŒè·¯å¾„ã€‚  
4. **æ€§èƒ½ç•™æ„**ï¼š`decode` åœ¨ä»…ç”¨äºæ ¡éªŒæ—¶å¯èƒ½äº§ç”Ÿä¸å¿…è¦çš„å­—ç¬¦ä¸²åˆ†é…ï¼Œè‹¥åç»­å‡ºç°å¤§é‡æ­¤ç±»è¯·æ±‚ï¼Œå¯è€ƒè™‘åœ¨ `_validate_input` ä¸­æ¥å— â€œtokenâ€‘ids + dummy textâ€ çš„è½»é‡å ä½ï¼Œä»¥é™ä½è§£ç å¼€é”€ã€‚  

æ€»ä½“æ¥è¯´ï¼Œæ­¤æ¬¡ä¿®æ”¹ä¿®å¤äº† MistralTokenizer åœ¨èŠå¤©æ¨¡æ¿è¿”å› tokenâ€‘ids æ—¶é—æ¼çš„è¾“å…¥é•¿åº¦æ ¡éªŒï¼Œæå‡äº†å…¼å®¹æ€§å’Œå®‰å…¨æ€§ã€‚åç»­å¯å…³æ³¨ä¸Šè¿°ç»†èŠ‚ï¼Œä»¥ä¿æŒè¡Œä¸ºä¸€è‡´å¹¶é˜²æ­¢æ½œåœ¨çš„å¼‚å¸¸æ³„æ¼ã€‚

---

#### ğŸŸ¢ ä½é‡è¦åº¦å˜æ›´ (9)

### [Misc] Fix typo: seperator -> separator in flashmla_sparse.py (#32411)
**SHA**: `2b99f21` | ğŸ”— [æŸ¥çœ‹æäº¤](https://github.com/vllm-project/vllm/commit/2b99f210f53faee71fd56cf52036040847e6b420)

**ğŸ¯ å˜æ›´ç±»å‹**ï¼šä»£ç é‡æ„  
**âš¡ é‡è¦ç¨‹åº¦**ï¼šğŸŸ¢ä½  
**ğŸ“‹ æ‘˜è¦**ï¼šå°† `FP8SeperatePrefillDecode` æ‹¼å†™é”™è¯¯æ›´æ­£ä¸º `FP8SeparatePrefillDecode`ï¼Œå¹¶åŒæ­¥æ›´æ–°æ‰€æœ‰å¼•ç”¨ã€ç±»å‹æ³¨è§£å’Œæ–­è¨€ï¼Œæ¶ˆé™¤å‘½åä¸ä¸€è‡´ã€‚

---

### [Model] Molmo2: Enable quantized weight mapping for vision backbone (#32385)
**SHA**: `1646fea` | ğŸ”— [æŸ¥çœ‹æäº¤](https://github.com/vllm-project/vllm/commit/1646fea672c939fa1204ae7ad0b7e87c072b3615)

**ğŸ¯ å˜æ›´ç±»å‹**ï¼šä»£ç é‡æ„  
**âš¡ é‡è¦ç¨‹åº¦**ï¼šğŸŸ¢ ä½  
**ğŸ“‹ æ‘˜è¦**ï¼šåœ¨ Molmo2 æ¨¡å‹ä¸­ä¸ºè§†è§‰èƒŒéª¨çš„çº¿æ€§å±‚åŠ å…¥ `prefix` å‚æ•°ä»¥æ”¯æŒé‡åŒ–æƒé‡æ˜ å°„ï¼Œå¹¶åŒæ­¥æ›´æ–° `WeightsMapper` ä¸­çš„æƒé‡åç§°æ˜ å°„ã€‚é¡ºåºè°ƒæ•´äº† `BaseDummyInputsBuilder` çš„å¯¼å…¥ã€‚

---

### [Models] Lfm2Moe: minor name changes for resolving lora conflicts (#29063)
**SHA**: `d3317bb` | ğŸ”— [æŸ¥çœ‹æäº¤](https://github.com/vllm-project/vllm/commit/d3317bbba44ec11bbef435308f98284487fce45a)

**ğŸ¯ å˜æ›´ç±»å‹**ï¼šä»£ç é‡æ„  
**âš¡ é‡è¦ç¨‹åº¦**ï¼šğŸŸ¢ä½  
**ğŸ“‹ æ‘˜è¦**ï¼šåœ¨ Lfm2 ä¸ Lfm2Moe æ¨¡å‹ä¸­å°† `conv` å±æ€§æ”¹åä¸º `short_conv`ï¼Œå¹¶åœ¨ `load_weights` ä¸­åŠ å…¥ç›¸åº”çš„åç§°æ˜ å°„ï¼Œä»¥è§£å†³ LoRA å‚æ•°å‘½åå†²çªï¼ŒåŒæ—¶åœ¨ LoRA å‚æ•°æ˜ å°„è¡¨ä¸­æ–°å¢ `in_proj`ã€‚

---

### [Docs][Governance] Add @robertshaw2-redhat to lead maintainers group (#32498)
**SHA**: `5a3050a` | ğŸ”— [æŸ¥çœ‹æäº¤](https://github.com/vllm-project/vllm/commit/5a3050a0892a78f4224cd6e8e7f3f737578b9362)

**ğŸ¯ å˜æ›´ç±»å‹**ï¼šæ–‡æ¡£æ›´æ–°  
**âš¡ é‡è¦ç¨‹åº¦**ï¼šğŸŸ¢ä½  
**ğŸ“‹ æ‘˜è¦**ï¼šåœ¨ `docs/governance/process.md` ä¸­æ–°å¢ `@robertshaw2-redhat` ä¸º Lead Maintainers æˆå‘˜ã€‚

---

### [TPU][Core] Enable Pipeline Parallelism on TPU backend (#28506)
**SHA**: `484e22b` | ğŸ”— [æŸ¥çœ‹æäº¤](https://github.com/vllm-project/vllm/commit/484e22bc1880bcf87c51164ba2ae4e25b7a432e9)

**ğŸ¯ å˜æ›´ç±»å‹**ï¼šä»£ç é‡æ„  
**âš¡ é‡è¦ç¨‹åº¦**ï¼šğŸŸ¢ä½  
**ğŸ“‹ æ‘˜è¦**ï¼šåœ¨ `multiproc_executor` ä¸­æŠ½å–å¹¶è¡Œå°ºå¯¸è·å–é€»è¾‘ï¼Œæ–°å¢é©±åŠ¨ worker åˆ¤å®šä¸åç½®åˆå§‹åŒ–é’©å­ï¼›åœ¨ `ray_utils` ä¸­å°è£… `IntermediateTensors` çš„ç±»å‹æ£€æŸ¥ã€‚

---

### [CI] Fix OOM in Hopper Fusion E2E Tests (H100) (#32489)
**SHA**: `ca21288` | ğŸ”— [æŸ¥çœ‹æäº¤](https://github.com/vllm-project/vllm/commit/ca21288080882714d7d10ee8588641225b08756c)

**ğŸ¯ å˜æ›´ç±»å‹**ï¼šé…ç½®è°ƒæ•´  
**âš¡ é‡è¦ç¨‹åº¦**ï¼šğŸŸ¢ä½  
**ğŸ“‹ æ‘˜è¦**ï¼šåœ¨ Buildkite æµ‹è¯•æµæ°´çº¿é…ç½®ä¸­ï¼Œé’ˆå¯¹ Hopper Fusion E2E æµ‹è¯•ï¼ˆH100ï¼‰ï¼Œæ–°å¢å¯¹ `Llama-4` æ¨¡å‹çš„è¿‡æ»¤ï¼Œä»¥é¿å… OOMï¼›é€šè¿‡ `-k 'not Llama-4'` å‚æ•°è·³è¿‡è¯¥æ¨¡å‹çš„è¿è¡Œã€‚

---

### [responsesAPI] allow tuning include_stop_str_in_output (#32383)
**SHA**: `4c82b6f` | ğŸ”— [æŸ¥çœ‹æäº¤](https://github.com/vllm-project/vllm/commit/4c82b6fac7700ef544e748aa4c6d1774cebc6ab2)

**ğŸ¯ å˜æ›´ç±»å‹**ï¼šä»£ç é‡æ„ï¼ˆæ–°å¢è¯·æ±‚å­—æ®µï¼‰  
**âš¡ é‡è¦ç¨‹åº¦**ï¼šğŸŸ¢ ä½  
**ğŸ“‹ æ‘˜è¦**ï¼šåœ¨ `ResponsesRequest` ä¸­åŠ å…¥ `include_stop_str_in_output` å‚æ•°ï¼Œå¹¶åœ¨ `to_sampling_params` ä¸­å‘é‡‡æ ·é…ç½®ä¼ é€’è¯¥æ ‡å¿—ï¼Œé»˜è®¤å…³é—­ã€‚

---

### [LoRA] Update LoRA expand kernel heuristic (#32425)
**SHA**: `a884bc6` | ğŸ”— [æŸ¥çœ‹æäº¤](https://github.com/vllm-project/vllm/commit/a884bc62d6eeeb58e87e56b2d966c63f073ada77)

**ğŸ¯ å˜æ›´ç±»å‹**ï¼šä»£ç é‡æ„  
**âš¡ é‡è¦ç¨‹åº¦**ï¼šğŸŸ¢ä½  
**ğŸ“‹ æ‘˜è¦**ï¼šå°† LoRA expand kernel çš„ `block_n` ä»å›ºå®š 128 æ”¹ä¸º `max(64, next_power_of_2(128 // num_slices))`ï¼Œåœ¨å¤šåˆ‡ç‰‡æƒ…å†µä¸‹è‡ªé€‚åº”æå‡æ€§èƒ½ã€‚

---

### [CI] Update deepgemm to newer version (#32479)
**SHA**: `9fd918e` | ğŸ”— [æŸ¥çœ‹æäº¤](https://github.com/vllm-project/vllm/commit/9fd918e510c8981ccbab0380bf8d42fa81df1e9e)

**ğŸ¯ å˜æ›´ç±»å‹**ï¼šé…ç½®è°ƒæ•´  
**âš¡ é‡è¦ç¨‹åº¦**ï¼šğŸŸ¢ä½  
**ğŸ“‹ æ‘˜è¦**ï¼šå°† `tools/install_deepgemm.sh` ä¸­çš„ DeepGEMM ä»£ç ä»“åº“å¼•ç”¨ä» commit `594953a...` æ›´æ–°ä¸ºæœ€æ–°çš„ `0f5f266...`ï¼Œä»¥ä½¿ç”¨æ–°ç‰ˆ DeepGEMMã€‚

---

