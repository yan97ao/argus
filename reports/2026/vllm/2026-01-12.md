# æ¯æ—¥æ›´æ–°æŠ¥å‘Šï¼ˆ2026-01-12ï¼‰

## vllm-project/vllm

| æäº¤æ—¶é—´ | ä½œè€… | æäº¤ä¿¡æ¯ |
|----------|------|----------|
| 2026-01-12 23:33:21 | TJian | [ROCm] [Bugfix] Fix order of mori build in Dockerfile.rocm_base (#32179) |
| 2026-01-12 23:10:50 | Andy Zhang | doc: Update model name for Qwen3-Coder in documentation (#32185) |
| 2026-01-12 23:00:43 | Or Ozeri | OffloadingConnector: Add cpu_bytes_to_use configuration (#24498) |
| 2026-01-12 22:23:04 | Hongxin Xu | [Feature] Support recording expert indices for rollout router replay (#28284) |
| 2026-01-12 20:35:35 | dtc | [P/D] Refactor mooncake connector sender thread using async coroutines (#31573) |
| 2026-01-12 19:13:41 | Isotr0py | [Bugfix] Fix missing scale passing for encoder Triton Attention implementation  (#32149) |
| 2026-01-12 18:33:48 | RickyChen / é™³æ˜­å„’ | [Doc] Add documentation for offline API docs feature (#32134) |
| 2026-01-12 18:19:17 | Jee Jee Li | [Doc] Improve LoRA docs (#32159) |
| 2026-01-12 18:18:38 | XlKsyt | [doc] fix broken links (#32158) |
| 2026-01-12 18:03:32 | daniel-salib | [Frontend] Fix Flaky MCP Streaming Test (#32153) |
| 2026-01-12 18:03:28 | Andika Rachman | [cpu][bench] Add Fused MoE Micro Benchmark for CPU Backend (#32092) |
| 2026-01-12 17:58:21 | NicolÃ² Lucchesi | [Misc] Disable default `--ready-check-timeout-sec` extra call in vllm bench (#30975) |
| 2026-01-12 17:19:30 | Cyrus Leung | [Model] Remove incorrect `SupportsPP` from MTP models (#32150) |
| 2026-01-12 15:54:09 | wang.yuqi | [Model] Improve multimodal pooling examples (#32085) |
| 2026-01-12 13:28:12 | Cyrus Leung | [Model] Avoid hardcoding pooling type (#32119) |
| 2026-01-12 12:24:30 | Woosuk Kwon | [Model Runner V2] Remove async barrier (#32083) |
| 2026-01-12 06:31:04 | Woosuk Kwon | [Model Runner V2] Skip building deprecated fields in attn metadata (#32132) |

### ğŸ“Š ç»Ÿè®¡æ‘˜è¦
> æœ¬æ—¥å…± 17 ä¸ªæäº¤ | ğŸ”´é«˜ 1 | ğŸŸ¡ä¸­ 9 | ğŸŸ¢ä½ 7
## ğŸ“‹ ç›®å½•

- [vllm-project/vllm](#vllm-project-vllm)
  - [ğŸ“Š ç»Ÿè®¡æ‘˜è¦](#-ç»Ÿè®¡æ‘˜è¦)
  - [ğŸ”´ é«˜é‡è¦åº¦å˜æ›´ (1)](#-ğŸ”´-é«˜é‡è¦åº¦å˜æ›´-1)
    - [[Model Runner V2] Remove async barrier (#32083)](#025a32f)
  - [ğŸŸ¡ ä¸­é‡è¦åº¦å˜æ›´ (9)](#-ğŸŸ¡-ä¸­é‡è¦åº¦å˜æ›´-9)
    - [OffloadingConnector: Add cpu_bytes_to_use configuration (...](#9cddbdb)
    - [[Feature] Support recording expert indices for rollout ro...](#49e6b86)
    - [[P/D] Refactor mooncake connector sender thread using asy...](#0565f1f)
    - [[Bugfix] Fix missing scale passing for encoder Triton Att...](#9dbe1fe)
    - [[cpu][bench] Add Fused MoE Micro Benchmark for CPU Backen...](#5e034f2)
    - [[Model] Remove incorrect `SupportsPP` from MTP models (#3...](#600aaab)
    - [[Model] Improve multimodal pooling examples (#32085)](#60446cd)
    - [[Model] Avoid hardcoding pooling type (#32119)](#9101dc7)
    - [[Model Runner V2] Skip building deprecated fields in attn...](#19504ac)
  - [ğŸŸ¢ ä½é‡è¦åº¦å˜æ›´ (7)](#-ğŸŸ¢-ä½é‡è¦åº¦å˜æ›´-7)
    - [[ROCm] [Bugfix] Fix order of mori build in Dockerfile.roc...](#0346396)
    - [doc: Update model name for Qwen3-Coder in documentation (...](#e68b0da)
    - [[Doc] Add documentation for offline API docs feature (#32...](#a5f89ae)
    - [[Doc] Improve LoRA docs (#32159)](#05e8981)
    - [[doc] fix broken links (#32158)](#899541b)
    - [[Frontend] Fix Flaky MCP Streaming Test (#32153)](#d7b2e57)
    - [[Misc] Disable default `--ready-check-timeout-sec` extra ...](#22970c1)
#### ğŸ”´ é«˜é‡è¦åº¦å˜æ›´ (1)

### [Model Runner V2] Remove async barrier (#32083)
**SHA**: `025a32f` | ğŸ”— [æŸ¥çœ‹æäº¤](https://github.com/vllm-project/vllm/commit/025a32f9ed53b69c90be8a8883f5c9d880880d8a)

**ğŸ¯ å˜æ›´ç±»å‹**ï¼šé‡æ„ / æ€§èƒ½ä¼˜åŒ–  
**âš¡ é‡è¦ç¨‹åº¦**ï¼šğŸ”´é«˜  

---  

### ğŸ“‹ å˜æ›´æ‘˜è¦
1. å½»åº•ç§»é™¤ `async_barrier`ï¼Œæ”¹ä¸º **æ˜¾å¼ stagedâ€‘write** ä¸ **UVA buffer pool** æœºåˆ¶ï¼Œæ‰€æœ‰ CPUâ†’GPU çš„æ‹·è´ç»Ÿä¸€èµ° `UvaBufferPool` / `StagedWriteTensor`ã€‚  
2. æ–°å¢ `buffer_utils.py`ï¼Œæä¾› `UvaBuffer`, `UvaBufferPool`, `UvaBackedTensor`, `StagedWriteTensor` å››ç±»é«˜æ•ˆç¼“å†²åŒºå®ç°ã€‚  
3. `BlockTablesã€InputBuffersã€InputBatchã€ModelRunnerã€Samplerã€SpecDecodeã€Statesã€StructuredOutputs` ç­‰æ ¸å¿ƒæ¨¡å—åŒæ­¥æ”¹ç”¨ä¸Šè¿°ç¼“å†²åŒºï¼Œå»é™¤ `CpuGpuBuffer` ä¸ `async_barrier` ç›¸å…³ä»£ç ã€‚  
4. å°† **é‡‡æ ·å…ƒæ•°æ®æ‰©å±•**ï¼ˆexpand_sampling_metadataï¼‰å†…è”åˆ° `expand_idx_mapping`ï¼Œå¹¶åœ¨é‡‡æ ·ç›¸å…³ kernel ä¸­æ˜¾å¼ä¼ å…¥ `idx_mapping`ã€‚  
5. å¼•å…¥ `StructuredOutputsWorker` è´Ÿè´£è¯­æ³•ä½æ©ç çš„æ‹·è´/æ˜ å°„ï¼Œé¿å…åœ¨ `model_runner` ä¸­ç›´æ¥æ“ä½œ `InputBuffers`ã€‚  

---  

### ğŸ¯ å½±å“èŒƒå›´
- **vllm/v1/worker/gpu/**ï¼š`block_table.py`, `buffer_utils.py`, `cudagraph_utils.py`, `input_batch.py`, `model_runner.py`, `sample/*`, `spec_decode/*`, `states.py`, `structured_outputs.py`  
- **æ ¸å¿ƒæ‰§è¡Œè·¯å¾„**ï¼šæ¨¡å‹å‰å‘ã€CUDA Graph æ•è·ã€é‡‡æ ·ã€specâ€‘decodeã€grammarâ€‘bitmask åº”ç”¨ã€KVâ€‘cache æ›´æ–°ã€‚  
- **è·¨è¿›ç¨‹/å¤š GPUï¼ˆDPï¼‰**ï¼š`cudagraph_utils` ä¸ `UvaBufferPool` çš„å¹¶å‘æ‹·è´é€»è¾‘ã€‚  

---  

### ğŸ” æŠ€æœ¯æ´å¯Ÿ  

| ç»´åº¦ | å½±å“ | è¯´æ˜ |
|------|------|------|
| **æ¶æ„** | **è§£è€¦ asyncâ€‘barrier** <br>å¼•å…¥ç»Ÿä¸€çš„ **Stageâ€‘Write â†’ Apply** æµç¨‹ | é€šè¿‡ `StagedWriteTensor.apply_write()` æ˜ç¡®å†™å…¥æ—¶ç‚¹ï¼Œé¿å…åŸæ¥ä¾èµ– `async_barrier` çš„éšå¼åŒæ­¥ï¼›æ¨¡å—é—´ä¸å†é€šè¿‡å…¨å±€ `Event` ä¼ é€’çŠ¶æ€ï¼Œä»£ç å¯è¯»æ€§å’Œå¯ç»´æŠ¤æ€§æå‡ã€‚ |
| **æ€§èƒ½** | **æ˜¾è‘—é™ä½åŒæ­¥ç‚¹** <br>**CPUâ†’GPU æ‹·è´æ‰¹é‡åŒ–** | 1) åªåœ¨éœ€è¦æ—¶ä¸€æ¬¡æ€§æŠŠæ‰€æœ‰ staged æ•°æ®å†™å…¥ GPUï¼Œå‰Šå‡ `cudaMemcpyAsync` è°ƒç”¨æ¬¡æ•°ã€‚<br>2) `UvaBufferPool` å®ç° **ç¯å½¢ buffer**ï¼Œåœ¨åŒä¸€å¸§å†…å¤šæ¬¡æ‹·è´å¯å¤ç”¨å·²æœ‰ UVA æ˜ å°„ï¼Œé™ä½æ˜¾å­˜å ç”¨ã€‚<br>3) ç§»é™¤ `async_barrier` åï¼ŒCPU ç«¯å‡†å¤‡ä¸ GPU ç«¯æ‰§è¡Œå¯ä»¥å¹¶è¡Œï¼Œæå‡ååï¼ˆå®˜æ–¹ PR å·å·²æŠ¥å‘Š ~5â€‘10% åŠ é€Ÿï¼‰ã€‚ |
| **å†…å­˜** | **UVA å¤ç”¨ + å—é™æ˜¾å­˜å ç”¨** | `UvaBackedTensor` åªåœ¨ CPU ä¸Šä¿ç•™åŸå§‹æ•°æ®ï¼ŒGPU ç«¯é€šè¿‡ UVA è§†å›¾è¯»å–ï¼Œé€‚ç”¨äºè¶…å¤§ `prefill_token_ids`ã€`prompt_bin_mask` ç­‰ç¨€ç–/ä¸€æ¬¡æ€§ä½¿ç”¨çš„å¼ é‡ã€‚å¯åœ¨æ˜¾å­˜ç´§å¼ çš„åœºæ™¯ä¸‹æ˜¾è‘—èŠ‚çœæ˜¾å­˜ï¼ˆå°¤å…¶åœ¨é«˜ `max_model_len` æ—¶ï¼‰ã€‚ |
| **å®‰å…¨** | **æ— æ–°å¢ç½‘ç»œ/æ–‡ä»¶é£é™©** | å˜æ›´ä»…æ¶‰åŠå†…éƒ¨æ•°æ®æ¬è¿ä¸ kernel å‚æ•°ï¼Œæœªå¼•å…¥å¤–éƒ¨è¾“å…¥è·¯å¾„ã€‚å”¯ä¸€å®‰å…¨å…³æ³¨ç‚¹æ˜¯ **UVA å¯ç”¨æ€§æ£€æµ‹**ï¼š`UvaBuffer` åœ¨æ„é€ æ—¶ä»ä¼š `assert is_uva_available()`ï¼ˆåœ¨ `buffer_utils.py` ä¸­ï¼‰ï¼Œå› æ­¤åœ¨ä¸æ”¯æŒ UVA çš„æœºå™¨ä¸Šä¼šæå‰æŠ¥é”™ï¼Œä¿æŒå®‰å…¨è¾¹ç•Œã€‚ |
| **å¹¶å‘/åˆ†å¸ƒå¼** | **UvaBufferPool æ”¯æŒ max_concurrency** | é€šè¿‡è½®è½¬æ–¹å¼å®ç° **å¤šå¹¶å‘æ‹·è´**ï¼Œåœ¨ DPï¼ˆDataâ€‘Parallelï¼‰æ¨¡å¼ä¸‹å¯é¿å…å• buffer æˆä¸ºç“¶é¢ˆã€‚ä½†ä»éœ€ç¡®ä¿ `copy_to_uva` ä¸åç»­ `apply_write` ä¹‹é—´çš„åŒæ­¥ï¼ˆ`torch.cuda.synchronize()` å·²åœ¨é‡æ–°åˆ†é…æ—¶æ’å…¥ï¼‰ã€‚ |
| **å¯ç»´æŠ¤æ€§** | **ç»Ÿä¸€ç¼“å†²åŒºæŠ½è±¡** <br>**é‡‡æ ·å…ƒæ•°æ®ä¸å†åœ¨ kernel å†…éƒ¨å±•å¼€** | `expand_idx_mapping` ä¸ `expand_idx_mapping_kernel` æ›¿ä»£äº†åŸ `expand_sampling_metadata`ï¼Œå®ç°æ›´è½»é‡çš„ â€œä¸€æ¬¡æ€§æ˜ å°„â€ã€‚ä»£ç è·¯å¾„æ›´æ¸…æ™°ï¼Œåç»­åŠ å…¥æ–°é‡‡æ ·å‚æ•°åªéœ€è¦åœ¨ `SamplingMetadata` ä¸­æ·»åŠ å­—æ®µå¹¶åœ¨ `expand_idx_mapping` ä¸­å¤åˆ¶å³å¯ã€‚ |
| **å…¼å®¹æ€§** | **å‘åå…¼å®¹æ€§ç ´å** | - `ModelRunner`ã€`Sampler`ã€`SpecDecode` æ¥å£å·²å…¨éƒ¨æ”¹ä¸ºæ¥å— `idx_mapping`ï¼ˆåŸå…ˆåŸºäº `req_ids` çš„æ˜ å°„å·²åˆ é™¤ï¼‰ï¼Œå¤–éƒ¨è°ƒç”¨è‹¥ç›´æ¥ä½¿ç”¨æ—§ API å°†ç¼–è¯‘é”™è¯¯ã€‚ <br>- `InputBuffers` åˆ é™¤äº† `pin_memory` å‚æ•°ï¼Œæ‰€æœ‰ `CpuGpuBuffer` æ›¿æ¢ä¸º `torch` åŸç”Ÿå¼ é‡æˆ–æ–°çš„ç¼“å†²ã€‚ <br>å› æ­¤å‡çº§åˆ°æ­¤æäº¤éœ€åŒæ­¥æ›´æ–°è‡ªå®šä¹‰æ’ä»¶æˆ–å¤–éƒ¨æµ‹è¯•è„šæœ¬ã€‚ |

---  

### âš ï¸ æ½œåœ¨é£é™©  

1. **Staged Write æ—¶åºé”™è¯¯**  
   - è‹¥åœ¨ `apply_staged_writes()` å‰å³ä½¿ç”¨ `prefill_token_ids.gpu`ã€`num_computed_tokens` ç­‰å¼ é‡ï¼Œå¯èƒ½è¯»å–åˆ°æœªå†™å…¥çš„æ—§å€¼ã€‚æ‰€æœ‰ä½¿ç”¨è¿™äº›å¼ é‡çš„ä»£ç å¿…é¡»åœ¨ `apply_staged_writes()` ä¹‹åæ‰§è¡Œï¼ˆå·²åœ¨ `ModelRunner.update_states`ã€`prepare_inputs` ä¸­è°ƒåºï¼Œä½†å¤–éƒ¨æ’ä»¶éœ€ä¿æŒä¸€è‡´ï¼‰ã€‚  

2. **UVA ä¸å¯ç”¨çš„å›é€€è·¯å¾„ç¼ºå¤±**  
   - `UvaBufferPool` åœ¨æ„é€ æ—¶ä¼šç›´æ¥ `assert is_uva_available()`ï¼›åœ¨ä¸æ”¯æŒ UVA çš„æœºå™¨ï¼ˆå¦‚æŸäº›æ—§æ˜¾å¡é©±åŠ¨ï¼‰ä¼šåœ¨ import æ—¶æŠ›å¼‚å¸¸ï¼Œå¯¼è‡´æ•´ä¸ªæœåŠ¡å¯åŠ¨å¤±è´¥ã€‚å»ºè®®åœ¨éƒ¨ç½²è„šæœ¬ä¸­æ£€æµ‹ `torch.cuda.get_device_capability()` å¹¶æå‰ç»™å‡ºæç¤ºã€‚  

3. **Kernel å‘å°„æ¬¡æ•°æ¿€å¢**  
   - `StagedWriteTensor.apply_write` ä¸ºæ¯ä¸ª block tableå¯åŠ¨å•ç‹¬ kernel (`_apply_write_kernel`). åœ¨æç«¯æƒ…å†µä¸‹ï¼ˆå¤§é‡ KVâ€‘groupï¼‰ï¼Œå¯èƒ½äº§ç”Ÿå¤§é‡å° kernelï¼Œå¸¦æ¥è°ƒåº¦å¼€é”€ã€‚åç»­å¯è€ƒè™‘åˆå¹¶æ‰€æœ‰ block tablesåˆ°ä¸€ä¸ª kernelï¼ˆPR å·²æ ‡è®° TODOï¼‰ã€‚  

4. **é‡‡æ ·å…ƒæ•°æ®æ‰©å±•é”™è¯¯**  
   - `expand_idx_mapping` ä¾èµ– `cu_num_logits` ä¸ `max_expand_len`ï¼Œè‹¥ `num_speculative_steps` ä¸å®é™… draft tokenæ•°ä¸åŒ¹é…ï¼Œæ˜ å°„é•¿åº¦ä¼šå‡ºé”™ï¼Œå¯¼è‡´ **IndexError** æˆ– **logits è¦†ç›–**ã€‚å¿…é¡»åœ¨ `prepare_inputs` ä¸­ä¸¥æ ¼æ£€æŸ¥ `total_num_logits == input_batch.cu_num_logits[-1]`ã€‚  

5. **Grammar Bitmask æ˜ å°„**  
   - `StructuredOutputsWorker.apply_grammar_bitmask` ç°åœ¨é€šè¿‡ä¸¤æ­¥æ‹·è´ï¼ˆæ˜ å°„ â†’ bitmaskï¼‰ï¼Œè‹¥ `grammar_req_ids` ä¸ `input_batch.req_ids` ä¸åŒ¹é…ä¼šäº§ç”Ÿ **ç©ºæ˜ å°„**ï¼Œå¯¼è‡´ kernel è¯»å–æœªåˆå§‹åŒ–çš„ `logits_indices`ã€‚éœ€åœ¨è°ƒç”¨å‰éªŒè¯ `len(mapping) == grammar_bitmask.shape[0]`ã€‚  

6. **DP ç¯å¢ƒä¸‹çš„ `UvaBufferPool`

---

#### ğŸŸ¡ ä¸­é‡è¦åº¦å˜æ›´ (9)

### OffloadingConnector: Add cpu_bytes_to_use configuration (#24498)
**SHA**: `9cddbdb` | ğŸ”— [æŸ¥çœ‹æäº¤](https://github.com/vllm-project/vllm/commit/9cddbdba6d714bb0b0303b0648c8f8bb14d0b8f2)

**ğŸ¯ å˜æ›´ç±»å‹**ï¼šåŠŸèƒ½å¢å¼ºã€è¿ç§»æ—§é…ç½®  
**âš¡ é‡è¦ç¨‹åº¦**ï¼šğŸŸ¡ ä¸­  

**ğŸ“‹ å˜æ›´æ‘˜è¦**  
- åœ¨ `OffloadingConnector` ä¸­å¼•å…¥ `cpu_bytes_to_use`ï¼Œå–ä»£åŸæ¥çš„ `num_cpu_blocks`ï¼Œç”±ç”¨æˆ·ç›´æ¥å£°æ˜å¸Œæœ›å ç”¨çš„ CPU å†…å­˜ï¼ˆå­—èŠ‚ï¼‰ã€‚  
- `OffloadingSpecFactory` ä¸æ‰€æœ‰ Offloadingâ€‘Spec çš„æ„é€ å‡½æ•°æ–°å¢ `kv_cache_config` å‚æ•°ï¼Œä»¥ä¾¿åœ¨ CPU ç«¯æ ¹æ® KVâ€‘cache é¡µé¢å¤§å°ã€å—æ•°ç­‰ä¿¡æ¯è®¡ç®—å®é™…éœ€è¦çš„å—æ•° (`num_blocks`)ã€‚  
- ç›¸åº”çš„æ–‡æ¡£ã€å•å…ƒæµ‹è¯•ä»¥åŠ `VllmConfig._post_init_kv_transfer_config` å·²åŒæ­¥æ”¹ä¸ºä½¿ç”¨æ–°å­—æ®µã€‚  

**ğŸ¯ å½±å“èŒƒå›´**  
- `vllm/config/vllm.py`ã€`vllm/distributed/kv_transfer/kv_connector/v1/offloading_connector.py`ã€`vllm/v1/kv_offload/*.py`ã€`vllm/v1/kv_offload/factory.py`ã€`vllm/v1/kv_offload/spec.py`ã€‚  
- å•å…ƒæµ‹è¯• `tests/v1/kv_connector/unit/*`ã€`tests/v1/kv_offload/test_cpu_offloading.py`ã€‚  
- æ–‡æ¡£ `docs/features/disagg_prefill.md`ã€‚  

**ğŸ’¡ å…³æ³¨å»ºè®®**  
1. **å…¼å®¹æ€§**ï¼š`num_cpu_blocks` å·²ä¸å†ä½¿ç”¨ï¼Œè‹¥å¤–éƒ¨ä»ä¼ å…¥è¯¥å­—æ®µä¼šè¢«å¿½ç•¥æˆ–å¯¼è‡´å¼‚å¸¸ã€‚å»ºè®®åœ¨ `VllmConfig._post_init_kv_transfer_config` åŠ å…¥å‘åå…¼å®¹è­¦å‘Šæˆ–è‡ªåŠ¨è½¬æ¢ï¼Œä»¥å…ç”¨æˆ·å‡çº§åæŠ¥é”™ã€‚  
2. **è®¡ç®—æ ¡éªŒ**ï¼š`CPUOffloadingSpec` æ ¹æ® `cpu_bytes_to_use` è®¡ç®— `num_blocks`ï¼Œæ¶‰åŠ `kv_cache_config`ã€å¹¶è¡Œåº¦ä¸é¡µé¢å¤§å°çš„ä¹˜ç§¯ã€‚è¯·ç¡®ä¿åœ¨æ¨¡å‹åˆå§‹åŒ–å‰ `kv_cache_config` å·²å®Œå…¨æ„é€ ï¼Œå¦åˆ™ä¼šå‡ºç° `None` å¯¼è‡´æ–­è¨€å¤±è´¥ã€‚å¯åœ¨ `OffloadingConnector` åˆå§‹åŒ–å‰åŠ å…¥æ˜¾å¼æ£€æŸ¥å¹¶ç»™å‡ºå‹å¥½é”™è¯¯ä¿¡æ¯ã€‚  
3. **æº¢å‡ºä¸ç²¾åº¦**ï¼š`cpu_bytes_to_use` å¯èƒ½æ˜¯å¤§æ•°ï¼ˆGiB çº§ï¼‰ï¼Œåœ¨ `int(cpu_bytes_to_use) // kv_bytes_per_offloaded_block` æ—¶è¦é˜²æ­¢é™¤é›¶æˆ–è´Ÿå€¼ã€‚å»ºè®®åœ¨è¯»å–é…ç½®æ—¶å¯¹æ•°å€¼èŒƒå›´åšä¸€æ¬¡ `>0` æ ¡éªŒã€‚  
4. **æ–‡æ¡£ä¸ç¤ºä¾‹**ï¼šæ–‡æ¡£å·²æ”¹ä¸ºç¤ºä¾‹ä½¿ç”¨ `cpu_bytes_to_use`ï¼Œä½†ä»ä¿ç•™æ—§å­—æ®µçš„è¯´æ˜ä¼šå¸®åŠ©è¿ç§»ã€‚å¯åœ¨ README æˆ– changelog ä¸­åˆ—å‡º â€œä» `num_cpu_blocks` åˆ° `cpu_bytes_to_use` çš„è¿ç§»æ­¥éª¤â€ã€‚  
5. **æµ‹è¯•è¦†ç›–**ï¼šå½“å‰å•å…ƒæµ‹è¯•å·²æ›´æ–°ä¸ºä½¿ç”¨å­—èŠ‚å€¼ï¼Œä½†ä»ç¼ºå°‘å¯¹å¼‚å¸¸è·¯å¾„çš„éªŒè¯ï¼ˆå¦‚ç¼ºå°‘ `cpu_bytes_to_use`ã€kv_cache_config ä¸º None ç­‰ï¼‰ã€‚è¡¥å……è¿™äº›è¾¹ç•Œæµ‹è¯•ï¼Œä»¥é˜²å›å½’ã€‚  

æ€»ä½“æ¥çœ‹ï¼Œæ­¤æ¬¡æ”¹åŠ¨æŠŠç”¨æˆ·å…³æ³¨ç‚¹ä»â€œå—æ•°â€è¿ç§»åˆ°æ›´ç›´è§‚çš„â€œå†…å­˜å¤§å°â€ï¼Œæå‡å¯é…ç½®æ€§ã€‚åªè¦æ³¨æ„å…¼å®¹æ€§æ£€æŸ¥ã€è®¡ç®—çš„å¥å£®æ€§ä»¥åŠå®Œå–„æ–‡æ¡£/æµ‹è¯•ï¼Œå³å¯å®‰å…¨åˆå…¥ã€‚

---

### [Feature] Support recording expert indices for rollout router replay (#28284)
**SHA**: `49e6b86` | ğŸ”— [æŸ¥çœ‹æäº¤](https://github.com/vllm-project/vllm/commit/49e6b86c91cddc4a4b2152c6d8834780bbd50deb)

**ğŸ¯ å˜æ›´ç±»å‹**ï¼šåŠŸèƒ½å¢å¼º  
**âš¡ é‡è¦ç¨‹åº¦**ï¼šğŸŸ¡ ä¸­  
**ğŸ“‹ å˜æ›´æ‘˜è¦**ï¼šæ–°å¢ `enable_return_routed_experts` é…ç½®é¡¹ï¼Œæ”¯æŒåœ¨ MoEï¼ˆMixtureâ€‘ofâ€‘Expertsï¼‰æ¨¡å‹æ¨ç†æ—¶è®°å½•æ¯å±‚è·¯ç”±åˆ°çš„ä¸“å®¶ç´¢å¼•ï¼Œå¹¶é€šè¿‡å…±äº«å†…å­˜æŠŠè¿™äº›ä¿¡æ¯ä» GPU ä¼ åˆ° CPUï¼Œæœ€ç»ˆåœ¨ `CompletionOutput` ä¸­è¿”å› `routed_experts`ï¼ˆå½¢çŠ¶ `[seq_len, num_layers, topk]`ï¼‰ã€‚  

**ğŸ¯ å½±å“èŒƒå›´**ï¼š

| æ¨¡å— | ä¸»è¦æ”¹åŠ¨ |
|------|----------|
| `config/model.py`ã€`config/vllm.py`ã€`engine/arg_utils.py`ã€`entrypoints/llm.py` | æ·»åŠ  `enable_return_routed_experts` å‚æ•°å¹¶æ¥å…¥ CLI / APIã€‚ |
| `model_executor/layers/fused_moe` | æ–°å¢ `RoutedExpertsCapturer` ä¸ `RoutedExpertsReader`ï¼Œåœ¨ `FusedMoE` å‰å‘ä¸­æ•è· `topk_ids` å¹¶å†™å…¥å…±äº«å†…å­˜ã€‚ |
| `outputs.py`ã€`v1/core/sched/scheduler.py`ã€`v1/engine/*` | åœ¨è°ƒåº¦ã€è¾“å‡ºå¤„ç†é“¾è·¯ä¸­è¯»å–å…±äº«å†…å­˜å¹¶æŠŠæ•°æ®å¡«å……è¿› `EngineCoreOutput` â†’ `RequestOutput` â†’ `CompletionOutput.routed_experts`ã€‚ |
| `gpu_model_runner.py` | åˆå§‹åŒ–æ•è·å™¨ã€åœ¨æ¨¡å‹æ‰§è¡Œç»“æŸåä¿å­˜ç¼“å†²åŒºã€åœ¨ KVâ€‘cache æ›´æ–°é˜¶æ®µæ¸…ç†ç¼“å†²åŒºã€‚ |
| å…¶å®ƒ | æ·»åŠ å¿…è¦çš„ `numpy` å¯¼å…¥ã€ç±»å‹æ³¨è§£ä»¥åŠæ–­è¨€ï¼ˆç¦æ­¢åœ¨ DCP/PCP åœºæ™¯ä¸‹ä½¿ç”¨ï¼‰ã€‚ |

**ğŸ’¡ å…³æ³¨å»ºè®®**ï¼š

1. **å…¼å®¹æ€§**ï¼šé»˜è®¤ `False`ï¼Œæ—§ä»£ç ä¸å—å½±å“ã€‚è‹¥å¼€å¯ï¼Œéœ€è¦ç¡®ä¿ **å•æœºå•è¿›ç¨‹**ï¼ˆ`dcp_world_size == pcp_world_size == 1`ï¼‰ä»¥åŠè‡³å°‘ä¸€ä¸ª KVâ€‘cache groupï¼Œå¦åˆ™ä¼šæŠ¥æ–­è¨€é”™è¯¯ã€‚  
2. **èµ„æºç®¡ç†**ï¼šå…±äº«å†…å­˜å’Œæ–‡ä»¶é”åœ¨è¿›ç¨‹å¼‚å¸¸é€€å‡ºæ—¶å¯èƒ½æ®‹ç•™ï¼Œå»ºè®®åœ¨éƒ¨ç½²è„šæœ¬æˆ–å®ˆæŠ¤è¿›ç¨‹ä¸­åŠ å…¥æ¸…ç†é€»è¾‘ï¼ˆ`RoutedExpertsCapturer.cleanup()` / `RoutedExpertsReader.cleanup()`ï¼‰ã€‚  
3. **æ€§èƒ½è¯„ä¼°**ï¼šæ•è·ã€å†™å…¥å…±äº«å†…å­˜ä»¥åŠè¯»å–ä¼šåœ¨æ¯ä¸ª batch ç»“æŸåäº§ç”Ÿé¢å¤–çš„åŒæ­¥å¼€é”€ï¼Œå»ºè®®åœ¨ç”Ÿäº§ç¯å¢ƒåšåŸºå‡†æµ‹è¯•ï¼Œå¿…è¦æ—¶é€šè¿‡ `--enable-return-routed-experts` å¼€å…³å…³é—­ã€‚  
4. **æµ‹è¯•è¦†ç›–**ï¼šæ–°å¢çš„æ•è·è·¯å¾„åœ¨ `dummy_run` åœºæ™¯ä¸‹å¯èƒ½è¿”å› `None`ï¼Œç¡®ä¿å•å…ƒæµ‹è¯•è¦†ç›– `enable_return_routed_experts=True` ä¸ `False` ä¸¤ç§æƒ…å†µï¼Œä»¥åŠå¤š GPUï¼ˆä½†å•è¿›ç¨‹ï¼‰ä¸‹çš„è¡Œä¸ºã€‚  
5. **æ–‡æ¡£æ›´æ–°**ï¼šåœ¨ç”¨æˆ·æ‰‹å†Œã€API æ–‡æ¡£ä»¥åŠ CLI å‚æ•°è¯´æ˜ä¸­æ·»åŠ  `--enable-return-routed-experts` åŠå…¶è¿”å›å­—æ®µ `routed_experts` çš„è§£é‡Šå’Œä½¿ç”¨ç¤ºä¾‹ã€‚  

æ€»ä½“æ¥çœ‹ï¼Œæ­¤åŠŸèƒ½ä¸ºä¸“å®¶è·¯ç”±è°ƒè¯•ä¸å¯è§£é‡Šæ€§æä¾›äº†å¼ºæœ‰åŠ›çš„æ”¯æŒï¼Œä½†åœ¨å¼€å¯åä¼šå¼•å…¥å…±äº«å†…å­˜å’ŒåŒæ­¥å¼€é”€ï¼Œéœ€è¦åœ¨å®é™…éƒ¨ç½²å‰è¿›è¡Œå……åˆ†çš„èµ„æºå’Œæ€§èƒ½è¯„ä¼°ã€‚

---

### [P/D] Refactor mooncake connector sender thread using async coroutines (#31573)
**SHA**: `0565f1f` | ğŸ”— [æŸ¥çœ‹æäº¤](https://github.com/vllm-project/vllm/commit/0565f1fdec86dd0f38438d50db2219246f0e196d)

**ğŸ¯ å˜æ›´ç±»å‹**ï¼šé‡æ„ï¼ˆå°† Mooncakeâ€¯connector çš„å‘é€ç«¯ä»å¤šçº¿ç¨‹â€¯+â€¯é˜»å¡ ZMQ æ”¹ä¸ºçº¯å¼‚æ­¥åç¨‹ï¼‰  
**âš¡ é‡è¦ç¨‹åº¦**ï¼šğŸŸ¡ ä¸­  
**ğŸ“‹ å˜æ›´æ‘˜è¦**ï¼š  
- å°†åŸæ¥çš„ `threading.Event`ã€`ThreadPoolExecutor`+é˜»å¡ ZMQ æµç¨‹å…¨éƒ¨æ¢æˆ `asyncio.Event`ã€`asyncio.Queue` ä¸ `zmq.asyncio`ï¼›  
- æ–°å¢ `sender_loop`ã€`receiver_loop` ä¸¤ä¸ªç‹¬ç«‹çš„äº‹ä»¶å¾ªç¯å¹¶åœ¨åå°çº¿ç¨‹ä¸­è¿è¡Œï¼›  
- åˆå¹¶åŸå…ˆçš„ `SendReqMeta`ã€`FinishedSendReqSet`ã€`FinishedReceiveReqSet` ä¸ºæ™®é€š `dict / set`ï¼Œå¹¶åœ¨åç¨‹ä¸­å®Œæˆè¶…æ—¶æ¸…ç†ä¸çŠ¶æ€æ›´æ–°ï¼›  
- å¼•å…¥ `_async_loop`ã€`_sender_worker`ã€`_sender_listener` ç­‰å¼‚æ­¥ä»»åŠ¡ï¼Œä½¿ç”¨ `await` å–ä»£ `threading.Event.wait()`ï¼Œå¹¶åœ¨ `send_kv_to_decode` ä¸­å¼‚æ­¥æ„å»ºä¼ è¾“å‚æ•°åäº¤ç»™çº¿ç¨‹æ± æ‰§è¡Œå®é™…çš„ `batch_transfer_sync_write`ã€‚

**ğŸ¯ å½±å“èŒƒå›´**ï¼š  
- `vllm/distributed/kv_transfer/kv_connector/v1/mooncake_connector.py`ï¼ˆæ ¸å¿ƒ KVâ€‘transfer é€»è¾‘ï¼‰  
- ä¸ä¹‹è€¦åˆçš„ `vllm` è°ƒåº¦ã€prefill/decoder ä»£ç ä¸­å¯¹ `get_finished`ã€`start_load_kv`ã€`register_kv_caches` çš„è°ƒç”¨è·¯å¾„  
- ä¾èµ– `zmq`ã€`zmq.asyncio` çš„è¿è¡Œæ—¶ç¯å¢ƒ  

**ğŸ’¡ å…³æ³¨å»ºè®®**  

1. **äº‹ä»¶å¾ªç¯ç”Ÿå‘½å‘¨æœŸ**ï¼š`sender_loop` ä¸ `receiver_loop` åœ¨ `shutdown` æ—¶ä»…è°ƒç”¨ `stop()`ï¼Œä½†æœªç­‰å¾…å¾ªç¯å®Œå…¨é€€å‡ºï¼Œå¯èƒ½å¯¼è‡´æœªå®Œæˆçš„åç¨‹æ®‹ç•™ã€‚å»ºè®®åœ¨ `shutdown` ä¸­åŠ å…¥ `loop.run_until_complete(loop.shutdown_asyncgens())` å¹¶åœ¨ `join()` å‰ç¡®è®¤ `loop.is_closed()`ã€‚  
2. **å¼‚å¸¸ä¼ æ’­**ï¼š`_sender_worker` ä¸­æ•è· `Exception` å¹¶è®°å½•æ—¥å¿—åç»§ç»­å¾ªç¯ï¼Œè‹¥ `batch_transfer_sync_write` æŠ›å‡ºå¼‚å¸¸ï¼Œå½“å‰ä»…è¿”å›é”™è¯¯ç ã€‚è€ƒè™‘åœ¨åç¨‹å±‚é¢æŠ›å‡ºå¼‚å¸¸æˆ–å°†é”™è¯¯åŠ å…¥ `finished_sending_reqs`ï¼Œé¿å…ä¸Šå±‚æ— é™ç­‰å¾…ã€‚  
3. **å¹¶å‘å®‰å…¨**ï¼š`reqs_need_send`ã€`finished_sending_reqs`ã€`finished_recving_reqs` å·²æ”¹ä¸ºæ™®é€šå®¹å™¨ï¼Œä½†åœ¨å¤šçº¿ç¨‹ï¼ˆ`ThreadPoolExecutor`ï¼‰å’Œå¼‚æ­¥ä»»åŠ¡å¹¶å‘è®¿é—®æ—¶ä»ç¼ºå°‘é”ã€‚å»ºè®®åœ¨å¯¹è¿™äº›å®¹å™¨çš„å†™æ“ä½œï¼ˆå¦‚ `del self.reqs_need_send[req_id]`ã€`self.finished_sending_reqs.update(...)`ï¼‰å¤–å±‚åŠ  `asyncio.Lock` æˆ–ä½¿ç”¨ `collections.defaultdict` ä¸åŸå­æ“ä½œã€‚  
4. **èµ„æºæ³„æ¼**ï¼š`_sender_listener` å…³é—­æ—¶ä»…å–æ¶ˆä»»åŠ¡ï¼Œæœªç¡®ä¿ `sock.close()` åœ¨æ‰€æœ‰è·¯å¾„è¢«æ‰§è¡Œã€‚æœ€å¥½åœ¨ `finally` é‡Œç»Ÿä¸€å…³é—­ ZMQ socketã€‚  
5. **å…¼å®¹æ€§**ï¼šåŸæœ‰ `threading.Event` è¢«æ›¿æ¢ä¸º `asyncio.Event`ï¼Œå¤–éƒ¨å¦‚æœä»æŒæœ‰æ—§çš„ `Event` å®ä¾‹ï¼ˆå¦‚å•å…ƒæµ‹è¯•æˆ–æ’ä»¶ï¼‰ä¼šå¯¼è‡´ä¸å¯è¾¾çŠ¶æ€ã€‚æ£€æŸ¥æ˜¯å¦æœ‰å…¶ä»–æ¨¡å—ç›´æ¥å¼•ç”¨ `SendBlockMeta.ready`ã€‚  
6. **æ€§èƒ½å›é€€é£é™©**ï¼šæ–°å¢ `asyncio.Queue` ä¸å¤§é‡åç¨‹ï¼ˆ`num_sender_tasks = workers*2`ï¼‰ä¼šå¢åŠ ä¸Šä¸‹æ–‡åˆ‡æ¢å¼€é”€ï¼Œå»ºè®®åœ¨ä¸åŒç¡¬ä»¶ä¸Šå¯¹æ¯”æ—§å®ç°çš„ååé‡ï¼Œç¡®ä¿æ”¹åŠ¨å¸¦æ¥é¢„æœŸçš„æ€§èƒ½æå‡æˆ–è‡³å°‘ä¸äº§ç”Ÿå›é€€ã€‚  

**æ€»ä½“å»ºè®®**ï¼šåœ¨åˆå¹¶åè¿›è¡Œä¸€æ¬¡å®Œæ•´çš„é›†æˆæµ‹è¯•ï¼Œè¦†ç›–å‘é€ã€æ¥æ”¶ã€è¶…æ—¶ã€å¼‚å¸¸è·¯å¾„ï¼Œé‡ç‚¹éªŒè¯å¤šè¿›ç¨‹/å¤šèŠ‚ç‚¹æƒ…å†µä¸‹çš„èµ„æºå›æ”¶ä¸çŠ¶æ€ä¸€è‡´æ€§ã€‚è‹¥ç¡®è®¤å¹¶å‘å®‰å…¨åï¼Œå¯è€ƒè™‘åœ¨ `README` æˆ–æ³¨é‡Šä¸­è¯´æ˜æ–°æ—§å®ç°çš„å·®å¼‚ï¼Œä¾¿äºåç»­ç»´æŠ¤ã€‚

---

### [Bugfix] Fix missing scale passing for encoder Triton Attention implementation  (#32149)
**SHA**: `9dbe1fe` | ğŸ”— [æŸ¥çœ‹æäº¤](https://github.com/vllm-project/vllm/commit/9dbe1fe960f9931a262c88b4082aa7551cf7dfc0)

**ğŸ¯ å˜æ›´ç±»å‹**ï¼šBugä¿®å¤  
**âš¡ é‡è¦ç¨‹åº¦**ï¼šğŸŸ¡ ä¸­

**ğŸ“‹ å˜æ›´æ‘˜è¦**  
1. åœ¨ `triton_attn.py` ä¸­ä¸º encoderâ€‘side çš„ Triton æ³¨æ„åŠ›è°ƒç”¨è¡¥é½ `softmax_scale` å‚æ•°ï¼Œé˜²æ­¢ä½¿ç”¨é»˜è®¤çš„ 1/âˆšdâ‚– å¯¼è‡´æ•°å€¼åå·®ã€‚  
2. å°† `context_attention_fwd` çš„ç­¾ååŠ å…¥ `softmax_scale`ï¼ˆå¯é€‰ï¼‰å¹¶åœ¨è®¡ç®—æ—¶ä½¿ç”¨è¯¥å€¼ã€‚  
3. æ¸…ç†äº†ç¦»çº¿æ¨ç†ç¤ºä¾‹è„šæœ¬ä¸­ä¸ ROCm/Flexâ€‘Attention ç›¸å…³çš„ç¡¬ç¼–ç ï¼Œæ”¹ä¸ºç»Ÿä¸€èµ°é»˜è®¤é…ç½®ã€‚

**ğŸ¯ å½±å“èŒƒå›´**  
- `vllm/v1/attention/backends/triton_attn.py`ï¼ˆencoder æ³¨æ„åŠ›è·¯å¾„ï¼‰  
- `vllm/v1/attention/ops/triton_prefill_attention.py`ï¼ˆåº•å±‚ Triton kernel è°ƒç”¨ï¼‰  
- ç¤ºä¾‹ `examples/offline_inference/basic/*`ï¼ˆä¸å†å¼ºåˆ¶ ROCm åç«¯ï¼‰

**ğŸ’¡ å…³æ³¨å»ºè®®**  
1. **åŠŸèƒ½éªŒè¯**ï¼šåœ¨åŒ…å« encoderâ€‘only æ¨¡å‹ï¼ˆå¦‚ BERTã€Encoderâ€‘Decoderï¼‰æ—¶ï¼Œè·‘ä¸€æ¬¡å‰å‘æ¨ç†ï¼Œæ¯”è¾ƒåŠ å…¥ `softmax_scale` å‰åçš„ logits / lossï¼Œç¡®ä¿æ•°å€¼ä¸€è‡´æˆ–æå‡ã€‚  
2. **å…¼å®¹æ€§**ï¼šé»˜è®¤ `softmax_scale=None` æ—¶ä»å›é€€åˆ° `1/âˆšdâ‚–`ï¼Œå› æ­¤æ—§ç¯å¢ƒä¸å—å½±å“ï¼›å»ºè®®åœ¨æ–‡æ¡£ä¸­è¯´æ˜è¯¥å‚æ•°çš„æ„ä¹‰ä¸ä½¿ç”¨åœºæ™¯ã€‚  
3. **æ€§èƒ½å›å½’**ï¼š`softmax_scale` çš„ä¼ é€’æœ¬èº«å¼€é”€æå°ï¼Œä½†è¯·åœ¨ CI ä¸­åŠ å…¥é’ˆå¯¹ä¸åŒåç«¯ï¼ˆCUDAã€ROCmï¼‰å’Œä¸åŒæ¨¡å‹å°ºå¯¸çš„åŸºå‡†æµ‹è¯•ï¼Œé˜²æ­¢æ„å¤–çš„æ€§èƒ½å›é€€ã€‚  
4. **ç±»å‹æ£€æŸ¥**ï¼šå‡½æ•°ç­¾åå·²åŠ å…¥ `float | None`ï¼Œç¡®ä¿åœ¨è°ƒç”¨å¤„ä¼ å…¥ `self.scale`ï¼ˆåœ¨ `Attention` ç±»ä¸­å®šä¹‰ï¼‰ï¼Œè‹¥åç»­æœ‰è‡ªå®šä¹‰ scaleï¼Œéœ€è¦ä¿æŒç±»å‹ä¸€è‡´ã€‚  
5. **ç¤ºä¾‹è„šæœ¬**ï¼šç§»é™¤ç¡¬ç¼–ç åï¼Œç¡®ä¿ç¤ºä¾‹ä»èƒ½åœ¨ ROCm ç¯å¢ƒä¸‹æ­£å¸¸è¿è¡Œï¼›å¦‚æœ‰ç‰¹æ®Šéœ€æ±‚ï¼Œå¯åœ¨ CLI ä¸­æ˜¾å¼é…ç½® `--attention-backend flex_attention`ã€‚  

æ€»ä½“æ¥è¯´ï¼Œæ­¤æ¬¡æäº¤ä¿®æ­£äº† encoder Triton æ³¨æ„åŠ›ç¼ºå¤± scale çš„ bugï¼Œä»£ç è·¯å¾„æ¸…æ™°ï¼Œæ”¹åŠ¨èŒƒå›´å±€é™äºæ³¨æ„åŠ›å®ç°å’Œç¤ºä¾‹è„šæœ¬ï¼Œé£é™©è¾ƒä½ã€‚æ¨èé€šè¿‡å®Œæ•´çš„å•å…ƒ/é›†æˆæµ‹è¯•ååˆå¹¶ã€‚

---

### [cpu][bench] Add Fused MoE Micro Benchmark for CPU Backend (#32092)
**SHA**: `5e034f2` | ğŸ”— [æŸ¥çœ‹æäº¤](https://github.com/vllm-project/vllm/commit/5e034f2e3d6a90b6af3f2ae55d9915505917191d)

**ğŸ¯ å˜æ›´ç±»å‹**ï¼šå…¶ä»–ï¼ˆæ–°å¢ CPUâ€¯Fusedâ€¯MoE å¾®åŸºå‡†ï¼‰  
**âš¡ é‡è¦ç¨‹åº¦**ï¼šğŸŸ¡ ä¸­  

**ğŸ“‹ å˜æ›´æ‘˜è¦**  
æœ¬æ¬¡æäº¤åœ¨ `benchmarks/kernels/cpu/` æ–°å¢ `benchmark_cpu_fused_moe.py`ï¼Œç”¨äºæµ‹é‡ CPU åç«¯çš„ fusedâ€¯MoE æ ¸å¿ƒæ€§èƒ½ã€‚è„šæœ¬å®Œæˆå‚æ•°è§£æã€æƒé‡é¢„åŒ…è£…ã€topâ€‘k è·¯ç”±ç”Ÿæˆã€è°ƒç”¨ `cpu_fused_moe` å¹¶ç»Ÿè®¡æ—¶å»¶ã€ååï¼ˆTFLOP/sï¼‰ç­‰æŒ‡æ ‡ã€‚  

**ğŸ¯ å½±å“èŒƒå›´**  
- ä»…æ–°å¢æ–‡ä»¶ï¼Œä¸ä¼šå½±å“åº“çš„è¿è¡Œæ—¶é€»è¾‘ã€‚  
- ä¾èµ– `vllm._custom_ops.cpu_fused_moe`ã€`cpu_prepack_moe_weight`ï¼›è‹¥å¹³å°ä¸æä¾›è¿™äº›æ‰©å±•ï¼Œè„šæœ¬ä¼šæå‰é€€å‡ºã€‚  
- ä¸ `vllm.platforms.current_platform.seed_everything`ã€`FlexibleArgumentParser` äº¤äº’ã€‚  

**ğŸ’¡ å…³æ³¨å»ºè®®**  
1. **å¹³å°æ£€æµ‹**ï¼šå½“å‰ä½¿ç”¨ `torch._C._cpu._is_amx_tile_supported()` åˆ¤æ–­ ISAï¼Œå»ºè®®åœ¨ä¸æ”¯æŒ AMX çš„æœºå™¨ä¸Šä»èƒ½æ˜ç¡®æŠ¥é”™æˆ–å›é€€åˆ° `vec`ï¼Œé˜²æ­¢ `ISA_CHOICES` ä¸ºç©ºå¯¼è‡´ argparse æŠ¥é”™ã€‚  
2. **å‚æ•°æ ¡éªŒ**ï¼š`batch-sizeã€expert-numã€hidden-sizeã€intermediate-size` ç­‰æ•´æ•°åº”åŠ ä¸Šæœ€å°å€¼æ£€æŸ¥ï¼Œé˜²æ­¢è´Ÿæ•°æˆ–é›¶å¯¼è‡´éæ³•å¼ é‡ã€‚  
3. **æ–‡æ¡£/å…¥å£**ï¼šå»ºè®®åœ¨ README æˆ– benchmark æ€»ç›®å½•æ·»åŠ è¯¥è„šæœ¬çš„ä½¿ç”¨è¯´æ˜ï¼Œæ ‡æ˜éœ€è¦ç¼–è¯‘ CPUâ€¯extensionsï¼ˆx86â€‘64ã€AVX2/AVXâ€‘512ï¼‰ã€‚  
4. **ç»Ÿè®¡å‡†ç¡®æ€§**ï¼š`flops_per_token` çš„å…¬å¼å·²ç¡¬ç¼–ç ï¼Œè‹¥åç»­æ›´æ¢æ¿€æ´»å‡½æ•°æˆ–å®ç°ç»†èŠ‚ï¼Œéœ€åŒæ­¥æ›´æ–°ï¼›å¯è€ƒè™‘æŠ½è±¡ä¸ºå‡½æ•°å¹¶åŠ å…¥æ³¨é‡Šã€‚  
5. **CI é›†æˆ**ï¼šè‹¥è®¡åˆ’åœ¨ CI ä¸­è·‘åŸºå‡†ï¼Œå¯åŠ å…¥å¹³å°æ£€æµ‹ guardï¼Œä½¿é x86 ç¯å¢ƒè·³è¿‡ï¼Œé¿å… CI å¤±è´¥ã€‚  

æ€»ä½“è€Œè¨€ï¼Œæ­¤æ¬¡æ”¹åŠ¨ä¸ºçº¯æµ‹è¯„å·¥å…·ï¼Œé£é™©ä½ï¼Œä»£ç ç»“æ„æ¸…æ™°ã€‚é‡ç‚¹å…³æ³¨å¹³å°å…¼å®¹æ€§å’Œå‚æ•°åˆæ³•æ€§å³å¯é¡ºåˆ©åˆå¹¶ã€‚

---

### [Model] Remove incorrect `SupportsPP` from MTP models (#32150)
**SHA**: `600aaab` | ğŸ”— [æŸ¥çœ‹æäº¤](https://github.com/vllm-project/vllm/commit/600aaab8d626301f4dbfcd812ccf47b3e8d81ac9)

**ğŸ¯ å˜æ›´ç±»å‹**ï¼šé‡æ„ / çº é”™  
**âš¡ é‡è¦ç¨‹åº¦**ï¼šğŸŸ¡ ä¸­ï¼ˆä¸å½±å“åŠŸèƒ½ï¼Œä½†æ¶‰åŠæ¨¡å‹å®ä¾‹åŒ–è·¯å¾„ï¼‰  

**ğŸ“‹ å˜æ›´æ‘˜è¦**  
æœ¬æ¬¡æäº¤ç»Ÿä¸€ç§»é™¤äº†æ‰€æœ‰ MTPï¼ˆMixtureâ€‘ofâ€‘Expertsâ€¯+â€¯Pipelineâ€‘Parallelï¼‰æ¨¡å‹å¯¹ `SupportsPP` æ¥å£çš„ç»§æ‰¿ã€‚æ­¤å‰ `SupportsPP` åœ¨è¿™äº›æ¨¡å‹ä¸­å¹¶æœªå®ç°å¯¹åº”çš„åè®®æ–¹æ³•ï¼Œå¯¼è‡´ç±»å‹å£°æ˜ä¸å®é™…å®ç°ä¸ä¸€è‡´ï¼Œæ½œåœ¨è§¦å‘ `isinstance` æ£€æŸ¥æˆ–é™æ€åˆ†æè¯¯æŠ¥ã€‚ä»£ç ä»…ä¿ç•™æ¨¡å‹æœ¬èº«çš„ MoE åŸºç±»ï¼ˆå¦‚ `DeepseekV2MixtureOfExperts`ã€`Glm4MixtureOfExperts` ç­‰ï¼‰ï¼Œå¹¶æ¸…ç†äº†ç›¸å…³çš„ import ä¸å†—ä½™å±æ€§ï¼ˆå¦‚ `make_empty_intermediate_tensors`ï¼‰ã€‚

**ğŸ¯ å½±å“èŒƒå›´**  
- `vllm/model_executor/models/deepseek_mtp.py`  
- `vllm/model_executor/models/ernie_mtp.py`  
- `vllm/model_executor/models/glm4_moe_mtp.py`  
- `vllm/model_executor/models/longcat_flash_mtp.py`  
- `vllm/model_executor/models/openpangu_mtp.py`  
- `vllm/model_executor/models/qwen3_next_mtp.py`  

æ¶‰åŠçš„æ¨¡å—å‡å±äº **æ¨¡å‹æ‰§è¡Œå™¨ â†’ MTP ç³»åˆ—**ï¼Œä¸ **pipelineâ€‘parallel** ç›¸å…³çš„è°ƒåº¦é€»è¾‘ä¸å†ä¾èµ–è¯¥æ¥å£ã€‚

**ğŸ’¡ å…³æ³¨å»ºè®®**  
1. **å…¼å®¹æ€§æ£€æŸ¥**ï¼šç¡®è®¤é¡¹ç›®å†…éƒ¨æˆ–å¤–éƒ¨ï¼ˆå¦‚æ’ä»¶ã€ç”¨æˆ·è‡ªå®šä¹‰ä»£ç ï¼‰æ²¡æœ‰åŸºäº `SupportsPP` åš `isinstance(..., SupportsPP)` åˆ¤æ–­çš„é€»è¾‘ï¼Œè‹¥æœ‰éœ€åŒæ­¥æ”¹ä¸ºæ£€æµ‹å¯¹åº” MoE åŸºç±»æˆ–ç›´æ¥ä½¿ç”¨æ¨¡å‹å®ä¾‹ã€‚  
2. **æ–‡æ¡£åŒæ­¥**ï¼šæ›´æ–° README / API æ–‡æ¡£ä¸­å…³äº MTP æ¨¡å‹â€œæ”¯æŒ pipelineâ€‘parallelâ€ çš„æè¿°ï¼Œé¿å…è¯¯å¯¼ç”¨æˆ·ã€‚  
3. **å•å…ƒæµ‹è¯•**ï¼šæ·»åŠ /æ›´æ–°é’ˆå¯¹ MTP æ¨¡å‹çš„å®ä¾‹åŒ–æµ‹è¯•ï¼Œç¡®ä¿åœ¨æ²¡æœ‰ `SupportsPP` çš„æƒ…å†µä¸‹ä»èƒ½æ­£å¸¸è°ƒç”¨ `forward`ã€`embed_input_ids` ç­‰å…¬å…±æ–¹æ³•ã€‚  
4. **æŒç»­é›†æˆ**ï¼šè¿è¡Œå®Œæ•´çš„ `pytest -m "mtp"`ï¼ˆè‹¥å·²æœ‰ï¼‰ä»¥æ•è·å› æ¥å£ç§»é™¤å¯¼è‡´çš„æ½œåœ¨å›å½’ã€‚  
5. **ä»£ç å®¡è®¡**ï¼šæ£€æŸ¥ `vllm/model_executor/interfaces.py` ä¸­ `SupportsPP` çš„å®ç°æ˜¯å¦ä»è¢«å…¶ä»–éâ€‘MTP ç»„ä»¶å¼•ç”¨ï¼Œè‹¥æœªä½¿ç”¨å¯è€ƒè™‘æ¸…ç†æˆ–æ ‡è®°ä¸ºå·²åºŸå¼ƒã€‚  

æ€»ä½“æ¥çœ‹ï¼Œæ­¤æ¬¡æ”¹åŠ¨æ˜¯å¯¹ä»£ç ä¸€è‡´æ€§çš„ç»†è‡´ä¿®æ­£ï¼Œé£é™©ä½ï¼Œåªéœ€æ³¨æ„ä¸Šè¿°å…¼å®¹æ€§ä¸æ–‡æ¡£åŒæ­¥å³å¯é¡ºåˆ©ä¸Šçº¿ã€‚

---

### [Model] Improve multimodal pooling examples (#32085)
**SHA**: `60446cd` | ğŸ”— [æŸ¥çœ‹æäº¤](https://github.com/vllm-project/vllm/commit/60446cd684d55c0918295bb5e61da19330a0fb35)

**ğŸ¯ å˜æ›´ç±»å‹**ï¼šåŠŸèƒ½å¢å¼ºï¼ˆç¤ºä¾‹/æ–‡æ¡£å±‚é¢ï¼‰  
**âš¡ é‡è¦ç¨‹åº¦**ï¼šğŸŸ¡ ä¸­  

**ğŸ“‹ å˜æ›´æ‘˜è¦**  
- docs/serving ä¸­çš„é“¾æ¥ç»Ÿä¸€ä¸ºæœ€æ–°ç¤ºä¾‹ï¼ŒæŒ‡å‘ `vision_embedding_online.py`ã€`score_api_online.py` ç­‰ã€‚  
- æ–°å¢ **offline** ç¤ºä¾‹ `vision_embedding_offline.py`ï¼Œå±•ç¤ºå¦‚ä½•åœ¨æœ¬åœ°ä½¿ç”¨ `LLM.embed` è¿›è¡Œ Visionâ€‘LLM åµŒå…¥ã€‚  
- é‡å‘½åå¹¶æ‰©å±•åœ¨çº¿ç¤ºä¾‹ `vision_embedding_online.py`ï¼ŒåŠ å…¥ `continue_final_message`ã€`add_special_tokens` å‚æ•°ï¼Œä»¥å…¼å®¹ Qwenâ€‘VL ç­‰æ¨¡å‹çš„å¤šæ¨¡æ€åµŒå…¥éœ€æ±‚ã€‚  
- æ›¿æ¢æ—§çš„è·¨æ¨¡æ€è¯„åˆ†ç¤ºä¾‹ï¼Œæ–°å¢ `vision_score_api_online.py`ã€`vision_rerank_api_online.py`ï¼Œæ¼”ç¤ºå›¾æ–‡â€¯â†’â€¯åˆ†æ•°/rerank çš„è°ƒç”¨æ–¹å¼ã€‚  
- åˆ é™¤è¿‡æ—¶çš„ `openai_cross_encoder_score_for_multimodal.py`ã€‚  

**ğŸ¯ å½±å“èŒƒå›´**  
- `docs/serving/openai_compatible_server.md`ï¼ˆæ–‡æ¡£é“¾æ¥ï¼‰  
- `examples/pooling/*` ç›®å½•ä¸‹çš„æ‰€æœ‰åµŒå…¥ã€è¯„åˆ†ç¤ºä¾‹ï¼ˆoffline/onlineï¼‰  
- `examples/pooling/score/template`ï¼ˆé—´æ¥ä¾èµ–çš„ Jinja æ¨¡æ¿ä¿æŒä¸å˜ï¼‰  

**ğŸ’¡ å…³æ³¨å»ºè®®**  
1. **API å‚æ•°ä¸€è‡´æ€§**ï¼šç¡®è®¤ `continue_final_message` ä¸ `add_special_tokens` å·²åœ¨æœåŠ¡å™¨ç«¯ï¼ˆ`vllm` ä¸»åº“ï¼‰å®ç°å¹¶é»˜è®¤å¼€å¯ï¼Œå¦åˆ™ç¤ºä¾‹ä¼šåœ¨å®é™…è¿è¡Œæ—¶æŠ¥é”™ã€‚  
2. **ç¤ºä¾‹å¯æ‰§è¡Œæ€§**ï¼šåœ¨ CI ä¸­åŠ å…¥å¯¹æ–°å¢ç¤ºä¾‹çš„å¿«é€Ÿè·‘é€šæµ‹è¯•ï¼Œç¡®ä¿ä¾èµ–ï¼ˆ`requests`ã€`openai`ã€`torchvision` ç­‰ï¼‰å·²åˆ—å…¥ `requirements.txt`ã€‚  
3. **æ–‡æ¡£åŒæ­¥**ï¼šæ£€æŸ¥æ‰€æœ‰æ–‡æ¡£ä¸­ä»å¼•ç”¨è¢«åˆ é™¤çš„ `openai_cross_encoder_score_for_multimodal.py` é“¾æ¥ï¼Œé¿å…å‡ºç° 404ã€‚  
4. **è·¯å¾„å’Œå˜é‡ç»Ÿä¸€**ï¼šç¤ºä¾‹ä¸­å¤šæ¬¡å‡ºç°ç¡¬ç¼–ç çš„å›¾ç‰‡ URL ä¸ `text`ï¼Œå»ºè®®æŠ½è±¡ä¸º CLI å‚æ•°ï¼Œæå‡å¤ç”¨æ€§ã€‚  
5. **ç¤ºä¾‹è¯´æ˜**ï¼šåœ¨æ¯ä¸ªç¤ºä¾‹æ–‡ä»¶å¤´éƒ¨æ·»åŠ ç®€è¦çš„è¿è¡Œå‰ç½®æ¡ä»¶ï¼ˆå¦‚æ¨¡å‹éœ€æ”¯æŒ `--chat-template`ï¼‰ï¼Œå¸®åŠ©æ–°æ‰‹å¿«é€Ÿä¸Šæ‰‹ã€‚  

æ€»ä½“è€Œè¨€ï¼Œæœ¬æ¬¡æäº¤ä¸°å¯Œäº†å¤šæ¨¡æ€ Pooling çš„ä½¿ç”¨åœºæ™¯ï¼Œæå‡äº†æ–‡æ¡£å¯è¯»æ€§å’Œç¤ºä¾‹å®Œæ•´åº¦ï¼Œåªè¦ç¡®ä¿æœåŠ¡å™¨ç«¯å·²æ”¯æŒæ–°å¢å‚æ•°ï¼Œå³å¯é¡ºåˆ©åœ¨ç”Ÿäº§ç¯å¢ƒå¼•ç”¨ã€‚

---

### [Model] Avoid hardcoding pooling type (#32119)
**SHA**: `9101dc7` | ğŸ”— [æŸ¥çœ‹æäº¤](https://github.com/vllm-project/vllm/commit/9101dc756c14b6467c192e7bfc67036f40d76320)

**å˜æ›´ç±»å‹**ï¼šåŠŸèƒ½å¢å¼º / é‡æ„  
**é‡è¦ç¨‹åº¦**ï¼šğŸŸ¡ ä¸­  
**å˜æ›´æ‘˜è¦**ï¼šæœ¬æ¬¡æäº¤å»é™¤å¯¹ `CLSPool` çš„ç¡¬ç¼–ç ï¼Œå®ç°äº†åŸºäºé…ç½®çš„åºåˆ—æ± åŒ–æ–¹å¼ã€‚å¼•å…¥ `get_seq_pooling_method`ï¼Œåœ¨ BERTã€Robertaã€ModernBertã€GritLM ç­‰æ¨¡å‹çš„ `Pooler` åˆå§‹åŒ–æ—¶ç»Ÿä¸€ä½¿ç”¨ `pooler_config.seq_pooling_type`ï¼Œå¹¶åœ¨ç›¸å…³ `DispatchPooler` è°ƒç”¨å¤„å»é™¤æ˜¾å¼ `CLSPool` å®ä¾‹ã€‚  

**å½±å“èŒƒå›´**  
- `vllm/model_executor/models/bert*.py`ã€`gritlm.py`ã€`modernbert.py`ã€`roberta.py`ã€`transformers/pooling.py` ç­‰æ¨¡å‹å®ç°ã€‚  
- `vllm/config` ä¸­ `PoolerConfig` å¿…é¡»åœ¨æ¨¡å‹é…ç½®ä¸­æä¾›ï¼Œå¦åˆ™ä¼šè§¦å‘æ–­è¨€ã€‚  
- ä¾èµ–åŸå…ˆé»˜è®¤ `CLS` æ± åŒ–çš„å¤–éƒ¨ä»£ç ï¼ˆå¦‚è‡ªå®šä¹‰æ¨ç†è„šæœ¬ï¼‰éœ€è¦ç¡®è®¤ `pooler_config` å·²æ­£ç¡®è®¾ç½®ã€‚  

**å…³æ³¨å»ºè®®**  
1. **å¼€å‘è€…**ï¼šç¡®è®¤ `VllmConfig.model_config.pooler_config` åœ¨æ‰€æœ‰æ¨¡å‹çš„é…ç½®æ–‡ä»¶æˆ–è¿è¡Œæ—¶å‚æ•°ä¸­è¢«å¡«å……ï¼›è‹¥ä»å¸Œæœ›ä½¿ç”¨ `CLS`ï¼Œå°† `seq_pooling_type` è®¾ä¸º `"CLS"`ã€‚  
2. **å•å…ƒæµ‹è¯•**ï¼šæ–°å¢é’ˆå¯¹ä¸åŒ `seq_pooling_type`ï¼ˆCLSã€MEANã€MAX ç­‰ï¼‰çš„æµ‹è¯•ï¼ŒéªŒè¯ `DispatchPooler` çš„ `pooling` ä¸ `classifier` çš„ç»´åº¦åŒ¹é…ã€‚  
3. **æ–‡æ¡£**ï¼šæ›´æ–°æ¨¡å‹ä½¿ç”¨è¯´æ˜ï¼Œè¯´æ˜ pooler é…ç½®çš„å¯é€‰å€¼åŠé»˜è®¤è¡Œä¸ºï¼Œç‰¹åˆ«æ˜¯å¯¹ `Roberta`ã€`ModernBert` çš„å…¼å®¹ç»†èŠ‚ã€‚  
4. **ç”¨æˆ·**ï¼šå‡çº§åˆ°æ–°ç‰ˆæ—¶è‹¥å‡ºç° â€œpooler_config is Noneâ€ çš„æ–­è¨€é”™è¯¯ï¼Œè¯·æ£€æŸ¥è‡ªå®šä¹‰ `model_config.json` æˆ–é€šè¿‡ `--pooler-config` å‚æ•°æ˜¾å¼ä¼ å…¥ã€‚  

æ€»ä½“ä¸Šï¼Œæ­¤æ”¹åŠ¨æå‡äº†æ± åŒ–æ–¹å¼çš„å¯é…ç½®æ€§ï¼Œé¿å…äº†ç¡¬ç¼–ç é”™è¯¯ï¼Œå…¼å®¹æ€§å½±å“å±€é™åœ¨éœ€è¦æ˜¾å¼æä¾› `PoolerConfig` çš„åœºæ™¯ã€‚ä¿æŒç°æœ‰é»˜è®¤ `CLS`ï¼Œå¯¹æ—§æœ‰ä½¿ç”¨è€…å½±å“æœ€å°ã€‚

---

### [Model Runner V2] Skip building deprecated fields in attn metadata (#32132)
**SHA**: `19504ac` | ğŸ”— [æŸ¥çœ‹æäº¤](https://github.com/vllm-project/vllm/commit/19504ac07fda211744bd67e62c03ab6b32c92ab1)

**ğŸ¯ å˜æ›´ç±»å‹**ï¼šåŠŸèƒ½å¢å¼ºï¼ˆModel Runner V2ï¼‰  
**âš¡ é‡è¦ç¨‹åº¦**ï¼šğŸŸ¡ ä¸­  

**ğŸ“‹ å˜æ›´æ‘˜è¦**  
æœ¬æ¬¡æäº¤åˆ é™¤äº† `seq_lens_np`ã€`num_computed_tokens_cpu` ç­‰å·²åºŸå¼ƒçš„å­—æ®µï¼Œæ”¹ç”¨ç»Ÿä¸€çš„ `max_seq_len` å‚æ•°åœ¨æ„å»ºæ³¨æ„åŠ›å…ƒæ•°æ®æ—¶ä¼ é€’ã€‚ç›¸åº”åœ°ï¼Œ`cudagraph_utils.py`ã€`input_batch.py`ã€`model_runner.py`ã€`eagle.py` ç­‰å¤šå¤„è°ƒç”¨ç‚¹åŒæ­¥æ›´æ–°ï¼Œå»æ‰äº†å¯¹ NumPy ç‰ˆåºåˆ—é•¿åº¦çš„é¢å¤–æ‹·è´å’Œæ— ç”¨è®¡ç®—ã€‚

**ğŸ¯ å½±å“èŒƒå›´**  
- `vllm/v1/worker/gpu/attn_utils.py`ï¼ˆæ³¨æ„åŠ›å…ƒæ•°æ®æ„å»ºæ ¸å¿ƒï¼‰  
- `vllm/v1/worker/gpu/cudagraph_utils.py`ï¼ˆå›¾æ•è·å…¥å£ï¼‰  
- `vllm/v1/worker/gpu/input_batch.py`ï¼ˆæ‰¹æ•°æ®ç»“æ„ï¼‰  
- `vllm/v1/worker/gpu/model_runner.py`ï¼ˆæ¨¡å‹è°ƒåº¦ä¸»é€»è¾‘ï¼‰  
- `vllm/v1/worker/gpu/spec_decode/eagle.py`ï¼ˆSpecâ€‘decode æµç¨‹ï¼‰  

**ğŸ’¡ å…³æ³¨å»ºè®®**  
1. **ä»£ç å…¼å®¹æ€§**ï¼šç¡®è®¤æ‰€æœ‰è‡ªå®šä¹‰ Attention Backendï¼ˆé™¤ FA3 ä¹‹å¤–ï¼‰æœªä¾èµ– `seq_lens_np` / `num_computed_tokens_cpu`ï¼Œå¦åˆ™éœ€è¦åœ¨å¯¹åº”å®ç°ä¸­æ”¹ä¸ºä½¿ç”¨ `max_seq_len`ã€‚  
2. **æ€§èƒ½å›å½’**ï¼šå»é™¤ NumPy æ‹·è´ååº”é™ä½ CPU å†…å­˜å ç”¨å’Œæ‹·è´å¼€é”€ï¼Œå»ºè®®è·‘ä¸€æ¬¡å®Œæ•´çš„ååé‡åŸºå‡†ï¼Œç¡®ä¿æœªå‡ºç°æ„å¤–çš„å›é€€ã€‚  
3. **å•å…ƒæµ‹è¯•**ï¼šæ›´æ–°ä»ç„¶å¼•ç”¨å·²åˆ é™¤å­—æ®µçš„æµ‹è¯•ç”¨ä¾‹ï¼Œå°¤å…¶æ˜¯ `prepare_dummy_attn_metadata`ã€`prepare_inputs` ç­‰è·¯å¾„ã€‚  
4. **æ–‡æ¡£/æ³¨é‡Š**ï¼šåœ¨ `attn_utils.build_attn_metadata` çš„ç­¾ååŠæ³¨é‡Šä¸­æ˜ç¡® `max_seq_len` çš„å«ä¹‰ï¼Œé¿å…æœªæ¥è¯¯ç”¨æ—§å­—æ®µã€‚  

æ€»ä½“è€Œè¨€ï¼Œæ­¤æ¬¡æ¸…ç†ç®€åŒ–äº†æ³¨æ„åŠ›å…ƒæ•°æ®çš„æ„å»ºè·¯å¾„ï¼Œé™ä½äº† CPUâ€‘GPU åŒæ­¥æˆæœ¬ï¼Œé£é™©ä¸»è¦åœ¨äºå°šæœªè¿ç§»çš„è‡ªå®šä¹‰åç«¯ä»£ç ï¼Œéœ€åšå¥½ç›¸åº”éªŒè¯ã€‚

---

#### ğŸŸ¢ ä½é‡è¦åº¦å˜æ›´ (7)

### [ROCm] [Bugfix] Fix order of mori build in Dockerfile.rocm_base (#32179)
**SHA**: `0346396` | ğŸ”— [æŸ¥çœ‹æäº¤](https://github.com/vllm-project/vllm/commit/0346396e94106edcbce13e083da172c119d0aa17)

**ğŸ¯ å˜æ›´ç±»å‹**ï¼šé…ç½®è°ƒæ•´  
**âš¡ é‡è¦ç¨‹åº¦**ï¼šğŸŸ¢ä½  
**ğŸ“‹ æ‘˜è¦**ï¼šåœ¨ `Dockerfile.rocm_base` ä¸­é‡æ–°æ’åˆ— MORI æ„å»ºé¡ºåºï¼Œç§»åŠ¨å…¶é˜¶æ®µè‡³ PyTorch ä¹‹åï¼Œå¹¶åŠ å…¥ `MORI_BRANCH`ã€`MORI_REPO` å‚æ•°åŠç‰ˆæœ¬è®°å½•ã€‚

---

### doc: Update model name for Qwen3-Coder in documentation (#32185)
**SHA**: `e68b0da` | ğŸ”— [æŸ¥çœ‹æäº¤](https://github.com/vllm-project/vllm/commit/e68b0dad8b4070e3ae24603c12f53b6c659ba6f9)

**å˜æ›´ç±»å‹**ï¼šæ–‡æ¡£æ›´æ–°  
**é‡è¦ç¨‹åº¦**ï¼šğŸŸ¢ ä½  
**æ‘˜è¦**ï¼šåœ¨ `docs/features/tool_calling.md` ä¸­å°†æ¨¡å‹åç§° `Qwen/Qwen3-480B-A35B-Instruct` ä¿®æ­£ä¸º `Qwen/Qwen3-Coder-480B-A35B-Instruct`ï¼Œä¿æŒæ¨¡å‹åˆ—è¡¨ä¸å®é™…å‘½åä¸€è‡´ã€‚

---

### [Doc] Add documentation for offline API docs feature (#32134)
**SHA**: `a5f89ae` | ğŸ”— [æŸ¥çœ‹æäº¤](https://github.com/vllm-project/vllm/commit/a5f89ae296c5c25c996eb0bb567f0d70e7577aff)

**ğŸ¯ å˜æ›´ç±»å‹**ï¼šæ–‡æ¡£æ›´æ–°  
**âš¡ é‡è¦ç¨‹åº¦**ï¼šğŸŸ¢ä½  
**ğŸ“‹ æ‘˜è¦**ï¼šåœ¨ `docs/serving/openai_compatible_server.md` ä¸­æ–°å¢ â€œOffline API Documentationâ€ å°èŠ‚ï¼Œè¯´æ˜ä½¿ç”¨ `--enable-offline-docs` å‚æ•°å¯åœ¨æ— ç½‘ç»œç¯å¢ƒä¸‹å¯ç”¨ FastAPI `/docs` ç¦»çº¿è®¿é—®ã€‚

---

### [Doc] Improve LoRA docs (#32159)
**SHA**: `05e8981` | ğŸ”— [æŸ¥çœ‹æäº¤](https://github.com/vllm-project/vllm/commit/05e8981234d307c20139ffb5180b8fe2a4caf861)

**ğŸ¯ å˜æ›´ç±»å‹**ï¼šæ–‡æ¡£æ›´æ–°  
**âš¡ é‡è¦ç¨‹åº¦**ï¼šğŸŸ¢ä½  
**ğŸ“‹ æ‘˜è¦**ï¼šå°† LoRA ç¤ºä¾‹æ–‡æ¡£ä¸­çš„æ¨¡å‹ã€ä»“åº“å’Œè·¯å¾„ä» Llamaâ€‘2â€‘7B æ›¿æ¢ä¸º Llamaâ€‘3.2â€‘3Bâ€‘Instructï¼Œå¹¶æ¼”ç¤ºæ–° `--lora-modules` JSON æ ¼å¼æ”¯æŒ `base_model_name`ï¼Œæ›´æ–°ç›¸å…³ç¤ºä¾‹å’Œè¯´æ˜ã€‚

---

### [doc] fix broken links (#32158)
**SHA**: `899541b` | ğŸ”— [æŸ¥çœ‹æäº¤](https://github.com/vllm-project/vllm/commit/899541bdb1e42762c17a8cb5cf5bf2800ef63811)

**ğŸ¯ å˜æ›´ç±»å‹**ï¼šæ–‡æ¡£æ›´æ–°  
**âš¡ é‡è¦ç¨‹åº¦**ï¼šğŸŸ¢ä½  
**ğŸ“‹ æ‘˜è¦**ï¼šå°† `docs/design/paged_attention.md` ä¸­çš„ HTML `<p>` åŒ…è£¹çš„å›¾ç‰‡æ ‡ç­¾æ”¹ä¸º Markdown å›¾ç‰‡è¯­æ³•ï¼Œä¿®å¤äº†æ–‡æ¡£ä¸­å›¾ç‰‡é“¾æ¥å¤±æ•ˆçš„é—®é¢˜ã€‚

---

### [Frontend] Fix Flaky MCP Streaming Test (#32153)
**SHA**: `d7b2e57` | ğŸ”— [æŸ¥çœ‹æäº¤](https://github.com/vllm-project/vllm/commit/d7b2e57097dae8a620c28eddf663adad2a8329c5)

**ğŸ¯ å˜æ›´ç±»å‹**ï¼šæµ‹è¯•ä¿®æ”¹  
**âš¡ é‡è¦ç¨‹åº¦**ï¼šğŸŸ¢ä½  
**ğŸ“‹ æ‘˜è¦**ï¼šåœ¨ `tests/entrypoints/openai/responses/test_harmony.py` ä¸­ï¼Œå°† Mâ€‹CP æµå¼æµ‹è¯•çš„è¾“å…¥è¡¨è¾¾å¼ä» `15 * 32` æ”¹ä¸º `123 * 456`ï¼Œæ¶ˆé™¤ flaky è¡Œä¸ºã€‚

---

### [Misc] Disable default `--ready-check-timeout-sec` extra call in vllm bench (#30975)
**SHA**: `22970c1` | ğŸ”— [æŸ¥çœ‹æäº¤](https://github.com/vllm-project/vllm/commit/22970c16266746971f80fbd8e1fd505a5f35511d)

**ğŸ¯ å˜æ›´ç±»å‹**ï¼šé…ç½®è°ƒæ•´  
**âš¡ é‡è¦ç¨‹åº¦**ï¼šğŸŸ¢ ä½  
**ğŸ“‹ æ‘˜è¦**ï¼šåœ¨ `vllm/benchmarks/serve.py` ä¸­å°† `--ready-check-timeout-sec` çš„é»˜è®¤å€¼ä» 600 ç§’æ”¹ä¸º 0ï¼Œé»˜è®¤è·³è¿‡å°±ç»ªæ£€æŸ¥ï¼Œå¹¶ç›¸åº”æ›´æ–°å¸®åŠ©æ–‡æ¡ˆã€‚

---

