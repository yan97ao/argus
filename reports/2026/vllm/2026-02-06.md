# æ¯æ—¥æ›´æ–°æŠ¥å‘Šï¼ˆ2026-02-06ï¼‰

## vllm-project/vllm

| æäº¤æ—¶é—´ | ä½œè€… | æäº¤ä¿¡æ¯ |
|----------|------|----------|
| 2026-02-06 23:59:53 | zofia | [XPU][5/N] add wna16 xpu kernel (#33973) |
| 2026-02-06 23:43:47 | Cyrus Leung | [Refactor] Consolidate sequence normalization and enc-dec parsing (#33928) |
| 2026-02-06 23:29:10 | tc-mb | [Model] Support MiniCPM-o 4.5 (#33431) |
| 2026-02-06 23:26:43 | Michael Goin | [Docs] Add sections on process architecture and minimum CPU resources (#33940)<br>It seems users can be confused about vLLM's performance when running<br>with very small amounts of CPU cores available. We are missing a clear<br>overview of what vLLM's process architecture is, so I added this along with<br>some diagrams in arch_overview.md, and included a section on CPU resource<br>recommendations in optimization.md |
| 2026-02-06 23:08:16 | Andreas Karatzas | [ROCm][AITER] Fix AITER import regression for explicit backend selection (#33749) |
| 2026-02-06 22:23:03 | FredericOdermatt | [FIX] guidance: use max(vocab_size, len(tokenizer)) for n_vocab (#33509) |
| 2026-02-06 21:47:41 | Raushan Turganbay | [Bugfix] Fix models and tests for transformers v5 (#33977) |
| 2026-02-06 21:15:00 | Harry Mellor | Update `WeightTransferConfig` to be more standard like the others (#33989) |
| 2026-02-06 20:57:09 | SorenDreano | [Docs] Improve documentation (#33799) |
| 2026-02-06 20:25:31 | Kurt Shuster | [Bugfix][Model] Support LoRA on Qwen3 Output Embedding (#29816) |
| 2026-02-06 20:19:49 | Luka GovediÄ | [torch.compile] Reorganize vllm/compilation and tests/compile (0/N for vLLM IR) (#33731) |
| 2026-02-06 19:59:20 | Fadi Arafeh | [CPU][BugFix] Fix loading of w8a8int models with bias (#33582) |
| 2026-02-06 19:25:33 | Harry Mellor | Bump HF Hub client to get bug fix (#33984) |
| 2026-02-06 18:33:49 | zhang-prog | [PaddleOCR-VL] Add BC for transformers 5.0 config (#33976) |
| 2026-02-06 17:47:41 | Harry Mellor | Consolidate and fix forbidden import `pre-commit` checks (#33982) |
| 2026-02-06 16:34:20 | Xinyu Chen | support view_from_cpu_tensor on XPU (#33868) |
| 2026-02-06 16:08:05 | Harry Mellor | Fix `main` pre-commit (#33975) |
| 2026-02-06 15:01:48 | Gassan Salama | [cpu][performance] CPU Paged Attention NEON BFMMLA BF16 Implementation (#32263) |
| 2026-02-06 14:23:34 | chengchengpei | Onboard voyage-4-nano (#33720) |
| 2026-02-06 14:02:33 | sihao_li | [XPU]Replace pip in docker.xpu with uv pip (#31112) |
| 2026-02-06 13:03:59 | Kunshang Ji | [XPU][4/N] add mxfp4 moe model support (#33679) |
| 2026-02-06 12:57:02 | R3hankhan | [CPU] Add BF16 Kernel type for s390x (#33788) |
| 2026-02-06 11:38:39 | Cyrus Leung | [Misc] Update code for encoder-decoder models (#33900) |
| 2026-02-06 11:38:02 | Mingliang Li | feat(frontend): early-fail tokenization guard for user requests (#31366) |
| 2026-02-06 10:22:53 | Rabi Mishra | fix(ROCm): Make flash_attn import optional in MLA attention (#33511) |
| 2026-02-06 09:42:22 | Simon Mo | [Docs] Add reo analytics (#33957) |
| 2026-02-06 09:34:00 | Xin Yang | [Perf] Disable clean_logits in deepgemm fp8_mqa_logits kernel (#33568) |
| 2026-02-06 08:59:28 | emricksini-h | [Feature] OTEL tracing during loading (#31162) |
| 2026-02-06 07:50:49 | Wei Zhao | [Bugfix] Fix DeepSeek v3.2 tokenizer outputting None issue (#33832) |
| 2026-02-06 06:16:02 | Hashem Hashemi | Adds padding and perf improvements to wvSplitK_fp8 (#33527) |
| 2026-02-06 06:05:09 | Lumosis | [Minor] Sort safetensors files to ensure deterministic loading order (#33491) |
| 2026-02-06 04:40:58 | Cyrus Leung | [Bugfix] Make MM batching more robust (#33817) |
| 2026-02-06 03:22:19 | Matthew Bonanni | [Bugfix] Fix DSV3.2 NVFP4 (#33932) |
| 2026-02-06 03:16:52 | NicolÃ² Lucchesi | [Misc] Rename `translations` to `speech_to_text` for OAI serving component (#33904) |
| 2026-02-06 03:16:20 | Harry Mellor | Fix tokenizer test for renamed attr on Transformers v5 (#33902) |
| 2026-02-06 02:47:09 | Tsukasa OI | [Bugfix] Suppress non-TTY color output on the process name part of the log (#29714) |
| 2026-02-06 02:29:20 | Isotr0py | [Models] Consolidate Deepseek-OCR2 processor (#33909) |
| 2026-02-06 02:07:18 | bnellnm | [Moe Refactor] Make Inplace Flag for FusedMoEModularKernel part of the constructor (#33375) |
| 2026-02-06 01:51:58 | zackyoray | [Bugfix] Fix swapped engine_ids in NIXL Llama 4 local attention path (#33795) |
| 2026-02-06 01:42:40 | NicolÃ² Lucchesi | [Misc] Add debug logs (#33931) |
| 2026-02-06 01:37:18 | Benjamin Chislett | [Spec Decode] Unified Parallel Drafting (#32887) |
| 2026-02-06 01:25:55 | danisereb | [BugFix] Fix LoRA Fp8 (#33879) |
| 2026-02-06 01:13:23 | Aaron Hao | [Feat][RL][1/2] Native Weight Syncing API: NCCL (#31943) |
| 2026-02-06 00:04:04 | Mario Hong | [Bugfix] Fix step3p5 parser when using mtp (#33690) |

### ğŸ“Š ç»Ÿè®¡æ‘˜è¦
> æœ¬æ—¥å…± 44 ä¸ªæäº¤ | ğŸ”´é«˜ 7 | ğŸŸ¡ä¸­ 20 | ğŸŸ¢ä½ 17
## ğŸ“‹ ç›®å½•

- [vllm-project/vllm](#vllm-project-vllm)
  - [ğŸ“Š ç»Ÿè®¡æ‘˜è¦](#-ç»Ÿè®¡æ‘˜è¦)
  - [ğŸ”´ é«˜é‡è¦åº¦å˜æ›´ (7)](#-ğŸ”´-é«˜é‡è¦åº¦å˜æ›´-7)
    - [[Refactor] Consolidate sequence normalization and enc-dec...](#cd8b405)
    - [[torch.compile] Reorganize vllm/compilation and tests/com...](#ac32e66)
    - [feat(frontend): early-fail tokenization guard for user re...](#a32cb49)
    - [[Feature] OTEL tracing during loading (#31162)](#325ab6b)
    - [[Bugfix] Make MM batching more robust (#33817)](#116880a)
    - [[Spec Decode] Unified Parallel Drafting (#32887)](#af3162d)
    - [[Feat][RL][1/2] Native Weight Syncing API: NCCL (#31943)](#c1858b7)
  - [ğŸŸ¡ ä¸­é‡è¦åº¦å˜æ›´ (20)](#-ğŸŸ¡-ä¸­é‡è¦åº¦å˜æ›´-20)
    - [[XPU][5/N] add wna16 xpu kernel (#33973)](#2ce9fe4)
    - [[Model] Support MiniCPM-o 4.5 (#33431)](#4707f7e)
    - [[Docs] Add sections on process architecture and minimum C...](#c39ee9e)
    - [[ROCm][AITER] Fix AITER import regression for explicit ba...](#350ca72)
    - [[Bugfix] Fix models and tests for transformers v5 (#33977)](#85ee1d9)
    - [[Docs] Improve documentation (#33799)](#6e7b1c4)
    - [[Bugfix][Model] Support LoRA on Qwen3 Output Embedding (#...](#2991dd3)
    - [Consolidate and fix forbidden import `pre-commit` checks ...](#791a94b)
    - [support view_from_cpu_tensor on XPU (#33868)](#e969a16)
    - [[cpu][performance] CPU Paged Attention NEON BFMMLA BF16 I...](#1363e3d)
    - [Onboard voyage-4-nano (#33720)](#9655256)
    - [[XPU]Replace pip in docker.xpu with uv pip (#31112)](#6550815)
    - [[XPU][4/N] add mxfp4 moe model support (#33679)](#7439e4f)
    - [fix(ROCm): Make flash_attn import optional in MLA attenti...](#20d7454)
    - [[Perf] Disable clean_logits in deepgemm fp8_mqa_logits ke...](#79028d4)
    - [Adds padding and perf improvements to wvSplitK_fp8 (#33527)](#d5c4800)
    - [[Misc] Rename `translations` to `speech_to_text` for OAI ...](#20f5d18)
    - [[Models] Consolidate Deepseek-OCR2 processor (#33909)](#87d0d17)
    - [[Moe Refactor] Make Inplace Flag for FusedMoEModularKerne...](#a57c822)
    - [[Bugfix] Fix step3p5 parser when using mtp (#33690)](#82914d2)
  - [ğŸŸ¢ ä½é‡è¦åº¦å˜æ›´ (17)](#-ğŸŸ¢-ä½é‡è¦åº¦å˜æ›´-17)
    - [[FIX] guidance: use max(vocab_size, len(tokenizer)) for n...](#1fb0495)
    - [Update `WeightTransferConfig` to be more standard like th...](#51a7bda)
    - [[CPU][BugFix] Fix loading of w8a8int models with bias (#3...](#f79d9dc)
    - [Bump HF Hub client to get bug fix (#33984)](#ba5cbbf)
    - [[PaddleOCR-VL] Add BC for transformers 5.0 config (#33976)](#233b26a)
    - [Fix `main` pre-commit (#33975)](#6d8d34b)
    - [[CPU] Add BF16 Kernel type for s390x (#33788)](#ac04dd3)
    - [[Misc] Update code for encoder-decoder models (#33900)](#035a6cb)
    - [[Docs] Add reo analytics (#33957)](#5819ca8)
    - [[Bugfix] Fix DeepSeek v3.2 tokenizer outputting None issu...](#91a07ff)
    - [[Minor] Sort safetensors files to ensure deterministic lo...](#42d5d70)
    - [[Bugfix] Fix DSV3.2 NVFP4 (#33932)](#4145e50)
    - [Fix tokenizer test for renamed attr on Transformers v5 (#...](#1887acc)
    - [[Bugfix] Suppress non-TTY color output on the process nam...](#92e7562)
    - [[Bugfix] Fix swapped engine_ids in NIXL Llama 4 local att...](#1ee9584)
    - [[Misc] Add debug logs (#33931)](#7d8c680)
    - [[BugFix] Fix LoRA Fp8 (#33879)](#5b2a942)
#### ğŸ”´ é«˜é‡è¦åº¦å˜æ›´ (7)

### [Refactor] Consolidate sequence normalization and enc-dec parsing (#33928)
**SHA**: `cd8b405` | ğŸ”— [æŸ¥çœ‹æäº¤](https://github.com/vllm-project/vllm/commit/cd8b405bd0c0f386ef7eedcb7d792a8bb72a8b65)

**ğŸ¯ å˜æ›´ç±»å‹**ï¼šé‡æ„ / æ¶æ„å˜æ›´  

**âš¡ é‡è¦ç¨‹åº¦**ï¼šğŸ”´é«˜  

**ğŸ“‹ å˜æ›´æ‘˜è¦**  
æœ¬æ¬¡æäº¤å¯¹ **vLLM** çš„ Prompt é¢„å¤„ç†ã€æ¸²æŸ“ä»¥åŠ Engine æ¥å£è¿›è¡Œå…¨é“¾è·¯é‡æ„ï¼Œæ ¸å¿ƒç›®æ ‡æ˜¯ **ç»Ÿä¸€åºåˆ—åŒ–ï¼ˆpromptâ€‘toâ€‘seqï¼‰** ä¸ **Encoderâ€‘Decoder è§£æ** çš„å®ç°ã€‚æ–°å¢ `vllm.renderers.inputs` åŒ…ï¼Œæä¾›ç»Ÿä¸€çš„ DictPrompt / TokPrompt ç±»å‹ä»¥åŠä¸€å¥— `prompt_to_seqã€parse_model_promptã€extract_prompt_components` ç­‰å‡½æ•°ï¼Œå–ä»£åŸæœ‰çš„ `inputs.parse`ã€`inputs.zip_enc_dec_prompts`ã€`inputs.build_explicit_enc_dec_prompt` ç­‰æ•£è½åœ¨å¤šä¸ªæ¨¡å—çš„å®ç°ã€‚æ‰€æœ‰æ¸²æŸ“å™¨ï¼ˆHFã€Mistralã€DeepSeekã€Grok2ã€Terratorch ç­‰ï¼‰ä»¥åŠ OpenAI å…¥å£ã€Engineã€AsyncEngineã€InputProcessorã€LLMEngine ç­‰å‡æ”¹ä¸ºä½¿ç”¨æ–°çš„ç»Ÿä¸€æ¥å£ï¼Œå¹¶ç›¸åº”åˆ é™¤äº†æ—§çš„ `get_prompt_components / get_prompt_len / is_explicit_encoder_decoder_prompt` ç­‰å·¥å…·å‡½æ•°ã€‚  

**ğŸ¯ å½±å“èŒƒå›´**  

| å—å½±å“çš„ä¸»è¦æ¨¡å— / æ–‡ä»¶ |
|------------------------|
| `vllm/renderers/inputs/*`ï¼ˆæ–°å¢ï¼‰ |
| `vllm/renderers/*`ï¼ˆHFã€Mistralã€DeepSeekã€Grok2ã€Terratorchï¼‰ |
| `vllm/entrypoints/openai/*`ï¼ˆchat_completionã€completionã€engineã€responses ç­‰ï¼‰ |
| `vllm/entrypoints/llm.py` |
| `vllm/v1/engine/*`ï¼ˆasync_llmã€input_processorã€llm_engineã€utilsï¼‰ |
| `vllm/engine/protocol.py` |
| `vllm/inputs/*`ï¼ˆdataã€preprocessã€parseï¼‰ |
| `vllm/multimodal/*`ï¼ˆinputsï¼‰ |
| ç›¸å…³æµ‹è¯•æ–‡ä»¶ï¼ˆtests/renderersã€tests/entrypointsã€tests/inputs ç­‰ï¼‰ |
| å…¶ä»–è¾…åŠ©æ–‡ä»¶ï¼š`vllm/platforms/interface.py`ã€`vllm/renderers/protocol.py` ç­‰ |

**ğŸ” æŠ€æœ¯æ´å¯Ÿ**  

- **æ¶æ„å½±å“**  
  - **ç»Ÿä¸€ Prompt ç±»å‹**ï¼šå¼•å…¥ `DictPrompt`ï¼ˆåŒ…å« Decoderâ€‘Onlyã€Encoderâ€‘Decoderã€Singletonï¼‰å’Œ `TokPrompt`ï¼ˆå·²å®Œæˆ token åŒ–çš„ Promptï¼‰ï¼Œæ¶ˆé™¤äº†ä¹‹å‰åœ¨ä¸åŒä»£ç è·¯å¾„ä¸­å¯¹ `TextPrompt / TokensPrompt / EmbedsPrompt / ExplicitEncoderDecoderPrompt` çš„æ‰‹å·¥æ‹¼è£…ã€‚  
  - **é›†ä¸­è§£æé€»è¾‘**ï¼š`prompt_to_seq`ã€`parse_model_prompt`ã€`extract_prompt_components` è´Ÿè´£ä¸€æ¬¡æ€§å°†ä»»æ„ç”¨æˆ·è¾“å…¥ï¼ˆstrã€bytesã€list[int]ã€dictï¼‰æ ‡å‡†åŒ–ä¸ºç»Ÿä¸€å­—å…¸ç»“æ„ï¼Œå†äº¤ç»™æ¸²æŸ“å™¨ä¸ Tokenizerã€‚è¿™æ ·æ¸²æŸ“å™¨ä¸å†éœ€è¦è‡ªè¡Œåˆ¤æ–­è¾“å…¥ç±»å‹ï¼Œé™ä½äº†ä»£ç é‡å¤åº¦ã€‚  
  - **æ¸²æŸ“å™¨åè®®ç®€åŒ–**ï¼š`BaseRenderer.render_prompt`ï¼ˆåŸ `render_completion`ï¼‰ç»Ÿä¸€è¿”å› `DictPrompt`ï¼Œå¯¹åº”çš„ `tokenize_prompt`ã€`tokenize_prompts` é€šè¿‡ overload æ”¯æŒä¸‰ç§è¾“å…¥ï¼ˆæ–‡æœ¬ã€tokenã€embedï¼‰ä»¥åŠ Encoderâ€‘Decoder ç»“æ„ã€‚  
  - **Engine ä¸ InputProcessor é€‚é…**ï¼š`EngineCoreRequest`ã€`add_request`ã€`generate`ã€`encode` ç­‰å…¥å£å‚æ•°ç±»å‹ä» `PromptType` æ‰©å±•ä¸º `PromptType | DictPrompt | TokPrompt`ï¼Œå¹¶åœ¨å†…éƒ¨ç»Ÿä¸€ä½¿ç”¨ `extract_prompt_components` æå– `text / token_ids / embeds`ã€‚  
  - **å»é™¤æ—§å·¥å…·**ï¼š`inputs.parse.is_explicit_encoder_decoder_prompt`ã€`zip_enc_dec_prompts`ã€`build_explicit_enc_dec_prompt` ç­‰å·²è¢«åˆ é™¤ï¼Œç›¸å…³æ’ä»¶ï¼ˆIOProcessorï¼‰éœ€è¦æ›´æ–°ä»¥ä½¿ç”¨æ–°çš„ `DictPrompt` ç»“æ„ã€‚  

- **æ€§èƒ½å½±å“**  
  - **æ­£é¢**ï¼šç»Ÿä¸€çš„é¢„å¤„ç†é¿å…äº†åœ¨æ¸²æŸ“å™¨ã€Engineã€EntryPoints å¤šæ¬¡é‡å¤çš„ç±»å‹æ£€æµ‹ä¸å­—å…¸æ„é€ ï¼Œç†è®ºä¸Šå¯å‡å°‘ CPU åˆ†æ”¯å¼€é”€ã€‚  
  - **æ½œåœ¨è´Ÿé¢**ï¼šæ–°å¢çš„å‡½æ•°åŒ…è£…å±‚ï¼ˆå°¤å…¶æ˜¯ overload ä¸ runtime `if "encoder_prompt" in prompt` æ£€æŸ¥ï¼‰ä¼šå¼•å…¥è½»å¾®çš„å‡½æ•°è°ƒç”¨å¼€é”€ï¼›ä½†å¯¹å¤§æ¨¡å‹ååé‡çš„å½±å“å¾®ä¹å…¶å¾®ï¼Œä¸”å·²åœ¨ `AsyncMicrobatchTokenizer` ä¸­ä¿æŒå¼‚æ­¥æ‰¹é‡åŒ–çš„ä¼˜åŠ¿ã€‚  
  - **ç¼“å­˜/å‰ç¼€ç¼“å­˜**ï¼šå¯¹ `prompt_embeds` çš„åŠ è½½è·¯å¾„ä¿æŒä¸å˜ï¼Œä»ä½¿ç”¨ `safe_load_prompt_embeds`ï¼›å¤šæ¨¡æ€ç¼“å­˜ç»Ÿè®¡ä»é€šè¿‡ `MultiModalCacheStats` è®°å½•ã€‚  

- **å®‰å…¨è€ƒè™‘**  
  - **è¾“å…¥æ ¡éªŒç»Ÿä¸€åŒ–**ï¼šæ‰€æœ‰å…¥å£ç°åœ¨ç»Ÿä¸€èµ° `parse_model_prompt`/`parse_enc_dec_prompt`ï¼Œè¿™ä¸¤ä¸ªå‡½æ•°åœ¨æ£€æµ‹éæ³•ç»„åˆï¼ˆå¦‚åœ¨ Decoderâ€‘Only æ¨¡å‹ä¸­å‡ºç° `encoder_prompt`ã€åœ¨ Encoderâ€‘Decoder ä¸­å‡ºç° `prompt_embeds`ï¼‰æ—¶ä¼šæŠ› `TypeError`ï¼Œå¯é˜²æ­¢åŸå…ˆæŸäº›åˆ†æ”¯æ¼æ‰çš„éæ³•è¾“å…¥ã€‚  
  - **åˆ é™¤äº† `get_prompt_len`**ï¼šé•¿åº¦è®¡ç®—æ”¹ä¸º `extract_prompt_len`ï¼Œè¯¥å‡½æ•°ä½¿ç”¨ `length_from_prompt_token_ids_or_embeds`ï¼Œç¡®ä¿å¯¹åµŒå…¥å¼ Prompt ä»èƒ½å¾—åˆ°æ­£ç¡®çš„ token é•¿åº¦ï¼Œé¿å…å› é•¿åº¦è®¡ç®—é”™è¯¯å¯¼è‡´ `max_total_tokens` è¶Šç•Œè€Œè§¦å‘ OOMã€‚  
  - **å‘åå…¼å®¹**ï¼šæ—§çš„ `PromptType` ä»ç„¶æ˜¯ `DecoderOnlyPrompt` çš„å­é›†ï¼Œè°ƒç”¨æ–° API æ—¶è‹¥ä»ä¼ å…¥åŸå§‹ç»“æ„ï¼ˆå¦‚ `str`ã€`list[int]`ï¼‰ï¼Œ`prompt_to_seq` ä¼šè‡ªåŠ¨åŒ…è£…ä¸ºåˆ—è¡¨ï¼Œä¿æŒå…¼å®¹ã€‚å”¯ä¸€çš„å®‰å…¨é£é™©åœ¨äº **ç¬¬ä¸‰æ–¹æ’ä»¶** ç›´æ¥è®¿é—®å·²åˆ é™¤çš„å†…éƒ¨å·¥å…·å‡½æ•°æˆ–ä¾èµ–æ—§çš„ Prompt å­—æ®µç»“æ„ï¼Œéœ€è¦æ‰‹åŠ¨è¿ç§»ã€‚  

**âš ï¸ æ½œåœ¨é£é™©**  

1. **å‘åå…¼å®¹æ€§ç ´å**  
   - æŸäº›å¤–éƒ¨æ’ä»¶ï¼ˆå°¤å…¶æ˜¯è‡ªå®šä¹‰ `IOProcessor`ã€ç”¨æˆ·è‡ªè¡Œå®ç°çš„ `Renderer`ï¼‰ä»å¯èƒ½å¼•ç”¨å·²åˆ é™¤çš„ `inputs.parse.is_explicit_encoder_decoder_prompt`ã€`zip_enc_dec_prompts` ç­‰å‡½æ•°ï¼Œå¯¼è‡´ `ImportError`ã€‚  
   - `vllm.entrypoints.utils.get_max_tokens` ç°åœ¨æ¥å— `input_length` è€Œä¸æ˜¯ Prompt å¯¹è±¡ï¼Œè‹¥æœªåŒæ­¥æ›´æ–°è°ƒç”¨æ–¹ä¼šå‡ºç°å‚æ•°ä¸åŒ¹é…é”™è¯¯ã€‚  

2. **å¤šæ¨¡æ€æ•°æ®è·¯å¾„å›å½’**  
   - `InputProcessor._validate_mm_uuids` ä¸­çš„ç±»å‹æ£€æŸ¥æ”¹ä¸º `isinstance(prompt, dict) and "encoder_prompt" in prompt`ï¼Œè‹¥å‡ºç° **è£¸å­—å…¸**ï¼ˆä¸ç¬¦åˆ TypedDictï¼‰ä½†åŒ…å«ç›¸åŒé”®åï¼Œå¯èƒ½å¯¼è‡´æœªè§¦å‘ `mm_processor_kwargs` çš„æ ¡éªŒï¼Œä»è€Œå‡ºç°éšå¼é”™è¯¯ã€‚  

3. **Encoderâ€‘Decoder æ”¯æŒç»†èŠ‚**  
   - å¯¹ Encoderâ€‘Decoder æ¨¡å‹çš„ Prompt è§£æç°åœ¨ç»Ÿä¸€èµ° `parse_enc_dec_prompt`ï¼Œä½†åœ¨ `LLMEngine.encode` ä¸ `AsyncLLMEngine.encode` ä¸­ä»ç›´æ¥è½¬å‘ `prompt`ã€‚è‹¥ç”¨æˆ·ä¼ å…¥ä»…åŒ…å« Encoder Promptï¼ˆä¸å¸¦ DecoderPromptï¼‰ï¼Œ`parse_enc_dec_prompt` ä¼šæŠŠ `decoder_prompt=None`ï¼Œåç»­ `tokenize_prompt` ä¼šå¯¹ `decoder_prompt` æ‰§è¡Œ `None` æ£€æŸ¥ï¼Œå·²é€šè¿‡ guard ä½†æ˜¯åœ¨æœªæ¥çš„ç‰¹æ€§ï¼ˆä¾‹å¦‚å¼ºåˆ¶è¦æ±‚ DecoderPromptï¼‰å¯èƒ½å‡ºç°é€»è¾‘å†²çªã€‚  

4. **æ€§èƒ½å›å½’**  
   - æ–°çš„ overload å®ç°å¯¼è‡´ **mypy/pyright** ç±»å‹æ£€æŸ¥æ—¶äº§ç”Ÿ `Any`ï¼Œå®é™…è¿è¡Œæ—¶ Python çš„ **dispatch** ä¼šéå† overload åˆ—è¡¨ï¼Œ

---

### [torch.compile] Reorganize vllm/compilation and tests/compile (0/N for vLLM IR) (#33731)
**SHA**: `ac32e66` | ğŸ”— [æŸ¥çœ‹æäº¤](https://github.com/vllm-project/vllm/commit/ac32e66cf95c40502ad7b00b2e80dfb0315bfee4)

**ğŸ¯ å˜æ›´ç±»å‹**ï¼šæ¶æ„å˜æ›´ / é‡æ„  
**âš¡ é‡è¦ç¨‹åº¦**ï¼šğŸ”´é«˜  

**ğŸ“‹ å˜æ›´æ‘˜è¦**  
æ­¤æ¬¡æäº¤å¯¹ `vllm` çš„ç¼–è¯‘å­ç³»ç»Ÿè¿›è¡Œäº†å¤§å¹…é‡æ„ï¼š  
1. å°†åŸå…ˆæ•£è½åœ¨ `vllm/compilation` ä¸‹çš„æ‰€æœ‰ Passã€å·¥å…·å‡½æ•°ã€FX è¾…åŠ©ç­‰ç»Ÿä¸€è¿ç§»è‡³æ–° package `vllm/compilation/passes`ï¼Œå¹¶ç›¸åº”æ›´æ–°äº†å†…éƒ¨ import è·¯å¾„ã€‚  
2. å¼•å…¥ **`collective_fusion.py`**ï¼Œå®ç°äº†åŸºäºå¯¹ç§°å†…å­˜çš„ GEMM + ReduceScatter / AllGather + GEMM ç­‰å¼‚æ­¥ Tensorâ€‘Parallelï¼ˆAsyncTPï¼‰èåˆ Passã€‚  
3. é‡æ–°ç»„ç»‡æµ‹è¯•ç›®å½•ï¼šæ‰€æœ‰ç¼–è¯‘ Pass çš„å•å…ƒæµ‹è¯•ç»Ÿä¸€æ¬è‡³ `tests/compile/passes`ï¼Œå¹¶æ–°å¢ **correctness_e2e** å­ç›®å½•ç”¨äºç«¯åˆ°ç«¯åŠŸèƒ½éªŒè¯ï¼ˆå¦‚ AsyncTP æ­£ç¡®æ€§ï¼‰ã€‚  
4. åŒæ—¶åŒæ­¥æ›´æ–° Buildkite CI æµæ°´çº¿çš„ YAML é…ç½®ï¼Œä»¥åŒ¹é…æ–°çš„æµ‹è¯•è·¯å¾„å’Œèµ„æºæ ‡ç­¾ã€‚  

**ğŸ¯ å½±å“èŒƒå›´**  
- **æ ¸å¿ƒæ¨¡å—**ï¼š`vllm/compilation/*`ï¼ˆå°¤å…¶æ˜¯ `passes`ã€`inductor_pass`ã€`pass_manager`ã€`backends`ï¼‰  
- **é…ç½®æ¨¡å—**ï¼š`vllm/config/compilation.py`ã€`vllm/platforms/interface.py`ï¼ˆPass manager è·¯å¾„æ›´æ”¹ï¼‰  
- **æµ‹è¯•å¥—ä»¶**ï¼š`tests/compile/*`ï¼ˆå…¨éƒ¨è¿ç§»è‡³ `passes` å­ç›®å½•ï¼‰  
- **CI/CD**ï¼š`.buildkite/*.yaml`ï¼ˆagent poolã€testè·¯å¾„ã€å‘½ä»¤è¡Œå‚æ•°ï¼‰  

---

## ğŸ” æŠ€æœ¯æ´å¯Ÿ

| ç»´åº¦ | å½±å“æè¿° |
|------|-----------|
| **æ¶æ„å½±å“** | - **æ¨¡å—åŒ–æå‡**ï¼šæ‰€æœ‰ Pass ç»Ÿä¸€å½’å…¥ `passes` åŒ…ï¼Œå½¢æˆæ¸…æ™°çš„å±‚çº§ï¼ˆ`fusion`, `utility`ï¼‰ï¼Œä¾¿äºåç»­æ‰©å±•å’Œç»´æŠ¤ã€‚<br>- **å…¥å£ç»Ÿä¸€**ï¼š`vllm/compilation/passes/__init__.py` æˆä¸ºå…¬å…±å¯¼å‡ºç‚¹ï¼Œé™ä½è·¨æ–‡ä»¶å¼•ç”¨é”™è¯¯ã€‚<br>- **Pass Manager é‡å®šä½**ï¼š`PostGradPassManager` çš„å…¨è·¯å¾„ä» `vllm.compilation.pass_manager` æ”¹ä¸º `vllm.compilation.passes.pass_manager`ï¼Œç¡®ä¿å¹³å°å±‚è·å–æ­£ç¡®å®ç°ã€‚<br>- **åç«¯åˆ†ç¦»**ï¼š`backends.py` ç°åœ¨æ˜¾å¼ä¾èµ– `passes.inductor_pass` ä¸ `passes.pass_manager`ï¼Œä½¿åç«¯ä¸ Pass è§£è€¦ã€‚ |
| **æ€§èƒ½å½±å“** | - **AsyncTP Fusion**ï¼šæ–°å®ç°çš„ `AsyncTPPass` é€šè¿‡å¯¹ç§°å†…å­˜ (`symm_mem`) å°† GEMM ä¸ AllGather/ReduceScatter èåˆï¼Œæ˜¾è‘—é™ä½è·¨ GPU é€šä¿¡å¼€é”€ï¼Œå°¤å…¶åœ¨å¤§æ¨¡å‹çš„ Tensorâ€‘Parallel åœºæ™¯ä¸‹å¯æå‡ **10%â€‘30%** çš„ååé‡ï¼ˆå–å†³äºç¡¬ä»¶ä¸ batch å¤§å°ï¼‰ã€‚<br>- **Fakeâ€‘mode ä¸ pattern matcher**ï¼š`enable_fake_mode` ä¿æŒåŸæœ‰çš„ç¼–è¯‘æ—¶â€œå¿«é€ŸéªŒè¯â€èƒ½åŠ›ï¼Œæœªå¯¹ runtime æ€§èƒ½äº§ç”Ÿè´Ÿé¢å½±å“ã€‚<br>- **Test è¿‡æ»¤**ï¼šCI ä¸­å¯¹ `passes` å­ç›®å½•çš„æ˜¾å¼ `--ignore` è§„é¿äº†åˆ†å¸ƒå¼æµ‹è¯•çš„å¹¶è¡Œå†²çªï¼Œæå‡ CI ç¨³å®šæ€§ã€‚ |
| **å®‰å…¨è€ƒè™‘** | - **å¯¼å…¥è·¯å¾„å˜æ›´**ï¼šå¤§è§„æ¨¡çš„ import é‡å†™è‹¥æœªåŒæ­¥æ‰€æœ‰å…¥å£ï¼ˆå¦‚ç¬¬ä¸‰æ–¹æ’ä»¶æˆ–å¤–éƒ¨è„šæœ¬ï¼‰ï¼Œå¯èƒ½å¯¼è‡´ **ImportError**ï¼Œè¿›è€Œåœ¨ç”Ÿäº§ç¯å¢ƒè§¦å‘æœåŠ¡å¼‚å¸¸ã€‚<br>- **å¯¹ç§°å†…å­˜å¯ç”¨**ï¼š`torch.distributed._symmetric_memory.enable_symm_mem_for_group` ä¾èµ–åº•å±‚ NCCL/torch.distributed å®ç°ï¼Œè‹¥åœ¨ä¸æ”¯æŒçš„ç¯å¢ƒï¼ˆè€ç‰ˆé©±åŠ¨æˆ–æœªå¼€å¯ `symm_mem`ï¼‰ä½¿ç”¨ï¼Œä¼šæŠ›å‡º runtime é”™è¯¯ï¼Œéœ€è¦åœ¨ `VLLM` å¯åŠ¨å‰è¿›è¡Œå…¼å®¹æ€§æ£€æŸ¥ã€‚<br>- **é…ç½®åºåˆ—åŒ–**ï¼š`vllm/config/compilation.py` ä¸­å¯¹ `FI_ALLREDUCE_FUSION_MAX_SIZE_MB` çš„å¯¼å…¥è·¯å¾„æ›´æ–°æœªæ”¹å˜éªŒè¯é€»è¾‘ï¼Œå®‰å…¨å½±å“æœ‰é™ã€‚ |
| **å¯ç»´æŠ¤æ€§** | - **ç»Ÿä¸€å‘½åç©ºé—´**ï¼šæ‰€æœ‰ Pass é‡‡ç”¨ `vllm.compilation.passes.<category>.<module>`ï¼Œä¾¿äº IDE è‡ªåŠ¨è¡¥å…¨å’Œæ–‡æ¡£ç”Ÿæˆã€‚<br>- **æµ‹è¯•ç»“æ„åŒ–**ï¼šæŠŠåŠŸèƒ½æµ‹è¯•ã€å•å…ƒæµ‹è¯•ã€ç«¯åˆ°ç«¯æ­£ç¡®æ€§æµ‹è¯•åˆ†å±‚ï¼Œæå‡å®šä½é—®é¢˜çš„æ•ˆç‡ã€‚<br>- **æ—§è·¯å¾„æ®‹ç•™**ï¼šä»æœ‰å°‘æ•°æ–‡ä»¶ï¼ˆå¦‚ `vllm/compilation/backends.py`ï¼‰åœ¨æ³¨é‡Šä¸­ä¿ç•™æ—§ importï¼Œéœ€åœ¨åç»­æ¸…ç†ï¼Œé¿å…æ··æ·†ã€‚ |
| **å…¼å®¹æ€§** | - **å‘åå…¼å®¹**ï¼šä»…åœ¨å†…éƒ¨ import å±‚é¢å˜æ›´ï¼Œå…¬å¼€ APIï¼ˆå¦‚ `vllm.compilation.inductor_pass`, `vllm.compilation.pass_manager`ï¼‰çš„è·¯å¾„å·²åŒæ­¥åˆ°æ–°è·¯å¾„ï¼Œå¤–éƒ¨ä½¿ç”¨è€…è‹¥ç¡¬ç¼–ç æ—§è·¯å¾„å°†å‡ºç° `ImportError`ã€‚å»ºè®®åœ¨æ–‡æ¡£ä¸­æ˜ç¡®è¿ç§»æŒ‡å—æˆ–æä¾›å…¼å®¹ shimã€‚<br>- **Python ç‰ˆæœ¬**ï¼šä»£ç ä»åŸºäº Python 3.10+ï¼ˆä½¿ç”¨ `ParamSpec`ï¼‰ï¼Œæœªå—å½±å“ã€‚ |

---

## âš ï¸ æ½œåœ¨é£é™©

1. **å¯¼å…¥è·¯å¾„ç ´å**  
   - å¤–éƒ¨æ’ä»¶ã€ç”¨æˆ·è‡ªå®šä¹‰ Pass æˆ–è„šæœ¬ä»å¯èƒ½å¼•ç”¨æ—§çš„ `vllm.compilation.*` è·¯å¾„ã€‚æœªæä¾›å…¼å®¹å±‚ä¼šå¯¼è‡´è¿è¡Œæ—¶å¼‚å¸¸ã€‚  

2. **å¯¹ç§°å†…å­˜å¯ç”¨å¤±è´¥**  
   - åœ¨ä¸æ”¯æŒ `torch.distributed._symmetric_memory`ï¼ˆå¦‚æ—§ç‰ˆ CUDA/NCCLã€é GPU ç¯å¢ƒï¼‰ä¸‹ï¼Œ`AsyncTPPass` çš„æ„é€ ä¼šæŠ›å‡º `ImportError` æˆ– `RuntimeError`ï¼Œå¯¼è‡´æ•´å¥—ç¼–è¯‘æµç¨‹ä¸­æ­¢ã€‚  

3. **CI èµ„æºä¸åŒ¹é…**  
   - Buildkite ä¸­çš„ `agent_pool: mi325_8` ä¸å®é™…ç¡¬ä»¶èµ„æºä¸ç¬¦æ—¶ï¼Œå¯èƒ½å¯¼è‡´ä½œä¸šæ’é˜Ÿæˆ–å¤±è´¥ã€‚éœ€è¦ç¡®è®¤ `mi325_8` å·²åœ¨ Buildkite é…ç½®ä¸­åˆ›å»ºã€‚  

4. **æµ‹è¯• flaky**  
   - è¿ç§»åçš„åˆ†å¸ƒå¼æµ‹è¯•ï¼ˆå°¤å…¶ `correctness_e2e`ï¼‰å¯¹ GPU æ‹“æ‰‘ä¸è¿›ç¨‹é—´åŒæ­¥è¦æ±‚æ›´é«˜ï¼Œè‹¥ CI å¹¶å‘åº¦æå‡ï¼Œå¯èƒ½å‡ºç°é—´æ­‡æ€§å¤±è´¥ã€‚  

5. **Pass æ³¨å†Œå†²çª**  
   - `pass_manager` åœ¨å¹³å°åˆå§‹åŒ–æ—¶è‡ªåŠ¨æ³¨å†Œ Passã€‚è‹¥æ—§ Pass æœªå®Œå…¨è¿ç§»ï¼Œå¹³å°å¯èƒ½é‡å¤æ³¨å†ŒåŒå Passï¼Œå¼•å‘ `KeyError` æˆ–è¦†ç›–é—®é¢˜ã€‚  

---

## ğŸ’¡ å…³æ³¨å»ºè®®

| ç›®æ ‡ | å»ºè®® |
|------|------|
| **å¹³æ»‘è¿ç§»** | - åœ¨ `vllm/compilation/__init__.py` æ·»åŠ  **å…¼å®¹ shim**ï¼šæŠŠæ—§è·¯å¾„çš„ç±»/å‡½æ•°é‡æ–°å¯¼å‡ºåˆ°æ–°å®ç°ä¸Šï¼Œç»™ä½¿ç”¨è€… 1â€‘2 ç‰ˆæœ¬çš„å®½é™æœŸã€‚<br>- åœ¨é¡¹ç›®çš„ `README` ä¸ `CHANGELOG` æ˜ç¡®åˆ—å‡ºè¿ç§»æ­¥éª¤ã€‚ |
| **å¯¹ç§°å†…å­˜å®‰å…¨** | - åœ¨ `AsyncTPPass.__init__` å‰åŠ å…¥ **ç¯å¢ƒæ£€æµ‹**ï¼š`if not hasattr(torch.distributed, "_symmetric_memory"):` è®°å½•è­¦å‘Šå¹¶å›é€€åˆ°ä¼ ç»Ÿ AllGather+GEMM å®ç°ã€‚<br>- ä¸º `VllmConfig` å¢åŠ  `enable_async_tp` å¼€å…³ï¼Œé»˜è®¤åœ¨ä¸æ”¯æŒæ—¶è‡ªåŠ¨å…³é—­ã€‚ |
| **CI ç¨³å®šæ€§** | - ä¸º `tests/compile/passes/distributed/*` æ·»åŠ  **pytest.mark.timeout** ä¸ **retry** è£…é¥°å™¨ï¼Œå‡è½»å¶å‘æ€§è¶…æ—¶ã€‚<br>- ç¡®è®¤ `agent_pool: mi325_8` å·²åœ¨ Buildkite ä¸­é…ç½®ï¼Œå¹¶åœ¨ PR æ£€æŸ¥è„šæœ¬ä¸­éªŒè¯å…¶å¯ç”¨æ€§ã€‚ |
| **æ–‡æ¡£ä¸ä¾‹å­** | - åœ¨ `docs/source/compilation` å¢åŠ  **Pass å¼€å‘æŒ‡å—**ï¼Œæ¼”ç¤ºå¦‚ä½•åœ¨ `vllm.compilation.passes` ä¸­æ·»åŠ æ–° Pass å¹¶æ³¨å†Œåˆ°å¹³å°ã€‚<br>- ä¸º `AsyncTPPass` æä¾› **æ€§èƒ½åŸºå‡†**ï¼ˆå¦‚ä¸åŒ TP sizeã€æ¨¡å‹è§„æ¨¡çš„å¯¹æ¯”å›¾ï¼‰ï¼Œå¸®åŠ©ç”¨æˆ·è¯„ä¼°æ˜¯å¦å¯ç”¨ã€‚ |
| **ä»£ç æ¸…ç†** | - åœ¨åç»­è¿­ä»£ä¸­ç§»é™¤ `vllm/compilation/backends.py` ä¸­å·²æ³¨é‡Šçš„æ—§ import ä¸å ä½ä»£ç ã€‚<br>- ä½¿ç”¨ static analysisï¼ˆ`ruff`, `pylint`) æ£€æŸ¥æœªä½¿ç”¨çš„ import

---

### feat(frontend): early-fail tokenization guard for user requests (#31366)
**SHA**: `a32cb49` | ğŸ”— [æŸ¥çœ‹æäº¤](https://github.com/vllm-project/vllm/commit/a32cb49b60688fb64a6d3d7f86378b4d2fad06e6)

**ğŸ¯ å˜æ›´ç±»å‹**ï¼šåŠŸèƒ½å¢å¼ºï¼ˆå‰ç«¯æ¸²æŸ“å±‚â€¯+â€¯å‚æ•°/Tokenizer åè®®ï¼‰  
**âš¡ é‡è¦ç¨‹åº¦**ï¼šğŸ”´é«˜  

**ğŸ“‹ å˜æ›´æ‘˜è¦**  
1. ä¸º `HfRenderer` å¢åŠ  **â€œæå‰å¤±è´¥çš„ token åŒ–å®ˆå«â€**ï¼šåœ¨æ”¶åˆ°ç”¨æˆ·è¯·æ±‚æ—¶ï¼Œå…ˆå¯¹åŸå§‹æ–‡æœ¬é•¿åº¦ï¼ˆå­—ç¬¦æ•°ï¼‰è¿›è¡Œæ£€æŸ¥ï¼Œè‹¥è¶…å‡ºæ¨¡å‹åœ¨å­—ç¬¦å±‚é¢çš„æœ€å¤§å¯æ¥å—é•¿åº¦ï¼Œåˆ™ç›´æ¥æŠ›å‡º `VLLMValidationError`ï¼Œé¿å…æ— æ„ä¹‰çš„ token åŒ–è€—æ—¶ã€‚  
2. åœ¨ `vllm.renderers.params.TokenizeParams` ä¸­å®ç°äº†ç»Ÿä¸€çš„ **æ–‡æœ¬/Token é•¿åº¦æ ¡éªŒã€å¤§å°å†™ç»Ÿä¸€ã€é¢„å¡«å……/æˆªæ–­é€»è¾‘**ï¼Œå¹¶å°†åŸæœ‰çš„ `_apply_*` æ–¹æ³•æ›´åä¸º `_token_*`ï¼Œä½¿èŒè´£æ›´æ¸…æ™°ã€‚  
3. ç»™æ‰€æœ‰ Tokenizer å®ç°ï¼ˆHFã€DeepSeekâ€‘V32ã€Grokâ€‘2ã€Mistral ç­‰ï¼‰ä»¥åŠæŠ½è±¡åè®® `TokenizerLike` æ–°å¢ `max_chars_per_token` å±æ€§ï¼Œç”¨äºåœ¨å­—ç¬¦å±‚é¢ä¼°ç®—æœ€å¤§å¯æ¥å—çš„è¾“å…¥é•¿åº¦ã€‚  
4. æµ‹è¯•å¥—ä»¶åŒæ­¥åŒ–ï¼ˆå»æ‰ `async`ï¼‰ï¼Œå¹¶å¼•å…¥ `DummyTokenizer` è¿›è¡Œ **encode å‚æ•°æ•è·**ï¼ŒéªŒè¯æ–° guard çš„è¡Œä¸ºã€‚

---

### ğŸ¯ å½±å“èŒƒå›´
- **æ ¸å¿ƒæ¸²æŸ“æ¨¡å—**ï¼š`vllm/renderers/hf_renderer.py`ï¼ˆ`render_completions[_async]` ä»£ç è·¯å¾„ï¼‰  
- **å‚æ•°æ ¡éªŒå±‚**ï¼š`vllm/renderers/params.py`  
- **Tokenizer å®ç°**ï¼š`vllm/tokenizers/*.py`ï¼ˆHFã€DeepSeekâ€‘V32ã€Grokâ€‘2ã€Mistralï¼‰ä»¥åŠæŠ½è±¡åè®® `vllm/tokenizers/protocol.py`  
- **å•å…ƒæµ‹è¯•**ï¼š`tests/renderers/test_completions.py`ï¼ˆå…¨éƒ¨æ”¹ä¸ºåŒæ­¥è°ƒç”¨ï¼‰  

---

### ğŸ” æŠ€æœ¯æ´å¯Ÿ

| ç»´åº¦ | å½±å“ |
|------|------|
| **æ¶æ„å½±å“** | - åœ¨æ¸²æŸ“å±‚åŠ å…¥ **å‰ç½®æ ¡éªŒ**ï¼Œå½¢æˆâ€œè¯·æ±‚ â†’ å‚æ•°æ£€æŸ¥ â†’ ï¼ˆå¯é€‰ï¼‰token åŒ– â†’ æ¸²æŸ“â€ä¸‰æ®µå¼æµæ°´çº¿ï¼ŒèŒè´£æ›´åŠ å•ä¸€ã€‚<br>- ä¸ºæ‰€æœ‰ Tokenizer å¢åŠ ç»Ÿä¸€çš„ `max_chars_per_token` æ¥å£ï¼Œç»Ÿä¸€äº†å­—ç¬¦â€‘token è½¬æ¢çš„ä¸Šé™ä¼°ç®—ï¼Œæå‡äº†ä¸åŒæ¨¡å‹ä¹‹é—´çš„å¯æ¯”æ€§ã€‚ |
| **æ€§èƒ½å½±å“** | - **æ˜¾è‘—é™ä½ CPU/GPU èµ„æºæ¶ˆè€—**ï¼šå¯¹æ˜æ˜¾è¶…é•¿çš„æ–‡æœ¬è¯·æ±‚ï¼Œç›´æ¥åœ¨ Python å±‚æŠ›å¼‚å¸¸ï¼Œä¸ä¼šè¿›å…¥ HuggingFace `encode`ï¼ˆå¾€å¾€æ˜¯ C++/Rust å®ç°ï¼‰ï¼Œé¿å…æ•°ç™¾æ¯«ç§’ç”šè‡³ç§’çº§çš„æ— æ•ˆè®¡ç®—ã€‚<br>- å¯¹å·²åœ¨å­—ç¬¦å±‚é¢å—é™çš„è¯·æ±‚ï¼ˆå¦‚ `max_total_tokens=100` ä¸” `max_chars_per_token=4`ï¼‰ï¼Œæ–° guard èƒ½åœ¨ **O(1)** æ—¶é—´å®Œæˆæ£€æŸ¥ï¼Œè€Œæ—§å®ç°åªèƒ½åœ¨ token åŒ–åæ•è·é”™è¯¯ï¼Œå¯¼è‡´ **ä¸¤å€ä»¥ä¸Š** çš„æ— æ•ˆç®—åŠ›æµªè´¹ã€‚ |
| **å®‰å…¨è€ƒè™‘** | - é˜²æ­¢ **DoS æ”»å‡»**ï¼šæ¶æ„ç”¨æˆ·å‘é€æé•¿å­—ç¬¦åºåˆ—ï¼ˆæ•°åä¸‡å­—ç¬¦ï¼‰ï¼ŒåŸå…ˆä¼šè€—å°½ token åŒ–ç®—åŠ›ï¼Œæ–° guard åœ¨å‡ å¾®ç§’å†…æ‹’ç»ï¼Œæå‡æœåŠ¡ç¨³å¥æ€§ã€‚<br>- é”™è¯¯ä¿¡æ¯ä¸­æŠ«éœ²çš„æ¨¡å‹ä¸Šä¸‹æ–‡é•¿åº¦ä¿æŒåœ¨å…¬å¼€èŒƒå›´ï¼Œæ— æ•æ„Ÿä¿¡æ¯æ³„éœ²é£é™©ã€‚ |
| **å¯ç»´æŠ¤æ€§** | - å‚æ•°æ ¡éªŒç»Ÿä¸€æ¬åˆ° `TokenizeParams`ï¼Œå·²å»é™¤æµ‹è¯•ä¸­å¯¹ `AsyncMock` çš„ä¾èµ–ï¼Œä»£ç è·¯å¾„æ›´ç®€æ´ã€‚<br>- æ–¹æ³•åç§°ä» `_apply_*` æ”¹ä¸º `_token_*`ï¼Œè¯­ä¹‰æ›´æ˜ç¡®ï¼Œé™ä½è¯¯ç”¨é£é™©ã€‚<br>- æ–°å¢ `max_chars_per_token` åï¼Œæ‰€æœ‰ç°æœ‰ Tokenizer å®ç°éœ€ä¿æŒè¯¥å±æ€§ï¼›è‹¥æœªæ¥å¼•å…¥è‡ªå®šä¹‰ tokenizerï¼Œå¿…é¡»å®ç°è¯¥å±æ€§ï¼Œå¦åˆ™ä¼šåœ¨æ¸²æŸ“æ—¶è§¦å‘å±æ€§é”™è¯¯ã€‚ |
| **å…¼å®¹æ€§** | - **å‘åå…¼å®¹**ï¼šå¯¹å·²æœ‰è°ƒç”¨ï¼ˆåŒ…æ‹¬ `async` æ¥å£ï¼‰è¡Œä¸ºä¿æŒä¸å˜ï¼Œåªæ˜¯æå‰æŠ¥é”™ã€‚<br>- **æ½œåœ¨ç ´å**ï¼šå¦‚æœæŸ tokenizer çš„å®ç°æ²¡æœ‰ `max_chars_per_token`ï¼ˆç¬¬ä¸‰æ–¹è‡ªå®šä¹‰å®ç°ï¼‰ï¼Œå°†å¯¼è‡´è¿è¡Œæ—¶ `AttributeError`ã€‚éœ€è¦åœ¨æ–‡æ¡£ä¸­æé†’ç”¨æˆ·å®ç°è¯¥å±æ€§æˆ–å›é€€åˆ°é»˜è®¤ `max_chars_per_token = 1`ï¼ˆå·²åœ¨ `DummyTokenizer` ä¸­ä½¿ç”¨ï¼‰ã€‚ |

---

### âš ï¸ æ½œåœ¨é£é™©

1. **è¯¯æŠ¥é£é™©**  
   - `max_chars_per_token` é‡‡ç”¨ **æœ€é•¿ token é•¿åº¦** ä¼°ç®—ï¼Œå¯èƒ½æ˜¾è‘—ä½ä¼°å®é™…å¯æ¥å—çš„å­—ç¬¦æ•°ï¼ˆå°¤å…¶æ˜¯æ±‰å­—ã€emoji ç­‰å¤šå­—èŠ‚å­—ç¬¦ï¼‰ï¼Œå¯¼è‡´åˆæ³•è¯·æ±‚è¢«æå‰æ‹’ç»ã€‚  
   - ç”Ÿäº§ç¯å¢ƒéœ€è¯„ä¼°ä¸åŒè¯­è¨€æ¨¡å‹çš„å®é™… `max_chars_per_token`ï¼Œæˆ–å…è®¸é€šè¿‡é…ç½®è¦†ç›–ï¼ˆå¦‚ `--override-max-chars-per-token`).  

2. **è·¨è¯­è¨€/è‡ªå®šä¹‰ tokenizer å…¼å®¹**  
   - ç¬¬ä¸‰æ–¹ tokenizer è‹¥æœªå®ç° `max_chars_per_token`ï¼Œæ¸²æŸ“é˜¶æ®µä¼šæŠ› `NotImplementedError`ã€‚è¿™åœ¨ä½¿ç”¨ç¤¾åŒºè‡ªå®šä¹‰ tokenizer æ—¶å®¹æ˜“è¢«å¿½è§†ã€‚  

3. **åŒæ­¥/å¼‚æ­¥è·¯å¾„ä¸ä¸€è‡´**  
   - ä»£ç ä¸»è¦åœ¨åŒæ­¥è·¯å¾„æ·»åŠ äº† guardï¼Œasyncè·¯å¾„ä»é€šè¿‡ `tokenize_prompts_async` è°ƒç”¨ `TokenizeParams.get_encode_kwargs`ï¼Œä½†æœªæ˜¾å¼æ•è· `VLLMValidationError`ï¼Œå¯èƒ½å¯¼è‡´æœªæ•è·å¼‚å¸¸ä¼ æ’­åˆ°å¼‚æ­¥ä»»åŠ¡è°ƒåº¦å™¨ã€‚  

4. **æµ‹è¯•è¦†ç›–ä¸è¶³**  
   - æ–°å¢çš„å­—ç¬¦å±‚é¢æ£€æŸ¥ä»…åœ¨ `tests/renderers/test_completions.py` ä¸­ç”¨ `DummyTokenizer` éªŒè¯ï¼Œæœªè¦†ç›–çœŸå® HuggingFace tokenizerã€‚å®é™… tokenizers çš„ `max_chars_per_token` è®¡ç®—æ˜¯å¦å‡†ç¡®ä»ç¼ºå°‘ç«¯åˆ°ç«¯æµ‹è¯•ã€‚  

---

### ğŸ’¡ å…³æ³¨å»ºè®®

1. **å®Œå–„æ–‡æ¡£ & é…ç½®**  
   - åœ¨ä½¿ç”¨è¯´æ˜ä¸­æ˜ç¡® `max_chars_per_token` çš„è¯­ä¹‰å’Œè®¡ç®—æ–¹å¼ï¼Œå¹¶æä¾› **è¦†ç›–é€‰é¡¹**ï¼ˆç¯å¢ƒå˜é‡æˆ– CLI å‚æ•°ï¼‰ä»¥åº”å¯¹è¯¯æŠ¥ã€‚  
   - å¯¹è‡ªå®šä¹‰ tokenizer ç»™å‡ºå®ç°æ¨¡æ¿ï¼Œå¼ºè°ƒå¿…é¡»å®ç° `max_chars_per_token`ã€‚  

2. **å…¼å®¹æ€§ä¿æŠ¤**  
   - åœ¨ `TokenizeParams.get_encode_kwargs` ä¸­åŠ å…¥ **fallback**ï¼šè‹¥ `tokenizer` æ²¡æœ‰ `max_chars_per_token`ï¼Œä½¿ç”¨ `1` ä½œä¸ºä¿å®ˆé»˜è®¤ï¼Œé¿å… `AttributeError`ã€‚  
   - å¯¹ async è·¯å¾„åœ¨è°ƒç”¨å‰ç»Ÿä¸€ä½¿ç”¨ `TokenizeParams._text_len_check`ï¼Œç¡®ä¿ä¸¤æ¡è·¯å¾„è¡Œä¸ºä¸€è‡´ã€‚  

3. **æ‰©å±•æµ‹è¯•**  
   - æ·»åŠ  **çœŸå®æ¨¡å‹ tokenizer**ï¼ˆå¦‚ `gpt2`, `Llama`, `Mistral`) çš„ç«¯åˆ°ç«¯é›†æˆæµ‹è¯•ï¼ŒéªŒè¯å­—ç¬¦/token ä¼°ç®—çš„å‡†ç¡®æ€§ã€‚  
   - å¯¹è¾¹ç¼˜å­—ç¬¦ï¼ˆä¸­æ–‡ã€æ—¥æ–‡ã€emojiã€ç©ºæ ¼ç­‰ï¼‰è¿›è¡Œ fuzz æµ‹è¯•ï¼Œç¡®ä¿ä¸ä¼šå‡ºç°è¯¯æŠ¥ã€‚  

4. **ç›‘æ§ä¸æŠ¥è­¦**  
   - åœ¨æœåŠ¡ç«¯è®°å½• **â€œæå‰å¤±è´¥è¯·æ±‚â€** çš„ç»Ÿè®¡ï¼ˆè¯·æ±‚ä½“é•¿åº¦ã€æ¨¡å‹ã€é”™è¯¯åŸå› ï¼‰ï¼Œç›‘æ§æ˜¯å¦å‡ºç°å¼‚å¸¸å¢é•¿ï¼Œä»¥ä¾¿å¿«é€Ÿå‘ç° `max_chars_per_token` è®¾å®šä¸åˆç†çš„æƒ…å†µã€‚  

5. **æ€§èƒ½åŸºå‡†**  
   - å¯¹æ¯” **æœ‰/æ—  guard** çš„è¯·æ±‚è€—æ—¶ï¼ˆå°¤å…¶æ˜¯é•¿æ–‡æœ¬ï¼‰ï¼Œåœ¨ CI ä¸­åŠ å…¥åŸºå‡†æµ‹è¯•ï¼Œç¡®ä¿ guard çš„å¼•å…¥å¸¦æ¥é¢„æœŸçš„èµ„æºèŠ‚çº¦ã€‚  

---

**ç»“è®º**ï¼šæœ¬æ¬¡ä¿®æ”¹åœ¨**å‰ç«¯æ¸²æŸ“å±‚åŠ å…¥äº†æå‰å¤±è´¥çš„å­—ç¬¦é•¿åº¦æ ¡éªŒ**ï¼Œé…åˆç»Ÿä¸€çš„ `max_chars_per_token` æ¥å£ï¼Œèƒ½å¤Ÿæ˜¾è‘—é™ä½ä¸åˆç†è¯·æ±‚çš„ç®—åŠ›æ¶ˆè€—å¹¶æå‡å®‰å…¨æ€§ã€‚è‹¥åœ¨ç”Ÿäº§ç¯å¢ƒä¸­éƒ¨ç½²ï¼Œå»ºè®®åšå¥½æ–‡æ¡£è¯´æ˜ã€å…¼å®¹æ€§é˜²æŠ¤ä»¥åŠçœŸå® tokenizer çš„å›å½’æµ‹è¯•ï¼Œä»¥è§„é¿è¯¯æŠ¥å’Œç¬¬ä¸‰æ–¹å®ç°ä¸å…¼å®¹çš„é£é™©ã€‚æ•´ä½“é£é™©å¯æ§ï¼Œä»·å€¼æ˜¾è‘—ï¼Œå»ºè®®å°½å¿«åˆå¹¶å¹¶åœ¨æ­£å¼ç¯å¢ƒå¼€å¯ã€‚

---

### [Feature] OTEL tracing during loading (#31162)
**SHA**: `325ab6b` | ğŸ”— [æŸ¥çœ‹æäº¤](https://github.com/vllm-project/vllm/commit/325ab6b0a896f4b483b26d99afdfc6d75ea61074)

**ğŸ¯ å˜æ›´ç±»å‹**ï¼šåŠŸèƒ½å¢å¼ºï¼ˆOTELâ€¯OpenTelemetryâ€¯å…¨é“¾è·¯è¿½è¸ªï¼‰  
**âš¡ é‡è¦ç¨‹åº¦**ï¼šğŸ”´ é«˜  

**ğŸ“‹ å˜æ›´æ‘˜è¦**  
- ä¸º vLLM é¡¹ç›®å¼•å…¥å¯é€‰çš„ OpenTelemetryï¼ˆOTELï¼‰è¿½è¸ªåç«¯ï¼Œæ–°å¢ `vllm.tracing` åŒ…å®ç°ç»Ÿä¸€çš„ tracing æ¥å£ã€‚  
- åœ¨ `setup.py` ä¸­å£°æ˜ `otel` å¯é€‰ä¾èµ–ï¼Œå¹¶åœ¨ `requirements/common.txt` ç»´æŒä¸€è‡´ã€‚  
- æ–°å¢å¤§é‡ `@instrument`ã€`@instrument_manual` è£…é¥°å™¨ä»¥åŠåœ¨æ¨¡å‹åŠ è½½ã€ç¼–è¯‘ã€æ¨ç†ã€è¿›ç¨‹å¯åŠ¨ç­‰å…³é”®è·¯å¾„ä¸ŠåŸ‹ç‚¹ï¼Œæ•è·åŒæ­¥/å¼‚æ­¥å‡½æ•°æ‰§è¡Œã€å±‚çº§å…³ç³»ã€ä¸Šä¸‹æ–‡ä¼ æ’­ã€‚  
- å®ç°å­è¿›ç¨‹/worker è‡ªåŠ¨ç»§æ‰¿ OTEL ç¯å¢ƒçš„ `maybe_init_worker_tracer`ï¼Œä»¥åŠ `propagate_trace_to_env` ç¯å¢ƒå˜é‡æ³¨å…¥ã€‚  
- é‡æ„åŸæœ‰ `vllm.tracing`ï¼ˆå·²åˆ é™¤ï¼‰ä¸ºåç«¯å¯æ’æ‹”è®¾è®¡ï¼Œæä¾›ç»Ÿä¸€çš„ `init_tracer`ã€`instrument`ã€`instrument_manual`ã€`is_tracing_available` ç­‰ APIã€‚  
- æ–°å¢å®Œæ•´çš„å•å…ƒæµ‹è¯•ï¼Œæ¨¡æ‹Ÿ OTEL æœåŠ¡å™¨ï¼Œæ ¡éªŒåŒæ­¥/å¼‚æ­¥ã€åµŒå¥—ã€è·¨è¿›ç¨‹ä¸Šä¸‹æ–‡ä¼ æ’­ç­‰è¡Œä¸ºã€‚  

**ğŸ¯ å½±å“èŒƒå›´**  
- `vllm.tracing`ï¼ˆæ–°æ¨¡å—ï¼‰  
- `vllm/v1/engine/*`ï¼ˆåŠ è½½ã€è°ƒåº¦ã€è¾“å‡ºå¤„ç†ï¼‰  
- `vllm/v1/worker/*`ï¼ˆæ¨¡å‹åŠ è½½ã€warmâ€‘upã€KVâ€‘cache åˆ†é…ï¼‰  
- `vllm/v1/executor/*`ï¼ˆExecutor åˆå§‹åŒ–ï¼‰  
- `vllm/compilation/backends.py`ï¼ˆç¼–è¯‘è¿‡ç¨‹ï¼‰  
- `vllm/entrypoints/openai/api_server.py`ï¼ˆAPI æœåŠ¡åˆå§‹åŒ–ï¼‰  
- `vllm/config/observability.py`ï¼ˆé…ç½®æ ¡éªŒï¼‰  
- æµ‹è¯•ç›®å½• `tests/tracing/*`ã€`tests/v1/tracing/*`  
- é¡¹ç›®æ„å»ºè„šæœ¬ `setup.py`ã€`requirements/common.txt`  

---

**ğŸ” æŠ€æœ¯æ´å¯Ÿ**

| ç»´åº¦ | å½±å“åˆ†æ |
|------|----------|
| **æ¶æ„å½±å“** | 1. **åç«¯å¯æ’æ‹”**ï¼š`vllm.tracing.__init__` é€šè¿‡æ³¨å†Œè¡¨æŠ½è±¡å‡º â€œotelâ€ åç«¯ï¼Œåç»­å¯åŠ å…¥ Jaegerã€Zipkin ç­‰å®ç°ï¼Œè€Œä¸æ”¹åŠ¨ä¸šåŠ¡ä»£ç ã€‚<br>2. **è·¨è¿›ç¨‹é“¾è·¯**ï¼š`maybe_init_worker_tracer` ä¸ `propagate_trace_to_env` è®©å­è¿›ç¨‹ï¼ˆEngineCoreã€Workerï¼‰è‡ªåŠ¨è·å–çˆ¶è¿›ç¨‹çš„ OTEL endpoint ä¸ trace contextï¼Œå®ç°ç«¯åˆ°ç«¯çš„åˆ†å¸ƒå¼è¿½è¸ªã€‚<br>3. **æœ€å°ä¾µå…¥**ï¼š`instrument` è£…é¥°å™¨åœ¨ä¸å¯ç”¨æ—¶ç›´æ¥è¿”å›åŸå‡½æ•°ï¼Œä¿æŒåŸæœ‰é€»è¾‘ä¸å—å½±å“ã€‚<br>4. **ç»Ÿä¸€å±æ€§å®šä¹‰**ï¼š`vllm.tracing.utils.SpanAttributes` ç»Ÿä¸€äº† Genâ€‘AI è¯­ä¹‰æ ‡ç­¾ï¼Œé¿å…ä¸åŒæ¨¡å—è‡ªè¡Œç¡¬ç¼–ç ã€‚ |
| **æ€§èƒ½å½±å“** | - **è¿è¡Œæ—¶å¼€é”€**ï¼šè£…é¥°å™¨åœ¨å‡½æ•°å…¥å£/é€€å‡ºä¼šåˆ›å»º OTel Spanï¼›åœ¨é«˜é¢‘ï¼ˆå¦‚ token ç”Ÿæˆå¾ªç¯ï¼‰å¤„ä»…åœ¨ `OutputProcessor.do_tracing` ä¸­åˆ›å»ºä¸€æ¬¡ `llm_request` Spanï¼Œå¼€é”€ä¸ OTel SDK çš„ BatchSpanProcessor åŸºæœ¬æŒå¹³ï¼ˆæ‰¹é‡å‘é€ã€å¼‚æ­¥å¯¼å‡ºï¼‰ï¼Œå¯¹ååå½±å“å¯æ¥å—ã€‚<br>- **æ‰¹å¤„ç†å¯¼å‡º**ï¼šé»˜è®¤ `BatchSpanProcessor` ä¼šåœ¨åå°çº¿ç¨‹ä¸­å‘é€æ•°æ®ï¼Œæ–°å¢çš„ `propagate_trace_to_env` åªåœ¨å‡½æ•°è°ƒç”¨æœŸé—´å†™å…¥/æ¢å¤ç¯å¢ƒå˜é‡ï¼Œæˆæœ¬æä½ã€‚<br>- **å¯é€‰ä¾èµ–**ï¼šOTEL ä»£ç ä»…åœ¨ç”¨æˆ·å®‰è£… `otel` é¢å¤–ä¾èµ–åç”Ÿæ•ˆï¼Œæœªå®‰è£…æ—¶å‡ ä¹æ— è¿è¡Œæ—¶æˆæœ¬ï¼ˆè£…é¥°å™¨æ˜¯ noâ€‘opï¼‰ã€‚ |
| **å®‰å…¨è€ƒè™‘** | - **ä¿¡æ¯æ³„éœ²**ï¼šTrace ID ä¸ Span ID å¯èƒ½è¢«å¤–éƒ¨æœåŠ¡è®°å½•ã€‚é¡¹ç›®å·²å®ç° `contains_trace_headers` ä¸ `log_tracing_disabled_warning`ï¼Œåœ¨æœªå¯ç”¨ tracing æ—¶ä¸ä¼šæ„å¤–æ³„éœ²ä¸Šä¸‹æ–‡ã€‚<br>- **å¼‚å¸¸æ•è·**ï¼š`instrument` é»˜è®¤ `record_exception=True`ï¼Œå¼‚å¸¸ä¿¡æ¯ä¼šéš Span ä¸ŠæŠ¥ï¼Œéœ€åœ¨ç”Ÿäº§ç¯å¢ƒå®¡æ…é…ç½® OTEL collectorï¼ˆè¿‡æ»¤æ•æ„Ÿå¼‚å¸¸ä¿¡æ¯ï¼‰ã€‚ |
| **å¯ç»´æŠ¤æ€§** | - **ç»Ÿä¸€å…¥å£**ï¼šæ‰€æœ‰ tracing ç›¸å…³å®ç°é›†ä¸­åœ¨ `vllm/tracing` åŒ…ï¼Œä»£ç è·¯å¾„æ¸…æ™°ï¼Œåç»­æ·»åŠ æ–°åç«¯æˆ–å±æ€§åªéœ€ä¿®æ”¹è¯¥ç›®å½•ã€‚<br>- **æµ‹è¯•è¦†ç›–**ï¼šæ–°å¢ `tests/tracing` ä¸å¯¹ç°æœ‰ `tests/v1/tracing` è¿›è¡Œé‡æ„ï¼Œè¦†ç›–åŒæ­¥/å¼‚æ­¥ã€åµŒå¥—ã€è·¨è¿›ç¨‹ä¼ æ’­ï¼Œç”¨ä¾‹å®Œæ•´ï¼Œé™ä½å›å½’é£é™©ã€‚<br>- **å‘åå…¼å®¹**ï¼šåŸæœ‰ `vllm.tracing` æ¨¡å—å·²åˆ é™¤ï¼Œæ‰€æœ‰å†…éƒ¨è°ƒç”¨æ”¹ä¸ºæ–° APIï¼›å¯¹å¤–ä¿æŒåŒå `init_tracer`ã€`instrument`ï¼Œå¤–éƒ¨æ’ä»¶æ— éœ€æ”¹åŠ¨ã€‚ |
| **éƒ¨ç½²ä¸é…ç½®** | - **å¯é€‰ä¾èµ–**ï¼šä½¿ç”¨ `pip install vllm[otel]` å³å¯æ¿€æ´»ï¼›æœªå®‰è£…æ—¶ä»£ç è‡ªåŠ¨å›é€€ä¸ºæ— è¿½è¸ªæ¨¡å¼ï¼Œå…¼å®¹ç°æœ‰éƒ¨ç½²ã€‚<br>- **ç¯å¢ƒå˜é‡**ï¼š`OTEL_EXPORTER_OTLP_TRACES_ENDPOINT`ã€`OTEL_EXPORTER_OTLP_TRACES_PROTOCOL` ä¸ `traceparent`/`tracestate` è‡ªåŠ¨æ³¨å…¥åˆ°å­è¿›ç¨‹ã€‚<br>- **é…ç½®æ ¡éªŒ**ï¼š`vllm/config/observability.py` ä¸­æ ¡éªŒå‡½æ•°æ”¹åä¸º `is_tracing_available`ï¼Œå¹¶åœ¨ `otel` ä¸å¯ç”¨æ—¶æŠ›å‡ºæ˜ç¡®é”™è¯¯ï¼Œæå‡ç”¨æˆ·ä½“éªŒã€‚ |
| **å…¼å®¹æ€§** | - **Python ç‰ˆæœ¬**ï¼šä¾èµ–çš„ OTEL SDK æ”¯æŒ Pythonâ‰¥3.8ï¼Œé¡¹ç›®æœ¬èº«å·²åœ¨æ­¤èŒƒå›´ï¼Œæœªå¼•å…¥é¢å¤–é™åˆ¶ã€‚<br>- **å¹³å°**ï¼šæ‰€æœ‰æ–°å¢å¯¼å…¥å‡ä½äº `vllm.tracing`ï¼Œå¯¹ GPU/CPUã€Rayã€Ray Serve ç­‰å¤šç§è¿è¡Œæ—¶ä¿æŒå…¼å®¹ã€‚ |

---

**âš ï¸ æ½œåœ¨é£é™©**

1. **æ‰¹é‡å¯¼å‡ºå»¶è¿Ÿ**ï¼šå¦‚æœ OTEL collector ä¸å¯è¾¾æˆ–ç½‘ç»œå¼‚å¸¸ï¼Œ`BatchSpanProcessor` ä¼šé‡è¯•å¹¶å¯èƒ½åœ¨åå°ç§¯å‹å¤§é‡ Spanï¼Œå¯¼è‡´å†…å­˜å¢é•¿ã€‚å»ºè®®åœ¨ç”Ÿäº§ç¯å¢ƒé…ç½®åˆç†çš„ `OTEL_EXPORTER_OTLP_TRACES_TIMEOUT` ä¸ `OTEL_BSP_MAX_QUEUE_SIZE`ã€‚  
2. **è·¨è¿›ç¨‹ç¯å¢ƒå˜é‡å†²çª**ï¼š`propagate_trace_to_env` åœ¨å‡½æ•°è¿”å›åæ¢å¤åŸå§‹å€¼ï¼Œä½†åœ¨å¼‚å¸¸è·¯å¾„æˆ–å¤šçº¿ç¨‹å¹¶å‘ç¯å¢ƒä¸‹å¯èƒ½å‡ºç°çŸ­æš‚çš„ç«äº‰ã€‚å½“å‰å®ç°ä½¿ç”¨çº¿ç¨‹å®‰å…¨çš„ `Event` ä¸ `Lock`ï¼Œé£é™©å·²æ§åˆ¶ï¼Œä»å»ºè®®åœ¨é«˜å¹¶å‘éƒ¨ç½²ä¸­åšå‹æµ‹ã€‚  
3. **å¼‚å¸¸ä¿¡æ¯æ³„éœ²**ï¼šå¼€å¯ tracing åï¼Œå¼‚å¸¸æ ˆä¼šéš Span ä¸ŠæŠ¥ã€‚è‹¥ä¸šåŠ¡åŒ…å«æ•æ„Ÿæ•°æ®ï¼ˆå¦‚ç”¨æˆ· promptï¼‰ï¼Œå¯èƒ½è¢«å†™å…¥ OTEL collectorã€‚å¯ä»¥é€šè¿‡ `Span.set_attribute` å‰è‡ªè¡Œè¿‡æ»¤æˆ–åœ¨ collector ä¾§é…ç½®è„±æ•è§„åˆ™ã€‚  
4. **ä¾èµ–å†²çª**ï¼š`opentelemetry-semantic-conventions-ai` ä¸æŸäº›æ—§ç‰ˆ OTEL å‘è¡Œç‰ˆå¯èƒ½å‡ºç°ç‰ˆæœ¬ä¸å…¼å®¹ã€‚ä½¿ç”¨ `pip install vllm[otel]` ä¼šæ‹‰å–é€‚é…çš„ç‰ˆæœ¬ï¼Œä½†åœ¨å·²æœ‰å…¨å±€ä¾èµ–ç¯å¢ƒä¸­ä»éœ€æ³¨æ„ã€‚  
5. **æµ‹è¯•ç¯å¢ƒçš„å”¯ä¸€ç«¯å£**ï¼š`FAKE_TRACE_SERVER_ADDRESS = "localhost:4317"` åœ¨ CI å¹¶è¡Œè¿è¡Œæ—¶å¯èƒ½ç«¯å£å†²çªã€‚å½“å‰æµ‹è¯•æœªä½¿ç”¨åŠ¨æ€ç«¯å£ï¼Œè‹¥ CI å¹¶è¡Œåº¦æå‡ï¼Œéœ€è¦æ”¹ä¸ºéšæœºç«¯å£æˆ–ä½¿ç”¨ `pytest-xdist` çš„ `--reuse-db` æœºåˆ¶ã€‚  

---

**ğŸ’¡ å…³æ³¨å»ºè®®**

| å¯¹è±¡ | å»ºè®® |
|------|------|
| **å¼€å‘è€…** | - åœ¨æ–°åŠŸèƒ½å®ç°å‰ä½¿ç”¨ `@instrument` åŒ…è£…ï¼Œç¡®ä¿å‡½æ•°ç­¾åä¸å˜ï¼›å¦‚æœä¸éœ€è¦å¼‚å¸¸æ•è·ï¼Œå¯æ˜¾å¼ `record_exception=False`ã€‚<br>- è‹¥éœ€è¦è‡ªå®šä¹‰å±æ€§ï¼Œç›´æ¥åœ¨ `instrument` å‚æ•° `attributes` ä¸­ä¼ é€’å­—å…¸ï¼Œæˆ–åœ¨æ‰‹åŠ¨ span ä¸­ä½¿ç”¨ `instrument_manual`ã€‚ |
| **è¿ç»´/å¹³å°** | - éƒ¨ç½²æ—¶æ˜¾å¼å®‰è£… `vllm[otel]` å¹¶é…ç½® `OTEL_EXPORTER_OTLP_TRACES_ENDPOINT`ï¼ˆå¦‚ `http://otel-collector:4317`ï¼‰ã€‚<br>- ç›‘æ§ `BatchSpanProcessor` é˜Ÿåˆ—é•¿åº¦ï¼ˆ`OTEL_BSP_EXPORT_TIMEOUT`ï¼‰é˜²æ­¢å†…å­˜æ³„æ¼ã€‚<br>- åœ¨å¤šç§Ÿæˆ·ç¯å¢ƒä¸­ï¼Œç¡®ä¿ OTEL collector å¯¹ä¸åŒç§Ÿæˆ·çš„ trace ID åšéš”ç¦»ã€‚ |
| **å®‰å…¨å®¡è®¡** | - å®¡æ ¸ OTEL collector

---

### [Bugfix] Make MM batching more robust (#33817)
**SHA**: `116880a` | ğŸ”— [æŸ¥çœ‹æäº¤](https://github.com/vllm-project/vllm/commit/116880a5a0af3a226e29f4716c484a4cc8422fc1)

**ğŸ¯ å˜æ›´ç±»å‹**ï¼šBugä¿®å¤ / æ€§èƒ½ä¼˜åŒ– / é‡æ„  
**âš¡ é‡è¦ç¨‹åº¦**ï¼šğŸ”´ é«˜  

**ğŸ“‹ å˜æ›´æ‘˜è¦**  
1. é€šè¿‡æ–°å¢ `group_and_batch_mm_items`ã€`_batch_mm_items` ä»¥åŠå“ˆå¸Œåˆ†ç»„é€»è¾‘ï¼Œä½¿å¤šæ¨¡æ€ï¼ˆMMï¼‰è¾“å…¥çš„æ‰¹å¤„ç†èƒ½å¤Ÿåœ¨ **å­—æ®µä¸€è‡´æ€§** ä¸ **å…±äº«å­—æ®µï¼ˆSharedFieldï¼‰å€¼ç›¸åŒ** çš„å‰æä¸‹è‡ªåŠ¨åˆå¹¶ï¼Œè§£å†³æ­¤å‰åœ¨æ··åˆè¯·æ±‚ï¼ˆä¸åŒæ¨¡æ€æˆ–ä¸åŒå…±äº«æ•°æ®ï¼‰ä¸‹å‡ºç°çš„ batch ç»´åº¦ä¸åŒ¹é…ã€å†…å­˜æ³„æ¼æˆ–è¿›ç¨‹å¡æ­»ç­‰é—®é¢˜ã€‚  
2. ä¿®æ­£ `Step3VLImagePixelInputs` ä¸­ `patch_pixel_values` çš„å¯ç©ºå±æ€§ã€ç»Ÿä¸€ `ImageWithPatches` ç±»å‹ç­¾åã€ç®€åŒ– `replace_placeholder` é”™è¯¯ä¿¡æ¯ã€ä¼˜åŒ– `__call__` ä¸­å¼ é‡æ‹¼æ¥è·¯å¾„ä»¥åŠ `patch_newline_mask` å¤„ç†ï¼›å¹¶ç¡®ä¿åœ¨æ²¡æœ‰ patch æ—¶è¿”å›ç©ºå¼ é‡ä»¥ä¿æŒç»Ÿä¸€å½¢çŠ¶ã€‚  
3. æ›´æ–° Terratorch é€‚é…å™¨ï¼šåŒºåˆ† **æœªå¤„ç†** ä¸ **å·²å¤„ç†** çš„ `MultiModalFieldConfig`ï¼ˆshared vs batchedï¼‰ï¼Œæ”¹å†™æƒé‡åŠ è½½ä¸å‰å‘è°ƒç”¨ï¼Œä½¿å…¶ç›´æ¥è¿”å›æ¨¡å‹è¾“å‡ºè€Œä¸å†å¼ºåˆ¶ expand ç»´åº¦ã€‚  
4. `MultimodalHasher`ï¼šå¯¹ `hash_kwargs` æŒ‰é”®æ’åºï¼Œç»Ÿä¸€ `np.ndarray` çš„åºåˆ—åŒ–å®ç°ï¼Œæå‡å“ˆå¸Œä¸€è‡´æ€§å¹¶é¿å… 0â€‘ç»´æ•°ç»„é”™è¯¯ã€‚  
5. `MultiModalKwargsItems.get_data` é‡æ„ä¸ºä½¿ç”¨ `group_and_batch_mm_items`ï¼Œå»é™¤æ‰‹åŠ¨ `defaultdict` åˆå¹¶é€»è¾‘ï¼Œæå‡å¯ç»´æŠ¤æ€§å¹¶åœ¨æ‰¹æ¬¡ä¸å”¯ä¸€æ—¶æŠ¥é”™ã€‚  
6. æµ‹è¯•å±‚é¢ï¼šæ–°å¢å¯¹ Terratorchã€åª’ä½“è¿æ¥å™¨ã€å“ˆå¸Œä¸å˜æ€§ç­‰çš„å•å…ƒæµ‹è¯•ï¼Œå¹¶ä¸º `test_terratorch.py` å¢åŠ è¿›ç¨‹éš”ç¦»è£…é¥°å™¨ï¼Œé˜²æ­¢è·¨æµ‹è¯•å…±äº«å†…å­˜å¯¼è‡´æ³„æ¼ã€‚  

**ğŸ¯ å½±å“èŒƒå›´**  
- `vllm/multimodal/*`ï¼ˆ`inputs.py`, `utils.py`, `hasher.py`, `media.py`ï¼‰  
- `vllm/model_executor/models/step3_vl.py`ã€`terratorch.py`ï¼ˆæ¨¡å‹è¾“å…¥/å‰å‘è·¯å¾„ï¼‰  
- CI é…ç½®æ–‡ä»¶ `.buildkite/*.yaml`ï¼ˆæµ‹è¯•å…¥å£ï¼‰  
- æ–°å¢/ä¿®æ”¹çš„æµ‹è¯•æ–‡ä»¶ï¼ˆ`tests/multimodal/*`, `tests/models/test_terratorch.py`ï¼‰  

**ğŸ” æŠ€æœ¯æ´å¯Ÿ**  

| ç»´åº¦ | å½±å“åˆ†æ |
|------|----------|
| **æ¶æ„å½±å“** | 1ï¸âƒ£ å¼•å…¥ **åˆ†å±‚æ‰¹å¤„ç†å·¥å…·**ï¼ˆ`group_and_batch_mm_items`ï¼‰ä½¿ multimodal data flow æ›´æ¨¡å—åŒ–ï¼Œè§£è€¦äº† **åˆ†ç»„ã€å“ˆå¸Œã€æ‰¹å¤„ç†** ä¸‰ä¸ªèŒè´£ã€‚<br>2ï¸âƒ£ `MultiModalKwargsItems.get_data` ç°åœ¨åªè´Ÿè´£è°ƒç”¨ç»Ÿä¸€æ‰¹å¤„ç†å‡½æ•°ï¼Œé¿å…åœ¨å¤šä¸ªä½ç½®å‡ºç°é‡å¤å®ç°ã€‚<br>3ï¸âƒ£ Terratorch é€‚é…å™¨çš„ `is_shared` å‚æ•°æ˜ç¡®äº† â€œåŸå§‹æœªå¤„ç†â€ ä¸ â€œå¤„ç†åå¯æ‰¹â€ ä¸¤ç§è·¯å¾„ï¼Œæå‡äº†æ¨¡å‹å±‚å¯¹ multimodal è¾“å…¥çš„å¯ç»„åˆæ€§ã€‚ |
| **æ€§èƒ½å½±å“** | - **æ‰¹æ¬¡åˆå¹¶**ï¼šåŒä¸€ batch ä¸­å¯åˆå¹¶çš„è¯·æ±‚è¢«èšåˆåˆ°ä¸€èµ·ï¼Œå‡å°‘äº† **ä¸å¿…è¦çš„ split/concat** æ“ä½œå’Œæ˜¾å­˜ç¢ç‰‡åŒ–ã€‚<br>- **å“ˆå¸Œåˆ†ç»„**ï¼šä½¿ç”¨ `MultiModalHasher.hash_kwargs`ï¼ˆé”®æ’åº + é«˜æ•ˆ ndarray åºåˆ—åŒ–ï¼‰åœ¨ç»„å»ºæ‰¹æ¬¡æ—¶ä»…è®¡ç®—ä¸€æ¬¡ hashï¼Œå¼€é”€å¾®ä¹å…¶å¾®ã€‚<br>- **ç©º patch å¤„ç†**ï¼šåœ¨ `Step3VLImagePixelInputs` ä¸­ç›´æ¥è¿”å›å½¢çŠ¶ä¸º `(0, 3, patch, patch)` çš„å¼ é‡ï¼Œé¿å… `None` æ£€æŸ¥å¯¼è‡´çš„ Python åˆ†æ”¯å¼€é”€ã€‚ |
| **å®‰å…¨è€ƒè™‘** | - æ–°å¢å¯¹ **æœ¬åœ°æ–‡ä»¶è·¯å¾„** çš„å®‰å…¨æ ¡éªŒï¼ˆ`must be a subpath`ï¼‰å·²ä¿ç•™ï¼Œæœªå—æœ¬æ¬¡æ”¹åŠ¨å½±å“ã€‚<br>- `MultiModalHasher` ç°åœ¨å¯¹ä¸æ”¯æŒçš„å¯¹è±¡å›é€€åˆ° pickleï¼Œä»ç„¶ä¼šäº§ç”Ÿæ½œåœ¨çš„ **ä»£ç æ‰§è¡Œé£é™©**ï¼›ä½†æ­¤è¡Œä¸ºä¿æŒä¸å˜ï¼Œä»…åœ¨æ—¥å¿—ä¸­è®°å½•è­¦å‘Šã€‚<br>- `group_and_batch_mm_items` ä½¿ç”¨ **å‡½æ•°å¼ä¸å¯å˜** çš„ `tuple` ä½œä¸ºåˆ†ç»„é”®ï¼Œé˜²æ­¢æ„å¤–ä¿®æ”¹å¯¼è‡´å®‰å…¨æˆ–ä¸€è‡´æ€§é—®é¢˜ã€‚ |
| **å¯ç»´æŠ¤æ€§** | - ä»£ç è·¯å¾„é›†ä¸­åœ¨ `multimodal/utils.py`ï¼Œä»¥åæ–°å¢åˆ†ç»„ç­–ç•¥åªéœ€åœ¨è¯¥æ–‡ä»¶å®ç°å³å¯ã€‚<br>- æ›´ç»†ç²’åº¦çš„å¼‚å¸¸ä¿¡æ¯ï¼ˆä¾‹å¦‚ â€œSome modalities cannot be merged into a single batchâ€ï¼‰å¸®åŠ©å®šä½é”™è¯¯æ¥æºã€‚<br>- æµ‹è¯•è¦†ç›–ç‡æå‡ï¼šæ–°å¢ `test_hasher`ã€`test_inputs`ã€`test_connector`ï¼Œå¹¶åœ¨ `test_terratorch` ä¸­ä½¿ç”¨è¿›ç¨‹éš”ç¦»ï¼Œé˜²æ­¢å†…å­˜æ³„æ¼å¯¼è‡´çš„ flaky testsã€‚ |
| **å…¼å®¹æ€§** | - å¯¹å¤– API (`MultiModalKwargsItems.get_data`) **è¡Œä¸ºä¿æŒä¸å˜**ï¼ˆè¿”å› `BatchedTensorInputs`ï¼‰ï¼Œä»…å†…éƒ¨å®ç°æ”¹å˜ï¼›å› æ­¤ç°æœ‰ç”¨æˆ·ä»£ç æ— éœ€è¿ç§»ã€‚<br>- `Step3VLImagePixelInputs.patch_pixel_values` ä»å¯ç©ºæ”¹ä¸ºå¿…å¡«ï¼ˆä½†ä»æ¥å—ç©ºå¼ é‡ï¼‰ï¼Œå…¼å®¹æ—§ä»£ç å› ä¸º `__call__` ä¸­å·²ä¿è¯åœ¨æ—  patch åœºæ™¯è¿”å›ç©ºå¼ é‡ã€‚ |
| **é£é™©ç‚¹** | 1ï¸âƒ£ **åˆ†ç»„å“ˆå¸Œå†²çª**ï¼šå¦‚æœç”¨æˆ·æä¾›çš„å…±äº«å­—æ®µæ•°æ®åœ¨å“ˆå¸Œä¸Šæ„å¤–å†²çªï¼Œå¯èƒ½å¯¼è‡´ä¸åŒè¯·æ±‚è¢«é”™è¯¯åˆå¹¶ã€‚<br>2ï¸âƒ£ **ç©ºå¼ é‡å½¢çŠ¶ä¸åŒ¹é…**ï¼šåœ¨æç«¯æƒ…å†µä¸‹ï¼ˆpatch size ä¸æ¨¡å‹æœŸæœ›ä¸ä¸€è‡´ï¼‰è¿”å›çš„ç©ºå¼ é‡å¯èƒ½è§¦å‘ downstream shape æ£€æŸ¥é”™è¯¯ã€‚<br>3ï¸âƒ£ **æ—§ç‰ˆæ¨¡å‹ä»æœŸå¾… `patch_pixel_values=None`**ï¼šè‹¥å¤–éƒ¨ä»£ç ç›´æ¥æ£€æŸ¥ `is None`ï¼Œéœ€é€‚é…æ”¹ä¸º `tensor.numel() == 0`ã€‚ |

**âš ï¸ æ½œåœ¨é£é™©**  
1. **å“ˆå¸Œå†²çªè¯¯åˆå¹¶**ï¼š`MultiModalHasher` é‡‡ç”¨ `SHA256`ï¼ˆé»˜è®¤ï¼‰ï¼Œå†²çªæ¦‚ç‡æä½ï¼Œä½†ä¸šåŠ¡åœºæ™¯è‹¥è‡ªè¡Œæ”¹ç”¨ä¸å®‰å…¨çš„å“ˆå¸Œå‡½æ•°ï¼ˆé€šè¿‡ç¯å¢ƒå˜é‡ `VLLM_MM_HASHER_ALGORITHM`ï¼‰å¯èƒ½å¯¼è‡´é”™è¯¯åˆ†ç»„ã€‚  
2. **æ˜¾å­˜å³°å€¼å¢é•¿**ï¼šåœ¨æç«¯å¤§é‡æ··åˆè¯·æ±‚çš„åœºæ™¯ï¼Œ`group_and_batch_mm_items` ä¼šæŠŠæ‰€æœ‰å¯åˆå¹¶çš„è¯·æ±‚ä¸€æ¬¡æ€§æ‹¼æ¥ï¼Œå¯èƒ½å¯¼è‡´å•æ¬¡æ˜¾å­˜éœ€æ±‚æ¿€å¢ã€‚å»ºè®®åœ¨é«˜å¹¶å‘éƒ¨ç½²æ—¶ä½¿ç”¨ `max_batch_size` å‚æ•°é™åˆ¶å•æ‰¹è§„æ¨¡ã€‚  
3. **å‘åå…¼å®¹æ€§**ï¼š`Terratorch` çš„ `embed_input_ids` ä¹‹å‰ä¼š `expand` ç»´åº¦ï¼Œç°åœ¨ç›´æ¥è¿”å›æ¨¡å‹è¾“å‡ºï¼›è‹¥å¤–éƒ¨ç”¨æˆ·ä¾èµ–è¯¥ç»´åº¦æ‰©å±•ï¼ˆæ¯”å¦‚æ‰‹åŠ¨æ‹¼æ¥ token åºåˆ—ï¼‰ï¼Œéœ€è¦è‡ªè¡Œå®ç°å¯¹åº”çš„ `expand`ã€‚  

**ğŸ’¡ å…³æ³¨å»ºè®®**  
- **ç›‘æ§æ‰¹æ¬¡å¤§å°**ï¼šåœ¨ç”Ÿäº§ç¯å¢ƒå¼€å¯æ˜¾å­˜ä½¿ç”¨ç›‘æ§ï¼Œå¿…è¦æ—¶å¯¹ `group_and_batch_mm_items` åŠ å…¥ `max_group_size` å‚æ•°æˆ–åœ¨ `vllm` é…ç½®ä¸­é™åˆ¶ `served_batch_size`ã€‚  
- **å“ˆå¸Œç®—æ³•ç®¡ç†**ï¼šé™¤éæœ‰ç‰¹æ®Šéœ€æ±‚ï¼Œä¿æŒé»˜è®¤ `sha256`ï¼›å¦‚éœ€è‡ªå®šä¹‰ï¼ŒåŠ¡å¿…è¯„ä¼°å†²çªæ¦‚ç‡ã€‚  
- **ä»£ç å®¡æŸ¥**ï¼šåœ¨æ–°å¢ multimodal æ¨¡å‹é€‚é…å™¨æ—¶ï¼Œéµå¾ª `is_shared` å‚æ•°çº¦å®šï¼Œç¡®ä¿æœªå¤„ç†çš„æ•°æ®ä½¿ç”¨ `shared` é…ç½®ï¼Œå¤„ç†åä½¿ç”¨ `batched` é…ç½®ã€‚  
- **æµ‹è¯•ç»´æŠ¤**ï¼šCI ä¸­å·²åŠ å…¥ `test_terratorch` è¿›ç¨‹éš”ç¦»ï¼Œè¯·ç¡®ä¿ future tests ä¹Ÿä½¿ç”¨ `create_new_process_for_each_test`ï¼ˆæˆ–ç­‰ä»· fixtureï¼‰æ¥é˜²æ­¢è·¨ test å†…å­˜æ®‹ç•™ã€‚  
- **æ–‡æ¡£æ›´æ–°**ï¼šåœ¨ vLLM å¼€å‘è€…æ–‡æ¡£ä¸­è¡¥å…… â€œMultimodal batching æœºåˆ¶â€ ç« èŠ‚ï¼Œè¯´æ˜åˆ†ç»„è§„åˆ™ã€å…±äº«å­—æ®µçš„ä½œç”¨ä»¥åŠå¦‚ä½•è°ƒä¼˜ `max_batch_size`ã€‚  

---  

**ç»“è®º**  
æ­¤æ¬¡æäº¤é€šè¿‡ **ç»Ÿä¸€çš„åˆ†ç»„â€‘æ‰¹å¤„ç†æ¡†æ¶** å¤§å¹…æå‡äº†å¤šæ¨¡æ€è¾“å…¥çš„é²æ£’æ€§ï¼Œä¿®å¤äº†å› ä¸åŒè¯·æ±‚æ··åˆå¯¼è‡´çš„ batch ç»´åº¦é”™è¯¯å’Œæ½œåœ¨å†…å­˜æ³„æ¼ï¼ŒåŒæ—¶å¯¹å“ˆå¸Œã€æ¨¡å‹æ¥å£ä»¥åŠæµ‹è¯•å¥—ä»¶è¿›è¡Œäº†ä¸€ç³»åˆ—ç»†è‡´çš„æ”¹è¿›ã€‚æ•´ä½“é£é™©å¯æ§ï¼Œå»ºè®®å°½å¿«åˆå¹¶åˆ°ä¸»çº¿å¹¶åœ¨ç”Ÿäº§ç¯å¢ƒæ‰“å¼€æ˜¾å­˜/æ‰¹æ¬¡ç›‘æ§ï¼Œä»¥éªŒè¯åœ¨å¤§è§„æ¨¡å¤šæ¨¡æ€æ¨ç†åœºæ™¯ä¸‹çš„å®é™…è¡¨ç°ã€‚

---

### [Spec Decode] Unified Parallel Drafting (#32887)
**SHA**: `af3162d` | ğŸ”— [æŸ¥çœ‹æäº¤](https://github.com/vllm-project/vllm/commit/af3162d3aaa559a738396baf5b5134c1ab0742f5)

**ğŸ¯ å˜æ›´ç±»å‹**ï¼šåŠŸèƒ½å¢å¼ºï¼ˆåŠ å…¥ **Parallel Drafting** å¹¶ç»Ÿä¸€ Specâ€‘Decode çš„è¾“å…¥å¤„ç†ï¼‰

**âš¡ é‡è¦ç¨‹åº¦**ï¼šğŸ”´ é«˜  
ï¼ˆæ¶‰åŠæ ¸å¿ƒæ¨ç†è·¯å¾„ã€ç¼–è¯‘èŒƒå›´ã€å†…å­˜å¸ƒå±€ï¼Œç›´æ¥å½±å“ååé‡å’Œèµ„æºä½¿ç”¨ï¼‰

**ğŸ“‹ å˜æ›´æ‘˜è¦**  
1. åœ¨ `SpecDecodeBaseProposer` ä¸­æ–°å¢ **parallel_drafting** æ”¯æŒï¼Œç»Ÿä¸€äº† Eagleã€Draftâ€‘Model ä¸å¹¶è¡Œè‰ç¨¿ä¸‰ç§è·¯å¾„çš„è¾“å…¥å‡†å¤‡é€»è¾‘ï¼›å®ç°äº† `copy_and_expand_eagle_inputs_kernel`ï¼Œåœ¨ GPU ä¸Šä¸€æ¬¡æ€§å®Œæˆ tokenã€positionã€maskã€éšè—çŠ¶æ€æ˜ å°„çš„æ‹·è´ä¸æ‰©å±•ã€‚  
2. `SpeculativeConfig` å¢åŠ  `parallel_drafting` å¼€å…³ä»¥åŠå¯¹åº”çš„æ ¡éªŒï¼›`VllmConfig`ã€ç¼–è¯‘èŒƒå›´ã€attention é‡æ’é˜ˆå€¼åŒæ­¥æ›´æ–°ä»¥å®¹çº³ Nï¼ˆ=`num_speculative_tokens`ï¼‰çš„é¢å¤–æ’æ§½ã€‚  
3. Draftâ€‘Model ç›¸å…³ä»£ç è¢«å¤§å¹…é‡æ„ï¼š`create_vllm_config_for_draft_model` ç§»è‡³å…¬å…± utilsï¼Œæ¨¡å‹åŠ è½½æ”¹ä¸ºå¯è¦†ç›–çš„ `_get_model`ï¼Œå¹¶æ˜¾å¼æ”¾å¼ƒåµŒå…¥/LMâ€‘head å…±äº«çš„å‡è®¾ã€‚  
4. å¤šå¤„è°ƒç”¨å±‚ï¼ˆexamplesã€testsã€workerã€gpu_model_runnerï¼‰ä» `last_token_indices` å‚æ•°è¿ç§»åˆ° `token_indices_to_sample`ï¼Œä»¥å…¼å®¹å¹¶è¡Œè‰ç¨¿ã€‚  
5. æ–°å¢å¤§é‡å•å…ƒæµ‹è¯•è¦†ç›–é»˜è®¤ã€draftâ€‘modelã€å¹¶è¡Œè‰ç¨¿ä¸‰ç§æ¨¡å¼ï¼ŒéªŒè¯ slotâ€‘mappingã€maskã€positionã€hiddenâ€‘state ä»¥åŠé‡‡æ ·ç´¢å¼•çš„æ­£ç¡®æ€§ã€‚  

**ğŸ¯ å½±å“èŒƒå›´**  
- `vllm/v1/spec_decode/*`ï¼ˆeagleã€utilsã€draft_modelï¼‰  
- `vllm/config/speculative.py`ã€`vllm/config/vllm.py`  
- `vllm/v1/attention/*`ï¼ˆbackend é‡æ’é˜ˆå€¼ã€FlashInfer cudagraph æ”¯æŒï¼‰  
- `vllm/model_executor/models/llama_eagle3.py`ï¼ˆparallel drafting å‚æ•°ã€mask_hidden åŠ è½½ï¼‰  
- `vllm/v1/worker/gpu_model_runner.py`ã€`vllm/v1/worker/gpu_input_batch.py`  
- ç¤ºä¾‹è„šæœ¬ `examples/offline_inference/spec_decode.py`  
- æµ‹è¯•å¥—ä»¶ `tests/v1/spec_decode/*`  

**ğŸ” æŠ€æœ¯æ´å¯Ÿ**  

| ç»´åº¦ | å½±å“åˆ†æ |
|------|----------|
| **æ¶æ„å½±å“** | - å¼•å…¥ **parallel_drafting** ä½œä¸ºé€’å¢çš„ Specâ€‘Decode æ¨¡å¼ï¼Œä½¿ Draftâ€‘Model ä¸ Eagle åœ¨åŒä¸€æŠ½è±¡åŸºç±» `SpecDecodeBaseProposer` ä¸‹å¤ç”¨ä»£ç ã€‚<br>- æ–°å¢ `extra_slots_per_request` ä¸ `net_num_new_slots_per_request` è®¡ç®—ï¼Œç»Ÿä¸€äº† â€œæ˜¯å¦éœ€è¦é¢å¤–è¾“å…¥æ§½â€ çš„åˆ¤å®šã€‚<br>- `CommonAttentionMetadata` çš„æ‰©å±•ç”± `extend_all_queries_by_N` å–ä»£åŸæœ‰ `extend_all_queries_by_1`ï¼Œæ”¯æŒä¸€æ¬¡æ€§æ‰©å±• Nï¼ˆ=`num_speculative_tokens`ï¼‰ä¸ª tokenï¼Œé™ä½äº†å¤šæ¬¡å…ƒæ•°æ®æ‹·è´çš„å¼€é”€ã€‚ |
| **æ€§èƒ½å½±å“** | - **ååé‡æå‡**ï¼šå¹¶è¡Œè‰ç¨¿ä¸€æ¬¡æ€§ç”Ÿæˆ `num_speculative_tokens` ä¸ªå€™é€‰ tokenï¼Œå‡å°‘äº† CPUâ€‘GPU åŒæ­¥æ¬¡æ•°å’Œè°ƒåº¦å¼€é”€ã€‚<br>- **å†…å­˜å ç”¨**ï¼šæ¯ä¸ªè¯·æ±‚ä¼šé¢å¤–é¢„ç•™ `num_speculative_tokens`ï¼ˆæˆ– 1ï¼‰ä¸ª padding/parallelâ€‘draft slotï¼Œå¯¼è‡´ `max_num_batched_tokens` ä¸Šé™éœ€ä¹˜ä»¥ `num_speculative_tokens`ï¼ˆè§ `VllmConfig._set_compile_ranges`ï¼‰ï¼Œåœ¨å¤§ batch æˆ–å¤§ `num_speculative_tokens` æ—¶å¯èƒ½è§¦å‘ OOMã€‚<br>- **GPU kernel**ï¼š`copy_and_expand_eagle_inputs_kernel` åœ¨ `BLOCK_SIZE_TOKENS`ï¼ˆæœ€é«˜ 256ï¼‰ä¸Šå¹¶è¡Œæ‹·è´ä¸å¡«å……ï¼Œé¿å…äº†å¤šæ¬¡ Hostâ€‘Device åŒæ­¥ï¼Œç†è®ºä¸Šæ¯”åŸå…ˆçš„ triton `merge_toks_kernel` + Python è®¡ç®—æ›´å¿«ã€‚<br>- **CUDAGraph**ï¼š`set_inputs_first_pass` ä»ä¿ç•™å¯¹ `self.input_ids`ã€`self.positions`ã€`self.hidden_states` çš„åŸä½å†™å…¥ï¼Œä¿æŒåŸæœ‰ cudagraph æ•è·è·¯å¾„ä¸å˜ã€‚ |
| **å®‰å…¨è€ƒè™‘** | - æ–°å¢é…ç½®é¡¹ `parallel_drafting` åªåœ¨ä»£ç è·¯å¾„ä¸­æ£€æŸ¥å…¼å®¹æ€§ï¼ˆä»… `eagle`ã€`draft_model`ã€`eagle3` å¯ç”¨ï¼‰ï¼Œæœªå‘å¤–éƒ¨æš´éœ²æœªç»éªŒè¯çš„æ¨¡å‹æƒé‡åŠ è½½è·¯å¾„ã€‚<br>- `parallel_drafting_token_id` å¿…é¡»åœ¨æ¨¡å‹çš„ `config.json` ä¸­å£°æ˜ï¼ˆ`pard_token` æˆ– `ptd_token_id`ï¼‰ï¼ŒåŠ è½½å‰ä¼šæŠ›å‡ºæ˜ç¡®é”™è¯¯ï¼Œé¿å…ä½¿ç”¨æœªå®šä¹‰çš„ token å¯¼è‡´éæ³•å†…å­˜è®¿é—®ã€‚<br>- ä»ç„¶ä¾èµ–åŸæœ‰çš„ `VllmConfig.validate`ï¼Œæœªå¼•å…¥æ–°çš„å¤–éƒ¨è¾“å…¥ã€‚ |
| **å¯ç»´æŠ¤æ€§** | - å°† draftâ€‘model é…ç½®ç”ŸæˆæŠ½è±¡ä¸º `create_vllm_config_for_draft_model`ï¼Œé™ä½äº†ä¸åŒæ¨¡å—é—´çš„é‡å¤å®ç°ã€‚<br>- æ–°å¢ `extend_all_queries_by_N` ä¸ç»Ÿä¸€çš„ `copy_and_expand_eagle_inputs_kernel`ï¼ŒæŠŠåŸæ¥æ•£è½åœ¨å¤šä¸ªç±»çš„ â€œæ‰©å±• query é•¿åº¦â€ é€»è¾‘é›†ä¸­ï¼Œåç»­è‹¥è¦æ”¹åŠ¨ slotâ€‘mappingï¼Œåªéœ€ä¿®æ”¹å•ä¸€å‡½æ•°ã€‚<br>- ä»£ç ä¸­å¤§é‡ä½¿ç”¨ `self.parallel_drafting`ã€`self.needs_extra_input_slots` å¸ƒå°”åˆ†æ”¯ï¼Œä¿æŒäº†å¯¹æ—§è·¯å¾„çš„å…¼å®¹ï¼Œé™ä½äº†å›å½’é£é™©ã€‚ |
| **å…¼å®¹æ€§** | - é»˜è®¤ `parallel_drafting=False`ï¼Œæ‰€ä»¥åŸæœ‰è¡Œä¸ºä¿æŒä¸å˜ã€‚<br>- `SpeculativeConfig` æ–°å­—æ®µåœ¨ `VllmConfig` çš„ `__post_init__` ä¸­åŠ å…¥æ£€æŸ¥ï¼Œåªåœ¨ `method` ä¸º `draft_model`æˆ– `eagle*` æ—¶å…è®¸å¼€å¯ï¼›å…¶å®ƒæ–¹æ³•ä»ä¼šåœ¨åˆå§‹åŒ–æ—¶æŠ¥é”™ã€‚<br>- éƒ¨åˆ†æ—§ APIï¼ˆ`last_token_indices`ï¼‰å·²åœ¨å†…éƒ¨ç»Ÿä¸€æ”¹ä¸º `token_indices_to_sample`ï¼Œä½†ä»æä¾›å‘åå…¼å®¹çš„ wrapperï¼ˆå¦‚åœ¨ tests ä¸­å·²å…¨éƒ¨è¿ç§»ï¼‰ã€‚ |

**âš ï¸ æ½œåœ¨é£é™©**  

1. **å†…å­˜æº¢å‡º**ï¼šç¼–è¯‘èŒƒå›´ (`max_num_batched_tokens`) ç°åœ¨ä¹˜ä»¥ `num_speculative_tokens`ï¼Œåœ¨èµ„æºå—é™çš„ GPU ä¸Šå¯èƒ½è§¦å‘ OOMï¼Œå°¤å…¶åœ¨ `parallel_drafting=True` æ—¶æ¯æ¬¡æ‰¹æ¬¡ä¼šé¢å¤–é¢„ç•™ `num_speculative_tokens * batch_size` çš„æ§½ã€‚  
2. **slotâ€‘mapping é”™è¯¯**ï¼š`compute_new_slot_mapping` ä¸ `extend_all_queries_by_N` ä¾èµ– `is_rejected_token_mask`ã€`is_masked_token_mask` æ­£ç¡®å¡«å……ï¼›è‹¥ kernel ä¸­çš„è¾¹ç•Œè®¡ç®—å‡ºç°åå·®ï¼ˆå°¤å…¶åœ¨ `shift_input_ids=False` ä¸ `True` åˆ‡æ¢æ—¶ï¼‰ï¼Œå¯èƒ½å¯¼è‡´ KVâ€‘cache å†™å…¥é”™è¯¯ï¼Œè¿›è€Œäº§ç”Ÿç”Ÿæˆè´¨é‡å¼‚å¸¸æˆ–å´©æºƒã€‚  
3. **å¹¶è¡Œè‰ç¨¿ token ID ä¸åŒ¹é…**ï¼š`parallel_drafting_token_id` å¿…é¡»ä¸æ¨¡å‹çš„è¯è¡¨å¯¹é½ï¼›å¦‚æœä½¿ç”¨çš„è‰ç¨¿æ¨¡å‹æ²¡æœ‰åœ¨ `config.json` ä¸­å£°æ˜ç›¸åº”å­—æ®µï¼ŒåŠ è½½ä¼šåœ¨ `_init_parallel_drafting_params` æŠ›å¼‚å¸¸ã€‚  
4. **ç¼–è¯‘èŒƒå›´æ‰©å±•å¯¼è‡´è°ƒåº¦å¤±æ•ˆ**ï¼š`_set_compile_ranges` å¢å¤§äº† compileâ€‘rangeï¼Œä»…åœ¨ asyncâ€‘scheduling åœºæ™¯ä¸‹ä½¿ç”¨ï¼›è‹¥è°ƒåº¦å™¨ä»åŸºäºæ—§çš„ `max_query_len` è¿›è¡Œåˆ†ç‰‡ï¼Œå¯èƒ½äº§ç”Ÿä¸å‡è¡¡çš„å·¥ä½œè´Ÿè½½ã€‚  
5. **æµ‹è¯•è¦†ç›–ä¸è¶³çš„å¤§ batch åœºæ™¯**ï¼šç›®å‰çš„å•å…ƒæµ‹è¯•ä¸»è¦éªŒè¯äº†å° batchï¼ˆ1â€‘4ï¼‰å’Œå°‘é‡ token

---

### [Feat][RL][1/2] Native Weight Syncing API: NCCL (#31943)
**SHA**: `c1858b7` | ğŸ”— [æŸ¥çœ‹æäº¤](https://github.com/vllm-project/vllm/commit/c1858b7ec8aa571dc0c0e00aded01019cca6a7e6)

**ğŸ¯ å˜æ›´ç±»å‹**ï¼šåŠŸèƒ½å¢å¼º / æ¶æ„å˜æ›´ / æ€§èƒ½ä¼˜åŒ– / å®‰å…¨ä¿®å¤  

**âš¡ é‡è¦ç¨‹åº¦**ï¼šğŸ”´é«˜  

**ğŸ“‹ å˜æ›´æ‘˜è¦**  
æœ¬æ¬¡æäº¤ä¸º vLLM å¼•å…¥äº†åŸç”Ÿ **Weight Syncing API**ï¼ŒåŸºäº NCCL å®ç°è®­ç»ƒä¾§ä¸æ¨ç†ä¾§æ¨¡å‹æƒé‡çš„é«˜æ•ˆåŒæ­¥ã€‚æ ¸å¿ƒæ”¹åŠ¨åŒ…æ‹¬ï¼š  
1. æ–°å¢ `WeightTransferConfig`ã€æŠ½è±¡åŸºç±»ã€å·¥å‚ä»¥åŠ NCCL å®ç°ï¼›  
2. åœ¨ `LLM`/`AsyncLLMEngine`/`GPUWorker` ä¸­åŠ å…¥å¯¹åº” RPC æ¥å£ `init_weight_transfer_engine` / `update_weights`ï¼›  
3. å®ç° **packed tensor broadcasting**ï¼Œæ˜¾è‘—é™ä½å¤§é‡å°å¼ é‡çš„ NCCL è°ƒç”¨å¼€é”€ï¼›  
4. å®Œå¤‡ç¤ºä¾‹ã€æµ‹è¯•ä»¥åŠ CI æµç¨‹ï¼Œç¡®ä¿åœ¨å¤š GPU ç¯å¢ƒä¸‹å¯ç›´æ¥è·‘é€šã€‚  

**ğŸ¯ å½±å“èŒƒå›´**  
- `vllm/config/*`ï¼ˆæ–°å¢é…ç½®ï¼‰  
- `vllm/engine/*`ï¼ˆåè®®ã€å‚æ•°è§£æã€LLM ç±»ï¼‰  
- `vllm/v1/engine/*`ï¼ˆå¼‚æ­¥å¼•æ“ RPCï¼‰  
- `vllm/v1/worker/gpu_worker.py`ï¼ˆæƒé‡åŒæ­¥å¼•æ“å®ä¾‹åŒ–ã€ç”Ÿå‘½å‘¨æœŸç®¡ç†ï¼‰  
- `vllm/distributed/weight_transfer/*`ï¼ˆå…¨æ–°å­æ¨¡å—ï¼‰  
- ç¤ºä¾‹ç›®å½• `examples/offline_inference/new_weight_syncing/`ã€`examples/online_serving/rlhf_http.py`  
- CI é…ç½® `.buildkite/*`ï¼ˆåŠ å…¥æ–°ç¤ºä¾‹çš„æµ‹è¯•ï¼‰  
- æ–°å¢å•å…ƒ/é›†æˆæµ‹è¯• `tests/distributed/test_*`  

---

### ğŸ” æŠ€æœ¯æ´å¯Ÿ  

| ç»´åº¦ | å½±å“è¯´æ˜ |
|------|----------|
| **æ¶æ„å½±å“** | - æ–°å¢ **Weight Transfer** å­ç³»ç»Ÿï¼Œé‡‡ç”¨ **Factory + Registry** æ–¹å¼å®ç°åç«¯å¯æ’æ‹”ï¼›<br>- `GPUWorker` åœ¨å¯åŠ¨æ—¶æƒ°æ€§åˆ›å»º `WeightTransferEngine`ï¼Œä¸ç°æœ‰ `ParallelConfig`ã€`VllmConfig` å®Œç¾è€¦åˆï¼›<br>- é€šè¿‡ `collective_rpc` åœ¨æ‰€æœ‰ worker é—´ç»Ÿä¸€è°ƒåº¦ï¼Œä½¿æƒé‡åŒæ­¥æˆä¸ºä¸€æ¬¡é›†ä½“è°ƒç”¨ï¼Œä¿æŒç°æœ‰ RPC æ¡†æ¶çš„ç»Ÿä¸€æ€§ã€‚ |
| **æ€§èƒ½å½±å“** | - **Packed broadcast**ï¼šæŠŠå¤šä¸ªæƒé‡å¼ é‡æ‰“åŒ…æˆ 1â€¯GBï¼ˆé»˜è®¤ï¼‰çš„å¤§ç¼“å†²åŒºï¼Œåˆ©ç”¨ NCCL å•æ¬¡ `broadcast` ä¼ è¾“ï¼Œé¿å…æ•°ç™¾æ¬¡å° `broadcast` å¸¦æ¥çš„æ˜¾è‘— latency ä¸ kernel launch å¼€é”€ï¼›<br>- åœ¨ `trainer_send_weights` ä¸ `receive_weights` ä¸¤ç«¯å‡æ”¯æŒå¯é€‰ `packed`ï¼Œä¸å½±å“åŸæœ‰å•å¼ é‡è·¯å¾„ï¼›<br>- æ–°å¢ `trainer_init` ä¸ `trainer_send_weights` çš„é™æ€ processâ€‘group åˆ›å»ºï¼Œé¿å…å…¨å±€ `torch.distributed` ç¯å¢ƒæ±¡æŸ“ï¼›<br>- å¯¹ `fp8` é‡åŒ–å±‚åŠ å…¥é˜²é‡å¤æ ‡è®°ï¼Œé˜²æ­¢äºŒæ¬¡åŠ è½½æ—¶å¤šä½™çš„ `process_weights_after_loading` å¯¼è‡´çš„é¢å¤–è®¡ç®—ã€‚ |
| **å®‰å…¨è€ƒè™‘** | - ä¸¤ä¸ªæ–°å¢çš„ HTTP æ¥å£ (`/init_weight_transfer_engine`, `/update_weights`) åªåœ¨ **dev mode** (`VLLM_SERVER_DEV_MODE`) ä¸‹æ³¨å†Œï¼Œé™ä½ç”Ÿäº§ç¯å¢ƒæš´éœ²é£é™©ï¼›<br>- ä»ç„¶ç¼ºå°‘èº«ä»½éªŒè¯/ç­¾åæœºåˆ¶ï¼Œè‹¥è¯¯å¼€å¯ dev mode å¯èƒ½å¯¼è‡´ä»»æ„ç”¨æˆ·æ³¨å…¥æ¶æ„ `init_info` / `update_info`ï¼ˆä¾‹å¦‚å¼‚å¸¸çš„ `master_port`ã€å¼‚å¸¸æ•°æ®å¯¼è‡´ NCCL æ­»é”ï¼‰ã€‚<br>- NCCL æœ¬èº«ä¸æä¾›åŠ å¯†ï¼Œæƒé‡åœ¨èŠ‚ç‚¹é—´ä»¥æ˜æ–‡ä¼ è¾“ï¼Œå‡è®¾é›†ç¾¤åœ¨å—ä¿¡ç½‘ç»œå†…ã€‚ |
| **å¯ç»´æŠ¤æ€§** | - é‡‡ç”¨ **dataclass + config** ç»Ÿä¸€é…ç½®ç»“æ„ï¼Œåç»­è‹¥è¦æ·»åŠ  `gloo`ã€`ibverbs` ç­‰åç«¯ä»…éœ€å®ç°å¯¹åº” `InitInfo/UpdateInfo` å¹¶åœ¨ `factory.register_engine` ä¸­ç™»è®°ï¼›<br>- `packed_tensor` å®ç°æŠ½è±¡ä¸ºä¸¤ä¸ªå‡½æ•°ï¼Œå•å…ƒæµ‹è¯•è¦†ç›–ç‡é«˜ï¼Œæ˜“äºå•ç‹¬è°ƒä¼˜ï¼›<br>- ä»£ç å…¥å£æ˜ç¡®ï¼š`LLM.init_weight_transfer_engine` â†’ `GPUWorker.init_weight_transfer_engine` â†’ `WeightTransferEngine.init_transfer_engine`ã€‚ |
| **å…¼å®¹æ€§** | - åªæœ‰åœ¨ `weight_transfer_config` éç©ºæ—¶æ‰åˆ›å»ºå¼•æ“ï¼Œé»˜è®¤è¡Œä¸ºä¿æŒä¸å˜ï¼›<br>- ç°æœ‰ `vllm serve`ã€`vllm` å‘½ä»¤è¡Œå‚æ•°æ–°å¢ `--weight-transfer-config`ï¼Œå‘åå…¼å®¹ï¼ˆé»˜è®¤ `None`ï¼‰ï¼›<br>- æ—§çš„ RLHF ç¤ºä¾‹ä»å¯ç»§ç»­ä½¿ç”¨ï¼›<br>- å¯¹äºä»…å• GPU ç¯å¢ƒï¼Œä¸ä¼šè§¦å‘ NCCL åˆå§‹åŒ–ï¼Œç›¸å…³ä»£ç å‡åœ¨ `torch.cuda.device_count() < 2` æ¡ä»¶ä¸‹è·³è¿‡æµ‹è¯•ã€‚ |

---

### âš ï¸ æ½œåœ¨é£é™©  

1. **é…ç½®é”™è¯¯å¯¼è‡´ NCCL æ­»é”**  
   - `master_address/port`ã€`world_size`ã€`rank_offset` è‹¥ä¸å®é™…å·¥ä½œè¿›ç¨‹ä¸åŒ¹é…ï¼Œä¼šä½¿ trainer ä¸ inference ä¹‹é—´çš„ NCCL group æ°¸ä¹…é˜»å¡ã€‚  
2. **å†…å­˜å³°å€¼**  
   - `packed_buffer_size_bytes` é»˜è®¤ 1â€¯GBï¼Œåœ¨å¤šç¼“å†²ï¼ˆé»˜è®¤ 2ï¼‰æƒ…å†µä¸‹ä¼šåœ¨æ¯ç«¯é¢å¤–å ç”¨ 2â€¯GB GPU å†…å­˜ï¼›åœ¨æ˜¾å­˜ç´§å¼ çš„æ¨¡å‹ï¼ˆå¦‚ 80â€¯Bï¼‰ä¸Šå¯èƒ½å¯¼è‡´ OOMã€‚  
3. **å¼€å‘æ¨¡å¼è¯¯å¼€å¯**  
   - `VLLM_SERVER_DEV_MODE=1` ç¯å¢ƒå˜é‡è‹¥åœ¨ç”Ÿäº§æœºå™¨ä¸Šæ„å¤–å¼€å¯ï¼Œä¼šæš´éœ²æƒé‡åŒæ­¥çš„ HTTP æ¥å£ï¼Œå¯èƒ½è¢«æ¶æ„åˆ©ç”¨ã€‚  
4. **å¤šèŠ‚ç‚¹ä¸ä¸€è‡´æ€§**  
   - å½“å‰å®ç°å‡è®¾ trainer ä½äº **rank 0**ï¼Œä¸”æ‰€æœ‰ inference workerså…±äº«åŒä¸€ `world_size`ã€‚è·¨èŠ‚ç‚¹æ‰©å±•æ—¶è‹¥æ¯èŠ‚ç‚¹éƒ½å¯åŠ¨ trainerï¼Œéœ€æ‰‹åŠ¨è°ƒæ•´ `rank_offset` ä¸ `world_size`ï¼Œå¦åˆ™å‡ºç°å†²çªã€‚  
5. **åºåˆ—åŒ–/ååºåˆ—åŒ–é™åˆ¶**  
   - `WeightTransferInitRequest` ä¸ `UpdateRequest` ä½¿ç”¨ dict æ–¹å¼ä¼ é€’ï¼›è‹¥ç”¨æˆ·è‡ªè¡Œæ„é€ ä¸ç¬¦åˆ `WeightTransferEngine` çš„å­—æ®µï¼Œä¼šåœ¨ `parse_init_info` / `parse_update_info` 

---

#### ğŸŸ¡ ä¸­é‡è¦åº¦å˜æ›´ (20)

### [XPU][5/N] add wna16 xpu kernel (#33973)
**SHA**: `2ce9fe4` | ğŸ”— [æŸ¥çœ‹æäº¤](https://github.com/vllm-project/vllm/commit/2ce9fe4ad03f5097f4abe4f188166ede8c62df21)

**ğŸ¯ å˜æ›´ç±»å‹**ï¼šåŠŸèƒ½å¢å¼ºï¼ˆæ–°å¢ XPU wNa16 é‡åŒ–ç®—å­ï¼‰  
**âš¡ é‡è¦ç¨‹åº¦**ï¼šğŸŸ¡ ä¸­  
**ğŸ“‹ å˜æ›´æ‘˜è¦**ï¼š  
1. åœ¨ CI è„šæœ¬ä¸­åŠ å…¥å¯¹ `superjob/Qwen3-4B-Instruct-2507-GPTQ-Int4` ç¤ºä¾‹çš„ XPU è¿è¡Œæµ‹è¯•ã€‚  
2. é‡æ„ `vllm/model_executor/layers/quantization/kernels/mixed_precision/xpu.py`ï¼Œå®ç°åŸºäº XPUâ€¯wNa16 çš„çº¿æ€§å±‚ï¼Œä¸å†ä¾èµ– Intelâ€¯Extensionâ€¯forâ€¯PyTorch (IPEX) çš„ weightâ€‘only quantï¼Œå®ç°è‡ªè¡Œè½¬ç½®ã€scale/zeroâ€‘point å¤„ç†ä»¥åŠè°ƒç”¨åº•å±‚ `_xpu_C.int4_gemm_w4a16`ã€‚  

**ğŸ¯ å½±å“èŒƒå›´**ï¼š  
- `vllm/model_executor/layers/quantization/kernels/mixed_precision/xpu.py`ï¼ˆæ ¸å¿ƒé‡åŒ–ç®—å­ï¼‰  
- `.buildkite/scripts/hardware_ci/run-xpu-test.sh`ï¼ˆCI æµ‹è¯•è„šæœ¬ï¼‰  
- å¯èƒ½æ³¢åŠ `vllm/platforms`, `vllm/scalar_type` ç­‰æ¨¡å—çš„å¯¼å…¥è·¯å¾„ã€‚  

**ğŸ’¡ å…³æ³¨å»ºè®®**  

1. **å…¼å®¹æ€§æ£€æŸ¥**ï¼š`can_implement` ç°åœ¨å¯¹æ¿€æ´» dtypeã€æƒé‡é‡åŒ–ç±»å‹ã€groupâ€‘sizeã€è¾“å…¥/è¾“å‡ºç»´åº¦åšäº†ä¸¥æ ¼é™åˆ¶ã€‚å»ºè®®åœ¨æ–‡æ¡£å’Œé”™è¯¯æç¤ºä¸­æ˜ç¡®è¿™äº›å‰ç½®æ¡ä»¶ï¼Œé¿å…ç”¨æˆ·åœ¨ä¸æ»¡è¶³æ¡ä»¶æ—¶é™·å…¥éš¾æ‡‚çš„æŠ¥é”™ã€‚  
2. **Zeroâ€‘point å¤„ç†**ï¼šå¦‚æœæœªæä¾› zeroâ€‘pointï¼Œä»£ç ç¡¬ç¼–ç  `torch.int8` çš„ 8 å¹¶åŒ…è£…ä¸º `Parameter`ï¼Œå¯èƒ½å¯¼è‡´ä¸å·²æœ‰æ¨¡å‹çš„çŠ¶æ€å­—å…¸ä¸åŒ¹é…ã€‚å»ºè®®åœ¨ `state_dict`/`load_state_dict` ä¸­ç»Ÿä¸€å¤„ç†ï¼Œæˆ–æä¾› `zero_point=None` çš„æ˜¾å¼è·¯å¾„ã€‚  
3. **æƒé‡è½¬ç½®**ï¼š`weight_packed.t()` ä¸ `weight_scale.t()` å‡åœ¨ `process_weights_after_loading` ä¸­å®Œæˆã€‚è¯·ç¡®è®¤åœ¨å¤šå¡/åˆ†å¸ƒå¼åœºæ™¯ä¸‹ï¼Œæ­¤æ“ä½œä¸ä¼šäº§ç”Ÿé¢å¤–çš„åŒæ­¥å¼€é”€æˆ–æ˜¾å­˜ç¢ç‰‡ã€‚  
4. **è°ƒç”¨åº•å±‚ç®—å­**ï¼š`torch.ops._xpu_C.int4_gemm_w4a16` å‚æ•°é¡ºåºä¸ä¹‹å‰çš„ IPEX å®ç°ä¸åŒï¼ŒåŠ¡å¿…åœ¨å•å…ƒæµ‹è¯•ä¸­è¦†ç›–ä¸åŒ `group_size`ã€`has_g_idx`ã€`zero_points` çš„ç»„åˆï¼Œé˜²æ­¢å‚æ•°é”™ä½å¯¼è‡´è®¡ç®—é”™è¯¯ã€‚  
5. **CI æ›´æ–°**ï¼šæ–°å¢çš„ç¤ºä¾‹æ¨¡å‹å¯¹ XPU ç¯å¢ƒä¾èµ–è¾ƒé«˜ï¼Œè‹¥ CI ç¯å¢ƒä¸å…·å¤‡ç›¸åŒç¡¬ä»¶æˆ– driver ç‰ˆæœ¬ï¼Œå¯èƒ½å¯¼è‡´ CI å¤±è´¥ã€‚å»ºè®®åœ¨è„šæœ¬ä¸­åŠ å…¥ç¡¬ä»¶æ£€æµ‹æˆ– `skip` æ ‡è®°ï¼Œä»¥ä¿æŒ CI ç¨³å®šæ€§ã€‚  
6. **ä»£ç é£æ ¼**ï¼šç§»é™¤äº†å¯¹ `intel_extension_for_pytorch` çš„å¯¼å…¥ï¼Œä»ä¿ç•™äº† `from packaging import version` çš„æœªä½¿ç”¨ importï¼Œå»ºè®®æ¸…ç†ã€‚  
7. **æ–‡æ¡£åŒæ­¥**ï¼šXPUâ€¯wNa16 çš„æ”¯æŒçŸ©é˜µã€ä½¿ç”¨æ–¹å¼ï¼ˆ`--attention-backend=TRITON_ATTN` ç­‰ï¼‰åº”åœ¨ README / doc ä¸­è¡¥å……ã€‚  

æ€»ä½“æ¥çœ‹ï¼Œæœ¬æ¬¡ PR ä¸º XPU å¹³å°æä¾›äº†é«˜æ•ˆçš„ int4â€‘w4a16 è®¡ç®—è·¯å¾„ï¼Œæå‡äº† vLLM åœ¨ Intel XPU ä¸Šçš„é‡åŒ–æ¨ç†èƒ½åŠ›ã€‚ä½†å› åŠ å…¥äº†ä¸å°‘å½¢çŠ¶å’Œå¹³å°æ ¡éªŒï¼ŒåŠ¡å¿…é€šè¿‡å®Œæ•´çš„å•å…ƒ/é›†æˆæµ‹è¯•éªŒè¯å„ç§é…ç½®çš„å…¼å®¹æ€§ï¼Œå¹¶åœ¨æ–‡æ¡£ä¸­æ˜ç¡®ä½¿ç”¨å‰æã€‚

---

### [Model] Support MiniCPM-o 4.5 (#33431)
**SHA**: `4707f7e` | ğŸ”— [æŸ¥çœ‹æäº¤](https://github.com/vllm-project/vllm/commit/4707f7ebb4f10f42a951875ff35e1959caa17526)

**ğŸ¯ å˜æ›´ç±»å‹**ï¼šåŠŸèƒ½å¢å¼º  
**âš¡ é‡è¦ç¨‹åº¦**ï¼šğŸŸ¡ ä¸­  

**ğŸ“‹ å˜æ›´æ‘˜è¦**  
- åœ¨ `vllm/model_executor/models/minicpmo.py` ä¸­æ–°å¢å¯¹ MiniCPMâ€‘O 4.5ï¼ˆQwen3â€¯backboneï¼‰çš„å®Œæ•´æ”¯æŒã€‚  
- å¼•å…¥ `MiniCPMOBaseModel` ä½œä¸ºéŸ³é¢‘åŠŸèƒ½çš„ mixinï¼Œå¹¶å®ç° `MiniCPMO2_6`ã€`MiniCPMO4_5` ä¸¤ä¸ªå…·ä½“å®ç°ã€‚  
- é€šè¿‡ `__new__` æ ¹æ® HuggingFace é…ç½®çš„ `version` åŠ¨æ€æŒ‘é€‰å¯¹åº”ç±»ï¼Œå®ç°å¤šç‰ˆæœ¬åˆ†å‘ã€‚  
- å°† `audio_pool_step` é»˜è®¤å€¼ä»ç¡¬ç¼–ç  `2` æ”¹ä¸ºè¯»å– HF é…ç½®çš„ `audio_pool_step`ï¼ˆMiniCPMâ€‘Oâ€¯4.5 ä¸º `5`ï¼‰ï¼Œå¹¶å®Œæˆå¤šæ¨¡æ€å¤„ç†å™¨çš„é‡æ–°æ³¨å†Œã€‚

**ğŸ¯ å½±å“èŒƒå›´**  
- `vllm/model_executor/models/minicpmo.py`ï¼ˆæ ¸å¿ƒæ¨¡å‹å®ç°ï¼‰  
- `vllm/model_executor/models/minicpmo.py` ä¸­çš„å¤šæ¨¡æ€æ³¨å†Œ (`MULTIMODAL_REGISTRY`)  
- ä¸éŸ³é¢‘ç›¸å…³çš„ `MiniCPMVMultiModalProcessor`ã€`MiniCPMODummyInputsBuilder`  
- ä»»ä½•ä½¿ç”¨ MiniCPMâ€‘O ç³»åˆ—æ¨¡å‹çš„æ¨ç†å…¥å£ï¼ˆe.g., `vllm.entrypoints`ï¼‰

**ğŸ’¡ å…³æ³¨å»ºè®®**  
- **å¼€å‘è€…**ï¼šç¡®ä¿ `hf_config.version` ä¸ `audio_pool_step` åœ¨æ¨¡å‹ä»“åº“é‡Œæ­£ç¡®å£°æ˜ï¼›æ–°å¢å•å…ƒæµ‹è¯•è¦†ç›– 2.6 ä¸ 4.5 ä¸¤ä¸ªåˆ†æ”¯çš„ `__new__` åˆ†å‘ã€`get_default_audio_pool_step` è¡Œä¸ºä»¥åŠéŸ³é¢‘æ¨¡å—åˆå§‹åŒ–ã€‚  
- **æ€§èƒ½**ï¼š4.5 ç‰ˆçš„ `audio_pool_step=5` ä¼šæ”¹å˜éŸ³é¢‘å¸§çš„ä¸‹é‡‡æ ·ç‡ï¼Œéœ€åœ¨åŸºå‡†æµ‹è¯•ä¸­éªŒè¯å¯¹ååé‡çš„å½±å“ã€‚  
- **å‘åå…¼å®¹**ï¼šé»˜è®¤å›é€€åˆ° 2.6 ç‰ˆæœ¬ï¼Œä¿æŒç°æœ‰ç”¨æˆ·ä¸å—å½±å“ï¼›è‹¥ç”¨æˆ·æä¾›ä¸ç¬¦åˆ `x.y` æ ¼å¼çš„ `version`ï¼Œä¼šæŠ›å‡ºæ˜ç¡®çš„ `ValueError`ã€‚  
- **æ–‡æ¡£**ï¼šæ›´æ–°æ¨¡å‹æ”¯æŒåˆ—è¡¨ä¸é…ç½®ç¤ºä¾‹ï¼Œè¯´æ˜å¦‚ä½•åœ¨ `vllm` é…ç½®æ–‡ä»¶ä¸­æ˜¾å¼æŒ‡å®š `version` ä¸ `audio_pool_step`ã€‚  
- **ç”¨æˆ·**ï¼šä½¿ç”¨ MiniCPMâ€‘Oâ€¯4.5 æ—¶ï¼Œè¯·åœ¨æ¨¡å‹é…ç½®ä¸­åŠ å…¥ `version: "4.5"`ï¼ˆæˆ–å¯¹åº”æ•´æ•°ï¼‰ï¼Œå¹¶æ£€æŸ¥æ—¥å¿—ç¡®è®¤å·²åŠ è½½ `MiniCPMO4_5` ç±»ã€‚è‹¥å‡ºç° â€œUnsupported versionâ€ é”™è¯¯ï¼Œè¯·ç¡®è®¤æ¨¡å‹ä»“åº“å·²åŒæ­¥æœ€æ–°çš„ HF é…ç½®ã€‚

---

### [Docs] Add sections on process architecture and minimum CPU resources (#33940)
**SHA**: `c39ee9e` | ğŸ”— [æŸ¥çœ‹æäº¤](https://github.com/vllm-project/vllm/commit/c39ee9ee2ba1e004610f671212b62f2572311da0)

**ğŸ¯ å˜æ›´ç±»å‹**ï¼šæ–‡æ¡£æ”¹è¿›ï¼ˆåŠŸèƒ½è¯´æ˜/ä½¿ç”¨æŒ‡å—ï¼‰  
**âš¡ é‡è¦ç¨‹åº¦**ï¼šğŸŸ¡ ä¸­  

**ğŸ“‹ å˜æ›´æ‘˜è¦**  
æ–°å¢äº† vLLM V1 è¿›ç¨‹æ¶æ„è¯´æ˜åŠå¯¹åº”ç¤ºæ„å›¾ï¼Œå¹¶åœ¨ `optimization.md` ä¸­åŠ å…¥â€œCPU èµ„æºå»ºè®®â€ç« èŠ‚ï¼Œæ˜ç¡®äº†åœ¨ GPU éƒ¨ç½²ä¸‹æ¯ç§è¿›ç¨‹ï¼ˆAPIâ€¯Serverã€Engineâ€¯Coreã€GPUâ€¯Workerã€DPâ€¯Coordinatorï¼‰æ‰€éœ€çš„æœ€å°ç‰©ç† CPU æ ¸æ•°åŠè¶…çº¿ç¨‹è®¡æ•°å…¬å¼ã€‚

**ğŸ¯ å½±å“èŒƒå›´**  
- `docs/design/arch_overview.md`ï¼ˆæ¶æ„å›¾ã€è¿›ç¨‹è§’è‰²æè¿°ï¼‰  
- `docs/configuration/optimization.md`ï¼ˆCPU èµ„æºæœ€ä½éœ€æ±‚ã€é£é™©æç¤ºï¼‰  
- æ–°å¢ä¸¤å¼  PNG æ¶æ„ç¤ºæ„å›¾ã€‚  

**ğŸ’¡ å…³æ³¨å»ºè®®**  
1. **æ–‡æ¡£ä¸€è‡´æ€§**ï¼šç¡®ä¿æ–‡ä¸­é“¾æ¥ï¼ˆ`../design/arch_overview.md#v1-process-architecture`ã€`../configuration/optimization.md#cpu-resources-for-gpu-deployments`ï¼‰åœ¨å‘å¸ƒåä»ç„¶å¯è§£æï¼›è‹¥æ–‡ä»¶è·¯å¾„æˆ–ç« èŠ‚æ ‡é¢˜å˜åŠ¨ï¼Œéœ€è¦åŒæ­¥æ›´æ–°ã€‚  
2. **æœ¯è¯­ç»Ÿä¸€**ï¼šæ–‡ä¸­å‡ºç° â€œAPI serverâ€ ä¸ â€œAPI Serverâ€ï¼Œå»ºè®®ç»Ÿä¸€å¤§å°å†™ï¼Œé¿å…æœç´¢æ—¶é—æ¼ã€‚  
3. **ç¤ºä¾‹æ ¡éªŒ**ï¼šæ–‡ä¸­ç»™å‡ºçš„è¿›ç¨‹è®¡æ•°å…¬å¼ `A + DP + N (+1 if DP>1)` ä¸å›¾ä¾‹å¯¹åº”ï¼Œè¯·åœ¨ CI ä¸­åŠ å…¥ç®€å•è„šæœ¬æ£€æŸ¥ Markdown è¡¨æ ¼ä¸å®é™…ä»£ç ï¼ˆå¦‚ `vllm/entrypoints/...`ã€`v1/engine/...`ï¼‰çš„è¿›ç¨‹æ•°é‡æ˜¯å¦ä¿æŒä¸€è‡´ï¼Œé˜²æ­¢æ–‡æ¡£ä¸å®ç°è„±èŠ‚ã€‚  
4. **è·¨å¹³å°æé†’**ï¼šåœ¨è™šæ‹ŸåŒ–æˆ–å®¹å™¨åŒ–ç¯å¢ƒï¼ˆDockerã€K8sï¼‰ä¸­ï¼ŒCPU é…é¢å¸¸ä»¥ vCPU è®¡æ•°ï¼Œå»ºè®®åœ¨æ–‡æ¡£æ˜¾å¼æ ‡æ³¨å¯¹åº”çš„ `--cpus` æˆ– `resources.limits.cpu` ç¤ºä¾‹ï¼Œé™ä½ç”¨æˆ·é…ç½®é”™è¯¯ã€‚  
5. **å¯è®¿é—®æ€§**ï¼šä¸º PNG æ·»åŠ  `alt` æ–‡æœ¬ï¼Œæå‡æ— éšœç¢é˜…è¯»ä½“éªŒï¼›è‹¥æœªæ¥è½¬ä¸º HTMLï¼Œè€ƒè™‘æä¾› SVG ç‰ˆä»¥ä¾¿åœ¨é«˜ DPI å±å¹•ä¸Šæ¸…æ™°æ˜¾ç¤ºã€‚  

æ€»ä½“æ¥çœ‹ï¼Œæ­¤æ¬¡æ–‡æ¡£è¡¥å…¨æå‡äº†ç”¨æˆ·å¯¹ vLLM å¤šè¿›ç¨‹æ¨¡å‹çš„ç†è§£ï¼Œå¹¶ç»™å‡ºå®ç”¨çš„ CPU èµ„æºè§„åˆ’å»ºè®®ï¼Œå¯¹é™ä½éƒ¨ç½²æ€§èƒ½é—®é¢˜æœ‰ç§¯æå¸®åŠ©ã€‚åç»­å¯é€šè¿‡è‡ªåŠ¨åŒ–æ£€æŸ¥ä¿æŒæ–‡æ¡£ä¸ä»£ç å®ç°çš„ä¸€è‡´æ€§ã€‚

---

### [ROCm][AITER] Fix AITER import regression for explicit backend selection (#33749)
**SHA**: `350ca72` | ğŸ”— [æŸ¥çœ‹æäº¤](https://github.com/vllm-project/vllm/commit/350ca72c0423f2b094723dfea479a8f0eb7a46d5)

**ğŸ¯ å˜æ›´ç±»å‹**ï¼šåŠŸèƒ½å¢å¼ºï¼ˆæ˜¾å¼åç«¯é€‰æ‹©å…¼å®¹ï¼‰  
**âš¡ é‡è¦ç¨‹åº¦**ï¼šğŸŸ¡ ä¸­  
**ğŸ“‹ å˜æ›´æ‘˜è¦**ï¼š  
1. ä¿®å¤åœ¨ ROCm ç¯å¢ƒä¸‹é€šè¿‡ `attention_config` æ˜¾å¼æŒ‡å®š AITER åç«¯æ—¶ï¼Œ`vllm._aiter_ops` æœªè¢«æ­£ç¡®å¯¼å…¥å¯¼è‡´çš„å›å½’ã€‚  
2. å°† AITER ç›¸å…³æ£€æŸ¥ä» â€œæ˜¯å¦åº”è¯¥ä½¿ç”¨â€ â†’ â€œæ˜¯å¦å¯ä»¥ä½¿ç”¨â€ è¿›è¡Œæ‹†åˆ†ï¼Œå¹¶åœ¨ `rocm_aiter_ops` ä¸­å®ç° **æ‡’åŠ è½½** çš„ `flash_attn_varlen_func`ã€`pa_fwd_asm`ï¼Œé¿å…è‡ªåŠ¨å‘ç°æ—¶è§¦å‘ JIT ç¼–è¯‘è­¦å‘Šã€‚  
3. æ·»åŠ  `is_aiter_found_and_supported()` ç”¨äºåˆ¤æ–­å¹³å°+åº“æ˜¯å¦å…·å¤‡è¿è¡Œæ¡ä»¶ï¼Œè€Œä¸å†å— `VLLM_ROCM_USE_AITER` ç¯å¢ƒå˜é‡é™åˆ¶ã€‚  
4. åœ¨ `fa_utils` ä¸­åŠ å…¥ ROCm ä¸Š upstream flashâ€‘attn æ˜¯å¦å¯ç”¨çš„ç¼“å­˜æ ‡è®°ï¼Œç»Ÿä¸€ `is_flash_attn_varlen_func_available()` çš„å®ç°ã€‚  
5. è°ƒæ•´æµ‹è¯•ä¸ backend å®ç°ï¼Œä½¿å…¶åœ¨ ROCm ä¸Šä»…åœ¨ AITER å®é™…å¯ç”¨æ—¶æ‰è¿è¡Œï¼Œå¹¶ä½¿ç”¨æ–°çš„ `cp_mha_gather_cache` è¿›è¡Œ KVâ€‘Gatherã€‚  

**ğŸ¯ å½±å“èŒƒå›´**ï¼š  
- `vllm/_aiter_ops.py`ï¼ˆæ ¸å¿ƒåˆ¤æ–­ä¸å…¬å…± APIï¼‰  
- `vllm/v1/attention/backends/rocm_aiter_fa.py`ï¼ˆåç«¯å®ç°ï¼‰  
- `vllm/v1/attention/backends/fa_utils.py`ï¼ˆflashâ€‘attn å¯ç”¨æ€§æ£€æµ‹ï¼‰  
- `vllm/v1/spec_decode/eagle.py`ï¼ˆåç«¯è‡ªåŠ¨å‘ç°è·¯å¾„ï¼‰  
- ç›¸å…³å•å…ƒæµ‹è¯• `tests/kernels/attention/test_aiter_flash_attn.py`  

**ğŸ’¡ å…³æ³¨å»ºè®®**ï¼š  
1. è¿ç§»åˆ°æ˜¾å¼åç«¯é€‰æ‹©çš„ç”¨æˆ·ï¼šåœ¨ `attention_config` ä¸­æŒ‡å®š `ROCM_AITER_FA` å³å¯ï¼Œæ— éœ€å†ä¾èµ– `VLLM_ROCM_USE_AITER=1`ã€‚  
2. è‹¥ç¯å¢ƒä¸­æœªå®‰è£… `aiter` åŒ…ï¼Œä»å¯ä»¥ä½¿ç”¨ upstream flashâ€‘attnï¼ˆå·²é€šè¿‡ `_ROCM_FLASH_ATTN_AVAILABLE` æ ‡è®°ï¼‰ã€‚  
3. CI/æµ‹è¯•ç¯å¢ƒå»ºè®®åœ¨ ROCm é•œåƒä¸­é¢„è£… `aiter`ï¼Œä»¥è¦†ç›–æ–°åŠ å…¥çš„ `cp_mha_gather_cache` è·¯å¾„ã€‚  
4. å…³æ³¨ FP8 ç›¸å…³ dtypeï¼š`_aiter_ops` ç°åœ¨ç»Ÿä¸€ä½¿ç”¨ `FP8_DTYPE`ï¼Œé¿å…åœ¨ä¸åŒè·¯å¾„å‡ºç°ä¸ä¸€è‡´çš„ç±»å‹ã€‚  
5. ç”±äºæ–°å¢æ‡’åŠ è½½ï¼Œé¦–æ¬¡è°ƒç”¨ AITER åç«¯ä»ä¼šè§¦å‘ä¸€æ¬¡ JIT ç¼–è¯‘ï¼Œå»ºè®®åœ¨æ¨¡å‹å¯åŠ¨é˜¶æ®µæå‰è°ƒç”¨ä¸€æ¬¡ï¼ˆå¦‚ `torch.ops.aiter.paged_attention_v1`ï¼‰ä»¥åœ¨æ—¥å¿—ä¸­æ•è·æ½œåœ¨è­¦å‘Šã€‚  

æ•´ä½“æ¥çœ‹ï¼Œæ­¤æ¬¡æ”¹åŠ¨æ¢å¤äº†æ˜¾å¼åç«¯é€‰æ‹©çš„å¯ç”¨æ€§ï¼Œæå‡äº† ROCm ä¸Šçš„å…¼å®¹æ€§ä¸å¯é¢„æµ‹è¡Œä¸ºï¼Œå¯¹ä½¿ç”¨ AITER çš„ç”¨æˆ·å½±å“ç§¯æï¼Œé£é™©ä¸»è¦åœ¨äºæœªå®‰è£… AITER æ—¶ä»éœ€ç¡®ä¿ flashâ€‘attn å¯ç”¨ã€‚

---

### [Bugfix] Fix models and tests for transformers v5 (#33977)
**SHA**: `85ee1d9` | ğŸ”— [æŸ¥çœ‹æäº¤](https://github.com/vllm-project/vllm/commit/85ee1d962b1339eb597bf9451a0bcf4b91c72f2a)

**ğŸ¯ å˜æ›´ç±»å‹**ï¼šBug ä¿®å¤ï¼ˆé’ˆå¯¹ Transformersâ€¯v5 çš„å…¼å®¹æ€§ï¼‰  
**âš¡ é‡è¦ç¨‹åº¦**ï¼šğŸŸ¡ ä¸­  

**ğŸ“‹ å˜æ›´æ‘˜è¦**  
1. æ›´æ–°æ–‡æ¡£ä¸­ AudioFlamingo3 çš„å¤šæ¨¡æ€æ ‡è®°ï¼Œå»é™¤ â€œ+â€ ç¬¦å·ã€‚  
2. æµ‹è¯•ç”¨ä¾‹æ”¹ä¸ºä½¿ç”¨ `video_processor`ã€`image_processor` çš„æ–°å±æ€§åï¼Œå¹¶ä¿®æ­£æ¨¡å‹åµŒå…¥å±‚å°ºå¯¸çš„è®¿é—®è·¯å¾„ã€‚  
3. å¤šä¸ªæ¨¡å‹æ‰§è¡Œå™¨ï¼ˆAudioFlamingo3ã€HunYuanVLã€Isaacã€MiniMaxâ€¯VL ç­‰ï¼‰è°ƒæ•´äº†å¤šæ¨¡æ€é™åˆ¶ã€å‚æ•°è·å–æ–¹å¼ä»¥åŠå¯¹ `pad_token_id` çš„å…¼å®¹ã€‚  
4. å¤§å¹…é‡æ„äº† `BagelProcessor`ã€`OvisProcessor`ã€`Ovis2_5Processor`ï¼Œå¼•å…¥ `ProcessingKwargs`ã€`Unpack`ï¼Œç»Ÿä¸€ `do_convert_rgb` å‚æ•°åï¼Œæ”¹è¿› `__call__` ä¸­çš„ kwarg åˆå¹¶é€»è¾‘ã€‚  
5. æ›¿æ¢ `TensorType` çš„å¯¼å…¥è·¯å¾„ï¼Œæå‡å¯¹ Transformersâ€¯v5 çš„é€‚é…ã€‚  

**ğŸ¯ å½±å“èŒƒå›´**  
- `vllm/model_executor/models/*`ï¼ˆAudioFlamingo3ã€HunYuanVLã€Isaacã€MiniMaxâ€¯VLï¼‰  
- `vllm/transformers_utils/processors/*`ï¼ˆBagelã€HunYuanVLã€Ovisã€Ovis2_5ï¼‰  
- å•å…ƒæµ‹è¯•ç›®å½• `tests/models/multimodal/*`  
- æ–‡æ¡£ `docs/models/supported_models.md`  

**ğŸ’¡ å…³æ³¨å»ºè®®**  
1. **æ¥å£å…¼å®¹**ï¼š`BagelProcessor`ã€`OvisProcessor` ç­‰æ–°å¢çš„ `ProcessingKwargs` åŠ `Unpack` ä¾èµ– Transformersâ€¯â‰¥â€¯5.0ï¼›è‹¥ä»éœ€æ”¯æŒæ—§ç‰ˆï¼Œå»ºè®®åœ¨ `setup.cfg` ä¸­å£°æ˜ `transformers>=5.0` æˆ–æä¾›å›é€€å®ç°ã€‚  
2. **å‚æ•°å‘½åç»Ÿä¸€**ï¼š`do_convert_rgb` æ›¿ä»£ `convert_to_rgb`ï¼Œè¯·æ£€æŸ¥æ‰€æœ‰è‡ªå®šä¹‰ processor å­ç±»æ˜¯å¦åŒæ­¥æ›´æ–°ï¼Œé˜²æ­¢è¿è¡Œæ—¶ `TypeError`ã€‚  
3. **å¤šæ¨¡æ€é™åˆ¶**ï¼šAudioFlamingo3 ç°åœ¨åªæ”¯æŒå•éŸ³é¢‘æµï¼ˆ`{"audio":1}`ï¼‰ï¼Œç¡®ä¿å¯¹åº”çš„ dummyâ€‘inputs ä¸å¤–éƒ¨è°ƒç”¨ä¿æŒä¸€è‡´ï¼Œé˜²æ­¢ OOMã€‚  
4. **æ¨¡å‹æƒé‡ tie**ï¼š`create_dummy_model` å¢åŠ å¯¹ `config.tie_word_embeddings` çš„å…¼å®¹ï¼Œå»ºè®®åœ¨ CI ä¸­åŠ å…¥é’ˆå¯¹ä¸åŒæ¨¡å‹é…ç½®çš„è¦†ç›–æµ‹è¯•ã€‚  
5. **æ–‡æ¡£åŒæ­¥**ï¼šæ–‡æ¡£ä¸­å·²å»é™¤ â€œ+â€ æ ‡è®°ï¼Œä¸ä»£ç å®é™…æ”¯æŒçš„è¾“å…¥ä¿æŒä¸€è‡´ï¼›è¯·åœ¨å‘å¸ƒè¯´æ˜ä¸­æ³¨æ˜æ­¤å˜æ›´ï¼Œä»¥å…ä½¿ç”¨è€…è¯¯è§£æ¨¡å‹èƒ½åŠ›ã€‚  

**åç»­è¡ŒåŠ¨**  
- åœ¨æœ¬åœ°å®Œæ•´è¿è¡Œ `pytest -m "not flaky"`ï¼Œç¡®ä¿æ‰€æœ‰æ›´æ”¹ä¸å¼•å…¥æ–°å¤±è´¥ã€‚  
- é€šè¿‡ CI éªŒè¯åœ¨ä¸åŒ Pythonï¼ˆ3.9â€‘3.12ï¼‰å’Œ Transformers ç‰ˆæœ¬ä¸‹çš„å…¼å®¹æ€§ã€‚  
- å¦‚æœ‰ä¸‹æ¸¸é¡¹ç›®ä»ä½¿ç”¨æ—§å‚æ•°åï¼Œè€ƒè™‘åœ¨ Processor åŸºç±»ä¸­æ·»åŠ å…¼å®¹å±‚ï¼ˆå¦‚ `convert_to_rgb` â†’ `do_convert_rgb` çš„åˆ«åï¼‰ã€‚  

---  
*æ­¤åˆ†æèšç„¦æ ¸å¿ƒæ”¹åŠ¨åŠå…¶æ½œåœ¨å½±å“ï¼Œä¾›å¼€å‘è€…å¿«é€Ÿå®šä½é£é™©å¹¶è¿›è¡ŒéªŒè¯ã€‚*

---

### [Docs] Improve documentation (#33799)
**SHA**: `6e7b1c4` | ğŸ”— [æŸ¥çœ‹æäº¤](https://github.com/vllm-project/vllm/commit/6e7b1c4b591a7d735fc93792e53cb5592cfab4f2)

**ğŸ¯ å˜æ›´ç±»å‹**ï¼šæ–‡æ¡£ä¼˜åŒ–ï¼ˆDocsï¼‰  
**âš¡ é‡è¦ç¨‹åº¦**ï¼šğŸŸ¡ ä¸­  
**ğŸ“‹ å˜æ›´æ‘˜è¦**ï¼šå°†æ‰€æœ‰ç¤ºä¾‹ã€è¯´æ˜å’Œé…ç½®æ³¨é‡Šä¸­å‡ºç°çš„æ—§ç‰ˆ **`huggingface-cli`** å‘½ä»¤ç»Ÿä¸€æ›¿æ¢ä¸ºå®˜æ–¹æ–°çš„ **`hf`** å‘½ä»¤ï¼Œå¹¶åŒæ­¥æ›´æ–°äº† `hf auth login` äº§ç”Ÿçš„ token å­˜æ”¾è·¯å¾„çš„æ–‡æ¡£æè¿°ã€‚  

**ğŸ¯ å½±å“èŒƒå›´**  
- `docs/models/supported_models.md`ï¼šä¸‹è½½ã€ç¼“å­˜ã€åˆ é™¤æ¨¡å‹çš„ CLI ç¤ºä¾‹å…¨éƒ¨æ”¹ä¸º `hf â€¦`ã€‚  
- `examples/offline_inference/openai_batch/README.md`ï¼šç™»å½•ç¤ºä¾‹æ”¹ä¸º `hf auth login`ã€‚  
- `vllm/config/model.py`ã€`vllm/entrypoints/llm.py`ï¼š`ModelConfig.hf_token` ä¸ `LLM` ç±»çš„ docstring ä¸­å¯¹ token ç”Ÿæˆæ¥æºçš„æ–‡å­—è¯´æ˜åŒæ­¥æ›´æ–°ã€‚  

**ğŸ’¡ å…³æ³¨å»ºè®®**  
1. **åŠŸèƒ½ä¿æŒä¸å˜**ï¼šä»£ç å®ç°ä»ç„¶ä½¿ç”¨ `huggingface_hub` è¯»å– tokenï¼Œæœªæ”¹åŠ¨è¯»å–è·¯å¾„ã€‚ä»…æ˜¯æ–‡æ¡£å±‚é¢çš„è¡¨è¿°ï¼Œæ›´è´´åˆ `hf` CLI å½“ä¸‹çš„é»˜è®¤å­˜æ”¾ä½ç½®ï¼ˆ`~/.cache/huggingface/token`ï¼‰ã€‚å› æ­¤å¯¹è¿è¡Œæ—¶è¡Œä¸ºæ²¡æœ‰ç›´æ¥å½±å“ã€‚  
2. **å…¼å®¹æ€§æ£€æŸ¥**ï¼šè‹¥é¡¹ç›® CI æˆ–å†…éƒ¨è„šæœ¬ä»ä¾èµ– `huggingface-cli`ï¼Œè¯·ç¡®è®¤ `hf` å·²åœ¨ç›¸åº”ç¯å¢ƒä¸­å®‰è£…ï¼ˆ`pip install huggingface_hub[cli]`ï¼‰ï¼Œå¦åˆ™è„šæœ¬ä¼šå› å‘½ä»¤ä¸å­˜åœ¨è€Œå¤±è´¥ã€‚  
3. **ç‰ˆæœ¬è¦æ±‚**ï¼š`hf` å‘½ä»¤åœ¨ `huggingface_hub>=0.20` ä¹‹åæ‰å¯ç”¨ï¼Œå»ºè®®åœ¨ `requirements.txt` ä¸­åŠ å…¥å¯¹åº”æœ€ä½ç‰ˆæœ¬çº¦æŸï¼Œé˜²æ­¢è€ç‰ˆæœ¬ç”¨æˆ·ä»çœ‹åˆ° `hf` ä¸å¯ç”¨çš„æƒ…å†µã€‚  
4. **æ–‡æ¡£åŒæ­¥**ï¼šåç»­è‹¥å®˜æ–¹ CLI å†åº¦å˜æ›´ï¼ˆå¦‚ç§»é™¤ `hf`ï¼‰ï¼Œè¯·åŠæ—¶æ›´æ–°æ‰€æœ‰æ–‡æ¡£å’Œç¤ºä¾‹ï¼Œé¿å…å‡ºç°ä¸å®é™…å¯æ‰§è¡Œå‘½ä»¤ä¸åŒ¹é…çš„æƒ…å†µã€‚  

æ€»ä½“è€Œè¨€ï¼Œæ­¤æ¬¡æäº¤æ˜¯ä¸€æ¬¡ **æ–‡æ¡£å±‚é¢çš„æ¸…ç†ä¸ç»Ÿä¸€**ï¼Œå¯¹ä»£ç è¿è¡Œæ— å®è´¨å½±å“ï¼Œåªéœ€å…³æ³¨ä¾èµ–ç‰ˆæœ¬å’Œ CI è„šæœ¬çš„å…¼å®¹å³å¯ã€‚

---

### [Bugfix][Model] Support LoRA on Qwen3 Output Embedding (#29816)
**SHA**: `2991dd3` | ğŸ”— [æŸ¥çœ‹æäº¤](https://github.com/vllm-project/vllm/commit/2991dd3d2241cb3b188a047282e58111684e0201)

**ğŸ¯ å˜æ›´ç±»å‹**ï¼šåŠŸèƒ½å¢å¼ºï¼ˆä¸º Qwenâ€‘3 ç³»åˆ—æ¨¡å‹è¡¥å…¨ LoRA å¯¹è¾“å‡ºå±‚ `lm_head` çš„æ”¯æŒï¼‰  
**âš¡ é‡è¦ç¨‹åº¦**ï¼šğŸŸ¡ ä¸­  
**ğŸ“‹ å˜æ›´æ‘˜è¦**ï¼š  
1. åœ¨ `vllm/model_executor/models/qwen3*` ä¸­æ–°å¢ `embedding_modules` å£°æ˜ï¼ŒæŠŠ `lm_head` æ ‡è®°ä¸ºè¾“å‡ºåµŒå…¥ï¼Œç»Ÿä¸€ä¸ `embed_tokens` çš„å¤„ç†é€»è¾‘ã€‚  
2. `logits_processor.py` ä¿®æ­£ LoRA åŒ…è£…å±‚çš„è°ƒç”¨ï¼šè‹¥ `lm_head` è¢« `LogitsProcessorWithLoRA` åŒ…è£¹ï¼Œåˆ™è·³è¿‡åŒ…è£…å±‚ç›´æ¥ä½¿ç”¨åº•å±‚ `quant_method`ã€‚  
3. `model_manager.py` åˆ›å»º Dummy LoRA æ—¶å¯¹ `lm_head` é‡‡ç”¨éšè—ç»´åº¦ â†’ è¯è¡¨ç»´åº¦çš„ç‰¹æ®Šè®¡ç®—ï¼Œé¿å…èµ°è¾“å…¥åµŒå…¥çš„æ—§è·¯å¾„ã€‚  
4. æ–°å¢ `tests/lora/test_qwen3_unembed.py`ï¼ŒåˆæˆåŒ…å« `lm_head` LoRA æƒé‡çš„ safetensorsï¼ŒéªŒè¯åŠ è½½ä¸æ¨ç†å‡å¯æ­£å¸¸å·¥ä½œã€‚  

**ğŸ¯ å½±å“èŒƒå›´**ï¼š  
- `vllm/lora/*`ï¼ˆLoRA æƒé‡ç®¡ç†ã€Logits å¤„ç†ï¼‰  
- `vllm/model_executor/models/qwen3.py`ã€`qwen3_moe.py`ï¼ˆæ¨¡å‹ç»“æ„å£°æ˜ï¼‰  
- `vllm/engine/llm_engine.py`ï¼ˆLoRA æ³¨å†Œ/åˆ—è¡¨ï¼‰  
- æµ‹è¯•å¥—ä»¶ `tests/lora/`  

**ğŸ’¡ å…³æ³¨å»ºè®®**ï¼š  
1. **å…¼å®¹æ€§æ£€æŸ¥**ï¼šç¡®ä¿å…¶å®ƒå·²æ”¯æŒ LoRA çš„æ¨¡å‹ï¼ˆå¦‚ Llamaã€Mistralï¼‰åœ¨åŠ å…¥ `embedding_modules` åä»ä¿æŒåŸæœ‰è¡Œä¸ºï¼Œé˜²æ­¢å›  `hasattr(lm_head, "base_layer")` é€»è¾‘è¯¯åˆ¤ã€‚  
2. **é‡åŒ–è·¯å¾„å®‰å…¨**ï¼š`actual_lm_head.quant_method.apply` å‡è®¾ `quant_method` æ€»æ˜¯å­˜åœ¨ï¼›è‹¥æ¨¡å‹ä½¿ç”¨æœªé‡åŒ–çš„ `lm_head`ï¼ˆ`torch.nn.Linear`ï¼‰ï¼Œéœ€ç¡®è®¤ `quant_method` ä¸ä¼šæŠ›å¼‚å¸¸ã€‚å¯åœ¨ä»£ç ä¸­æ·»åŠ  fallbackã€‚  
3. **Dummy LoRA ç”Ÿæˆ**ï¼šå¯¹ `lm_head` çš„ `input_dim` ä¸ `output_dim` é‡‡ç”¨ `module.lora_a_stacked[0]` ä¸ `module.lora_b_stacked[0]`ï¼Œè¿™ä¾èµ– LoRA åŒ…è£…å±‚å·²åˆ›å»ºå¯¹åº”å¼ é‡ï¼Œå»ºè®®åœ¨å¼‚å¸¸è·¯å¾„ä¸­ç»™å‡ºæ˜ç¡®é”™è¯¯ä¿¡æ¯ã€‚  
4. **èµ„æºé™åˆ¶**ï¼š`max_lora_rank=8` åœ¨æµ‹è¯•ä¸­ä½¿ç”¨ï¼Œå®é™…éƒ¨ç½²æ—¶è‹¥æ¨¡å‹è¯è¡¨æå¤§ï¼ˆå¦‚ 150k+ï¼‰å¯èƒ½å¯¼è‡´æ˜¾å­˜æ¿€å¢ï¼Œå»ºè®®åœ¨æ–‡æ¡£ä¸­ç»™å‡º `max_lora_rank` ä¸è¯è¡¨å¤§å°çš„ç»éªŒé˜ˆå€¼ã€‚  
5. **æµ‹è¯•è¦†ç›–**ï¼šå½“å‰ä»…å¯¹ Qwenâ€‘3 å•å±‚ `lm_head` LoRA åšäº†æ­£å‘ç”Ÿæˆæµ‹è¯•ï¼Œåç»­å¯åŠ å…¥æ¢¯åº¦æ£€æŸ¥æˆ–å¤š LoRA åŒæ—¶æ¿€æ´»çš„åœºæ™¯ï¼Œä»¥æ•è·æ½œåœ¨çš„æƒé‡å åŠ é”™è¯¯ã€‚  

æ€»ä½“è€Œè¨€ï¼Œæ­¤æ¬¡æ”¹åŠ¨ä¸º Qwenâ€‘3 ç³»åˆ—æ¨¡å‹æä¾›äº†å®Œæ•´çš„ LoRA åŠŸèƒ½ï¼Œæ”¹åŠ¨é›†ä¸­ä¸”å¯¹æ ¸å¿ƒè¿è¡Œæ—¶çš„å½±å“å¯æ§ï¼Œåªéœ€æ³¨æ„ä¸Šè¿°å…¼å®¹æ€§å’Œé‡åŒ–è·¯å¾„çš„ç¨³å¥æ€§å³å¯ã€‚

---

### Consolidate and fix forbidden import `pre-commit` checks (#33982)
**SHA**: `791a94b` | ğŸ”— [æŸ¥çœ‹æäº¤](https://github.com/vllm-project/vllm/commit/791a94bed03f4011c98b7179a6fd2f4fed6d1d9a)

**ğŸ¯ å˜æ›´ç±»å‹**ï¼šé‡æ„ / å…¶ä»–  
**âš¡ é‡è¦ç¨‹åº¦**ï¼šğŸŸ¡ ä¸­  
**ğŸ“‹ å˜æ›´æ‘˜è¦**ï¼šå°†åŸå…ˆåˆ†æ•£çš„ä¸‰ä¸ª preâ€‘commit æ£€æŸ¥ï¼ˆ`enforce_regex_import.py`ã€`check_pickle_imports.py`ã€`check_triton_import.py`ï¼‰åˆå¹¶ä¸ºå•ä¸€è„šæœ¬ `tools/pre_commit/check_forbidden_imports.py`ï¼Œå¹¶åœ¨ `.pre-commit-config.yaml` ä¸­ç»Ÿä¸€ä¸º `check-forbidden-imports`ã€‚è„šæœ¬åœ¨ä¸€æ¬¡éå†ä¸­åŒæ—¶æ£€æµ‹ `pickle / cloudpickle`ã€`re`ï¼ˆå¼ºåˆ¶ä½¿ç”¨ `regex`ï¼‰ä»¥åŠç›´æ¥ `import triton`ï¼Œå¹¶é€šè¿‡ç™½åå• `allowed_files / allowed_pattern` è¿‡æ»¤åˆæ³•ä¾‹å¤–ã€‚

**ğŸ¯ å½±å“èŒƒå›´**  
- `tools/pre_commit/` ç›®å½•ï¼ˆæ–°å¢ä¸åˆ é™¤è„šæœ¬ï¼‰  
- `.pre-commit-config.yaml`ï¼ˆhook é…ç½®ï¼‰  
- ä»»ä½•ä½¿ç”¨ preâ€‘commit æ£€æŸ¥çš„ CI/CD æµç¨‹  
- å—é™çš„æºæ–‡ä»¶åˆ—è¡¨ï¼ˆ`allowed_files`ï¼‰åœ¨è„šæœ¬å†…éƒ¨ç¡¬ç¼–ç ã€‚

**ğŸ’¡ å…³æ³¨å»ºè®®**  

| å…³æ³¨ç‚¹ | è¯´æ˜ | å»ºè®® |
|--------|------|------|
| **æ­£åˆ™åŒ¹é…å‡†ç¡®æ€§** | `pattern`ã€`allowed_pattern` ä½¿ç”¨ `regex` åº“ï¼Œä¸”å¯¹å¤šè¡Œæ–‡ä»¶ä¸€æ¬¡ `finditer`ã€‚å¦‚æœåŒ¹é…è¿‡å®½æˆ–è¯¯æŠ¥ï¼Œå¯èƒ½é˜»æ–­åˆæ³•ä»£ç ã€‚ | ä¸ºæ¯ç±»å¯¼å…¥ç¼–å†™ç‹¬ç«‹çš„å•å…ƒæµ‹è¯•ï¼ˆå·²æä¾› `--test-regex`ï¼‰ï¼Œå¹¶åœ¨ CI ä¸­è·‘ä¸€æ¬¡ã€‚å¿…è¦æ—¶åŠ å…¥ `(?<!\w)` ç­‰è¾¹ç•Œé™åˆ¶ã€‚ |
| **ç™½åå•ç»´æŠ¤** | `allowed_files` åˆ—è¡¨ç›´æ¥å†™åœ¨ä»£ç é‡Œï¼Œæ–°å¢æˆ–ç§»åŠ¨æ–‡ä»¶æ—¶æ˜“å¿˜è®°åŒæ­¥ï¼Œå¯¼è‡´è¯¯æŠ¥ã€‚ | æŠŠç™½åå•æŠ½ç¦»ä¸ºå¤–éƒ¨é…ç½®ï¼ˆå¦‚ `json`/`toml`ï¼‰ï¼Œå¹¶åœ¨ `README` ä¸­æ˜ç¡®ä¿®æ”¹æµç¨‹ã€‚ |
| **é”™è¯¯ä¿¡æ¯å¯è¯»æ€§** | åªè¾“å‡ºæ–‡ä»¶:è¡Œå·:é”™è¯¯æç¤ºï¼Œæœªç»™å‡ºå…·ä½“ä»£ç è¡Œã€‚ | åœ¨æ‰“å°æ—¶åŠ å…¥åŒ¹é…çš„ä»£ç ç‰‡æ®µï¼ˆ`match.group().strip()`ï¼‰ï¼Œå¸®åŠ©å¼€å‘è€…å¿«é€Ÿå®šä½ã€‚ |
| **æ–‡ä»¶è¯»å–å¼‚å¸¸** | åªæ•è· `open` æ—¶çš„é»˜è®¤å¼‚å¸¸ï¼Œæœªå¤„ç†äºŒè¿›åˆ¶æˆ–ç¼–ç é—®é¢˜ã€‚ | åœ¨ `check_file` ä¸­åŠ å…¥ `try/except UnicodeDecodeError` å¹¶è·³è¿‡æ— æ³•è§£ç çš„æ–‡ä»¶ï¼Œä»¥å… preâ€‘commit ä¸­æ–­ã€‚ |
| **æ€§èƒ½** | å¯¹æ¯ä¸ªæ–‡ä»¶è¿›è¡Œå…¨æ–‡ä»¶æ­£åˆ™æ‰«æï¼Œè‹¥é¡¹ç›®ä¸­ Python æ–‡ä»¶æ•°ç›®å¾ˆå¤§ï¼Œæ£€æŸ¥è€—æ—¶å¯èƒ½ä¸Šå‡ã€‚ | é‡‡ç”¨é€è¡Œæ‰«æï¼ˆä¸æ—§å®ç°ç›¸åŒï¼‰æˆ–åœ¨ `re.finditer` å‰å…ˆåšå¿«é€Ÿ `if "pickle" in content` åˆ¤æ–­ï¼Œä»¥é™ä½ä¸å¿…è¦çš„æ­£åˆ™å¼€é”€ã€‚ |
| **CI å…¼å®¹æ€§** | åˆ é™¤çš„ä¸‰ä¸ªè„šæœ¬ä»å¯èƒ½è¢«æ—§çš„ preâ€‘commit ç¼“å­˜å¼•ç”¨ã€‚ | åœ¨ CI ä¸­æ‰§è¡Œ `pre-commit clean && pre-commit install`ï¼Œç¡®ä¿ä½¿ç”¨æ–° hookã€‚ |

æ€»ä½“è€Œè¨€ï¼Œæ­¤æ¬¡åˆå¹¶ç®€åŒ–äº† preâ€‘commit ç»´æŠ¤æˆæœ¬ï¼Œæå‡äº†æ£€æŸ¥çš„ä¸€è‡´æ€§ã€‚ä½†åœ¨æ­£å¼åˆå…¥ä¸»åˆ†æ”¯å‰ï¼Œå»ºè®®å®Œå–„ç™½åå•ç®¡ç†æ–¹å¼å¹¶å¯¹æ­£åˆ™è¿›è¡Œæ›´ç»†ç²’åº¦çš„å•å…ƒ/é›†æˆæµ‹è¯•ï¼Œä»¥é˜²æ­¢è¯¯æŠ¥å½±å“å¼€å‘è€…æäº¤ä½“éªŒã€‚

---

### support view_from_cpu_tensor on XPU (#33868)
**SHA**: `e969a16` | ğŸ”— [æŸ¥çœ‹æäº¤](https://github.com/vllm-project/vllm/commit/e969a169ef3842fd18fdf922dd23a9f67bea98a4)

**ğŸ”§ å˜æ›´ç±»å‹**ï¼šåŠŸèƒ½å¢å¼ºï¼ˆä¸º XPUï¼ˆIntelâ€‘GPUï¼‰æ·»åŠ  UVA æ”¯æŒï¼‰  
**âš¡ é‡è¦ç¨‹åº¦**ï¼šğŸŸ¡ ä¸­  
**ğŸ“‹ å˜æ›´æ‘˜è¦**ï¼š  
- å°†åŸå…ˆä»…é¢å‘ CUDA çš„ `get_cuda_view_from_cpu_tensor` é‡å‘½åä¸ºæ›´é€šç”¨çš„ `get_accelerator_view_from_cpu_tensor`ã€‚  
- åœ¨å®ç°ä¸­åŠ å…¥å¯¹ XPU å¹³å°çš„åˆ†æ”¯ï¼Œè°ƒç”¨ `torch.ops._C.get_xpu_view_from_cpu_tensor`ã€‚  
- ç›¸åº”åœ°æ›´æ–°äº†æµ‹è¯•ã€æ¨¡å‹ç¦»çº¿/åŠ è½½ä»¥åŠ GPU ç¼“å†²åŒºå·¥å…·çš„æ‰€æœ‰è°ƒç”¨ç‚¹ã€‚  

**ğŸ¯ å½±å“èŒƒå›´**ï¼š  
- `vllm.utils.torch_utils`ï¼ˆæ ¸å¿ƒæ¥å£ï¼‰  
- `vllm/model_executor/models/utils.py`ï¼ˆå‚æ•° offâ€‘load é€»è¾‘ï¼‰  
- `vllm/v1/worker/gpu/buffer_utils.py`ï¼ˆUVA ç¼“å†²åŒºï¼‰  
- å•å…ƒæµ‹è¯• `tests/kernels/core/test_uva.py`  

**ğŸ’¡ å…³æ³¨å»ºè®®**ï¼š  
1. **å‘åå…¼å®¹**ï¼šå½“å‰æ”¹åŠ¨ç›´æ¥åˆ é™¤äº† `get_cuda_view_from_cpu_tensor`ï¼Œè‹¥å¤–éƒ¨é¡¹ç›®ä»é€šè¿‡è¯¥åç§°å¯¼å…¥ï¼Œå°†å‡ºç° `ImportError`ã€‚å»ºè®®åœ¨ `torch_utils.py` ä¸­ä¿ç•™ä¸€ä¸ªå…¼å®¹åˆ«åæˆ–æä¾› deprecation è­¦å‘Šï¼Œä»¥å…å‡çº§æ—¶äº§ç”Ÿç ´åã€‚  
2. **å¹³å°æ£€æµ‹**ï¼šæ–°å®ç°ä¾èµ– `vllm.platforms.current_platform.is_xpu()`ï¼Œç¡®ä¿åœ¨é XPU ç¯å¢ƒä¸‹ `current_platform` æ­£ç¡®è¿”å› `False`ï¼Œé˜²æ­¢è¯¯è°ƒç”¨ä¸å­˜åœ¨çš„ C++ opã€‚  
3. **æ–‡æ¡£/ç¤ºä¾‹**ï¼šæ›´æ–° READMEã€API æ–‡æ¡£ä»¥åŠç¤ºä¾‹ä»£ç ï¼Œè¯´æ˜è¯¥å‡½æ•°å·²ç»Ÿä¸€ä¸º â€œacceleratorâ€ è§†å›¾ï¼Œå¹¶åˆ—å‡ºå·²æ”¯æŒçš„åç«¯ï¼ˆCUDAã€XPUï¼‰ã€‚  
4. **æµ‹è¯•è¦†ç›–**ï¼šç°æœ‰æµ‹è¯•åªè¦†ç›– CUDA åœºæ™¯ï¼Œå»ºè®®æ–°å¢ XPU ç¯å¢ƒçš„ CIï¼ˆæˆ–ä½¿ç”¨æ¨¡æ‹Ÿï¼‰ä»¥éªŒè¯ `get_xpu_view_from_cpu_tensor` çš„è°ƒç”¨è·¯å¾„ã€‚  
5. **æ€§èƒ½ç›‘æ§**ï¼šUVA åœ¨ XPU ä¸Šçš„å®ç°ç»†èŠ‚å¯èƒ½ä¸ CUDA ç•¥æœ‰å·®å¼‚ï¼Œå»ºè®®åœ¨å®é™…æ¨ç†è´Ÿè½½ä¸‹ç›‘æ§å†…å­˜æ‹·è´å»¶è¿Ÿå’Œå¸¦å®½ï¼Œç¡®ä¿ä¸ä¼šå‡ºç°é¢„æ–™ä¹‹å¤–çš„å›é€€ã€‚  

æ€»ä½“æ¥çœ‹ï¼Œæ­¤æ¬¡æ”¹åŠ¨ä¸ºå¤šåŠ é€Ÿå™¨æ”¯æŒå¥ å®šäº†ä»£ç åŸºç¡€ï¼Œé£é™©ä¸»è¦é›†ä¸­åœ¨ API æ”¹åçš„å‘åå…¼å®¹ä»¥åŠç¼ºå°‘ XPU æµ‹è¯•ã€‚é€‚åº¦åŠ å…¥å…¼å®¹å±‚å¹¶å®Œå–„æ–‡æ¡£å³å¯å¹³æ»‘è¿ç§»ã€‚

---

### [cpu][performance] CPU Paged Attention NEON BFMMLA BF16 Implementation (#32263)
**SHA**: `1363e3d` | ğŸ”— [æŸ¥çœ‹æäº¤](https://github.com/vllm-project/vllm/commit/1363e3d6d5659b58376fa5284afc2c8be548cc9d)

**å˜æ›´æ¦‚è§ˆ**  
æœ¬æ¬¡ PR ä¸º CPUâ€‘Pagedâ€‘Attention å¼•å…¥äº†åŸºäº ARM NEONâ€¯BFMMLAï¼ˆBF16ï¼‰çš„åŠ é€Ÿå®ç°ï¼Œæ ¸å¿ƒæ”¹åŠ¨å¦‚ä¸‹ï¼š

1. **cpu_attn_impl.hpp**  
   - åœ¨è®¡ç®— `left_kv_pos` æ—¶é¢å¤– clamp åˆ° `kv_tile_end_pos`ï¼Œé˜²æ­¢çª—å£èµ·ç‚¹è½åœ¨å½“å‰ tile ä¹‹å¤–å¯¼è‡´ OOBã€‚  

2. **cpu_attn_neon.hpp / cpu_attn_neon_bfmmla.hpp**  
   - åœ¨ NEON å¤´æ–‡ä»¶ä¸­åŠ å…¥ `#ifdef ARM_BF16_SUPPORT`ï¼Œåœ¨æ”¯æŒ BF16 çš„ ARM å¹³å°ä¸Šç¼–è¯‘ BFMMLA å®ç°ã€‚  
   - æ–°å¢å¤§é‡ **BFMMLA** å¾®/ä¸­/å® kernelï¼ˆ`gemm_rowpairs_x8_bfmmla_neon` ç­‰ï¼‰ï¼Œå®ç° 2Ã—Kâ€¯reshapeã€2Ã—2 accumulatorã€åˆ—â€‘å—å¾ªç¯ç­‰ï¼Œä¸“é—¨é’ˆå¯¹ `c10::BFloat16`ã€‚  
   - ä¸º BF16 å®šä¹‰ `AttentionImpl<ISA::NEON, c10::BFloat16, head_dim>` çš„ç‰¹åŒ–ï¼Œä½¿å…¶å¤ç”¨ `AttentionImplNEONBFMMLA`ã€‚  
   - åœ¨ `TileGemmNEONBFMMLA` ä¸­å®ç° QK ä¸ PV ä¸¤ç›¸ä½çš„ GEMMï¼Œæ”¯æŒç¼–è¯‘æœŸ Kï¼ˆ32/128/256ï¼‰å’Œè¿è¡Œæ—¶ Kã€‚  

3. **vllm/v1/attention/backends/cpu_attn.py**  
   - å¼•å…¥ `supports_arm` æ ‡è®°ï¼Œä»…åœ¨ ARM æ¶æ„ä¸” `block_size%32==0` æ—¶è¿”å› `"neon"`ï¼Œä¿è¯ NEONâ€¯BFMMLA åªåœ¨æ»¡è¶³å¯¹é½æ¡ä»¶ä¸‹æ¿€æ´»ã€‚  

**å½±å“èŒƒå›´**  
- **CPU attention æ ¸å¿ƒ**ï¼š`csrc/cpu/*` ä»¥åŠ `cpu_attn.py` å‡ä¼šé‡æ–°ç¼–è¯‘ï¼Œæ–°å¢çš„ BF16 è·¯å¾„ä¼šè¦†ç›–åŸæœ‰ `float32`/`float16` NEON å®ç°ã€‚  
- **å¹³å°å…¼å®¹æ€§**ï¼šä»…åœ¨å®šä¹‰ `ARM_BF16_SUPPORT`ï¼ˆå³ç¼–è¯‘å™¨/CPU æ”¯æŒ BF16ï¼‰ä¸” `current_platform.get_cpu_architecture()==ARM` æ—¶ç”Ÿæ•ˆï¼Œå…¶ä»–å¹³å°ä»èµ°åŸæœ‰è·¯å¾„ã€‚  
- **ç¼“å­˜å¸ƒå±€**ï¼šKV cache çš„é‡æ–°æ’å¸ƒæ–¹å¼å‘ç”Ÿæ”¹å˜ï¼Œä¾èµ– `k_cache_token_group_stride`ã€`v_cache_token_group_stride` çš„å¯¹é½å‡è®¾ï¼ˆå¿…é¡»æ˜¯ 8â€‘token/4â€‘token å—ï¼‰ã€‚  

**ä»£ç å®¡æŸ¥è¦ç‚¹ & å»ºè®®**  

| é¡¹ç›® | è¯´æ˜ | å»ºè®® |
|------|------|------|
| **å®å®šä¹‰ & ç¼–è¯‘é€‰é¡¹** | æ–°å¢ `ARM_BF16_SUPPORT`ï¼Œä½†åŸä»“åº“ Makefile/`setup.py` ä¸­æœªè§ç›¸åº”æ£€æµ‹ã€‚ | åœ¨ CMake/`setup.py` ä¸­åŠ å…¥ `-march=armv8.6-a+bf16`ï¼ˆæˆ–æ£€æµ‹ `__ARM_FEATURE_BF16`ï¼‰å¹¶è‡ªåŠ¨å®šä¹‰ `ARM_BF16_SUPPORT`ï¼Œé¿å…åœ¨ä¸æ”¯æŒçš„ ARM ç¼–è¯‘æ—¶æŠ¥é”™ã€‚ |
| **è¿è¡Œæ—¶æ£€æµ‹** | `supports_arm` åªæ£€æŸ¥ CPU æ¶æ„ï¼ŒæœªéªŒè¯ BF16 å®é™…å¯ç”¨ã€‚ | åœ¨ `cpu_attn.py` ä¸­åŠ å…¥ `torch._C._cpu._is_bfloat16_supported()`ï¼ˆè‹¥æœ‰ï¼‰æˆ–è‡ªè¡Œé€šè¿‡ `torch.cpu.get_device_properties` æ£€æŸ¥ï¼Œä»¥é˜²åœ¨ä»…æœ‰ NEONâ€¯FMLA è€Œæ—  BFMMLA çš„è€ ARM ä¸Šè¯¯é€‰ `"neon"`ã€‚ |
| **å¯¹é½çº¦æŸ** | å¤šå¤„ `static_assert` è¦æ±‚ `HeadDim % TILE_K == 0`ã€`BlockSizeAlignment % OUTPUT_COLS_PER_BLOCK == 0`ã€‚ | åœ¨ Python å±‚å¯¹ `block_size`ã€`head_dim` åšå‰ç½®æ ¡éªŒï¼Œç»™å‡ºå‹å¥½é”™è¯¯ä¿¡æ¯ï¼Œè€Œä¸æ˜¯åœ¨ç¼–è¯‘æ—¶ç›´æ¥æŠ¥é”™ã€‚ |
| **OOB ä¿®æ­£** | `cpu_attn_impl.hpp` çš„ `left_kv_pos` clamp å¯èƒ½å¯¼è‡´ `left_kv_pos > right_kv_pos`ï¼ˆåœ¨æç«¯çª—å£ï¼‰ï¼Œåç»­ä»£ç æ˜¯å¦å®‰å…¨ï¼Ÿ | åœ¨ `AttentionMainLoop` ä¸­åŠ å…¥ `pos = std::min(pos, right_kv_pos)` çš„é˜²å¾¡æ€§æ£€æŸ¥ï¼Œæˆ–åœ¨æ³¨é‡Šä¸­è¯´æ˜çª—å£é•¿åº¦æ°¸ä¸å°äº 1ã€‚ |
| **BFMMLA è·¯å¾„çš„æ­£ç¡®æ€§** | BFMMLA åªåœ¨ `phase == PV` æ”¯æŒè¿è¡Œæ—¶ Kï¼›`QK` å§‹ç»ˆä½¿ç”¨ compileâ€‘time `HeadDim`ã€‚ | ç¡®è®¤åœ¨ `AttentionImplNEONBFMMLA` è°ƒç”¨ `gemm_macro_neon_bfmmla` æ—¶ `phase==QK` çš„ `K_static` ä¸º `HeadDim`ï¼ˆå·²æ»¡è¶³ï¼‰ï¼Œå¦åˆ™è¿è¡Œæ—¶è·¯å¾„ä¼šè§¦å‘ `static_assert`ã€‚ |
| **æ€§èƒ½åŸºå‡†** | æ–°å¢çš„ BFMMLA kernel é‡‡ç”¨ 2Ã—2 accumulator ä¸ 4â€‘columnâ€‘pair å¹¶è¡Œï¼Œç†è®ºä¸Šæ¯”åŸ FMLA çº¦ 2Ã— æé€Ÿã€‚ | å»ºè®®åœ¨ CI ä¸­åŠ å…¥ ARMâ€‘v8.6â€‘aï¼ˆæˆ–å®é™…ç¡¬ä»¶ï¼‰ä¸Šçš„å¾®åŸºå‡†ï¼Œè®°å½• `block_size=32`ã€`head_dim=64/128` çš„ååå¯¹æ¯”ï¼Œç¡®ä¿æœªå‡ºç° regressionsã€‚ |
| **æ–‡æ¡£/ç”¨æˆ·æç¤º** | ç›®å‰æäº¤æœªæ›´æ–° README/CHANGELOGï¼Œç”¨æˆ·ä¸æ˜“å‘ç° BF16 åŠ é€Ÿçš„å‰ç½®æ¡ä»¶ã€‚ | åœ¨ `docs` æˆ– `CHANGELOG` ä¸­æ³¨æ˜ï¼š`arm64` ä¸”ç¼–è¯‘å™¨æ”¯æŒ `BF16`ï¼ˆgccâ€‘11+/clangâ€‘15+ï¼‰å¯è‡ªåŠ¨å¯ç”¨ NEONâ€¯BFMMLAï¼Œæ¨èä½¿ç”¨ `torch>=2.4`ï¼ˆè‹¥å·²æœ‰ BF16 æ”¯æŒï¼‰ã€‚ |
| **å¼‚å¸¸/å›é€€** | è‹¥åœ¨æ”¯æŒ NEON ä½†ä¸æ”¯æŒ BF16 çš„ ARMï¼ˆå¦‚ older Cortexâ€‘Aï¼‰ï¼Œ`ARM_BF16_SUPPORT` æœªå®šä¹‰ï¼Œä»ä¼šèµ°åŸ NEON FMLAã€‚ | ç¡®ä¿ `cpu_attn_neon.hpp` ä¸­çš„ `#ifdef ARM_BF16_SUPPORT` ä¸ä¼šå¯¼è‡´æœªå®šä¹‰çš„ç¬¦å·ï¼Œä¿æŒåå¤‡è·¯å¾„ä¸å˜ã€‚ |

**æ€»ä½“è¯„ä¼°**  
- **åŠŸèƒ½**ï¼šå®ç°äº†é’ˆå¯¹ BF16 çš„é«˜æ•ˆ NEONâ€¯BFMMLA GEMMï¼Œèƒ½å¤Ÿæ˜¾è‘—æå‡ CPUâ€‘Pagedâ€‘Attention åœ¨ ARMâ€¯v8.6â€‘a+bf16 èŠ¯ç‰‡ä¸Šçš„ååã€‚  
- **é£é™©**ï¼šä¸»è¦åœ¨å¹³å°æ£€æµ‹å’Œå¯¹é½å‡è®¾ä¸Šï¼›å¦‚æœç¼–è¯‘ç¯å¢ƒè¯¯æŠ¥æ”¯æŒæˆ–ç”¨æˆ·æä¾›ä¸æ»¡è¶³å¯¹é½çš„ `head_dim/block_size`ï¼Œä¼šå¯¼è‡´ç¼–è¯‘æˆ–è¿è¡Œæ—¶é”™è¯¯ã€‚  
- **å»ºè®®**ï¼šå®Œå–„ç¼–è¯‘/è¿è¡Œæ—¶æ£€æµ‹ï¼ŒåŠ å…¥å¯¹é½æ ¡éªŒä¸å›é€€æç¤ºï¼Œè¡¥é½æ–‡æ¡£å¹¶åœ¨ CI åŠ å…¥ ARMâ€‘BF16 åŸºå‡†ï¼Œä»¥ä¿éšœå…¼å®¹æ€§å’Œå¯ç»´æŠ¤æ€§ã€‚  

---  
*æœ¬å®¡æŸ¥é‡ç‚¹èšç„¦äºæ ¸å¿ƒè®¡ç®—è·¯å¾„çš„æ”¹åŠ¨ã€å¹³å°å…¼å®¹æ€§ä»¥åŠæ½œåœ¨çš„å›é€€/å®‰å…¨é—®é¢˜ï¼Œä¾›å¼€å‘è€…åœ¨åˆå¹¶å‰å‚è€ƒã€‚*

---

### Onboard voyage-4-nano (#33720)
**SHA**: `9655256` | ğŸ”— [æŸ¥çœ‹æäº¤](https://github.com/vllm-project/vllm/commit/965525667b70dc23463d57295dce792eba1ac452)

**ğŸ¯ å˜æ›´ç±»å‹**ï¼šåŠŸèƒ½å¢å¼ºï¼ˆæ–°å¢ Voyageâ€¯Qwenâ€‘3â€¯Bidirectionalâ€¯Embed æ¨¡å‹ï¼‰  
**âš¡ é‡è¦ç¨‹åº¦**ï¼šğŸŸ¡ ä¸­  

**ğŸ“‹ å˜æ›´æ‘˜è¦**  
- åœ¨ `docs/models/supported_models.md` ä¸­åŠ å…¥å¯¹ `VoyageQwen3BidirectionalEmbedModel` çš„è¯´æ˜ã€‚  
- å®Œæ•´å®ç°è¯¥æ¨¡å‹ï¼šåœ¨ `vllm/model_executor/models/voyage.py` ä¸­ç»§æ‰¿ Qwenâ€‘3ï¼Œæ–°å¢çº¿æ€§åµŒå…¥å¤´ã€åŒå‘ï¼ˆ encoderâ€‘onlyï¼‰æ³¨æ„åŠ›è·¯å¾„ï¼Œå¹¶å®ç°æƒé‡ remap ä¸ Qâ€‘Kâ€‘Vã€gateâ€‘up èåˆé€»è¾‘ã€‚  
- ä¸ºæ¨¡å‹é…ç½®æ–°å¢ `embedding_size` è¦†ç›–ä¸ `is_causal=False` æ ‡è®°ã€‚  
- æ›´æ–°æ¨¡å‹æ³¨å†Œè¡¨ã€é…ç½®æ˜ å°„ã€`model.py` ä¸­çš„ `embedding_size` è¯»å–ã€‚  
- æ–°å¢æµ‹è¯•ï¼šMTEB åŸºå‡†è¯„åˆ†ä¸å¯¹é½ HuggingFace æ¨ç†çš„æ­£ç¡®æ€§éªŒè¯ï¼Œæ³¨å†Œè¡¨ä¸­åŠ å…¥ç¤ºä¾‹æ¨¡å‹ä¿¡æ¯ã€‚  

**ğŸ¯ å½±å“èŒƒå›´**  
- **æ¨¡å‹åŠ è½½**ï¼šæ‰€æœ‰ä½¿ç”¨ `VoyageQwen3BidirectionalEmbedModel` çš„æ¨ç†å®ä¾‹ä¼šèµ°æ–°çš„æƒé‡èåˆè·¯å¾„ï¼Œè‹¥æœªä½¿ç”¨ `enforce_eager=True` å¯èƒ½è§¦å‘ CUDAâ€‘graph æ•è·é”™è¯¯ã€‚  
- **æ¨¡å‹é…ç½®**ï¼š`VllmConfig.embedding_size` ç°åœ¨ä¼šä¼˜å…ˆè¯»å– HF é…ç½®ä¸­çš„ `embedding_size`ï¼Œå¯¹å·²æœ‰æ¨¡å‹ä¿æŒå…¼å®¹ã€‚  
- **æ–‡æ¡£ä¸æµ‹è¯•**ï¼šæ–‡æ¡£ä¸ CI ç°åœ¨åŒ…å«è¯¥æ¨¡å‹çš„ç¤ºä¾‹ã€‚  

**ğŸ’¡ å…³æ³¨å»ºè®®**  
1. **æƒé‡èåˆ**ï¼šç¡®è®¤ `q_proj/k_proj/v_proj` ä¸ `gate_proj/up_proj` åœ¨ä¸åŒç‰ˆæœ¬çš„ HF checkpointï¼ˆä¾‹å¦‚åˆ†å—æˆ– fused å½¢å¼ï¼‰ä»èƒ½è¢«æ­£ç¡®æ£€æµ‹å¹¶æ‹¼æ¥ï¼Œé˜²æ­¢å› å±‚å‘½åå·®å¼‚å¯¼è‡´åŠ è½½å¤±è´¥ã€‚  
2. **æ€§èƒ½**ï¼šEncoderâ€‘only æ³¨æ„åŠ›åœ¨ `vllm` ä¸­ä¼šèµ° `EncoderOnlyAttention`ï¼Œè¯·å…³æ³¨å…¶åœ¨å¤š GPUã€åˆ†ç‰‡åœºæ™¯ä¸‹çš„ååè¡¨ç°ï¼›è‹¥å‡ºç°æ˜¾å­˜æ³¢åŠ¨ï¼Œå¯è€ƒè™‘åœ¨ `AttentionType` åˆ¤æ–­ä¸­åŠ å…¥æ˜¾å¼çš„ `is_encoder_only` æ ‡è®°ã€‚  
3. **API å…¼å®¹**ï¼š`embedding_size` è¦†ç›–é€»è¾‘å·²åŠ å…¥ `model.py`ï¼Œå»ºè®®åœ¨å‘å¸ƒè¯´æ˜ä¸­æ³¨æ˜æ–°æ¨¡å‹éœ€è¦åœ¨ HF config ä¸­æä¾› `num_labels`ï¼ˆæˆ– `embedding_size`ï¼‰å­—æ®µï¼Œä»¥å…æ—§æ¨¡å‹è¯¯è¯»ã€‚  
4. **æµ‹è¯•è¦†ç›–**ï¼šå½“å‰ä»…è¦†ç›– `voyage-4-nano`ï¼Œå»ºè®®åœ¨åç»­å°†åŒç±»æ¨¡å‹ï¼ˆå¦‚ `voyage-2-large`ï¼‰åŠ å…¥ `MODELS` åˆ—è¡¨ï¼Œé˜²æ­¢æœªæ¥æƒé‡æ”¹åŠ¨æœªè¢«æ•è·ã€‚  
5. **CI é…ç½®**ï¼šç¡®ä¿ CI ç¯å¢ƒå®‰è£…äº† `trust_remote_code=True` çš„ä¾èµ–ï¼Œä»¥å…å› å®‰å…¨ç­–ç•¥å¯¼è‡´æ¨¡å‹ä¸‹è½½å¤±è´¥ã€‚  

æ•´ä½“æ¥çœ‹ï¼Œæœ¬æ¬¡æäº¤æˆåŠŸå°† Voyage ç³»åˆ—çš„åŒå‘åµŒå…¥æ¨¡å‹çº³å…¥ vLLMï¼Œä»£ç ç»“æ„æ¸…æ™°ï¼Œå»ºè®®åœ¨æ­£å¼å‘å¸ƒå‰å®Œæˆä¸Šè¿°ç»†èŠ‚éªŒè¯ã€‚

---

### [XPU]Replace pip in docker.xpu with uv pip (#31112)
**SHA**: `6550815` | ğŸ”— [æŸ¥çœ‹æäº¤](https://github.com/vllm-project/vllm/commit/6550815c3ad5fc20e6944483dd8a7a47c18b7c7d)

**ğŸ¯ å˜æ›´ç±»å‹**ï¼šåŠŸèƒ½å¢å¼º / é‡æ„  
**âš¡ é‡è¦ç¨‹åº¦**ï¼šğŸŸ¡ ä¸­  

**ğŸ“‹ å˜æ›´æ‘˜è¦**  
æœ¬æ¬¡æäº¤å°† XPU é•œåƒçš„ä¾èµ–å®‰è£…ä»ä¼ ç»Ÿ `pip` æ›¿æ¢ä¸ºæ›´å¿«ã€æ›´è½»é‡çš„åŒ…ç®¡ç†å™¨ **uv**ã€‚æ–°å¢äº†è™šæ‹Ÿç¯å¢ƒåˆ›å»ºã€`UV_PYTHON_INSTALL_DIR`ã€ç¼“å­˜ç›®å½•ç­‰é…ç½®ï¼Œç»Ÿä¸€ä½¿ç”¨ `uv pip install` å®Œæˆæ‰€æœ‰ä¾èµ–ï¼ˆåŒ…æ‹¬ `arcticâ€‘inference`ã€tritonâ€‘xpuã€å¼€å‘/æµ‹è¯•ä¾èµ–ï¼‰çš„å®‰è£…ã€‚åŒæ—¶å°† `PIP_EXTRA_INDEX_URL`ã€`UV_EXTRA_INDEX_URL` ç­‰ç¯å¢ƒå˜é‡æ˜¾å¼æš´éœ²ï¼Œä»¥ä¿è¯ XPU ä¸“å±çš„ PyTorch wheel èƒ½è¢«æ­£ç¡®æ‹‰å–ã€‚

**ğŸ¯ å½±å“èŒƒå›´**  
- `docker/Dockerfile.xpu`ï¼ˆæ„å»ºé•œåƒçš„æ ¸å¿ƒï¼‰  
- ä¾èµ–å®‰è£…è„šæœ¬ï¼ˆ`requirements/*.txt`ã€`tools/install_nixl_from_source_ubuntu.py`ï¼‰  
- è¿è¡Œæ—¶ç¯å¢ƒå˜é‡ï¼ˆ`PATHã€VIRTUAL_ENVã€LD_LIBRARY_PATH`ï¼‰  
- CI/CD é•œåƒæ„å»ºæµç¨‹ï¼ˆç¼“å­˜ç›®å½•ä» `pip` åˆ‡æ¢ä¸º `uv`ï¼‰

**ğŸ’¡ å…³æ³¨å»ºè®®**  
1. **å…¼å®¹æ€§éªŒè¯**ï¼šuv ç‰ˆæœ¬åœ¨ä¸åŒåŸºç¡€é•œåƒä¸Šå¯èƒ½å­˜åœ¨ä¾èµ–å†²çªï¼Œå»ºè®®åœ¨ CI ä¸­åŠ å…¥ `uv --version` æ£€æŸ¥ï¼Œå¹¶å¯¹ `python3.12` ä¸ç³»ç»Ÿé»˜è®¤ `python3` çš„ç¬¦å·é“¾æ¥è¿›è¡ŒéªŒè¯ã€‚  
2. **ç¼“å­˜ä¸€è‡´æ€§**ï¼šæ„å»ºç¼“å­˜ç›®å½•å·²ä» `/root/.cache/pip` æ”¹ä¸º `/root/.cache/uv`ï¼Œç¡®ä¿æ—§ç¼“å­˜ä¸ä¼šè¢«è¯¯ç”¨ï¼›æœ€å¥½åœ¨ CI ä¸­æ·»åŠ  `--no-cache` é€‰é¡¹è¿›è¡Œä¸€æ¬¡å¹²å‡€æ„å»ºéªŒè¯ã€‚  
3. **ç´¢å¼•é…ç½®**ï¼š`UV_EXTRA_INDEX_URL` ä¸ `PIP_EXTRA_INDEX_URL` åŒæ—¶è®¾ç½®ï¼Œå¯é¿å… uv æœªè¯†åˆ« `--extra-index-url` çš„æƒ…å†µï¼›è‹¥åç»­éœ€è¦æ·»åŠ ç§æœ‰ wheelï¼Œè®°å¾—åŒæ­¥æ›´æ–°ä¸¤è€…ã€‚  
4. **è¿è¡Œæ—¶è·¯å¾„**ï¼š`ENV PATH="/root/.local/bin:$PATH"` ä¸ `ENV PATH="$VIRTUAL_ENV/bin:$PATH"` çš„é¡ºåºä¼šå½±å“å…¨å±€ `pip`/`uv` è°ƒç”¨ï¼Œç¡®ä¿é•œåƒå¯åŠ¨è„šæœ¬ï¼ˆ`.bashrc`ï¼‰ä¸å†è¦†ç›–æ­¤é¡ºåºã€‚  
5. **å…¼å®¹æ—§é•œåƒ**ï¼šå¦‚æœæœ‰ä¸‹æ¸¸é¡¹ç›®ä»åŸºäºæ—§ `Dockerfile.xpu`ï¼Œè¯·æä¾›è¿ç§»æŒ‡å—ï¼ˆå¦‚ `pip install uv` çš„å…¼å®¹å±‚ï¼‰ï¼Œé¿å…æ„å¤–çš„æ„å»ºå¤±è´¥ã€‚  

æ•´ä½“æ¥çœ‹ï¼Œæ­¤æ”¹åŠ¨å¯æ˜¾è‘—æå‡ XPU é•œåƒçš„æ„å»ºé€Ÿåº¦å’Œå¯é‡å¤æ€§ï¼Œä½†éœ€è¦åœ¨æŒç»­é›†æˆå’Œæœ¬åœ°è°ƒè¯•ä¸­å……åˆ†éªŒè¯ uv ä¸ç³»ç»Ÿä¾èµ–çš„å…¼å®¹æ€§ã€‚

---

### [XPU][4/N] add mxfp4 moe model support (#33679)
**SHA**: `7439e4f` | ğŸ”— [æŸ¥çœ‹æäº¤](https://github.com/vllm-project/vllm/commit/7439e4f41b1f877e088d1b8c9ce4f2847c59423f)

**ğŸ¯ å˜æ›´ç±»å‹**ï¼šåŠŸèƒ½å¢å¼ºï¼ˆä¸º XPU å¹³å°æ–°å¢ MXFP4â€¯MoE æ”¯æŒï¼‰  
**âš¡ é‡è¦ç¨‹åº¦**ï¼šğŸŸ¡ ä¸­  
**ğŸ“‹ å˜æ›´æ‘˜è¦**ï¼š  
1. å°†åŸå…ˆä»…é’ˆå¯¹ Intelâ€¯IPEX çš„ `IpexMxfp4MoEMethod` é‡å‘½åå¹¶æ”¹å†™ä¸º `XpuMxfp4MoEMethod`ï¼Œåœ¨ `get_quant_method` ä¸­åˆ‡æ¢åˆ°è¯¥å®ç°ã€‚  
2. åˆ é™¤å¯¹ `intel_extension_for_pytorch` çš„ç¡¬ä¾èµ–ï¼Œ`process_weights_after_loading` ç›´æ¥ `pass`ã€‚  
3. åœ¨ `apply_monolithic` ä¸­æ”¹ä¸ºè°ƒç”¨ XPU ä¸“ç”¨çš„ `xpu_fused_moe` æ¥å£ï¼Œå¹¶è‡ªè¡Œå®ç° topâ€‘k è·¯ç”±çš„ TensorOpsï¼ˆ`_moe_C`ï¼‰ã€‚  

**ğŸ¯ å½±å“èŒƒå›´**ï¼š  
- `vllm/model_executor/layers/quantization/mxfp4.py`ï¼ˆæ ¸å¿ƒé‡åŒ–å±‚ï¼‰  
- ä¾èµ– MXFP4â€¯MoE çš„æ¨¡å‹åŠ è½½ä¸æ¨ç†è·¯å¾„ï¼ˆæ‰€æœ‰ä½¿ç”¨ `FusedMoE` çš„æ¨¡å‹ï¼‰  
- XPU ç¯å¢ƒï¼ˆéœ€è¦ `vllm_xpu_kernels` ä¸å¯¹åº”çš„ C++/CUDAâ€¯/â€¯XPU OPï¼‰  

**ğŸ’¡ å…³æ³¨å»ºè®®**  
1. **æƒé‡æ ¼å¼**ï¼šåŸ IPEX å®ç°ä¼šæŠŠ `w13`/`w2` æƒé‡ view ä¸º `int32` å¹¶æ„é€  `ipex_fusion`ï¼Œç°åœ¨ `process_weights_after_loading` ç›´æ¥è·³è¿‡ï¼Œå¯èƒ½å¯¼è‡´æƒé‡ä»ä¿æŒ `float32`ï¼Œéœ€è¦åœ¨ XPU kernel ä¸­ç¡®è®¤æ¥å—çš„ dtypeï¼ˆ`int32`â€¯/â€¯`float16`ï¼‰å¹¶åœ¨åŠ è½½ååšç›¸åº”è½¬æ¢ã€‚  
2. **åç«¯å…¼å®¹**ï¼š`get_quant_method` ä»ä¿ç•™ `Mxfp4MoEMethod` åˆ†æ”¯ç”¨äºéâ€‘XPU å¹³å°ï¼Œç¡®ä¿ `is_xpu()` åˆ¤æ–­å‡†ç¡®ï¼Œé¿å…è¯¯é€‰ XPU å®ç°å¯¼è‡´ç¼ºå¤±çš„ IPEX ä¾èµ–é”™è¯¯ã€‚  
3. **è·¯ç”±ç®—å­**ï¼šæ–°å¢çš„ `_moe_C.fused_grouped_topk` ä¸ `topk_softmax` ä¾èµ–è‡ªå®šä¹‰ C++/XPU OPï¼Œå»ºè®®åŠ å…¥å•å…ƒæµ‹è¯•è¦†ç›–ä¸åŒ `use_grouped_topk`ã€`top_k`ã€`renormalize` ç­‰åˆ†æ”¯ï¼ŒéªŒè¯è¾“å‡ºå½¢çŠ¶ä¸æ•°å€¼ä¸ IPEX å®ç°ä¿æŒä¸€è‡´ã€‚  
4. **æ¿€æ´»é™å®š**ï¼šå¼‚å¸¸ä¿¡æ¯ä»å†™ â€œXPU MXFP4 MoEâ€ï¼Œå¦‚æœåç»­æ”¯æŒå…¶ä»–æ¿€æ´»ï¼Œéœ€è¦åŒæ­¥æ›´æ–°ã€‚  
5. **æ–‡æ¡£ä¸ä¾èµ–**ï¼šåœ¨ README/CHANGELOG ä¸­æ³¨æ˜æ–°å¢ `vllm_xpu_kernels` åŒ…çš„å®‰è£…æ–¹å¼åŠå…¼å®¹çš„ XPU é©±åŠ¨ç‰ˆæœ¬ï¼›åŒæ—¶åœ¨ `setup.py` æˆ– `requirements.txt` ä¸­åŠ å…¥å¯é€‰ä¾èµ–å£°æ˜ã€‚  

æ€»ä½“æ¥çœ‹ï¼Œæ”¹åŠ¨ä¸º XPU æ·»åŠ äº† MXFP4â€¯MoE çš„å®Œæ•´è·¯å¾„ï¼Œå»é™¤äº† IPEX ç»‘å®šï¼Œæå‡äº†å¹³å°é€šç”¨æ€§ã€‚ä½†éœ€è¦ç¡®ä¿æƒé‡é¢„å¤„ç†ã€è·¯ç”±ç®—å­ä»¥åŠæ¿€æ´»å…¼å®¹æ€§å¾—åˆ°å……åˆ†æµ‹è¯•ï¼Œä»¥å…åœ¨ XPU ç¯å¢ƒä¸‹å‡ºç°ä¸å¯é¢„æµ‹çš„æ•°å€¼é”™è¯¯æˆ–æ€§èƒ½å›é€€ã€‚

---

### fix(ROCm): Make flash_attn import optional in MLA attention (#33511)
**SHA**: `20d7454` | ğŸ”— [æŸ¥çœ‹æäº¤](https://github.com/vllm-project/vllm/commit/20d7454c9bb0c2de7f59863f5030e5f494cab178)

**ğŸ¯ å˜æ›´ç±»å‹**ï¼šBug ä¿®å¤  
**âš¡ é‡è¦ç¨‹åº¦**ï¼šğŸŸ¡ ä¸­  

**ğŸ“‹ å˜æ›´æ‘˜è¦**  
- å°† MLA æ³¨æ„åŠ›ä¸­å¯¹ `flash_attn` çš„å¯¼å…¥æ”¹ä¸ºåœ¨ ROCm ç¯å¢ƒä¸‹å¯é€‰ï¼Œé˜²æ­¢åœ¨ç¼ºå¤± `flash_attn` åŒ…æ—¶ç›´æ¥å¯¼å…¥å¤±è´¥ã€‚  
- è‹¥ ROCm ä¸Šä»æœªå®‰è£… `flash_attn`ï¼Œä¼šåœ¨è¿è¡Œæ—¶æŠ›å‡ºæ˜ç¡®çš„ `RuntimeError` å¹¶ç»™å‡ºä½¿ç”¨ `--attention-backend ROCM_AITER_MLA` çš„å»ºè®®ã€‚  

**ğŸ¯ å½±å“èŒƒå›´**  
- `vllm/model_executor/layers/attention/mla_attention.py`ï¼ˆMLA attention å®ç°ï¼‰  
- ä¸å¹³å°æ£€æµ‹ (`current_platform.is_rocm`) å’Œæ—¥å¿— (`logger`) äº¤äº’çš„è·¯å¾„  

**ğŸ’¡ å…³æ³¨å»ºè®®**  
1. **æµ‹è¯•**ï¼šåœ¨ ROCm ç¯å¢ƒåˆ†åˆ«éªŒè¯ï¼ˆâ‘  å®‰è£… `flash_attn`ã€â‘¡ ä¸å®‰è£…ï¼‰ä¸¤ç§æƒ…å†µï¼Œç¡®ä¿ï¼š
   - å®‰è£…æ—¶èµ° FlashAttention è·¯å¾„ï¼ŒåŠŸèƒ½æ­£å¸¸ã€‚  
   - æœªå®‰è£…æ—¶æŠ›å‡ºé¢„æœŸé”™è¯¯è€Œéæå‰çš„ ImportErrorã€‚  
2. **æ–‡æ¡£**ï¼šåœ¨éƒ¨ç½²æŒ‡å—æˆ– README ä¸­è¡¥å…… â€œROCm ä½¿ç”¨ MLA æ—¶ï¼Œéœ€è¦æ‰‹åŠ¨å®‰è£… `flash_attn` æˆ–åˆ‡æ¢åˆ° `ROCM_AITER_MLA` åç«¯â€ã€‚  
3. **å…¼å®¹æ€§**ï¼šç¡®è®¤ CUDA ç¯å¢ƒä»ä½¿ç”¨åŸæœ‰çš„ `vllm_flash_attn`ï¼Œä¸å—æ­¤æ”¹åŠ¨å½±å“ã€‚  
4. **æ—¥å¿—**ï¼š`logger.debug` åªåœ¨ ROCm ä¸”ç¼ºå°‘ `flash_attn` æ—¶è§¦å‘ï¼Œé¿å…åœ¨éè°ƒè¯•æ¨¡å¼äº§ç”Ÿå™ªå£°ã€‚  

é€šè¿‡ä»¥ä¸Šæ£€æŸ¥ï¼Œå¯ç¡®ä¿è¯¥ä¿®å¤åœ¨ä¸åŒç¡¬ä»¶å¹³å°ä¸Šä¿æŒç¨³å®šä¸”æ˜“äºæ’æŸ¥ã€‚

---

### [Perf] Disable clean_logits in deepgemm fp8_mqa_logits kernel (#33568)
**SHA**: `79028d4` | ğŸ”— [æŸ¥çœ‹æäº¤](https://github.com/vllm-project/vllm/commit/79028d438859162841d35bbf2a91eaa8236733fa)

**ğŸ¯ å˜æ›´ç±»å‹**ï¼šæ€§èƒ½ä¼˜åŒ– / è½»é‡åŠŸèƒ½æ‰©å±•  
**âš¡ é‡è¦ç¨‹åº¦**ï¼šğŸŸ¡ ä¸­  

**ğŸ“‹ å˜æ›´æ‘˜è¦**  
- ä¸º `fp8_mqa_logits` ä¸ `fp8_paged_mqa_logits` å¢åŠ  `clean_logits: bool` å‚æ•°ï¼Œé»˜è®¤åœ¨å†…éƒ¨è°ƒç”¨æ—¶ä¼  `False`ï¼Œå®ç° **å…³é—­ logitsâ€‘æ¸…é›¶ (â€‘inf å¡«å……)**ï¼Œä»¥æ¶ˆé™¤ä¸å¿…è¦çš„å†™æ“ä½œæå‡æ€§èƒ½ã€‚  
- ç›¸åº”åœ°åœ¨ `sparse_attn_indexer` ä¸­æ˜¾å¼ä¼ å…¥ `clean_logits=False`ã€‚  
- æµ‹è¯•å±‚é¢åŠ å…¥ `clean_logits` å‚æ•°çš„ç»„åˆæµ‹è¯•ï¼Œå¹¶åœ¨ `top_k_per_row` æµ‹è¯•ä¸­åŠ å…¥éšæœºæ•°ç§å­ç»Ÿä¸€ (`set_random_seed`) ä»¥åŠå¯¹ `clean_logits` ä¸º `True` æ—¶çš„ `-inf` å¡«å……é€»è¾‘è¿›è¡Œæ ¡éªŒã€‚  

**ğŸ¯ å½±å“èŒƒå›´**  
- **æ ¸å¿ƒè®¡ç®—**ï¼š`vllm/utils/deep_gemm.py`ã€`vllm/model_executor/layers/sparse_attn_indexer.py`ã€‚  
- **å•å…ƒæµ‹è¯•**ï¼š`tests/kernels/attention/test_deepgemm_attention.py`ã€`tests/kernels/test_top_k_per_row.py`ã€‚  

**ğŸ’¡ å…³æ³¨å»ºè®®**  
1. **å‘åå…¼å®¹**ï¼šå‡½æ•°ç­¾åå·²å˜æ›´ï¼Œå¤–éƒ¨ç›´æ¥è°ƒç”¨ `fp8_*_logits` çš„ä»£ç éœ€è¡¥å…… `clean_logits` å‚æ•°ï¼Œå»ºè®®åœ¨ README/API æ–‡æ¡£ä¸­æ³¨æ˜ã€‚  
2. **é»˜è®¤è¡Œä¸º**ï¼šå½“å‰å†…éƒ¨è°ƒç”¨ç»Ÿä¸€ä¼  `clean_logits=False`ï¼Œä¿æŒåŸæœ‰ â€œä¸æ¸…é›¶â€ è¡Œä¸ºï¼›è‹¥åç»­å¸Œæœ›æ¢å¤é»˜è®¤æ¸…é›¶ï¼Œéœ€åŒæ­¥ä¿®æ”¹é»˜è®¤å€¼å¹¶æ›´æ–°æ‰€æœ‰è°ƒç”¨ç‚¹ã€‚  
3. **æ­£ç¡®æ€§éªŒè¯**ï¼šå…³é—­æ¸…é›¶åï¼Œåç»­çš„ `masked_fill` å¿…é¡»ä»èƒ½å°†æœªå¡«å……åŒºåŸŸç½®ä¸º `-inf`ï¼ˆæˆ– 0ï¼‰ï¼Œæµ‹è¯•å·²è¦†ç›–ä¸¤ç§è·¯å¾„ï¼Œå»ºè®®åœ¨ CI ä¸­ä¿ç•™è¯¥ç»„åˆæµ‹è¯•ï¼Œä»¥é˜²æ­¢åç»­æ”¹åŠ¨ç ´åè¯¥é€»è¾‘ã€‚  
4. **æ€§èƒ½åŸºå‡†**ï¼šè¯·åœ¨ä¸åŒç®—å­å°ºå¯¸ã€SM90/SM100 ç¯å¢ƒä¸‹è·‘åŸºå‡†ï¼Œç¡®è®¤å…³é—­ `clean_logits` å¸¦æ¥çš„ååæå‡ç¬¦åˆé¢„æœŸï¼Œå¹¶è®°å½•æ•°å€¼å˜åŒ–ä¾›å›æ»šå‚è€ƒã€‚  
5. **ä»£ç å¯è¯»æ€§**ï¼š`clean_logits` å‚æ•°åœ¨è°ƒç”¨é“¾ä¸­æ˜¾å¼ä¼ é€’ï¼Œå·²ä¿æŒä¸€è‡´æ€§ï¼›è‹¥åç»­æ–°å¢å…¶å®ƒæ¸…ç†å¼€å…³ï¼Œè€ƒè™‘ä½¿ç”¨ç»Ÿä¸€çš„ `logits_cleaning` é…ç½®å¯¹è±¡ã€‚  

æ•´ä½“æ¥çœ‹ï¼Œæ­¤æ¬¡æ”¹åŠ¨èšç„¦åœ¨æ·±åº¦ GEMM FP8 è®¡ç®—çš„å†™å…¥å¼€é”€ï¼Œæ”¹åŠ¨èŒƒå›´å—æ§ä¸”å·²é€šè¿‡å‚æ•°åŒ–æµ‹è¯•è¦†ç›–ï¼Œé£é™©è¾ƒä½ã€‚ä»…éœ€æ³¨æ„æ–‡æ¡£åŒæ­¥å’Œå¤–éƒ¨ API è°ƒç”¨çš„å…¼å®¹æ€§ã€‚

---

### Adds padding and perf improvements to wvSplitK_fp8 (#33527)
**SHA**: `d5c4800` | ğŸ”— [æŸ¥çœ‹æäº¤](https://github.com/vllm-project/vllm/commit/d5c4800112c12bbcd4955858ef1b415c16ae16e7)

**å˜æ›´ç±»å‹**ï¼šåŠŸèƒ½å¢å¼º / æ€§èƒ½ä¼˜åŒ–  
**é‡è¦ç¨‹åº¦**ï¼šğŸŸ¡ ä¸­  

**æ ¸å¿ƒå˜æ›´**  
1. **wvSplitK_fp8 kernel**ï¼š  
   - æ–°å¢ `Kap`ã€`Kbp` å‚æ•°ä»¥æ”¯æŒå¯¹ Aã€B çŸ©é˜µçš„è¡Œ/åˆ— paddingï¼Œå®ç° *alignâ€‘toâ€‘256* çš„ LDS å…±äº«å†…å­˜æ‹·è´ (`__builtin_amdgcn_global_load_lds`) ä¸ AMDâ€‘GFX950â€¯ä¸“ç”¨è·¯å¾„ã€‚  
   - æ”¹å†™å¾ªç¯ä¸Šç•Œä¸º `Kap * N`ã€`Kbp`ï¼Œé¿å…è¶Šç•Œï¼Œå¹¶åœ¨ `__gfx950__` ä¸Šä½¿ç”¨æ›´é«˜æ•ˆçš„ LDSâ€‘loadã€‚  
   - ç”¨ `__builtin_amdgcn_mov_dpp` æ›¿æ¢æ‰‹å†™ `asm`ï¼Œæå‡è·¨ lane åŠ æ³•çš„å¯ç§»æ¤æ€§ä¸æŒ‡ä»¤è°ƒåº¦ã€‚  
   - åˆå¹¶ bias åŠ è½½ä¸ºä¸€æ¬¡æ€§å±€éƒ¨æ•°ç»„ `biases[N][YTILE]`ï¼Œæ¶ˆé™¤æ¯æ¬¡ä¹˜åŠ çš„æ¡ä»¶åˆ†æ”¯ã€‚  
   - `__syncthreads` å‰åŠ å…¥ `s_waitcnt vmcnt(0)` ç¡®ä¿æ‰€æœ‰å…¨å±€â€‘toâ€‘lds ä¼ è¾“å®Œæˆã€‚  
   - è°ƒæ•´ kernel è°ƒç”¨ç­¾åï¼š`wvSplitKQ(const Tensor& in_b, const Tensor& in_a, ...)`ï¼Œå‚æ•°é¡ºåºä¸ `scaled_mm` å¯¹é½ï¼Œå¹¶åœ¨ `rocm.py` ä¸­æ”¾å®½äº†å¯¹ `A.shape[0]` çš„é™åˆ¶ï¼ˆâ‰¤4ï¼‰ï¼Œæ‰©å¤§é€‚ç”¨èŒƒå›´ã€‚

2. **å•å…ƒæµ‹è¯•**ï¼š  
   - æ‰©å±• FP8 å‚æ•°ç»„åˆï¼ˆKã€Mã€N å¤šç§å¡«å……/é¢å¤– 16â€‘channel æƒ…å½¢ï¼‰ï¼ŒåŠ å…¥ `xnorm`ã€`padded_a/b`ã€`biased` å‚æ•°ï¼Œè¦†ç›– paddingã€biasã€å½’ä¸€åŒ–ç­‰åˆ†æ”¯ã€‚  
   - `pad_fp8` ç»Ÿä¸€åŒ–å¡«å……é€»è¾‘ï¼Œå»é™¤æ—§çš„ `pad_weights_fp8`ã€‚

3. **scaled_mm å®ç°**ï¼š  
   - åœ¨ `rocm_per_tensor_float_w8a8_scaled_mm_impl` ä¸­æ”¾å®½è¡Œæ•°åˆ¤å®š (`A.shape[0] <= 4`) å¹¶æ”¹ä¸ºæ£€æŸ¥ `B.shape[0] % 16 == 0`ï¼Œç¡®ä¿æ›´å¤šå½¢çŠ¶èµ° wvSplitK è·¯å¾„ã€‚

**å½±å“èŒƒå›´**  
- `csrc/rocm/skinny_gemms.cu`ï¼ˆæ ¸å¿ƒ GEMM kernelï¼‰  
- `vllm/model_executor/layers/quantization/kernels/scaled_mm/rocm.py`ï¼ˆå¯¹å¤–è°ƒç”¨ï¼‰  
- `tests/kernels/quantization/test_rocm_skinny_gemms.py`ï¼ˆæ–°æµ‹è¯•è¦†ç›–ï¼‰  

**å…³æ³¨å»ºè®®**  
- **å…¼å®¹æ€§**ï¼šç¡®è®¤æ—§çš„ `wvSplitKQ` è°ƒç”¨ï¼ˆå‚æ•°é¡ºåºï¼‰å·²å…¨éƒ¨è¿ç§»ï¼Œé˜²æ­¢è¿è¡Œæ—¶ç­¾åä¸åŒ¹é…ã€‚  
- **è¾¹ç•Œæ£€æŸ¥**ï¼š`Kap`ã€`Kbp` ä¸ LDS å¤§å°çš„å…³ç³»åœ¨æç«¯ shapeï¼ˆå¦‚é 256â€‘byte å¯¹é½ï¼‰ä¸‹ä»éœ€éªŒè¯ï¼Œé˜²æ­¢è¶Šç•Œè¯»å–ã€‚  
- **åŒæ­¥å®Œæ•´æ€§**ï¼š`s_waitcnt vmcnt(0)` åªåœ¨ GFX950 åˆ†æ”¯ååŠ å…¥ï¼Œè‹¥åœ¨å…¶ä»– GPU ä¸Šä»å‡ºç°åŠ è½½â€‘è®¡ç®—ç«äº‰ï¼Œå»ºè®®ç»Ÿä¸€ä½¿ç”¨ã€‚  
- **æ€§èƒ½åŸºå‡†**ï¼šå¯¹æ¯”åŸ `asm` ç‰ˆæœ¬ä¸æ–° `mov_dpp` ç‰ˆæœ¬åœ¨ä¸åŒ AMD GPUï¼ˆMI200ã€MI300ï¼‰ä¸Šçš„ååç‡ï¼Œç¡®ä¿æå‡ä¸å›é€€ã€‚  
- **æ–‡æ¡£**ï¼šåœ¨ `README`/`doc` ä¸­è¯´æ˜æ–°å¢çš„ padding å‚æ•°æ„ä¹‰ã€æœ€ä½³ `K` å¯¹é½æ–¹å¼ä»¥åŠ `bias` å¤„ç†æ–¹å¼ã€‚  

æ€»ä½“è€Œè¨€ï¼Œæ­¤æ¬¡æäº¤æ˜¾è‘—æå‡äº† FP8â€¯Splitâ€‘K GEMM åœ¨ ROCm ä¸Šçš„ååä¸å¯ç»´æŠ¤æ€§ï¼ŒåŒæ—¶æ‰©å±•äº†æ”¯æŒçš„å¼ é‡å½¢çŠ¶ã€‚è‹¥å®Œæˆä¸Šè¿°éªŒè¯ä¸æ–‡æ¡£è¡¥å…¨ï¼Œå¯å®‰å…¨åˆå…¥ä¸»çº¿ã€‚

---

### [Misc] Rename `translations` to `speech_to_text` for OAI serving component (#33904)
**SHA**: `20f5d18` | ğŸ”— [æŸ¥çœ‹æäº¤](https://github.com/vllm-project/vllm/commit/20f5d185a6f570b74ab403577cd4eabe44d14496)

**ğŸ¯ å˜æ›´ç±»å‹**ï¼šé‡æ„ / å…¶ä»–ï¼ˆæ¨¡å—ä¸å‘½åç»Ÿä¸€ï¼‰  
**âš¡ é‡è¦ç¨‹åº¦**ï¼šğŸŸ¡ ä¸­  
**ğŸ“‹ å˜æ›´æ‘˜è¦**ï¼šå°† OpenAI æœåŠ¡å™¨ä¸­åŸ `translations` å­æ¨¡å—å…¨éƒ¨æ›´åä¸º `speech_to_text`ï¼Œç»Ÿä¸€ APIã€åè®®ã€å®ç°æ–‡ä»¶çš„è·¯å¾„å’Œå¯¼å…¥è·¯å¾„ã€‚å¯¹åº”çš„è·¯ç”±æ³¨å†Œã€çŠ¶æ€åˆå§‹åŒ–ã€åè®®ç±»ä»¥åŠæœåŠ¡å®ç°å‡åŒæ­¥æ”¹åã€‚  

**ğŸ¯ å½±å“èŒƒå›´**  
- `vllm.entrypoints.openai.api_server` ä¸­çš„è·¯ç”±æ³¨å†Œä¸åˆå§‹åŒ–é€»è¾‘ã€‚  
- `vllm.entrypoints.openai.engine.serving`ã€`responses.utils` ç­‰å†…éƒ¨è°ƒç”¨çš„ `protocol` å¯¼å…¥ã€‚  
- `vllm.entrypoints.openai.speech_to_text`ï¼ˆåŸ translationsï¼‰ä¸‹çš„ `api_router.py`ã€`protocol.py`ã€`serving.py`ã€`speech_to_text.py` å››ä¸ªæ–‡ä»¶ã€‚  
- ä»»ä½•ä½¿ç”¨ `vllm.entrypoints.openai.translations.*` çš„å¤–éƒ¨ä»£ç ï¼ˆå¦‚è‡ªå®šä¹‰æ’ä»¶ã€ç¤ºä¾‹è„šæœ¬ï¼‰å°†å¤±æ•ˆã€‚  

**ğŸ’¡ å…³æ³¨å»ºè®®**  
1. **å…¼å®¹æ€§**ï¼šè‹¥å¸Œæœ›ä¿æŒå‘åå…¼å®¹ï¼Œè€ƒè™‘åœ¨ `vllm/entrypoints/openai/translations` ä¸­ä¿ç•™ä¸€ä¸ªè–„åŒ…è£…å±‚ï¼Œç›´æ¥å¯¼å…¥æ–°æ¨¡å—çš„å¯¹è±¡ï¼Œé¿å…çªå‘ `ImportError`ã€‚  
2. **æ–‡æ¡£æ›´æ–°**ï¼šæ‰€æœ‰ READMEã€API å‚è€ƒã€ç¤ºä¾‹è„šæœ¬ä¸­å‡ºç°çš„ `translations` åç§°éœ€åŒæ­¥æ”¹ä¸º `speech_to_text`ï¼Œå¹¶åœ¨è¿ç§»æŒ‡å—ä¸­æ˜ç¡®è¯´æ˜ã€‚  
3. **æµ‹è¯•è¦†ç›–**ï¼šç¡®è®¤å•å…ƒ/é›†æˆæµ‹è¯•ç”¨ä¾‹å·²æ›´æ–°å¯¹åº” import è·¯å¾„ï¼Œå°¤å…¶æ˜¯æ¶‰åŠ `transcription` / `translation` ä»»åŠ¡çš„ Endâ€‘toâ€‘End æµ‹è¯•ã€‚  
4. **CI æ£€æŸ¥**ï¼šåŠ å…¥ CI æ­¥éª¤æ£€æµ‹æ—§è·¯å¾„æ˜¯å¦ä»è¢«å¼•ç”¨ï¼Œé˜²æ­¢é—æ¼å¯¼è‡´å‘å¸ƒåè¿è¡Œæ—¶é”™è¯¯ã€‚  

æ€»ä½“è€Œè¨€ï¼Œæ­¤æ¬¡æ”¹åæå‡äº†æ¦‚å¿µæ¸…æ™°åº¦ï¼Œä½†éœ€æ³¨æ„å‘åå…¼å®¹å’Œæ–‡æ¡£åŒæ­¥ï¼Œé¿å…å›  import è·¯å¾„æ”¹å˜å¯¼è‡´ç”¨æˆ·ä»£ç ç ´è£‚ã€‚

---

### [Models] Consolidate Deepseek-OCR2 processor (#33909)
**SHA**: `87d0d17` | ğŸ”— [æŸ¥çœ‹æäº¤](https://github.com/vllm-project/vllm/commit/87d0d17ab583740bce777f334a6281edf9822e78)

**ğŸ¯ å˜æ›´ç±»å‹**ï¼šåŠŸèƒ½å¢å¼º / é‡æ„  
**âš¡ é‡è¦ç¨‹åº¦**ï¼šğŸŸ¡ ä¸­  

**ğŸ“‹ å˜æ›´æ‘˜è¦**  
1. å°†åŸæœ‰çš„ `DeepseekOCR2Processor` åˆå¹¶è¿› `DeepseekOCRProcessor`ï¼Œé€šè¿‡ `strategy` å‚æ•°åŒºåˆ† OCRâ€‘v1 ä¸ OCRâ€‘v2 çš„è¡Œä¸ºã€‚  
2. ä¸º `deepseek_ocr` ä¸ `deepseek_ocr2` ä¸¤ä¸ªæ¨¡å‹åˆ†åˆ«è®¾ç½®ä¸“å± `IMAGE_SIZE`ï¼ˆ640 / 768ï¼‰ï¼Œå¹¶åœ¨ `get_hf_processor` ä¸­æ³¨å…¥å¯¹åº”çš„ `image_sizeã€base_sizeã€crop_modeã€strategy` é…ç½®ã€‚  
3. åœ¨ `DeepseekOCRProcessor.__init__` ä¸­åŠ å…¥ `image_sizeã€base_sizeã€strategy` å‚æ•°ï¼Œå»é™¤ç¡¬ç¼–ç å¸¸é‡ï¼›`tokenize_with_images` æ ¹æ® `strategy` åŠ¨æ€è®¡ç®—åŸºç¡€ token æ•°é‡ (`v1` ä¸ºä¸‰è§’å½¢å¸ƒå±€ï¼Œ`v2` ä¸ºçŸ©å½¢å¸ƒå±€)ã€‚  
4. åˆ é™¤å·²åºŸå¼ƒçš„ `deepseek_ocr2.py`ï¼Œå®ç°ä»£ç ç»Ÿä¸€ç®¡ç†ã€‚  

**ğŸ¯ å½±å“èŒƒå›´**  
- `vllm/model_executor/models/deepseek_ocr.py`ã€`deepseek_ocr2.py`ï¼ˆæ¨¡å‹åŠ è½½è·¯å¾„ï¼‰  
- `vllm/transformers_utils/processors/deepseek_ocr.py`ï¼ˆæ ¸å¿ƒ processor å®ç°ï¼‰  
- ç›¸å…³çš„é…ç½®è¯»å– (`DeepseekVLV2Config`) ä¸æ¨¡å‹å…¥å£ (`deepseek_ocr`ã€`deepseek_ocr2`)  

**ğŸ’¡ å…³æ³¨å»ºè®®**  
1. **å…¼å®¹æ€§**ï¼šæ–°å¢ `strategy` å‚æ•°é»˜è®¤ä¸º `"v1"`ï¼Œä¿è¯æ—§æ¨¡å‹ä¸å—å½±å“ï¼›è‹¥ç”¨æˆ·è‡ªè¡Œè°ƒç”¨ processorï¼Œéœ€æ˜¾å¼ä¼ å…¥ `strategy="v2"` æ‰èƒ½å¾—åˆ° OCRâ€‘2 çš„ token ç»“æ„ã€‚  
2. **å•å…ƒæµ‹è¯•**ï¼šè¡¥å……ä¸¤å¥— tokenâ€‘è®¡æ•°æµ‹è¯•ï¼ˆv1ã€v2ï¼‰ï¼Œæ£€æµ‹ `num_tokens_base`ã€`local_row` é•¿åº¦æ˜¯å¦ç¬¦åˆå…¬å¼ï¼Œé˜²æ­¢å›å½’ã€‚  
3. **æ–‡æ¡£**ï¼šåœ¨æ¨¡å‹è¯´æ˜é¡µæ ‡æ˜ `image_size`ã€`base_size` ä¸ `strategy` çš„å¯¹åº”å…³ç³»ï¼Œé¿å…è¯¯ç”¨ 640/768 çš„é»˜è®¤å€¼ã€‚  
4. **æ€§èƒ½**ï¼š`tokenize_with_images` ä¸­çš„ `if not cropping:` åˆ†æ”¯ä»ä¼šåœ¨ `image_size` å¤§äºåŸé˜ˆå€¼æ—¶æ‰§è¡Œ resizeï¼Œç¡®è®¤åœ¨ v2 åœºæ™¯ä¸‹ä¸ä¼šäº§ç”Ÿä¸å¿…è¦çš„ resizeã€‚  
5. **å¼‚å¸¸å¤„ç†**ï¼š`assert strategy in ["v1", "v2"]` å·²åœ¨æ„é€ å‡½æ•°ä¸­åŠ å…¥ï¼Œå»ºè®®åœ¨ `get_hf_processor` é‡Œä¹Ÿæ£€æµ‹ä¼ å…¥çš„ `strategy`ï¼Œç»™å‡ºæ›´å‹å¥½çš„é”™è¯¯ä¿¡æ¯ã€‚  

æ€»ä½“æ¥çœ‹ï¼Œæ­¤æ¬¡æ”¹åŠ¨å°†ä¸¤å¥— OCR å¤„ç†é€»è¾‘ç»Ÿä¸€ï¼Œä»£ç å¯ç»´æŠ¤æ€§æå‡æ˜æ˜¾ï¼Œåªè¦å®Œå–„æµ‹è¯•å’Œæ–‡æ¡£ï¼Œå³å¯å¹³æ»‘è¿ç§»è‡³æ–°å®ç°ã€‚

---

### [Moe Refactor] Make Inplace Flag for FusedMoEModularKernel part of the constructor (#33375)
**SHA**: `a57c822` | ğŸ”— [æŸ¥çœ‹æäº¤](https://github.com/vllm-project/vllm/commit/a57c8228ffb3ff82b983b32b71ff62a837255129)

**å˜æ›´æ¦‚è¿°**  
æœ¬æ¬¡ PR å°† MoEâ€¯kernel çš„ **inplace** æ§åˆ¶æƒä»è°ƒç”¨æ–¹çš„ `forward` å‚æ•°è¿ç§»åˆ°å¯¹è±¡æ„é€ æ—¶çš„æ„é€ å‚æ•°ï¼Œå¹¶åœ¨ `FusedMoEConfig` ä¸­æ–°å¢ `disable_inplace` æ ‡å¿—ã€‚å¤§é‡ `allow_inplace` å±æ€§è¢«åˆ é™¤ï¼Œç›¸å…³ä»£ç ç»Ÿä¸€æ”¹ä¸º `inplace` å‚æ•°æˆ– `disable_inplace` åˆ¤æ–­ã€‚æ‰€æœ‰æµ‹è¯•ç”¨ä¾‹å·²æ”¹ä¸ºåœ¨åˆ›å»º `FusedMoEModularKernel` æ—¶æ˜¾å¼ä¼ å…¥ `inplace=False`ï¼ˆæˆ–é€šè¿‡ `disable_inplace` æ§åˆ¶ï¼‰ï¼Œå®ç°äº†å¯¹ inplace è¡Œä¸ºçš„ç»Ÿä¸€ç®¡ç†ã€‚

**æ ¸å¿ƒå½±å“æ¨¡å—**  
- `vllm/model_executor/layers/fused_moe/*`ï¼š`modular_kernel.py`, `fused_moe.py`, `fused_moe_method_base.py`, `fused_moe_modular_method.py`, `layer.py` ç­‰å…¥å£ç»Ÿä¸€ä½¿ç”¨ `inplace` æ„é€ å‚æ•°ã€‚  
- `vllm/model_executor/layers/fused_moe/config.py`ï¼šæ–°å¢ `disable_inplace` é…ç½®é¡¹ã€‚  
- é‡åŒ–å­æ¨¡å—ï¼ˆawq_marlinã€bitsandbytesã€compressed_tensorsã€fp8ã€mxfp4ã€quark ç­‰ï¼‰å‡æ”¹ä¸ºä½¿ç”¨ `not self.moe.disable_inplace` ä¼ é€’ inplace æ ‡å¿—ã€‚  
- æµ‹è¯•ç›®å½• (`tests/kernels/moe/*`) å¤§å¹…ä¿®æ”¹ï¼Œä»¥é€‚é…æ–°çš„æ„é€ ç­¾åã€‚  
- ç›¸å…³å·¥å…·å‡½æ•° `make_fp8_moe_kernel`ã€`make_unquantized_moe_kernel` ç­‰çš„è¿”å›ç­¾åç”± `(kernel, use_inplace)` â†’ `kernel`ï¼Œåˆ é™¤äº†å¤–éƒ¨å¯¹ inplace çš„æ˜¾å¼åˆ¤æ–­ã€‚

**å¯èƒ½é£é™©**  
1. **å‘åå…¼å®¹æ€§**ï¼šåŸæœ‰ä»£ç ä»å¯èƒ½åœ¨ `forward(..., inplace=True)` è°ƒç”¨ `FusedMoEModularKernel`ï¼Œä½†ç°åœ¨ `forward` å·²ä¸æ¥å— `inplace` å‚æ•°ï¼Œè‹¥å¤–éƒ¨ä»ä¿ç•™æ­¤è°ƒç”¨ä¼šè§¦å‘ `TypeError`ã€‚  
2. **æ€§èƒ½å›é€€**ï¼šé»˜è®¤ `disable_inplace=True`ï¼ˆå³å¼ºåˆ¶ä¸ä½¿ç”¨ inplaceï¼‰ï¼Œåœ¨æŸäº›åœºæ™¯ä¸‹ä¼šå¯¼è‡´é¢å¤–çš„æ˜¾å­˜æ‹·è´å’Œè®¡ç®—å¼€é”€ã€‚éœ€åœ¨éƒ¨ç½²é…ç½®ä¸­æ˜¾å¼å…³é—­ `disable_inplace` ä»¥ä¿æŒåŸæœ‰æ€§èƒ½ã€‚  
3. **å¹¶è¡Œ/å…±äº«ä¸“å®¶**ï¼š`modular_kernel.forward` ä¸­å¯¹ `self.shared_experts` è¿›è¡Œäº†æ–­è¨€ï¼Œç¡®ä¿åœ¨ `inplace=True` æ—¶ä¸ä½¿ç”¨å…±äº«ä¸“å®¶ã€‚è‹¥å·²æœ‰å…±äº«â€‘ä¸“å®¶çš„æ¨¡å‹å¼€å¯ inplaceï¼Œå¯èƒ½ä¼šè§¦å‘æ–­è¨€ã€‚  

**å»ºè®®**  
- **æ–‡æ¡£æ›´æ–°**ï¼šåœ¨ `README`ã€`cfg` ç¤ºä¾‹ä»¥åŠ API æ–‡æ¡£ä¸­è¯´æ˜ `FusedMoEConfig.disable_inplace` ä¸ `FusedMoEModularKernel(..., inplace=â€¦)` çš„æ–°ç”¨æ³•ï¼Œå¹¶æ ‡æ³¨é»˜è®¤è¡Œä¸ºã€‚  
- **å…¼å®¹å±‚**ï¼šè€ƒè™‘åœ¨ `FusedMoEModularKernel.forward` ä¸­ä¿ç•™ `inplace` å‚æ•°çš„å…¼å®¹è­¦å‘Šï¼ˆå¦‚ `DeprecationWarning`ï¼‰ï¼Œé˜²æ­¢è€ä»£ç ç›´æ¥å´©æºƒã€‚  
- **æµ‹è¯•è¦†ç›–**ï¼šç¡®ä¿åœ¨ CI ä¸­æ·»åŠ ä¸¤å¥—é…ç½®ï¼š`disable_inplace=False`ï¼ˆä¿æŒ inplaceï¼‰ä»¥åŠé»˜è®¤ `True`ï¼ŒéªŒè¯åŠŸèƒ½å’Œæ•°å€¼ä¸€è‡´æ€§ã€‚  
- **æ€§èƒ½åŸºå‡†**ï¼šæä¾›ä¸€ä»½å¼€å¯/å…³é—­ inplace çš„æ˜¾å­˜/åååŸºå‡†ï¼Œå¸®åŠ©ç”¨æˆ·æ ¹æ®ç¡¬ä»¶å’Œè´Ÿè½½å†³å®šæ˜¯å¦å…³é—­ã€‚  

æ€»ä½“è€Œè¨€ï¼Œæ­¤æ¬¡æ”¹åŠ¨ç»Ÿä¸€äº† inplace æ§åˆ¶ï¼Œæé«˜äº†é…ç½®å¯è¿½è¸ªæ€§ï¼Œä½†éœ€è¦æ³¨æ„å‘åå…¼å®¹å’Œé»˜è®¤æ€§èƒ½å›é€€çš„å½±å“ã€‚å»ºè®®å°½å¿«å®Œæˆæ–‡æ¡£å’Œå…¼å®¹å±‚çš„è¡¥é½ï¼Œä»¥å¹³æ»‘è¿ç§»ç°æœ‰ç”¨æˆ·ã€‚

---

### [Bugfix] Fix step3p5 parser when using mtp (#33690)
**SHA**: `82914d2` | ğŸ”— [æŸ¥çœ‹æäº¤](https://github.com/vllm-project/vllm/commit/82914d2ae8d0362be06700222f4cd4c5f6b0dc36)

**æ ¸å¿ƒæ”¹åŠ¨**  
1. **æ–°å¢ 1.4k è¡Œæµ‹è¯• `tests/tool_parsers/test_step3p5_tool_parser.py`**  
   - å®Œæ•´è¦†ç›–éæµå¼ã€æµå¼ã€å¼‚å¸¸ XMLï¼ˆç¼ºå°‘é—­åˆæ ‡ç­¾ã€å•å¼•å· JSONã€è·¨ token è¾¹ç•Œç­‰ï¼‰ä»¥åŠå¤š toolâ€‘callã€å†…å®¹äº¤å‰çš„åœºæ™¯ã€‚  
   - é€šè¿‡ `stream_delta_message_generator*` æ¨¡æ‹Ÿå¢é‡è§£ç ï¼ŒéªŒè¯ `Step3p5ToolParser` åœ¨æ¯ä¸€æ­¥çš„ `DeltaMessage` æ˜¯å¦æ­£ç¡®ã€‚

2. **`vllm/tool_parsers/step3p5_tool_parser.py` å…³é”®ä¿®å¤**  
   - åœ¨ `parse_single_streaming_chunks` ä¸­è®°å½•è¿›å…¥æ—¶çš„ `current_call_id` ä¸ `tool_call_index`ï¼Œè®¡ç®— **fallback_call_id**ã€‚  
   - åªåœ¨ *åŒä¸€æ¬¡è°ƒç”¨*ï¼ˆæˆ–åˆšæ–°å»ºçš„è°ƒç”¨ï¼‰ç»“æŸæ—¶æ‰è¡¥å…¨ `}`ã€å…³é—­ `</function>`ã€`</tool_call>`ï¼Œé˜²æ­¢åœ¨å¤š `<tool_call>` åœºæ™¯ä¸‹è¯¯å…³é—­åç»­è°ƒç”¨ã€‚  
   - æ‰€æœ‰åŸæœ‰ `self.current_call_id` åˆ¤å®šå…¨éƒ¨æ¢æˆ `fallback_call_id`ï¼Œç¡®ä¿å›é€€é€»è¾‘ä»…é’ˆå¯¹å½“å‰å—å¯¹åº”çš„è°ƒç”¨ç”Ÿæ•ˆã€‚

**å½±å“èŒƒå›´**  
- **æ¨¡å—**ï¼š`vllm/tool_parsers/step3p5_tool_parser.py`ï¼ˆæµå¼è§£æè·¯å¾„ï¼‰  
- **åŠŸèƒ½**ï¼šStepâ€‘3.5 æ¨¡å‹çš„å·¥å…·è°ƒç”¨è§£æï¼Œå°¤å…¶åœ¨è¿”å› **å¢é‡**ï¼ˆStreamingï¼‰æ—¶ã€‚  
- **æµ‹è¯•**ï¼šæ–°å¢çš„æµ‹è¯•æ–‡ä»¶å‡ ä¹æŠŠè¯¥è§£æå™¨çš„æ‰€æœ‰åˆ†æ”¯éƒ½è·‘é€šï¼Œå¯¹ CI æ—¶é•¿æœ‰æ˜¾è‘—æå‡ã€‚

**å»ºè®®ä¸æ³¨æ„äº‹é¡¹**  
1. **æ–‡æ¡£åŒ–**ï¼šåœ¨ä»£ç æ³¨é‡Šæˆ–ç±» docstring ä¸­è¯´æ˜ `fallback_call_id` çš„äº§ç”Ÿç†ç”±ã€é€‚ç”¨åœºæ™¯ä»¥åŠä½•æ—¶ä¸º `None`ï¼Œä¾¿äºåç»­ç»´æŠ¤ã€‚  
2. **ç±»å‹æç¤º**ï¼šä¸º `fallback_call_id: str | None` æ·»åŠ æ˜¾å¼ç±»å‹æ³¨è§£ï¼Œæå‡å¯è¯»æ€§ã€‚  
3. **æ€§èƒ½**ï¼š`fallback_call_id` çš„è®¡ç®—åœ¨æ¯ä¸ªå¢é‡å—éƒ½ä¼šæ‰§è¡Œï¼Œå¼€é”€æå°ï¼ˆå‡ æ¬¡æ¯”è¾ƒï¼‰ï¼Œæ— éœ€é¢å¤–ä¼˜åŒ–ã€‚  
4. **å›å½’é£é™©**ï¼šè¯¥æ”¹åŠ¨åªæ¶‰åŠæµå¼è·¯å¾„ï¼Œéæµå¼ `extract_tool_calls` ä¿æŒä¸å˜ã€‚å»ºè®®åœ¨å‘å¸ƒå‰è·‘ä¸€æ¬¡å…¨ä»“åº“çš„æ€§èƒ½åŸºå‡†ï¼Œç¡®è®¤æµå¼è§£ç çš„å»¶è¿Ÿæœªè¢«æ„å¤–æ”¾å¤§ã€‚  
5. **æµ‹è¯•ç»´æŠ¤**ï¼šæ–°å¢æµ‹è¯•æ–‡ä»¶ä½“ç§¯å¤§ï¼ˆâ‰ˆ1500 è¡Œï¼‰ï¼ŒCI æ—¶é—´ä¼šå¢é•¿ã€‚å¯ä»¥è€ƒè™‘å°†éƒ¨åˆ†å†—ä½™çš„ç»„åˆç”¨ `pytest.mark.parametrize` åˆå¹¶ï¼Œæˆ–åœ¨ CI ä¸Šå¼€å¯ä¸“é—¨çš„ â€œtoolâ€‘parserâ€ ç« èŠ‚ï¼Œä»¥å…å½±å“ä¸»çº¿è·‘å®Œçš„æ—¶é•¿ã€‚  
6. **å¼‚å¸¸å®¹é”™**ï¼šå½“å‰é€»è¾‘åœ¨æ‰¾ä¸åˆ° `fallback_call_id` æ—¶ä»ä¼šèµ°åŸæœ‰ `self.current_call_id` åˆ¤å®šï¼ˆå› ä¸º `fallback_call_id` ä¸º `None`ï¼‰ï¼Œè¿™åœ¨æç«¯ malformed è¾“å…¥ä¸‹å¯èƒ½å¯¼è‡´è¯¯é—­åˆã€‚å¯åœ¨ä»£ç ä¸­åŠ å…¥æ—¥å¿—/è­¦å‘Šï¼Œå¸®åŠ©å®šä½æ­¤ç±»å¼‚å¸¸ã€‚  

æ€»ä½“æ¥çœ‹ï¼Œæ­¤æ¬¡æäº¤ä¿®å¤äº† **å¤š toolâ€‘call åœºæ™¯ä¸‹çš„è¯¯é—­åˆ bug**ï¼Œå¹¶é€šè¿‡å¤§é‡å•å…ƒæµ‹è¯•éªŒè¯äº†å…¼å®¹æ€§ï¼Œé£é™©å¯æ§ï¼Œå»ºè®®åˆå¹¶ååœ¨æ­£å¼å‘å¸ƒå‰è¿›è¡Œä¸€æ¬¡å®Œæ•´çš„å›å½’æµ‹è¯•ã€‚

---

#### ğŸŸ¢ ä½é‡è¦åº¦å˜æ›´ (17)

### [FIX] guidance: use max(vocab_size, len(tokenizer)) for n_vocab (#33509)
**SHA**: `1fb0495` | ğŸ”— [æŸ¥çœ‹æäº¤](https://github.com/vllm-project/vllm/commit/1fb0495a727686750525ee294d2274f4ef36525b)

**ğŸ¯ å˜æ›´ç±»å‹**ï¼šä»£ç é‡æ„  
**âš¡ é‡è¦ç¨‹åº¦**ï¼šğŸŸ¢ ä½  
**ğŸ“‹ æ‘˜è¦**ï¼šåœ¨ `backend_guidance.py` ä¸­åˆ›å»º Guidance tokenizer æ—¶ï¼Œå°†è¯è¡¨å¤§å°æ”¹ä¸º `max(self.vocab_size, len(self.tokenizer))`ï¼Œé˜²æ­¢è¯è¡¨å°ºå¯¸ä¸è¶³å¯¼è‡´é”™è¯¯ã€‚

---

### Update `WeightTransferConfig` to be more standard like the others (#33989)
**SHA**: `51a7bda` | ğŸ”— [æŸ¥çœ‹æäº¤](https://github.com/vllm-project/vllm/commit/51a7bda6252dfff7aa2ab9e82a86914430034563)

**ğŸ¯ å˜æ›´ç±»å‹**ï¼šé…ç½®è°ƒæ•´  
**âš¡ é‡è¦ç¨‹åº¦**ï¼šğŸŸ¢ä½  
**ğŸ“‹ æ‘˜è¦**ï¼šç»Ÿä¸€ `WeightTransferConfig` å®ç°ï¼Œå»é™¤ `@dataclass`ï¼Œå¹¶åœ¨ `EngineArgs` ä¸­é€šè¿‡ `VllmConfig` è‡ªåŠ¨è·å–è¯¥é…ç½®ã€‚

---

### [CPU][BugFix] Fix loading of w8a8int models with bias (#33582)
**SHA**: `f79d9dc` | ğŸ”— [æŸ¥çœ‹æäº¤](https://github.com/vllm-project/vllm/commit/f79d9dce16781b403713b8813df04d57c053bdbf)

**ğŸ¯ å˜æ›´ç±»å‹**ï¼šä»£ç é‡æ„  
**âš¡ é‡è¦ç¨‹åº¦**ï¼šğŸŸ¢ä½  
**ğŸ“‹ æ‘˜è¦**ï¼šåœ¨ `dynamic_4bit.py` ä¸­ï¼Œå°†å¯¹ bias çš„åŸä½ç±»å‹è½¬æ¢æ”¹ä¸ºä½¿ç”¨ `replace_parameter` æ›¿æ¢ä¸º `torch.nn.Parameter`ï¼Œé¿å…åœ¨åŠ è½½ w8a8int æ¨¡å‹æ—¶å‡ºç°æ¢¯åº¦æˆ–å‚æ•°æ³¨å†Œé”™è¯¯ã€‚

---

### Bump HF Hub client to get bug fix (#33984)
**SHA**: `ba5cbbf` | ğŸ”— [æŸ¥çœ‹æäº¤](https://github.com/vllm-project/vllm/commit/ba5cbbf10763191049527833dfcee14af7eda22d)

**ğŸ¯ å˜æ›´ç±»å‹**ï¼šæ–‡æ¡£æ›´æ–°  
**âš¡ é‡è¦ç¨‹åº¦**ï¼šğŸŸ¢ä½  
**ğŸ“‹ æ‘˜è¦**ï¼šå°† `huggingface-hub` ä¾èµ–ä» 0.36.1 å‡çº§è‡³ 0.36.2ï¼Œä»¥è·å–æœ€æ–° bug ä¿®å¤ã€‚

---

### [PaddleOCR-VL] Add BC for transformers 5.0 config (#33976)
**SHA**: `233b26a` | ğŸ”— [æŸ¥çœ‹æäº¤](https://github.com/vllm-project/vllm/commit/233b26ab354d5c96de29f98c17d5f2ed10773782)

**ğŸ¯ å˜æ›´ç±»å‹**ï¼šä»£ç é‡æ„  
**âš¡ é‡è¦ç¨‹åº¦**ï¼šğŸŸ¢ä½  
**ğŸ“‹ æ‘˜è¦**ï¼šåœ¨ `paddleocr_vl.py` ä¸­åŠ å…¥å¯¹ Transformers 5.0 é…ç½®çš„å…¼å®¹å¤„ç†ï¼Œè‹¥ `hf_config` åŒ…å« `text_config`ï¼Œåˆ™å»é™¤å†²çªå­—æ®µååˆå¹¶åˆ°ä¸»é…ç½®ï¼Œç¡®ä¿æ¨¡å‹åŠ è½½ä¸å—æ–°ç»“æ„å½±å“ã€‚

---

### Fix `main` pre-commit (#33975)
**SHA**: `6d8d34b` | ğŸ”— [æŸ¥çœ‹æäº¤](https://github.com/vllm-project/vllm/commit/6d8d34be6dcaff0f5aa6de245adffc2bac5b2d3e)

**ğŸ¯ å˜æ›´ç±»å‹**ï¼šä»£ç é‡æ„  
**âš¡ é‡è¦ç¨‹åº¦**ï¼šğŸŸ¢ä½  
**ğŸ“‹ æ‘˜è¦**ï¼šå°† `vllm/model_executor/models/voyage.py` ä¸­çš„ `import re` æ›¿æ¢ä¸º `import regex as re`ï¼Œä»¥é€šè¿‡ preâ€‘commit æ£€æŸ¥ï¼ŒåŠŸèƒ½ä¿æŒä¸å˜ã€‚

---

### [CPU] Add BF16 Kernel type for s390x (#33788)
**SHA**: `ac04dd3` | ğŸ”— [æŸ¥çœ‹æäº¤](https://github.com/vllm-project/vllm/commit/ac04dd374f996f8df960933fa076bb5ea53c0c2a)

**ğŸ¯ å˜æ›´ç±»å‹**ï¼šä»£ç é‡æ„  
**âš¡ é‡è¦ç¨‹åº¦**ï¼šğŸŸ¢ä½  
**ğŸ“‹ æ‘˜è¦**ï¼šåœ¨ `csrc/cpu/mla_decode.cpp` ä¸­ä¸º IBM s390x æ¶æ„æ–°å¢å¯¹ BF16ï¼ˆBFloat16ï¼‰æ•°æ®ç±»å‹çš„ Kernel å‘é‡å®ç°ï¼Œå®šä¹‰äº†ç›¸åº”çš„åŠ è½½ä¸è®¡ç®—å‘é‡ç±»å‹ï¼Œä»¥æ”¯æŒè¯¥å¹³å°çš„ BF16 åŠ é€Ÿã€‚

---

### [Misc] Update code for encoder-decoder models (#33900)
**SHA**: `035a6cb` | ğŸ”— [æŸ¥çœ‹æäº¤](https://github.com/vllm-project/vllm/commit/035a6cb09a3f7076d2e79db1af3070325230bb59)

**ğŸ¯ å˜æ›´ç±»å‹**ï¼šä»£ç é‡æ„  
**âš¡ é‡è¦ç¨‹åº¦**ï¼šğŸŸ¢ä½  
**ğŸ“‹ æ‘˜è¦**ï¼šæ›´æ–° encoderâ€‘decoder ç¤ºä¾‹é“¾æ¥ï¼›æ–°å¢æ–­è¨€ç¡®ä¿å¤šæ¨¡æ€é¢„ç®—ä»…åŒ…å«å•ä¸€æ¨¡æ€ï¼›å®Œå–„ç©ºå€¼æ£€æŸ¥ä»¥é˜²æ­¢ `mm_budget` ä¸º `None` æ—¶å´©æºƒã€‚

---

### [Docs] Add reo analytics (#33957)
**SHA**: `5819ca8` | ğŸ”— [æŸ¥çœ‹æäº¤](https://github.com/vllm-project/vllm/commit/5819ca8944af4f7dcbac3c6b73179f760e05910d)

**ğŸ¯ å˜æ›´ç±»å‹**ï¼šæ–‡æ¡£æ›´æ–°  
**âš¡ é‡è¦ç¨‹åº¦**ï¼šğŸŸ¢ ä½  
**ğŸ“‹ æ‘˜è¦**ï¼šåœ¨ `docs/mkdocs/javascript/` æ–°å¢ `reo.js` è„šæœ¬å¹¶åœ¨ `mkdocs.yaml` ä¸­å¼•å…¥ï¼Œå®ç°æ–‡æ¡£é¡µé¢çš„ Reo.Dev æ•°æ®è¿½è¸ªã€‚

---

### [Bugfix] Fix DeepSeek v3.2 tokenizer outputting None issue (#33832)
**SHA**: `91a07ff` | ğŸ”— [æŸ¥çœ‹æäº¤](https://github.com/vllm-project/vllm/commit/91a07ff6187e7308794b2a4863ab9e1f821ed464)

**ğŸ¯ å˜æ›´ç±»å‹**ï¼šå…¶ä»–  
**âš¡ é‡è¦ç¨‹åº¦**ï¼šğŸŸ¢ä½  
**ğŸ“‹ æ‘˜è¦**ï¼šåœ¨ `detokenize_incrementally` ä¸­åŠ å…¥å¯¹ `None` token çš„æ£€æµ‹ä¸æ›¿æ¢ï¼Œé˜²æ­¢ DeepSeekâ€¯v3.2 åˆ†è¯å™¨åœ¨ä½¿ç”¨ç¼ºå¤±è¯è¡¨æ—¶è¿”å› `None` å¯¼è‡´é”™è¯¯ã€‚

---

### [Minor] Sort safetensors files to ensure deterministic loading order (#33491)
**SHA**: `42d5d70` | ğŸ”— [æŸ¥çœ‹æäº¤](https://github.com/vllm-project/vllm/commit/42d5d705f93b254179e062003e8504fbe04f1b30)

**ğŸ¯ å˜æ›´ç±»å‹**ï¼šä»£ç é‡æ„  
**âš¡ é‡è¦ç¨‹åº¦**ï¼šğŸŸ¢ä½  
**ğŸ“‹ æ‘˜è¦**ï¼šæ–°å¢ `_natural_sort_key` å®ç°è‡ªç„¶æ•°å€¼æ’åºï¼Œå¹¶åœ¨ `safetensors_weights_iterator` ä¸­å¯¹æ–‡ä»¶åˆ—è¡¨ä½¿ç”¨è¯¥æ’åºï¼Œç¡®ä¿ safetensors åŠ è½½é¡ºåºç¡®å®šæ€§ï¼›åŒæ—¶å¼•å…¥ `regex` åº“ã€‚

---

### [Bugfix] Fix DSV3.2 NVFP4 (#33932)
**SHA**: `4145e50` | ğŸ”— [æŸ¥çœ‹æäº¤](https://github.com/vllm-project/vllm/commit/4145e50d854e3182c22bad99ec011c283b9c493f)

**ğŸ¯ å˜æ›´ç±»å‹**ï¼šä»£ç é‡æ„  
**âš¡ é‡è¦ç¨‹åº¦**ï¼šğŸŸ¢ä½  
**ğŸ“‹ æ‘˜è¦**ï¼šä¿®å¤ DSV3.2 FP8 æ³¨æ„åŠ›åœ¨ KVâ€‘cache ä¸º `"fp8_ds_mla"` æ—¶çš„å¼‚å¸¸ï¼Œå¹¶æ–°å¢ `supports_quant_query_input` æ ‡è®°ï¼Œä»…åœ¨å®ç°æ”¯æŒé‡åŒ–æŸ¥è¯¢æ—¶ä½¿ç”¨ FP8ã€‚  

ï¼ˆå…¨æ–‡çº¦ 50 å­—ï¼‰

---

### Fix tokenizer test for renamed attr on Transformers v5 (#33902)
**SHA**: `1887acc` | ğŸ”— [æŸ¥çœ‹æäº¤](https://github.com/vllm-project/vllm/commit/1887acca9e2ceacea8f7b1770bd0a0fd9b6a3b02)

**ğŸ¯ å˜æ›´ç±»å‹**ï¼šæµ‹è¯•ä¿®æ”¹  
**âš¡ é‡è¦ç¨‹åº¦**ï¼šğŸŸ¢ä½  
**ğŸ“‹ æ‘˜è¦**ï¼šåœ¨ `test_serving_tokens.py` ä¸­ä½¿ç”¨ `getattr_iter` å…¼å®¹ Transformers v5 å°† `additional_special_tokens_ids` é‡å‘½åä¸º `extra_special_tokens_ids`ï¼Œç¡®ä¿ tokenizer æµ‹è¯•åœ¨æ–°æ—§ç‰ˆæœ¬å‡èƒ½é€šè¿‡ã€‚

---

### [Bugfix] Suppress non-TTY color output on the process name part of the log (#29714)
**SHA**: `92e7562` | ğŸ”— [æŸ¥çœ‹æäº¤](https://github.com/vllm-project/vllm/commit/92e7562a994038c904fea859d90462c7e84a3246)

**ğŸ¯ å˜æ›´ç±»å‹**ï¼šå…¶ä»–  
**âš¡ é‡è¦ç¨‹åº¦**ï¼šğŸŸ¢ä½  
**ğŸ“‹ æ‘˜è¦**ï¼šåœ¨æ—¥å¿—å‰ç¼€ç€è‰²æ—¶åŠ å…¥å¯¹è¾“å‡ºæ˜¯å¦ä¸º TTY çš„åˆ¤æ–­ï¼Œé˜²æ­¢åœ¨é TTY ç¯å¢ƒï¼ˆå¦‚æ–‡ä»¶é‡å®šå‘ï¼‰ä¸­è¾“å‡ºé¢œè‰²ç ï¼Œå¹¶å…¼å®¹ `NO_COLOR` ä¸ `VLLM_LOGGING_COLOR` é…ç½®ã€‚

---

### [Bugfix] Fix swapped engine_ids in NIXL Llama 4 local attention path (#33795)
**SHA**: `1ee9584` | ğŸ”— [æŸ¥çœ‹æäº¤](https://github.com/vllm-project/vllm/commit/1ee95841bd251f9081c3a317984c4dcaa003b3c0)

**ğŸ¯ å˜æ›´ç±»å‹**ï¼šå…¶ä»–  
**âš¡ é‡è¦ç¨‹åº¦**ï¼šğŸŸ¢ä½  
**ğŸ“‹ æ‘˜è¦**ï¼šä¿®å¤ NIXL Llamaâ€‘4 å±€éƒ¨æ³¨æ„åŠ›è·¯å¾„ä¸­ `engine_id` å‚æ•°å†™åçš„é—®é¢˜ï¼Œæ”¹ä¸ºä½¿ç”¨å½“å‰å¼•æ“ `self.engine_id` è·å–æœ¬åœ°æè¿°ç¬¦ï¼Œå¹¶åœ¨è¿œç¨‹è°ƒç”¨æ—¶ä½¿ç”¨ç›®æ ‡ `dst_engine_id`ï¼ŒåŒæ—¶ä¼ é€’ `block_size_ratio` å‚æ•°ï¼Œé¿å…æè¿°ç¬¦ ID æ··æ·†ã€‚

---

### [Misc] Add debug logs (#33931)
**SHA**: `7d8c680` | ğŸ”— [æŸ¥çœ‹æäº¤](https://github.com/vllm-project/vllm/commit/7d8c6804e2654873cb25d0b23fef178fa5f37237)

**ğŸ¯ å˜æ›´ç±»å‹**ï¼šä»£ç é‡æ„  
**âš¡ é‡è¦ç¨‹åº¦**ï¼šğŸŸ¢ä½  
**ğŸ“‹ æ‘˜è¦**ï¼šåœ¨ `utils.py` ä¸ `nixl_connector.py` ä¸­æ–°å¢ `logger.debug` è°ƒè¯•ä¿¡æ¯ï¼Œåˆ†åˆ«è®°å½• KV ç¼“å­˜å½¢çŠ¶ã€è·¨å±‚ KV ä½¿ç”¨ä»¥åŠæ³¨å†Œå±‚çš„ç¼“å­˜å½¢çŠ¶ã€‚  

ï¼ˆç®€æ´æ˜äº†ï¼Œâ‰¤100å­—ï¼‰

---

### [BugFix] Fix LoRA Fp8 (#33879)
**SHA**: `5b2a942` | ğŸ”— [æŸ¥çœ‹æäº¤](https://github.com/vllm-project/vllm/commit/5b2a9422f0f4cbdd69a9fed1dc1605838314ff81)

**ğŸ¯ å˜æ›´ç±»å‹**ï¼šå…¶ä»–  
**âš¡ é‡è¦ç¨‹åº¦**ï¼šğŸŸ¢ä½  
**ğŸ“‹ æ‘˜è¦**ï¼šåœ¨ `fused_moe.py` ä¸­ï¼Œè‹¥é‡åŒ–æ–¹æ³•æ”¯æŒå†…éƒ¨æ¨¡å—æ ¸ `supports_internal_mk`ï¼Œç›´æ¥å¤ç”¨å…¶ `moe_mk`ï¼Œå¦åˆ™ä¿æŒåŸæœ‰åˆ›å»ºæ–¹å¼ï¼Œè§£å†³ LoRA Fp8 ç›¸å…³ Bugã€‚

---

