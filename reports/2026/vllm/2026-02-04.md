# æ¯æ—¥æ›´æ–°æŠ¥å‘Šï¼ˆ2026-02-04ï¼‰

## vllm-project/vllm

| æäº¤æ—¶é—´ | ä½œè€… | æäº¤ä¿¡æ¯ |
|----------|------|----------|
| 2026-02-04 23:56:02 | Cyrus Leung | [Bugfix] Fix `normalize` still being passed to `PoolerConfig` (#33794) |
| 2026-02-04 22:34:32 | Wentao Ye | [Perf] Optimize spec decoding + async scheduling, 1.5% Throughput improvement (#33612) |
| 2026-02-04 21:36:29 | Micah Williamson | [Bugfix][ROCm] Include float8_e4m3fnuz in NCCL Dtype Dispatching (#33713) |
| 2026-02-04 21:35:39 | Cyrus Leung | Apply #33621 to main (#33758) |
| 2026-02-04 20:30:36 | Chauncey | [Perf] Optimize chat completion streaming performance (#33782) |
| 2026-02-04 20:23:01 | Cyrus Leung | [Model] Apply #32631 for recent models (#33785) |
| 2026-02-04 20:15:29 | Yueqian Lin | [Bugfix][Model] Fix audio-in-video support for Qwen2.5-Omni and Qwen3-Omni       (#33605) |
| 2026-02-04 19:20:52 | Vadim Gimpelson | [PERF] Change GDN Attention State Layout from [N, HV, K, V] to [N, HV, V, K] (#33291) |
| 2026-02-04 19:16:34 | Or Ozeri | [KV Connector][BugFix] scheduler: Delay freeing blocks of aborted async loads (#32255)<br>Fixes a not-yet-reported case where it was possible for blocks to be<br>freed by an abort before an async transfer completed, resulting<br>in corrupted KV data. |
| 2026-02-04 18:56:45 | Zhengxu Chen | [compile] Remove runner type from ignored caching factor list. (#33712) |
| 2026-02-04 18:12:53 | Zhengxu Chen | [compile] Clean up AOT compile bypass on evaluate_guards. (#33578) |
| 2026-02-04 18:12:25 | Kunshang Ji | [XPU][2/N] add support unquantized moe support for xpu  (#33659) |
| 2026-02-04 18:04:11 | Augusto Yao | use ORJSONResponse when available to improve the efficiency of request process (#33548) |
| 2026-02-04 16:40:17 | Kunshang Ji | [XPU] remove common path warning log (#33769) |
| 2026-02-04 15:46:48 | zhanqiuhu | [Metrics] Add labeled prompt token metrics for P/D disaggregation (#33290)<br>Add labeled Prometheus metrics to distinguish where prompt tokens come<br>from in P/D disaggregated deployments.<br>In P/D disaggregation, decode instances receive KV cache from prefill instances.<br>Currently, decode reports inflated prompt throughput because it counts all<br>prompt tokens as "computed", even though most were transferred.<br>This PR adds labeled metrics so users can understand actual compute work vs<br>transferred work:<br>vllm:prompt_tokens_by_source_total{source="local_compute"}        # Tokens prefilled locally<br>vllm:prompt_tokens_by_source_total{source="external_kv_transfer"} # Tokens received via KV transfer  <br>vllm:prompt_tokens_by_source_total{source="local_cache_hit"}      # Tokens from local prefix cache<br>vllm:prompt_tokens_cached_total                                    # Total cached (local + external, -1 when all  |
| 2026-02-04 14:51:33 | Matt | [Hardware][AMD][CI] Refactor AMD tests to properly use BuildKite parallelism (#32745) |
| 2026-02-04 13:58:21 | Wentao Ye | [Deprecation] Deprecate profiling envs (#33722) |
| 2026-02-04 13:51:52 | Cyrus Leung | [Deprecation] Remove `_get_data_parser` in MM processor (#33757) |
| 2026-02-04 13:27:34 | Frank Wang | [Feature] Enable `TRITON_ATTN` for Batch Invariance (#33688) |
| 2026-02-04 13:25:11 | Wentao Ye | [Refactor] Remove unused dead code (#33718) |
| 2026-02-04 13:24:14 | Michael Goin | [Bugfix] Define router_logits_dtype for remaining MoE models (#33737) |
| 2026-02-04 12:37:51 | Huy Do | Save startup benchmark results as a list of values (#33629) |
| 2026-02-04 12:07:30 | Shanshan Shen | [MM] Align the prefix of MMEncoderAttention with Attention (#33750) |
| 2026-02-04 11:37:15 | R3hankhan | [CPU] Split attention dispatch by head_dim alignment (#32161) |
| 2026-02-04 10:59:03 | Andrew Xia | [1/N] Initial Implementation of Parser for ResponsesAPI (#32712) |
| 2026-02-04 10:17:37 | Isotr0py | [Bugfix] Fix torchrun PP broadcast deadlock with async scheduling (#33701) |
| 2026-02-04 09:48:40 | wang.yuqi | [Frontend][4/n] Make pooling entrypoints request schema consensus \| ScoreRequest (#33060) |
| 2026-02-04 07:34:41 | Nick Hill | [BugFix][Spec Decoding] Fix negative accepted tokens metric crash (#33729) |
| 2026-02-04 07:30:47 | Wentao Ye | [Dependency] Remove comments of ray in dependency files (#33351) |
| 2026-02-04 07:29:48 | Matthew Bonanni | [Bugfix] Fix sparse MLA metadata building (#33579) |
| 2026-02-04 05:26:51 | Michael Goin | [Bugfix] Disable TRTLLM FP8 MoE if router_logits_dtype==float32 and routing_method!=DeepSeekV3 (#33613) |
| 2026-02-04 05:03:28 | Patrick von Platen | [Voxtral Realtime] Change name (#33716) |
| 2026-02-04 04:10:31 | Vadim Gimpelson | [MISC] Fix Tensor Parallelism for Quantized Mamba Models with n_groups=1 (#33257) |
| 2026-02-04 01:40:59 | Harry Mellor | Turn `@config` into a `dataclass_transform` (#31541) |
| 2026-02-04 01:12:11 | Richard Zou | [torch.compile] Significantly speed up cold start times (#33641) |
| 2026-02-04 00:08:47 | Lucas Wilkinson | [Attention][FA3] Update FA3 to include new swizzle optimization (#23465) |
| 2026-02-04 00:08:25 | dtc | [P/D] rework mooncake connector and introduce its bootstrap server (#31034) |

### ğŸ“Š ç»Ÿè®¡æ‘˜è¦
> æœ¬æ—¥å…± 37 ä¸ªæäº¤ | ğŸ”´é«˜ 3 | ğŸŸ¡ä¸­ 21 | ğŸŸ¢ä½ 13
## ğŸ“‹ ç›®å½•

- [vllm-project/vllm](#vllm-project-vllm)
  - [ğŸ“Š ç»Ÿè®¡æ‘˜è¦](#-ç»Ÿè®¡æ‘˜è¦)
  - [ğŸ”´ é«˜é‡è¦åº¦å˜æ›´ (3)](#-ğŸ”´-é«˜é‡è¦åº¦å˜æ›´-3)
    - [[1/N] Initial Implementation of Parser for ResponsesAPI (...](#e1bf04b)
    - [[Frontend][4/n] Make pooling entrypoints request schema c...](#1b8fe6f)
    - [[P/D] rework mooncake connector and introduce its bootstr...](#0d6ccf6)
  - [ğŸŸ¡ ä¸­é‡è¦åº¦å˜æ›´ (21)](#-ğŸŸ¡-ä¸­é‡è¦åº¦å˜æ›´-21)
    - [[Model] Apply #32631 for recent models (#33785)](#e57ef99)
    - [[Bugfix][Model] Fix audio-in-video support for Qwen2.5-Om...](#f8516a1)
    - [[PERF] Change GDN Attention State Layout from [N, HV, K, ...](#8240580)
    - [[KV Connector][BugFix] scheduler: Delay freeing blocks of...](#8e32690)
    - [[XPU][2/N] add support unquantized moe support for xpu  (...](#f79f777)
    - [[Metrics] Add labeled prompt token metrics for P/D disagg...](#4403e3e)
    - [[Deprecation] Deprecate profiling envs (#33722)](#d88a1df)
    - [[Feature] Enable `TRITON_ATTN` for Batch Invariance (#33688)](#45f8fd6)
    - [[Refactor] Remove unused dead code (#33718)](#5e1e0a0)
    - [[Bugfix] Define router_logits_dtype for remaining MoE mod...](#eb5ed20)
    - [[MM] Align the prefix of MMEncoderAttention with Attentio...](#9fb27dd)
    - [[CPU] Split attention dispatch by head_dim alignment (#32...](#4dffc5e)
    - [[Bugfix] Fix torchrun PP broadcast deadlock with async sc...](#0208017)
    - [[BugFix][Spec Decoding] Fix negative accepted tokens metr...](#52ee210)
    - [[Bugfix] Fix sparse MLA metadata building (#33579)](#bd8da29)
    - [[Bugfix] Disable TRTLLM FP8 MoE if router_logits_dtype==f...](#2a99c5a)
    - [[Voxtral Realtime] Change name (#33716)](#3f7662d)
    - [[MISC] Fix Tensor Parallelism for Quantized Mamba Models ...](#a372f3f)
    - [Turn `@config` into a `dataclass_transform` (#31541)](#61e632a)
    - [[torch.compile] Significantly speed up cold start times (...](#b1bb18d)
    - [[Attention][FA3] Update FA3 to include new swizzle optimi...](#2267cb1)
  - [ğŸŸ¢ ä½é‡è¦åº¦å˜æ›´ (13)](#-ğŸŸ¢-ä½é‡è¦åº¦å˜æ›´-13)
    - [[Bugfix] Fix `normalize` still being passed to `PoolerCon...](#80f921b)
    - [[Perf] Optimize spec decoding + async scheduling, 1.5% Th...](#711edaf)
    - [[Bugfix][ROCm] Include float8_e4m3fnuz in NCCL Dtype Disp...](#1d367a7)
    - [Apply #33621 to main (#33758)](#32a02c7)
    - [[Perf] Optimize chat completion streaming performance (#3...](#f67ee8b)
    - [[compile] Remove runner type from ignored caching factor ...](#a208439)
    - [[compile] Clean up AOT compile bypass on evaluate_guards....](#bcd2f74)
    - [use ORJSONResponse when available to improve the efficien...](#4c8d1bf)
    - [[XPU] remove common path warning log (#33769)](#061da6b)
    - [[Hardware][AMD][CI] Refactor AMD tests to properly use Bu...](#08e0949)
    - [[Deprecation] Remove `_get_data_parser` in MM processor (...](#90d74eb)
    - [Save startup benchmark results as a list of values (#33629)](#2647163)
    - [[Dependency] Remove comments of ray in dependency files (...](#655efb3)
#### ğŸ”´ é«˜é‡è¦åº¦å˜æ›´ (3)

### [1/N] Initial Implementation of Parser for ResponsesAPI (#32712)
**SHA**: `e1bf04b` | ğŸ”— [æŸ¥çœ‹æäº¤](https://github.com/vllm-project/vllm/commit/e1bf04b6c27a070859264290ffdccbf333f27fa6)

**ğŸ¯ å˜æ›´ç±»å‹**ï¼šåŠŸèƒ½å¢å¼ºï¼ˆæ–°å¢ç»Ÿä¸€ Parser æ¡†æ¶ï¼Œä»¥æ”¯æŒ Responses API çš„ Reasoning ä¸ Tool è°ƒç”¨è§£æï¼‰  

**âš¡ é‡è¦ç¨‹åº¦**ï¼šğŸ”´ é«˜  

**ğŸ“‹ å˜æ›´æ‘˜è¦**ï¼š  
1. åœ¨ `vllm/parser` åŒ…ä¸­æ–°å»ºæŠ½è±¡å±‚ã€ç®¡ç†å™¨ä»¥åŠ MiniMaxâ€‘M2 ç»Ÿä¸€è§£æå™¨ï¼Œå®ç°äº† ReasoningParser ä¸ ToolParser çš„ç»Ÿä¸€å…¥å£ã€‚  
2. å…¥å£å±‚ (`chat_completion/serving.py`ã€`responses/serving.py`) æ”¹ä¸ºé€šè¿‡ `ParserManager.get_parser` è·å–ç»Ÿä¸€è§£æå™¨ï¼Œç§»é™¤åŸæœ‰ç§æœ‰ `_get_*_parser` æ–¹æ³•ã€‚  
3. ç›¸åº”çš„å•å…ƒæµ‹è¯•åŠ å…¥ `model` å­—æ®µä»¥å…¼å®¹æ–°æ¥å£ã€‚  

**ğŸ¯ å½±å“èŒƒå›´**ï¼š  
- `vllm/entrypoints/openai/chat_completion/serving.py`  
- `vllm/entrypoints/openai/responses/serving.py`  
- `vllm/entrypoints/openai/engine/serving.py`ï¼ˆåˆ é™¤æ—§å·¥å…·è§£æè¾…åŠ©å‡½æ•°ï¼‰  
- æ–°å¢ `vllm/parser/*`ï¼ˆæŠ½è±¡åŸºç±»ã€ç®¡ç†å™¨ã€MiniMaxâ€‘M2 å…·ä½“å®ç°ï¼‰  
- å—å½±å“çš„å•å…ƒæµ‹è¯•æ–‡ä»¶ï¼ˆ`tests/entrypoints/openai/*`ï¼‰  

---

### ğŸ” æŠ€æœ¯æ´å¯Ÿ

| ç»´åº¦ | å½±å“ |
|------|------|
| **æ¶æ„å½±å“** | - å¼•å…¥ **ParserManager** ä½œä¸ºç»Ÿä¸€çš„æ³¨å†Œ/æ‡’åŠ è½½ä¸­å¿ƒï¼Œå½¢æˆâ€œæ’ä»¶å¼â€è§£æå™¨æ¶æ„ã€‚<br>- é€šè¿‡ `ParserManager.get_parser` èƒ½åœ¨è¿è¡Œæ—¶ç»„åˆ **ReasoningParser** + **ToolParser**ï¼Œæˆ–ç›´æ¥ä½¿ç”¨å·²ç»å®ç°çš„ç»Ÿä¸€è§£æå™¨ï¼ˆå¦‚ `MiniMaxM2Parser`ï¼‰ã€‚<br>- åŸæœ‰ `EngineServing` ä¸­æ‰‹åŠ¨è·å– Tool/Reasoning è§£æå™¨çš„å®ç°è¢«åˆ é™¤ï¼Œé™ä½è€¦åˆåº¦ï¼Œç»Ÿä¸€å…¥å£ä»…åœ¨ **Responses/ChatCompletion** å±‚å®Œæˆã€‚ |
| **æ€§èƒ½å½±å“** | - **æ‡’åŠ è½½**ï¼šé¦–æ¬¡ä½¿ç”¨æŸä¸ªè§£æå™¨æ—¶æ‰ä¼š `importlib.import_module`ï¼Œå¯åŠ¨æ—¶å¼€é”€å‡ ä¹ä¸ºé›¶ã€‚<br>- ç»Ÿä¸€è§£æå™¨åœ¨å¤šæ•°è¯·æ±‚è·¯å¾„ä¸‹åªå®ä¾‹åŒ–ä¸€æ¬¡ï¼ˆ`Parser` å¯¹è±¡æŒæœ‰ tokenizerï¼‰ï¼Œåç»­å¤ç”¨åŒä¸€å®ä¾‹ï¼Œå’Œä¹‹å‰çš„åšæ³•å·®åˆ«ä¸å¤§ã€‚<br>- é¢å¤–çš„ **å‡½æ•°åŒ…è£…å±‚**ï¼ˆ`_WrappedParser`ï¼‰å¸¦æ¥æå°çš„è°ƒç”¨å¼€é”€ï¼ˆå±æ€§è®¿é—®ä¸ä¸€æ¬¡å¯¹è±¡åˆ›å»ºï¼‰ï¼Œå¯¹æ•´ä½“ååå½±å“å¯å¿½ç•¥ã€‚ |
| **å®‰å…¨è€ƒè™‘** | - è§£æå™¨ä»æ—§æ˜¯å†…éƒ¨å®ç°ï¼Œæœªæš´éœ²å¤–éƒ¨æ‰§è¡Œä»£ç çš„èƒ½åŠ›ã€‚<br>- é€šè¿‡ **æ³¨å†Œè¡¨** åŠ è½½çš„æ¨¡å—è·¯å¾„å—é™äºé¡¹ç›®æºç ï¼Œè‹¥ç”¨æˆ·è‡ªè¡Œè°ƒç”¨ `ParserManager.import_parser` åŠ è½½å¤–éƒ¨æ’ä»¶ï¼Œéœ€è‡ªè¡Œè¯„ä¼°å®‰å…¨é£é™©ï¼ˆæœªåœ¨æ­¤æäº¤ä¸­ä½¿ç”¨ï¼‰ã€‚<br>- ä»£ç å¯¹å¼‚å¸¸æ•è·åšäº†æ˜ç¡®åŒ…è£…ï¼Œé¿å…å› æœªæ³¨å†Œçš„è§£æå™¨å¯¼è‡´æœåŠ¡å´©æºƒã€‚ |
| **å¯ç»´æŠ¤æ€§** | - ç»Ÿä¸€çš„ **Parser** æŠ½è±¡è®©æ–°æ¨¡å‹åªéœ€å®ç° `ReasoningParser` / `ToolParser` æˆ–ç›´æ¥ç»§æ‰¿ `DelegatingParser`ï¼Œæå¤§é™ä½äº†æ–°æ¨¡å‹é€‚é…æˆæœ¬ã€‚<br>- æ³¨å†Œ/æ‡’åŠ è½½æœºåˆ¶é¿å…åœ¨ä¸»åº“ä¸­ç¡¬ç¼–ç å¤§é‡ `if-else`ï¼Œæ–°å¢æ¨¡å‹åªéœ€åœ¨ `register_lazy_parsers` ä¸­å£°æ˜å³å¯ã€‚<br>- ç§»é™¤ `EngineServing._get_*_parser` ç§æœ‰æ–¹æ³•ï¼Œä½¿ä»£ç æ›´ç®€æ´ã€èŒè´£æ›´å•ä¸€ã€‚ |
| **å…¼å®¹æ€§** | - æ—§çš„ `ReasoningParserManager` ä¸ `ToolParserManager` ä»ç„¶ä¿ç•™ï¼Œ`ParserManager` ä¼šåœ¨å¿…è¦æ—¶è°ƒç”¨å®ƒä»¬ï¼Œæ‰€ä»¥å·²æœ‰æ¨¡å‹åœ¨ä¸æä¾›ç»Ÿä¸€è§£æå™¨çš„æƒ…å†µä¸‹ä»èƒ½æ­£å¸¸å·¥ä½œã€‚<br>- éœ€è¦åœ¨æ¨¡å‹é…ç½®ä¸­æä¾› `model` å­—æ®µï¼ˆå·²åœ¨æµ‹è¯•ä¸­è¡¥å……ï¼‰ä»¥ä¾› `ParserManager.get_tool_parser` åˆ¤æ–­ Llamaâ€‘3.2 è­¦å‘Šï¼›å¯¹å·²æœ‰æ¨¡å‹å½±å“æå°ã€‚ |

---

### âš ï¸ æ½œåœ¨é£é™©

1. **æ³¨å†Œå†²çª**ï¼šå¦‚æœå¤–éƒ¨æ’ä»¶æˆ–æœªæ¥å†…éƒ¨ä»£ç å†æ¬¡ä½¿ç”¨ç›¸åŒåç§°æ³¨å†Œä¸åŒçš„è§£æå™¨ï¼Œä¼šè§¦å‘ `KeyError`ï¼ˆé™¤é `force=True`ï¼‰ï¼Œå¯¼è‡´å¯åŠ¨å¤±è´¥ã€‚  
2. **æ‡’åŠ è½½å¼‚å¸¸**ï¼šç¬¬ä¸€æ¬¡è°ƒç”¨æœªæ³¨å†Œçš„ç»Ÿä¸€è§£æå™¨ä¼šåœ¨ `importlib.import_module` æ—¶æŠ›å‡ºå¼‚å¸¸ï¼Œé”™è¯¯ä¿¡æ¯è¾ƒä¸ºé€šç”¨ï¼Œå¯èƒ½ä¸æ˜“å®šä½ã€‚  
3. **å¹¶å‘å®ä¾‹åŒ–**ï¼š`ParserManager.get_parser` åœ¨é«˜å¹¶å‘åœºæ™¯ä¸‹å¯èƒ½å¤šæ¬¡åˆ›å»º `Parser` å®ä¾‹ï¼ˆå› ä¸ºè¿”å›çš„æ˜¯ç±»è€Œéå•ä¾‹ï¼‰ï¼Œè‹¥è§£æå™¨å†…éƒ¨æŒæœ‰å¤§é‡çŠ¶æ€æˆ–å¤§å¯¹è±¡ï¼ˆå¦‚ tokenizerï¼‰ï¼Œä¼šå¯¼è‡´å†…å­˜é‡å¤ã€‚  
4. **å‘åå…¼å®¹**ï¼šæŸäº›è‡ªå®šä¹‰æ’ä»¶ä»ç„¶ä¾èµ– `EngineServing._get_tool_parser` ç§æœ‰æ–¹æ³•ï¼›è¿™äº›è·¯å¾„åœ¨æœªæ¥å¯èƒ½è¢«ç§»é™¤ï¼Œéœ€è¦æå‰è¿ç§»ã€‚  
5. **æµ‹è¯•è¦†ç›–ä¸è¶³**ï¼šå½“å‰ä»…åœ¨ chat/completion é”™è¯¯è·¯å¾„è¡¥å……äº† `model` å­—æ®µï¼Œæœªå¯¹æ–°ç»Ÿä¸€è§£æå™¨çš„å®Œæ•´åŠŸèƒ½ï¼ˆreasoning + toolï¼‰è¿›è¡Œé›†æˆæµ‹è¯•ï¼Œå¯èƒ½éšè—è¾¹ç¼˜ caseã€‚  

---

### ğŸ’¡ å…³æ³¨å»ºè®®

| å¯¹è±¡ | å»ºè®® |
|------|------|
| **å¼€å‘è€…** | - åœ¨æ–°å¢æ¨¡å‹æ—¶ï¼Œé¦–é€‰å®ç° **ç»Ÿä¸€ Parser**ï¼ˆç»§æ‰¿ `DelegatingParser`ï¼‰å¹¶åœ¨ `register_lazy_parsers` ä¸­å£°æ˜ï¼›è‹¥åªèƒ½åˆ†åˆ«å®ç° Reasoning/Toolï¼Œç¡®ä¿ä¸¤è€…å‡å·²åœ¨å„è‡ªçš„ `Manager` ä¸­æ³¨å†Œã€‚<br>- å¯¹ `ParserManager.get_parser` è¿”å›çš„ç±»åšä¸€æ¬¡å®ä¾‹åŒ–ï¼ˆå¦‚ `parser = ParserManager.get_parser(...)(tokenizer)`ï¼‰åï¼Œæœ€å¥½ç¼“å­˜åˆ°æœåŠ¡å®ä¾‹ï¼Œé¿å…åœ¨æ¯æ¬¡è¯·æ±‚éƒ½é‡æ–°å®ä¾‹åŒ–ã€‚ |
| **è¿ç»´ / ç›‘æ§** | - ç›‘æ§ `ParserManager` çš„åŠ è½½æ—¥å¿—ï¼ˆ`Using unified parser â€¦`ï¼‰ï¼Œç¡®è®¤æœŸæœ›çš„ç»Ÿä¸€è§£æå™¨è¢«æ­£ç¡®é€‰ä¸­ã€‚<br>- å…³æ³¨å†…å­˜å ç”¨ï¼Œå°¤å…¶åœ¨å¼€å¯å¤§é‡æ¨¡å‹å®ä¾‹æ—¶ï¼Œæ£€æŸ¥æ˜¯å¦å‡ºç°åŒä¸€ `Parser` è¢«é‡å¤å®ä¾‹åŒ–çš„æƒ…å†µã€‚ |
| **å®‰å…¨å®¡è®¡** | - è‹¥è®¡åˆ’å¼€æ”¾ `ParserManager.import_parser` ç»™ç”¨æˆ·è‡ªå®šä¹‰æ’ä»¶ï¼Œè¯·åœ¨å…¥å£å±‚åŠ å…¥ç™½åå•æˆ–ç­¾åéªŒè¯ï¼Œé˜²æ­¢åŠ è½½æ¶æ„ä»£ç ã€‚ |
| **æµ‹è¯•** | - ä¸º `MiniMaxM2Parser` æ·»åŠ å®Œæ•´çš„å•å…ƒæµ‹è¯•ï¼Œè¦†ç›–ï¼š<br>  * `extract_reasoning`ã€`extract_reasoning_streaming`<br>  * `extract_tool_calls`ã€`extract_tool_calls_streaming`<br>  * è¾¹ç¼˜è¾“å…¥ï¼ˆæ— ç»“æŸæ ‡ç­¾ã€åµŒå¥—è°ƒç”¨ç­‰ï¼‰<br>- æ·»åŠ é›†æˆæµ‹è¯•ï¼Œç¡®ä¿ `Responses` ä¸ `ChatCompletion` ä¸¤ä¸ªå…¥å£å‡èƒ½æ­£ç¡®ä½¿ç”¨ç»Ÿä¸€è§£æå™¨ä¸”è¿”å›çš„ JSON æ ¼å¼ç¬¦åˆ OpenAI è§„èŒƒã€‚ |
| **æ–‡æ¡£** | - åœ¨é¡¹ç›®æ–‡æ¡£ï¼ˆREADME/CONTRIBUTINGï¼‰ä¸­è¡¥å…… â€œParser æ’ä»¶å¼€å‘æŒ‡å—â€ï¼Œè¯´æ˜æ³¨å†Œæ–¹å¼ã€æ‡’åŠ è½½æœºåˆ¶ä»¥åŠç»Ÿä¸€è§£æå™¨çš„æ¨èå®ç°æ¨¡å¼ã€‚ |

---

**æ€»ä½“ç»“è®º**ï¼šæ­¤æ¬¡æäº¤ä¸º vLLM å¼•å…¥äº†ä¸€å¥—ç»Ÿä¸€ä¸”å¯æ‰©å±•çš„ **Parser** æ¡†æ¶ï¼Œå¯¹æ¶æ„çš„å¯ç»„åˆæ€§ã€ä»£ç æ•´æ´åº¦ä»¥åŠæ–°æ¨¡å‹é€‚é…æ•ˆç‡æœ‰æ˜¾è‘—æå‡ã€‚åªè¦åœ¨éƒ¨ç½²å‰éªŒè¯æ³¨å†Œè¡¨æ— å†²çªã€åˆç†ç¼“å­˜ `Parser` å®ä¾‹å¹¶è¡¥è¶³ç›¸åº”æµ‹è¯•ï¼Œé£é™©å¯æ§ï¼Œæ¨èå°½å¿«åˆå¹¶åˆ°ä¸»çº¿ã€‚

---

### [Frontend][4/n] Make pooling entrypoints request schema consensus | ScoreRequest (#33060)
**SHA**: `1b8fe6f` | ğŸ”— [æŸ¥çœ‹æäº¤](https://github.com/vllm-project/vllm/commit/1b8fe6f7c4b96ec57172f4fd268341a03c12499b)

**ğŸ¯ å˜æ›´ç±»å‹**ï¼šåŠŸèƒ½å¢å¼º / æ¶æ„å˜æ›´  
**âš¡ é‡è¦ç¨‹åº¦**ï¼šğŸ”´ é«˜  

**ğŸ“‹ å˜æ›´æ‘˜è¦**  
æ­¤æ¬¡æäº¤ç»Ÿä¸€äº†â€¯vLLMâ€¯Poolingâ€¯Scoreâ€¯/â€¯Rerankâ€¯å…¥å£çš„è¯·æ±‚ç»“æ„ï¼Œå®ç°äº† **ScoreInput / ScoreInputs** ä¸ **ScoreData** çš„æ–°æŠ½è±¡ï¼Œå¹¶åœ¨ `utils`, `protocol`, `serving` ä»¥åŠæ ¸å¿ƒ `llm` å®ç°ä¸­åŠ å…¥ç»Ÿä¸€çš„æ ¡éªŒä¸è§£æé€»è¾‘ã€‚  
- æ–°å¢å¯¹ `queries/items/documents` å¤šç§ç»„åˆï¼ˆå­—ç¬¦ä¸²ã€å•æ¡å¤šæ¨¡æ€ã€åˆ—è¡¨ï¼‰ çš„å…¨é‡æ”¯æŒã€‚  
- å¼•å…¥ `validate_score_input`ï¼Œå¯¹å¤šæ¨¡æ€ä¸éå¤šæ¨¡æ€æ¨¡å‹è¿›è¡Œç»Ÿä¸€é•¿åº¦ä¸ç±»å‹æ£€æŸ¥ã€‚  
- ç¤ºä¾‹ã€æµ‹è¯•åŠ OpenAIâ€‘compatible ç«¯ç‚¹å…¨éƒ¨æ”¹ä¸ºä½¿ç”¨æ–°çš„ schemaï¼Œæå‡äº† API çš„ä¸€è‡´æ€§ä¸å¯ç»„åˆæ€§ã€‚  

**ğŸ¯ å½±å“èŒƒå›´**  
- **vllm.entrypoints.pooling.score.utils** â€“ æ–°å¢ç±»å‹ã€æ ¡éªŒã€è§£æå‡½æ•°ã€‚  
- **vllm.entrypoints.pooling.score.protocol** â€“ è¯·æ±‚æ¨¡å‹åŠ å…¥ `ScoreQueriesItemsRequest`ï¼Œ`ScoreInputs` å–ä»£åŸæœ‰ `str | ScoreMultiModalParam`ã€‚  
- **vllm.entrypoints.pooling.score.serving** â€“ è¯„åˆ†/é‡æ’å®ç°æ”¹ä¸ºç»Ÿä¸€è°ƒç”¨ `_score_func`ï¼Œå¹¶åœ¨å†…éƒ¨ä½¿ç”¨ `ScoreData`ã€‚  
- **vllm.entrypoints.llm** â€“ `score` æ–¹æ³•ç­¾åä¸å†…éƒ¨è·¯å¾„æ›´æ–°ï¼Œä½¿ç”¨ `validate_score_input`ã€‚  
- **ç¤ºä¾‹ä»£ç ã€å•å…ƒæµ‹è¯•** â€“ å…¨é¢è¿ç§»åˆ°æ–° schemaã€‚  

---

### ğŸ” æŠ€æœ¯æ´å¯Ÿ  

| ç»´åº¦ | å½±å“ |
|------|------|
| **æ¶æ„å½±å“** | - **ç»Ÿä¸€æŠ½è±¡å±‚**ï¼š`ScoreInputs` / `ScoreData` æˆä¸ºæ‰€æœ‰ pooling å…¥å£çš„å•ä¸€å…¥å£ç‚¹ï¼Œé™ä½äº†ä¸åŒç«¯ç‚¹é—´çš„å®ç°ç¢ç‰‡åŒ–ã€‚<br>- **è§£è€¦åè®®å±‚**ï¼šåŸæ¥ `ScoreMultiModalParam` è¢«å¼±åŒ–ï¼Œä»…åœ¨ `ScoreInput` ä¸­ä¿ç•™ `content` é”®ï¼Œåè®®å±‚åªå…³å¿ƒâ€œå†…å®¹â€è€Œéå…·ä½“å­—æ®µï¼Œä¾¿äºæœªæ¥æ‰©å±•ï¼ˆå¦‚æ·»åŠ éŸ³é¢‘ã€è§†é¢‘ç­‰ï¼‰ã€‚ |
| **æ€§èƒ½å½±å“** | - **é¢å¤–æ ¡éªŒ**ï¼š`validate_score_input` åœ¨è¯·æ±‚å…¥å£åšä¸€æ¬¡éå†å¹¶å¯¹å¤šæ¨¡æ€ç»“æ„è¿›è¡Œè§£åŒ…ï¼Œæˆæœ¬åœ¨æ¯«ç§’çº§ï¼ˆO(N)ï¼‰ï¼Œå¯¹æ‰¹é‡æ¨ç†çš„æ•´ä½“ååå½±å“å¯å¿½ç•¥ã€‚<br>- **è·¨ç¼–ç è·¯å¾„æœªå˜**ï¼šå®é™…æ¨¡å‹å‰å‘ä»ä½¿ç”¨åŸæœ‰çš„ `encode` / `crossâ€‘encoding` å®ç°ï¼Œæœªå¼•å…¥é¢å¤–è®¡ç®—ã€‚ |
| **å®‰å…¨è€ƒè™‘** | - **è¾“å…¥è§„èŒƒåŒ–**ï¼šç»Ÿä¸€æ ¡éªŒé¿å…äº†â€œå­—ç¬¦ä¸²+dictæ··ç”¨â€å¯¼è‡´çš„æ„å¤–è§£æé”™è¯¯ï¼Œé™ä½äº†æ½œåœ¨çš„æ³¨å…¥é£é™©ã€‚<br>- **é”™è¯¯ä¿¡æ¯æ˜ç¡®**ï¼šå¯¹ä¸æ”¯æŒçš„å¤šæ¨¡æ€è¾“å…¥æŠ›å‡ºæ˜ç¡® `ValueError`ï¼Œé˜²æ­¢åç«¯å› é”™è¯¯è§£æå¯¼è‡´å¼‚å¸¸æ³„éœ²ã€‚ |
| **å¯ç»´æŠ¤æ€§** | - **ç±»å‹ç»Ÿä¸€**ï¼šæ‰€æœ‰å…¥å£ä½¿ç”¨åŒä¸€ `ScoreInputs`ï¼Œä»£ç è·¯å¾„åˆå¹¶ï¼Œæœªæ¥å˜æ›´åªéœ€åœ¨ `utils.validate_score_input` ä¸€å¤„è°ƒæ•´ã€‚<br>- **æ–‡æ¡£/ç¤ºä¾‹åŒæ­¥**ï¼šç¤ºä¾‹å·²æ›´æ–°ï¼Œé™ä½æ–°ç”¨æˆ·ä½¿ç”¨é—¨æ§›ã€‚ |
| **å‘åå…¼å®¹** | - ç ´åæ€§ï¼šæ—§ç‰ˆç›´æ¥ä¼ é€’ `ScoreMultiModalParam`ï¼ˆä¸åœ¨ `content` é”®ä¸‹ï¼‰å·²ä¸å†è¢«æ¥å—ï¼Œè°ƒç”¨æ–¹éœ€è¦è¿ç§»ã€‚<br>- æä¾›äº† **`ScoreQueriesItemsRequest`** å…¼å®¹æ—§çš„ `items` å­—æ®µï¼Œå¸®åŠ©å¹³æ»‘è¿ç§»ã€‚ |

---

**âš ï¸ æ½œåœ¨é£é™©**  

1. **å‘åå…¼å®¹æ€§**  
   - ç›´æ¥ä½¿ç”¨æ—§ç‰ˆ JSONï¼ˆå¦‚ `{"queries": "q", "documents": {"type":"text","text":"d"}}`ï¼‰å°†è§¦å‘ `ValueError`ã€‚æ‰€æœ‰ä½¿ç”¨ vLLM ä½œä¸ºå†…éƒ¨æœåŠ¡çš„ç³»ç»Ÿéœ€åŒæ­¥æ›´æ–°è¯·æ±‚æ ¼å¼ã€‚  

2. **æ‰¹é‡è¯·æ±‚é•¿åº¦æ ¡éªŒ**  
   - `validate_score_input` ä»ç„¶è¦æ±‚ `len(data_1) == len(data_2)`ï¼ˆæˆ–å•æ¡è‡ªåŠ¨å¹¿æ’­ï¼‰ã€‚å¦‚æœä¸šåŠ¡ä¾§è¯¯ä¼ ä¸åŒ¹é…çš„åˆ—è¡¨ï¼Œä¼šåœ¨å…¥å£æŠ›å¼‚å¸¸ï¼Œå¯¼è‡´ 400 é”™è¯¯ã€‚  

3. **å¤šæ¨¡æ€æ¨¡å‹é™åˆ¶**  
   - å½“å‰åµŒå…¥å¼è¯„åˆ† (`_embedding_score`) æ˜ç¡®ä¸æ”¯æŒå¤šæ¨¡æ€è¾“å…¥ã€‚è‹¥åœ¨è·¨æ¨¡æ€æ¨¡å‹ä¸Šè¯¯ç”¨ `score`ï¼ˆè€Œé `rerank`ï¼‰ï¼Œä¼šè§¦å‘ `NotImplementedError`ã€‚  

4. **å¹¶å‘æ€§**  
   - `ThreadPoolExecutor(max_workers=1)` ä»ç”¨äº tokenizer è°ƒç”¨ã€‚é«˜å¹¶å‘åœºæ™¯ä¸‹å¯èƒ½æˆä¸ºç“¶é¢ˆï¼Œè™½ç„¶æ­¤è¡Œä¸ºåœ¨åŸå§‹å®ç°ä¸­å·²å­˜åœ¨ã€‚  

5. **æ–‡æ¡£åŒæ­¥**  
   - å…¬å¼€ API æ–‡æ¡£è‹¥æœªåŠæ—¶æ›´æ–°ï¼Œç”¨æˆ·å¯èƒ½ä»å‚è€ƒæ—§å­—æ®µï¼Œå¯¼è‡´è°ƒç”¨å¤±è´¥ã€‚  

---

**ğŸ’¡ å…³æ³¨å»ºè®®**  

| å¯¹è±¡ | å»ºè®® |
|------|------|
| **å¼€å‘è€…** | - åœ¨æ‰€æœ‰è°ƒç”¨ç«¯ç»Ÿä¸€ä½¿ç”¨ `ScoreInputs`ï¼ˆå­—ç¬¦ä¸²ã€å•æ¡ `ScoreMultiModalParam`ã€æˆ–åˆ—è¡¨ï¼‰å¹¶é€šè¿‡ `content` é”®åŒ…è£…å¤šæ¨¡æ€æ•°æ®ã€‚<br>- å¯¹äºä»…æ–‡æœ¬æ¨¡å‹ä»å¯ç›´æ¥ä¼ å­—ç¬¦ä¸²ï¼Œä¿æŒå…¼å®¹æ€§ã€‚ |
| **è¿ç»´ / CI** | - ä¸º **API å…¼å®¹æ€§** å¢åŠ å›å½’æµ‹è¯•ï¼šç¡®ä¿æ—§ç‰ˆè¯·æ±‚èƒ½è¿”å›æ¸…æ™°çš„ 400 é”™è¯¯ä¿¡æ¯ï¼Œé¿å…æœåŠ¡å¼‚å¸¸ã€‚<br>- ç›‘æ§ `score` ä¸ `rerank` è·¯å¾„çš„ **ThreadPoolExecutor** é˜Ÿåˆ—æ·±åº¦ï¼Œè¯„ä¼°æ˜¯å¦éœ€è¦æå‡ `max_workers`ã€‚ |
| **æ–‡æ¡£ç»´æŠ¤** | - æ›´æ–° OpenAPI/Swagger æè¿°ï¼Œå°† `ScoreInputs` ä¸ `ScoreData` æ ‡è®°ä¸ºä¸»è¯·æ±‚ä½“æ¨¡å‹ã€‚<br>- åœ¨ README ä¸ç¤ºä¾‹ä¸­æ˜ç¡®å±•ç¤ºå››ç§å¸¸è§ç»„åˆï¼ˆqueryâ€‘string / documentâ€‘list / multimodalâ€‘dict / mixedï¼‰ã€‚ |
| **å®‰å…¨å®¡è®¡** | - æ£€æŸ¥ `ScoreMultiModalParam` ä¸­çš„ `content` æ˜¯å¦å¯èƒ½æºå¸¦æ¶æ„ URL/è·¯å¾„ï¼Œè‹¥æœ‰éœ€è¦åœ¨ `fetch_image` ç­‰å‡½æ•°ä¸­åŠ å…¥ç™½åå•æˆ–å¤§å°é™åˆ¶ã€‚ |
| **æœªæ¥æ‰©å±•** | - ç°æœ‰æŠ½è±¡å·²ä¸º **éŸ³é¢‘/è§†é¢‘** ç­‰æ–°æ¨¡æ€é¢„ç•™ï¼Œåç»­åªéœ€åœ¨ `ScoreContentPartParam` ä¸­åŠ å…¥å¯¹åº”ç±»å‹ï¼Œå®ç°å³å¯ã€‚ |

> **æ€»ä½“ç»“è®º**ï¼šæ­¤ PR åœ¨ **åŠŸèƒ½å®Œæ•´æ€§** ä¸ **æ¶æ„ç»Ÿä¸€æ€§** ä¸Šå¸¦æ¥æ˜¾è‘—æå‡ï¼Œé£é™©ä¸»è¦é›†ä¸­åœ¨å‘åå…¼å®¹ä¸å¹¶å‘ tokenizer å¤„ç†ä¸Šã€‚åªè¦åœ¨ä¸Šçº¿å‰å®Œæˆå…¼å®¹æ€§å›å½’ä¸æ–‡æ¡£åŒæ­¥ï¼Œæ¨èæ­£å¼åˆå¹¶å¹¶åœ¨ä¸‹ä¸€ä¸ªå‘è¡Œç‰ˆå‘å¸ƒã€‚

---

### [P/D] rework mooncake connector and introduce its bootstrap server (#31034)
**SHA**: `0d6ccf6` | ğŸ”— [æŸ¥çœ‹æäº¤](https://github.com/vllm-project/vllm/commit/0d6ccf68fa2c439e17d02f26c4044ed5df7f7099)

**ğŸ¯ å˜æ›´ç±»å‹**ï¼šæ¶æ„å˜æ›´ / åŠŸèƒ½å¢å¼º  
**âš¡ é‡è¦ç¨‹åº¦**ï¼šğŸ”´ é«˜  

**ğŸ“‹ å˜æ›´æ‘˜è¦**  
1. ä¸º vLLM å¼•å…¥å…¨æ–°çš„ **MooncakeConnector** å®ç°ï¼Œé‡æ–°è®¾è®¡äº† KVâ€‘cache è·¨å‰ç¼€/è§£ç èŠ‚ç‚¹çš„ä¼ è¾“æœºåˆ¶ã€‚  
2. æ–°å¢ **MooncakeBootstrapServer**ï¼Œè´Ÿè´£åœ¨åˆ†å¸ƒå¼é¢„å¡«ï¼ˆprefillï¼‰èŠ‚ç‚¹ä¸Šæ³¨å†Œå¹¶å‘ç°å„ worker çš„ ZMQ é€šä¿¡åœ°å€ï¼Œå®ç°â€œprefillâ€‘>decodeâ€ åŒå‘ KV è¿ç§»çš„åŠ¨æ€è·¯ç”±ã€‚  
3. å®Œå–„æ–‡æ¡£ã€ç¤ºä¾‹è„šæœ¬ä»¥åŠè„šæœ¬åŒ–çš„ **proxy**ï¼ˆåŸºäº FastAPI + httpxï¼‰å’Œ **run_mooncake_connector.sh**ï¼Œå¯ä¸€é”®å¯åŠ¨å¤š GPU çš„ç”Ÿäº§è€…/æ¶ˆè´¹è€…æœåŠ¡å¹¶è¿›è¡ŒåŸºå‡†æµ‹è¯•ã€‚  
4. å¯¹åŸæœ‰ `kv_connector/factory.py`ã€`kv_connector/v1/mooncake` åŒ…ç»“æ„ã€ä»¥åŠå¤§é‡å†…éƒ¨æ•°æ®ç»“æ„ï¼ˆæ–°å¢ `TransferId`ã€`MooncakeXferMetadata`ã€`MooncakeXferResponse` ç­‰ï¼‰è¿›è¡Œé‡æ„ï¼Œä»¥æ”¯æ’‘å¼‚æ­¥ã€åˆ†ç‰‡ã€è¶…æ—¶å’Œé”™è¯¯å¤„ç†ã€‚  

**ğŸ¯ å½±å“èŒƒå›´**  
- **æ ¸å¿ƒå­ç³»ç»Ÿ**ï¼š`vllm.distributed.kv_transfer.kv_connector`ï¼ˆMooncakeConnectorã€BootstrapServerï¼‰  
- **è°ƒåº¦å±‚**ï¼š`MooncakeConnectorScheduler`ã€`MooncakeConnectorWorker`ï¼ˆæ–°å¢ KV è§’è‰²åˆ¤æ–­ã€çº¿ç¨‹æ± /ä»»åŠ¡æ± é…ç½®ï¼‰  
- **è¿è¡Œæ—¶**ï¼šZMQ sideâ€‘channelã€FastAPI ä»£ç†ã€HTTPX å®¢æˆ·ç«¯ï¼ˆå…¨å±€æ”¹ä¸º `http://host:port` å½¢å¼ï¼‰  
- **æ–‡æ¡£ & ç¤ºä¾‹**ï¼š`docs/features/mooncake_connector_usage.md`ã€`examples/online_serving/disaggregated_serving/mooncake_connector/*`  
- **CI/æµ‹è¯•**ï¼šåŸæœ‰ `tests/v1/kv_connector` ä»ä¿æŒå…¼å®¹ï¼Œæ–°å¢è„šæœ¬æœªè¿›å…¥ CIï¼ˆå¤–éƒ¨ä¾èµ– `mooncake.engine`ï¼‰  

---  

### ğŸ” æŠ€æœ¯æ´å¯Ÿ  

| ç»´åº¦ | å½±å“æè¿° |
|------|----------|
| **æ¶æ„å½±å“** | 1. **ä¸­å¿ƒåŒ–æ³¨å†ŒæœåŠ¡**ï¼ˆBootstrapServerï¼‰æŠŠåŸå…ˆçš„å›ºå®šç«¯å£å‡è®¾è½¬å˜ä¸º **åŠ¨æ€å‘ç°**ï¼šæ¯ä¸ª Prefill å®ä¾‹åœ¨å¯åŠ¨æ—¶æ³¨å†Œè‡ªèº«çš„ ZMQ ç«¯å£ã€DP/TP/PP åæ ‡ï¼ŒDecoder é€šè¿‡ `remote_bootstrap_addr` æŸ¥è¯¢å¯¹åº” workerã€‚<br>2. **è§’è‰²åˆ†ç¦»**ï¼šé€šè¿‡ `kv_role`ï¼ˆproducer / consumer / bothï¼‰åœ¨ Scheduler/Worker ä¸­ç»Ÿä¸€åˆ¤æ–­ï¼Œé¿å…è€ä»£ç ä¸­ç¡¬ç¼–ç çš„ `"kv_producer"` ä¸ `"kv_consumer"`ã€‚<br>3. **å…ƒæ•°æ®åè®®å‡çº§**ï¼šä» `MooncakeAgentMetadata` æ¼”è¿›ä¸º `MooncakeXferMetadata`/`MooncakeXferResponse`ï¼Œé‡‡ç”¨ `msgspec` ç¼–ç ï¼Œæ”¯æŒ **TransferId**ã€**é”™è¯¯çŠ¶æ€**ã€**è‡ªå¢çš„ need_send / sent / sending** è®¡æ•°ï¼Œå®ç°äº† **å¼‚æ­¥åˆ†ç‰‡ã€è¶…æ—¶ã€é”™è¯¯èšåˆ**ã€‚ |
| **æ€§èƒ½å½±å“** | - **å¹¶å‘å‘é€**ï¼šæ–°å¢ `num_sender_workers`ï¼ˆé»˜è®¤ 10ï¼‰ä¸ **ä¸¤å€ä»»åŠ¡æ•°** çš„çº¿ç¨‹æ± ï¼Œä½¿å¾—åœ¨å¤š TP åœºæ™¯ä¸‹ä»èƒ½ä¿æŒå‘é€ç«¯ Saturateã€‚<br>- **è¯·æ±‚è·¯ç”±**ï¼šä½¿ç”¨ ZMQ **ROUTER/DEALER** åŒå‘æ¨¡å¼ï¼Œå•æ¡è¯·æ±‚åªèµ°ä¸€æ¬¡ ZMQï¼ˆmetadataï¼‰+ RDMA/å…¶ä»– Mooncake åè®®ï¼ˆå®é™… KV å—ï¼‰ï¼Œç†è®ºä¸Šæ¯”åŸå§‹å•å‘è½®è¯¢æ›´ä½å»¶è¿Ÿã€‚<br>- **è¶…æ—¶ä¸å›å‹**ï¼š`VLLM_MOONCAKE_ABORT_REQUEST_TIMEOUT`ï¼ˆé»˜è®¤ 480â€¯sï¼‰åœ¨å‘é€ç«¯åš `asyncio.wait`ï¼Œå¯ä»¥åŠæ—¶å›æ”¶é˜»å¡è¯·æ±‚ï¼Œé˜²æ­¢ KV å—æ³„æ¼ã€‚<br>- **é¢å¤–å¼€é”€**ï¼šå¼•å…¥ FastAPI ä»£ç†ã€HTTPX æŸ¥è¯¢ bootstrapã€é¢å¤–çš„ `msgspec` ç¼–è§£ç å’Œ ZMQ socket åˆ›å»ºï¼Œå¯åŠ¨æ—¶çº¦å¢åŠ  10â€‘20â€¯msï¼Œè¿è¡Œæ—¶å¯¹ååå½±å“å¯å¿½ç•¥ï¼ˆæ®åŸºå‡†è„šæœ¬æ˜¾ç¤ºï¼Œä¸åŸå®ç°ç›¸å½“ï¼‰ã€‚ |
| **å®‰å…¨è€ƒè™‘** | - **ç½‘ç»œæš´éœ²**ï¼šBootstrapServer ä¸ Proxy é»˜è®¤ç»‘å®š `0.0.0.0`ï¼ˆå¯é€šè¿‡ `--host`/`--port` è‡ªå®šä¹‰ï¼‰ï¼Œè‹¥åœ¨ä¸å¯ä¿¡ç½‘ç»œä¸­è¿è¡Œï¼Œå¯èƒ½è¢«æœªæˆæƒèŠ‚ç‚¹æŸ¥è¯¢æˆ–æ³¨å†Œã€‚å»ºè®®åœ¨ç”Ÿäº§ç¯å¢ƒä½¿ç”¨å†…éƒ¨ç½‘ç»œæˆ–åŠ å±‚é˜²ç«å¢™ã€‚<br>- **èº«ä»½æ ¡éªŒ**ï¼šç›®å‰ä¸åšä»»ä½•èº«ä»½éªŒè¯ï¼Œæ³¨å†Œä¸æŸ¥è¯¢å‡ä¸ºæ˜æ–‡ HTTPï¼›è‹¥éœ€è¦å¤šç§Ÿæˆ·æˆ–è·¨é›†ç¾¤ä½¿ç”¨ï¼Œéœ€è¦åœ¨ `RegisterWorkerPayload` ä¸­åŠ å…¥ token/ç­¾åæœºåˆ¶ã€‚<br>- **è¾“å…¥éªŒè¯**ï¼šFastAPI è‡ªåŠ¨å¯¹ `RegisterWorkerPayload` è¿›è¡Œå­—æ®µç±»å‹æ£€æŸ¥ï¼Œä½†æœªæ ¡éªŒ `addr` çš„åˆæ³•æ€§ï¼ˆIP/ç«¯å£ï¼‰ï¼Œç†è®ºä¸Šå¯åˆ¶é€  ZMQ è¿æ¥åˆ°æ¶æ„åœ°å€è¿›è¡Œ DoSã€‚å¯åœ¨æ³¨å†Œæ—¶å¯¹ `addr` åšæ­£åˆ™æˆ– IP ç™½åå•ã€‚ |
| **å¯ç»´æŠ¤æ€§** | - **ä»£ç ä½“é‡**å¤§å¹…å¢é•¿ï¼ˆ+~1500 è¡Œï¼‰ï¼Œä½†é€šè¿‡ **dataclass / msgspec** æ˜ç¡®äº†æ•°æ®ç»“æ„ï¼Œæ˜“äºè¿½è¸ªã€‚<br>- **åˆ†å±‚æ¸…æ™°**ï¼šScheduler åªè´Ÿè´£ç”Ÿæˆ `MooncakeConnectorMetadata`ï¼ŒWorker åªåšç½‘ç»œ I/O ä¸å—ä¼ è¾“ï¼Œç¬¦åˆå•ä¸€èŒè´£ã€‚<br>- **å¤–éƒ¨ä¾èµ–**ï¼šå¼ºåˆ¶ä¾èµ– `mooncake.engine`ï¼ˆæœªåœ¨ vLLM `requirements.txt` ä¸­å£°æ˜ï¼‰ï¼Œå¯¼è‡´åœ¨ç¼ºå¤±æ—¶ä¼šåœ¨è¿è¡Œæ—¶æŠ›å¼‚å¸¸ï¼›éœ€è¦åœ¨æ–‡æ¡£ä¸ CI ä¸­æ˜¾å¼æ·»åŠ å®‰è£…æ­¥éª¤ã€‚ |
| **å…¼å®¹æ€§** | - **KVâ€‘Connector æ¥å£**ä¿æŒ `KVConnectorBase_V1`ï¼Œå› æ­¤æ—§çš„ `ExampleConnector`ã€`NixlConnector` ç­‰ä»å¯å…±å­˜ã€‚<br>- **KVâ€‘Role = kv_both** å·²å¾—åˆ°æ”¯æŒï¼ˆå†…éƒ¨åŒæ—¶åˆ›å»º sender & receiverï¼‰ï¼Œä½†æœªåœ¨è„šæœ¬ä¸­æ¼”ç¤ºã€‚ |

---  

**âš ï¸ æ½œåœ¨é£é™©**  
1. **BootstrapServer å•ç‚¹æ•…éšœ**ï¼šæ‰€æœ‰ Decoder å¿…é¡»æˆåŠŸæŸ¥è¯¢åˆ°æ³¨å†Œè¡¨ï¼›è‹¥æœåŠ¡æœªå¯åŠ¨æˆ–å› ç½‘ç»œåˆ†åŒºå¯¼è‡´æŸ¥è¯¢è¶…æ—¶ï¼Œæ•´ä¸ªåˆ†å¸ƒå¼æ¨ç†é“¾è·¯ä¼šå¡æ­»ã€‚  
2. **ZMQ ç«¯å£å†²çª**ï¼š`side_channel_port` ç”± `bind_to_random_port` è‡ªåŠ¨åˆ†é…ï¼Œä½†å¦‚æœåŒä¸€æœºå™¨ä¸Šå¯åŠ¨å¤šä¸ª Prefill å®ä¾‹ä¸” `bind_to_random_port` å–ä¸åˆ°å¯ç”¨ç«¯å£ï¼Œä¼šæŠ›å¼‚å¸¸ã€‚  
3. **å¼‚æ„ TP ä¸æ”¯æŒ**ï¼šä»£ç ä¸­æ˜ç¡®æŠ›å‡º `NotImplementedError`ï¼Œè‹¥æœªæ¥ç”¨æˆ·å°è¯•ä¸åŒ TP å¤§å°çš„ Prefill/Decode ç»„åˆï¼Œå°†ç›´æ¥å´©æºƒã€‚  
4. **è¶…æ—¶è¯¯åˆ¤**ï¼š`VLLM_MOONCAKE_ABORT_REQUEST_TIMEOUT` å–å€¼ä¸å½“ï¼ˆè¿‡å°ï¼‰ä¼šå¯¼è‡´æ­£å¸¸çš„é•¿è¯·æ±‚è¢«æå‰é‡Šæ”¾ KV å—ï¼Œå¯¼è‡´é”™è¯¯çš„ â€œblock not foundâ€ å¤±è´¥ã€‚  
5. **å®‰å…¨æ³„éœ²**ï¼šæ— èº«ä»½éªŒè¯çš„æ³¨å†Œ/æŸ¥è¯¢æ¥å£åœ¨å…¬ç½‘æš´éœ²æ—¶å¯èƒ½è¢«æ¶æ„èŠ‚ç‚¹åˆ©ç”¨è¿›è¡Œ DoS æˆ–ä¼ªé€ æ³¨å†Œä¿¡æ¯ï¼Œä½¿ Decoder ä¸é”™è¯¯çš„ Prefill ç«¯é€šä¿¡ã€‚  

---  

**ğŸ’¡ å…³æ³¨å»ºè®®**  
1. **å¼¹æ€§å¯åŠ¨**ï¼šåœ¨ `run_mooncake_connector.sh` ä¸­åŠ å…¥å¯¹ BootstrapServer å¯åŠ¨æˆåŠŸçš„æ£€æŸ¥ï¼ˆè½®è¯¢ `/query`ï¼‰ï¼Œè‹¥å¤±è´¥è‡ªåŠ¨é€€å‡ºå¹¶ç»™å‡ºæ˜ç¡®é”™è¯¯ã€‚  
2. **å®‰å…¨åŠ å›º**ï¼š  
   - åœ¨ `MooncakeBootstrapServer` åŠ å…¥ `--auth-token` å‚æ•°ï¼Œä»…å½“è¯·æ±‚å¤´éƒ¨å¸¦ç›¸åŒ token æ—¶æ¥å—æ³¨å†Œ/æŸ¥è¯¢ã€‚  
   - å¯¹ `addr` è¿›è¡Œæ­£åˆ™æ ¡éªŒï¼Œåªå…è®¸æœ¬æœºæˆ–å†…éƒ¨å­ç½‘ IPã€‚  
3. **ç›‘æ§ & ç»Ÿè®¡**ï¼šåœ¨ `MooncakeConnectorWorker` ä¸­è®°å½•ä»¥ä¸‹æŒ‡æ ‡å¹¶è¾“å‡ºåˆ° `vLLM` ç›‘æ§ä½“ç³»ï¼š  
   - æ¯ç§’å‘é€/æ¥æ”¶å—æ•°ã€å¹³å‡å»¶è¿Ÿã€è¶…æ—¶æ¬¡æ•°ã€é”™è¯¯ç åˆ†å¸ƒã€‚  
4. **å®¹é”™ä¸é«˜å¯ç”¨**ï¼šè€ƒè™‘å°† BootstrapServer æ”¹ä¸º **å¤šå®ä¾‹**ï¼ˆä½¿ç”¨ä¸€è‡´æ€§å“ˆå¸Œæˆ– etcdï¼‰æˆ–åœ¨ `prefill` å¯åŠ¨æ—¶ **é‡è¯•** è¿æ¥è‡³å·²å­˜åœ¨çš„æœåŠ¡å™¨ï¼ˆå¦‚æœå·²åœ¨åŒä¸€ DP ç»„å†…ï¼‰ã€‚  
5. **æ–‡æ¡£åŒæ­¥**ï¼šåœ¨ `docs/` ä¸­æ³¨æ˜ **ä½¿ç”¨å‰æ**ï¼ˆå¿…é¡»æœ‰ `mooncake.engine`ã€è‡³å°‘ 2 GPUã€å†…

---

#### ğŸŸ¡ ä¸­é‡è¦åº¦å˜æ›´ (21)

### [Model] Apply #32631 for recent models (#33785)
**SHA**: `e57ef99` | ğŸ”— [æŸ¥çœ‹æäº¤](https://github.com/vllm-project/vllm/commit/e57ef99b409ba651695a515f6022c9badf25b2a2)

**ğŸ¯ å˜æ›´ç±»å‹**ï¼šé‡æ„ / åŠŸèƒ½å¢å¼º  
**âš¡ é‡è¦ç¨‹åº¦**ï¼šğŸŸ¡ ä¸­  

**ğŸ“‹ å˜æ›´æ‘˜è¦**  
- åœ¨å¤šä¸ªå¤šæ¨¡æ€æ¨¡å‹ï¼ˆeagle2_5_vlã€openpangu_vlã€qwen3_asrã€funaudiochatï¼‰ä¸­ï¼Œå¼•å…¥ `with self._mark_tower_model(... )` å’Œ `with self._mark_language_model(... )` è¯­å¢ƒç®¡ç†å™¨ï¼Œæ˜¾å¼æ ‡è®° Vision/Audio Tower ä¸ Language Modelã€‚  
- åŒæ—¶åˆ é™¤äº†æ¯ä¸ªæ¨¡å‹ç»Ÿä¸€æä¾›çš„ `get_language_model()` æ–¹æ³•ã€‚  

**ğŸ¯ å½±å“èŒƒå›´**  
- `vllm/model_executor/models/*` ä¸­çš„ 4â€¯ä¸ªæ¨¡å‹å®ç°ã€‚  
- ä¾èµ– `model.get_language_model()` çš„å¤–éƒ¨å·¥å…·æˆ–è‡ªå®šä¹‰æ’ä»¶ï¼ˆå¦‚ LoRAã€prefixâ€‘tuningã€ç›‘æ§è„šæœ¬ï¼‰å¯èƒ½ä¼šå‡ºç° `AttributeError`ã€‚  
- è´Ÿè´£æ¨¡å‹åˆ‡åˆ†ã€å¹¶è¡Œè°ƒåº¦ã€KVâ€‘Cache åˆ†é…çš„å†…éƒ¨è°ƒåº¦å™¨å°†è·ç›Šäºæ›´ç²¾ç¡®çš„ â€œtower / languageâ€ æ ‡è¯†ã€‚  

**ğŸ’¡ å…³æ³¨å»ºè®®**  
1. **å…¼å®¹æ€§**ï¼šè‹¥é¡¹ç›®ä¸­ä»é€šè¿‡ `model.get_language_model()` è®¿é—®è¯­è¨€å­æ¨¡å‹ï¼Œè¯·æ”¹ä¸ºç›´æ¥ä½¿ç”¨ `model.language_model` æˆ–åœ¨å¿…è¦æ—¶è‡ªè¡Œå®ç°å…¼å®¹åŒ…è£…ã€‚  
2. **æ–‡æ¡£ & ç¤ºä¾‹**ï¼šæ›´æ–°æ¨¡å‹ä½¿ç”¨æ–‡æ¡£ï¼Œè¯´æ˜ `vision_model` / `audio_tower` ä¸ `language_model` çš„æ–°æ ‡è®°æœºåˆ¶ä»¥åŠæ¨èçš„å±æ€§è®¿é—®æ–¹å¼ã€‚  
3. **æµ‹è¯•**ï¼šè¿è¡Œå®Œæ•´çš„å•å…ƒ/é›†æˆæµ‹è¯•ï¼Œå°¤å…¶æ˜¯å¤šæ¨¡æ€æ¨ç†ã€LoRAã€æ¨¡å‹å¹¶è¡Œã€KVâ€‘Cache çš„è·¯å¾„ï¼Œç¡®ä¿è°ƒåº¦å™¨èƒ½å¤Ÿæ­£ç¡®è¯†åˆ«å¹¶åˆ†é…èµ„æºã€‚  
4. **å›é€€æ–¹æ¡ˆ**ï¼šè‹¥å‡ºç°æ„å¤–å…¼å®¹é—®é¢˜ï¼Œå¯ä¸´æ—¶åœ¨æ¨¡å‹å­ç±»ä¸­åŠ å…¥æ—§çš„ `get_language_model` æ–¹æ³•çš„å…¼å®¹å®ç°ï¼Œä»¥ä¾¿å¹³æ»‘å‡çº§ã€‚  

æ€»ä½“è€Œè¨€ï¼Œæ­¤æ¬¡é‡æ„æå‡äº†æ¨¡å‹ç»„ä»¶çš„å¯è¾¨è¯†åº¦ï¼Œä¸ºåç»­å¤šæ¨¡æ€å¹¶è¡Œä¼˜åŒ–å¥ å®šåŸºç¡€ï¼Œåªéœ€æ³¨æ„å¯¹å·²æœ‰è°ƒç”¨çš„è¿ç§»å³å¯ã€‚

---

### [Bugfix][Model] Fix audio-in-video support for Qwen2.5-Omni and Qwen3-Omni       (#33605)
**SHA**: `f8516a1` | ğŸ”— [æŸ¥çœ‹æäº¤](https://github.com/vllm-project/vllm/commit/f8516a1ab95febcf131a37478914031f50fdd9db)

**ğŸ¯ å˜æ›´ç±»å‹**ï¼šBug ä¿®å¤ï¼ˆå¤šæ¨¡æ€æ¨¡å‹ audioâ€‘inâ€‘video æ”¯æŒï¼‰  
**âš¡ é‡è¦ç¨‹åº¦**ï¼šğŸŸ¡ ä¸­  

**ğŸ“‹ å˜æ›´æ‘˜è¦**  
- ä¸º Qwen2.5â€‘Omni ä¸ Qwen3â€‘Omni æ·»åŠ äº†â€¯`check_interleaved_audio_video` ä¸ `merge_interleaved_embeddings` ä¸¤ä¸ªå·¥å…·å‡½æ•°ï¼Œä¸“é—¨æ£€æµ‹å¹¶å¤„ç† **éŸ³é¢‘åµŒå…¥åœ¨è§†é¢‘ä»¤ç‰Œåºåˆ—ä¸­äº¤é”™** çš„æƒ…å†µã€‚  
- åœ¨ `embed_input_ids` æµç¨‹ä¸­å…ˆåˆ¤æ–­æ˜¯å¦å­˜åœ¨äº¤é”™çš„éŸ³è§†é¢‘ä»¤ç‰Œï¼Œè‹¥æ˜¯åˆ™ä½¿ç”¨ `merge_interleaved_embeddings` å°†è§†é¢‘ã€éŸ³é¢‘ã€å…¶å®ƒå¤šæ¨¡æ€åµŒå…¥æŒ‰çœŸå®ä½ç½®é‡æ–°æ’åºåå†™å› `inputs_embeds`ï¼›å¦åˆ™èµ°åŸæ¥çš„ `_merge_multimodal_embeddings`ã€‚  
- Qwen3â€‘Omni çš„ deepâ€‘stack é€»è¾‘äº¦åŒæ­¥åŠ å…¥äº¤é”™æ£€æµ‹ï¼Œé¿å…åœ¨å¤šå°ºåº¦è§†è§‰ç‰¹å¾å¤„ç†æ—¶ä½¿ç”¨é”™è¯¯çš„æ©ç ã€‚

**ğŸ¯ å½±å“èŒƒå›´**  
- `vllm/model_executor/models/qwen2_5_omni_thinker.py`  
- `vllm/model_executor/models/qwen3_omni_moe_thinker.py`ï¼ˆåŠå…¶å†…éƒ¨çš„ deepâ€‘stack è§†è§‰å¤„ç†ï¼‰  
- ç›¸å…³çš„å¤šæ¨¡æ€å¤„ç†å·¥å…· `vllm/model_executor/models/qwen2_5_omni_thinker.py` ä¸­çš„ç§æœ‰åˆå¹¶å®ç° `_merge_multimodal_embeddings`ï¼ˆé—´æ¥å—å½±å“ï¼‰ã€‚  

**ğŸ’¡ å…³æ³¨å»ºè®®**  
1. **å›å½’æµ‹è¯•**ï¼šé’ˆå¯¹ Qwen2.5â€‘Omniã€Qwen3â€‘Omni å¢åŠ  audioâ€‘inâ€‘video åœºæ™¯çš„å•å…ƒ/é›†æˆæµ‹è¯•ï¼ŒéªŒè¯äº¤é”™åºåˆ—çš„åµŒå…¥ä½ç½®ä¸è¾“å‡ºä¸€è‡´ã€‚  
2. **æ€§èƒ½è¯„ä¼°**ï¼š`merge_interleaved_embeddings` é€šè¿‡ `torch.cat` ä¸ç´¢å¼•èµ‹å€¼å®ç°ï¼Œä»ä¿æŒ O(N) æ•ˆç‡ï¼Œä½†å»ºè®®åœ¨å¤§æ‰¹é‡æ¨ç†æ—¶ç›‘æµ‹æ˜¾å­˜ç¢ç‰‡ä¸æ‹·è´å¼€é”€ã€‚  
3. **æ–‡æ¡£æ›´æ–°**ï¼šåœ¨æ¨¡å‹ä½¿ç”¨è¯´æ˜ä¸­æ³¨æ˜ `use_audio_in_video=True` æ—¶çš„è¾“å…¥æ ¼å¼è¦æ±‚åŠè¯¥åŠŸèƒ½çš„å®ç°ç»†èŠ‚ã€‚  
4. **å…¼å®¹æ€§æ£€æŸ¥**ï¼šç¡®è®¤æ—§ç‰ˆ `is_multimodal` æ©ç é€»è¾‘åœ¨ä¸å‡ºç°äº¤é”™æ—¶ä»ä¿æŒåŸå§‹è·¯å¾„ä¸å˜ï¼Œé¿å…æ„å¤–è¡Œä¸ºå›å½’ã€‚  

æ€»ä½“è€Œè¨€ï¼Œæ­¤æ¬¡æ”¹åŠ¨è§£å†³äº† Qwen ç³»åˆ—åœ¨éŸ³è§†é¢‘æ··åˆè¾“å…¥æ—¶åµŒå…¥é”™ä½çš„å…³é”® bugï¼Œå¯¹å¤šæ¨¡æ€æ¨ç†çš„æ­£ç¡®æ€§æå‡æ˜¾è‘—ï¼Œå½±å“èŒƒå›´å±€é™äºå¯¹åº”æ¨¡å‹å®ç°ï¼Œé£é™©å¯é€šè¿‡ä¸Šè¿°æµ‹è¯•ä¸æ–‡æ¡£åŒæ­¥é™ä½ã€‚

---

### [PERF] Change GDN Attention State Layout from [N, HV, K, V] to [N, HV, V, K] (#33291)
**SHA**: `8240580` | ğŸ”— [æŸ¥çœ‹æäº¤](https://github.com/vllm-project/vllm/commit/824058076c56164a3772a5f5829bd9662507e5a3)

**ğŸ¯ å˜æ›´ç±»å‹**ï¼šæ€§èƒ½ä¼˜åŒ– / é‡æ„  
**âš¡ é‡è¦ç¨‹åº¦**ï¼šğŸŸ¡ ä¸­  
**ğŸ“‹ å˜æ›´æ‘˜è¦**ï¼šå°† Gatedâ€‘Deltaâ€‘Netï¼ˆGDNï¼‰æ³¨æ„åŠ›çŠ¶æ€çš„å†…éƒ¨å¸ƒå±€ä» `[N, HV, K, V]` è°ƒæ•´ä¸º `[N, HV, V, K]`ï¼Œå¹¶åœ¨æ‰€æœ‰ç›¸å…³çš„ CUDAâ€‘Triton kernelsã€Python æ¥å£ä»¥åŠæ–‡æ¡£ä¸­åŒæ­¥æ›´æ”¹ã€‚æ­¤å¸ƒå±€ä½¿å¾—åœ¨åç»­çš„çŸ©é˜µä¹˜æ³•ä¸­å¯ä»¥ç›´æ¥ä½¿ç”¨ `tl.trans`ï¼Œæå‡ç¼“å­˜è®¿é—®å±€éƒ¨æ€§å’Œç®—å­èåˆæ•ˆç‡ã€‚  

**ğŸ¯ å½±å“èŒƒå›´**  
- `vllm/model_executor/layers/fla/ops/*` ä¸­çš„æ‰€æœ‰ kernelï¼ˆ`chunk_delta_h`, `chunk_o`, `fused_recurrent` ç­‰ï¼‰  
- å…¬å…± API `chunk_gated_delta_rule`ã€`fused_recurrent_gated_delta_rule`ã€`fused_recurrent_kda_fwd` çš„ `initial_state`/`final_state` å‚æ•°å½¢çŠ¶è¯´æ˜  
- ä¸ GDN ç›¸å…³çš„æ¨¡å‹ checkpoint/loadingã€åºåˆ—åŒ–ã€ä»¥åŠå¯èƒ½çš„è‡ªå®šä¹‰åˆå§‹åŒ–ä»£ç   
- `mamba_utils.gated_delta_net_state_shape` ä¸­çš„ç»´åº¦é¡ºåºè®¡ç®—  

**ğŸ’¡ å…³æ³¨å»ºè®®**  
1. **å…¼å®¹æ€§**ï¼šè¯¥æ”¹åŠ¨æ˜¯ **ç ´åæ€§** çš„ï¼Œæ‰€æœ‰ä½¿ç”¨ GDN çŠ¶æ€çš„æ—§æ¨¡å‹æˆ–è‡ªè¡Œæ„é€  `initial_state` çš„ä»£ç éœ€è¦æ”¹ä¸º `[..., V, K]`ã€‚å»ºè®®åœ¨é¦–æ‰¹å‘å¸ƒä¸­åŠ å…¥è¿ç§»è„šæœ¬æˆ–åœ¨ API ä¸­æ·»åŠ  `DeprecationWarning`ï¼Œå¹¶åœ¨ `README` æ˜ç¡®è¯´æ˜ã€‚  
2. **å•å…ƒæµ‹è¯•**ï¼šæ–°å¢é’ˆå¯¹ä¸åŒ `K/V` å¤§å°ï¼ˆå°¤å…¶æ˜¯ >64ã€>128ã€>192 çš„åˆ†å—è·¯å¾„ï¼‰çš„å¯¹æ¯”æµ‹è¯•ï¼Œç¡®ä¿æ•°å€¼ä¸æ—§å¸ƒå±€åœ¨ `float16/bfloat16` ä¸‹ä¿æŒä¸€è‡´ã€‚  
3. **æ€§èƒ½éªŒè¯**ï¼šåœ¨å¤šå¡/TPP ç¯å¢ƒä¸‹è·‘åŸºå‡†ï¼Œç¡®è®¤æ–°å¸ƒå±€å¸¦æ¥çš„å¸¦å®½æå‡æ˜¯å¦è¾¾é¢„æœŸï¼ˆå°¤å…¶æ˜¯ `triton` çš„ `tl.trans` æ˜¯å¦è¢«æ­£ç¡®å±•å¼€ï¼‰ã€‚  
4. **æ£€æŸ¥ stride/contiguity**ï¼šç”±äº `torch.Tensor.stride` æ”¹å˜ï¼ŒåŠ è½½/ä¿å­˜ checkpoint æ—¶éœ€è¦ç¡®ä¿ `torch.save` ä¸ `torch.load` èƒ½æ­£ç¡®æ¢å¤æ–°å¸ƒå±€ï¼›å¦‚æœæœ‰ `torch.nn.Parameter` åŒ…è£…çš„ stateï¼Œéœ€è¦é‡æ–° `contiguous()`ã€‚  
5. **æ–‡æ¡£åŒæ­¥**ï¼šæ‰€æœ‰ docstringã€ç¤ºä¾‹ä»£ç ä»¥åŠ `examples/` ä¸­çš„æ¨¡å‹æ„é€ è„šæœ¬å‡å·²æ›´æ–°ä¸º `[..., V, K]`ï¼Œè¯·å†æ¬¡å®¡é˜…ç¡®ä¿æ— é—æ¼ã€‚  

æ€»ä½“æ¥çœ‹ï¼Œå¸ƒå±€è°ƒæ•´å¯¹ç®—å­å†…å­˜è®¿é—®æ¨¡å¼æœ‰ç§¯æå½±å“ï¼Œä½†éœ€åœ¨è¿ç§»è·¯å¾„ã€æµ‹è¯•è¦†ç›–åŠæ–‡æ¡£ä¸Šåšå¥½æ”¯æ’‘ï¼Œä»¥å…ç°æœ‰ç”¨æˆ·åœ¨å‡çº§åé­é‡ Shape mismatchã€‚

---

### [KV Connector][BugFix] scheduler: Delay freeing blocks of aborted async loads (#32255)
**SHA**: `8e32690` | ğŸ”— [æŸ¥çœ‹æäº¤](https://github.com/vllm-project/vllm/commit/8e3269086916d81b010a2d6209784a106ac2994a)

**ğŸ¯ å˜æ›´ç±»å‹**ï¼šBug ä¿®å¤  
**âš¡ é‡è¦ç¨‹åº¦**ï¼šğŸŸ¡ ä¸­  
**ğŸ“‹ å˜æ›´æ‘˜è¦**ï¼šåœ¨ KVâ€‘Connector çš„å¼‚æ­¥åŠ è½½è¿‡ç¨‹ä¸­ï¼Œè‹¥è¯·æ±‚è¢« `FINISHED_ABORTED` æå‰ç»ˆæ­¢ï¼Œæ—§å®ç°ä¼šç«‹å³é‡Šæ”¾å…¶å ç”¨çš„å—ï¼Œå¯¼è‡´åç»­å¼‚æ­¥ä¼ è¾“å†™å…¥å·²å›æ”¶çš„å—å¹¶ corrupt KV æ•°æ®ã€‚æ­¤æ¬¡ä¿®æ”¹åœ¨ `Scheduler.finish_requests` ä¸ `_free_request` ä¸­å¼•å…¥ â€œå»¶è¿Ÿé‡Šæ”¾å—â€ æœºåˆ¶ï¼šå½“è¯·æ±‚ä»åœ¨ç­‰å¾…è¿œç«¯ KVï¼ˆ`WAITING_FOR_REMOTE_KVS`ï¼‰ä¸”å¯¹åº”çš„ `finished_recving_kv_req_ids` å°šæœªæ”¶åˆ°å®Œæˆä¿¡å·æ—¶ï¼Œå…ˆä¿ç•™å—ï¼Œå¾… KVâ€‘Connector å›æŠ¥ `finished_recving` æ—¶å†ç»Ÿä¸€é‡Šæ”¾ã€‚ç›¸åº”åœ°åœ¨ `_update_from_kv_xfer_finished` ä¸­è¡¥å……äº†å¯¹å¼‚å¸¸çŠ¶æ€çš„æ–­è¨€ä¸å³æ—¶é‡Šæ”¾é€»è¾‘ã€‚æ–°å¢ä¸‰é¡¹å•å…ƒ/é›†æˆæµ‹è¯•è¦†ç›–ï¼šâ‘  ç­‰å¾…è¿œç«¯ KV æ—¶è¢« abort â†’ æ­£å¸¸åˆ é™¤ï¼›â‘¡ å·²æ”¶åˆ°è¿œç«¯ KV å®Œæˆæ ‡è®°å abort â†’ ç«‹å³åˆ é™¤ï¼›â‘¢ å¼‚æ­¥åŠ è½½æœªå®Œæˆå³ abort â†’ ä»èƒ½æ­£ç¡®å®ŒæˆåŠ è½½ååˆ é™¤ã€‚

**ğŸ¯ å½±å“èŒƒå›´**  
- `vllm/v1/core/sched/scheduler.py`ï¼ˆè¯·æ±‚ç»“æŸã€å—é‡Šæ”¾é€»è¾‘ï¼‰  
- KVâ€‘Connector ç›¸å…³æ›´æ–° (`_update_from_kv_xfer_finished`)  
- æµ‹è¯•å¥—ä»¶ `tests/v1/core/test_scheduler.py`ã€`tests/v1/kv_connector/unit/test_offloading_connector.py`  

**ğŸ’¡ å…³æ³¨å»ºè®®**  
1. **ä»£ç å®¡é˜…**ï¼šç¡®è®¤ `delay_free_blocks` ä»…åœ¨ `WAITING_FOR_REMOTE_KVS` åœºæ™¯è§¦å‘ï¼Œé¿å…å¯¹å·²å®Œæˆè¯·æ±‚äº§ç”Ÿä¸å¿…è¦çš„å»¶è¿Ÿã€‚  
2. **å¹¶å‘å®‰å…¨**ï¼š`finished_recving_kv_req_ids` åœ¨å¤šçº¿ç¨‹/å¤šè¿›ç¨‹ç¯å¢ƒä¸‹ä»é€šè¿‡å•çº¿ç¨‹è°ƒåº¦å™¨è®¿é—®ï¼Œè‹¥æœªæ¥æ”¹ä¸ºå¹¶å‘æ›´æ–°ï¼Œéœ€è¦åŠ é”æˆ–åŸå­æ“ä½œã€‚  
3. **æ€§èƒ½è¯„ä¼°**ï¼šå»¶è¿Ÿé‡Šæ”¾å¯èƒ½å¯¼è‡´çŸ­æš‚çš„ GPU block ç´¯è®¡å¢åŠ ï¼Œå»ºè®®åœ¨å¤§è§„æ¨¡å¹¶å‘ abort åœºæ™¯ä¸‹è·‘åŸºå‡†ï¼Œç¡®ä¿ä¸ä¼šå‡ºç°æ˜¾è‘—çš„å†…å­˜å³°å€¼ã€‚  
4. **å›å½’æµ‹è¯•**ï¼šè¿è¡Œå…¨å¥— `vllm` æµ‹è¯•ï¼Œç‰¹åˆ«æ˜¯é•¿æ—¶é—´è¿è¡Œçš„ KVâ€‘offload åœºæ™¯ï¼Œç¡®ä¿ abortâ€‘load ä¸å†è§¦å‘ KV æ•°æ®æŸåã€‚  
5. **æ–‡æ¡£/æ³¨é‡Š**ï¼šåœ¨ `Scheduler.finish_requests` ä¸ `_free_request` æ·»åŠ ä½¿ç”¨è¯´æ˜ï¼Œå¸®åŠ©åç»­ç»´æŠ¤è€…ç†è§£ â€œå»¶è¿Ÿé‡Šæ”¾å—â€ çš„è§¦å‘æ¡ä»¶ã€‚  

æ€»ä½“æ¥çœ‹ï¼Œæ­¤æ¬¡æ”¹åŠ¨è§£å†³äº†æ½œåœ¨çš„æ•°æ®è…è´¥é£é™©ï¼Œå½±å“èŒƒå›´å±€é™åœ¨è°ƒåº¦å™¨ä¸ KVâ€‘Connectorï¼Œé£é™©å¯æ§ã€‚å»ºè®®åœ¨æ­£å¼å‘å¸ƒå‰å®Œæˆä¸Šè¿°å›å½’ä¸æ€§èƒ½éªŒè¯ã€‚

---

### [XPU][2/N] add support unquantized moe support for xpu  (#33659)
**SHA**: `f79f777` | ğŸ”— [æŸ¥çœ‹æäº¤](https://github.com/vllm-project/vllm/commit/f79f777803ae70bc3ee2a4cfd2822e26a378dcdb)

**ğŸ¯ å˜æ›´ç±»å‹**ï¼šåŠŸèƒ½å¢å¼º  
**âš¡ é‡è¦ç¨‹åº¦**ï¼šğŸŸ¡ ä¸­  

**ğŸ“‹ å˜æ›´æ‘˜è¦**  
- ä¸º XPUï¼ˆIntel GPUï¼‰åŠ å…¥å¯¹æœªé‡åŒ– MoEï¼ˆMixtureâ€‘ofâ€‘Expertsï¼‰æ¨¡å‹çš„åŸç”Ÿæ”¯æŒã€‚  
- æ–°å¢ `XPUExperts` å®ç°å¹¶åœ¨ç»Ÿä¸€çš„ fusedâ€‘moe æ¥å£ä¸­æ³¨å†Œï¼Œä½¿è°ƒåº¦é€»è¾‘èƒ½å¤Ÿåœ¨ XPU ä¸Šèµ°è‡ªç ” kernelã€‚  
- åŒæ­¥ CI è„šæœ¬ä¸ä¾èµ–ï¼ˆvllm_xpu_kernels å‡è‡³ 0.1.1ï¼‰ï¼Œå¹¶åœ¨ CI æµ‹ä¾‹ä¸­åŠ å…¥ PowerMoE ç¤ºä¾‹ã€‚  

**ğŸ¯ å½±å“èŒƒå›´**  
- `vllm/model_executor/layers/fused_moe/*`ï¼ˆ`__init__`, `oracle/unquantized.py`, `unquantized_fused_moe_method.py`, æ–°å¢ `xpu_fused_moe.py`ï¼‰  
- å¹³å°æ£€æµ‹ `vllm/platforms/interface.py`ï¼ˆä½¿ç”¨ `is_xpu`ï¼‰  
- CI è„šæœ¬ä¸ `requirements/xpu.txt`  

**ğŸ’¡ å…³æ³¨å»ºè®®**  
1. **å…¼å®¹æ€§æ£€æŸ¥**ï¼š`UnquantizedMoeBackend.XPU` è¢«ä» â€œä¸æ”¯æŒâ€ åˆ—è¡¨ä¸­ç§»é™¤ï¼Œä½†åœ¨ `unquantized_fused_moe_method.py` ä»ä¿ç•™å¯¹ XPU çš„è€å®ç°æ³¨é‡Šï¼Œéœ€ç¡®è®¤ `self._is_monolithic`ã€`_select_monolithic` ç­‰åˆ†æ”¯ä¸å†è¯¯è§¦ã€‚  
2. **æµ‹è¯•è¦†ç›–**ï¼šCI å·²åŠ å…¥ PowerMoE ç¤ºä¾‹ï¼Œä½†å»ºè®®è¡¥å……å•å…ƒæµ‹è¯•éªŒè¯ `XPUExperts.apply` çš„è¿”å›å€¼ã€å¼‚å¸¸è·¯å¾„ï¼ˆä¸æ”¯æŒçš„æ¿€æ´»/é‡åŒ–æ–¹æ¡ˆï¼‰ã€‚  
3. **æ–‡æ¡£åŒæ­¥**ï¼šREADME/ä½¿ç”¨æŒ‡å—ä¸­åº”æ ‡æ˜ XPU ä»…æ”¯æŒæœªé‡åŒ– MoEï¼Œä¸”ç›®å‰ä»…æ”¯æŒ `silu/gelu/swigluoai` ä»¥åŠ FP8â€‘static Tensorã€‚  
4. **ä¾èµ–ç®¡ç†**ï¼š`vllm_xpu_kernels` ç‰ˆæœ¬å‡çº§å¯èƒ½å½±å“å·²æœ‰ XPU ç¯å¢ƒï¼Œå‘å¸ƒæ—¶è¯·æä¾›å…¼å®¹çŸ©é˜µæˆ–å›é€€æŒ‡å¼•ã€‚  

æ€»ä½“æ¥çœ‹ï¼Œæ­¤æ¬¡æ”¹åŠ¨ä¸º XPU å¹³å°æä¾›äº†å®Œæ•´çš„ MoE æ”¯æŒï¼Œæ ¸å¿ƒå®ç°å·²æŠ½è±¡ä¸º `XPUExperts`ï¼Œå¯¹å·²æœ‰ä»£ç ä¾µå…¥åº¦ä½ï¼Œä½†ä»éœ€å…³æ³¨åˆ†æ”¯é€»è¾‘å’Œæµ‹è¯•å®Œæ•´æ€§ã€‚

---

### [Metrics] Add labeled prompt token metrics for P/D disaggregation (#33290)
**SHA**: `4403e3e` | ğŸ”— [æŸ¥çœ‹æäº¤](https://github.com/vllm-project/vllm/commit/4403e3ed4c880365978d1716e5f3a8dbe6a6af31)

**ğŸ¯ å˜æ›´ç±»å‹**ï¼šåŠŸèƒ½å¢å¼º  
**âš¡ é‡è¦ç¨‹åº¦**ï¼šğŸŸ¡ ä¸­  

**ğŸ“‹ å˜æ›´æ‘˜è¦**  
- ä¸º P/Dï¼ˆPrefill/Decodeï¼‰è§£è€¦éƒ¨ç½²æ–°å¢ Prometheus è®¡æ•°å™¨ï¼ŒæŒ‰æ¥æºåˆ’åˆ† Prompt Tokenï¼ˆæœ¬åœ°è®¡ç®—ã€å¤–éƒ¨ KV è½¬ç§»ã€æœ¬åœ°ç¼“å­˜ï¼‰ã€‚  
- åœ¨ `EngineCoreOutput` ä¸­åŠ å…¥ `num_external_computed_tokens`ï¼Œå¹¶åœ¨è°ƒåº¦å™¨ã€ç»Ÿè®¡æ¨¡å—ä¸­ä½¿ç”¨æ–°çš„ `PromptTokenStats` æ¥è®°å½•ã€èšåˆè¿™äº›æ•°æ®ã€‚  
- åŒæ—¶æä¾› â€œcachedâ€ ä¸ â€œrecomputedâ€ è®¡æ•°ï¼Œä»¥ä¾¿åœ¨å…¨ç¼“å­˜æƒ…å†µä¸‹ä»èƒ½ç»Ÿè®¡æœ€åä¸€ä¸ªå¼ºåˆ¶è®¡ç®—çš„ tokenã€‚  

**ğŸ¯ å½±å“èŒƒå›´**  
- `vllm/v1/engine/__init__.py`ï¼ˆè¾“å‡ºç»“æ„ï¼‰  
- `vllm/v1/core/sched/scheduler.py`ï¼ˆè°ƒåº¦å™¨è°ƒç”¨ï¼‰  
- `vllm/v1/metrics/stats.py`ï¼ˆPromptTokenStats æ•°æ®ç±»ï¼‰  
- `vllm/v1/metrics/loggers.py`ï¼ˆPrometheus è®¡æ•°å™¨åˆ›å»ºä¸ä¸ŠæŠ¥ï¼‰  
- `tests/v1/metrics/test_stats.py`ï¼ˆæ–°å¢å•å…ƒæµ‹è¯•ï¼‰  

**ğŸ’¡ å…³æ³¨å»ºè®®**  
1. **å‘åå…¼å®¹**ï¼šè™½ç„¶å·²æä¾› `IterationStats.num_prompt_tokens` å±æ€§ï¼Œä½†å¤–éƒ¨ä»£ç ä»å¯èƒ½ç›´æ¥è®¿é—® `IterationStats.prompt_token_stats`ï¼Œå»ºè®®åœ¨æ–‡æ¡£ä¸­æ˜ç¡®ä¸¤è€…çš„æ„ä¹‰åŠä½¿ç”¨æ—¶æœºã€‚  
2. **æŒ‡æ ‡æ ‡ç­¾ä¸€è‡´æ€§**ï¼š`PromptTokenStats.ALL_SOURCES` é‡Œä½¿ç”¨çš„æ ‡ç­¾éœ€ä¸ Prometheus é…ç½®ä¿æŒåŒæ­¥ï¼Œé˜²æ­¢æ–°å¢æˆ–åˆ é™¤æ ‡ç­¾å¯¼è‡´ç›‘æ§æŠ¥é”™ã€‚  
3. **æ€§èƒ½å½±å“**ï¼šæ¯æ¬¡è¿­ä»£ç°åœ¨ä¼šåˆ›å»ºå¹¶æ›´æ–°å¤šä¸ª Counterï¼Œå¯¹é«˜å¹¶å‘éƒ¨ç½²éœ€éªŒè¯è®¡æ•°å™¨å†™å…¥çš„é”å¼€é”€ï¼Œå¿…è¦æ—¶å¯è€ƒè™‘ä½¿ç”¨ `inc` çš„æ‰¹é‡å†™æ³•ã€‚  
4. **æµ‹è¯•è¦†ç›–**ï¼šå½“å‰ä»…è¦†ç›–äº† `PromptTokenStats` çš„å†…éƒ¨é€»è¾‘ï¼Œå»ºè®®åœ¨é›†æˆå±‚é¢ï¼ˆå¦‚å®é™… `EngineCore` è¿è¡Œï¼‰å†åŠ å…¥ä¸€æ¬¡ç«¯åˆ°ç«¯çš„æŒ‡æ ‡æ£€æŸ¥ï¼Œç¡®ä¿ `num_external_computed_tokens` åœ¨çœŸå® KVâ€‘Transfer åœºæ™¯ä¸‹è¢«æ­£ç¡®å¡«å……ã€‚  

æ€»ä½“è€Œè¨€ï¼Œæ­¤æ¬¡æ”¹åŠ¨ä¸º P/D è§£è€¦ç¯å¢ƒæä¾›äº†æ›´ç»†ç²’åº¦çš„ç®—åŠ›/æ•°æ®è¿ç§»å¯è§‚æµ‹æ€§ï¼Œå¯¹æ€§èƒ½è°ƒä¼˜å’Œèµ„æºä½¿ç”¨åˆ†æéå¸¸æœ‰ä»·å€¼ã€‚åªè¦æ³¨æ„å…¼å®¹æ€§ä¸ç›‘æ§é…ç½®ï¼Œå³å¯å®‰å…¨æŠ•å…¥ä½¿ç”¨ã€‚

---

### [Deprecation] Deprecate profiling envs (#33722)
**SHA**: `d88a1df` | ğŸ”— [æŸ¥çœ‹æäº¤](https://github.com/vllm-project/vllm/commit/d88a1df699f68e5284fe3a3170f8ae292a3e9c3f)

**ğŸ¯ å˜æ›´ç±»å‹**ï¼šåŠŸèƒ½å¢å¼º â†’ **[Deprecation]**  
**âš¡ é‡è¦ç¨‹åº¦**ï¼šğŸŸ¡ ä¸­  

**ğŸ“‹ å˜æ›´æ‘˜è¦**  
- å°†åŸå…ˆé€šè¿‡ç¯å¢ƒå˜é‡ `VLLM_TORCH_*`ã€`VLLM_PROFILER_*` æ§åˆ¶çš„ Torch/CUDA Profiling åŠŸèƒ½å…¨éƒ¨ä¸‹çº¿ï¼Œç»Ÿä¸€æ”¹ä¸ºä½¿ç”¨æ–° CLI å‚æ•° `--profiler-config` å¯ç”¨ã€‚  
- ç›¸åº”çš„ç¯å¢ƒå˜é‡åœ¨ `vllm/envs.py` ä¸­è¢«å½»åº•ç§»é™¤ï¼ˆå…± 15 æ¡ï¼‰ï¼Œæ–‡æ¡£ä¸­ä¹ŸåŒæ­¥æ›´æ–°äº†è¯´æ˜ã€‚  

**ğŸ¯ å½±å“èŒƒå›´**  
- **vllm/envs.py**ï¼šç¯å¢ƒå˜é‡æ³¨å†Œè¡¨å‰Šå‡ï¼Œå½±å“æ‰€æœ‰é€šè¿‡ `envs.get` è¯»å–è¿™äº›é”®çš„è·¯å¾„ã€‚  
- **HTTP å®‰å…¨æ–‡æ¡£**ï¼ˆ`docs/usage/security.md`ï¼‰ï¼šå¯¹å¤–å±•ç¤ºçš„ profiling ç«¯ç‚¹è§¦å‘æ¡ä»¶ä» env å˜é‡æ”¹ä¸º `--profiler-config`ã€‚  
- ä»»ä½•ä¾èµ–æ—§ç¯å¢ƒå˜é‡çš„è„šæœ¬ã€Docker é•œåƒæˆ– CI é…ç½®éƒ½å°†å¤±æ•ˆã€‚  

**ğŸ’¡ å…³æ³¨å»ºè®®**  

1. **å‘åå…¼å®¹**ï¼šå¦‚æœåº“ä»åœ¨å†…éƒ¨ç›´æ¥è¯»å–è¿™äº›å·²åˆ é™¤çš„ envâ€‘keyï¼ˆä¾‹å¦‚åœ¨ `AsyncLLMEngine`ã€`Profiler` åˆå§‹åŒ–å¤„ï¼‰ï¼Œè¯·æ±‚åœ¨è¯»å–å‰åŠ å…¥ **é€æ­¥é€€å½¹è­¦å‘Š**ï¼ˆ`warnings.warn`ï¼‰ï¼Œå¹¶åœ¨æœªæ¥çš„ major ç‰ˆæœ¬ä¸­å½»åº•ç§»é™¤ã€‚  
2. **æ–‡æ¡£ä¸ç¤ºä¾‹åŒæ­¥**ï¼šåœ¨ READMEã€quickâ€‘start ç¤ºä¾‹ä»¥åŠ CI è„šæœ¬ä¸­åŠ å…¥ `--profiler-config` ç¤ºä¾‹ï¼Œé¿å…ç”¨æˆ·ä»ä½¿ç”¨æ—§ envã€‚  
3. **æµ‹è¯•è¦†ç›–**ï¼šæ–°å¢å•å…ƒæµ‹è¯•ï¼Œç¡®è®¤åœ¨æœªæä¾› `--profiler-config` æ—¶ profiling ç«¯ç‚¹ä¸æš´éœ²ï¼Œä¸”åœ¨æä¾›æ—¶èƒ½å¤Ÿæ­£å¸¸å¯åŠ¨å¹¶è¿”å›é¢„æœŸæ–‡ä»¶ã€‚  
4. **å…¼å®¹æ€§æ£€æŸ¥**ï¼šæœç´¢ä»“åº“ä¸­ `os.getenv("VLLM_TORCH_â€¦")`ã€`os.getenv("VLLM_PROFILER_â€¦")` çš„æ®‹ä½™å¼•ç”¨ï¼Œç¡®ä¿å…¨éƒ¨è¿ç§»æˆ–æ ‡è®°ä¸ºåºŸå¼ƒã€‚  
5. **å‘å¸ƒè¯´æ˜**ï¼šåœ¨ changelog ä¸­æ˜ç¡®åˆ—å‡º **â€œå·²åºŸé™¤çš„ç¯å¢ƒå˜é‡â€**ï¼Œå¹¶æä¾›è¿ç§»æŒ‡å—ï¼ˆä¾‹å¦‚ `VLLM_TORCH_PROFILER_DIR` â†’ `--profiler-config output_dir=...`ï¼‰ï¼Œé™ä½ç”Ÿäº§ç¯å¢ƒå‡çº§é£é™©ã€‚  

æ€»ä½“æ¥çœ‹ï¼Œæ­¤æ¬¡å»é™¤æ—§çš„ profiling ç¯å¢ƒå˜é‡æ˜¯ä¸€æ¬¡æ¸…ç†ä¸ç»Ÿä¸€å…¥å£çš„å·¥ä½œï¼Œä¸»è¦å½±å“é…ç½®å±‚é¢ã€‚åªè¦ç¡®ä¿æ‰€æœ‰å†…éƒ¨å¼•ç”¨å¾—åˆ°ç›¸åº”æ”¹å†™å¹¶åœ¨æ–‡æ¡£/CI ä¸­åŠ å…¥è¿ç§»æŒ‡å¼•ï¼Œå‡çº§é£é™©å¯æ§åˆ¶åœ¨ä½æ°´å¹³ã€‚ç¥è°ƒè¯•é¡ºåˆ©ï¼

---

### [Feature] Enable `TRITON_ATTN` for Batch Invariance (#33688)
**SHA**: `45f8fd6` | ğŸ”— [æŸ¥çœ‹æäº¤](https://github.com/vllm-project/vllm/commit/45f8fd6f979de059e2d8a03ea2ddc40c06394931)

**ğŸ¯ å˜æ›´ç±»å‹**ï¼šåŠŸèƒ½å¢å¼º  
**âš¡ é‡è¦ç¨‹åº¦**ï¼šğŸŸ¡ ä¸­  

**ğŸ“‹ å˜æ›´æ‘˜è¦**  
1. æ–‡æ¡£ä¸­æ–°å¢ GPTâ€‘OSS ç³»åˆ—æ¨¡å‹å·²éªŒè¯æ”¯æŒ batchâ€‘invarianceã€‚  
2. å°† `TRITON_ATTN` åŠ å…¥ determinism æµ‹è¯•åç«¯åˆ—è¡¨ï¼Œè§†ä¸ºå¯ç”¨äº batchâ€‘invariance çš„è§£ç ä¸å˜åç«¯ã€‚  
3. åœ¨ `batch_invariant.py` ä¸­æŠŠ `TRITON_ATTN` ä¸ `FLASH_ATTN` åˆå¹¶ä¸º â€œdecodeâ€‘invariantâ€ åç«¯ï¼Œå¹¶å°†å…¶ä» `supported_backends` ä¸­å‰”é™¤ï¼Œæ”¹ä¸ºåœ¨éè§£ç ä¸å˜æ¨¡å¼ä¸‹ç»™å‡ºè­¦å‘Šã€‚  
4. `triton_unified_attention.py` è¯»å–å…¨å±€ `vllm_is_batch_invariant()` æ ‡å¿—ï¼Œå¹¶åœ¨åˆ¤æ–­æ˜¯å¦ä½¿ç”¨ 2â€‘D kernel æ—¶åŠ å…¥è¯¥æ ‡å¿—ï¼Œä½¿å¾—å¼€å¯ batchâ€‘invariance æ—¶å¼ºåˆ¶èµ° 2â€‘D å®ç°ã€‚  

**ğŸ¯ å½±å“èŒƒå›´**  
- `vllm.model_executor.layers.batch_invariant`ï¼ˆåç«¯é€‰æ‹©ã€è­¦å‘Šé€»è¾‘ï¼‰  
- `vllm.v1.attention.ops.triton_unified_attention`ï¼ˆkernel é€‰æ‹©ï¼‰  
- æ–‡æ¡£ `docs/features/batch_invariance.md`ã€determinism æµ‹è¯• `tests/v1/determinism/utils.py`  

**ğŸ’¡ å…³æ³¨å»ºè®®**  
1. **åŠŸèƒ½éªŒè¯**ï¼šæ–°å¢ `TRITON_ATTN` æ”¯æŒåï¼Œåº”è¡¥å……é’ˆå¯¹è¯¥åç«¯çš„å•å…ƒ/é›†æˆæµ‹è¯•ï¼Œå°¤å…¶æ˜¯ prefillâ€‘>decode åœºæ™¯çš„ batchâ€‘invariance æ£€æŸ¥ã€‚  
2. **è­¦å‘Šä¿¡æ¯**ï¼šå½“å‰ warning æ–‡æ¡ˆå·²æ”¹ä¸º â€œnonâ€‘decodeâ€‘invariantâ€ï¼Œå»ºè®®åœ¨æ—¥å¿—ä¸­æ˜ç¡®æŒ‡å‡ºå·²å¯ç”¨çš„åç«¯ï¼ˆä¾‹å¦‚ `TRITON_ATTN`ï¼‰ï¼Œé¿å…ç”¨æˆ·è¯¯è§£ã€‚  
3. **ç¯å¢ƒå˜é‡å…¼å®¹**ï¼š`override_envs_for_invariance` ä»ç„¶åœ¨ `supported_backends` ä¸­ä¿ç•™ `TRITON_MLA` ç­‰éè§£ç ä¸å˜åç«¯ï¼Œç¡®ä¿æ—§ç‰ˆè„šæœ¬ä¸å›  `TRITON_ATTN` è¿›å…¥ decode åˆ—è¡¨è€Œäº§ç”Ÿæ„å¤–è¡Œä¸ºã€‚  
4. **æ–‡æ¡£åŒæ­¥**ï¼šæ–‡æ¡£å·²åˆ—å‡º GPTâ€‘OSS æ¨¡å‹ï¼Œå»ºè®®åœ¨ â€œSupported backendsâ€ å°èŠ‚ä¸­è¯´æ˜ `TRITON_ATTN` ç°å·²å…¼å®¹ batchâ€‘invarianceã€‚  
5. **æ€§èƒ½é¢„ä¼°**ï¼šå¼ºåˆ¶ä½¿ç”¨ 2â€‘D kernel å¯èƒ½å¯¼è‡´åœ¨å¤§ batch åœºæ™¯ä¸‹æ€§èƒ½ä¸‹é™ï¼Œå»ºè®®åœ¨ release note ä¸­ç»™å‡ºåŸºå‡†æˆ–æä¾›å¯é€‰çš„å›é€€å¼€å…³ã€‚  

æ•´ä½“æ¥çœ‹ï¼Œæ­¤æ¬¡æ”¹åŠ¨åœ¨ä¿æŒç°æœ‰ FLASHâ€‘ATTN è¡Œä¸ºçš„åŒæ—¶ï¼Œæ˜¾è‘—æ‰©å¤§äº† Tritonâ€‘based attention çš„ batch invariance å¯ç”¨æ€§ã€‚ä½†éœ€åœ¨æµ‹è¯•è¦†ç›–ã€æ—¥å¿—å¯è¯»æ€§ä»¥åŠæ–‡æ¡£è¯´æ˜ä¸Šå†åšç»†åŒ–ï¼Œä»¥é˜²æ­¢æ½œåœ¨çš„å›å½’æˆ–ä½¿ç”¨è¯¯è§£ã€‚

---

### [Refactor] Remove unused dead code (#33718)
**SHA**: `5e1e0a0` | ğŸ”— [æŸ¥çœ‹æäº¤](https://github.com/vllm-project/vllm/commit/5e1e0a0fbdf52dd21bfa6bc4dd6e88487a917d23)

**ğŸ¯ å˜æ›´ç±»å‹**ï¼šé‡æ„ï¼ˆåˆ é™¤æ­»ä»£ç ï¼‰  
**âš¡ é‡è¦ç¨‹åº¦**ï¼šğŸŸ¡ ä¸­  
**ğŸ“‹ å˜æ›´æ‘˜è¦**ï¼šæ­¤æ¬¡æäº¤åœ¨ `collect_env.py`ã€`fx_utils.py`ã€`config/utils.py` ä¸­ç§»é™¤äº†è‹¥å¹²æœªè¢«ä½¿ç”¨çš„å‡½æ•°ä¸å¯¹åº”çš„å¯¼å…¥ï¼Œä»£ç é‡å‡å°‘çº¦ 80 è¡Œã€‚åˆ é™¤çš„å†…å®¹åŒ…æ‹¬ `run_and_return_first_line`ã€`find_specified_fn*`ã€`contains_object_print`ã€`assert_hashable`ã€`handle_deprecated` ç­‰å·¥å…·å‡½æ•°ï¼Œä»¥åŠå¯¹ `regex` åŒ…çš„å¼•ç”¨ã€‚  

**ğŸ¯ å½±å“èŒƒå›´**ï¼š  
- **vllm/collect_env.py**ï¼šä»…å½±å“ç¯å¢ƒä¿¡æ¯æ”¶é›†é€»è¾‘ï¼Œæœªå†ä½¿ç”¨çš„è¡Œå·å‡½æ•°è¢«åˆ é™¤ã€‚  
- **vllm/compilation/fx_utils.py**ï¼šåˆ é™¤äº†å¯¹æŒ‡å®š `fx.Node` æŸ¥æ‰¾çš„è¾…åŠ©å‡½æ•°ï¼Œå½“å‰ä»£ç å·²æ”¹ä¸ºä»…ä½¿ç”¨ `find_auto_fn_maybe` ç³»åˆ—ã€‚  
- **vllm/config/utils.py**ï¼šå»æ‰äº†å¯¹è±¡æ‰“å°æ£€æµ‹ã€å“ˆå¸Œå®‰å…¨æ£€æŸ¥ä»¥åŠæ—§é…ç½®å­—æ®µçš„è¿ç§»è­¦å‘Šå®ç°ï¼Œæ¶‰åŠé…ç½®å“ˆå¸Œä¸å‘åå…¼å®¹çš„æ—§ä»£ç è¢«å½»åº•æ¸…ç†ã€‚  

**ğŸ’¡ å…³æ³¨å»ºè®®**ï¼š  
1. **ç¡®è®¤æœªæ®‹ç•™å¼•ç”¨**ï¼šåœ¨å…¨åº“æœç´¢ï¼ˆ`grep -R "run_and_return_first_line"`ã€`find_specified_fn`ã€`contains_object_print` ç­‰ï¼‰ç¡®ä¿æ²¡æœ‰å¤–éƒ¨æ’ä»¶æˆ–ç”¨æˆ·ä»£ç ä»ä¾èµ–è¿™äº›å‡½æ•°ã€‚  
2. **é…ç½®å“ˆå¸Œè¡Œä¸º**ï¼š`assert_hashable` ä¸ `handle_deprecated` çš„ç§»é™¤ä¼šå¯¼è‡´ä¹‹å‰å¯¹éå“ˆå¸Œå®‰å…¨é…ç½®çš„è­¦å‘Šä¸å†å‡ºç°ï¼Œéœ€ç¡®è®¤è¿™ä¸å½±å“ç°æœ‰çš„é…ç½®æ ¡éªŒæˆ–ç‰ˆæœ¬è¿ç§»æµç¨‹ã€‚è‹¥åç»­éœ€è¦ç±»ä¼¼åŠŸèƒ½ï¼Œè¯·åœ¨æ›´é«˜å±‚åŠ å…¥æ˜¾å¼çš„éªŒè¯ã€‚  
3. **æµ‹è¯•è¦†ç›–**ï¼šè¿è¡Œå®Œæ•´å•å…ƒæµ‹è¯•ä¸é›†æˆæµ‹è¯•ï¼Œå°¤å…¶æ˜¯ `vllm.collect_env` ä¸ `vllm.compilation` çš„è·¯å¾„æµ‹è¯•ï¼Œç¡®ä¿åˆ é™¤çš„å‡½æ•°æœªè¢«é—´æ¥è°ƒç”¨ã€‚  
4. **æ–‡æ¡£æ›´æ–°**ï¼šè‹¥å…¬å¼€ API æ–‡æ¡£ä¸­æ›¾åˆ—å‡ºä¸Šè¿°å‡½æ•°ï¼Œéœ€è¦åŒæ­¥åˆ é™¤æˆ–æ ‡è®°ä¸ºå·²ä¸‹çº¿ï¼Œä»¥å…ç”¨æˆ·è¯¯ç”¨ã€‚  

æ€»ä½“è€Œè¨€ï¼Œæ­¤æ¬¡æ¸…ç†æå‡äº†ä»£ç å¯ç»´æŠ¤æ€§ä¸ä½“ç§¯ï¼Œé£é™©ä¸»è¦åœ¨äºæ½œåœ¨çš„å¤–éƒ¨ä¾èµ–å’Œé…ç½®æ ¡éªŒé€»è¾‘çš„ç¼ºå¤±ï¼Œå»ºè®®åœ¨å‘å¸ƒå‰å®Œæˆå…¨åº“æœç´¢ä¸å›å½’æµ‹è¯•ã€‚

---

### [Bugfix] Define router_logits_dtype for remaining MoE models (#33737)
**SHA**: `eb5ed20` | ğŸ”— [æŸ¥çœ‹æäº¤](https://github.com/vllm-project/vllm/commit/eb5ed207437d31daf09cd4ae51e993fc1efa6928)

**ğŸ¯ å˜æ›´ç±»å‹**ï¼šBug ä¿®å¤  
**âš¡ é‡è¦ç¨‹åº¦**ï¼šğŸŸ¡ ä¸­  

**ğŸ“‹ å˜æ›´æ‘˜è¦**  
æœ¬æ¬¡æäº¤ä¸ºå¤šè·¯ä¸“å®¶ï¼ˆMixtureâ€‘ofâ€‘Expertsï¼‰ç³»åˆ—æ¨¡å‹è¡¥å…¨ `router_logits_dtype` å‚æ•°ï¼Œç»Ÿä¸€æ˜¾å¼æŒ‡å®šè·¯ç”±æ—¥å¿—çš„è®¡ç®—ç²¾åº¦ã€‚åŸå…ˆéƒ¨åˆ†æ¨¡å‹åœ¨æ„é€  `FusedMoE`ã€`LongcatRouter`ã€`MIMO` ç­‰ç»„ä»¶æ—¶æœªä¼ é€’ dtypeï¼Œå¯¼è‡´åœ¨ä¸åŒç¡¬ä»¶æˆ–æ··åˆç²¾åº¦é…ç½®ä¸‹å‡ºç°ç±»å‹ä¸åŒ¹é…æˆ–éšå¼è½¬å‹é”™è¯¯ã€‚  

**ğŸ¯ å½±å“èŒƒå›´**  
- `vllm/model_executor/models/afmoe.py`  
- `vllm/model_executor/models/bailing_moe.py`  
- `vllm/model_executor/models/flex_olmo.py`  
- `vllm/model_executor/models/longcat_flash.py`  
- `vllm/model_executor/models/mimo_v2_flash.py`  
- `vllm/model_executor/models/step3p5.py`  

**ğŸ’¡ å…³æ³¨å»ºè®®**  
1. **ä¸€è‡´æ€§æ ¡éªŒ**ï¼šç¡®è®¤ `router_logits_dtype` ä¸æ¨¡å‹æ•´ä½“ `dtype`ï¼ˆ`self.router_dtype`ã€`self.gate_dtype` ç­‰ï¼‰ä¿æŒä¸€è‡´ï¼Œé¿å…åœ¨æ··åˆç²¾åº¦è®­ç»ƒ/æ¨ç†æ—¶å‡ºç°ç²¾åº¦ä¸‹é™ã€‚  
2. **é…ç½®æš´éœ²**ï¼šè‹¥ä¸Šå±‚é…ç½®ï¼ˆå¦‚ `VllmConfig`ï¼‰å…è®¸ç”¨æˆ·è‡ªå®šä¹‰è·¯ç”±ç²¾åº¦ï¼Œå»ºè®®åœ¨æ„é€ å‡½æ•°å‚æ•°ä¸­åŠ å…¥ç›¸åº”é€‰é¡¹ï¼Œé˜²æ­¢ç¡¬ç¼–ç ä¸º `torch.float32`ã€‚  
3. **æµ‹è¯•è¦†ç›–**ï¼šè¡¥å……å•å…ƒæµ‹è¯•ï¼ŒéªŒè¯åœ¨ `bfloat16`ã€`float16`ã€`float32` ä¸‰ç§è·¯ç”± dtype ä¸‹çš„å‰å‘è·¯å¾„èƒ½æ­£å¸¸è¿è¡Œï¼›ç‰¹åˆ«æ˜¯ GPU ä¸ CPU åŒå¹³å°ã€‚  
4. **æ–‡æ¡£æ›´æ–°**ï¼šåœ¨æ¨¡å‹æ–‡æ¡£æˆ– `README` ä¸­è¯´æ˜æ–°å¢çš„ `router_logits_dtype` å‚æ•°å«ä¹‰åŠæ¨èå–å€¼ï¼Œä»¥å…ä½¿ç”¨è€…è¯¯ä»¥ä¸ºä¿æŒé»˜è®¤ã€‚  
5. **æ€§èƒ½è¯„ä¼°**ï¼šå¯¹æ¯”æ·»åŠ  dtype å‰ååœ¨å¤§æ¨¡å‹ï¼ˆ>30Bï¼‰ä¸Šçš„æ˜¾å­˜å ç”¨å’Œååé‡ï¼Œç¡®è®¤æ”¹åŠ¨ä¸ä¼šå¼•å…¥é¢å¤–å¼€é”€ã€‚  

æ€»ä½“è€Œè¨€ï¼Œæ­¤æ¬¡è¡¥å…¨æå‡äº† MoE ç³»åˆ—æ¨¡å‹åœ¨å¤šç¡¬ä»¶ç¯å¢ƒä¸‹çš„é²æ£’æ€§ï¼Œä½†éœ€æ³¨æ„ dtype ä¸æ•´ä½“é…ç½®çš„ä¸€è‡´æ€§ï¼Œå¹¶é€šè¿‡æµ‹è¯•ä¸æ–‡æ¡£è¿›è¡Œå……åˆ†éªŒè¯ã€‚

---

### [MM] Align the prefix of MMEncoderAttention with Attention (#33750)
**SHA**: `9fb27dd` | ğŸ”— [æŸ¥çœ‹æäº¤](https://github.com/vllm-project/vllm/commit/9fb27dd3b3530cbf958a24ee2dcfc907acbf5455)

**ğŸ¯ å˜æ›´ç±»å‹**ï¼šé‡æ„ / å…¼å®¹æ€§ä¿®æ­£  
**âš¡ é‡è¦ç¨‹åº¦**ï¼šğŸŸ¡ ä¸­  

**ğŸ“‹ å˜æ›´æ‘˜è¦**  
æœ¬æ¬¡æäº¤ç»Ÿä¸€äº† `MMEncoderAttention` çš„å‚æ•°å‰ç¼€ï¼Œå°†åŸå…ˆç›´æ¥ä½¿ç”¨ `prefix` çš„æ–¹å¼æ”¹ä¸º `f"{prefix}.attn"`ï¼Œä¸å¸¸è§„ `Attention` å®ç°ä¿æŒä¸€è‡´ã€‚ä¸ºæ­¤åœ¨ 20 å¤šä¸ªæ¶‰åŠå¤šæ¨¡æ€è§†è§‰â€‘è¯­è¨€æ¨¡å‹çš„æ–‡ä»¶ä¸­ä¸€æ¬¡æ€§ä¿®æ”¹äº†æ„é€ å‡½æ•°è°ƒç”¨ã€‚

**ğŸ¯ å½±å“èŒƒå›´**  
- æ‰€æœ‰ä½¿ç”¨ `MMEncoderAttention` çš„æ¨¡å‹ï¼š`aimv2ã€blipã€glm4_1vã€glm4vã€glm_ocrã€idefics2_vision_modelã€intern_vitã€interns1_vitã€mllama4ã€molmoã€molmo2ã€openpangu_vlã€qwen2_5_vlã€qwen2_vlã€qwen3_omni_moe_thinkerã€step3_vlã€step_vl` ç­‰ã€‚  
- ä¸æƒé‡åŠ è½½ã€æ—¥å¿—/ç›‘æ§ã€triton/kv cache ç»Ÿè®¡ç­‰ä¾èµ– module åç§°çš„åŠŸèƒ½ç›¸å…³ã€‚

**ğŸ’¡ å…³æ³¨å»ºè®®**  
1. **æ£€æŸ¥å…¼å®¹æ€§**ï¼šæ—§æ¨¡å‹ checkpoint ä¸­çš„ `attn` å‰ç¼€ä¼šç¼ºå¤±ï¼Œéœ€åœ¨ `load_state_dict` æ—¶åŠ å…¥æ˜ å°„ï¼ˆå¦‚ `rename_keys`ï¼‰ï¼Œæˆ–åœ¨æ–‡æ¡£æç¤ºç”¨æˆ·ä½¿ç”¨æ–°ç‰ˆ checkpointã€‚  
2. **æµ‹è¯•è¦†ç›–**ï¼šç¡®ä¿æ‰€æœ‰å—å½±å“æ¨¡å‹åœ¨åŠ è½½æ—§ checkpointã€æ‰§è¡Œæ¨ç†ã€ä»¥åŠå¤šå¡å¹¶è¡Œï¼ˆtensorâ€‘parallelã€pipelineâ€‘parallelï¼‰ä¸‹å‡èƒ½é€šè¿‡ï¼Œé˜²æ­¢å› å‘½åä¸åŒ¹é…å¯¼è‡´æ‰¾ä¸åˆ°å‚æ•°ã€‚  
3. **æ—¥å¿—/ç›‘æ§**ï¼šè‹¥å·²æœ‰ç›‘æ§æˆ– profiling æŒ‰å‰ç¼€èšåˆç»Ÿè®¡ï¼Œæ›´æ–°ç›¸åº”è§„åˆ™ä»¥æ•è· `*.attn` å­æ¨¡å—ã€‚  
4. **ä¿æŒç»Ÿä¸€**ï¼šåç»­æ–°å¢çš„å¤šæ¨¡æ€ Attention å®ç°è¯·éµå¾ªæ­¤å‘½åçº¦å®šï¼Œé¿å…å†æ¬¡å‡ºç°å‰ç¼€ä¸ä¸€è‡´çš„é—®é¢˜ã€‚  

æ•´ä½“æ¥çœ‹ï¼Œæ­¤æ¬¡æ”¹åŠ¨æ˜¯ä¸€æ¬¡ä»£ç é£æ ¼ç»Ÿä¸€ï¼Œå¯¹åŠŸèƒ½æœ¬èº«æ²¡æœ‰ç›´æ¥æ€§èƒ½å½±å“ï¼Œä½†éœ€å…³æ³¨æ¨¡å‹æƒé‡å…¼å®¹ä¸ç›‘æ§é…ç½®çš„åŒæ­¥æ›´æ–°ã€‚

---

### [CPU] Split attention dispatch by head_dim alignment (#32161)
**SHA**: `4dffc5e` | ğŸ”— [æŸ¥çœ‹æäº¤](https://github.com/vllm-project/vllm/commit/4dffc5e044317326b9e2b2fd2a019c499d63c427)

**ğŸ¯ å˜æ›´ç±»å‹**ï¼šåŠŸèƒ½å¢å¼º  
**âš¡ é‡è¦ç¨‹åº¦**ï¼šğŸŸ¡ ä¸­  
**ğŸ“‹ å˜æ›´æ‘˜è¦**ï¼šå¼•å…¥è„šæœ¬ `generate_cpu_attn_dispatch.py` è‡ªåŠ¨ç”Ÿæˆ CPU Attention è°ƒåº¦åˆ†å‘å®ï¼Œå°†åŸå…ˆæ‰‹å†™çš„ `CPU_ATTN_DISPATCH_CASEâ€¦`ã€`CPU_ATTN_DISPATCH_IMPL` å¤§å—ä»£ç æ›¿æ¢ä¸ºç»Ÿä¸€çš„ `CPU_ATTN_DISPATCH(HEAD_DIM, ISA_TYPE, â€¦)` å®ã€‚CMake åœ¨ç¼–è¯‘å‰æ‰§è¡Œè„šæœ¬ç”Ÿæˆ `cpu_attn_dispatch_generated.h`ï¼Œ`cpu_attn.cpp` ä»… `#include` è¯¥å¤´æ–‡ä»¶å³å¯å®Œæˆè°ƒåº¦ã€‚æµ‹è¯•ç”¨ä¾‹æ‰©å¤§åˆ° VEC16 ç›¸å…³çš„ headâ€‘sizeï¼ˆ80ã€112ï¼‰ã€‚

**ğŸ¯ å½±å“èŒƒå›´**  
- `csrc/cpu/*`ï¼ˆattention å®ç°ã€å®å®šä¹‰ï¼‰  
- `cmake/cpu_extension.cmake`ï¼ˆç”Ÿæˆæ­¥éª¤ï¼‰  
- æ–°å¢è„šæœ¬ `csrc/cpu/generate_cpu_attn_dispatch.py`  
- æµ‹è¯• `tests/kernels/attention/test_cpu_attn.py`

**ğŸ’¡ å…³æ³¨å»ºè®®**  

1. **ç”Ÿæˆæ–‡ä»¶çš„ä¾èµ–ç®¡ç†**  
   - ç›®å‰ CMake ä½¿ç”¨ `execute_process` åœ¨é…ç½®é˜¶æ®µä¸€æ¬¡æ€§ç”Ÿæˆå¤´æ–‡ä»¶ï¼Œç¼ºå°‘å¯¹æºæ–‡ä»¶ (`generate_cpu_attn_dispatch.py`ã€`cpu_attn_dispatch_generated.h`) çš„æ˜¾å¼ä¾èµ–ã€‚å»ºè®®æ”¹ä¸º `add_custom_command(OUTPUT ...)` + `add_custom_target`ï¼Œç¡®ä¿è„šæœ¬æ”¹åŠ¨æˆ–å®ä¿®æ”¹æ—¶é‡æ–°ç”Ÿæˆï¼Œå¦åˆ™å¯èƒ½å‡ºç°â€œæ—§æ–‡ä»¶æ®‹ç•™â€å¯¼è‡´ç¼–è¯‘é”™è¯¯ã€‚

2. **æšä¸¾å€¼åŒ¹é…**  
   - `encode_cpu_attn_params` é‡‡ç”¨ `static_cast<int64_t>(isa)` ä¸è„šæœ¬ä¸­ç¡¬ç¼–ç çš„ `ISA_TYPES`ï¼ˆAMX=0, VEC=1, VEC16=2, NEON=3ï¼‰ä¿æŒä¸€è‡´ã€‚åŠ¡å¿…åœ¨ `cpu_attn.hpp`ï¼ˆæˆ–å¯¹åº”æšä¸¾å®šä¹‰ï¼‰æ£€æŸ¥å¯¹åº”å€¼æ˜¯å¦æœªè¢«ä¿®æ”¹ï¼›å¦åˆ™ç”Ÿæˆçš„ `case` ç¼–å·ä¼šå¤±é…ï¼Œè§¦å‘é»˜è®¤åˆ†æ”¯çš„ `TORCH_CHECK`ã€‚

3. **ç¼–è¯‘æ—¶é—´ä¸äºŒè¿›åˆ¶ä½“ç§¯**  
   - è‡ªåŠ¨ç”Ÿæˆçš„ `switch` åŒ…å« 8ï¼ˆhead_dimï¼‰Ã—4ï¼ˆISAï¼‰â‰ˆ32 æ¡ caseï¼Œæ¯æ¡æ¨¡æ¿å®ä¾‹åŒ–ä¼šç”Ÿæˆå¤§é‡ç‰¹åŒ–ä»£ç ã€‚å»ºè®®åœ¨ CI ä¸­è§‚å¯Ÿç¼–è¯‘æ—¶é—´å’Œç›®æ ‡æ–‡ä»¶å¤§å°ï¼Œå¿…è¦æ—¶å¯¹ä¸å¸¸ç”¨ç»„åˆä½¿ç”¨ `#if defined(__AVX2__)` ç­‰æ¡ä»¶ç¼–è¯‘è£å‰ªã€‚

4. **æµ‹è¯•è¦†ç›–**  
   - æ–°å¢ `HEAD_SIZES_VEC16` å·²è¦†ç›– VEC16-only head_dimï¼ˆ80ã€112ï¼‰ï¼Œä½†ä»åº”åœ¨é x86ã€é ARM ç¯å¢ƒä¸‹è·‘ä¸€æ¬¡å®Œæ•´çš„å•å…ƒæµ‹è¯•ï¼Œç¡®ä¿ fallback åˆ†æ”¯ (`#else` ä¸­çš„ VEC/VEC16) æ­£å¸¸å·¥ä½œã€‚

5. **æ–‡æ¡£æ›´æ–°**  
   - ç”±äºè°ƒåº¦é€»è¾‘å·²è¿ç§»è‡³ç”Ÿæˆæ–‡ä»¶ï¼ŒREADME/å¼€å‘è€…æŒ‡å—ä¸­åº”è¡¥å…… â€œCPU attention è°ƒåº¦ä¾èµ– head_dim ä¸ ISA çš„ç»„åˆâ€ ä»¥åŠ â€œå¦‚ä½•æ‰‹åŠ¨è·‘ç”Ÿæˆè„šæœ¬â€ çš„è¯´æ˜ã€‚

æ€»ä½“æ¥çœ‹ï¼Œæ­¤æ¬¡æ”¹åŠ¨æ˜¾è‘—æå‡äº†è°ƒåº¦ä»£ç çš„å¯ç»´æŠ¤æ€§ä¸å¯æ‰©å±•æ€§ï¼Œåªè¦å®Œå–„ç”Ÿæˆæ­¥éª¤çš„ä¾èµ–ç®¡ç†å¹¶ç¡®ä¿æšä¸¾å€¼çš„ä¸€è‡´æ€§ï¼Œå³å¯é¡ºåˆ©åœ¨å„ç§å¹³å°ä¸Šä½¿ç”¨ã€‚

---

### [Bugfix] Fix torchrun PP broadcast deadlock with async scheduling (#33701)
**SHA**: `0208017` | ğŸ”— [æŸ¥çœ‹æäº¤](https://github.com/vllm-project/vllm/commit/02080179a3fc92c339b93040838f44b72313e07b)

**ğŸ¯ å˜æ›´ç±»å‹**ï¼šBug ä¿®å¤  
**âš¡ é‡è¦ç¨‹åº¦**ï¼šğŸŸ¡ ä¸­  
**ğŸ“‹ å˜æ›´æ‘˜è¦**ï¼šåœ¨ `torchrun` ä½¿ç”¨ Pipeline Parallelï¼ˆPPï¼‰ä¸”å¼€å¯ `broadcast_pp_output=True` æ—¶ï¼Œå¼‚æ­¥è°ƒåº¦ä¼šå¯¼è‡´å¹¿æ’­å·²ç”Ÿæˆçš„ tokenâ€‘ids å†æ¬¡å‘é€ï¼Œä»è€Œè§¦å‘æ­»é”ã€‚ä¿®å¤é€šè¿‡åœ¨ `GpuModelRunner.sample_tokens` ä¸­åŠ å…¥ `self.broadcast_pp_output` åˆ¤å®šï¼Œä»…åœ¨éœ€è¦æ—¶æ‰æ‰§è¡Œ `_pp_broadcast_prev_sampled_token_ids`ï¼Œå¹¶åŒæ­¥æ›´æ–°äº†ä¸¤ä¸ªåˆ†å¸ƒå¼æµ‹è¯•ç”¨ä¾‹ï¼Œå»æ‰äº†ä¸´æ—¶å…³é—­ `async_scheduling` çš„æ³¨é‡Šã€‚  

**ğŸ¯ å½±å“èŒƒå›´**ï¼š  
- `vllm/v1/worker/gpu_model_runner.py`ï¼ˆæ ¸å¿ƒè¿è¡Œæ—¶è·¯å¾„ï¼‰  
- `tests/distributed/test_torchrun_example*.py`ï¼ˆåˆ†å¸ƒå¼ç¤ºä¾‹æµ‹è¯•ï¼‰  

**ğŸ’¡ å…³æ³¨å»ºè®®**  
1. **è¿è¡Œæ—¶éªŒè¯**ï¼šåœ¨å¤šæœºå¤šå¡ã€PP + TP ç»„åˆä¸‹å¼€å¯ `async_scheduling=True` å†æ¬¡æ‰§è¡Œ `torchrun`ï¼Œç¡®è®¤ä¸å†å‡ºç°æ­»é”ï¼›å°¤å…¶ç•™æ„ `broadcast_pp_output` å‚æ•°çš„å–å€¼ã€‚  
2. **å…¼å®¹æ€§æ£€æŸ¥**ï¼šæ—§ç‰ˆä½¿ç”¨ `broadcast_pp_output=False` çš„éƒ¨ç½²ä»ä¿æŒåŸæœ‰è¡Œä¸ºï¼Œç¡®ä¿ä¸ä¼šå› æ–°å¢æ¡ä»¶å¯¼è‡´é—æ¼å¹¿æ’­ã€‚  
3. **æ–‡æ¡£æ›´æ–°**ï¼šåœ¨ç”¨æˆ·æ‰‹å†Œæˆ– API æ³¨é‡Šä¸­æ³¨æ˜ï¼šå½“ä½¿ç”¨å¤–éƒ¨ launcherï¼ˆtorchrunï¼‰ä¸” `broadcast_pp_output=True` æ—¶ï¼Œå¼‚æ­¥è°ƒåº¦å®‰å…¨å¯ç”¨ï¼›å¦åˆ™ä¿æŒåŸæœ‰åŒæ­¥å¹¿æ’­ã€‚  
4. **å›å½’æµ‹è¯•**ï¼šæ–°å¢å¯¹ `self.broadcast_pp_output` ä¸º `True` æ—¶ä¸è°ƒç”¨ `_pp_broadcast_prev_sampled_token_ids` çš„å•å…ƒæµ‹è¯•ï¼Œé˜²æ­¢æœªæ¥è¯¯åˆ è¯¥åˆ¤æ–­ã€‚  

æ€»ä½“æ¥çœ‹ï¼Œæ­¤æ¬¡ä¿®æ”¹å®šä½æ˜ç¡®ã€å½±å“èŒƒå›´å±€é™åœ¨åˆ†å¸ƒå¼ PP çš„å¹¿æ’­è·¯å¾„ï¼Œé£é™©è¾ƒä½ã€‚å»ºè®®åœ¨ CI ä¸­åŠ å…¥ä¸åŒ `broadcast_pp_output` é…ç½®çš„ç»„åˆæµ‹è¯•ï¼Œä»¥é˜²æ­¢ç±»ä¼¼çš„è°ƒåº¦é€»è¾‘ç–æ¼å†æ¬¡å‡ºç°ã€‚

---

### [BugFix][Spec Decoding] Fix negative accepted tokens metric crash (#33729)
**SHA**: `52ee210` | ğŸ”— [æŸ¥çœ‹æäº¤](https://github.com/vllm-project/vllm/commit/52ee21021a87735d46c4245c60bc0be42dd58c73)

**ğŸ¯ å˜æ›´ç±»å‹**ï¼šBug ä¿®å¤  
**âš¡ é‡è¦ç¨‹åº¦**ï¼šğŸŸ¡ ä¸­  

**ğŸ“‹ å˜æ›´æ‘˜è¦**  
- `scheduler.update_from_output` åœ¨ç»Ÿè®¡ Specâ€‘Decoding æ—¶ï¼Œè‹¥æ¨¡å‹è¿”å›ç©ºçš„ `sampled_token_ids`ï¼ˆå³ `generated_token_ids` ä¸º `[]`ï¼‰ï¼Œä¼šå‡ºç° `num_accepted = -1`ï¼Œè¿›è€Œå¯¼è‡´ Prometheus è´Ÿå€¼è®¡æ•°å¼‚å¸¸ã€‚  
- æ·»åŠ äº† `if scheduled_spec_token_ids and generated_token_ids:` çš„æ¡ä»¶åˆ†æ”¯ï¼Œé˜²æ­¢åœ¨ç©ºè¾“å‡ºæ—¶ç»§ç»­è®¡ç®—ç»Ÿè®¡ã€‚  
- å¢æ·»äº†å›å½’æµ‹è¯• `test_spec_decoding_stats_empty_output`ï¼ŒéªŒè¯åœ¨ç©ºè¾“å‡ºæƒ…å†µä¸‹ Scheduler ä¸ä¼šæŠ›å¼‚å¸¸ï¼Œä¸”å¯¹åº”çš„ç»Ÿè®¡ä¿¡æ¯ä¸º `None`ã€‚

**ğŸ¯ å½±å“èŒƒå›´**  
- **æ ¸å¿ƒæ¨¡å—**ï¼š`vllm/v1/core/sched/scheduler.py`ï¼ˆSpecâ€‘Decoding ç»Ÿè®¡é€»è¾‘ï¼‰ã€‚  
- **æµ‹è¯•å¥—ä»¶**ï¼š`tests/v1/core/test_scheduler.py`ï¼ˆæ–°å¢å›å½’æµ‹è¯•ï¼‰ã€‚  
- ä¸ Prometheus ç›‘æ§ç›¸å…³çš„æŒ‡æ ‡æ”¶é›†è·¯å¾„ä¹Ÿå—åˆ°é—´æ¥å½±å“ã€‚

**ğŸ’¡ å…³æ³¨å»ºè®®**  
1. **ä»£ç å®¡æŸ¥**ï¼šç¡®è®¤å…¶ä»–è·¯å¾„ï¼ˆå¦‚æ™®é€šè§£ç ã€prefillï¼‰åœ¨æ”¶åˆ°ç©º token åˆ—è¡¨æ—¶åŒæ ·ä¸ä¼šäº§ç”Ÿè´Ÿå€¼ç»Ÿè®¡ã€‚  
2. **ç›‘æ§å®‰å…¨**ï¼šè‹¥å·²æœ‰è‡ªå®šä¹‰ç›‘æ§æˆ–æŠ¥è­¦ä¾èµ– `num_accepted_tokens_per_pos`ï¼Œéœ€è¦éªŒè¯è¿™äº›æŒ‡æ ‡åœ¨ç©ºè¾“å‡ºæ—¶ä»ä¿æŒæœ‰æ•ˆæˆ–ä¸º `0`ã€‚  
3. **æ–‡æ¡£æ›´æ–°**ï¼šåœ¨ Specâ€‘Decoding ä½¿ç”¨è¯´æ˜ä¸­åŠ å…¥â€œç©ºè¾“å‡ºä¸ä¼šäº§ç”Ÿç»Ÿè®¡æ•°æ®â€çš„è¯´æ˜ï¼Œå¸®åŠ©ä½¿ç”¨è€…ç†è§£å¼‚å¸¸è·¯å¾„ã€‚  
4. **å›å½’æµ‹è¯•**ï¼šåœ¨ CI ä¸­ä¿ç•™è¯¥æ–°å¢æµ‹è¯•ï¼Œé¿å…æœªæ¥çš„é‡æ„å†æ¬¡å¼•å…¥è´Ÿå€¼è®¡ç®—ã€‚  
5. **æ€§èƒ½æ£€æŸ¥**ï¼šè¯¥åˆ†æ”¯ä»…å¢åŠ ä¸€æ¬¡ç©ºåˆ—è¡¨æ£€æŸ¥ï¼Œå½±å“å¯å¿½ç•¥ï¼Œä»å»ºè®®è·‘å…¨å¥—æ€§èƒ½åŸºå‡†ç¡®ä¿æ²¡æœ‰æ„å¤–å›å½’ã€‚

---

### [Bugfix] Fix sparse MLA metadata building (#33579)
**SHA**: `bd8da29` | ğŸ”— [æŸ¥çœ‹æäº¤](https://github.com/vllm-project/vllm/commit/bd8da29a66ea8c0e0f208cab7ba0b6be640f3faa)

**ğŸ¯ å˜æ›´ç±»å‹**ï¼šBugä¿®å¤  
**âš¡ é‡è¦ç¨‹åº¦**ï¼šğŸŸ¡ ä¸­  
**ğŸ“‹ å˜æ›´æ‘˜è¦**ï¼šæœ¬æ¬¡æäº¤ä¿®æ­£äº†ç¨€ç– MLAï¼ˆMultiâ€‘Linear Attentionï¼‰å®ç°ä¸­å¯¹ decode / prefill tokens çš„å…ƒæ•°æ®æ‹†åˆ†é€»è¾‘ã€‚åŸä»£ç åœ¨ç¨€ç–è·¯å¾„ä¸‹å¼ºåˆ¶æ–­è¨€ `attn_metadata` å¿…é¡»åŒ…å«å…¨éƒ¨ decodeâ€‘prefill ä¿¡æ¯ï¼Œå¹¶ä¸”æŠŠæ‰€æœ‰ token å½“ä½œ MQA å¤„ç†ï¼Œå¯¼è‡´åœ¨ä»…æœ‰ prefillï¼ˆæˆ–ä»…æœ‰ decodeï¼‰åœºæ™¯ä¸‹å‡ºç° `AssertionError` æˆ–ä¸åŒ¹é…çš„åˆ‡ç‰‡ã€‚æ”¹åŠ¨é‡æ–°ä¾æ®å®ç°ç±»å‹ï¼ˆç¨€ç– vs éç¨€ç–ï¼‰åˆ†åˆ«è®¡ç®— MQA ä¸ MHA çš„ token æ•°é‡ï¼Œå»æ‰ä¸å¿…è¦çš„å¼ºæ–­è¨€ï¼Œç¡®ä¿ä¸¤ç±»å®ç°éƒ½èƒ½æ­£ç¡®å¤„ç†æ··åˆæˆ–å•ä¸€çš„ token ç±»å‹ã€‚  

**ğŸ¯ å½±å“èŒƒå›´**ï¼š  
- `vllm/model_executor/layers/attention/mla_attention.py`ï¼ˆæ ¸å¿ƒæ³¨æ„åŠ›å±‚ï¼‰  
- ç›¸å…³çš„ç¨€ç– MLA å®ç° (`SparseMLAAttentionImpl`) ä¸æ™®é€š MLA å®ç° (`MLAAttentionImpl`)  
- è°ƒç”¨è·¯å¾„æ¶‰åŠ `KVCache` å†™å…¥ã€`forward_mha`ã€`forward_mqa` ä»¥åŠåˆ†å¸ƒå¼å¤åˆ¶ï¼ˆDCPï¼‰é€»è¾‘  

**ğŸ’¡ å…³æ³¨å»ºè®®**ï¼š  
1. **æµ‹è¯•è¦†ç›–**ï¼šè¡¥å……ç¨€ç– MLA åœ¨ä»… prefillã€ä»… decodeã€ä»¥åŠ decodeâ€‘prefill æ··åˆä¸‰ç§æƒ…å½¢ä¸‹çš„å•å…ƒ/é›†æˆæµ‹è¯•ï¼ŒéªŒè¯ `num_mqa_tokens` ä¸ `num_mha_tokens` çš„åˆ‡åˆ†æ­£ç¡®æ€§ã€‚  
2. **æ–­è¨€ä¿ç•™**ï¼šå¯¹éç¨€ç–å®ç°ä»ä¿ç•™å¯¹ `attn_metadata` å®Œæ•´æ€§çš„æ–­è¨€ï¼Œä»¥é˜²é—æ¼å…³é”®å­—æ®µï¼›ç¨€ç–å®ç°åˆ™å¯åœ¨å¿…è¦æ—¶è‡ªè¡Œæ£€æŸ¥ã€‚  
3. **æ–‡æ¡£æ›´æ–°**ï¼šåœ¨æ³¨æ„åŠ›å±‚çš„ API æ–‡æ¡£ä¸­è¯´æ˜ç¨€ç–å®ç°ä¸å†éœ€è¦ `num_decodes`/`num_prefills`ï¼Œå¹¶æ ‡æ˜ä¸¤ç§å®ç°çš„åŒºåˆ«ã€‚  
4. **æ€§èƒ½ç›‘æ§**ï¼šç¨€ç–è·¯å¾„ä»ä½¿ç”¨ `forward_mqa` å¤„ç†æ‰€æœ‰ tokenï¼Œå»ºè®®åœ¨å¤§è§„æ¨¡æ¨ç†æ—¶ç›‘æ§ KVâ€‘cache çš„å†™å…¥ä¸è¯»å–å¼€é”€ï¼Œç¡®ä¿æ”¹åŠ¨æœªå¼•å…¥é¢å¤–å»¶è¿Ÿã€‚  

æ•´ä½“æ¥çœ‹ï¼Œæ”¹åŠ¨æ¶ˆé™¤äº†åŸå…ˆå¯¹å…ƒæ•°æ®çš„è¿‡åº¦ä¾èµ–ï¼Œä½¿ç¨€ç– MLA åœ¨æ›´å¹¿æ³›çš„ä½¿ç”¨åœºæ™¯ä¸‹ç¨³å®šè¿è¡Œï¼Œé£é™©è¾ƒä½ã€‚åç»­å…³æ³¨å…¼å®¹æ€§æµ‹è¯•ä¸æ–‡æ¡£åŒæ­¥å³å¯ã€‚

---

### [Bugfix] Disable TRTLLM FP8 MoE if router_logits_dtype==float32 and routing_method!=DeepSeekV3 (#33613)
**SHA**: `2a99c5a` | ğŸ”— [æŸ¥çœ‹æäº¤](https://github.com/vllm-project/vllm/commit/2a99c5a6c86daef8c766ba2dbf05c385b192c64b)

**å˜æ›´æ¦‚è§ˆ**  
æœ¬æ¬¡æäº¤ä¸º **Bugfix**ï¼Œä¿®å¤äº† TRTâ€‘LLM FP8 MoE åœ¨ `router_logits_dtype==float32` ä¸” `routing_method!=DeepSeekV3` æ—¶ä»è¢«é”™è¯¯å¯ç”¨çš„é—®é¢˜ã€‚æ ¸å¿ƒä¿®æ”¹åŒ…æ‹¬ï¼š

1. ** `flashinfer_trtllm_moe.py`**  
   - æ–°å¢ `_supports_router_logits_dtype` ç”¨äºåˆ¤å®š float32 logits åªåœ¨ DeepSeekV3 è·¯ç”±ä¸‹å—æ”¯æŒã€‚  
   - `is_supported_config_trtllm_fp8` å°†ä¸Šè¿°åˆ¤å®šçº³å…¥é…ç½®æ£€æŸ¥ã€‚  
   - `flashinfer_fused_moe_blockscale_fp8` å‚æ•°æ”¹ä¸º `routing_bias: Tensor|None`ï¼Œåœ¨ DeepSeekV3 è·¯ç”±æ—¶æ˜¾å¼æŠŠ `routing_logits` è½¬ä¸º `float32`ï¼Œå¹¶å¯¹ bias åš dtype å¯¹é½ã€‚  

2. **è°ƒç”¨æ–¹æ›´æ–°** (`oracle/fp8.pyã€compressed_tensors_moe.pyã€fp8.py`)  
   - å°†åŸæ¥çš„ `is_supported_config_trtllm` æ›¿æ¢ä¸ºæ–°å‡½æ•° `is_supported_config_trtllm_fp8`ã€‚  
   - ç§»é™¤å†—ä½™çš„ `RoutingMethodType` å¼•å…¥ï¼Œç»Ÿä¸€ä½¿ç”¨å±‚å¯¹è±¡çš„ `routing_method_type`ã€‚  
   - `torch.ops.vllm.flashinfer_fused_moe_blockscale_fp8` ç°åœ¨ç›´æ¥ä¼ å…¥åŸå§‹ `router_logits` ä¸ `e_score_correction_bias`ï¼Œä¸å†æ‰‹åŠ¨è½¬ dtypeï¼Œè½¬ dtype çš„é€»è¾‘è¿ç§»è‡³åº•å±‚å®ç°ã€‚  

3. **æ¨¡å‹åˆå§‹åŒ–** (`minimax_m2.py`)  
   - ä¸º MoE expert æ·»åŠ  `router_logits_dtype=torch.float32`ï¼Œé…åˆ DeepSeekV3 è·¯ç”±ä½¿ç”¨ã€‚  

**å½±å“èŒƒå›´**  
- **TRTâ€‘LLM FP8 MoE** çš„é…ç½®æ£€æŸ¥ä¸ kernel è°ƒç”¨è·¯å¾„ã€‚  
- ç›¸å…³çš„ **Fp8 MoE é‡åŒ–å±‚**ï¼ˆ`compressed_tensors_moe.py`ã€`fp8.py`ï¼‰ã€‚  
- ä½¿ç”¨ **DeepSeekV3** è·¯ç”±çš„æ¨¡å‹ï¼ˆå¦‚ Minimaxâ€‘M2ï¼‰ç°åœ¨å¯ä»¥å®‰å…¨ä½¿ç”¨ float32 logitsã€‚  

**é£é™© & å»ºè®®**  
- ç”±äº `routing_logits` ç°åœ¨åœ¨åº•å±‚ç»Ÿä¸€è½¬æ¢ä¸º `float32`ï¼ˆä»… DeepSeekV3ï¼‰ï¼Œè¯·ç¡®ä¿åœ¨å…¶ä»–è·¯ç”±æ–¹å¼ä¸‹ä»ä¿æŒ `bfloat16`ï¼Œå¦åˆ™ä¼šè§¦å‘ `is_supported_config_trtllm_fp8` æ£€æŸ¥å¤±è´¥ã€‚  
- æ–°å¢çš„ `routing_bias` ä¸ºå¯é€‰å‚æ•°ï¼ŒåŠ¡å¿…åœ¨è‡ªå®šä¹‰ MoE å®ç°ä¸­ä¿æŒ `None` ä¸ Tensor ä¸¤ç§æƒ…å†µçš„å…¼å®¹æ€§ã€‚  
- å»ºè®®è¡¥å……å•å…ƒæµ‹è¯•ï¼šâ‘  é DeepSeekV3 è·¯ç”±ä½¿ç”¨ `float32` logits åº”æŠ›å‡ºæ˜ç¡®é”™è¯¯ï¼›â‘¡ `routing_bias=None` åœºæ™¯ä¸‹ kernel èƒ½æ­£å¸¸è¿è¡Œï¼›â‘¢ è¿ç§»å‰åæ€§èƒ½å¯¹æ¯”ï¼Œç¡®ä¿æœªå¼•å…¥é¢å¤–å¼€é”€ã€‚  
- æ–‡æ¡£åº”åŒæ­¥è¯´æ˜ `router_logits_dtype` ä¸ `routing_method` çš„çº¦æŸå…³ç³»ï¼Œä»¥åŠ `is_supported_config_trtllm_fp8` çš„ä½¿ç”¨åœºæ™¯ã€‚  

æ•´ä½“æ¥çœ‹ï¼Œä¿®æ”¹ä½¿å¾— FP8 MoE åœ¨ä¸å…¼å®¹çš„é…ç½®ä¸‹è‡ªåŠ¨å¤±æ•ˆï¼Œæå‡äº†ç³»ç»Ÿé²æ£’æ€§ï¼Œé£é™©å¯æ§ã€‚

---

### [Voxtral Realtime] Change name (#33716)
**SHA**: `3f7662d` | ğŸ”— [æŸ¥çœ‹æäº¤](https://github.com/vllm-project/vllm/commit/3f7662d6505e441026e668ba78a2207d669f4f32)

**ğŸ¯ å˜æ›´ç±»å‹**ï¼šå…¶ä»–ï¼ˆæ¨¡å‹åç§°æ›´æ–°ï¼‰  
**âš¡ é‡è¦ç¨‹åº¦**ï¼šğŸŸ¡ ä¸­  

**ğŸ“‹ å˜æ›´æ‘˜è¦**  
æŠŠæ‰€æœ‰æ¼”ç¤ºè„šæœ¬å’Œå¯¹åº”å•å…ƒæµ‹è¯•ä¸­ç¡¬ç¼–ç çš„ Voxtralâ€‘Miniâ€‘3Bâ€‘Realtimeâ€‘2602 æ›¿æ¢ä¸ºæœ€æ–°ç‰ˆ Voxtralâ€‘Miniâ€‘4Bâ€‘Realtimeâ€‘2602ï¼Œä¿æŒç¤ºä¾‹ä¸å®é™…å‘å¸ƒæ¨¡å‹ä¸€è‡´ã€‚  

**ğŸ¯ å½±å“èŒƒå›´**  
- `examples/online_serving` ä¸‹çš„ä¸¤å¥— realtime å®¢æˆ·ç«¯è„šæœ¬  
- `tests/entrypoints/openai/test_realtime_validation.py`  
- `tests/models/multimodal/generation/test_voxtral_realtime.py`  

**ğŸ’¡ å…³æ³¨å»ºè®®**  
1. **å…¼å®¹æ€§æ£€æŸ¥**ï¼š4B æ¨¡å‹åœ¨å‚æ•°é‡ã€ä¸Šä¸‹æ–‡é•¿åº¦ã€éŸ³é¢‘å¤„ç†éœ€æ±‚ä¸Šå¯èƒ½ä¸ 3B æœ‰å·®å¼‚ï¼Œç¡®è®¤æµ‹è¯•ç”¨ä¾‹ï¼ˆå¦‚è¾“å‡ºé•¿åº¦ã€å“åº”æ—¶é—´ï¼‰ä»ç¬¦åˆé¢„æœŸï¼›è‹¥å‡ºç°æ–­è¨€å¤±æ•ˆï¼Œé€‚å½“æ”¾å®½é˜ˆå€¼æˆ–æ›´æ–°æœŸæœ›å€¼ã€‚  
2. **CI ç¯å¢ƒ**ï¼šç¡®ä¿ CI é•œåƒå·²ç¼“å­˜æˆ–èƒ½å³æ—¶ä¸‹è½½ `mistralai/Voxtral-Mini-4B-Realtime-2602`ï¼Œé¿å…å› æ¨¡å‹ä¸å­˜åœ¨å¯¼è‡´æµ‹è¯•è¶…æ—¶ã€‚  
3. **æ–‡æ¡£åŒæ­¥**ï¼šREADMEã€ç¤ºä¾‹æ–‡æ¡£ç­‰ä»æåŠ 3B æ—¶éœ€è¦åŒæ­¥æ›´æ–°ï¼Œé˜²æ­¢ç”¨æˆ·è¯¯å¯¼ã€‚  
4. **å›é€€ç­–ç•¥**ï¼šè‹¥ç”¨æˆ·ä»éœ€ä½¿ç”¨ 3B ç‰ˆæœ¬ï¼Œä¿æŒè„šæœ¬ä¸­ `--model` å‚æ•°å¯æ‰‹åŠ¨è¦†ç›–ï¼Œé¿å…å¼ºåˆ¶ç»‘å®šæ–°æ¨¡å‹ã€‚  

æ€»ä½“é£é™©ä½ï¼Œä¸»è¦æ˜¯æ–‡å­—/å¸¸é‡å˜æ›´ï¼Œå»ºè®®åœ¨å‘å¸ƒå‰è·‘ä¸€éå®Œæ•´çš„ realtime æµ‹è¯•å¥—ä»¶å¹¶éªŒè¯æ¨¡å‹ä¸‹è½½é€Ÿåº¦ã€‚

---

### [MISC] Fix Tensor Parallelism for Quantized Mamba Models with n_groups=1 (#33257)
**SHA**: `a372f3f` | ğŸ”— [æŸ¥çœ‹æäº¤](https://github.com/vllm-project/vllm/commit/a372f3f40afd0aed802242ce59b6a2640d4ef59e)

**ğŸ› ï¸ å˜æ›´ç±»å‹**ï¼šåŠŸèƒ½å¢å¼º / Bug ä¿®å¤  
**âš¡ é‡è¦ç¨‹åº¦**ï¼šğŸŸ¡ ä¸­  

**ğŸ“‹ å˜æ›´æ‘˜è¦**  
- è§£å†³é‡åŒ– Mamba æ¨¡å‹åœ¨ `n_groups=1` æ—¶çš„ Tensorâ€‘Parallelï¼ˆTPï¼‰é”™è¯¯ã€‚  
- å°†åŸå…ˆä½¿ç”¨çš„ `MergedColumnParallelLinear` æ›¿æ¢ä¸ºç»Ÿä¸€çš„ `ColumnParallelLinear`ï¼Œå¹¶é€šè¿‡è‡ªå®šä¹‰ `mamba_v2_sharded_weight_loader` å®Œæˆæƒé‡åˆ‡åˆ†ä¸å¤åˆ¶ã€‚  
- æ–°å¢å¯¹ `BasevLLMParameter`ï¼ˆé‡åŒ–æƒé‡åŒ…è£…ç±»ï¼‰çš„æ£€æµ‹ï¼Œç»Ÿä¸€åœ¨ `in_proj.weight` ä¸ŠæŒ‚è½½è‡ªå®šä¹‰ loaderï¼Œå…¼å®¹æ™®é€š `Parameter` ä¸é‡åŒ–å±‚ã€‚

**ğŸ¯ å½±å“èŒƒå›´**  
- `vllm/model_executor/layers/mamba/mamba_mixer2.py`ï¼ˆMamba Mixer å®ç°ï¼‰ã€‚  
- ç›¸å…³çš„æƒé‡åŠ è½½é€»è¾‘ `mamba_v2_sharded_weight_loader` ä¸ `set_weight_attrs`ã€‚  
- å¯èƒ½æ³¢åŠä½¿ç”¨ Mamba é‡åŒ–æ¨¡å‹çš„æ‰€æœ‰ TP é…ç½®ï¼ˆå°¤å…¶æ˜¯ `tp_size>1 && n_groups==1` çš„åœºæ™¯ï¼‰ã€‚

**ğŸ’¡ å…³æ³¨å»ºè®®**  
1. **å…¼å®¹æ€§æµ‹è¯•**ï¼šåœ¨ä¸åŒ TP å¤§å°ã€`n_groups`ï¼ˆ>1 ä¸ =1ï¼‰ä»¥åŠé‡åŒ–/éé‡åŒ–æ¨¡å‹ç»„åˆä¸‹è·‘å…¨å¥—å•å…ƒ/é›†æˆæµ‹è¯•ï¼Œç¡®ä¿æƒé‡åˆ‡åˆ†ã€å¤åˆ¶ä»¥åŠ forward å‡æ­£ç¡®ã€‚  
2. **æƒé‡åŠ è½½è·¯å¾„**ï¼šç¡®è®¤ `BasevLLMParameter` å­ç±»ï¼ˆå¦‚ FP8ã€GPTQ ç­‰ï¼‰åœ¨åŠ è½½æ—¶ä¸å†æ„å¤–è§¦å‘ `AttributeError`ï¼Œå¹¶æ£€æŸ¥ `weight_loader` é€»è¾‘æ˜¯å¦åœ¨é‡åŒ–å±‚ä¸­è¢«æ­£ç¡®è°ƒç”¨ã€‚  
3. **æ–‡æ¡£ä¸ç¤ºä¾‹**ï¼šæ›´æ–°æ–‡æ¡£è¯´æ˜ TP ä¸ `n_groups` çš„é™åˆ¶å·²æ”¾å®½ï¼Œæä¾›ä¸€ä¸ªæœ€å°å¤ç°è„šæœ¬æ¼”ç¤º `n_groups=1` é‡åŒ–æ¨¡å‹çš„å¯åŠ¨æ–¹å¼ã€‚  
4. **å›æ»šé£é™©**ï¼šè‹¥åç»­å‡ºç°åˆ‡åˆ†é”™è¯¯ï¼Œå¯ä¸´æ—¶ä¿ç•™ `MergedColumnParallelLinear` çš„å®ç°ä½œä¸ºå›é€€è·¯å¾„ï¼Œæˆ–åœ¨ `ColumnParallelLinear` å¤–å±‚åŠ ä¸€å±‚å…¼å®¹å±‚ã€‚  

æ€»ä½“æ¥çœ‹ï¼Œæ­¤æ¬¡ä¿®æ”¹åœ¨ä¿æŒåŠŸèƒ½å®Œæ•´çš„å‰æä¸‹ï¼Œç®€åŒ–äº†å®ç°å¹¶è§£å†³äº†å…³é”®çš„ TPâ€‘é‡åŒ–å…¼å®¹é—®é¢˜ã€‚å»ºè®®åœ¨ CI ä¸­åŠ å…¥å¯¹åº”çš„ TPâ€‘é‡åŒ–çŸ©é˜µæ£€æŸ¥ï¼Œä»¥é˜²æ­¢å›å½’ã€‚

---

### Turn `@config` into a `dataclass_transform` (#31541)
**SHA**: `61e632a` | ğŸ”— [æŸ¥çœ‹æäº¤](https://github.com/vllm-project/vllm/commit/61e632aea15f76fd1c46354b00f9cac62cd28c4e)

**ğŸ¯ å˜æ›´ç±»å‹**ï¼šåŠŸèƒ½å¢å¼ºï¼ˆå°† `@config` å‡çº§ä¸º `dataclass_transform`ï¼Œç»Ÿä¸€ä½¿ç”¨ Pydantic dataclassï¼‰

**âš¡ é‡è¦ç¨‹åº¦**ï¼šğŸŸ¡ ä¸­  
**ğŸ“‹ å˜æ›´æ‘˜è¦**  
- `vllm.config.utils.config` é‡æ–°å®ç°ä¸º `@dataclass_transform`ï¼Œå†…éƒ¨è°ƒç”¨ `pydantic.dataclasses.dataclass` å¹¶é»˜è®¤ `ConfigDict(extra="forbid")`ã€‚  
- åˆ é™¤é¡¹ç›®ä¸­å‡ ä¹æ‰€æœ‰æ˜¾å¼çš„ `@dataclass` è£…é¥°å™¨ï¼Œæ”¹ä¸ºä»…ä½¿ç”¨ `@config`ï¼ˆæˆ– `@config(config=â€¦)`ï¼‰ã€‚  
- æ–°å¢ `replace`ã€`is_init_field`ã€`get_field` ç­‰å…¼å®¹ Pydantic `Field` çš„å·¥å…·å‡½æ•°ã€‚  
- ç›¸åº”æµ‹è¯•ã€é¢„æäº¤æ ¡éªŒè„šæœ¬ã€CLI å‚æ•°ç±»ã€æ¨¡å‹é…ç½®ç­‰å…¨éƒ¨æ”¹å†™ä»¥é€‚é…æ–°çš„è£…é¥°å™¨å’Œ `Field`ï¼ˆå¦‚ `pydantic.Field` æ›¿ä»£ `dataclasses.field`ï¼‰ã€‚  

**ğŸ¯ å½±å“èŒƒå›´**  
- **æ ¸å¿ƒé…ç½®æ¨¡å—**ï¼š`vllm/config/*`ï¼ˆå‡ ä¹å…¨éƒ¨ï¼‰ï¼Œ`vllm/config/utils.py`ï¼ˆå®ç°å˜åŒ–ï¼‰ã€‚  
- **è¿è¡Œæ—¶ä»£ç **ï¼š`vllm/v1/spec_decode/draft_model.py`ã€`vllm/entrypoints/openai/cli_args.py`ã€`vllm/engine/arg_utils.py` ç­‰ä½¿ç”¨ `replace` çš„åœ°æ–¹ã€‚  
- **å·¥å…·é“¾**ï¼š`tools/pre_commit/validate_config.py`ï¼ˆä»…æ£€æŸ¥ `@config`ï¼Œä¸å†è¦æ±‚ `@dataclass`ï¼‰ã€‚  
- **æµ‹è¯•**ï¼šå…¨éƒ¨ `tests/*` å—å½±å“ï¼Œå°¤å…¶æ˜¯ `test_config.py`ã€`test_arg_utils.py`ã€`tools/test_config_validator.py`ã€‚  

**ğŸ’¡ å…³æ³¨å»ºè®®**  

1. **å…¼å®¹æ€§æ£€æŸ¥**ï¼š`replace` ç°åœ¨æ˜¯è‡ªå®ç°çš„å‡½æ•°ï¼Œå¤åˆ¶ `dataclasses.replace` çš„è¯­ä¹‰â€”â€”è¯·ç¡®è®¤åœ¨æ‰€æœ‰è°ƒç”¨å¤„ä¼ å…¥çš„å‚æ•°å‡ä¸º **init** å­—æ®µï¼Œå¦åˆ™ä¼šå‡ºç°æ„å¤–å±æ€§ç¼ºå¤±ã€‚  
2. **ç±»å‹æ£€æŸ¥**ï¼š`@dataclass_transform` ä»…åœ¨ç±»å‹æ£€æŸ¥é˜¶æ®µç”Ÿæ•ˆï¼Œè¿è¡Œæ—¶è¡Œä¸ºä¸å˜ã€‚è‹¥é¡¹ç›®æˆ– downstream ä»ä½¿ç”¨ `is_dataclass` æ£€æµ‹ï¼Œéœ€è¦ç¡®è®¤ä»è¿”å› `True`ï¼ˆPydantic dataclass å·²æ»¡è¶³ï¼‰ã€‚  
3. **é»˜è®¤å­—æ®µ**ï¼š`config` ç°åœ¨è‡ªåŠ¨åŠ ä¸Š `ConfigDict(extra="forbid")`ï¼Œè‹¥æœ‰å†å²ä»£ç ä¾èµ–äºé¢å¤–å­—æ®µå®½å®¹ï¼Œéœ€è¦åœ¨è£…é¥°å™¨è°ƒç”¨æ—¶æ˜¾å¼ä¼ å…¥ `config=ConfigDict(extra="allow")`ã€‚  
4. **æ–‡æ¡£ä¸ç¤ºä¾‹**ï¼šæ›´æ–° README / API æ–‡æ¡£ï¼Œè¯´æ˜ **ä¸å†éœ€è¦** `@dataclass`ï¼Œä»…ä¿ç•™ `@config`ï¼ˆå¯å¸¦ `config=` å‚æ•°ï¼‰ã€‚ç¤ºä¾‹ä»£ç ä¸­ä½¿ç”¨ `pydantic.Field` æ›¿ä»£ `dataclasses.field`ã€‚  
5. **CI/Preâ€‘commit**ï¼š`tools/pre_commit/validate_config.py` å·²ç®€åŒ–ï¼Œåªæ£€æŸ¥ `@config`ã€‚è‹¥å›¢é˜Ÿä»æœ‰è‡ªå®šä¹‰ lint è§„åˆ™ä¾èµ– `@dataclass`ï¼Œè¯·åŒæ­¥è°ƒæ•´ã€‚  
6. **å›å½’æµ‹è¯•**ï¼šè¿è¡Œå®Œæ•´æµ‹è¯•å¥—ä»¶ï¼ˆâ‰ˆ 2000+ ç”¨ä¾‹ï¼‰ç¡®ä¿æ‰€æœ‰é…ç½®çš„ JSON CLI è§£æã€é»˜è®¤å·¥å‚ã€åµŒå¥—é…ç½®ç­‰ä»è¡¨ç°ä¸€è‡´ï¼Œå¹¶é‡ç‚¹å…³æ³¨ `test_get_kwargs`ã€`test_config_validator`ã€‚  

æ€»ä½“æ¥è¯´ï¼Œæ­¤æ¬¡æ”¹åŠ¨æå‡äº†ç±»å‹å®‰å…¨å’Œç»Ÿä¸€æ€§ï¼Œä½†æ¶‰åŠçš„æ¨¡å—å¹¿æ³›ï¼Œå»ºè®®åœ¨åˆå¹¶å‰åšä¸€æ¬¡å…¨é‡é›†æˆæµ‹è¯•ï¼Œå¹¶åœ¨å‘è¡Œè¯´æ˜ä¸­æ˜ç¡® â€œ`@config` å·²å–ä»£ `@dataclass`â€ çš„è¿ç§»è·¯å¾„ã€‚

---

### [torch.compile] Significantly speed up cold start times (#33641)
**SHA**: `b1bb18d` | ğŸ”— [æŸ¥çœ‹æäº¤](https://github.com/vllm-project/vllm/commit/b1bb18de8d12cac63e3bbb0f59b3726fcb68dc80)

**ğŸ¯ å˜æ›´ç±»å‹**ï¼šåŠŸèƒ½å¢å¼ºï¼ˆå†·å¯åŠ¨ç¼–è¯‘ç¼“å­˜ä¼˜åŒ–ï¼‰  
**âš¡ é‡è¦ç¨‹åº¦**ï¼šğŸŸ¡ ä¸­  
**ğŸ“‹ å˜æ›´æ‘˜è¦**ï¼š  
1. å°†ç¼–è¯‘ç¼“å­˜çš„é”®ä» `(runtime_shape, graph_index, backend_name)` æ”¹ä¸º `(runtime_shape, graph_hash, backend_name)`ï¼Œé€šè¿‡å¯¹ `fx.GraphModule` è¿›è¡Œ `sanitize_gm_for_cache` ååºåˆ—åŒ–å¹¶å“ˆå¸Œå¾—åˆ° `graph_hash`ã€‚  
2. ä¸ºé¿å…é‡å¤è¯»å–ç£ç›˜ï¼Œæ–°å¢ `loaded_cache_entries` ç”¨äºåœ¨è¿›ç¨‹å†…ç¼“å­˜å·²åŠ è½½çš„ compiled graphã€‚  
3. ç›¸åº”åœ°åˆ é™¤äº† `CompilerInterface.load` ç­‰æ–¹æ³•ä¸­ä¸å†éœ€è¦çš„ `graph_index` å‚æ•°ã€‚  
4. æµ‹è¯• `test_cold_start` æ›´æ–°ä¸ºåªæ£€æŸ¥ 3 æ¬¡ cache missã€0 æ¬¡ cache hitï¼ŒéªŒè¯å”¯ä¸€å­å›¾åªç¼–è¯‘ä¸€æ¬¡ã€‚

**ğŸ¯ å½±å“èŒƒå›´**ï¼š  
- `vllm/compilation/backends.py`ï¼ˆç¼“å­˜é”®ã€åŠ è½½/ä¿å­˜é€»è¾‘ï¼‰  
- `vllm/compilation/compiler_interface.py`ï¼ˆå‡½æ•°ç­¾ååˆ é™¤ `graph_index`ï¼‰  
- `tests/compile/test_cold_start.py`ï¼ˆæ–­è¨€æ›´æ–°ï¼‰  
- å¯èƒ½æ¶‰åŠ `torch._functorch._aot_autograd.autograd_cache` çš„åºåˆ—åŒ–å…¼å®¹æ€§ã€‚

**ğŸ’¡ å…³æ³¨å»ºè®®**ï¼š  
1. **å…¼å®¹æ€§æ£€æŸ¥**ï¼šç¡®ä¿æ‰€æœ‰è°ƒç”¨ `CompilerManager.compile`ã€`load`ã€ä»¥åŠ `CompilerInterface.load` çš„åœ°æ–¹å·²åŒæ­¥æ”¹ä¸ºä¼ å…¥ `graph_hash` è€Œé `graph_index`ï¼Œå¦åˆ™ä¼šåœ¨è¿è¡Œæ—¶æŠ›å‡ºå‚æ•°é”™è¯¯ã€‚  
2. **ç¼“å­˜è¿ç§»**ï¼šæ­¤å‰ç”Ÿæˆçš„ `vllm_compile_cache.py` ä½¿ç”¨æ•´æ•°ç´¢å¼•ï¼Œå‡çº§åå°†æ— æ³•ç›´æ¥è¯»å–ã€‚å»ºè®®åœ¨å‘å¸ƒè¯´æ˜ä¸­æç¤ºç”¨æˆ·åˆ é™¤æ—§ç¼“å­˜æˆ–æä¾›è¿ç§»è„šæœ¬ã€‚  
3. **åºåˆ—åŒ–å®‰å…¨**ï¼š`sanitize_gm_for_cache` å¯èƒ½å‰”é™¤éç¡®å®šæ€§å±æ€§ï¼Œç¡®ä¿è¿™ä¸€æ­¥åœ¨æ‰€æœ‰æ”¯æŒçš„æ¨¡å‹ä¸Šä¸ä¼šç ´ååç«¯ç‰¹æœ‰ä¿¡æ¯ï¼ˆå¦‚è‡ªå®šä¹‰å­æ¨¡å—ï¼‰ã€‚  
4. **æ€§èƒ½å›å½’**ï¼šæ–°å¢çš„ `hashlib.sha256` è®¡ç®—å’Œ `pickle.dumps`ï¼ˆvia `AOTAutogradCachePickler`) åœ¨å†·å¯åŠ¨æ—¶ä¼šæœ‰ä¸€å®šå¼€é”€ï¼Œå»ºè®®åœ¨ CI ä¸­åŠ å…¥åŸºå‡†æµ‹è¯•ï¼Œç¡®ä¿æ•´ä½“å†·å¯åŠ¨æ—¶é—´ä»æœ‰æ˜¾è‘—æå‡ã€‚  
5. **æ–‡æ¡£æ›´æ–°**ï¼šåœ¨ `vllm` ç¼–è¯‘ç¼“å­˜ç« èŠ‚è¡¥å……è¯´æ˜ç¼“å­˜é”®çš„å˜åŒ–ã€ä½•æ—¶ä¼šäº§ç”Ÿæ–° hashã€ä»¥åŠå¦‚ä½•æ‰‹åŠ¨æ¸…é™¤ç¼“å­˜ã€‚  

æ•´ä½“æ¥çœ‹ï¼Œæ­¤æ¬¡æ”¹åŠ¨é€šè¿‡åŸºäºå­å›¾å†…å®¹çš„å“ˆå¸Œå®ç°äº†çœŸæ­£çš„å­å›¾å»é‡ï¼Œæ˜¾è‘—é™ä½äº†å†·å¯åŠ¨æ—¶çš„é‡å¤ç¼–è¯‘æ¬¡æ•°ï¼Œå¯¹å¤§æ¨¡å‹å¯åŠ¨æ€§èƒ½æå‡æ˜æ˜¾ã€‚ä½†éœ€æ³¨æ„ç¼“å­˜æ ¼å¼å…¼å®¹åŠè°ƒç”¨æ–¹ç­¾ååŒæ­¥ï¼Œä»¥é˜²å¼•å…¥è¿è¡Œæ—¶é”™è¯¯ã€‚

---

### [Attention][FA3] Update FA3 to include new swizzle optimization (#23465)
**SHA**: `2267cb1` | ğŸ”— [æŸ¥çœ‹æäº¤](https://github.com/vllm-project/vllm/commit/2267cb1cfd838a192f47ff677d91164fb5cb2862)

**ğŸ¯ å˜æ›´ç±»å‹**ï¼šåŠŸèƒ½å¢å¼ºï¼ˆFA3 æ–°å¢ swizzle ä¼˜åŒ–ï¼‰  
**âš¡ é‡è¦ç¨‹åº¦**ï¼šğŸŸ¡ ä¸­  
**ğŸ“‹ å˜æ›´æ‘˜è¦**ï¼šå°† vllmâ€‘flashâ€‘attn å­æ¨¡å—å‡çº§è‡³æœ€æ–° commitï¼Œå¹¶åœ¨ FlashAttention ä¸ MLA ä¸¤ä¸ªåç«¯çš„ CUDAâ€‘graph åˆå§‹åŒ–ä¸­ï¼Œå°† `scheduler_metadata` é•¿åº¦æå‡ä¸º `max(max_cudagraph_size, max_num_seqs) * 4 + 1`ï¼Œä»¥å…¼å®¹æ–°å®ç°çš„ 4â€‘å€ swizzle éœ€æ±‚ã€‚  
**ğŸ¯ å½±å“èŒƒå›´**ï¼š`vllm/v1/attention/backends/flash_attn.py`ã€`vllm/v1/attention/backends/mla/flashattn_mla.py`ã€CMake å¤–éƒ¨é¡¹ç›®é…ç½®ã€‚æ¶‰åŠè°ƒåº¦å™¨ã€GPU å†…å­˜åˆ†é…ä»¥åŠ CUDAâ€‘graph æ•è·ã€‚  

**ğŸ’¡ å…³æ³¨å»ºè®®**  
1. **å†…å­˜å ç”¨**ï¼šä¹˜ä»¥ 4 ä¼šæ˜¾è‘—å¢åŠ  `scheduler_metadata` çš„æ˜¾å­˜éœ€æ±‚ï¼Œå»ºè®®åœ¨ CI/benchmark ä¸­ç›‘æ§æ˜¾å­˜å³°å€¼ï¼Œå°¤å…¶åœ¨ `max_num_seqs` è¾ƒå¤§æ—¶ã€‚  
2. **å…¼å®¹æ€§**ï¼šæ–°å­æ¨¡å— tag å¯èƒ½å¸¦æ¥ API å˜åŒ–æˆ–ç¼–è¯‘ä¾èµ–ï¼Œè¯·ç¡®ä¿æ‰€æœ‰å·²æœ‰æ’ä»¶ï¼ˆå¦‚ LoRAã€TPUâ€‘offloadï¼‰åœ¨æ–°ç‰ˆæœ¬ä¸‹ä»èƒ½ç¼–è¯‘é€šè¿‡ã€‚  
3. **é…ç½®æ£€æŸ¥**ï¼š`max_cudagraph_size` è‹¥ä¸º `None` ä¼šè¢«è½¬ä¸º `0`ï¼Œé¿å…æ„å¤–ç”Ÿæˆä»… `max_num_seqs*4+1` çš„ç¼“å†²ï¼›å»ºè®®åœ¨æ–‡æ¡£ä¸­æ˜ç¡® `max_cudagraph_capture_size` çš„å–å€¼èŒƒå›´ã€‚  
4. **åŠŸèƒ½éªŒè¯**ï¼šå¯¹æ¯” FA2 ä¸ FA3 åœ¨ä¸åŒ batch/seq é•¿åº¦ä¸‹çš„ååå’Œå»¶è¿Ÿï¼Œç¡®ä¿ swizzle ä¼˜åŒ–å¸¦æ¥çš„æ”¶ç›Šå¤§äºé¢å¤–çš„å†…å­˜å¼€é”€ã€‚  
5. **å›é€€è·¯å¾„**ï¼šè‹¥ç”¨æˆ·éœ€ä½¿ç”¨æ—§è¡Œä¸ºï¼Œå¯è€ƒè™‘æ–°å¢ç¯å¢ƒå˜é‡æˆ–é…ç½®é€‰é¡¹æ¥å…³é—­ä¹˜ 4 çš„æ‰©å®¹ï¼Œä»¥é˜²æ˜¾å­˜å—é™çš„è®¾å¤‡å‡ºç° OOMã€‚  

æ€»ä½“è€Œè¨€ï¼Œæ­¤æ¬¡æ”¹åŠ¨å¯¹æ€§èƒ½ä¼˜åŒ–æœ‰æ­£å‘æœŸå¾…ï¼Œä½†éœ€è¦å……åˆ†çš„å›å½’æµ‹è¯•ä¸æ˜¾å­˜è¯„ä¼°ï¼Œé˜²æ­¢åœ¨é«˜è´Ÿè½½åœºæ™¯ä¸‹å‡ºç°èµ„æºä¸è¶³çš„é—®é¢˜ã€‚

---

#### ğŸŸ¢ ä½é‡è¦åº¦å˜æ›´ (13)

### [Bugfix] Fix `normalize` still being passed to `PoolerConfig` (#33794)
**SHA**: `80f921b` | ğŸ”— [æŸ¥çœ‹æäº¤](https://github.com/vllm-project/vllm/commit/80f921ba4bab2ea251d149305ea0f912c6fc218a)

**ğŸ¯ å˜æ›´ç±»å‹**ï¼šä»£ç é‡æ„  
**âš¡ é‡è¦ç¨‹åº¦**ï¼šğŸŸ¢ä½  
**ğŸ“‹ æ‘˜è¦**ï¼šå°† `PoolerConfig` ä¸­çš„ `normalize` å‚æ•°æ”¹ä¸º `use_activation`ï¼ŒåŒæ­¥æ›´æ–°æ–‡æ¡£è¯´æ˜åŠå¯¹åº”æµ‹è¯•ä»£ç ã€‚

---

### [Perf] Optimize spec decoding + async scheduling, 1.5% Throughput improvement (#33612)
**SHA**: `711edaf` | ğŸ”— [æŸ¥çœ‹æäº¤](https://github.com/vllm-project/vllm/commit/711edaf0d089a15df5fa2b99248c516e53929bd2)

**ğŸ¯ å˜æ›´ç±»å‹**ï¼šä»£ç é‡æ„  
**âš¡ é‡è¦ç¨‹åº¦**ï¼šğŸŸ¢ä½  
**ğŸ“‹ æ‘˜è¦**ï¼šåœ¨ `AsyncScheduler` ä¸­å¼•å…¥å…±äº«çš„å ä½ç¬¦åˆ—è¡¨ä»¥å¤ç”¨ spec decoding çš„ placeholderï¼Œè°ƒæ•´ `Scheduler` ä¸­å¯¹ `spec_token_ids` çš„è£å‰ªé€»è¾‘å¹¶é˜²æ­¢ç©ºåˆ—è¡¨é”™è¯¯ï¼Œæå‡çº¦ 1.5% ååã€‚

---

### [Bugfix][ROCm] Include float8_e4m3fnuz in NCCL Dtype Dispatching (#33713)
**SHA**: `1d367a7` | ğŸ”— [æŸ¥çœ‹æäº¤](https://github.com/vllm-project/vllm/commit/1d367a738e9098ad4af1f6865747914ccd2c65ca)

**ğŸ¯ å˜æ›´ç±»å‹**ï¼šä»£ç é‡æ„  
**âš¡ é‡è¦ç¨‹åº¦**ï¼šğŸŸ¢ä½  
**ğŸ“‹ æ‘˜è¦**ï¼šåœ¨ `pynccl_wrapper.py` ä¸­å°†å¯¹ `torch.float8_e4m3fn` çš„ç¡¬ç¼–ç æ£€æŸ¥æ”¹ä¸º `current_platform.fp8_dtype()`ï¼Œä¿®å¤ ROCm ç¯å¢ƒä¸‹çš„ Float8 dtype æ´¾å‘é”™è¯¯ã€‚

---

### Apply #33621 to main (#33758)
**SHA**: `32a02c7` | ğŸ”— [æŸ¥çœ‹æäº¤](https://github.com/vllm-project/vllm/commit/32a02c7ca29180f70c1c8c73d0f57445231b17b5)

**ğŸ¯ å˜æ›´ç±»å‹**ï¼šæ–‡æ¡£æ›´æ–°  
**âš¡ é‡è¦ç¨‹åº¦**ï¼šğŸŸ¢ä½  
**ğŸ“‹ æ‘˜è¦**ï¼šå°† `aiohttp` ç‰ˆæœ¬çº¦æŸç»Ÿä¸€å‡çº§è‡³ `>=3.13.3`ï¼ˆåœ¨ `requirements/common.txt`ã€`requirements/rocm-test.txt`ã€`requirements/test.txt` ä¸­ï¼‰ï¼Œä¿è¯ä¾èµ–ä¸€è‡´æ€§ã€‚

---

### [Perf] Optimize chat completion streaming performance (#33782)
**SHA**: `f67ee8b` | ğŸ”— [æŸ¥çœ‹æäº¤](https://github.com/vllm-project/vllm/commit/f67ee8b859215df4b521c67b9f26e27f30c9739f)

**ğŸ¯ å˜æ›´ç±»å‹**ï¼šä»£ç é‡æ„  
**âš¡ é‡è¦ç¨‹åº¦**ï¼šğŸŸ¢ä½  
**ğŸ“‹ æ‘˜è¦**ï¼šåœ¨ `chat_completion_stream_generator` ä¸­æ–°å¢ `prompt_is_reasoning_end_arr` ç¼“å­˜ï¼Œé¿å…åœ¨æµå¼å“åº”çš„æ¯ä¸ªå¢é‡ä¸Šé‡å¤è°ƒç”¨ `reasoning_parser.is_reasoning_end`ï¼Œæå‡èŠå¤©å®Œæˆçš„æµå¼æ€§èƒ½ã€‚

---

### [compile] Remove runner type from ignored caching factor list. (#33712)
**SHA**: `a208439` | ğŸ”— [æŸ¥çœ‹æäº¤](https://github.com/vllm-project/vllm/commit/a208439537a9071668b99dc8089db0dd8995034a)

**ğŸ¯ å˜æ›´ç±»å‹**ï¼šä»£ç é‡æ„  
**âš¡ é‡è¦ç¨‹åº¦**ï¼šğŸŸ¢ä½  
**ğŸ“‹ æ‘˜è¦**ï¼šåœ¨ `ModelConfig` ä¸­åˆ é™¤ `runner` é€‰é¡¹ï¼Œä½¿å…¶ä¸å†è¢« `compute_hash` çš„å¿½ç•¥å› å­åˆ—è¡¨æ’é™¤ï¼Œä»è€Œä½¿ Runner é…ç½®å‚ä¸ç¼“å­˜é”®çš„è®¡ç®—ã€‚

---

### [compile] Clean up AOT compile bypass on evaluate_guards. (#33578)
**SHA**: `bcd2f74` | ğŸ”— [æŸ¥çœ‹æäº¤](https://github.com/vllm-project/vllm/commit/bcd2f74c0d1e85a2da4dcb41849ad75a7e3fdaf4)

**ğŸ¯ å˜æ›´ç±»å‹**ï¼šä»£ç é‡æ„  
**âš¡ é‡è¦ç¨‹åº¦**ï¼šğŸŸ¢ ä½  
**ğŸ“‹ æ‘˜è¦**ï¼šåœ¨ `vllm/compilation/wrapper.py` ä¸­åˆ é™¤äº†é’ˆå¯¹ `VLLM_USE_AOT_COMPILE` çš„æ–­è¨€å’Œæ³¨é‡Šï¼Œæ¸…ç†äº†å·²åºŸå¼ƒçš„ AOT ç¼–è¯‘æ£€æŸ¥é€»è¾‘ã€‚ä»£ç åŠŸèƒ½ä¿æŒä¸å˜ï¼Œä»…å»é™¤ä¸å†ä½¿ç”¨çš„è·¯å¾„ã€‚

---

### use ORJSONResponse when available to improve the efficiency of request process (#33548)
**SHA**: `4c8d1bf` | ğŸ”— [æŸ¥çœ‹æäº¤](https://github.com/vllm-project/vllm/commit/4c8d1bf361c0ad4066f2c90f636b5fabe80a94eb)

**ğŸ¯ å˜æ›´ç±»å‹**ï¼šä»£ç é‡æ„  
**âš¡ é‡è¦ç¨‹åº¦**ï¼šğŸŸ¢ä½  
**ğŸ“‹ æ‘˜è¦**ï¼šåœ¨ embeddings API ä¸­å¼•å…¥å¯¹ `orjson` çš„å¯é€‰ä½¿ç”¨ï¼Œä½¿ç”¨ LRU ç¼“å­˜è·å–å“åº”ç±»ï¼Œæœªå®‰è£…æ—¶å›é€€ JSONResponse å¹¶è®°å½•ä¸€æ¬¡è­¦å‘Šï¼Œä»¥æå‡è¯·æ±‚åºåˆ—åŒ–æ•ˆç‡ã€‚

---

### [XPU] remove common path warning log (#33769)
**SHA**: `061da6b` | ğŸ”— [æŸ¥çœ‹æäº¤](https://github.com/vllm-project/vllm/commit/061da6bcf7d369cc2fb55a56b8bdc91fd9bc96d5)

**ğŸ¯ å˜æ›´ç±»å‹**ï¼šä»£ç é‡æ„  
**âš¡ é‡è¦ç¨‹åº¦**ï¼šğŸŸ¢ä½  
**ğŸ“‹ æ‘˜è¦**ï¼šå°†åŸå…ˆåœ¨ `__init__.py` ä¸­çš„ XCCL æœªå¯ç”¨è­¦å‘Šç§»è‡³ `xpu.py`ï¼Œä»…åœ¨ä¸æ”¯æŒ XCCL æ—¶æ‰è¾“å‡ºï¼Œé»˜è®¤åç«¯æ”¹ä¸º `xccl`ã€‚

---

### [Hardware][AMD][CI] Refactor AMD tests to properly use BuildKite parallelism (#32745)
**SHA**: `08e0949` | ğŸ”— [æŸ¥çœ‹æäº¤](https://github.com/vllm-project/vllm/commit/08e094997ecb28b4c5ad4dd28fd6fbb48adba279)

**ğŸ¯ å˜æ›´ç±»å‹**ï¼šé…ç½®è°ƒæ•´  
**âš¡ é‡è¦ç¨‹åº¦**ï¼šğŸŸ¢ä½  
**ğŸ“‹ æ‘˜è¦**ï¼šåœ¨ AMD CI è„šæœ¬ä¸­å»é™¤æ‰‹åŠ¨åˆ†ç‰‡å¹¶è¡Œæ‰§è¡Œï¼Œæ”¹ä¸ºç›´æ¥ä½¿ç”¨ Buildkite å¹¶è¡Œï¼›åŒæ­¥å°†å¤šæ¡ AMD æµ‹è¯•æ­¥éª¤çš„ `agent_pool` ä» `mi325_8` è°ƒæ•´ä¸º `mi325_1`ã€‚

---

### [Deprecation] Remove `_get_data_parser` in MM processor (#33757)
**SHA**: `90d74eb` | ğŸ”— [æŸ¥çœ‹æäº¤](https://github.com/vllm-project/vllm/commit/90d74ebaa47fcecdcd8ef72338dda47b7cb6fbf0)

**ğŸ¯ å˜æ›´ç±»å‹**ï¼šä»£ç é‡æ„  
**âš¡ é‡è¦ç¨‹åº¦**ï¼šğŸŸ¢ä½  
**ğŸ“‹ æ‘˜è¦**ï¼šåœ¨ `BaseMultiModalProcessor` ä¸­åˆ é™¤å¯¹å·²åºŸå¼ƒçš„ `_get_data_parser` çš„å…¼å®¹å¤„ç†ï¼Œè‹¥å­ç±»ä»å®ç°è¯¥æ–¹æ³•åˆ™æŠ›å‡º `ValueError`ï¼Œç»Ÿä¸€ä½¿ç”¨ `info.get_data_parser()`ï¼ˆå³ `BaseProcessingInfo.build_data_parser`ï¼‰ã€‚ä»…æ¶‰åŠå°‘é‡è¡Œæ•°ä¿®æ”¹ã€‚

---

### Save startup benchmark results as a list of values (#33629)
**SHA**: `2647163` | ğŸ”— [æŸ¥çœ‹æäº¤](https://github.com/vllm-project/vllm/commit/2647163674720242cee78dae3f7c7b98539ed029)

**ğŸ¯ å˜æ›´ç±»å‹**ï¼šä»£ç é‡æ„  
**âš¡ é‡è¦ç¨‹åº¦**ï¼šğŸŸ¢ä½  
**ğŸ“‹ æ‘˜è¦**ï¼šåœ¨ `convert_to_pytorch_benchmark_format` ä¸­åŠ å…¥å¯¹ metric å¿…é¡»ä¸º list çš„ç±»å‹æ£€æŸ¥ï¼Œå¹¶åœ¨ `startup.py` å°†å•å€¼åŒ…è£…ä¸ºåˆ—è¡¨ä»¥åŒ¹é…æ–°æ¥å£ã€‚

---

### [Dependency] Remove comments of ray in dependency files (#33351)
**SHA**: `655efb3` | ğŸ”— [æŸ¥çœ‹æäº¤](https://github.com/vllm-project/vllm/commit/655efb3e69bb18d150a88c0d726ca2b49f22cbdd)

**ğŸ¯ å˜æ›´ç±»å‹**ï¼šé…ç½®è°ƒæ•´  
**âš¡ é‡è¦ç¨‹åº¦**ï¼šğŸŸ¢ä½  
**ğŸ“‹ æ‘˜è¦**ï¼šåœ¨ `requirements/cuda.txt` ä¸ `requirements/rocm.txt` ä¸­å»é™¤ `ray[cgraph]>=2.48.0` åçš„æ³¨é‡Šï¼Œç»Ÿä¸€ä¾èµ–å£°æ˜ã€‚

---

