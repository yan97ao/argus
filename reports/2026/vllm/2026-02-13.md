# æ¯æ—¥æ›´æ–°æŠ¥å‘Šï¼ˆ2026-02-13ï¼‰

## vllm-project/vllm

| æäº¤æ—¶é—´ | ä½œè€… | æäº¤ä¿¡æ¯ |
|----------|------|----------|
| 2026-02-13 21:59:00 | Roger Wang | [Bugfix] Exclude `language_model_only` key from MM AOT compile hash but include in model one (#34508) |
| 2026-02-13 21:24:25 | Roger Wang | [Misc] Port Qwen3.5 Configs (#34512) |
| 2026-02-13 17:53:09 | Ilya Boytsov | Extend ColBERT support to non-standard BERT backbones (#34170) |
| 2026-02-13 17:24:45 | Woosuk Kwon | [GDN] Use CPU tensors to build GDN metadata (#34498) |
| 2026-02-13 16:38:16 | Wentao Ye | [Feature] Pipeline Parallel Async send/recv, 2.9% E2E throughput improvement (#33368) |
| 2026-02-13 16:15:10 | Aaron Hao | [Core] Move pause and resume functions into engine (#34125) |
| 2026-02-13 16:14:30 | Martin Hickey | [KVConnector] Clean up redundant code in KV connectors (#34147) |
| 2026-02-13 16:14:27 | Matthias Gehre | [Perf] fused_moe: add int4_w4a16 benchmark support and tuning config (#34130) |
| 2026-02-13 16:13:45 | Marek Michalowski | [Bugfix] fix the import path in moe test utils.py (#34245) |
| 2026-02-13 16:13:22 | haosdent | [Bug Fix] Fix MambaManager.cache_blocks() crash on null blocks in align mode (#34418) |
| 2026-02-13 16:13:14 | Harry Huang | [BugFix] Fix and optimize max_num_blocks_per_req calculation for MambaSpec (#34440) |
| 2026-02-13 16:12:45 | myselvess | [New Model] support new model ovis2.6 (#34426) |
| 2026-02-13 14:48:45 | Cyrus Leung | [Refactor] Call renderer for online IO processor request (#34490) |
| 2026-02-13 14:48:42 | Roger Wang | [Bugfix] Fix mamba state dtype setting for Qwen3-Next and Qwen3.5 (#34489) |
| 2026-02-13 14:48:38 | Cyrus Leung | [Refactor] Pass full VllmConfig to Renderer (#34485) |
| 2026-02-13 14:43:53 | Cyrus Leung | [CI/Build] Fix CUDA re-initialization error in distributed model tests (#34491) |
| 2026-02-13 13:04:06 | haosdent | [Bugfix] Fix encoder cache underestimation for GLM-4V/GLM-OCR single image (#34483) |
| 2026-02-13 12:47:01 | Cyrus Leung | [Bugfix] Standardize getting number of image patches/tokens (#34358) |
| 2026-02-13 11:27:53 | Andreas Karatzas | [ROCm][CI] Fix serving tokens test failures (#34047) |
| 2026-02-13 10:39:28 | Cyrus Leung | Add new sections to CODEOWNERS (#34309) |
| 2026-02-13 10:21:52 | Harry Huang |  [Hybrid] Fix and optimize block-aligned splitting in mamba cache align mode (#33706) |
| 2026-02-13 10:21:19 | Frank Wang | [Bugfix] Fix Random Dataset Prefix Length Inaccuracy (#33907) |
| 2026-02-13 10:21:05 | Yanan Cao | [Kernel] [Helion] [5/N] Add Helion Autotuning infrastructure (#34025) |
| 2026-02-13 10:18:42 | LoganJane | [Bugfix] Delete unused redundant code in Kimi-K2.5 (#34427) |
| 2026-02-13 10:18:24 | Cyrus Leung | [Refactor] Simplify BOS/EOS token handling (#34435) |
| 2026-02-13 10:18:15 | bnellnm | [Bugfix] Remove assert that's no longer valid (#34443) |
| 2026-02-13 10:18:07 | Harry Huang | [BugFix] Add block_size validation for mamba cache align mode (#34445) |
| 2026-02-13 10:18:03 | Zhuohan Li | Fix num_logprobs parameter description in sampler.py (#34451) |
| 2026-02-13 10:15:36 | Cyrus Leung | [CI/Build] Update video URLs for testing (#34446) |
| 2026-02-13 10:13:12 | Yanan Cao | [Kernel] [Helion] [4/N] Add silu_mul_fp8 Helion kernel  (#33373) |
| 2026-02-13 08:16:38 | Jaewon | [Core] Profiler improvements and lazy initialization (#33198) |
| 2026-02-13 08:16:25 | Jaewon | [Core] Add sleep level 0 mode with enqueue/wait pattern (#33195) |
| 2026-02-13 08:15:48 | Alec S | [Frontend] Enable generic structured_outputs for responses API (#33709) |
| 2026-02-13 08:14:43 | Mengtao (Martin) Yuan | Use paged_attention_v1 for sliding window decode in rocm_aiter_fa (#34378) |
| 2026-02-13 05:06:58 | amitz-nv | [Kernel] Support Flashinfer trtllm fused MoE non gated FP8 & NVFP4 (#33506) |
| 2026-02-13 04:26:36 | Hashem Hashemi | small adjustment to wvSplitKrc (#34410) |
| 2026-02-13 04:08:06 | Michael Goin | [Bugfix] Enforce DeepGEMM when using sparse_attn_indexer on CUDA (#34374) |
| 2026-02-13 02:47:34 | Andreas Karatzas | [ROCm][CI] Pin TorchCodec to v0.10.0 for ROCm compatibility (#34447) |
| 2026-02-13 01:46:43 | Patrick von Platen | [Voxtral Realtime] Refactor & Improve buffering logic (#34428) |
| 2026-02-13 01:43:24 | Patrick von Platen | [Voxstral Realtime] Enable tests (#33803) |
| 2026-02-13 01:40:19 | xuebwang-amd | [ROCm][quantization] improve OCP weight quant parser robust (#34431) |
| 2026-02-13 01:40:01 | Isotr0py | [Bugfix] Remove broken raw url GGUF model loading support (#34433) |
| 2026-02-13 01:29:42 | Harry Mellor | Fix MoE for the Transformers modelling backend (#34436) |
| 2026-02-13 01:21:54 | Matthew Bonanni | [Attention] Add FlashInfer Sparse MLA backend (#33451) |
| 2026-02-13 01:01:51 | NicolÃ² Lucchesi | [Docs] Spec decoding docs warning removal (#34439) |
| 2026-02-13 00:19:13 | Aaron Hao | [BUG] Reset running requests when clearing cache for pause/resume (#34382) |

### ğŸ“Š ç»Ÿè®¡æ‘˜è¦
> æœ¬æ—¥å…± 46 ä¸ªæäº¤ | ğŸ”´é«˜ 5 | ğŸŸ¡ä¸­ 17 | ğŸŸ¢ä½ 24
## ğŸ“‹ ç›®å½•

- [vllm-project/vllm](#vllm-project-vllm)
  - [ğŸ“Š ç»Ÿè®¡æ‘˜è¦](#-ç»Ÿè®¡æ‘˜è¦)
  - [ğŸ”´ é«˜é‡è¦åº¦å˜æ›´ (5)](#-ğŸ”´-é«˜é‡è¦åº¦å˜æ›´-5)
    - [Extend ColBERT support to non-standard BERT backbones (#3...](#071d863)
    - [[Core] Move pause and resume functions into engine (#34125)](#dddbff4)
    - [[Bugfix] Standardize getting number of image patches/toke...](#372b2e7)
    - [[Kernel] [Helion] [4/N] Add silu_mul_fp8 Helion kernel  (...](#96161fe)
    - [[Attention] Add FlashInfer Sparse MLA backend (#33451)](#f2c4788)
  - [ğŸŸ¡ ä¸­é‡è¦åº¦å˜æ›´ (17)](#-ğŸŸ¡-ä¸­é‡è¦åº¦å˜æ›´-17)
    - [[Bugfix] Exclude `language_model_only` key from MM AOT co...](#1dae7b7)
    - [[Misc] Port Qwen3.5 Configs (#34512)](#5885e33)
    - [[Feature] Pipeline Parallel Async send/recv, 2.9% E2E thr...](#3d2a026)
    - [[KVConnector] Clean up redundant code in KV connectors (#...](#47e9b63)
    - [[Perf] fused_moe: add int4_w4a16 benchmark support and tu...](#934acdd)
    - [[New Model] support new model ovis2.6 (#34426)](#bcf0731)
    - [[Refactor] Call renderer for online IO processor request ...](#ec090c2)
    - [[Bugfix] Fix mamba state dtype setting for Qwen3-Next and...](#eea3024)
    - [[Refactor] Pass full VllmConfig to Renderer (#34485)](#2f30821)
    - [[Kernel] [Helion] [5/N] Add Helion Autotuning infrastruct...](#de13dd7)
    - [[Refactor] Simplify BOS/EOS token handling (#34435)](#ea5ff3a)
    - [[Core] Profiler improvements and lazy initialization (#33...](#4453ba8)
    - [[Core] Add sleep level 0 mode with enqueue/wait pattern (...](#aa181c9)
    - [[Frontend] Enable generic structured_outputs for response...](#be7370d)
    - [[Kernel] Support Flashinfer trtllm fused MoE non gated FP...](#f120bd4)
    - [[Voxtral Realtime] Refactor & Improve buffering logic (#3...](#6c0baee)
    - [[Voxstral Realtime] Enable tests (#33803)](#1100a97)
  - [ğŸŸ¢ ä½é‡è¦åº¦å˜æ›´ (24)](#-ğŸŸ¢-ä½é‡è¦åº¦å˜æ›´-24)
    - [[GDN] Use CPU tensors to build GDN metadata (#34498)](#0916e79)
    - [[Bugfix] fix the import path in moe test utils.py (#34245)](#742d214)
    - [[Bug Fix] Fix MambaManager.cache_blocks() crash on null b...](#4137c5d)
    - [[BugFix] Fix and optimize max_num_blocks_per_req calculat...](#7a8a46d)
    - [[CI/Build] Fix CUDA re-initialization error in distribute...](#1b4e8e5)
    - [[Bugfix] Fix encoder cache underestimation for GLM-4V/GLM...](#dcf6ee8)
    - [[ROCm][CI] Fix serving tokens test failures (#34047)](#6afa587)
    - [Add new sections to CODEOWNERS (#34309)](#94ed6cf)
    - [[Hybrid] Fix and optimize block-aligned splitting in mamb...](#bf37812)
    - [[Bugfix] Fix Random Dataset Prefix Length Inaccuracy (#33...](#b86bf44)
    - [[Bugfix] Delete unused redundant code in Kimi-K2.5 (#34427)](#62788f9)
    - [[Bugfix] Remove assert that's no longer valid (#34443)](#04ea31b)
    - [[BugFix] Add block_size validation for mamba cache align ...](#6f019e6)
    - [Fix num_logprobs parameter description in sampler.py (#34...](#d707678)
    - [[CI/Build] Update video URLs for testing (#34446)](#fc22cae)
    - [Use paged_attention_v1 for sliding window decode in rocm_...](#9ea1f59)
    - [small adjustment to wvSplitKrc (#34410)](#fac4e96)
    - [[Bugfix] Enforce DeepGEMM when using sparse_attn_indexer ...](#6d4e27c)
    - [[ROCm][CI] Pin TorchCodec to v0.10.0 for ROCm compatibili...](#4c078fa)
    - [[ROCm][quantization] improve OCP weight quant parser robu...](#766e167)
    - [[Bugfix] Remove broken raw url GGUF model loading support...](#becbe24)
    - [Fix MoE for the Transformers modelling backend (#34436)](#679ca5d)
    - [[Docs] Spec decoding docs warning removal (#34439)](#334c715)
    - [[BUG] Reset running requests when clearing cache for paus...](#7b5a8b4)
#### ğŸ”´ é«˜é‡è¦åº¦å˜æ›´ (5)

### Extend ColBERT support to non-standard BERT backbones (#34170)
**SHA**: `071d863` | ğŸ”— [æŸ¥çœ‹æäº¤](https://github.com/vllm-project/vllm/commit/071d863e208b40fa1bb986ad230e322b2bbbbcf5)

**ğŸ¯ å˜æ›´ç±»å‹**ï¼šåŠŸèƒ½å¢å¼º / é‡æ„  
**âš¡ é‡è¦ç¨‹åº¦**ï¼šğŸ”´é«˜  
**ğŸ“‹ å˜æ›´æ‘˜è¦**ï¼š  
- ä¸º vLLM ä¸­çš„ ColBERT æ£€ç´¢æ¨¡å‹å¼•å…¥å¯¹éæ ‡å‡† BERT èƒŒéª¨ï¼ˆModernBERTã€Jina XLMâ€‘RoBERTaï¼‰çš„åŸç”Ÿæ”¯æŒã€‚  
- æ–°å¢ `ColBERTMixin` æŠ½è±¡å±‚ä¸ä¸‰å¥—å…·ä½“å®ç°ï¼š`ColBERTModel`ï¼ˆåŸå§‹ BERTï¼‰ã€`ColBERTModernBertModel`ã€`ColBERTJinaRobertaModel`ã€‚  
- æ›´æ–°æ–‡æ¡£ã€ç¤ºä¾‹ã€æ³¨å†Œè¡¨ã€é…ç½®æ˜ å°„ä»¥åŠå•å…ƒæµ‹è¯•ï¼Œç¡®ä¿ä¸åŒ backbone åœ¨ `--hf-overrides` æˆ– `trust-remote-code` ä¸‹å‡å¯ä½¿ç”¨ `/rerank` ä¸ `/score` æ¥å£ã€‚  

**ğŸ¯ å½±å“èŒƒå›´**ï¼š  
- `vllm/model_executor/models/colbert.py`ï¼ˆæ ¸å¿ƒå®ç°ï¼‰  
- `vllm/model_executor/models/registry.py`ã€`config.py`ï¼ˆæ¨¡å‹æ˜ å°„ï¼‰  
- `vllm/transformers_utils/config.py`ï¼ˆå¥å‘é‡ Dense æ¨¡å—è¯†åˆ«ï¼‰  
- æ–‡æ¡£ `docs/models/pooling_models.md`ã€ç¤ºä¾‹ `examples/pooling/score/colbert_rerank_online.py`  
- æµ‹è¯•ç›®å½• `tests/models/...`ã€`tests/entrypoints/...`  

**ğŸ” æŠ€æœ¯æ´å¯Ÿ**  

| ç»´åº¦ | å½±å“è¯´æ˜ |
|------|----------|
| **æ¶æ„å½±å“** | â€¢ å¼•å…¥ **Mixin** ä½¿ ColBERT çš„æŠ•å½±å±‚ã€æ± åŒ–é€»è¾‘ä¸åº•å±‚ encoder è§£è€¦ï¼Œå¤ç”¨åŒä¸€å¥—åå¤„ç†ï¼ˆ`pooler_for_token_embed`ï¼‰ã€‚<br>â€¢ ä¸‰ä¸ªæ–°æ¨¡å‹ç±»åˆ†åˆ«åŒ…è£… `BertEmbeddingModel`ã€`ModernBertModel`ã€`JinaRobertaModel`ï¼Œå®ç°ç»Ÿä¸€çš„ `embed_input_ids / forward` æ¥å£ï¼Œä¿æŒä¸ç°æœ‰ `EmbeddingModel` æ¥å£å…¼å®¹ã€‚<br>â€¢ æ³¨å†Œè¡¨ä¸ config æ˜ å°„åŒæ­¥æ›´æ–°ï¼Œæ¨¡å‹åç§° â†’ å®ç°ç±»çš„æ˜ å°„ä¸å†å±€é™äº `HF_ColBERT`ï¼Œæ”¯æŒ `ColBERTModernBertModel`ã€`ColBERTJinaRobertaModel`ã€‚ |
| **æ€§èƒ½å½±å“** | â€¢ æŠ•å½±å±‚ä½¿ç”¨ **Noâ€‘bias** çº¿æ€§å±‚ï¼Œä¿æŒåŸå§‹ ColBERT æ¨ç†æˆæœ¬ã€‚<br>â€¢ å¯¹ ModernBERT ä¸ RoBERTaâ€‘based backbonesï¼Œä»èµ° **FP16/FP32** æ¨ç†è·¯å¾„ï¼Œæœªæ–°å¢é¢å¤–è®¡ç®—å›¾ã€‚<br>â€¢ æƒé‡åŠ è½½æ—¶ï¼ŒæŠ•å½±å±‚å¯åœ¨ **lazy** åˆ›å»ºï¼ˆåœ¨é¦–æ¬¡å‡ºç° `linear.weight` æ—¶ï¼‰ï¼Œé¿å…å› æœªçŸ¥ `colbert_dim` å¯¼è‡´çš„äºŒæ¬¡åˆ†é…ã€‚<br>â€¢ æ–°å¢çš„ `try_get_dense_modules` é€šè¿‡é›†åˆåŒ¹é…å¤šç§ Dense ç±»å‹ï¼Œç•¥å¾®æå‡æ¨¡å‹å…ƒä¿¡æ¯è§£æçš„é²æ£’æ€§ï¼Œå¼€é”€å¯å¿½ç•¥ã€‚ |
| **å®‰å…¨è€ƒè™‘** | â€¢ æ”¯æŒ `--trust-remote-code`ï¼ˆJina ç¤ºä¾‹ï¼‰æ—¶ä»ä¾èµ– vLLM ç°æœ‰çš„ `remote_code` å®‰å…¨æ£€æŸ¥ï¼›æœ¬æ¬¡æ”¹åŠ¨æœªæ”¹å˜è¯¥æœºåˆ¶ã€‚<br>â€¢ æ–°å¢çš„ `hf_overrides` å‚æ•°åœ¨å†…éƒ¨ä»…ç”¨äºè¦†ç›–æ¨¡å‹é…ç½®å­—æ®µ `architectures`ï¼Œä¸æ¶‰åŠä»»æ„ä»£ç æ‰§è¡Œã€‚<br>â€¢ æƒé‡åŠ è½½è¿‡ç¨‹ä¸¥æ ¼åŒ¹é… `linear.weight` å‰ç¼€ï¼Œæœªå¼•å…¥ä»»æ„åŠ¨æ€è·¯å¾„æˆ–æ–‡ä»¶è¯»å–ï¼Œå®‰å…¨é¢ä¿æŒä¸å˜ã€‚ |
| **å¯ç»´æŠ¤æ€§** | â€¢ `ColBERTMixin` å°†å…±é€šé€»è¾‘æŠ½å–ï¼Œåç»­æ–°å¢å…¶ä»–é BERT backbone åªéœ€å®ç° `model` ä¸ `pooler`ï¼Œä¸å¿…é‡å¤æŠ•å½±å±‚ä»£ç ã€‚<br>â€¢ `load_weights` é€šè¿‡ç»Ÿä¸€çš„ `_load_colbert_weights` æ–¹æ³•åˆ†ç¦»æŠ•å½±æƒé‡ï¼Œé™ä½äº†ä¸åŒå®ç°é—´çš„å·®å¼‚ã€‚<br>â€¢ å•å…ƒæµ‹è¯•è¦†ç›– **BERTã€ModernBERTã€Jina** ä¸‰ä¸ªåç«¯çš„ tokenâ€‘embedã€scoreã€rerankã€å¼‚å¸¸ä»»åŠ¡ç­‰ï¼Œæä¾›å›å½’å®‰å…¨ç½‘ã€‚<br>â€¢ æ–‡æ¡£ä¸ç¤ºä¾‹åŒæ­¥æ›´æ–°ï¼Œé™ä½ä½¿ç”¨è€…å› ç¼ºå°‘è¯´æ˜è€Œè‡ªè¡Œ hack çš„é£é™©ã€‚ |

**âš ï¸ æ½œåœ¨é£é™©**  
1. **æ¨¡å‹å…¼å®¹æ€§**ï¼šModernBERT ä¸ Jina RoBERTa çš„ checkpoint ç»“æ„å¯èƒ½éšæœªæ¥ç‰ˆæœ¬æ›´æ”¹ï¼ˆä¾‹å¦‚ `linear.weight` åç§°æ”¹ä¸º `proj.weight`ï¼‰ï¼Œå¯¼è‡´ `_load_colbert_weights` å¤±æ•ˆã€‚  
2. **æ··åˆç²¾åº¦**ï¼šæŠ•å½±å±‚åœ¨ `dtype` ä¸º `half` æ—¶ä»ä½¿ç”¨ `torch.float16`ï¼Œè‹¥åº•å±‚æ¨¡å‹é‡‡ç”¨ **BF16** æˆ– **int8** é‡åŒ–ï¼ŒæŠ•å½±å±‚å¯èƒ½å‡ºç°ç²¾åº¦ä¸åŒ¹é…ï¼Œéœ€è¦åœ¨æœªæ¥æ˜¾å¼æ”¯æŒå¤šç§ `head_dtype`ã€‚  
3. **è¿œç¨‹ä»£ç **ï¼šç¤ºä¾‹ä¸­å¯¹ Jina æ¨¡å‹ä½¿ç”¨ `--trust-remote-code`ï¼Œè‹¥ç”¨æˆ·åœ¨ç”Ÿäº§ç¯å¢ƒè¯¯å¼€å¯è¯¥æ ‡å¿—ï¼Œä»å¯èƒ½æ‰§è¡Œç¬¬ä¸‰æ–¹ä»£ç ã€‚å»ºè®®åœ¨æ–‡æ¡£å†æ¬¡å¼ºè°ƒè¯¥é€‰é¡¹çš„å®‰å…¨è¾¹ç•Œã€‚  
4. **æƒé‡éªŒè¯**ï¼šåœ¨ `load_weights` ä¸­ï¼ŒæŠ•å½±å±‚æƒé‡è¢«æ ‡è®°ä¸ºå·²åŠ è½½ (`pooler.head.projector.weight`)ï¼›è‹¥æ¨¡å‹ checkpoint å·²ç»åŒ…å«å®Œæ•´çš„ `pooler` æƒé‡ï¼ˆæå°‘æ•°æƒ…å†µï¼‰ï¼Œå¯èƒ½å‡ºç°â€œæƒé‡é‡å¤æœªä½¿ç”¨â€è­¦å‘Šã€‚  

**ğŸ’¡ å…³æ³¨å»ºè®®**  
- **å›å½’æµ‹è¯•**ï¼šåœ¨ CI ä¸­ä¿ç•™å¯¹ `torch.float16`ã€`torch.bfloat16`ã€`torch.float32` ä¸‰ç§ dtype çš„äº¤å‰æµ‹è¯•ï¼Œé˜²æ­¢æœªæ¥é‡åŒ–è·¯å¾„å¼•å…¥éšæ€§é”™è¯¯ã€‚  
- **æ–‡æ¡£å¼ºåŒ–**ï¼šæ˜ç¡®è¯´æ˜ä½•ç§æ¨¡å‹éœ€è¦ `--hf-overrides`ï¼ˆä»…åœ¨ config ä¸­ç¼ºå¤± `architectures` æ—¶ï¼‰ï¼Œå¹¶ç»™å‡ºè‡ªåŠ¨æ£€æµ‹è„šæœ¬ç¤ºä¾‹ï¼Œä»¥é™ä½ç”¨æˆ·æ‰‹åŠ¨è¦†ç›–çš„å‡ºé”™æ¦‚ç‡ã€‚  
- **æƒé‡å…¼å®¹å±‚**ï¼šè€ƒè™‘åœ¨ `_load_colbert_weights` ä¸­åŠ å…¥å¯¹ `linear.bias`ã€`proj.weight` ç­‰åˆ«åçš„å…¼å®¹æ£€æŸ¥ï¼Œæå‡å¯¹æœªæ¥ checkpoint çš„å®¹é”™æ€§ã€‚  
- **å®‰å…¨å®¡è®¡**ï¼šå¯¹ `--trust-remote-code` çš„ä½¿ç”¨åœºæ™¯åšå®‰å…¨å®¡è®¡æŒ‡å¼•ï¼Œå»ºè®®åœ¨ç”Ÿäº§éƒ¨ç½²ä¸­é»˜è®¤å…³é—­å¹¶ä»…åœ¨å—ä¿¡ç¯å¢ƒä¸‹æ˜¾å¼å¼€å¯ã€‚  
- **ç›‘æ§æŒ‡æ ‡**ï¼šè‹¥å›¢é˜Ÿè®¡åˆ’åœ¨æœåŠ¡å±‚é¢ç›‘æ§ ColBERT è¯·æ±‚ï¼Œå»ºè®®æ–°å¢ **tokenâ€‘embed latency** ä¸ **maxsim scoring latency** ä¸¤é¡¹æŒ‡æ ‡ï¼Œä»¥æ•è·ä¸åŒ backbone å¯èƒ½çš„æ€§èƒ½å·®å¼‚ã€‚

---

### [Core] Move pause and resume functions into engine (#34125)
**SHA**: `dddbff4` | ğŸ”— [æŸ¥çœ‹æäº¤](https://github.com/vllm-project/vllm/commit/dddbff46242a9292085e2ae3309dc559f242cad6)

**ğŸ¯ å˜æ›´ç±»å‹**ï¼šåŠŸèƒ½å¢å¼º / é‡æ„ / æ¶æ„å˜æ›´  

**âš¡ é‡è¦ç¨‹åº¦**ï¼šğŸ”´é«˜  

**ğŸ“‹ å˜æ›´æ‘˜è¦**  
- å°†åŸæœ¬åˆ†æ•£åœ¨ `AsyncLLM`ã€`EngineCoreClient` ç­‰å±‚é¢çš„ **pause / resume** é€»è¾‘ç»Ÿä¸€è¿ç§»åˆ° Engine æ ¸å¿ƒï¼Œå®ç°ç»Ÿä¸€è°ƒåº¦æš‚åœ/æ¢å¤ã€‚  
- æ–°å¢ `PauseState` æšä¸¾ã€è°ƒåº¦å™¨ `pause_state` ä¸ `set_pause_state` æ¥å£ï¼Œä½¿è°ƒåº¦å™¨èƒ½å¤Ÿåœ¨ **UNPAUSED / PAUSED_NEW / PAUSED_ALL** ä¸‰ç§çŠ¶æ€é—´åˆ‡æ¢ã€‚  
- `EngineCoreProc` æ–°å¢ `pause_scheduler` / `resume_scheduler` / `is_scheduler_paused` å®ç°ï¼Œå¹¶é€šè¿‡ `per_step_hooks` åœ¨æ¯è½®è°ƒåº¦åå®Œæˆå¼‚æ­¥æ¸…ç†ã€ç¼“å­˜é‡ç½®ç­‰å·¥ä½œã€‚  
- å¯¹å¤–æä¾› `AsyncLLM.pause_generation`ã€`resume_generation`ã€`is_paused` æ–°å®ç°ï¼Œæ”¯æŒ `abort / wait / keep` ä¸‰ç§æ¨¡å¼ã€‚  
- ä¸ºæ•°æ®å¹¶è¡Œï¼ˆDPï¼‰åœºæ™¯è¡¥é½äº†ç›¸åº”çš„æµ‹è¯•ã€ç¤ºä¾‹è„šæœ¬ä»¥åŠè·¨è¿›ç¨‹ `future_echo` å®ç”¨å·¥å…·ã€‚  

**ğŸ¯ å½±å“èŒƒå›´**  
- `vllm/v1/core/sched/interface.py`ã€`vllm/v1/core/sched/scheduler.py`ï¼ˆè°ƒåº¦å™¨ï¼‰  
- `vllm/v1/engine/core.py`ã€`vllm/v1/engine/async_llm.py`ã€`vllm/v1/engine/core_client.py`ï¼ˆæ ¸å¿ƒæ‰§è¡Œä¸å®¢æˆ·ç«¯ï¼‰  
- æ•°æ®å¹¶è¡Œå­æ¨¡å— (`vllm/v1/engine/dp_*`)  
- æµ‹è¯•å¥—ä»¶ `tests/v1/engine/*`ã€`tests/v1/distributed/*`  
- ç¤ºä¾‹ `examples/online_serving/data_parallel_pause_resume.py`  

**ğŸ” æŠ€æœ¯æ´å¯Ÿ**  

- **æ¶æ„å½±å“**  
  - å¼•å…¥ç»Ÿä¸€çš„ **PauseState**ï¼Œè°ƒåº¦å™¨ä¸å†é€šè¿‡å¤–éƒ¨é”/æ¡ä»¶å˜é‡æ§åˆ¶ï¼Œè€Œæ˜¯å†…éƒ¨çŠ¶æ€æœºå†³å®šæ˜¯å¦æ¥å—æ–°è¯·æ±‚æˆ–æ‰§è¡Œè°ƒåº¦ã€‚  
  - `EngineCoreProc` é€šè¿‡ `per_step_hooks` å®ç° **å¼‚æ­¥** å®Œæˆ â€œç¼“å­˜æ¸…ç†â€‘è¿”å› Futureâ€ çš„æµç¨‹ï¼Œä¿æŒä¸»å¾ªç¯çš„éé˜»å¡ç‰¹æ€§ã€‚  
  - `AsyncLLM.pause_generation` ç°åœ¨ç›´æ¥è°ƒç”¨ `engine_core.pause_scheduler_async(mode, clear_cache)`ï¼Œæ‰€æœ‰æš‚åœé€»è¾‘é›†ä¸­åœ¨ Engine Coreï¼Œå‡å°‘äº†è·¨å±‚è°ƒç”¨çš„å¤æ‚åº¦ã€‚  
  - æ•°æ®å¹¶è¡Œåœºæ™¯çš„æš‚åœè¡Œä¸ºé€šè¿‡ **allâ€‘reduce** åŒæ­¥å®Œæˆï¼ˆæµ‹è¯•ä¸­å·²éªŒè¯ï¼‰ï¼Œä½†ä»…åœ¨ `mp` åç«¯å¯ç”¨ï¼Œä¿æŒå‘åå…¼å®¹ã€‚  

- **æ€§èƒ½å½±å“**  
  - æ­£å¸¸è¿è¡Œæ—¶ï¼Œä»…åœ¨ `Scheduler.schedule` å¼€å¤´æ£€æŸ¥ `self._pause_state`ï¼Œå¼€é”€å¯å¿½ç•¥ã€‚  
  - `per_step_hooks` åœ¨æ¯è½®è°ƒåº¦ç»“æŸåéå†ä¸€æ¬¡ç”¨æˆ·æ³¨å†Œçš„ hookï¼Œè‹¥ä¸ä½¿ç”¨è¯¥ç‰¹æ€§ï¼Œé¢å¤–å¼€é”€ä¸º **O(0)**ã€‚  
  - `clear_cache` é»˜è®¤ trueï¼Œåœ¨ **abort / wait** æ¨¡å¼ä¸‹ä¼šåœ¨æš‚åœç‚¹ä¸€æ¬¡æ€§é‡Šæ”¾ KV/Prefix ç¼“å­˜ï¼Œåç»­æ¢å¤æ—¶éœ€è¦é‡æ–°åŠ è½½ï¼Œå¯èƒ½å¯¼è‡´çŸ­æš‚çš„æ¢å¤æŠ–åŠ¨ï¼Œä½†æœ‰åŠ©äºé™ä½æ˜¾å­˜ç¢ç‰‡ã€‚  
  - â€œkeepâ€ æ¨¡å¼ä¸‹åªé˜»æ­¢æ–°è¯·æ±‚è¿›å…¥è°ƒåº¦é˜Ÿåˆ—ï¼Œå·²è¿è¡Œè¯·æ±‚ç»§ç»­æ‰§è¡Œï¼Œæ€§èƒ½åŸºæœ¬ä¸å—å½±å“ã€‚  

- **å®‰å…¨è€ƒè™‘**  
  - æš‚åœ/æ¢å¤æ¶‰åŠ **è¯·æ±‚ä¸­æ­¢ (abort)**ï¼Œå¿…é¡»ç¡®ä¿ abort è¾“å‡ºæ­£ç¡®è¿”å›ç»™å®¢æˆ·ç«¯ï¼›å®ç°ä¸­é€šè¿‡ `_send_abort_outputs` æŒ‰ clientâ€‘index åˆ†å‘ï¼Œé¿å…ä¿¡æ¯æ³„éœ²æˆ–é”™è¯¯è·¯ç”±ã€‚  
  - è¾“å…¥å‚æ•° `mode` ç»è¿‡æ˜¾å¼æ ¡éªŒï¼Œä»…æ¥å— `keep/abort/wait`ï¼Œé˜²æ­¢æ³¨å…¥éæ³•è¡Œä¸ºã€‚  
  - ç”±äºæš‚åœæœŸé—´ä¸æ¥å—æ–°è¯·æ±‚ï¼Œæ½œåœ¨çš„ **æ‹’ç»æœåŠ¡** æ”»å‡»å‘é‡å¤§å¹…ä¸‹é™ã€‚  
  - æ²¡æœ‰å¼•å…¥ç½‘ç»œæˆ–æ–‡ä»¶ç³»ç»Ÿæƒé™çš„æ›´æ”¹ï¼Œå®‰å…¨é£é™©ä¿æŒåœ¨åŸæœ‰æ°´å¹³ã€‚  

**âš ï¸ æ½œåœ¨é£é™©**  

1. **å¹¶å‘/æ­»é”é£é™©**ï¼š`per_step_hooks` å¯èƒ½åœ¨æŸäº›å¼‚å¸¸è·¯å¾„ä¸‹æœªè¢«æ¸…é™¤ï¼Œå¯¼è‡´æ— é™å¾ªç¯çš„ â€œwaitâ€‘untilâ€‘idleâ€ Hookã€‚  
2. **æ•°æ®å¹¶è¡Œå…¼å®¹æ€§**ï¼šæš‚åœé€»è¾‘å½“å‰ä»…åœ¨ `mp` åç«¯å®ç°ï¼Œè‹¥ç”¨æˆ·åˆ‡æ¢åˆ°å…¶ä»– DP åç«¯ï¼ˆå¦‚ NCCLã€Glooï¼‰ï¼Œå¯èƒ½å‡ºç°æœªå®ç°çš„ `NotImplementedError`ã€‚  
3. **ç¼“å­˜æ¸…ç†å‰¯ä½œç”¨**ï¼š`clear_cache=True` åœ¨ `abort` ä¸ `wait` æ¨¡å¼ä¸‹å¼ºåˆ¶æ¸…ç† KV/Prefixï¼Œè‹¥ç”¨æˆ·æœŸæœ›ä¿ç•™ç¼“å­˜ï¼ˆä¾‹å¦‚åœ¨å¾®è°ƒåå¿«é€Ÿç»§ç»­ç”Ÿæˆï¼‰ï¼Œéœ€è¦æ‰‹åŠ¨å…³é—­ã€‚  
4. **å®¢æˆ·ç«¯ API å˜æ›´**ï¼š`AsyncLLM.pause_generation` å‚æ•°ç­¾åå˜æ›´ï¼Œæ—§è°ƒç”¨ä¸å†æ¥å— `wait_for_inflight_requests`ï¼Œå¯èƒ½å¯¼è‡´å…¼å®¹æ€§é—®é¢˜ã€‚  
5. **æµ‹è¯•è¦†ç›–ä¸è¶³**ï¼šå½“å‰ä»…åœ¨å•æœº `mp` ç¯å¢ƒä¸‹éªŒè¯ DP æš‚åœï¼Œè·¨æœºå™¨ã€ä¸åŒ `torch` ç‰ˆæœ¬çš„è¡¨ç°å°šæœªè¦†ç›–ã€‚  

**ğŸ’¡ å…³æ³¨å»ºè®®**  

- **å›å½’æµ‹è¯•**ï¼šåœ¨ CI ä¸­åŠ å…¥éâ€‘`mp` DP åç«¯çš„å…¼å®¹æ€§æ£€æµ‹ï¼Œæˆ–åœ¨æ–‡æ¡£ä¸­æ˜ç¡®é™å®šæ”¯æŒåç«¯ã€‚  
- **Hook æ¸…ç†**ï¼šåœ¨ `EngineCoreProc._process_per_step_hooks` ä¸­åŠ å…¥è¶…æ—¶æˆ–å¼‚å¸¸æ•è·ï¼Œç¡®ä¿å¼‚å¸¸ Hook ä¸ä¼šå¯¼è‡´è°ƒåº¦å™¨æ°¸ä¹…é˜»å¡ã€‚  
- **æ–‡æ¡£ä¸è¿ç§»æŒ‡å—**ï¼šæ›´æ–°ç”¨æˆ·æ‰‹å†Œï¼Œè¯´æ˜ `pause_generation` å·²ä¸å†æ¥å— `wait_for_inflight_requests`ï¼Œå¹¶æä¾› `clear_cache=False` çš„ä½¿ç”¨åœºæ™¯ç¤ºä¾‹ã€‚  
- **æ€§èƒ½ç›‘æ§**ï¼šåœ¨ç”Ÿäº§ç¯å¢ƒå¼€å¯æŒ‡æ ‡ï¼ˆå¦‚ `engine.pause_state`ã€`engine.per_step_hooks.count`ï¼‰ä»¥ç›‘æ§å› é¢‘ç¹æš‚åœå¯¼è‡´çš„æ¢å¤æ—¶é—´æ³¢åŠ¨ã€‚  
- **å®‰å…¨å®¡è®¡**ï¼šç¡®è®¤ `abort` è¾“å‡ºçš„ `finish_reason` æ­£ç¡®æ˜ å°„ä¸º `FinishReason.ABORT`ï¼Œé˜²æ­¢å¼‚å¸¸è·¯å¾„è¿”å›é”™è¯¯çš„çŠ¶æ€ç ã€‚  

æ•´ä½“æ¥çœ‹ï¼Œæ­¤æ¬¡æ”¹åŠ¨æ˜¾è‘—æå‡äº† **æš‚åœ/æ¢å¤** åŠŸèƒ½çš„å¯ç»´æŠ¤æ€§ä¸ä¸€è‡´æ€§ï¼Œä¸ºæœªæ¥çš„æ¨¡å‹çƒ­æ›´æ–°ã€RLHF å¾ªç¯ç­‰é«˜çº§å·¥ä½œæµå¥ å®šäº†å¯é çš„åŸºç¡€ï¼Œåªè¦æ³¨æ„ä¸Šè¿°é£é™©å¹¶åšå¥½ç›¸åº”çš„æµ‹è¯•ä¸æ–‡æ¡£å·¥ä½œï¼Œå³å¯å¹³ç¨³ä¸Šçº¿ã€‚

---

### [Bugfix] Standardize getting number of image patches/tokens (#34358)
**SHA**: `372b2e7` | ğŸ”— [æŸ¥çœ‹æäº¤](https://github.com/vllm-project/vllm/commit/372b2e762aeeb040e57a690f0aa0428775a1e239)

**ğŸ¯ å˜æ›´ç±»å‹**ï¼šæ¶æ„å˜æ›´ / é‡æ„ / Bugä¿®å¤  
**âš¡ é‡è¦ç¨‹åº¦**ï¼šğŸ”´é«˜  

**ğŸ“‹ å˜æ›´æ‘˜è¦**  
æ­¤æ¬¡æäº¤å¯¹ `vllm` ä¸­æ‰€æœ‰æ¶‰åŠå¤šæ¨¡æ€ï¼ˆå›¾åƒ/è§†é¢‘ï¼‰å¤„ç†çš„æ¨¡å‹å®ç°åšäº†ç»Ÿä¸€æ”¹é€ ï¼Œæ ¸å¿ƒç›®æ ‡æ˜¯ **æ ‡å‡†åŒ–è·å–å›¾åƒ/è§†é¢‘çš„ patch æ•°é‡ä¸ token æ•°é‡çš„é€»è¾‘**ï¼š  
1. å¼•å…¥ `mm_kwargs` å‚æ•°å¹¶ç»Ÿä¸€é€šè¿‡ `self.ctx.get_merged_mm_kwargs` åˆå¹¶æ¨¡å‹å±‚é¢çš„å¤šæ¨¡æ€é…ç½®ï¼Œå–ä»£åŸæœ‰å¯¹ `processor` ä¸º `None` æ—¶è‡ªè¡Œ `self.get_hf_processor()` çš„æ•£è½é€»è¾‘ã€‚  
2. å¯¹åŸæœ‰çš„ `processor` å‚æ•°åšå‡ºæ˜ç¡®ç±»å‹çº¦æŸï¼ˆä¸å†æ¥å— `None`ï¼‰ï¼Œå¹¶åœ¨å†…éƒ¨ç»Ÿä¸€ä½¿ç”¨ `processor.image_processor`ï¼Œä»è€Œæ¶ˆé™¤ã€Œprocessor ä¸º Noneã€çš„åˆ†æ”¯ã€‚  
3. æ›´æ–°äº†å¤§é‡å•å…ƒæµ‹è¯•ï¼Œå»æ‰äº†å¯¹ç‰¹å®š transformer ç‰ˆæœ¬çš„ç¡¬ç¼–ç æ£€æŸ¥ï¼Œæ”¹ä¸ºä½¿ç”¨ `mm_kwargs` æˆ–ç‰ˆæœ¬è·³è¿‡è£…é¥°å™¨ã€‚  
4. ç›¸å…³æ¨¡å‹ï¼ˆCohere2Visionã€Ernie45VLã€Gemma3ã€Idefics3ã€Qwen ç³»åˆ—ç­‰ï¼‰åœ¨è®¡ç®— **patch æ•°**ã€**image token æ•°**ã€**è§†é¢‘ token æ•°** æ—¶å‡ä½¿ç”¨ç»Ÿä¸€çš„ `image_processor.get_number_of_image_patches` æ¥å£ï¼Œå¹¶é€šè¿‡ `mm_kwargs` æ”¯æŒç”¨æˆ·è‡ªå®šä¹‰ `size`ã€`min_pixels`ã€`max_pixels` ç­‰å‚æ•°ã€‚

---

**ğŸ¯ å½±å“èŒƒå›´**  
- `vllm/model_executor/models/*`ï¼šæ¶‰åŠæ‰€æœ‰å¤šæ¨¡æ€æ¨¡å‹å®ç°ï¼ˆCohere2Visionã€Ernie45VLã€Gemma3/3nã€H2OVLã€HunYuanVLã€Idefics3ã€InternVLã€Keyeã€LFM2VLã€Molmoã€Molmo2ã€Ovis2.5ã€PaddleOCRVLã€Phi3Vã€Phi4MMã€Pixtralã€Qwen2VLã€Qwen3VLã€SkyworkR1Vã€SmolVLM ç­‰ï¼‰ã€‚  
- `vllm/multimodal/processing/context.py`ï¼šæ–°å¢ `get_merged_mm_kwargs` å…¬å…±å·¥å…·ã€‚  
- `tests/*`ï¼šå¤§å¹…ä¿®æ”¹å¤šæ¨¡æ€ç›¸å…³å•å…ƒæµ‹è¯•ï¼Œç¡®ä¿æ–°æ¥å£è¢«è¦†ç›–å¹¶åˆ é™¤è¿‡æ—¶çš„ç‰ˆæœ¬é™åˆ¶ã€‚  

---

**ğŸ” æŠ€æœ¯æ´å¯Ÿ**  

- **æ¶æ„å½±å“**  
  - **ç»Ÿä¸€å…¥å£**ï¼šæ‰€æœ‰æ¨¡å‹ç°åœ¨é€šè¿‡ `self.ctx.get_merged_mm_kwargs` ç»Ÿä¸€è·å–å¹¶åˆå¹¶å¤šæ¨¡æ€å¤„ç†å™¨çš„ kwargsï¼Œæ¶ˆé™¤äº†å„æ¨¡å‹è‡ªè¡Œè§£æ `mm_kwargs`ã€æ‰‹åŠ¨åˆ¤æ–­ `processor is None` çš„å†—ä½™ä»£ç ã€‚  
  - **å¼ºç±»å‹åŒ–**ï¼šå‡½æ•°ç­¾åä» `processor: X | None` æ”¹ä¸º `processor: X`ï¼Œæå‡äº†ç±»å‹æ£€æŸ¥çš„å‡†ç¡®æ€§ï¼Œé˜²æ­¢åœ¨è¿è¡Œæ—¶å‡ºç° `NoneType` è°ƒç”¨é”™è¯¯ã€‚  
  - **è§£è€¦æ¨¡å‹ä¸ Processor**ï¼šæ¨¡å‹ä¸å†åœ¨å†…éƒ¨è‡ªè¡Œå®ä¾‹åŒ– `HF` processorï¼›æ‰€æœ‰å¤–éƒ¨è°ƒç”¨ï¼ˆåŒ…æ‹¬æµ‹è¯•ï¼‰éƒ½å¿…é¡»æ˜¾å¼æä¾› `processor` æˆ–é€šè¿‡ `self.get_hf_processor()` è·å¾—ï¼Œç¬¦åˆ â€œä¾èµ–å€’ç½®â€ çš„è®¾è®¡åŸåˆ™ã€‚  
  - **å¤šæ¨¡æ€é…ç½®å¯è¦†ç›–**ï¼š`mm_kwargs` é€šè¿‡ `MultimodalConfig.merge_mm_processor_kwargs` è¿›è¡Œåˆå¹¶ï¼Œä½¿å¾—ç”¨æˆ·åœ¨ `VllmConfig` ä¸­é…ç½®çš„é»˜è®¤å‚æ•°å¯ä»¥è¢«è¿è¡Œæ—¶ä¼ å…¥çš„ kwargs åŠ¨æ€è¦†ç›–ï¼Œå¢å¼ºäº†çµæ´»æ€§ã€‚

- **æ€§èƒ½å½±å“**  
  - **å¾®å°å¼€é”€**ï¼š`ctx.get_merged_mm_kwargs` åªåšä¸€æ¬¡æµ…å±‚å­—å…¸åˆå¹¶ï¼Œæˆæœ¬æä½ï¼ˆO(k)ï¼‰ï¼Œå¯¹æ•´ä½“æ¨ç†åååŸºæœ¬æ²¡æœ‰å¯æ„ŸçŸ¥å½±å“ã€‚  
  - **æ½œåœ¨æ”¶ç›Š**ï¼šç»Ÿä¸€ä½¿ç”¨ `image_processor.get_number_of_image_patches` æ›¿ä»£ä¹‹å‰è‡ªå®ç°çš„ `get_optimal_tiled_canvas` ç­‰å¤æ‚é€»è¾‘ï¼Œé™ä½äº†ä¸å¿…è¦çš„ Python è®¡ç®—è·¯å¾„ï¼Œç†è®ºä¸Šå¯ç•¥å¾®æå‡ patch è®¡æ•°çš„æ‰§è¡Œæ•ˆç‡ã€‚  
  - **ç¼“å­˜è¡Œä¸º unchanged**ï¼šåŸæœ‰çš„ `self.get_hf_processor()` ç¼“å­˜ä»ç„¶å­˜åœ¨ï¼Œæœªå› æ”¹åŠ¨å¯¼è‡´é¢å¤–å®ä¾‹åŒ–ã€‚

- **å®‰å…¨è€ƒè™‘**  
  - æœªå¼•å…¥ä»»ä½•å¤–éƒ¨ç½‘ç»œè¯·æ±‚ã€æ–‡ä»¶ I/O æˆ–åŠ¨æ€ä»£ç æ‰§è¡Œï¼Œå®‰å…¨é¢é£é™©åŸºæœ¬ä¸º **0**ã€‚  
  - å”¯ä¸€éœ€è¦å…³æ³¨çš„æ˜¯ **ç‰ˆæœ¬å…¼å®¹æ€§**ï¼šéƒ¨åˆ†æ¨¡å‹åŸæœ¬ä¾èµ–ç‰¹å®š `transformers` ç‰ˆæœ¬çš„å®ç°ç»†èŠ‚ï¼ˆå¦‚ `Cohere2Vision` çš„ `get_number_of_image_patches`ï¼‰ï¼Œç°åœ¨é€šè¿‡ç»Ÿä¸€æ¥å£ç›´æ¥è°ƒç”¨ï¼Œè‹¥ç”¨æˆ·ä½¿ç”¨çš„ `transformers` ç‰ˆæœ¬ä»ç¼ºå°‘è¯¥å®ç°ï¼Œå¯èƒ½æŠ›å‡º `AttributeError`ã€‚é¡¹ç›®å·²ç»åœ¨æµ‹è¯•å±‚é¢åŠ å…¥äº†å¯¹åº”çš„ç‰ˆæœ¬è·³è¿‡ï¼ˆe.g., Idefics3ã€SmolVLMï¼‰ï¼Œä½†è¿è¡Œæ—¶ä»éœ€æ–‡æ¡£æé†’æœ€ä½ `transformers` ç‰ˆæœ¬è¦æ±‚ã€‚

---

**âš ï¸ æ½œåœ¨é£é™©**  

| é£é™©ç‚¹ | è¯´æ˜ | ä¸¥é‡ç¨‹åº¦ | ç¼“è§£æªæ–½ |
|--------|------|----------|----------|
| **API ç ´å** | å¤šæ•°æ¨¡å‹çš„æ–¹æ³•ç­¾åä»å¯é€‰ `processor=None` æ”¹ä¸ºå¿…å¡« `processor`ï¼Œå¯¹å¤–éƒ¨ä½¿ç”¨è€…ï¼ˆè‡ªå®šä¹‰åŠ è½½å™¨ã€ç¬¬ä¸‰æ–¹é›†æˆï¼‰å¯èƒ½å¯¼è‡´ `TypeError`ã€‚ | é«˜ | 1) åœ¨ `ModelExecutor` åŒ…è£…å±‚ä¿æŒå‘åå…¼å®¹çš„é€‚é…å™¨ï¼ˆå†…éƒ¨å°† `None` è½¬ä¸º `self.get_hf_processor()`ï¼‰ã€‚2) åœ¨ Release Notes ä¸­æ˜ç¡®æ ‡æ³¨æ­¤ API å˜æ›´å¹¶æä¾›è¿ç§»ç¤ºä¾‹ã€‚ |
| **transformers ç‰ˆæœ¬ä¾èµ–** | ç»Ÿä¸€è°ƒç”¨ `image_processor.get_number_of_image_patches`ï¼Œä½†è¯¥æ–¹æ³•åœ¨æ—§ç‰ˆ `transformers` å¯èƒ½ä¸å­˜åœ¨æˆ–è¡Œä¸ºä¸ä¸€è‡´ã€‚ | ä¸­ | åœ¨æ–‡æ¡£ä¸­å£°æ˜æœ€ä½æ”¯æŒçš„ `transformers` ç‰ˆæœ¬ï¼ˆå¦‚ `>=4.57`ï¼‰ï¼Œå¹¶åœ¨åˆå§‹åŒ–æ—¶åŠ å…¥ç‰ˆæœ¬æ ¡éªŒè­¦å‘Šã€‚ |
| **mm_kwargs åˆå¹¶é€»è¾‘é”™è¯¯** | è‹¥ç”¨æˆ·æä¾›çš„ `mm_kwargs` ä¸æ¨¡å‹é»˜è®¤é…ç½®å†²çªï¼Œå¯èƒ½å¯¼è‡´æ„å¤–çš„ `size/min_pixels` ç­‰å‚æ•°è¢«è¦†ç›–ã€‚ | ä¸­ | åœ¨ `MultimodalConfig.merge_mm_processor_kwargs` ä¸­åŠ å…¥å†²çªæ£€æµ‹æˆ–æ—¥å¿—æç¤ºï¼›å•å…ƒæµ‹è¯•è¦†ç›–å¸¸è§è¦†ç›–åœºæ™¯ã€‚ |
| **é—æ¼è°ƒç”¨æ–¹æ›´æ–°** | ä»£ç åº“å†…éƒ¨å·²æœ‰å¤§é‡è°ƒç”¨ `get_num_image_tokens`ã€`_get_vision_info` ç­‰ç§æœ‰æ–¹æ³•ï¼Œè‹¥æœ‰é—æ¼æœªä¼ é€’ `mm_kwargs`ï¼Œå¯èƒ½å¯¼è‡´è¿è¡Œæ—¶æŠ¥é”™ã€‚ | ä¸­ | CI å·²ç»æ‰©å¤§äº†æµ‹è¯•è¦†ç›–ï¼ˆåŒ…æ‹¬å¤šæ¨¡å‹ã€å¤šé…ç½®ï¼‰ï¼Œä½†å»ºè®®åœ¨ CI ä¸­åŠ å…¥ **typeâ€‘checking**ï¼ˆmypyï¼‰ä¸ **runtime å‚æ•°æ ¡éªŒ**ï¼ˆ`inspect.signature`ï¼‰çš„æ£€æŸ¥ã€‚ |
| **æ€§èƒ½å¾®å¢** | æ¯æ¬¡è°ƒç”¨éƒ½ä¼šåšä¸€æ¬¡ kwargs åˆå¹¶ï¼Œæç«¯é«˜é¢‘è°ƒç”¨ï¼ˆå¦‚å¤§è§„æ¨¡æ‰¹æ¬¡ï¼‰å¯èƒ½ç´¯ç§¯å¾®å° CPU å¼€é”€ã€‚ | ä½ | å¦‚éœ€æè‡´æ€§èƒ½ï¼Œå¯åœ¨å†…éƒ¨å®ç°ä¸€æ¬¡æ€§ç¼“å­˜åˆå¹¶ç»“æœï¼ˆLRU cacheï¼‰æˆ–åœ¨ `ModelExecutor` å±‚æå‰åˆå¹¶ã€‚ |

---

**ğŸ’¡ å…³æ³¨å»ºè®®**  

1. **æ–‡æ¡£ä¸å‘å¸ƒè¯´æ˜**  
   - åœ¨ `README`ã€æ¨¡å‹é…ç½®è¯´æ˜ä»¥åŠ API æ–‡æ¡£ä¸­åŠ å…¥â€œ`mm_kwargs` ç»Ÿä¸€åˆå¹¶â€ç« èŠ‚ï¼Œåˆ—å‡ºå¸¸ç”¨å¯è¦†ç›–çš„é”®ï¼ˆ`size`, `min_pixels`, `max_pixels`, `do_pan_and_scan` ç­‰ï¼‰ã€‚  
   - æ˜ç¡®æœ€ä½ `transformers` ç‰ˆæœ¬è¦æ±‚ï¼ˆå¤šæ•°æ¨¡å‹å·²ä¾èµ– `>=4.57`ï¼Œéƒ¨åˆ†æ¨¡å‹éœ€è¦ `>=5.2.0`ï¼‰ï¼Œå¹¶åœ¨ `setup.py`/`pyproject.toml` ä¸­æ·»åŠ å¯¹åº”çš„ `install_requires` æ¡ä»¶ã€‚  

2. **å‘åå…¼å®¹å±‚**  
   - è€ƒè™‘åœ¨æ¯ä¸ªæ¨¡å‹åŸºç±»æˆ– `ModelExecutor` ä¸­å®ç°ä¸€ä¸ªåŒ…è£…å‡½æ•° `def _ensure_processor(self, processor)`ï¼Œå½“ `processor is None` æ—¶è‡ªåŠ¨è°ƒç”¨ `self.get_hf_processor()`ï¼Œå¹¶è®°å½•ä¸€æ¬¡ **DeprecationWarning**ã€‚è¿™æ ·å¯ä»¥åœ¨ä¸ç ´åè€ä»£ç çš„å‰æä¸‹å¹³æ»‘è¿ç§»ã€‚  

3. **æ›´ä¸¥æ ¼çš„å•å…ƒæµ‹è¯•**  
   - ä¸º `MultimodalConfig.merge_mm_processor_kwargs` å¢åŠ  **å†²çªæ£€æµ‹** æµ‹è¯•ï¼šç¡®ä¿ç”¨æˆ·è‡ªå®šä¹‰ `size`

---

### [Kernel] [Helion] [4/N] Add silu_mul_fp8 Helion kernel  (#33373)
**SHA**: `96161fe` | ğŸ”— [æŸ¥çœ‹æäº¤](https://github.com/vllm-project/vllm/commit/96161fe9785814bf1adcce49dfd3c47863a2ecac)

**ğŸ¯ å˜æ›´ç±»å‹**ï¼šåŠŸèƒ½å¢å¼º / æ€§èƒ½ä¼˜åŒ–  
**âš¡ é‡è¦ç¨‹åº¦**ï¼šğŸ”´é«˜  
**ğŸ“‹ å˜æ›´æ‘˜è¦**ï¼š  
1. ä¸º Helion åç«¯æ–°å¢ `silu_mul_fp8` ç®—å­ï¼Œå®ç° SiLUâ€¯+â€¯ä¹˜æ³•å¹¶åœ¨ FP8 (e4m3fn) é‡åŒ–è¾“å‡ºï¼Œé…å¥—è‡ªåŠ¨æ³¨å†Œã€é…ç½®é€‰æ‹©ä¸åŸºå‡†å®ç°ã€‚  
2. å¼•å…¥ä¸€å¥—å®Œæ•´çš„å•å…ƒæµ‹è¯•ï¼Œè¦†ç›–é…ç½®æŒ‘é€‰ã€æ•°å€¼æ­£ç¡®æ€§ã€å½¢çŠ¶æ¨æ–­ã€å¤šç»´è¾“å…¥ä»¥åŠä¸ PyTorch å‚è€ƒå®ç°çš„å¯¹æ¯”ã€‚  
3. æ–°å¢ Helium op è‡ªåŠ¨å¯¼å…¥æœºåˆ¶ã€å¹³å°/é…ç½® JSON æè¿°æ–‡ä»¶ä»¥åŠå¯¹ kernel æ³¨å†Œè¡¨çš„å®‰å…¨æ¸…ç†/æ¢å¤é€»è¾‘ã€‚  

**ğŸ¯ å½±å“èŒƒå›´**ï¼š  
- `vllm/kernels/helion/ops/silu_mul_fp8.py`ï¼ˆæ ¸å¿ƒç®—å­å®ç°ï¼‰  
- `vllm/kernels/helion/register.py`ï¼ˆæ³¨å†Œè¡¨ï¼‰  
- `vllm/kernels/helion/__init__.py`ï¼ˆè‡ªåŠ¨å¯¼å…¥æ‰€æœ‰ Helion opsï¼‰  
- `vllm/kernels/helion/config_manager.py`ï¼ˆå»é™¤å†—ä½™ `json` å¯¼å…¥ï¼‰  
- æ–°å¢æµ‹è¯•æ–‡ä»¶ `tests/kernels/helion/*`ï¼ˆéªŒè¯ç®—å­åŠŸèƒ½ï¼‰  
- æ–°å¢é…ç½®æ–‡ä»¶ `vllm/kernels/helion/configs/silu_mul_fp8.json`ï¼ˆGPUâ€‘å¹³å°â€‘é…ç½®æ˜ å°„ï¼‰  

---

### ğŸ” æŠ€æœ¯æ´å¯Ÿ  

| ç»´åº¦ | å½±å“åˆ†æ |
|------|----------|
| **æ¶æ„å½±å“** | - å¼•å…¥ **Helion ops åŒ…**ï¼ˆ`vllm/kernels/helion/ops/__init__.py`ï¼‰å®ç° *importâ€‘sideâ€‘effect* æ³¨å†Œï¼Œä¿è¯ `torch.ops.vllm_helion` åœ¨é¦–æ¬¡å¯¼å…¥æ—¶å³å®Œæ•´åŠ è½½ã€‚<br>- `silu_mul_fp8` é‡‡ç”¨ **Helion DSL** (`hl.tile`, `hl.specialize`, `hl.load`) ç¼–å†™ï¼Œä¿æŒä¸ç°æœ‰ Helion kernel æ¡†æ¶ä¸€è‡´ã€‚<br>- `ConfigManager` é€šè¿‡ JSON é…ç½®æ–‡ä»¶æä¾›å¹³å°â€‘ç‰¹åŒ–è°ƒåº¦å‚æ•°ï¼Œæå‡è·¨ GPUï¼ˆH100/H200ï¼‰é€‚é…èƒ½åŠ›ã€‚<br>- å¯¹ kernel æ³¨å†Œè¡¨çš„ **saveâ€‘clearâ€‘restore**ï¼ˆåœ¨ `TestKernelRegistry` ä¸­å®ç°ï¼‰é˜²æ­¢ test ä¹‹é—´çš„å‰¯ä½œç”¨ï¼Œæå‡æµ‹è¯•å¯é æ€§ã€‚ |
| **æ€§èƒ½å½±å“** | - FP8 é‡åŒ–æ˜¾è‘—é™ä½æ˜¾å­˜å ç”¨ï¼ˆçº¦ 1/4ï¼‰ï¼Œå¹¶åˆ©ç”¨ **Helion ç¼–è¯‘å™¨** ç”Ÿæˆçš„é«˜æ•ˆ CUDA å†…æ ¸ï¼Œé¢„æœŸåœ¨å¤§å‹æ¨¡å‹çš„ `SiluAndMul` é˜¶æ®µæå‡ **å¸¦å®½åˆ©ç”¨ç‡** ä¸ **åå**ã€‚<br>- é€šè¿‡ `pick_silu_mul_fp8_config` è‡ªåŠ¨æŒ‘é€‰æœ€åŒ¹é…çš„ Tile é…ç½®ï¼Œå¯åœ¨ä¸åŒ `intermediate_size`ã€`batchsize` åœºæ™¯ä¸‹è·å¾—æ¥è¿‘æ‰‹å·¥è°ƒä¼˜çš„æ€§èƒ½ã€‚<br>- åŸºå‡†å®ç° `silu_mul_fp8_baseline` ä»ä¿ç•™ï¼Œä»¥å…¼å®¹æœªè£… Helion çš„ç¯å¢ƒï¼Œä¿è¯åŠŸèƒ½å›é€€ã€‚ |
| **å®‰å…¨è€ƒè™‘** | - æ–°å¢çš„ä¾èµ– `helion` ä»…åœ¨ **å¯é€‰** ç¯å¢ƒä¸­åŠ è½½ï¼Œé˜²æ­¢åœ¨æœªå®‰è£… Helion çš„æœºå™¨ä¸Šäº§ç”Ÿ ImportErrorï¼ˆå·²é€šè¿‡ `has_helion()` æ£€æŸ¥å¹¶åœ¨æµ‹è¯•å±‚é¢ `skip`ï¼‰ã€‚<br>- ç®—å­å†…éƒ¨æ²¡æœ‰å¤–éƒ¨ I/Oã€æ–‡ä»¶å†™å…¥æˆ–ç½‘ç»œè°ƒç”¨ï¼Œå®‰å…¨é£é™©æä½ã€‚<br>- `scale` è¢«å¼ºåˆ¶è¦æ±‚æ˜¯ **æ ‡é‡ Tensor**ï¼Œé˜²æ­¢æ„å¤–çš„å¹¿æ’­æˆ–è¾“å…¥ç¯¡æ”¹ã€‚ |
| **å¯ç»´æŠ¤æ€§** | - è‡ªåŠ¨å¯¼å…¥æ‰€æœ‰å­æ¨¡å—çš„å®ç°æ–¹å¼ç®€æ´ï¼Œä½†ä¾èµ– `pkgutil.iter_modules`ï¼Œåœ¨æ‰“åŒ…æˆ– Cython ç¼–è¯‘åå¯èƒ½äº§ç”Ÿ **æ¨¡å—å‘ç°å¤±æ•ˆ**ï¼Œéœ€åœ¨ CI ä¸­éªŒè¯ã€‚<br>- é…ç½® JSON é‡‡ç”¨ç»Ÿä¸€ç»“æ„ï¼Œä¾¿äºåç»­ä¸ºæ–° GPUï¼ˆå¦‚ H800ï¼‰æ·»åŠ é…ç½®ã€‚<br>- æµ‹è¯•è¦†ç›–ç»†è‡´ï¼ŒåŒ…å«ä¸åŒç»´åº¦ã€ä¸åŒ `dtype`ã€ä¸åŒ `scale`ï¼Œä¸ºåæœŸå›å½’æä¾›å¯é åŸºçº¿ã€‚ |
| **å…¼å®¹æ€§** | - ä»…åœ¨æ”¯æŒ CUDA çš„ç¯å¢ƒä¸‹è¿è¡Œï¼›è‹¥ CUDA ä¸å¯ç”¨æˆ–å¹³å°ä¸åœ¨é…ç½®è¡¨ä¸­ï¼Œç®—å­ä¼šè¢« **skip**ï¼Œä¸å½±å“ä¸»åº“åŠŸèƒ½ã€‚<br>- å¯¹ `torch.float8_e4m3fn` çš„ä½¿ç”¨é™åˆ¶åœ¨ PyTorchâ€¯â‰¥â€¯2.1ï¼ˆå·²åœ¨ vLLM ä¸»çº¿ä¸­å£°æ˜ï¼‰ï¼Œå› æ­¤åœ¨æ—§ç‰ˆ PyTorch ä¸Šä»ä¼šå›é€€åˆ° baselineã€‚ |

---

### âš ï¸ æ½œåœ¨é£é™©  

1. **æ³¨å†Œè¡¨å…¨å±€çŠ¶æ€æ³„æ¼**  
   - åœ¨æµ‹è¯•å¤–éƒ¨ä½¿ç”¨ `vllm.kernels.helion.register._REGISTERED_KERNELS` æ—¶ï¼Œè‹¥å¿˜è®°æ¢å¤åŸå§‹çŠ¶æ€ï¼Œå¯èƒ½å¯¼è‡´åç»­æµ‹è¯•æˆ–è¿è¡Œæ—¶å‡ºç° **é‡å¤æ³¨å†Œ** æˆ– **è¦†ç›–** çš„æƒ…å½¢ã€‚  
2. **Helion ç‰ˆæœ¬å…¼å®¹**  
   - Helion ç¼–è¯‘å™¨æˆ–è¿è¡Œæ—¶ APIï¼ˆå¦‚ `hl.tile`ã€`hl.load`ï¼‰è‹¥åœ¨æ–°ç‰ˆæœ¬ä¸­å˜æ›´ï¼Œå½“å‰å®ç°å¯èƒ½å¤±æ•ˆã€‚éœ€åœ¨ `requirements` ä¸­é”å®šå…¼å®¹ç‰ˆæœ¬æˆ–åŠ  CI æ£€æŸ¥ã€‚  
3. **å¹³å°æ£€æµ‹è¯¯åˆ¤**  
   - `get_canonical_gpu_name()` ä¾èµ– NVIDIA é©±åŠ¨è¿”å›çš„å­—ç¬¦ä¸²ï¼Œè‹¥å‡ºç°æ–°å‹å·æœªæ”¶å½•åœ¨ JSON ä¸­ï¼Œç®—å­ä¼šè¢« skipï¼Œå¯¼è‡´åŠŸèƒ½ç¼ºå¤±ã€‚  
4. **è‡ªåŠ¨æ¨¡å—å¯¼å…¥çš„å‰¯ä½œç”¨**  
   - `pkgutil.iter_modules` ä¼šéå†æ‰€æœ‰å­åŒ…ï¼Œä»»ä½•åœ¨å¯¼å…¥é˜¶æ®µæŠ›å¼‚å¸¸çš„æ¨¡å—éƒ½ä¼šé˜»æ­¢åç»­æ¨¡å—åŠ è½½ï¼Œè¿›è€Œå¯¼è‡´ **éƒ¨åˆ† kernel æœªæ³¨å†Œ**ã€‚  
5. **FP8 é‡åŒ–è¯¯å·®**  
   - è™½ç„¶æµ‹è¯•é‡‡ç”¨å®½å®¹çš„ `atol/rtol=0.05`ï¼Œåœ¨å®é™…æ¨ç†ä»»åŠ¡ä¸­æç«¯æ•°å€¼å¯èƒ½å¯¼è‡´ **æ•°å€¼æ¼‚ç§»**ï¼Œç‰¹åˆ«æ˜¯å¯¹éœ€è¦é«˜ç²¾åº¦çš„åå¤„ç†é˜¶æ®µã€‚  

---

### ğŸ’¡ å…³æ³¨å»ºè®®  

| å»ºè®®å¯¹è±¡ | å…·ä½“æªæ–½ |
|----------|----------|
| **å¼€å‘è€…** | - å°† `helion` ä¾èµ–æ˜¾å¼æ ‡è®°ä¸º **optional**ï¼Œåœ¨ `setup.cfg` / `pyproject.toml` ä¸­ä½¿ç”¨ `extras_require["helion"]`ï¼Œå¹¶åœ¨æ–‡æ¡£æ˜ç¡®è¯´æ˜å®‰è£…æ–¹å¼ã€‚<br>- ä¸º `silu_mul_fp8` æ·»åŠ  **ç‰ˆæœ¬å…¼å®¹æ£€æŸ¥**ï¼ˆä¾‹å¦‚ `assert hasattr(hl, "tile")`ï¼‰ï¼Œåœ¨ä¸å…¼å®¹æ—¶ç»™å‡ºæ¸…æ™°é”™è¯¯ä¿¡æ¯ã€‚ |
| **CI / æµ‹è¯•** | - åœ¨ CI ä¸­åŠ å…¥ **GPUâ€‘matrix** æµ‹è¯•ï¼šç¡®ä¿è‡³å°‘ä¸€æ¬¡åœ¨ H100ã€H200 ä¸Šè·‘é€šé…ç½®æ–‡ä»¶è·¯å¾„ã€‚<br>- å¢åŠ å¯¹ `pkgutil.iter_modules` å¯èƒ½æŠ›å¼‚å¸¸çš„æ•è·ï¼Œç¡®ä¿å³ä½¿æŸå­æ¨¡å—åŠ è½½å¤±è´¥ä¹Ÿä¸ä¼šå½±å“æ•´ä½“æ³¨å†Œã€‚ |
| **è¿è¥ / éƒ¨ç½²** | - åœ¨ç”Ÿäº§éƒ¨ç½²å‰æ£€æµ‹ `torch.cuda.is_available()` ä¸ `has_helion()`ï¼Œè‹¥ç¼ºå¤±åˆ™è‡ªåŠ¨å›é€€åˆ° `silu_mul_fp8_baseline`ï¼Œé˜²æ­¢è¿è¡Œæ—¶å´©æºƒã€‚ |
| **æ–‡æ¡£** | - æ›´æ–° *Helion* ç« èŠ‚ï¼Œè¯´æ˜ **å¹³å°æ”¯æŒè¡¨**ã€**é…ç½®æ–‡ä»¶ç»“æ„**ã€**å¦‚ä½•è‡ªè¡Œæ·»åŠ æ–°å¹³å°**ã€‚<br>- ç»™å‡º **æ•°å€¼è¯¯å·®å®¹å¿** çš„ä½¿ç”¨æŒ‡å—ï¼Œæé†’ç”¨æˆ·åœ¨å¯¹æ•°å€¼æ•æ„Ÿçš„ downstream ä»»åŠ¡ä¸­é‡‡ç”¨åå¤„ç†æˆ–æ›´é«˜ç²¾åº¦çš„ fallbackã€‚ |
| **åç»­ä¼˜åŒ–** | - è€ƒè™‘åœ¨ `pick_silu_mul_fp8_config` ä¸­åŠ å…¥ **batchsize** ç»´åº¦çš„åŠ¨æ€åŒ¹é…ï¼Œè¿›ä¸€æ­¥æå‡å¯¹é 256â€‘batchsize åœºæ™¯çš„æ€§èƒ½ã€‚<br>- æ¢ç´¢ **FP8 å­ç±»å‹**ï¼ˆe4m3fnuzã€e5m2ï¼‰æ”¯æŒï¼Œä»¥å…¼å®¹æ›´å¤šç¡¬ä»¶çš„é‡åŒ–éœ€æ±‚ã€‚ |

--- 

**æ€»ä½“ç»“è®º**ï¼šæ­¤æäº¤ä¸º vLLM å¼•å…¥äº†åŸºäº Helion çš„ FP8 SiLUâ€¯Ã—â€¯Mul åŠ é€Ÿç®—å­ï¼Œå…·å¤‡æ˜¾è‘—çš„æ˜¾å­˜ä¸è®¡ç®—æ•ˆç‡æå‡ï¼ŒåŒæ—¶é€šè¿‡é…ç½®é©±åŠ¨ä¸è‡ªåŠ¨æ³¨å†Œæœºåˆ¶ä¿è¯è·¨ GPU çš„é€‚é…æ€§ã€‚é£é™©ä¸»è¦é›†ä¸­åœ¨å…¨å±€æ³¨å†Œè¡¨ç®¡ç†ã€Helion ç‰ˆæœ¬å…¼å®¹ä»¥åŠå¹³å°æ£€æµ‹ä¸Šï¼Œå»ºè®®åœ¨ CI ä¸­å¼ºåŒ–å¤š GPU

---

### [Attention] Add FlashInfer Sparse MLA backend (#33451)
**SHA**: `f2c4788` | ğŸ”— [æŸ¥çœ‹æäº¤](https://github.com/vllm-project/vllm/commit/f2c47886fdbabfeae7ddad871ee7889ee472d026)

**ğŸ¯ å˜æ›´ç±»å‹**ï¼šåŠŸèƒ½å¢å¼º / æ¶æ„å˜æ›´ / æ€§èƒ½ä¼˜åŒ–  
**âš¡ é‡è¦ç¨‹åº¦**ï¼šğŸ”´é«˜  

**ğŸ“‹ å˜æ›´æ‘˜è¦**  
1. åœ¨ vLLM ä¸­æ–°å¢ **FlashInferâ€¯MLAâ€¯Sparse** æ³¨æ„åŠ›åç«¯ï¼Œå®ç°åŸºäºç´¢å¼•çš„ç¨€ç– MLAï¼ˆ`FLASHINFER_MLA_SPARSE`ï¼‰ï¼Œå¹¶åœ¨åç«¯æ³¨å†Œè¡¨ã€é€‰æ‹©å™¨ã€å¹³å°å±‚åšå…¨é“¾è·¯é›†æˆã€‚  
2. ä¸ºç¨€ç–åç«¯æä¾›å®Œæ•´çš„ **Metadataã€MetadataBuilderã€Impl** å®ç°ï¼Œæ–°å¢ Tritonâ€‘kernel ç”¨äºå°†è¯·æ±‚â€‘ç´¢å¼•æ˜ å°„ä¸ºå…¨å±€ç¼“å­˜æ§½ä½å¹¶åœ¨åŒä¸€æ¬¡ kernel ä¸­ç»Ÿè®¡æœ‰æ•ˆç´¢å¼•æ•°ã€‚  
3. å¤§å¹…æ›´æ–°åŸºå‡†å¥—ä»¶ã€æ–‡æ¡£ã€é…ç½®æ–‡ä»¶ä»¥åŠæµ‹è¯•ï¼Œä»¥æ”¯æŒç¨€ç–åç«¯çš„æ€§èƒ½è¯„ä¼°å’Œæ­£ç¡®æ€§éªŒè¯ã€‚  

**ğŸ¯ å½±å“èŒƒå›´**  
- `vllm/v1/attention/backends/mla/*`ï¼ˆFlashInferâ€¯MLAâ€¯Sparseã€FlashMLAâ€¯Sparseã€å…¬å…±å·¥å…·ï¼‰  
- `vllm/v1/attention/backends/registry.py`ã€`selector.py`ã€`platforms/*`ï¼ˆåç«¯æšä¸¾ã€ä¼˜å…ˆçº§è°ƒåº¦ã€é…ç½®æ£€æŸ¥ï¼‰  
- `benchmarks/attention_benchmarks/*`ï¼ˆbenchmark runnerã€é…ç½®æ–‡ä»¶ã€æ’åºå‡½æ•°ï¼‰  
- `docs/design/attention_backends.md`ï¼ˆåç«¯æ–‡æ¡£ï¼‰  
- å•å…ƒæµ‹è¯• `tests/v1/attention/test_sparse_mla_backends.py`  
- ä»£ç ç”Ÿæˆå·¥å…· `tools/pre_commit/generate_attention_backend_docs.py`  

---

### ğŸ” æŠ€æœ¯æ´å¯Ÿ

| ç»´åº¦ | å½±å“åˆ†æ |
|------|----------|
| **æ¶æ„å½±å“** | â€¢ æ–°å¢ **AttentionBackend** å­ç±» `FlashInferMLASparseBackend`ï¼Œå®ç° `is_sparse=True`ã€`supports_compute_capability` åªåœ¨ SMâ€¯10 (Blackwell) å¯ç”¨ã€‚<br>â€¢ åœ¨ `AttentionBackendEnum` ä¸­åŠ å…¥ `FLASHINFER_MLA_SPARSE`ï¼Œå¹¶åœ¨å¹³å°å±‚ (`cuda._get_backend_priorities`) æ ¹æ® `num_heads` åŠ¨æ€è°ƒæ•´ç¨€ç–åç«¯çš„ä¼˜å…ˆé¡ºåºï¼ˆä½ headâ€‘count æ—¶ä¼˜å…ˆä½¿ç”¨ FlashInferâ€¯Sparseï¼‰ã€‚<br>â€¢ `MLA` é…ç½®æµç¨‹æ”¹ä¸ºåœ¨ `VllmConfig` ä¸­å¯é€‰ `index_topk`ï¼Œå¹¶å¼ºåˆ¶ KVâ€‘cache block size ä¸º 64â€¯Bï¼ˆSparseâ€¯FlashMLAï¼‰æˆ– 64â€¯B/32â€¯Bï¼ˆSparseâ€¯FlashInferï¼‰ã€‚<br>â€¢ ä¸ºç¨€ç–åç«¯æ–°å¢ `SparseMLAAttentionImpl` æŠ½è±¡ï¼Œå®ç° `forward_mqa`ï¼ˆç¨€ç–è§£ç ï¼‰ä»¥åŠå¯¹ `Indexer.topk_indices_buffer` çš„ä¾èµ–ã€‚ |
| **æ€§èƒ½å½±å“** | â€¢ ç¨€ç–åç«¯é€šè¿‡ **topâ€‘k** ç´¢å¼•åªè®¿é—®å°‘é‡ KVâ€‘slotï¼Œç†è®ºä¸Šæ˜¾è‘—é™ä½æ˜¾å­˜å¸¦å®½å’Œç®—åŠ›å ç”¨ï¼Œç‰¹åˆ«åœ¨å¤§â€‘contextï¼ˆ>16kï¼‰åœºæ™¯ã€‚<br>â€¢ `triton_convert_req_index_to_global_index` åœ¨åŒä¸€æ¬¡ kernel ä¸­å®Œæˆ **å…¨å±€æ˜ å°„ + æœ‰æ•ˆè®¡æ•°**ï¼Œé¿å…ä¸¤è½®éå†ï¼Œæå‡é¢„å¤„ç†ååã€‚<br>â€¢ `FlashInferMLASparseImpl.forward_mqa` å¤ç”¨ FlashInfer TRTâ€‘LLM MLA kernelï¼Œä¿æŒé«˜å ç”¨ç‡ï¼›ä½†é¢å¤–çš„ `topk_indices_buffer` æ‹·è´å’Œä¸€æ¬¡åŸå­ç´¯åŠ è®¡æ•°åœ¨æç«¯å¤§ topâ€‘kï¼ˆ2048ï¼‰æ—¶ä¼šæœ‰å°‘é‡å¼€é”€ã€‚<br>â€¢ å¯¹ `num_heads â‰¤â€¯16` åœºæ™¯ä¼˜å…ˆä½¿ç”¨ FlashInferâ€¯Sparseï¼Œå¯é¿å… FlashMLA ç¨ å¯†å®ç°çš„ padding å¼€é”€ã€‚ |
| **å®‰å…¨/å¯é æ€§** | â€¢ æ–°å¢çš„ Triton kernel ä½¿ç”¨ **åŸå­åŠ ** æ¥ç»Ÿè®¡æœ‰æ•ˆç´¢å¼•ï¼Œå¿…é¡»ä¿è¯ `valid_counts` åˆå§‹ä¸º **0**ï¼ˆå·²åœ¨å®ç°ä¸­æ˜¾å¼ zeroâ€‘fillï¼‰ï¼Œå¦åˆ™ä¼šäº§ç”Ÿè®¡æ•°é”™è¯¯ã€‚<br>â€¢ `index_topk` å¿…é¡»ç”±æ¨¡å‹é…ç½®æä¾›ï¼›è‹¥ç¼ºå¤±å½“å‰å®ç°ä¼šåœ¨ `supports_combination` è¿”å›é”™è¯¯ä¿¡æ¯ï¼Œé¿å…åœ¨ä¸æ”¯æŒçš„æ¨¡å‹ä¸Šå´©æºƒã€‚<br>â€¢ å¯¹ CUDA è®¾å¤‡èƒ½åŠ›çš„ç¡¬æ€§æ£€æŸ¥ (`major == 10`) é˜²æ­¢åœ¨ä¸æ”¯æŒçš„æ˜¾å¡ä¸ŠåŠ è½½å¯¼è‡´ kernel launch é”™è¯¯ã€‚<br>â€¢ å…¨å±€å·¥ä½œç©ºé—´ `_fi_sparse_workspace` ä¸º **å•ä¾‹**ï¼Œåœ¨å¤šè¿›ç¨‹/å¤šçº¿ç¨‹ç¯å¢ƒä¸‹å…±ç”¨åŒä¸€å¼ æ˜¾å­˜ï¼Œç†è®ºä¸Šä¸ä¼šäº§ç”Ÿç«äº‰ï¼ˆåªè¯»ï¼‰ï¼Œä½†è‹¥åœ¨åŒä¸€è¿›ç¨‹ä¸­å¹¶å‘åˆ›å»ºå¤šä¸ªå®ç°å®ä¾‹ï¼Œéœ€ç¡®ä¿ä¸ä¼šåŒæ—¶ä¿®æ”¹ã€‚ |
| **å¯ç»´æŠ¤æ€§** | â€¢ ç¨€ç–åç«¯é€»è¾‘ä¸å·²æœ‰ç¨ å¯†å®ç°ä¿æŒç›¸åŒçš„ **Metadata/Builder/Impl** æŠ½è±¡å±‚ï¼Œä¾¿äºåç»­ç»Ÿä¸€ç»´æŠ¤ã€‚<br>â€¢ æ–°å¢çš„å·¥å…·å‡½æ•° `batch_spec_sort_key` ä¸æ’åºè°ƒç”¨ç»Ÿä¸€åœ¨ benchmark ä»£ç ä¸­ä½¿ç”¨ï¼Œæå‡å¯è¯»æ€§ã€‚<br>â€¢ æ–‡æ¡£ã€é…ç½®æ–‡ä»¶ã€ä»£ç ç”Ÿæˆè„šæœ¬åŒæ­¥æ›´æ–°ï¼Œé™ä½ç”¨æˆ·ä½¿ç”¨æ—¶çš„æ–‡æ¡£/å®ç°ä¸ä¸€è‡´é£é™©ã€‚<br>â€¢ ä»£ç ä¸­ä»ä¿ç•™ä¸€äº› **æ—§åç«¯å°å†™å­—ç¬¦ä¸²**ï¼ˆå¦‚ benchmark é…ç½®ä»ä½¿ç”¨ `cutlass_mla`ï¼‰ï¼Œå¯èƒ½åœ¨æœªæ¥è¢«é—å¼ƒï¼Œéœ€è¦æ¸…ç†æˆ–åŠ å…¥åˆ«åæ˜ å°„ã€‚ |
| **å…¼å®¹æ€§** | â€¢ ä»…åœ¨ **SMâ€¯10** åŠä»¥ä¸Šæ˜¾å¡ä¸Šå¯ç”¨ï¼Œæ—©æœŸ Ampere/Hopper ä»é€šè¿‡ç¨ å¯† `FLASHMLA_SPARSE`ï¼ˆBF16ï¼‰æˆ– `FLASHMLA`/`CUTLASS_MLA` ç»§ç»­å·¥ä½œã€‚<br>â€¢ æ–°å¢åç«¯è¦æ±‚ `kv_cache_dtype` ä¸º `auto`/`bfloat16`ï¼ˆä¸æ”¯æŒ fp8ï¼‰ï¼Œå¯¹ä½¿ç”¨ fp8â€‘kvâ€‘cache çš„æ¨¡å‹éœ€è¦åœ¨é…ç½®å±‚æ˜¾å¼å›é€€ã€‚<br>â€¢ é€šè¿‡ `AttentionBackendEnum` ç»Ÿä¸€è®¿é—®ï¼Œæ—§ä»£ç è‹¥ç¡¬ç¼–ç å­—ç¬¦ä¸²ï¼ˆå¦‚ `"flashinfer_mla"`ï¼‰ä»ä¼šèµ°ç¨ å¯†è·¯å¾„ï¼›å»ºè®®ç»Ÿä¸€ä½¿ç”¨æšä¸¾æˆ– `get_attn_backend` æ¥å£ã€‚ |

---

### âš ï¸ æ½œåœ¨é£é™©

1. **å¹³å°å…¼å®¹æ€§ç¼ºå¤±**  
   - åœ¨é Blackwell GPUï¼ˆSMâ€¯<â€¯10ï¼‰ä¸Šä»ä¼šå°è¯•å¼ºåˆ¶ `block_size=64`ï¼Œè‹¥æœªæ­£ç¡®è¿‡æ»¤ä¼šå¯¼è‡´ä¸æ”¯æŒçš„ kernel è°ƒç”¨ã€‚  
2. **å…¨å±€å·¥ä½œç©ºé—´ç«äº‰**  
   - å•ä¾‹ `_fi_sparse_workspace` åœ¨å¤šè¿›ç¨‹ï¼ˆtorch.multiprocessingï¼‰æˆ–å¤šçº¿ç¨‹ç¯å¢ƒä¸‹å…±äº«ï¼Œè‹¥ä¸åŒå®ç°å®ä¾‹å¹¶è¡Œå†™å…¥å¯èƒ½å‡ºç° raceã€‚  
3. **æ¨¡å‹é…ç½®ä¸å®Œæ•´**  
   - `index_topk` ä¸ºå¿…éœ€å­—æ®µï¼›å·²æœ‰æ¨¡å‹é…ç½®æ–‡ä»¶æœªæä¾›æ—¶ä¼šåœ¨ `supports_combination` æŠ¥é”™ï¼Œå¯¼è‡´å¯åŠ¨å¤±è´¥ã€‚  
4. **åç«¯ä¼˜å…ˆçº§ç¡¬ç¼–ç **  
   - `cuda._get_backend_priorities` ä¾æ® `num_heads` åŠ¨æ€åˆ‡æ¢é¡ºåºï¼Œè‹¥æœªæ¥æ–°å¢ç¨€ç–åç«¯æˆ–æ”¹å˜ headâ€‘size ç­–ç•¥ï¼Œéœ€è¦åŒæ­¥æ›´æ–°æ­¤é€»è¾‘ã€‚  
5. **æµ‹è¯•éšæœºæ€§**  
   - å•å…ƒæµ‹è¯•ä½¿ç”¨éšæœº `topk_indices_buffer`ï¼Œåœ¨æç«¯ç§å­ä¸‹å¯èƒ½å‡ºç°ç¨€ç–ç´¢å¼•å…¨ä¸º `-1` å¯¼è‡´ç©ºç®—å­ï¼Œå¯¼è‡´ CI å¤±ç¨³ã€‚  
6. **æ–‡æ¡£/é…ç½®ä¸ä¸€è‡´**  
   - éƒ¨åˆ† benchmark é…ç½®ä»ä½¿ç”¨æ—§å°å†™åç«¯åç§°

---

#### ğŸŸ¡ ä¸­é‡è¦åº¦å˜æ›´ (17)

### [Bugfix] Exclude `language_model_only` key from MM AOT compile hash but include in model one (#34508)
**SHA**: `1dae7b7` | ğŸ”— [æŸ¥çœ‹æäº¤](https://github.com/vllm-project/vllm/commit/1dae7b7843062f3468485653779d43ef96c7245c)

**ğŸ¯ å˜æ›´ç±»å‹**ï¼šBug ä¿®å¤  
**âš¡ é‡è¦ç¨‹åº¦**ï¼šğŸŸ¡ ä¸­  
**ğŸ“‹ å˜æ›´æ‘˜è¦**ï¼šåœ¨ AOT ç¼–è¯‘å“ˆå¸Œè®¡ç®—ä¸­ï¼Œ`language_model_only` åªåº”å½±å“è¯­è¨€æ¨¡å‹çš„è®¡ç®—å›¾è€Œä¸å½±å“å¤šæ¨¡æ€å­å›¾ã€‚ä¸ºæ­¤ï¼šâ‘  ä» `MultiModalConfig.compute_hash` ä¸­å‰”é™¤è¯¥å­—æ®µï¼›â‘¡ åœ¨ `ModelConfig.compute_hash` ä¸­æ˜¾å¼åŠ å…¥è¯¥å­—æ®µï¼›â‘¢ æ–°å¢å•å…ƒæµ‹è¯•éªŒè¯è¡Œä¸ºã€‚  

**ğŸ¯ å½±å“èŒƒå›´**ï¼š  
- `vllm/config/multimodal.py`ï¼ˆå“ˆå¸Œå› å­ç”Ÿæˆï¼‰  
- `vllm/config/model.py`ï¼ˆæ¨¡å‹å±‚å“ˆå¸ŒåŠ å…¥ `language_model_only`ï¼‰  
- æµ‹è¯•å¥—ä»¶ `tests/config/test_multimodal_config.py`  

**ğŸ’¡ å…³æ³¨å»ºè®®**  
1. **å¼€å‘è€…**ï¼šç¡®è®¤æ‰€æœ‰åŸºäº `MultiModalConfig.compute_hash` çš„ç¼“å­˜æˆ–æ–‡ä»¶åç”Ÿæˆé€»è¾‘å·²ä¸å†ä¾èµ– `language_model_only`ï¼Œé˜²æ­¢è¯¯è§¦å‘ä¸å¿…è¦çš„é‡æ–°ç¼–è¯‘ã€‚è‹¥æœ‰å…¶ä»–æ¨¡å—æ‰‹åŠ¨æ‹¼æ¥å“ˆå¸Œï¼Œè¯·åŒæ­¥æ›´æ–°ã€‚  
2. **ç”¨æˆ·**ï¼šåœ¨ä½¿ç”¨ `language_model_only=True` çš„å¤šæ¨¡æ€æ¨¡å‹æ—¶ï¼Œé¦–æ¬¡ç¼–è¯‘åç”Ÿæˆçš„æ¨¡å‹æ–‡ä»¶å¯åœ¨åç»­çº¯è¯­è¨€æ¨¡å‹è¿è¡Œä¸­å¤ç”¨ï¼›ä½†åˆ‡æ¢ `language_model_only` çŠ¶æ€ä»ä¼šå¯¼è‡´æ¨¡å‹å±‚å“ˆå¸Œå˜æ›´ï¼Œéœ€é‡æ–°ç¼–è¯‘ã€‚  
3. **æ–‡æ¡£**ï¼šåœ¨é…ç½®ç« èŠ‚ä¸­è¯´æ˜ `language_model_only` å¯¹æ¨¡å‹å±‚å“ˆå¸Œçš„å½±å“èŒƒå›´ï¼Œé¿å…è¯¯è§£ã€‚  
4. **å›å½’**ï¼šè¿è¡Œå…¨é‡æµ‹è¯•ï¼Œç‰¹åˆ«æ˜¯æ¶‰åŠ AOT ç¼–è¯‘ç¼“å­˜çš„åœºæ™¯ï¼Œç¡®ä¿æ—§ç¼“å­˜ä¸ä¼šå› å“ˆå¸Œå˜åŒ–äº§ç”Ÿå†²çªã€‚  

æ­¤æ”¹åŠ¨æå‡äº†å“ˆå¸Œçš„è¯­ä¹‰ä¸€è‡´æ€§ï¼Œé™ä½äº†ä¸å¿…è¦çš„é‡æ–°ç¼–è¯‘æ¬¡æ•°ã€‚

---

### [Misc] Port Qwen3.5 Configs (#34512)
**SHA**: `5885e33` | ğŸ”— [æŸ¥çœ‹æäº¤](https://github.com/vllm-project/vllm/commit/5885e330efea5212733375f3573990de791d5042)

**ğŸ¯ å˜æ›´ç±»å‹**ï¼šåŠŸèƒ½å¢å¼ºï¼ˆä¸º vLLM æ–°å¢ Qwenâ€¯3.5 ä¸ Qwenâ€¯3.5â€‘MoE çš„é…ç½®æ”¯æŒï¼‰  
**âš¡ é‡è¦ç¨‹åº¦**ï¼šğŸŸ¡ ä¸­  
**ğŸ“‹ å˜æ›´æ‘˜è¦**ï¼šå°†åŸå…ˆç›´æ¥ä» HuggingFaceâ€‘Transformers å¯¼å…¥çš„ `Qwen3_5*Config`ã€`Qwen3_5Moe*Config` ç§»æ¤åˆ° `vllm.transformers_utils.configs` åŒ…ä¸­ï¼Œå¹¶åœ¨æ¨¡å‹å®ç° (`qwen3_5.py`, `qwen3_5_mtp.py`) æ”¹ä¸ºä½¿ç”¨è¿™äº›å†…éƒ¨å®ç°ã€‚ä¸æ­¤åŒæ—¶ï¼Œå‘é…ç½®æ³¨å†Œè¡¨ (`vllm/transformers_utils/config.py`ã€`configs/__init__.py`) ä¸­æ·»åŠ å¯¹åº”çš„é”®å€¼æ˜ å°„ï¼Œç¡®ä¿ `VLLMConfig["qwen3_5"]`ã€`["qwen3_5_moe"]` èƒ½è¢«æ­£ç¡®è§£æã€‚

**ğŸ¯ å½±å“èŒƒå›´**  
- `vllm/model_executor/models/qwen3_5*.py`ï¼ˆæ¨¡å‹å±‚å®ç°ï¼‰  
- `vllm/transformers_utils/config*`ï¼ˆé…ç½®æ³¨å†Œä¸å¯¼å…¥ï¼‰  
- æ–°å¢çš„ `vllm/transformers_utils/configs/qwen3_5*.py`ï¼ˆå®Œæ•´çš„ Text / Vision / MoE é…ç½®å®ç°ï¼‰  

**ğŸ’¡ å…³æ³¨å»ºè®®**  
1. **å…¼å®¹æ€§**ï¼šé¡¹ç›®ä¸­ä»æœ‰ç›´æ¥ `from transformers.models.qwen3_5...` çš„å¼•ç”¨å—ï¼Ÿè‹¥å­˜åœ¨ï¼Œéœ€è¦æ·»åŠ é€‚é…åˆ«åæˆ–ä¿æŒæ—§è·¯å¾„çš„å…¼å®¹å±‚ï¼Œä»¥å…ç”¨æˆ·å‡çº§åå‡ºç° `ImportError`ã€‚  
2. **åŠ è½½éªŒè¯**ï¼šåœ¨æœ¬åœ°æˆ– CI ä¸­ä½¿ç”¨ `vllm.LLM(model="Qwen/Qwen3.5-...")` è¿›è¡Œä¸€æ¬¡å®Œæ•´çš„æ¨¡å‹åŠ è½½ä¸æ¨ç†ï¼Œç¡®è®¤ `VLLMConfig.from_pretrained` èƒ½æ­£ç¡®è§£ææ–°é…ç½®ã€‚  
3. **æ–‡æ¡£ & ç¤ºä¾‹**ï¼šæ›´æ–° README / API æ–‡æ¡£ä¸­å…³äº Qwenâ€¯3.5 çš„è¯´æ˜ï¼Œåˆ—å‡ºé…ç½®ç±»çš„æ–°è·¯å¾„ï¼ˆ`vllm.transformers_utils.configs.qwen3_5`ï¼‰ã€‚  
4. **æµ‹è¯•è¦†ç›–**ï¼šä¸º `Qwen3_5Config` / `Qwen3_5MoeConfig` æ–°å¢å•å…ƒæµ‹è¯•ï¼Œå°¤å…¶æ˜¯ `base_model_tp_plan`ã€`base_model_pp_plan` ä¸ `layer_types` çš„é»˜è®¤ç”Ÿæˆé€»è¾‘ã€‚  
5. **ä»£ç æ¸…ç†**ï¼šç§»é™¤å·²ä¸å†ä½¿ç”¨çš„ `transformers.models.qwen3_5*` å¯¼å…¥ï¼Œé˜²æ­¢æœªæ¥çš„ä¾èµ–å†²çªã€‚  

æ€»ä½“æ¥çœ‹ï¼Œæ­¤æ¬¡è¿ç§»ä¸º vLLM æ·»åŠ äº†å¯¹æœ€æ–° Qwenâ€¯3.5 ç³»åˆ—æ¨¡å‹çš„åŸç”Ÿæ”¯æŒï¼Œå½±å“ä¸»è¦é™äºé…ç½®åŠ è½½è·¯å¾„ï¼Œè‹¥åšå¥½å‘åå…¼å®¹å’Œæµ‹è¯•ï¼Œå³å¯å®‰å…¨å‘å¸ƒã€‚

---

### [Feature] Pipeline Parallel Async send/recv, 2.9% E2E throughput improvement (#33368)
**SHA**: `3d2a026` | ğŸ”— [æŸ¥çœ‹æäº¤](https://github.com/vllm-project/vllm/commit/3d2a026fd0317204752d7933408aff19aaa80cfd)

**ğŸ¯ å˜æ›´ç±»å‹**ï¼šåŠŸèƒ½å¢å¼ºï¼ˆPipelineâ€‘Parallel å¼‚æ­¥ send/recvï¼‰  
**âš¡ é‡è¦ç¨‹åº¦**ï¼šğŸŸ¡ ä¸­  

**ğŸ“‹ å˜æ›´æ‘˜è¦**  
1. åœ¨ `GroupCoordinator` ä¸­æ–°å¢ `Handle` åè®®å¹¶å®ç° `isend_tensor_dict` / `irecv_tensor_dict`ï¼Œå®ç°å‘é€/æ¥æ”¶çš„éé˜»å¡æ¥å£ã€‚  
2. æ·»åŠ å†…éƒ¨åˆ¤æ–­ `all_gather` æ˜¯å¦é€‚ç”¨çš„ `_should_use_all_gather`ï¼Œå¹¶å°†å‘é€/æ¥æ”¶è¿‡ç¨‹æ‹†åˆ†ä¸º **metadata** + **tensor** ä¸¤æ­¥ï¼Œtensor ä½¿ç”¨ `torch.distributed.isend/irecv` å¹¶åœ¨ GPU ä¸Šè®°å½• streamã€‚  
3. `AsyncIntermediateTensors` ç»§æ‰¿è‡ª `IntermediateTensors`ï¼Œåœ¨ç¬¬ä¸€æ¬¡è®¿é—® `.tensors` å‰æƒ°æ€§ `wait` å¼‚æ­¥å¥æŸ„å¹¶æ‰§è¡Œåå¤„ç†ã€‚  
4. `Worker.execute_model` æ”¹ä¸ºåœ¨å‰ä¸€æ¬¡è¿­ä»£ç»“æŸå‰ç­‰å¾…ä¸Šä¸€æ¬¡çš„ PP å‘é€å·¥ä½œ (`_pp_send_work`)ï¼Œå¹¶åœ¨æ¥æ”¶ç«¯ä½¿ç”¨ `irecv_tensor_dict` è¿”å›çš„å¥æŸ„ä¸åå¤„ç†å‡½æ•°ã€‚  
5. æ–°å¢å•å…ƒæµ‹è¯•éªŒè¯ `irecv_tensor_dict` çš„é—­åŒ…ç»‘å®šä»¥åŠ `AsyncIntermediateTensors` çš„æƒ°æ€§ç­‰å¾…è¡Œä¸ºã€‚  

**ğŸ¯ å½±å“èŒƒå›´**  
- `vllm/distributed/parallel_state.py`ï¼ˆæ ¸å¿ƒé€šä¿¡å±‚ï¼‰  
- `vllm/v1/worker/gpu_worker.py`ï¼ˆæ¨¡å‹è¿è¡Œæ—¶è°ƒåº¦ï¼‰  
- `tests/distributed/test_comm_ops.py`ï¼ˆæ–°å¢/æ‰©å±•çš„åˆ†å¸ƒå¼é€šä¿¡å•å…ƒæµ‹è¯•ï¼‰  

**ğŸ’¡ å…³æ³¨å»ºè®®**  

1. **å¥æŸ„å…¼å®¹æ€§**ï¼š`Handle` ä»…è¦æ±‚ `wait` ä¸ `is_completed`ï¼Œä½†å½“å‰å®ç°è¿”å› `torch.distributed.Work`ã€‚è‹¥åç»­ä½¿ç”¨å…¶å®ƒåç«¯ï¼ˆe.g., NCCLâ€‘P2Pã€CPU è‡ªå®šä¹‰ï¼‰ï¼Œéœ€ç¡®ä¿å®ƒä»¬å®ç°åŒåè®®ï¼Œå¦åˆ™ä¼šåœ¨ç±»å‹æ£€æŸ¥æˆ–è¿è¡Œæ—¶è§¦å‘ `AttributeError`ã€‚  
2. **èµ„æºé‡Šæ”¾**ï¼š`isend`/`irecv` äº§ç”Ÿçš„ `Work` å¯¹è±¡åœ¨ `AsyncIntermediateTensors` å®Œæˆåæœªæ˜¾å¼é”€æ¯ï¼Œå»ºè®®åœ¨ `wait_for_comm` æœ«å°¾ç½® `self._comm_handles = []`ï¼Œé˜²æ­¢æŒæœ‰æ˜¾å¼çš„ CUDA event å¼•èµ·æ˜¾å­˜æ³„æ¼ã€‚  
3. **é”™è¯¯è·¯å¾„**ï¼šå‘é€/æ¥æ”¶å¼‚å¸¸æ—¶ï¼ˆå¦‚ `torch.distributed.isend` æŠ›å‡ºï¼‰ï¼Œå½“å‰ä»£ç ä¸ä¼šå›æ»šå·²åˆ›å»ºçš„å¥æŸ„ã€‚å¯ä»¥åœ¨ `isend_tensor_dict`/`irecv_tensor_dict` ä¸­æ•è·å¼‚å¸¸å¹¶å¯¹å·²åˆ›å»ºçš„ `Work` è°ƒç”¨ `wait` å†é‡æ–°æŠ›å‡ºï¼Œä»¥é¿å…æŒ‚èµ·çš„é€šä¿¡å¯¼è‡´åç»­ deadâ€‘lockã€‚  
4. **Allâ€‘Gather é€»è¾‘**ï¼š`_should_use_all_gather` ä¾èµ– `tensor.numel() % world_size == 0`ï¼›è‹¥å‡ºç°éæ•´é™¤ä½†ç”¨æˆ·å¼ºåˆ¶åœ¨ `all_gather_tensors` ä¸­è®¾ä¸º `True`ï¼Œä»ä¼šèµ°åˆ‡ç‰‡è·¯å¾„å¯¼è‡´ shape ä¸åŒ¹é…ã€‚å»ºè®®åœ¨å…¥å£å¤„æ ¡éªŒå¹¶åœ¨ä¸æ»¡è¶³æ¡ä»¶æ—¶å›è½ä¸ºæ™®é€š sendã€‚  
5. **CPU è‡ªå®šä¹‰é€šé“**ï¼š`use_cpu_custom_send_recv` åˆ†æ”¯ä»ä¿æŒåŒæ­¥è·¯å¾„ï¼Œå¼‚æ­¥ API è°ƒç”¨åä¼šç›´æ¥è¿”å›ç©ºå¥æŸ„åˆ—è¡¨ã€‚è‹¥æœªæ¥åœ¨ CPU ä¾§å®ç°å¼‚æ­¥å®ç°ï¼Œéœ€è¦åœ¨ `isend_tensor_dict`/`irecv_tensor_dict` ä¸­åŠ å…¥å¯¹åº”çš„ `Handle` åŒ…è£…ã€‚  
6. **æ€§èƒ½åŸºå‡†**ï¼šæäº¤å£°ç§° 2.9% E2E æå‡ï¼Œå»ºè®®åœ¨ CI ä¸­ä¿ç•™è¯¥åŸºå‡†æµ‹è¯•å¹¶åœ¨å¤šæœºå¤šå¡ç¯å¢ƒä¸‹éªŒè¯ï¼Œé˜²æ­¢åœ¨ç‰¹æ®Šæ‹“æ‰‘ï¼ˆå¦‚ NCCLâ€‘P2P ä¸å¯ç”¨ï¼‰ä¸‹å‡ºç°å›é€€åˆ°åŒæ­¥å¯¼è‡´æ€§èƒ½ä¸‹é™ã€‚  

æ€»ä½“æ¥çœ‹ï¼Œæ­¤æ¬¡æ”¹åŠ¨ä¸º Pipelineâ€‘Parallel å¼•å…¥äº†éé˜»å¡é€šä¿¡ï¼Œä»£ç ç»“æ„æ›´æ¸…æ™°ï¼Œå»¶è¿Ÿéšè—åœ¨ `AsyncIntermediateTensors` ä¸­ã€‚æ³¨æ„ä¸Šè¿°å…¼å®¹æ€§ã€å¼‚å¸¸å®‰å…¨ä¸èµ„æºå›æ”¶ï¼Œèƒ½å¤Ÿåœ¨æ­£å¼å‘å¸ƒå‰è¿›ä¸€æ­¥æå‡ç¨³å¥æ€§ã€‚

---

### [KVConnector] Clean up redundant code in KV connectors (#34147)
**SHA**: `47e9b63` | ğŸ”— [æŸ¥çœ‹æäº¤](https://github.com/vllm-project/vllm/commit/47e9b63e1afeb074b0fa584e0169e27d517b4e7b)

**ğŸ¯ å˜æ›´ç±»å‹**ï¼šé‡æ„ / ä»£ç æ¸…ç†  
**âš¡ é‡è¦ç¨‹åº¦**ï¼šğŸŸ¡ ä¸­ï¼ˆä»…æ¶‰åŠ KVâ€‘Connector å­æ¨¡å—çš„ç»†èŠ‚ä¼˜åŒ–ï¼‰  
**ğŸ“‹ å˜æ›´æ‘˜è¦**  
1. ä¿®æ­£ `noqa` æ³¨é‡Šçš„æ‹¼å†™é”™è¯¯ã€‚  
2. åˆ é™¤ `example_connector.py` ä¸­ä¸¤å¤„æ— æ„ä¹‰çš„ `reshape` è°ƒç”¨åŠå·²å¤±æ•ˆçš„ `metadata is None` è­¦å‘Šé€»è¾‘ã€‚  
3. ç§»é™¤ `lmcache_mp_connector.py` çš„æœªä½¿ç”¨ `VllmConfig` å¯¼å…¥ã€‚  
4. å°† `offloading_connector.py` ä¸­ `total_time` çš„é»˜è®¤ç±»å‹ç”± `int` æ”¹ä¸º `float`ï¼Œé˜²æ­¢ç»Ÿè®¡æ—¶å‡ºç°æ•´æ•°é™¤æ³•ç²¾åº¦æŸå¤±ã€‚  

**ğŸ¯ å½±å“èŒƒå›´**  
- `vllm/distributed/kv_transfer/kv_connector/v1/` åŒ…ä¸‹çš„å››ä¸ªå®ç°æ–‡ä»¶ï¼ˆ`example_connector`, `lmcache_mp_connector`, `offloading_connector`, `__init__`ï¼‰ã€‚  
- ç›¸å…³çš„ KVâ€‘Cache è¿ç§»ã€è§£ç åŸºå‡†ä»¥åŠ offloading ç»Ÿè®¡åŠŸèƒ½ã€‚

**ğŸ’¡ å…³æ³¨å»ºè®®**  
-â€¯`example_connector.inject_kv_into_layer` ç°åœ¨ä¸å†æ˜¾å¼æ¢å¤åŸå§‹å½¢çŠ¶ï¼Œç¡®è®¤è°ƒç”¨æ–¹ä¸ä¾èµ–è¯¥å‰¯ä½œç”¨ï¼ˆç›®å‰ `reshape` ä»…è¿”å›æ–°è§†å›¾ï¼ŒåŸä»£ç ç­‰ä»·äºæ— æ“ä½œï¼‰ã€‚  
-â€¯åˆ é™¤ `metadata is None` æ£€æŸ¥åï¼Œè‹¥å°†æ¥å‡ºç°é `ExampleConnectorMetadata` çš„æƒ…å½¢ï¼Œ`assert` ä¼šç›´æ¥æŠ›å¼‚å¸¸ï¼›å¦‚æœ‰éœ€è¦è¯·åœ¨ä¸Šå±‚åŠ å…¥æ›´å‹å¥½çš„é”™è¯¯æç¤ºã€‚  
-â€¯`total_time` æ”¹ä¸º `float` åï¼Œè¯·ç¡®ä¿æ‰€æœ‰ç»Ÿè®¡èšåˆä»£ç ä½¿ç”¨æµ®ç‚¹åŠ æ³•ï¼Œä»¥é¿å…æ„å¤–çš„æ•´æ•°æˆªæ–­ã€‚  
-â€¯è¿è¡Œå®Œæ•´çš„å•å…ƒ/é›†æˆæµ‹è¯•ï¼Œç‰¹åˆ«æ˜¯ KVâ€‘Transferã€offloading ä¸ decodeâ€‘bench åœºæ™¯ï¼Œç¡®ä¿æ²¡æœ‰å› è¿™äº›ç»†å¾®æ”¹åŠ¨å¯¼è‡´çš„è¿è¡Œæ—¶é”™è¯¯ã€‚  
-â€¯ä½¿ç”¨ `mypy` æˆ– `ruff` ç­‰å·¥å…·å†æ¬¡æ£€æŸ¥æœªä½¿ç”¨çš„å¯¼å…¥æˆ–ç±»å‹æç¤ºï¼Œä¿æŒä»£ç åŸºçº¿çš„æ•´æ´ã€‚

---

### [Perf] fused_moe: add int4_w4a16 benchmark support and tuning config (#34130)
**SHA**: `934acdd` | ğŸ”— [æŸ¥çœ‹æäº¤](https://github.com/vllm-project/vllm/commit/934acddef9fa4eb1b6cc897d2e39db77385539c6)

**ğŸ¯ å˜æ›´ç±»å‹**ï¼šæ€§èƒ½å¢å¼ºï¼ˆä¸º fusedâ€‘moe åŠ å…¥ int4â€†w4a16 é‡åŒ–çš„åŸºå‡†ä¸è°ƒå‚åŠŸèƒ½ï¼‰

**âš¡ é‡è¦ç¨‹åº¦**ï¼šğŸŸ¡ ä¸­

**ğŸ“‹ å˜æ›´æ‘˜è¦**  
1. åœ¨ `benchmarks/kernels/benchmark_moe.py` ä¸­æ–°å¢ `use_int4_w4a16` å‚æ•°ï¼Œå®Œæ•´å®ç° int4â€‘packed æƒé‡é‡åŒ–çš„éšæœºç”Ÿæˆã€scale å¤„ç†ã€ä»¥åŠ `weight_dtype` ä¼ é€’ã€‚  
2. æ‰©å±• CLIã€è°ƒä¼˜ã€é…ç½®ä¿å­˜ç­‰å…¨é“¾è·¯ï¼Œä½¿å…¶èƒ½å¤Ÿè¯†åˆ« `int4_w4a16`ã€è¯»å–æ¨¡å‹çš„ `group_size` å¹¶è‡ªåŠ¨æ„é€  `block_quant_shape=[0, group_size]`ã€‚  
3. æ–°å¢é’ˆå¯¹ Radeonâ€¯8060S çš„ int4 é…ç½® JSONï¼ˆ`E=128,N=768,â€¦,dtype=int4_w4a16.json`ï¼‰ï¼Œå¹¶åœ¨æœç´¢ç©ºé—´ç”Ÿæˆæ—¶å›ºå®š `SPLIT_K=1`ã€è·³è¿‡ blockâ€‘size è¿‡æ»¤ã€‚

**ğŸ¯ å½±å“èŒƒå›´**  
- `benchmarks/kernels/benchmark_moe.py`ï¼ˆåŸºå‡†ã€è°ƒä¼˜ã€CLIï¼‰  
- `vllm/model_executor/layers/fused_moe/configs/`ï¼ˆæ–°å¢ int4 é…ç½®ï¼‰  
- ç›¸å…³å·¥å…·å‡½æ•°ï¼ˆ`_get_config_dtype_str`ã€`get_quantization_group_size`ï¼‰  

**ğŸ’¡ å…³æ³¨å»ºè®®**  
- ç¡®è®¤æ¨¡å‹çš„ `quantization_config` ä¸­åŒ…å« `group_size`ï¼ˆæˆ– `config_groups`ï¼‰ï¼Œå¦åˆ™è¿è¡Œä¼šæŠ›å¼‚å¸¸ã€‚  
- è¿è¡Œ CI æ—¶åŠ å…¥ int4â€‘w4a16 åŸºå‡†æµ‹è¯•ï¼Œé˜²æ­¢åœ¨ä¸æ”¯æŒçš„ç¡¬ä»¶ä¸Šå›  `use_int4_w4a16` è¢«è¯¯è§¦å‘ã€‚  
- æ–‡æ¡£ä¸­è¡¥å…… `--dtype int4_w4a16` çš„è¯´æ˜åŠå¯¹åº”çš„ç¡¬ä»¶/é©±åŠ¨è¦æ±‚ï¼ˆROCmâ€¯â‰¥â€¯5.7ã€æ”¯æŒ uint8â€‘packed int4ï¼‰ã€‚  
- è‹¥åç»­åŠ å…¥å…¶å®ƒä½å®½çš„é‡åŒ–ï¼ˆå¦‚ int2ï¼‰ï¼Œè¯·ç»Ÿä¸€ `weight_dtype`ã€scale ç”Ÿæˆä¸ `block_quant_shape` çš„å¤„ç†é€»è¾‘ï¼Œé¿å…é‡å¤ä»£ç ã€‚

---

### [New Model] support new model ovis2.6 (#34426)
**SHA**: `bcf0731` | ğŸ”— [æŸ¥çœ‹æäº¤](https://github.com/vllm-project/vllm/commit/bcf0731aa07c11d92b6261c58f42d9ad07b949c6)

**ğŸ¯ å˜æ›´ç±»å‹**ï¼šåŠŸèƒ½å¢å¼ºï¼ˆæ–°å¢ Ovis2.6 ç³»åˆ—æ¨¡å‹ï¼‰  
**âš¡ é‡è¦ç¨‹åº¦**ï¼šğŸŸ¡ ä¸­  

**ğŸ“‹ å˜æ›´æ‘˜è¦**  
- åœ¨æ–‡æ¡£å’Œæ¨¡å‹æ³¨å†Œè¡¨ä¸­åŠ å…¥ `Ovis2_6ForCausalLM` ä¸ `Ovis2_6_MoeForCausalLM`ï¼Œå¹¶æŠŠå®ƒä»¬å¤ç”¨ç°æœ‰çš„ `Ovis2_5` å®ç°ã€‚  
- å¯¹ `Ovis2_5` ä»£ç åšäº†ä¸€ç³»åˆ— tokenâ€‘IDã€å ä½ç¬¦ä»¥åŠå›¾åƒ/è§†é¢‘å¤„ç†çš„è°ƒæ•´ï¼Œä½¿å…¶å…¼å®¹ 2.6 ç‰ˆæœ¬çš„ç‰¹æ®Š tokenï¼ˆ<image>ã€<video>ã€<ovis_â€¦>ï¼‰ã€‚  
- è¿ç§»äº†æ—§çš„ `IMAGE_PAD_TOKEN_MAP`ã€`IMAGE_PAD_TOKEN_ID_MAP` åˆ°ç»Ÿä¸€çš„å¸¸é‡ `IMAGE_PAD_TOKEN_ID`ï¼Œå¹¶åœ¨ processor ä¸­åŠ å…¥å¼ºæ ¡éªŒã€‚  
- æ›´æ–°äº†æµ‹è¯•ç™»è®°ä¿¡æ¯ï¼Œç¡®ä¿æ–°æ¨¡å‹åœ¨ç¦»çº¿/åœ¨çº¿ç¯å¢ƒä¸‹çš„å¯å‘ç°æ€§ã€‚  

**ğŸ¯ å½±å“èŒƒå›´**  
- `vllm/model_executor/models/ovis2_5.py`ï¼ˆæ ¸å¿ƒæ¨¡å‹å®ç°ï¼‰  
- `vllm/model_executor/models/registry.py`ï¼ˆæ¨¡å‹æ˜ å°„ï¼‰  
- `vllm/transformers_utils/processors/ovis2_5.py`ï¼ˆHF processor ä¸ token ç®¡ç†ï¼‰  
- `docs/models/supported_models.md`ã€`tests/models/registry.py`ï¼ˆæ–‡æ¡£/æµ‹è¯•ï¼‰  

**ğŸ’¡ å…³æ³¨å»ºè®®**  

1. **Token ID ä¸€è‡´æ€§**  
   - ç°åœ¨ `IMAGE_TOKEN`ã€`VIDEO_TOKEN` çš„æ˜ å°„æ˜¯ `vocab[IMAGE_TOKEN]`ã€`vocab[VIDEO_TOKEN]`ï¼Œä½† `PromptReplacement.target` ä»æ¥å—åˆ—è¡¨ (`[placeholder[modality]]`)ã€‚è‹¥åç»­ä»ä½¿ç”¨å• intï¼Œå»ºè®®ç»Ÿä¸€ä¸º `int`ï¼Œé¿å…ä¸å¿…è¦çš„åˆ—è¡¨åŒ…è£…ã€‚  
   - `INDICATOR_IDS` ä¸ `THINK_END_TOKEN_ID` çš„ç¡¬ç¼–ç å€¼ï¼ˆ151672~151675ã€151668ï¼‰åº”åœ¨é…ç½®æˆ– tokenizer ä¸­æ³¨é‡Šï¼Œé˜²æ­¢åœ¨ä¸åŒæ¨¡å‹ç‰ˆæœ¬ä¸­å‡ºç°å†²çªã€‚

2. **å ä½ç¬¦ ID ä¸ PAD Token**  
   - `image_pad_token_id` ç›´æ¥å– `IMAGE_PAD_TOKEN_ID`ï¼ˆ151655ï¼‰ï¼Œä¸å†ä¾æ®æ–‡æœ¬æ¨¡å‹ç±»å‹åˆ¤æ–­ï¼Œè¿™å¯¹ `Ovis2.6` æ˜¯åˆç†çš„ï¼Œä½†å¦‚æœä»¥åå†æ¬¡å¤ç”¨ `Ovis2_5` çš„ä»£ç ï¼Œéœ€è¦ç¡®ä¿å…¶å®ƒæ¨¡å‹çš„ PAD token ä»å…¼å®¹ã€‚å»ºè®®åœ¨ `__init__` ä¸­åŠ å…¥ fallback æˆ–è­¦å‘Šã€‚

3. **Processor å‚æ•°å»é™¤**  
   - `min_pixels`ã€`max_pixels` å‚æ•°è¢«ç¡¬åˆ é™¤ï¼Œæ”¹ä¸ºä»…é€šè¿‡ `output_kwargs` ä¼ é€’ã€‚è‹¥å¤–éƒ¨è°ƒç”¨ä»ä¾èµ–è¿™äº›å‚æ•°ï¼Œä¼šæŠ›å‡º `KeyError`ã€‚å»ºè®®åœ¨ `__call__` å‰åŠ å…¥å…¼å®¹å±‚æˆ–åœ¨æ–‡æ¡£ä¸­æ˜ç¡®åˆ é™¤è¯´æ˜ã€‚

4. **å¼‚å¸¸ä¿¡æ¯**  
   - `extra_special_tokens` è‹¥ç¼ºå¤±å¿…éœ€ tokenï¼Œä¼šæŠ›å‡º `ValueError` å¹¶æç¤ºå®Œæ•´çš„ `tokenizer_config.json` é“¾æ¥ï¼Œè¿™å¯¹ä½¿ç”¨è€…å‹å¥½ã€‚å¯è€ƒè™‘å°†æç¤ºä¿¡æ¯æŠ½å–ä¸ºå¸¸é‡ï¼Œä¾¿äºå¤šè¯­è¨€ç»´æŠ¤ã€‚

5. **æµ‹è¯•è¦†ç›–**  
   - ç›®å‰ä»…åœ¨ `tests/models/registry.py` ä¸­åŠ å…¥æ¨¡å‹ç™»è®°ä¿¡æ¯ï¼Œå»ºè®®è¡¥å……å¯¹ `Ovis2_6` çš„æ¨ç†è·¯å¾„ï¼ˆtokenizerã€processorã€visual tokenæ˜ å°„ï¼‰çš„å•å…ƒæµ‹è¯•ï¼Œä»¥é˜²æ­¢å›  token ID æ”¹åŠ¨å¯¼è‡´ runtime é”™è¯¯ã€‚

6. **ä»£ç æ¸…ç†**  
   - `siglip2navit.py` åˆ é™¤äº† `post_layernorm` è°ƒç”¨ï¼Œè‹¥è¯¥å±‚åœ¨å…¶ä»–æ¨¡å‹ä¸­ä»è¢«ä½¿ç”¨ï¼Œéœ€è¦ç¡®è®¤æ˜¯å¦æ„å¤–é—æ¼äº†å¿…è¦çš„å½’ä¸€åŒ–æ­¥éª¤ã€‚å¯ä»¥åœ¨æäº¤è¯´æ˜ä¸­åŠ å…¥åŸå› è¯´æ˜ã€‚

**æ€»ä½“å»ºè®®**ï¼šæœ¬æ¬¡æ”¹åŠ¨åœ¨ä¿æŒåŸæœ‰ `Ovis2_5` å®ç°çš„åŒæ—¶ï¼ŒæˆåŠŸåŠ å…¥äº† Ovis2.6 ç³»åˆ—æ¨¡å‹ï¼Œç»“æ„æ¸…æ™°ã€‚è¯·é‡ç‚¹æ£€æŸ¥ tokenâ€‘ID ä¸å ä½ç¬¦çš„ç»Ÿä¸€è·¯å¾„ï¼Œç¡®ä¿åœ¨ä¸åŒæ¨¡å‹ä¹‹é—´ä¸ä¼šå‡ºç°è·¨ç‰ˆæœ¬å†²çªï¼Œå¹¶è¡¥é½ç›¸åº”çš„å›å½’æµ‹è¯•ï¼Œä»¥æå‡å‘å¸ƒçš„ç¨³å®šæ€§ã€‚

---

### [Refactor] Call renderer for online IO processor request (#34490)
**SHA**: `ec090c2` | ğŸ”— [æŸ¥çœ‹æäº¤](https://github.com/vllm-project/vllm/commit/ec090c2429d179309641cba9e7793eab34e19f8d)

**ğŸ¯ å˜æ›´ç±»å‹**ï¼šé‡æ„ï¼ˆåŠŸèƒ½ç»†åŒ–ï¼‰  
**âš¡ é‡è¦ç¨‹åº¦**ï¼šğŸŸ¡ ä¸­  

**ğŸ“‹ å˜æ›´æ‘˜è¦**  
1. å°† `LLM._preprocess_completion` é‡å‘½åä¸º `_preprocess_cmpl`ï¼Œç»Ÿä¸€åœ¨ `enqueue`ã€`_run_completion` ç­‰è·¯å¾„çš„è°ƒç”¨ã€‚  
2. åœ¨ OpenAI `EngineServing` ä¸­æ–°å¢ `_preprocess_cmpl` å¼‚æ­¥å…¥å£ï¼Œä½¿åœ¨çº¿ IOâ€‘Processor åœ¨é¢„å¤„ç†é˜¶æ®µç›´æ¥èµ°æ¸²æŸ“å™¨é“¾è·¯ã€‚  
3. ä¸º `IOProcessorRequest` å¢åŠ  `build_tok_params` æ–¹æ³•ï¼Œç»Ÿä¸€æ„é€  `TokenizeParams`ï¼ˆä¹‹å‰åœ¨è°ƒç”¨æ–¹æ‰‹åŠ¨æ‹¼è£…ï¼‰ã€‚  
4. `PoolingServing` ç›¸åº”æ”¹é€ ï¼šåœ¨æ’ä»¶æ¨¡å¼ä¸‹ä½¿ç”¨ `await self._preprocess_cmpl` å¤„ç†åŸå§‹ promptï¼Œå¹¶ç»Ÿä¸€ `tokenization_kwargs` çš„è·å–æ–¹å¼ã€‚  

**ğŸ¯ å½±å“èŒƒå›´**  
- `vllm/entrypoints/llm.py`ï¼ˆæ ¸å¿ƒ LLM æ¥å£ï¼‰  
- `vllm/entrypoints/openai/engine/serving.py`ï¼ˆOpenAI æ¥å£ï¼‰  
- `vllm/entrypoints/pooling/pooling/protocol.py`ï¼ˆIOProcessor è¯·æ±‚å®šä¹‰ï¼‰  
- `vllm/entrypoints/pooling/pooling/serving.py`ï¼ˆPooling æœåŠ¡ï¼‰  

**ğŸ’¡ å…³æ³¨å»ºè®®**  
1. **å…¼å®¹æ€§**ï¼š`_preprocess_completion` å·²è¢«åˆ é™¤ï¼Œå¤–éƒ¨æ’ä»¶æˆ–è‡ªå®šä¹‰å­ç±»è‹¥ç›´æ¥è°ƒç”¨è¯¥ç§æœ‰æ–¹æ³•éœ€è¦æ”¹ä¸º `_preprocess_cmpl`ã€‚  
2. **å¼‚æ­¥ä¸€è‡´æ€§**ï¼š`_preprocess_cmpl` åœ¨ OpenAI ä¸ Pooling è·¯å¾„å‡ä¸º `async`ï¼Œç¡®ä¿æ‰€æœ‰è°ƒç”¨å¤„å‡ä½¿ç”¨ `await`ï¼Œé˜²æ­¢æ„å¤–çš„åç¨‹æ³„æ¼ã€‚  
3. **TokenizeParams ç»Ÿä¸€**ï¼š`IOProcessorRequest.build_tok_params` ä¾èµ– `model_config`ï¼Œè¯·æ£€æŸ¥æ¨¡å‹é…ç½®å­—æ®µï¼ˆå¦‚ `encoder_config`ï¼‰åœ¨ä¸åŒæ¨¡å‹ä¸Šæ˜¯å¦å®Œæ•´ï¼Œä»¥å…å‡ºç° `None` å¼•å‘å±æ€§é”™è¯¯ã€‚  
4. **æµ‹è¯•è¦†ç›–**ï¼šé‡ç‚¹è¡¥å……ä»¥ä¸‹åœºæ™¯çš„å•å…ƒ/é›†æˆæµ‹è¯•ï¼š  
   - `LLM.enqueue` åœ¨ `truncate_prompt_tokens` æ¡ä»¶ä¸‹ä»èƒ½æ­£ç¡®å½’ä¸€åŒ– Promptï¼›  
   - OpenAI `/v1/completions`ã€`/v1/chat/completions` ç»æ–°é¢„å¤„ç†æµç¨‹çš„å“åº”æ—¶åºï¼›  
   - Pooling æ’ä»¶æ¨¡å¼ä¸‹å¤šæ¨¡æ€è¾“å…¥çš„æ¸²æŸ“ä¸ tokenization å‚æ•°ä¼ é€’ã€‚  
5. **æ€§èƒ½ç›‘æ§**ï¼šæ¸²æŸ“å™¨è°ƒç”¨ç°åœ¨åœ¨ IOâ€‘Processor ç«¯å®Œæˆï¼Œå¯èƒ½ä¼šåœ¨é«˜å¹¶å‘ä¸‹å¼•å…¥é¢å¤–çš„ CPU/å†…å­˜å¼€é”€ï¼Œå»ºè®®åœ¨ç”Ÿäº§ç¯å¢ƒå¼€å¯ç›¸åº”æŒ‡æ ‡ï¼ˆè°ƒç”¨è€—æ—¶ã€å¼‚å¸¸ç‡ï¼‰è¿›è¡Œç›‘æ§ã€‚  

æ•´ä½“æ¥çœ‹ï¼Œæ­¤æ¬¡é‡æ„æå‡äº†é¢„å¤„ç†é€»è¾‘çš„å¯ç»„åˆæ€§ä¸ç»Ÿä¸€æ€§ï¼Œä½†æ¶‰åŠå¤šä¸ªç§æœ‰å…¥å£çš„æ”¹åå’Œå¼‚æ­¥åŒ–ï¼ŒåŠ¡å¿…åœ¨ CI ä¸­éªŒè¯å…¼å®¹æ€§å¹¶åšå¥½å›å½’æµ‹è¯•ã€‚

---

### [Bugfix] Fix mamba state dtype setting for Qwen3-Next and Qwen3.5 (#34489)
**SHA**: `eea3024` | ğŸ”— [æŸ¥çœ‹æäº¤](https://github.com/vllm-project/vllm/commit/eea3024f43e06ea4e037ec86464dcc249d0c0b44)

**ğŸ¯ å˜æ›´ç±»å‹**ï¼šBugfixï¼ˆä¿®æ­£ Qwen3â€‘Next / Qwen3.5â€¯Mamba çŠ¶æ€ç¼“å­˜ dtypeï¼‰  
**âš¡ é‡è¦ç¨‹åº¦**ï¼šğŸŸ¡ ä¸­  

**ğŸ“‹ å˜æ›´æ‘˜è¦**  
- ä¸º `MambaStateDtypeCalculator.gated_delta_net_state_dtype` æ–°å¢ `mamba_ssm_cache_dtype` å‚æ•°ï¼Œå®ç°å¯¹ SSMâ€‘Cache ä¸æ™®é€š Cache çš„ dtype åˆ†ç¦»ã€‚  
- åœ¨ `VllmConfig` éªŒè¯é˜¶æ®µä¸º Qwen3.5 ç³»åˆ—æ¨¡å‹åŒæ­¥ `mamba_ssm_cache_dtype`ï¼Œé»˜è®¤å– HF é…ç½®ä¸­çš„ `mamba_ssm_dtype`ï¼Œå¹¶åœ¨ç”¨æˆ·æ‰‹åŠ¨è¦†ç›–æ—¶ç»™å‡ºè­¦å‘Šã€‚  
- ç›¸åº”åœ°åœ¨ `qwen3_5.py`ã€`qwen3_next.py` ä¸­è°ƒç”¨æ—¶ä¼ å…¥æ–°å‚æ•°ï¼Œç¡®ä¿æ¨¡å‹è¿è¡Œæ—¶ä½¿ç”¨æ­£ç¡®çš„ dtypeã€‚  

**ğŸ¯ å½±å“èŒƒå›´**  
- `vllm/model_executor/layers/mamba/mamba_utils.py`  
- `vllm/model_executor/models/config.py`ï¼ˆæ–°å¢ Qwen3.5 é…ç½®æ ¡éªŒï¼‰  
- `vllm/model_executor/models/qwen3_5.py`ã€`qwen3_next.py`ï¼ˆdtype ä¼ é€’è·¯å¾„ï¼‰  

**ğŸ’¡ å…³æ³¨å»ºè®®**  
1. **æµ‹è¯•è¦†ç›–**ï¼šä¸º Qwen3.5 / Qwen3â€‘Next æ·»åŠ å•å…ƒæµ‹è¯•ï¼ŒéªŒè¯åœ¨ `--mamba-ssm-cache-dtype=auto`ã€æ˜¾å¼æŒ‡å®šä»¥åŠä¸ HF é…ç½®ä¸ç¬¦ä¸‰ç§æƒ…å½¢ä¸‹ï¼Œ`cache_config.mamba_ssm_cache_dtype` çš„å®é™…å–å€¼ã€‚  
2. **å‘åå…¼å®¹**ï¼šç¡®è®¤å…¶ä»–æ¨¡å‹åœ¨æœªæ˜¾å¼è®¾ç½® `mamba_ssm_cache_dtype` æ—¶ä»ä¿æŒåŸæœ‰è¡Œä¸ºï¼ˆè¿”å›ç›¸åŒ dtypeï¼‰ï¼Œé¿å…æ„å¤–å†…å­˜/ç²¾åº¦å˜åŒ–ã€‚  
3. **æ–‡æ¡£æ›´æ–°**ï¼šåœ¨ä½¿ç”¨è¯´æ˜ä¸­åŠ å…¥ `--mamba-ssm-cache-dtype` å‚æ•°çš„é»˜è®¤é€»è¾‘åŠå¯¹ Qwen3.5 ç³»åˆ—çš„ç‰¹æ®Šå¤„ç†ã€‚  
4. **æ—¥å¿—ç›‘ç£**ï¼šåœ¨ç”Ÿäº§ç¯å¢ƒç›‘æ§æ—¥å¿—ï¼Œç¡®ä¿å½“ç”¨æˆ·è‡ªè¡Œè¦†ç›–æ—¶èƒ½å¤Ÿçœ‹åˆ°æ˜ç¡®çš„è­¦å‘Šï¼Œä»¥é˜²è¯¯è®¾å¯¼è‡´æ€§èƒ½å›é€€ã€‚  

æ€»ä½“è€Œè¨€ï¼Œæ­¤æ¬¡ä¿®å¤ç¡®ä¿äº† Qwen3 ç³»åˆ—åœ¨æ··åˆç²¾åº¦ç¼“å­˜ä¸‹çš„æ­£ç¡® dtype é€‰å–ï¼Œæå‡æ•°å€¼ä¸€è‡´æ€§å’Œæ˜¾å­˜åˆ©ç”¨ç‡ã€‚

---

### [Refactor] Pass full VllmConfig to Renderer (#34485)
**SHA**: `2f30821` | ğŸ”— [æŸ¥çœ‹æäº¤](https://github.com/vllm-project/vllm/commit/2f308214c0ff6cfa849879c5beb884192714f429)

**ğŸ¯ å˜æ›´ç±»å‹**ï¼šé‡æ„ï¼ˆå°†æ¸²æŸ“å™¨ä»å•ç‹¬çš„ `ModelConfig` æ”¹ä¸ºå®Œæ•´çš„ `VllmConfig`ï¼‰  
**âš¡ é‡è¦ç¨‹åº¦**ï¼šğŸŸ¡ ä¸­  
**ğŸ“‹ å˜æ›´æ‘˜è¦**ï¼šæœ¬æ¬¡æäº¤ç»Ÿä¸€æ¸²æŸ“å™¨çš„å…¥å£å‚æ•°ï¼Œæ”¹ä¸ºæ¥å— `VllmConfig`ï¼ˆåŒ…å« `ModelConfig`ã€`ObservabilityConfig` ç­‰ï¼‰è€Œéä»… `ModelConfig`ã€‚ä¸ºæ­¤åœ¨æ¸²æŸ“å™¨åŸºç±»ã€å„å­ç±»ã€æ³¨å†Œè¡¨ã€engineã€inputâ€‘processor ä»¥åŠç›¸å…³å•å…ƒæµ‹è¯•ä¸­å…¨éƒ¨æ¢è£… `VllmConfig`ï¼Œå¹¶åœ¨æµ‹è¯•ä¸­å¼•å…¥ `MockVllmConfig` åŒ…è£…åŸæœ‰çš„ `MockModelConfig`ã€‚  

**ğŸ¯ å½±å“èŒƒå›´**  
- `vllm/renderers/*`ï¼ˆBaseRendererã€HfRendererã€MistralRendererã€DeepseekV32Rendererã€Grok2Rendererã€TerratorchRendererï¼‰  
- `vllm/renderers/registry.py`ã€`vllm/renderers/base.py` ä¸­çš„ç±»å‹ç­¾åä¸å±æ€§å (`config` â†’ `model_config`)  
- `vllm/inputs/preprocess.py`ã€`vllm/v1/engine/*`ï¼ˆAsyncLLMã€LLMEngineã€InputProcessorï¼‰å¯¹æ¸²æŸ“å™¨çš„åˆå§‹åŒ–é€»è¾‘å…¨éƒ¨æ”¹ä¸ºä½¿ç”¨ `vllm_config`  
- å•å…ƒæµ‹è¯•æ–‡ä»¶å¤§é‡è¿ç§»è‡³ `MockVllmConfig` å¹¶ç›¸åº”ä¿®æ”¹ `_preprocess_prompt` è°ƒç”¨å‚æ•°  

**ğŸ’¡ å…³æ³¨å»ºè®®**  
1. **å‘åå…¼å®¹**ï¼šåº“çš„å…¬å…± API ä»ç„¶å¯èƒ½è¢«å¤–éƒ¨ç”¨æˆ·ä»¥ `ModelConfig` ç›´æ¥è°ƒç”¨æ¸²æŸ“å™¨ï¼Œå»ºè®®åœ¨ `renderer_from_config` ä¸­ä¿ç•™æ¥å— `ModelConfig` çš„åŒ…è£…å±‚æˆ–åœ¨æ–‡æ¡£æ˜ç¡®è¿ç§»è·¯å¾„ï¼Œé¿å…çªå‘ `TypeError`ã€‚  
2. **æ–‡æ¡£åŒæ­¥**ï¼šæ‰€æœ‰æ¶‰åŠæ¸²æŸ“å™¨å®ä¾‹åŒ–çš„æ–‡æ¡£ã€ç¤ºä¾‹ä»£ç ä»¥åŠ README ä¸­çš„ `Renderer.from_config` ä½¿ç”¨è¯´æ˜éœ€æ›´æ–°ä¸º `VllmConfig`ã€‚  
3. **ç±»å‹æ£€æŸ¥**ï¼šéƒ¨åˆ†æ–‡ä»¶ä»ä¿ç•™å¯¹ `self.config` çš„å¼•ç”¨ï¼ˆå¦‚ `BaseRenderer.__init__` æ³¨é‡Šæˆ–æ³¨è§£ï¼‰ï¼Œè¯·ç»Ÿä¸€ä¸º `self.model_config` å¹¶åˆ é™¤å†—ä½™å±æ€§ï¼Œé˜²æ­¢ IDE/`mypy` æŠ¥é”™ã€‚  
4. **æ€§èƒ½å½±å“**ï¼šå¯¹æ¸²æŸ“å™¨çš„å®ä¾‹åŒ–è·¯å¾„åªå¢åŠ äº†ä¸€ä¸ªåŒ…è£…å±‚ï¼Œå¼€é”€å¯å¿½ç•¥ï¼Œä½†è¯·åœ¨ CI ä¸­ç›‘æµ‹å¯åŠ¨æ—¶é—´ï¼Œç¡®ä¿æ²¡æœ‰å› é€’å½’å±æ€§è®¿é—®å¯¼è‡´çš„å»¶è¿Ÿã€‚  
5. **æµ‹è¯•è¦†ç›–**ï¼šç›®å‰å·²ä¿®æ”¹æ ¸å¿ƒæµ‹è¯•ï¼Œä½†ä»éœ€æ£€æŸ¥æœªå—å½±å“çš„é«˜å±‚å…¥å£ï¼ˆå¦‚ `vllm.entrypoints.openai`ï¼‰æ˜¯å¦ä»ä½¿ç”¨æ—§ç­¾åï¼Œç¡®ä¿æ‰€æœ‰é›†æˆæµ‹è¯•é€šè¿‡ã€‚  
6. **å¼‚å¸¸ä¿¡æ¯**ï¼šåœ¨ `renderer_from_config` ä¸­å¯¹ `model_config` ä¸ `vllm_config` çš„å­—æ®µè®¿é—®ç»Ÿä¸€ä½¿ç”¨ `vllm_config.model_config`ï¼Œä»¥å…å‡ºç°å±æ€§æœªå®šä¹‰çš„ `AttributeError`ã€‚  

æ€»ä½“è€Œè¨€ï¼Œæ”¹åŠ¨é›†ä¸­åœ¨ç»Ÿä¸€é…ç½®å¯¹è±¡ï¼Œæå‡äº†é…ç½®ç®¡ç†çš„ä¸€è‡´æ€§ã€‚ä½†åŠ¡å¿…ä¿è¯å‘åå…¼å®¹å¹¶åŒæ­¥æ–‡æ¡£ï¼Œä»¥å…ç”¨æˆ·å‡çº§åå‡ºç°ä½¿ç”¨é”™è¯¯ã€‚

---

### [Kernel] [Helion] [5/N] Add Helion Autotuning infrastructure (#34025)
**SHA**: `de13dd7` | ğŸ”— [æŸ¥çœ‹æäº¤](https://github.com/vllm-project/vllm/commit/de13dd781f1bb18fb5bbaf4535389053d98780f8)

**å˜æ›´ç±»å‹**ï¼šåŠŸèƒ½å¢å¼ºï¼ˆHelion è‡ªåŠ¨è°ƒä¼˜ï¼‰  
**é‡è¦ç¨‹åº¦**ï¼šğŸŸ¡ ä¸­  

**å˜æ›´æ‘˜è¦**  
1. æ–°å¢ `scripts/autotune_helion_kernels.py`ï¼Œæä¾› CLI è‡ªåŠ¨è°ƒä¼˜ Helium å†…æ ¸ã€æ”¯æŒåˆ—ä¸¾ã€å¼ºåˆ¶ã€æ‰¹é‡ç­‰é€‰é¡¹ã€‚  
2. ä¸º `vllm.kernels.helion.ConfigManager` å¢åŠ  `set_configã€has_configã€save_configsã€ensure_base_dir_writable`ï¼Œå®ç°å¢é‡å†™å…¥ä¸å†™æƒé™æ£€æŸ¥ã€‚  
3. åœ¨ `register.py` ä¸­æŠ½å– `create_helion_decorated_kernel`ï¼Œç»Ÿä¸€ `static_shapes=False` çš„é»˜è®¤è¡Œä¸ºï¼›ä¸º `HelionKernelWrapper` å¢åŠ  `register_input_generatorã€get_inputsã€run_autotune`ï¼Œæ”¯æ’‘è„šæœ¬æŒ‰é…ç½®è‡ªåŠ¨ç”Ÿæˆè¾“å…¥å¹¶è°ƒç”¨ Helion çš„ autotuneã€‚  

**å½±å“èŒƒå›´**  
- `vllm/kernels/helion`ï¼ˆé…ç½®ç®¡ç†ã€å†…æ ¸æ³¨å†Œã€è£…é¥°å™¨ï¼‰  
- æ–°å¢è„šæœ¬ `scripts/autotune_helion_kernels.py`ï¼ˆä¾èµ– GPUã€Helion åŒ…ï¼‰  

**å…³æ³¨å»ºè®®**  
- **å…¼å®¹æ€§**ï¼š`ConfigManager` å•ä¾‹åœ¨å¤šè¿›ç¨‹/å¤šçº¿ç¨‹ç¯å¢ƒä»ä¼šå¤ç”¨åŒä¸€å®ä¾‹ï¼Œå»ºè®®åœ¨æ–‡æ¡£è¯´æ˜æˆ–ä»£ç ä¸­åŠ å…¥çº¿ç¨‹å®‰å…¨/è¿›ç¨‹å®‰å…¨çš„ä½¿ç”¨è­¦ç¤ºã€‚  
- **æ€§èƒ½**ï¼šè‡ªåŠ¨è°ƒä¼˜æ—¶æ¯å®Œæˆä¸€ä¸ªé…ç½®å°±è°ƒç”¨ `save_configs`ï¼Œä¼šé¢‘ç¹å†™ç£ç›˜ï¼Œå¯è€ƒè™‘æ‰¹é‡å†™æˆ–ç¼“å­˜åç»Ÿä¸€æŒä¹…åŒ–ã€‚  
- **é”™è¯¯å¤„ç†**ï¼šè„šæœ¬åœ¨è¯»å–/å†™å…¥é…ç½®ç›®å½•æ—¶ä»…æŠ›å‡º `OSError`ï¼Œå»ºè®®æ•è·å¹¶æç¤ºç”¨æˆ·ç›®å½•ä¸å¯å†™æˆ–ç£ç›˜æ»¡çš„å…·ä½“åŸå› ã€‚  
- **æµ‹è¯•**ï¼šä¸º `ConfigSet.set_configã€has_configã€save_configs` å¢åŠ å•å…ƒæµ‹è¯•ï¼ŒéªŒè¯å¹³å°åå¤§å°å†™ã€é‡å¤å†™å…¥è¦†ç›–ä»¥åŠå¤±æ•ˆè·¯å¾„çš„å¼‚å¸¸è¡Œä¸ºã€‚  
- **æ–‡æ¡£**ï¼šåœ¨ vLLM æ–‡æ¡£ä¸­è¡¥å…… â€œHelion è‡ªåŠ¨è°ƒä¼˜â€ ä½¿ç”¨è¯´æ˜ï¼Œåˆ—å‡ºå¿…é¡»çš„ `helion` ä¾èµ–ã€GPU ç¯å¢ƒä»¥åŠå¦‚ä½•ç¼–å†™ `register_input_generator`ã€‚  

ä»¥ä¸Šæ”¹åŠ¨ä¸º Helion å†…æ ¸æä¾›äº†ç”Ÿäº§çº§çš„è‡ªåŠ¨è°ƒä¼˜å…¥å£ï¼Œä½†éœ€å…³æ³¨å†™å…¥é¢‘ç‡ã€è·¨è¿›ç¨‹å®‰å…¨ä»¥åŠä½¿ç”¨å‰ç½®æ¡ä»¶çš„æ˜ç¡®æç¤ºã€‚

---

### [Refactor] Simplify BOS/EOS token handling (#34435)
**SHA**: `ea5ff3a` | ğŸ”— [æŸ¥çœ‹æäº¤](https://github.com/vllm-project/vllm/commit/ea5ff3a1f60e1b9f01af17260608009c184e7ff0)

**ğŸ¯ å˜æ›´æ¦‚è§ˆ**  
æœ¬æ¬¡ PR å°† **BOS/EOS** çš„è·å–ç»Ÿä¸€åˆ° `SamplingParams` ä¸ `BaseRenderer`ï¼Œå»æ‰äº†åœ¨ `Request / EngineCoreRequest` ç­‰å¯¹è±¡ä¸­ç‹¬ç«‹çš„ `eos_token_id` å‚æ•°ã€‚æ–°å¢ `SamplingParams._eos_token_id` ä¸åªè¯»å±æ€§ `eos_token_id`ï¼Œå¹¶åœ¨ `update_from_generation_config` ä¸­ç»Ÿä¸€æ³¨å…¥ï¼›`BaseRenderer` è´Ÿè´£ä»åº•å±‚ tokenizer è¯»å– `bos/eos` å¹¶æä¾› `get_bos_token_id / get_eos_token_id`ã€‚åŸæœ‰çš„ `Request.eos_token_id`ã€`EngineCoreRequest.eos_token_id` ä»ä¿ç•™ä½†æ ‡è®°ä¸º **deprecated**ï¼Œå¹¶è½¬å‘åˆ° `sampling_params.eos_token_id`ã€‚ç›¸åº”çš„æµ‹è¯•ã€å·¥å…·ä»¥åŠå†…éƒ¨è°ƒç”¨å…¨éƒ¨æ”¹ä¸ºä¸å†æ˜¾å¼ä¼ é€’ `eos_token_id`ï¼Œæ”¹ç”¨ `sampling_params.update_from_generation_config(..., eos_token_id)`ã€‚

**âš¡ å½±å“èŒƒå›´**  
- **æ ¸å¿ƒæ¨¡å—**ï¼š`vllm/sampling_params.pyã€vllm/v1/request.pyã€vllm/v1/engine/__init__.pyã€vllm/v1/engine/input_processor.pyã€vllm/v1/core/sched/utils.pyã€vllm/inputs/preprocess.pyã€vllm/renderers/base.py`ã€‚  
- **ç»“æ„åŒ–è¾“å‡º**ï¼š`vllm/v1/structured_output/utils.py` ç›´æ¥ä½¿ç”¨ `tokenizer.eos_token_id`ã€‚  
- **æµ‹è¯•å¥—ä»¶**ï¼šå¤§é‡ `tests/*` ä¸­çš„ `eos_token_id=` å‚æ•°è¢«åˆ é™¤æˆ–æ”¹ä¸º `sampling_params.update_from_generation_config`ã€‚  
- **æ—¥å¿—/è­¦å‘Š**ï¼š`BaseRenderer` ä¸­åŠ å…¥ `logger.warning_once`ï¼Œä¿æŒåŸæœ‰â€œtokenizer æœªåˆå§‹åŒ–â€æç¤ºã€‚

**ğŸ’¡ å…³æ³¨å»ºè®®**  
1. **å‘åå…¼å®¹**ï¼šè™½ç„¶å·²æ ‡è®° `eos_token_id` ä¸º deprecatedï¼Œä½†ä»å¯èƒ½æœ‰å¤–éƒ¨ä»£ç ç›´æ¥è®¿é—®ï¼Œå»ºè®®åœ¨ä¸‹ä¸€ä¸ª major ç‰ˆæœ¬å‰å½»åº•ç§»é™¤å¹¶åœ¨æ–‡æ¡£ä¸­è¯´æ˜è¿ç§»è·¯å¾„ã€‚  
2. **`SamplingParams.update_from_generation_config`** ç°åœ¨ä¼šåœ¨ `ignore_eos=False` æ—¶æŠŠ `eos_token_id` å†™å…¥ç§æœ‰å­—æ®µï¼›è¯·ç¡®ä¿æ‰€æœ‰åˆ›å»º `SamplingParams` çš„ä»£ç åœ¨ä½¿ç”¨å‰è°ƒç”¨æ­¤æ–¹æ³•ï¼Œå¦åˆ™ `eos_token_id` ä¸º `None` å¯èƒ½å¯¼è‡´æ„å¤–çš„ STOP è¡Œä¸ºã€‚  
3. **å¤šæ¨¡æ€ / LoRA åœºæ™¯**ï¼š`eos_token_id` ä»å¯èƒ½å›  LoRA è°ƒæ•´è€Œä¸åŒï¼Œç¡®ä¿ `SamplingParams` èƒ½åœ¨æ¯ä¸ªè¯·æ±‚çº§åˆ«è¢«æ­£ç¡®æ›´æ–°ï¼ˆå½“å‰å®ç°å·²æ”¯æŒï¼‰ã€‚  
4. **æ€§èƒ½**ï¼šå°† BOS/EOS è¯»å–æ¬åˆ°æ¸²æŸ“å™¨å±‚ï¼Œé¿å…åœ¨æ¯æ¡è¯·æ±‚æ„é€ æ—¶é‡å¤è®¿é—® tokenizerï¼Œç†è®ºä¸Šä¸ä¼šäº§ç”Ÿé¢å¤–å¼€é”€ï¼Œä½†è¯·ç•™æ„ `BaseRenderer.get_eos_token_id` åœ¨å¤šçº¿ç¨‹/å¼‚æ­¥ç¯å¢ƒä¸­çš„å¹¶å‘å®‰å…¨ï¼ˆç›®å‰ä»…è¯»å–å±æ€§ï¼Œå®‰å…¨æ€§è¾ƒé«˜ï¼‰ã€‚  
5. **æ–‡æ¡£/ç¤ºä¾‹**ï¼šæ›´æ–° READMEã€API æ–‡æ¡£ä»¥åŠä¾‹å­ï¼Œæ˜ç¡® **ä¸å†åœ¨ `Request` æ„é€ å‡½æ•°ä¸­ä¼ å…¥ `eos_token_id`**ï¼Œè€Œæ˜¯é€šè¿‡ `SamplingParams` æˆ– `generation_config` æ³¨å…¥ã€‚  

æ€»ä½“æ¥çœ‹ï¼Œæ­¤æ¬¡é‡æ„ç®€åŒ–äº† BOS/EOS çš„ç®¡ç†ï¼Œç»Ÿä¸€äº†å…¥å£ï¼Œé™ä½äº† API å¤æ‚åº¦ï¼Œæµ‹è¯•é€šè¿‡ç‡ä¿æŒä¸å˜ï¼ˆä»…åˆ å‡å†—ä½™å‚æ•°ï¼‰ï¼Œåç»­åªè¦æ³¨æ„ä¸Šè¿°è¿ç§»ç»†èŠ‚å³å¯å®‰å…¨ä½¿ç”¨ã€‚

---

### [Core] Profiler improvements and lazy initialization (#33198)
**SHA**: `4453ba8` | ğŸ”— [æŸ¥çœ‹æäº¤](https://github.com/vllm-project/vllm/commit/4453ba8d9ec8e35d68084a118f35ce5c48b5dae6)

**ğŸ¯ å˜æ›´ç±»å‹**ï¼šåŠŸèƒ½å¢å¼ºï¼ˆProfiler æ”¹è¿› + lazy åˆå§‹åŒ–ï¼‰  
**âš¡ é‡è¦ç¨‹åº¦**ï¼šğŸŸ¡ ä¸­  
**ğŸ“‹ å˜æ›´æ‘˜è¦**ï¼šä¸º vLLM æ·»åŠ äº† `profile_prefix` å‚æ•°ï¼Œæ”¯æŒè‡ªå®šä¹‰ trace æ–‡ä»¶å‰ç¼€ï¼›æ–°å¢ `get_worker_rank_suffix` ä»¥åœ¨å¤šå¹¶è¡Œç»´åº¦ï¼ˆDP/PP/TP/DCP/EPï¼‰ä¸Šç”Ÿæˆç»Ÿä¸€çš„ rank æ ‡è¯†ï¼Œå¹¶åœ¨ GPU/CPU worker ä¸­å®ç°äº† profiler çš„ **æƒ°æ€§åˆ›å»º**ï¼Œåªæœ‰ç¬¬ä¸€æ¬¡ `start_profile` æ—¶æ‰å®ä¾‹åŒ–å¯¹åº”çš„ Wrapperï¼ŒåŒæ—¶åŠ å…¥äº†å¯¹éæ³• profiler é…ç½®çš„æ£€æŸ¥ã€‚  
**ğŸ¯ å½±å“èŒƒå›´**ï¼š`vllm/distributed/utils.py`ã€`vllm/entrypoints/llm.py`ã€`vllm/v1/engine/*`ã€`vllm/v1/engine/core_client.py`ã€`vllm/v1/executor/abstract.py`ã€`vllm/v1/metrics/loggers.py`ã€`vllm/v1/worker/cpu_worker.py`ã€`vllm/v1/worker/gpu_worker.py`ã€‚  

**ğŸ’¡ å…³æ³¨å»ºè®®**  

1. **å‘åå…¼å®¹**ï¼šæ‰€æœ‰ `profile()`ã€`profile_async()` æ¥å£å‡æ–°å¢äº† `profile_prefix` å‚æ•°ï¼Œé»˜è®¤ `None` ä¿æŒåŸè¡Œä¸ºï¼Œç¡®ä¿å·²æœ‰è°ƒç”¨ä¸å—å½±å“ã€‚  
2. **lazy åˆå§‹åŒ–**ï¼š`gpu_worker.profile` ä¸­é¦–æ¬¡è°ƒç”¨ä¼šåˆ›å»º `TorchProfilerWrapper`/`CudaProfilerWrapper`ã€‚è‹¥åŒä¸€ worker å¤šæ¬¡ `start_profile`ï¼Œä¼šé‡å¤è°ƒç”¨ `start()`ï¼Œä½†ä¸ä¼šé‡æ–°å®ä¾‹åŒ–ï¼Œéœ€ç¡®è®¤åº•å±‚ Wrapper å¯¹ `start()` çš„å¹‚ç­‰æ€§ã€‚  
3. **trace åç§°**ï¼š`get_worker_rank_suffix` ä¾èµ–å¹¶è¡ŒçŠ¶æ€ï¼ˆDP/PP/TP/DCP/EPï¼‰ï¼Œåœ¨æœªåˆå§‹åŒ–æ—¶è¿”å›ç©ºæˆ–ä»… `rankX`ï¼Œé¿å…æŠ›å¼‚å¸¸ã€‚å»ºè®®åœ¨æ–‡æ¡£ä¸­è¯´æ˜åœ¨å•è¿›ç¨‹æˆ–æœªä½¿ç”¨å¹¶è¡Œæ—¶çš„è¿”å›æ ¼å¼ã€‚  
4. **å¼‚å¸¸å¤„ç†**ï¼š`gpu_worker.profile` ç°åœ¨åœ¨æœªå¯ç”¨ profiler æ—¶æŠ›å‡ºç»Ÿä¸€é”™è¯¯ä¿¡æ¯ï¼ŒåŒæ—¶åœ¨ `stop` æ—¶åŠ å…¥ â€œprofiler not startedâ€ è­¦å‘Šï¼Œæå‡å¯è°ƒè¯•æ€§ã€‚  
5. **æµ‹è¯•è¦†ç›–**ï¼šæ–°å¢å•å…ƒæµ‹è¯•åº”è¦†ç›–ï¼šâ‘  `profile_prefix` å¸¦/ä¸å¸¦æ—¶çš„ trace åç§°ï¼›â‘¡ å¤šå¹¶è¡Œç»´åº¦ä¸‹çš„ `get_worker_rank_suffix` æ­£ç¡®æ€§ï¼›â‘¢ lazy åˆ›å»ºè¿‡ç¨‹ï¼ˆç¡®ä¿åªå®ä¾‹åŒ–ä¸€æ¬¡ï¼‰ï¼›â‘£ éæ³• profiler é…ç½®æŠ› `ValueError`ã€‚  
6. **æ—¥å¿—/æ–‡æ¡£**ï¼š`torch` profiler çš„ `worker_name` å·²æ”¹ä¸ºå®Œæ•´çš„ `trace_name`ï¼Œè¯·åœ¨å‘è¡Œè¯´æ˜ä¸­æ›´æ–°ç¤ºä¾‹å‘½ä»¤ï¼Œè¯´æ˜ `--profiler-config.profiler` çš„å¯é€‰å€¼ä»¥åŠ `profile_prefix` çš„ä½¿ç”¨æ–¹å¼ã€‚  

æ•´ä½“æ¥çœ‹ï¼Œæ”¹åŠ¨æå‡äº† Profiling çš„å¯å®šåˆ¶æ€§å’Œèµ„æºä½¿ç”¨æ•ˆç‡ï¼Œä½†éœ€æ³¨æ„å¤šçº¿ç¨‹/å¤šè¿›ç¨‹ ç¯å¢ƒä¸‹çš„æƒ°æ€§å®ä¾‹åŒ–æ˜¯å¦ä¼šäº§ç”Ÿç«äº‰æ¡ä»¶ï¼Œå»ºè®®åœ¨é«˜å¹¶å‘å¯åŠ¨åœºæ™¯ä¸‹åŠ å…¥é”æˆ– `once` æ£€æŸ¥ã€‚

---

### [Core] Add sleep level 0 mode with enqueue/wait pattern (#33195)
**SHA**: `aa181c9` | ğŸ”— [æŸ¥çœ‹æäº¤](https://github.com/vllm-project/vllm/commit/aa181c923bf83b6f8c4ce5613492a6b410c0c535)

**ğŸ¯ å˜æ›´ç±»å‹**ï¼šåŠŸèƒ½å¢å¼ºï¼ˆæ–°å¢ enqueue / wait_for_completion æ¥å£å¹¶å®ç° sleepâ€‘levelâ€¯0ï¼‰  
**âš¡ é‡è¦ç¨‹åº¦**ï¼šğŸŸ¡ ä¸­  
**ğŸ“‹ å˜æ›´æ‘˜è¦**ï¼šåœ¨ `vllm.entrypoints.llm.LLM` ä¸­åŠ å…¥ **éé˜»å¡æäº¤** (`enqueue`) ä¸ **ç»Ÿä¸€æ”¶é›†ç»“æœ** (`wait_for_completion`) ä¸¤ä¸ª APIï¼›åœ¨å¼•æ“å±‚å®ç° **sleepâ€¯levelâ€¯0**ï¼ˆä»…æš‚åœè°ƒåº¦ä½†ç»§ç»­æ¥å—è¯·æ±‚ï¼‰ï¼Œå¹¶ç›¸åº”è°ƒæ•´ `sleep`ã€`wake_up`ã€`is_sleeping`ã€è°ƒåº¦å¾ªç¯ä»¥åŠè¯·æ±‚æ ¡éªŒè¿”å›å€¼ã€‚  

**ğŸ¯ å½±å“èŒƒå›´**  
- `vllm.entrypoints.llm`ï¼ˆå¯¹å¤– APIï¼‰  
- `vllm/v1/engine/core.py`ï¼ˆè°ƒåº¦å™¨æš‚åœ/æ¢å¤ã€sleepâ€¯logicï¼‰  
- `vllm/v1/engine/async_llm.py`ï¼ˆå¼‚æ­¥ sleep å®ç°ï¼‰  
- `vllm/v1/engine/llm_engine.py`ï¼ˆæ—¥å¿—è®°å½•æ¡ä»¶ï¼‰  
- ç›¸å…³å†…éƒ¨å·¥å…·å‡½æ•°ï¼ˆ`_validate_and_add_requests`ã€`_run_engine`ï¼‰  

**ğŸ’¡ å…³æ³¨å»ºè®®**  

1. **æ¥å£å…¼å®¹**ï¼š`enqueue` ç°åœ¨è¿”å› `list[str]`ï¼ˆrequest_idï¼‰ï¼Œè€ŒåŸ `generate` ä»è¿”å› `RequestOutput`ã€‚æ–‡æ¡£éœ€æ˜ç¡®ä¸¤å¥—è°ƒç”¨è·¯å¾„çš„ä½¿ç”¨åœºæ™¯ä»¥åŠè¿”å›å·®å¼‚ï¼Œé¿å…ç”¨æˆ·è¯¯æŠŠ `enqueue` å½“åŒæ­¥è°ƒç”¨ã€‚  

2. **å¹¶å‘å®‰å…¨**ï¼š`enqueue` åªå°†è¯·æ±‚æ”¾å…¥é˜Ÿåˆ—ï¼Œå®é™…æ‰§è¡Œåœ¨ `wait_for_completion` ä¸­è§¦å‘ã€‚è‹¥åœ¨ `sleep(level=0)` æœŸé—´è°ƒç”¨ `enqueue`ï¼Œè¯·æ±‚ä¼šè¢«ç§¯ç´¯ä½†ä¸è¢«å¤„ç†ï¼Œå¿…é¡»ä¿è¯ `wake_up(tags=["scheduling"])` èƒ½æ¢å¤è°ƒåº¦ï¼Œå¦åˆ™è¯·æ±‚ä¼šæ°¸ä¹…å¡ä½ã€‚å»ºè®®åœ¨ `enqueue` ä¸­æ£€æµ‹ `_scheduler_paused` å¹¶ç»™å‡ºæç¤ºæˆ–è‡ªåŠ¨å”¤é†’ï¼ˆå¯é€‰ï¼‰ã€‚  

3. **çŠ¶æ€æŸ¥è¯¢**ï¼š`is_sleeping` ç°åŒæ—¶æ£€æŸ¥è°ƒåº¦æš‚åœå’Œ executor çš„ç¡çœ çŠ¶æ€ã€‚å¤–éƒ¨ä»£ç è‹¥ä»…ä¾æ® `is_sleeping()` åˆ¤æ–­æ˜¯å¦å¯ä»¥æäº¤è¯·æ±‚ï¼Œéœ€è¦äº†è§£ä¸¤è€…çš„åŒºåˆ«ï¼Œå¿…è¦æ—¶æä¾›æ›´ç»†ç²’åº¦çš„çŠ¶æ€ APIï¼ˆå¦‚ `is_scheduler_paused`ï¼‰ã€‚  

4. **é”™è¯¯ä¼ æ’­**ï¼š`_validate_and_add_requests` ç°åœ¨è¿”å› `added_request_ids`ï¼Œä½†åœ¨å¼‚å¸¸è·¯å¾„ä¼šå…ˆ `abort_request` å†æŠ›å¼‚å¸¸ã€‚ç¡®è®¤ä¸Šå±‚ï¼ˆå¦‚ `enqueue`ï¼‰åœ¨æ•è·å¼‚å¸¸åä¸ä¼šæ³„æ¼å·²åˆ†é…çš„ request_idã€‚  

5. **æ€§èƒ½å½±å“**ï¼šåœ¨ `run_busy_loop` ä¸­åŠ å…¥ `_scheduler_paused` æ£€æŸ¥ï¼Œè°ƒåº¦æš‚åœæ—¶ä»ä¼šè½®è¯¢ `input_queue` ä¸ `batch_queue`ï¼ˆä½†ä¸æ‰§è¡Œå¼•æ“æ­¥éª¤ï¼‰ï¼Œè¿™å¢åŠ äº†ç©ºè½¬å¼€é”€ã€‚å¯è€ƒè™‘åœ¨æš‚åœæ—¶ç›´æ¥ `await asyncio.sleep` æˆ–è®© `run_busy_loop` è¿›å…¥é˜»å¡ç­‰å¾…ï¼Œä»¥é™ä½ CPU å ç”¨ã€‚  

6. **æµ‹è¯•è¦†ç›–**ï¼šæ–°å¢çš„ enqueueâ€‘wait æ¨¡å¼ã€sleepâ€¯0 ä»¥åŠè°ƒåº¦æ¢å¤è·¯å¾„éœ€è¦è¡¥å……å•å…ƒ/é›†æˆæµ‹è¯•ï¼Œå°¤å…¶æ˜¯ä»¥ä¸‹åœºæ™¯ï¼š  
   - `enqueue` â†’ `sleep(0)` â†’ `wait_for_completion`ï¼ˆåº”è¿”å›æ‰€æœ‰ç»“æœï¼‰  
   - å¹¶å‘ `enqueue` ä¸ `wake_up(tags=["scheduling"])` åŒæ—¶è¿›è¡Œçš„ race æ¡ä»¶  
   - `sleep(1/2)` å `wake_up()` æ˜¯å¦æ­£ç¡®æ¢å¤ GPU å†…å­˜å¹¶ç»§ç»­å¤„ç†å‰©ä½™è¯·æ±‚  

7. **æ–‡æ¡£ä¸ç¤ºä¾‹**ï¼šåœ¨ README / API æ–‡æ¡£ä¸­åŠ å…¥ç¤ºä¾‹ä»£ç ï¼Œå±•ç¤ºå¦‚ä½•ä½¿ç”¨ `enqueue` + `wait_for_completion` å®ç° **producerâ€‘consumer** æˆ– **æ‰¹é‡æäº¤** åœºæ™¯ï¼Œä»¥åŠå¦‚ä½•é€šè¿‡ `sleep(0)` å®ç° â€œæš‚åœè°ƒåº¦â€ çš„æœåŠ¡æ²»ç†ã€‚  

æ€»ä½“è€Œè¨€ï¼Œæ­¤æ¬¡æ”¹åŠ¨ä¸º vLLM å¼•å…¥äº†æ›´çµæ´»çš„è¯·æ±‚æäº¤æ¨¡å‹å’Œè½»é‡çº§æš‚åœåŠŸèƒ½ï¼Œæå‡äº†åœ¨å¤šç§Ÿæˆ·æˆ–åŠ¨æ€æ¨¡å‹åˆ‡æ¢åœºæ™¯ä¸‹çš„å¯ç”¨æ€§ã€‚ä½†éœ€æ³¨æ„è°ƒåº¦æš‚åœçš„çŠ¶æ€ä¸€è‡´æ€§ã€å¼‚å¸¸å¤„ç†ä»¥åŠç›¸åº”çš„æµ‹è¯•/æ–‡æ¡£æ”¯æ’‘ï¼Œä»¥é˜²å‡ºç°è¯·æ±‚ä¸¢å¤±æˆ–æ­»é”ã€‚

---

### [Frontend] Enable generic structured_outputs for responses API (#33709)
**SHA**: `be7370d` | ğŸ”— [æŸ¥çœ‹æäº¤](https://github.com/vllm-project/vllm/commit/be7370daf3596da71776375b9aba6dd712646fdc)

**ğŸ¯ å˜æ›´ç±»å‹**ï¼šåŠŸèƒ½å¢å¼º  
**âš¡ é‡è¦ç¨‹åº¦**ï¼šğŸŸ¡ ä¸­  

**ğŸ“‹ å˜æ›´æ‘˜è¦**  
- åœ¨ `ResponsesRequest` ä¸­æ–°å¢ `structured_outputs` å­—æ®µï¼Œç”¨äºç›´æ¥ä¼ é€’ç»“æ„åŒ–è¾“å‡ºå‚æ•°ã€‚  
- `to_sampling_params` ç°åœ¨ä¼šæŠŠè¯¥å­—æ®µè½¬å‘åˆ° `SamplingParams`ï¼Œå¹¶åœ¨ `text.format` ä¸º OpenAIâ€‘style `json_schema` æ—¶è‡ªåŠ¨æ„é€  `StructuredOutputsParams`ã€‚  
- è‹¥åŒæ—¶æä¾› `structured_outputs` ä¸ `text.format`ï¼ˆjson_schemaï¼‰ï¼Œä¼šæŠ›å‡ºæ˜ç¡®çš„ `ValueError`ã€‚  
- ä¸ºæ­¤æ–°å¢/æ‰©å±•å•å…ƒæµ‹è¯•ï¼Œè¦†ç›–æ­£å¸¸ä¼ é€’ã€å†²çªæ£€æµ‹ä»¥åŠ seed è¾¹ç•Œæ ¡éªŒã€‚

**ğŸ¯ å½±å“èŒƒå›´**  
- `vllm.entrypoints.openai.responses.protocol`ï¼ˆè¯·æ±‚æ¨¡å‹ä¸å‚æ•°æ˜ å°„ï¼‰  
- `vllm.sampling_params.StructuredOutputsParams`ï¼ˆç»“æ„åŒ–è¾“å‡ºé…ç½®ï¼‰  
- OpenAIâ€‘compatible æ¥å£çš„è°ƒç”¨æ–¹ä»¥åŠå¯¹åº”å•å…ƒæµ‹è¯•  

**ğŸ’¡ å…³æ³¨å»ºè®®**  
1. **æ–‡æ¡£/Schema**ï¼šåœ¨ OpenAPI / pydantic schema ä¸­åŠ å…¥ `structured_outputs` çš„è¯´æ˜ï¼Œé˜²æ­¢ä½¿ç”¨è€…è¯¯ä»¥ä¸ºä¸ `text.format` å…±å­˜ã€‚  
2. **å‘åå…¼å®¹**ï¼šé»˜è®¤ `None` ä¸å½±å“æ—§è°ƒç”¨ï¼Œä½†è‹¥å·²æœ‰ `text.format=json_schema` çš„ç”¨æˆ·ï¼Œéœ€è¦ç¡®è®¤ä¸ä¼šå› å†²çªæ£€æµ‹å¯¼è‡´å¼‚å¸¸ã€‚  
3. **é”™è¯¯ä¿¡æ¯**ï¼šå½“å‰é”™è¯¯ä¿¡æ¯å·²åŒ…å«å­—æ®µåï¼Œå¯åœ¨å¼‚å¸¸æ•è·å±‚ç»Ÿä¸€åŒ…è£…ï¼Œä»¥æä¾›æ›´å‹å¥½çš„ HTTP 400 å“åº”ã€‚  
4. **æœªå®ç°çš„ json_object**ï¼šè‹¥è®¡åˆ’æ”¯æŒ `json_object`ï¼Œåº”æå‰åœ¨ä»£ç ä¸­ç»™å‡º `NotImplementedError` æˆ–åœ¨æ–‡æ¡£ä¸­å£°æ˜é™åˆ¶ã€‚  
5. **æµ‹è¯•è¦†ç›–**ï¼šå»ºè®®æ·»åŠ è·¨ç‰ˆæœ¬çš„é›†æˆæµ‹è¯•ï¼Œç¡®ä¿ `structured_outputs` ä¸å…¶ä»–é‡‡æ ·å‚æ•°ï¼ˆå¦‚ `temperature`ã€`top_p`ï¼‰å…±åŒä½œç”¨æ—¶è¡Œä¸ºä¸€è‡´ã€‚  

æ€»ä½“æ¥çœ‹ï¼Œæ­¤æ¬¡æ”¹åŠ¨ä¸ºç»“æ„åŒ–è¾“å‡ºæä¾›äº†æ›´ç›´è§‚çš„ APIï¼Œä»£ç å®ç°æ¸…æ™°ï¼Œå”¯ä¸€éœ€è¦æ³¨æ„çš„æ˜¯æ–‡æ¡£åŒæ­¥ä¸å†²çªæ£€æµ‹çš„ç”¨æˆ·ä½“éªŒã€‚

---

### [Kernel] Support Flashinfer trtllm fused MoE non gated FP8 & NVFP4 (#33506)
**SHA**: `f120bd4` | ğŸ”— [æŸ¥çœ‹æäº¤](https://github.com/vllm-project/vllm/commit/f120bd42d3daf733425d7feaaeffc2a23ba71c17)

**ğŸ¯ å˜æ›´ç±»å‹**ï¼šåŠŸèƒ½å¢å¼º + Bug ä¿®å¤  
**âš¡ é‡è¦ç¨‹åº¦**ï¼šğŸŸ¡ ä¸­  
**ğŸ“‹ å˜æ›´æ‘˜è¦**  
- ä¸º FlashInferâ€‘TRTLLM MoE æ·»åŠ å¯¹ **éé—¨æ§(ReLU2â€‘NOâ€‘MUL)** ä¸ **é—¨æ§(SiLU/GELU)** ä¸¤ç±»æ¿€æ´»çš„å®Œæ•´æ”¯æŒï¼Œæ‰©å±•äº† FP8 ä¸ FP4 é‡åŒ–è·¯å¾„ã€‚  
- è°ƒæ•´æƒé‡/å°ºåº¦çš„æ’å¸ƒã€å¯¹é½é€»è¾‘ä»¥æ»¡è¶³ FlashInfer å¯¹ä¸­é—´ç»´åº¦çš„å¯¹é½è¦æ±‚ï¼ˆ16/128ï¼‰ï¼Œå¹¶åœ¨ kernel æ¥å£ä¸­æ˜¾å¼ä¼ é€’ `activation_type`ã€‚  
- å¢åŠ æµ‹è¯•éªŒè¯å‡½æ•° `check_accuracy`ï¼Œå¯¹æ¯”å®¹å·®æ”¾å®½è‡³ `atol=0.1ã€rtol=0.85ã€matchâ€¯â‰¥â€¯92.5%`ï¼Œå¹¶åœ¨å•å…ƒæµ‹è¯•ä¸­éå†ä¸¤ç§æ¿€æ´»ã€‚  

**ğŸ¯ å½±å“èŒƒå›´**  
- `vllm/model_executor/layers/fused_moe/flashinfer_trtllm_moe.py` â€“ æ¿€æ´»æ”¯æŒåˆ¤æ–­ã€å‡½æ•°ç­¾åã€è°ƒç”¨å‚æ•°ã€‚  
- `vllm/model_executor/layers/quantization/modelopt.py` â€“ æ–­è¨€æ›´æ–°ï¼Œæ¥å—ä¸¤ç§æ¿€æ´»ã€‚  
- `vllm/model_executor/layers/quantization/utils/flashinfer_fp4_moe.py`ã€`flashinfer_utils.py` â€“ æƒé‡æ’å¸ƒã€å¯¹é½ã€æ¿€æ´»â†’FlashInfer æšä¸¾æ˜ å°„ã€scale è®¡ç®—ã€‚  
- Test: `tests/kernels/moe/test_flashinfer.py` â€“ æ–°å¢æ¿€æ´»å‚æ•°åŒ–ã€ç²¾åº¦æ ¡éªŒå‡½æ•°ã€‚  

**ğŸ’¡ å…³æ³¨å»ºè®®**  
1. **å…¼å®¹æ€§æ£€æŸ¥**ï¼šåœ¨ç”Ÿäº§ç¯å¢ƒå‡çº§å‰ç¡®è®¤ä½¿ç”¨çš„ FlashInfer ç‰ˆæœ¬ â‰¥ 0.6.3ï¼Œæ—§ç‰ˆä¸æ”¯æŒ `activation_type` å‚æ•°ã€‚  
2. **æ€§èƒ½éªŒè¯**ï¼šå¯¹é½å¡«å……ä¼šå¯¼è‡´æ˜¾å­˜ç•¥å¢ï¼ˆä¸­é—´ç»´åº¦å¯¹é½ï¼‰ï¼Œå»ºè®®åœ¨å¤§æ¨¡å‹/å¤šå¡ç¯å¢ƒä¸‹è·‘åŸºå‡†ï¼Œç¡®è®¤ä¸ä¼šè§¦å‘ OOMã€‚  
3. **ä»£ç å®¡é˜…**ï¼š`activation_to_flashinfer_int` åªæ˜ å°„åˆ°å·²å®ç°çš„ FI æ¿€æ´»ï¼Œè‹¥åç»­æ–°å¢æ¿€æ´»éœ€åŒæ­¥æ›´æ–°è¯¥æ˜ å°„è¡¨ã€‚  
4. **å›é€€è·¯å¾„**ï¼š`_supports_no_act_and_mul` å·²æ”¹ä¸º `True`ï¼Œä½†ä»æœ‰éƒ¨åˆ† kernelï¼ˆå¦‚éé—¨æ§çš„ NVFP4ï¼‰å¯èƒ½å› å¯¹é½ä¸è¶³è€ŒæŠ¥é”™ï¼Œä¿æŒå¯¹ `rotate_weights_for_fi_trtllm_fp8_per_tensor_moe` çš„ `is_gated_activation` å‚æ•°ä¼ é€’æ­£ç¡®ã€‚  

æ€»ä½“è€Œè¨€ï¼Œæ­¤æ¬¡æäº¤æ˜¾è‘—æå‡äº† FlashInferâ€‘TRTLLM åœ¨å¤šæ¿€æ´»åœºæ™¯ä¸‹çš„å¯ç”¨æ€§ï¼ŒåŒæ—¶å¼•å…¥äº†å¯¹é½å¡«å……é€»è¾‘å’Œæ›´å®½æ¾çš„ç²¾åº¦æ ¡éªŒï¼Œéœ€åœ¨å‡çº§å‰å®Œæˆå…¼å®¹æ€§ä¸æ˜¾å­˜è¯„ä¼°ã€‚

---

### [Voxtral Realtime] Refactor & Improve buffering logic (#34428)
**SHA**: `6c0baee` | ğŸ”— [æŸ¥çœ‹æäº¤](https://github.com/vllm-project/vllm/commit/6c0baee61025f258c6d56830d0150feab34c45ab)

**ğŸ¯ å˜æ›´ç±»å‹**ï¼šé‡æ„ / åŠŸèƒ½å¢å¼º  
**âš¡ é‡è¦ç¨‹åº¦**ï¼šğŸŸ¡ ä¸­  
**ğŸ“‹ å˜æ›´æ‘˜è¦**  
æœ¬æ¬¡æäº¤å¯¹ Voxtral å®æ—¶è½¬å†™çš„ç¼“å†²é€»è¾‘åšäº†å¤§å¹…é‡æ„ï¼š  
1. æ–°å¢ `VoxtralRealtimeBuffer`ï¼Œä½¿ç”¨ `asyncio.Queue` ç»Ÿä¸€ç®¡ç†éŸ³é¢‘å—å’Œ tokenï¼Œå»é™¤äº†åŸæ¥çš„ `RealTimeAudioInput` ç±»ã€‚  
2. `VoxtralRealtimeBuffer.get_input_stream` è´Ÿè´£ç”Ÿæˆ `StreamingInput`ï¼Œå†…éƒ¨é€šè¿‡å¯¹å¸§å¤§å°ã€lookâ€‘ahead/back è¿›è¡Œé‡‡æ ·ç‡æ¢ç®—ï¼Œå®ç°äº†æ›´ç®€æ´çš„æ»‘åŠ¨çª—å£ã€‚  
3. `VoxtralRealtimeMultiModalProcessor` ç°åœ¨é€šè¿‡ `audio_config.get_num_delay_tokens()` è·å–å»¶è¿Ÿ token æ•°ã€‚  
4. ç›¸åº”çš„å•å…ƒæµ‹è¯• `test_voxtral_realtime_generator` ä¹Ÿæ”¹ä¸ºåŸºäºæ–° Buffer ä½¿ç”¨ã€‚  
5. ä¾èµ–ç‰ˆæœ¬ä» `mistral_common>=1.9.0` å‡çº§åˆ° `1.9.1`ï¼Œå¹¶åŒæ­¥äº† `requirements` æ–‡ä»¶ã€‚

**ğŸ¯ å½±å“èŒƒå›´**  
- `vllm/model_executor/models/voxtral_realtime.py`ï¼ˆæ ¸å¿ƒç¼“å†²å®ç°ï¼‰  
- `vllm/model_executor/models/voxtral.py`ï¼ˆpad è°ƒç”¨ç­¾åï¼‰  
- `vllm/v1/engine/async_llm.py`ï¼ˆä½¿ç”¨æ–°ç‰ˆ Bufferï¼‰  
- æµ‹è¯• `tests/models/multimodal/generation/test_voxtral_realtime.py`  
- ä¾èµ–å£°æ˜ `requirements/*`  

**ğŸ’¡ å…³æ³¨å»ºè®®**  
1. **å¹¶å‘å®‰å…¨**ï¼š`VoxtralRealtimeBuffer` åœ¨ `append_audio`ã€`append_tokens` ä¸ `get_input_stream` ä¹‹é—´ä½¿ç”¨å¤šä¸ª Queueï¼Œç¡®ä¿åœ¨å¼‚å¸¸æˆ–å–æ¶ˆæ—¶è°ƒç”¨ `queue.put_nowait(None)` ç»“æŸæµï¼Œå¦åˆ™å¯èƒ½å¯¼è‡´ `await self._audio_queue.get()` æ°¸ä¹…é˜»å¡ã€‚  
2. **å›é€€å…¼å®¹**ï¼š`AudioConfig.pad` å‚æ•°ä» `is_online_streaming` åˆ é™¤ï¼Œè‹¥æœ‰å¤–éƒ¨ä»£ç ä»ä¾èµ–æ—§ç­¾åéœ€åŒæ­¥æ›´æ–°ã€‚  
3. **æ€§èƒ½éªŒè¯**ï¼šæ–°å®ç°å–æ¶ˆäº† 30â€¯s é¢„åˆ†é…ç­–ç•¥ï¼Œæ”¹ä¸ºæŒ‰éœ€æ‰©å®¹ã€‚å»ºè®®åœ¨é•¿æ—¶æµå¼åœºæ™¯ä¸‹è·‘ä¸€æ¬¡å¤§æµé‡åŸºå‡†ï¼Œç¡®è®¤ä¸ä¼šå‡ºç°é¢‘ç¹çš„å†…å­˜é‡æ–°åˆ†é…ã€‚  
4. **æ–‡æ¡£æ›´æ–°**ï¼šæ–°å¢ `VoxtralRealtimeBuffer` ç±»å’Œå…¶ async æ¥å£ï¼ˆ`append_audio`ã€`append_tokens`ã€`get_input_stream`ï¼‰åº”åœ¨å¼€å‘è€…æ–‡æ¡£å’Œ API å‚è€ƒä¸­åŒæ­¥è¯´æ˜ã€‚  
5. **æµ‹è¯•è¦†ç›–**ï¼šå½“å‰ä»…è¦†ç›–äº†ç¦»çº¿æµå¼ï¼ˆ`StreamingMode.OFFLINE`ï¼‰è·¯å¾„ï¼Œè‹¥é¡¹ç›®è®¡åˆ’æ”¯æŒçœŸå®åœ¨çº¿æµå¼ï¼ˆ`StreamingMode.ONLINE`ï¼‰ï¼Œéœ€è¡¥å……ç›¸åº”å•å…ƒ/é›†æˆæµ‹è¯•ï¼ŒéªŒè¯ `feed_audio`ã€`feed_tokens` ä¸¤ä¸ªåå°ä»»åŠ¡çš„ååŒè¡Œä¸ºã€‚  

æ€»ä½“æ¥çœ‹ï¼Œæ­¤æ¬¡é‡æ„æ˜¾è‘—ç®€åŒ–äº†å®æ—¶è½¬å†™çš„éŸ³é¢‘â€‘token åŒæ­¥é€»è¾‘ï¼Œæå‡äº†ä»£ç å¯ç»´æŠ¤æ€§ï¼Œä½†åœ¨å¹¶å‘ç»ˆæ­¢ã€å‘åå…¼å®¹å’Œå¤§è§„æ¨¡æµå¼æ€§èƒ½æ–¹é¢ä»éœ€é¢å¤–éªŒè¯ã€‚

---

### [Voxstral Realtime] Enable tests (#33803)
**SHA**: `1100a97` | ğŸ”— [æŸ¥çœ‹æäº¤](https://github.com/vllm-project/vllm/commit/1100a97621ebbf226488268f47d0252b789276e6)

**ğŸ¯ å˜æ›´ç±»å‹**ï¼šå…¶ä»–ï¼ˆå¯ç”¨ Voxtral Realtime ç›¸å…³å•å…ƒæµ‹è¯•ï¼‰  
**âš¡ é‡è¦ç¨‹åº¦**ï¼šğŸŸ¡ ä¸­  

**ğŸ“‹ å˜æ›´æ‘˜è¦**  
1. ç§»é™¤å¯¹ Voxtralâ€‘Realtime æµ‹è¯•çš„ `skip`ï¼Œå¹¶åœ¨æµ‹è¯•å…¥å£åŠ å…¥ `--enforce-eager` ä¸ `--maxâ€‘modelâ€‘len 2048` å‚æ•°ã€‚  
2. åœ¨ `tests/models/registry.py` ä¸­å°† `VoxtralRealtimeGeneration` çš„ç¤ºä¾‹ä¿¡æ¯ä»å ä½ç¬¦æ”¹ä¸ºçœŸå®æ¨¡å‹ `mistralai/Voxtral-Mini-4B-Realtime-2602`ï¼Œå¹¶æ ‡è®° `enforce_eager=Trueã€tokenizer_mode="mistral"`ã€‚  
3. `vllm/model_executor/models/voxtral.py` æ–°å¢ `_validate_mm_placeholders` æ–¹æ³•çš„å ä½å®ç°ï¼Œä»¥ç»•è¿‡ Mistral tokenizer ä¸ HF å ä½ç¬¦è§„èŒƒä¸åŒ¹é…çš„é—®é¢˜ã€‚  
4. è°ƒæ•´ `test_common.py` ä¸­å¯¹è¯¥æ¨¡å‹çš„å¤„ç†æ­£ç¡®æ€§æµ‹è¯•ç›´æ¥ `skip`ï¼Œå¹¶åˆ æ‰æœªä½¿ç”¨çš„éŸ³é¢‘â€‘base64 è¾…åŠ©å‡½æ•°ã€‚  

**ğŸ¯ å½±å“èŒƒå›´**  
- **æµ‹è¯•å¥—ä»¶**ï¼š`tests/entrypoints/openai`, `tests/models/multimodal/generation`, `tests/models/multimodal/processing`, `tests/models/registry`ã€‚  
- **æ¨¡å‹æ‰§è¡Œå±‚**ï¼š`vllm/model_executor/models/voxtral.py`ï¼ˆå ä½ç¬¦éªŒè¯é€»è¾‘ï¼‰ã€‚  
- **æ¨¡å‹æ³¨å†Œè¡¨**ï¼š`vllm/model_registry.py`ï¼ˆç¤ºä¾‹ä¿¡æ¯ã€eager å¼ºåˆ¶ã€tokenizer æ¨¡å¼ï¼‰ã€‚  

**ğŸ’¡ å…³æ³¨å»ºè®®**  
1. **å ä½ç¬¦éªŒè¯**ï¼šå½“å‰å®ç°ä½¿ç”¨ `...`ï¼ˆçœç•¥å·ï¼‰è·³è¿‡æ ¡éªŒï¼Œåç»­åŠ¡å¿…è¡¥å…¨çœŸå®æ ¡éªŒé€»è¾‘ï¼Œé˜²æ­¢é”™è¯¯çš„å¤šæ¨¡æ€å ä½ç¬¦åœ¨ç”Ÿäº§ç¯å¢ƒæ³„æ¼ã€‚  
2. **æµ‹è¯•å¯é æ€§**ï¼šæ–°å¢çš„å®æ—¶æµæµ‹è¯•ä¾èµ–éŸ³é¢‘é‡‡æ ·ç‡è½¬æ¢å’Œ WebSocket é€šä¿¡ï¼ŒCI ç¯å¢ƒéœ€ç¡®ä¿ `librosa`ã€`numpy` ç­‰ä¾èµ–å®Œæ•´ï¼Œå¹¶ä¸”æœåŠ¡å™¨å¯åŠ¨å‚æ•° `--max-model-len 2048` ä¸å®é™…æ¨¡å‹é™åˆ¶åŒ¹é…ã€‚  
3. **æ–‡æ¡£åŒæ­¥**ï¼šåœ¨æ¨¡å‹åˆ—è¡¨/README ä¸­æ ‡æ³¨ Voxtralâ€‘Realtime å·²å¯ç”¨ï¼Œå¹¶è¯´æ˜éœ€è¦ `enforce_eager` æ‰èƒ½è¿è¡Œã€‚  
4. **å›å½’ç›‘æ§**ï¼šå› ä¸ºè·³è¿‡äº† `test_processing_correctness`ï¼Œå»ºè®®åœ¨åç»­å¼•å…¥çœŸæ­£çš„å ä½ç¬¦æµ‹è¯•ï¼Œä»¥é˜²æ­¢æ½œåœ¨çš„ tokenâ€‘toâ€‘audio å¯¹é½é”™è¯¯ã€‚  

æ€»ä½“æ¥çœ‹ï¼Œæœ¬æ¬¡æäº¤è§£é”äº† Voxtralâ€‘Realtime çš„è‡ªåŠ¨åŒ–éªŒè¯ï¼Œä¸ºåç»­åŠŸèƒ½è¿­ä»£æä¾›äº†æµ‹è¯•ä¾æ®ï¼Œä½†å ä½ç¬¦æ ¡éªŒçš„ä¸´æ—¶å®ç°éœ€å°½å¿«å®Œå–„ï¼Œä»¥å…ç•™ä¸‹éšè—ç¼ºé™·ã€‚

---

#### ğŸŸ¢ ä½é‡è¦åº¦å˜æ›´ (24)

### [GDN] Use CPU tensors to build GDN metadata (#34498)
**SHA**: `0916e79` | ğŸ”— [æŸ¥çœ‹æäº¤](https://github.com/vllm-project/vllm/commit/0916e7960bddf565c33153d2cf753e799de105b7)

**ğŸ¯ å˜æ›´ç±»å‹**ï¼šä»£ç é‡æ„  
**âš¡ é‡è¦ç¨‹åº¦**ï¼šğŸŸ¢ä½  
**ğŸ“‹ æ‘˜è¦**ï¼šåœ¨ GDN å…ƒæ•°æ®æ„å»ºä¸­æ”¹ç”¨ CPU å¼ é‡é¿å… CPUâ€‘GPU åŒæ­¥ï¼Œå¹¶åœ¨ utils ä¸­ä½¿ç”¨ `non_blocking=True` çš„å¤åˆ¶æå‡æ‹·è´æ•ˆç‡ã€‚

---

### [Bugfix] fix the import path in moe test utils.py (#34245)
**SHA**: `742d214` | ğŸ”— [æŸ¥çœ‹æäº¤](https://github.com/vllm-project/vllm/commit/742d214d6eeb1b0c92aabae36614be6a485fb94d)

**ğŸ¯ å˜æ›´ç±»å‹**ï¼šä»£ç é‡æ„  
**âš¡ é‡è¦ç¨‹åº¦**ï¼šğŸŸ¢ ä½  
**ğŸ“‹ æ‘˜è¦**ï¼šä¿®æ­£ `tests/kernels/moe/utils.py` ä¸­çš„å¯¼å…¥è·¯å¾„ï¼Œå°† `fused_moe`ã€`fused_topk` ç­‰æ¨¡å—çš„å¯¼å…¥è°ƒæ•´ä¸ºæ­£ç¡®çš„å­æ¨¡å—ï¼Œä»¥ç¡®ä¿å•å…ƒæµ‹è¯•èƒ½å¤Ÿæ­£ç¡®åŠ è½½ã€‚

---

### [Bug Fix] Fix MambaManager.cache_blocks() crash on null blocks in align mode (#34418)
**SHA**: `4137c5d` | ğŸ”— [æŸ¥çœ‹æäº¤](https://github.com/vllm-project/vllm/commit/4137c5dfa7c0de6c0ff74ad3774224b6b3280349)

**ğŸ¯ å˜æ›´ç±»å‹**ï¼šä»£ç é‡æ„  
**âš¡ é‡è¦ç¨‹åº¦**ï¼šğŸŸ¢ä½  
**ğŸ“‹ æ‘˜è¦**ï¼šåœ¨ `MambaManager.cache_blocks` ä¸­åŠ å…¥å¯¹ç©ºå— (`block.is_null`) çš„è·³è¿‡åˆ¤æ–­ï¼Œé˜²æ­¢å¯¹é½æ¨¡å¼ä¸‹å› ç©ºå—å¯¼è‡´çš„æ–­è¨€å´©æºƒï¼›åŒæ­¥æ·»åŠ é’ˆå¯¹è¯¥åœºæ™¯çš„å›å½’å•å…ƒæµ‹è¯•ã€‚

---

### [BugFix] Fix and optimize max_num_blocks_per_req calculation for MambaSpec (#34440)
**SHA**: `7a8a46d` | ğŸ”— [æŸ¥çœ‹æäº¤](https://github.com/vllm-project/vllm/commit/7a8a46ddcb05ba754e1f0f3f428ebbeb572d0f02)

**ğŸ¯ å˜æ›´ç±»å‹**ï¼šå…¶ä»–  
**âš¡ é‡è¦ç¨‹åº¦**ï¼šğŸŸ¢ä½  
**ğŸ“‹ æ‘˜è¦**ï¼šåœ¨ `gpu_model_runner.py` ä¸­é‡æ–°å®ç° KVâ€‘cache å—å¤§å°çš„æå–ï¼Œå»é™¤å¤šä½™åˆ—è¡¨å¹¶ç›´æ¥ä½¿ç”¨ `block_size`ï¼Œä¿®æ­£äº† `max_num_blocks_per_req` å¯¹ MambaSpec çš„è®¡ç®—é€»è¾‘ï¼Œé¿å…äº†ä¸å¿…è¦çš„ `max` æ“ä½œï¼Œæé«˜äº†æ­£ç¡®æ€§å’Œæ€§èƒ½ã€‚

---

### [CI/Build] Fix CUDA re-initialization error in distributed model tests (#34491)
**SHA**: `1b4e8e5` | ğŸ”— [æŸ¥çœ‹æäº¤](https://github.com/vllm-project/vllm/commit/1b4e8e53f87b2c6f5cd30d0eace501d7d2192236)

**å˜æ›´ç±»å‹**ï¼šæµ‹è¯•ä¿®æ”¹  
**é‡è¦ç¨‹åº¦**ï¼šğŸŸ¢ä½  
**æ‘˜è¦**ï¼šåœ¨ `test_voxtral_realtime.py` ä¸­å°† `VoxtralRealtimeBuffer` çš„å¯¼å…¥æ”¹ä¸ºæ‡’åŠ è½½ï¼Œé¿å…åˆ†å¸ƒå¼æ¨¡å‹æµ‹è¯•æ—¶å‡ºç° CUDA é‡åˆå§‹åŒ–é”™è¯¯ã€‚

---

### [Bugfix] Fix encoder cache underestimation for GLM-4V/GLM-OCR single image (#34483)
**SHA**: `dcf6ee8` | ğŸ”— [æŸ¥çœ‹æäº¤](https://github.com/vllm-project/vllm/commit/dcf6ee8592b4f33593feb579b7a420d155ada374)

**ğŸ¯ å˜æ›´ç±»å‹**ï¼šä»£ç é‡æ„/Bugfix  
**âš¡ é‡è¦ç¨‹åº¦**ï¼šğŸŸ¢ä½  
**ğŸ“‹ æ‘˜è¦**ï¼šä¿®æ­£ GLMâ€‘4V/GLMâ€‘OCR å•å›¾åƒåœºæ™¯ä¸‹å¯¹ encoder ç¼“å­˜çš„ä½ä¼°ã€‚æ–°å¢ `_get_image_max_pixels` è¯»å– HF å¤„ç†å™¨é…ç½®å¹¶åœ¨é¢„ç®—ä¼°ç®—æ—¶å¼ºåˆ¶ `num_frames=1`ï¼Œé˜²æ­¢å¤§å›¾å¯¼è‡´ç¼“å­˜æº¢å‡ºã€‚

---

### [ROCm][CI] Fix serving tokens test failures (#34047)
**SHA**: `6afa587` | ğŸ”— [æŸ¥çœ‹æäº¤](https://github.com/vllm-project/vllm/commit/6afa587d31e911c4be495f16916d45d98ebd600c)

**ğŸ¯ å˜æ›´ç±»å‹**ï¼šæµ‹è¯•ä¿®æ”¹  
**âš¡ é‡è¦ç¨‹åº¦**ï¼šğŸŸ¢ä½  
**ğŸ“‹ æ‘˜è¦**ï¼šåœ¨ ROCm ç¯å¢ƒä¸‹ï¼Œä¸ºé¿å…å‰ç¼€ç¼“å­˜å¯¼è‡´çš„ BF16 GEMM éç¡®å®šæ€§é”™è¯¯ï¼Œæ–°å¢ `--no-enable-prefix-caching` å‚æ•°å¹¶è®¾ç½® `VLLM_ROCM_USE_SKINNY_GEMM=0` ç¯å¢ƒå˜é‡ï¼Œä»¥ç¡®ä¿ servingâ€‘tokens æµ‹è¯•å¯é€šè¿‡ã€‚

---

### Add new sections to CODEOWNERS (#34309)
**SHA**: `94ed6cf` | ğŸ”— [æŸ¥çœ‹æäº¤](https://github.com/vllm-project/vllm/commit/94ed6cf6ea9b0097bbf738467b8fa27b77c2838a)

**ğŸ¯ å˜æ›´ç±»å‹**ï¼šæ–‡æ¡£æ›´æ–°  
**âš¡ é‡è¦ç¨‹åº¦**ï¼šğŸŸ¢ä½  
**ğŸ“‹ æ‘˜è¦**ï¼šåœ¨ `.github/CODEOWNERS` ä¸­æ–°å¢ã€è°ƒæ•´äº†å¤šä¸ªç›®å½•åŠæ–‡ä»¶çš„æ‰€æœ‰è€…/å®¡é˜…è€…ï¼Œç»†åŒ–äº†å…¥å£ç‚¹ã€I/O å¤„ç†ã€ç¼–è¯‘ç­‰æ¨¡å—çš„è´Ÿè´£äººå‘˜ï¼ŒåŒæ—¶æ›´æ–°äº†éƒ¨åˆ†è·¯å¾„æ˜ å°„ã€‚  

ï¼ˆä»…æ¶‰åŠä»£ç æ‰€æœ‰æƒé…ç½®ï¼Œæ— ä»£ç åŠŸèƒ½æ”¹åŠ¨ã€‚ï¼‰

---

### [Hybrid] Fix and optimize block-aligned splitting in mamba cache align mode (#33706)
**SHA**: `bf37812` | ğŸ”— [æŸ¥çœ‹æäº¤](https://github.com/vllm-project/vllm/commit/bf37812ca77acf7f00c7761bdb0cf257d0e391a3)

**ğŸ¯ å˜æ›´ç±»å‹**ï¼šä»£ç é‡æ„  
**âš¡ é‡è¦ç¨‹åº¦**ï¼šğŸŸ¢ä½  
**ğŸ“‹ æ‘˜è¦**ï¼šåœ¨ Mamba ç¼“å­˜å¯¹é½æ¨¡å¼ä¸‹ï¼Œé‡æ–°è®¡ç®—å·²è®¡ç®— token æ•°é‡å¹¶æ”¹è¿›é¢„å¡«é˜¶æ®µçš„å—å¯¹é½æ‹†åˆ†é€»è¾‘ï¼Œä¿®æ­£ `last_cache_position` è®¡ç®—å’Œæ¡ä»¶åˆ¤æ–­ï¼Œä»¥é¿å…ç¼“å­˜é”™å¤±ã€‚

---

### [Bugfix] Fix Random Dataset Prefix Length Inaccuracy (#33907)
**SHA**: `b86bf44` | ğŸ”— [æŸ¥çœ‹æäº¤](https://github.com/vllm-project/vllm/commit/b86bf4417e3172b372ff20cccf4d30289a6db8ae)

**ğŸ¯ å˜æ›´ç±»å‹**ï¼šä»£ç é‡æ„  
**âš¡ é‡è¦ç¨‹åº¦**ï¼šğŸŸ¢ä½  
**ğŸ“‹ æ‘˜è¦**ï¼šä¿®æ­£éšæœºæ•°æ®é›†å‰ç¼€é•¿åº¦ä¸å‡†çš„é—®é¢˜ã€‚`gen_prompt_decode_to_target_len` ç°åœ¨è¿”å› token å·®å€¼ï¼›`get_prefix` é€šè¿‡è¯¥å‡½æ•°æ ¡æ­£å‰ç¼€å¹¶åœ¨ä¸ä¸€è‡´æ—¶ç»™å‡ºè­¦å‘Šã€‚è°ƒç”¨å¤„ç›¸åº”ä¼ å…¥ `tokenizer` å‚æ•°ã€‚æ•´ä½“æ”¹åŠ¨æå‡å‰ç¼€ç”Ÿæˆçš„å‡†ç¡®æ€§ã€‚

---

### [Bugfix] Delete unused redundant code in Kimi-K2.5 (#34427)
**SHA**: `62788f9` | ğŸ”— [æŸ¥çœ‹æäº¤](https://github.com/vllm-project/vllm/commit/62788f99a4d0e483a6e9114e6708489b44b51a78)

**ğŸ¯ å˜æ›´ç±»å‹**ï¼šä»£ç é‡æ„  
**âš¡ é‡è¦ç¨‹åº¦**ï¼šğŸŸ¢ä½  
**ğŸ“‹ æ‘˜è¦**ï¼šåœ¨ `kimi_k25.py` ä¸­åˆ é™¤äº† `copy` å¯¼å…¥åŠå…¶æ·±æ‹·è´ `vllm_config` çš„ç›¸å…³ä»£ç ï¼Œæ¸…ç†æœªä½¿ç”¨çš„å†—ä½™é€»è¾‘ï¼Œä¿æŒåŠŸèƒ½ä¸å˜ã€‚

---

### [Bugfix] Remove assert that's no longer valid (#34443)
**SHA**: `04ea31b` | ğŸ”— [æŸ¥çœ‹æäº¤](https://github.com/vllm-project/vllm/commit/04ea31baabc6f5be6b0afd88541f569a4c771ab9)

**ğŸ¯ å˜æ›´ç±»å‹**ï¼šä»£ç é‡æ„  
**âš¡ é‡è¦ç¨‹åº¦**ï¼šğŸŸ¢ ä½  
**ğŸ“‹ æ‘˜è¦**ï¼šç§»é™¤ `assert not self.old_quant_method.is_monolithic`ï¼Œè¯¥æ–­è¨€å·²ä¸å†æˆç«‹ï¼Œé˜²æ­¢åœ¨ä½¿ç”¨éå•ä½“é‡åŒ–æ–¹æ³•æ—¶è¯¯è§¦å¼‚å¸¸ï¼Œæå‡æ¨¡å—å¥å£®æ€§ã€‚

---

### [BugFix] Add block_size validation for mamba cache align mode (#34445)
**SHA**: `6f019e6` | ğŸ”— [æŸ¥çœ‹æäº¤](https://github.com/vllm-project/vllm/commit/6f019e6e0a0cde34a33826bc08756480816448dd)

**ğŸ¯ å˜æ›´ç±»å‹**ï¼šé…ç½®è°ƒæ•´  
**âš¡ é‡è¦ç¨‹åº¦**ï¼šğŸŸ¢ä½  
**ğŸ“‹ æ‘˜è¦**ï¼šåœ¨ `vllm/config/vllm.py` ä¸­ä¸º Mamba ç¼“å­˜çš„ `align` æ¨¡å¼æ–°å¢æ–­è¨€ï¼Œæ ¡éªŒ `block_size` å¿…é¡»ä¸å¤§äº `max_num_batched_tokens`ï¼Œé˜²æ­¢é…ç½®ä¸å…¼å®¹å¯¼è‡´è¿è¡Œé”™è¯¯ã€‚

---

### Fix num_logprobs parameter description in sampler.py (#34451)
**SHA**: `d707678` | ğŸ”— [æŸ¥çœ‹æäº¤](https://github.com/vllm-project/vllm/commit/d707678dfb9a1f616d174022ebc74065d1011863)

**ğŸ¯ å˜æ›´ç±»å‹**ï¼šæ–‡æ¡£æ›´æ–°  
**âš¡ é‡è¦ç¨‹åº¦**ï¼šğŸŸ¢ä½  
**ğŸ“‹ æ‘˜è¦**ï¼šåœ¨ `sampler.py` ä¸­å°† `num_logprobs` å‚æ•°çš„æè¿°ä» â€œminimum number of logprobsâ€ æ›´æ­£ä¸º â€œmaximum number of logprobsâ€ï¼Œæ¾„æ¸…å…¶å®é™…å«ä¹‰ã€‚

---

### [CI/Build] Update video URLs for testing (#34446)
**SHA**: `fc22cae` | ğŸ”— [æŸ¥çœ‹æäº¤](https://github.com/vllm-project/vllm/commit/fc22cae4ac73288f0b3a4c6ef7cdc2521a5411ac)

**ğŸ¯ å˜æ›´ç±»å‹**ï¼šæµ‹è¯•ä¿®æ”¹  
**âš¡ é‡è¦ç¨‹åº¦**ï¼šğŸŸ¢ä½  
**ğŸ“‹ æ‘˜è¦**ï¼šå°† video æµ‹è¯•ç”¨ä¾‹çš„ URL æ›¿æ¢ä¸ºæ›´å¯é çš„èµ„æºï¼Œå¹¶å°† `MAXIMUM_VIDEOS` ä» 4 è°ƒæ•´ä¸º 3ã€‚

---

### Use paged_attention_v1 for sliding window decode in rocm_aiter_fa (#34378)
**SHA**: `9ea1f59` | ğŸ”— [æŸ¥çœ‹æäº¤](https://github.com/vllm-project/vllm/commit/9ea1f598ce48da3054d073e74b9e51e8d0de945a)

**ğŸ¯ å˜æ›´ç±»å‹**ï¼šä»£ç é‡æ„  
**âš¡ é‡è¦ç¨‹åº¦**ï¼šğŸŸ¢ä½  
**ğŸ“‹ æ‘˜è¦**ï¼šåœ¨ `rocm_aiter_fa.py` ä¸­æ”¹ç”¨ `paged_attention_v1` å®ç° slidingâ€‘window è§£ç ï¼Œåˆ é™¤æ—§çš„ `unified_attention` è°ƒç”¨ï¼Œå¹¶åœ¨è°ƒç”¨ä¸­æ–°å¢çª—å£å¤§å°å‚æ•°ã€‚

---

### small adjustment to wvSplitKrc (#34410)
**SHA**: `fac4e96` | ğŸ”— [æŸ¥çœ‹æäº¤](https://github.com/vllm-project/vllm/commit/fac4e96940d9f2ac8dde8fc864b4c76cbdfd0e2d)

**ğŸ¯ å˜æ›´ç±»å‹**ï¼šä»£ç é‡æ„  
**âš¡ é‡è¦ç¨‹åº¦**ï¼šğŸŸ¢ä½  
**ğŸ“‹ æ‘˜è¦**ï¼šåœ¨ `csrc/rocm/skinny_gemms.cu` ä¸­å°† `kOffcp` çš„è®¡ç®—ä»ä¸¤æ­¥èµ‹å€¼æ”¹ä¸ºç›´æ¥ä½¿ç”¨ `min__(K - A_CHUNK, k_str + kOff)`ï¼Œå»é™¤å†—ä½™å˜é‡å¹¶ä¿®æ­£æ³¨é‡Šï¼Œæå‡ä»£ç ç®€æ´æ€§ã€‚

---

### [Bugfix] Enforce DeepGEMM when using sparse_attn_indexer on CUDA (#34374)
**SHA**: `6d4e27c` | ğŸ”— [æŸ¥çœ‹æäº¤](https://github.com/vllm-project/vllm/commit/6d4e27ce29bac0e4cd4975cddf5b0dacc6cb727a)

**ğŸ¯ å˜æ›´ç±»å‹**ï¼šå…¶ä»–  
**âš¡ é‡è¦ç¨‹åº¦**ï¼šğŸŸ¢ä½  
**ğŸ“‹ æ‘˜è¦**ï¼šåœ¨ `sparse_attn_indexer.py` ä¸­æ–°å¢ DeepGEMM å¯ç”¨æ€§æ£€æŸ¥ï¼›å½“åœ¨ CUDA ç¯å¢ƒä¸‹ä¸”æœªå®‰è£… DeepGEMM æ—¶ï¼ŒæŠ›å‡ºè¿è¡Œæ—¶é”™è¯¯ï¼Œé˜²æ­¢ç¨€ç–æ³¨æ„åŠ›ç´¢å¼•å™¨å‡ºé”™ã€‚

---

### [ROCm][CI] Pin TorchCodec to v0.10.0 for ROCm compatibility (#34447)
**SHA**: `4c078fa` | ğŸ”— [æŸ¥çœ‹æäº¤](https://github.com/vllm-project/vllm/commit/4c078fa546016eacab87f833ff625463421f7d29)

**ğŸ¯ å˜æ›´ç±»å‹**ï¼šé…ç½®è°ƒæ•´  
**âš¡ é‡è¦ç¨‹åº¦**ï¼šğŸŸ¢ä½  
**ğŸ“‹ æ‘˜è¦**ï¼šåœ¨ ROCm CI å®‰è£…è„šæœ¬ä¸­å°† TorchCodec åˆ†æ”¯å›ºå®šä¸º v0.10.0ï¼Œä»¥ç¡®ä¿å…¼å®¹æ€§å’Œå¯å¤ç°æ€§ã€‚

---

### [ROCm][quantization] improve OCP weight quant parser robust (#34431)
**SHA**: `766e167` | ğŸ”— [æŸ¥çœ‹æäº¤](https://github.com/vllm-project/vllm/commit/766e1678210d797757dcfe28f05184a251685dfe)

**ğŸ¯ å˜æ›´ç±»å‹**ï¼šä»£ç é‡æ„  
**âš¡ é‡è¦ç¨‹åº¦**ï¼šğŸŸ¢ä½  
**ğŸ“‹ æ‘˜è¦**ï¼šåœ¨ `_is_w_ocp_mx_a_x` ä¸­æ–°å¢å¯¹ `weight_quant` ä¸ºåˆ—è¡¨çš„æ£€æµ‹ï¼Œè®°å½•è°ƒè¯•ä¿¡æ¯å¹¶è¿”å› Falseï¼Œä»¥æå‡ OCP_MX æƒé‡é‡åŒ–è§£æçš„é²æ£’æ€§ï¼Œé¿å…åˆ—è¡¨æ ¼å¼ï¼ˆå¦‚ `fp8_w4a8`ï¼‰å¯¼è‡´çš„é”™è¯¯ã€‚

---

### [Bugfix] Remove broken raw url GGUF model loading support (#34433)
**SHA**: `becbe24` | ğŸ”— [æŸ¥çœ‹æäº¤](https://github.com/vllm-project/vllm/commit/becbe2480871573f9464e4941b179c1c21f2c786)

**ğŸ¯ å˜æ›´ç±»å‹**ï¼šä»£ç é‡æ„/Bugfix  
**âš¡ é‡è¦ç¨‹åº¦**ï¼šğŸŸ¢ä½  
**ğŸ“‹ æ‘˜è¦**ï¼šåˆ é™¤äº†å¯¹åŸå§‹ HTTPS .gguf é“¾æ¥çš„ä¸‹è½½æ”¯æŒï¼Œè°ƒæ•´é”™è¯¯æç¤ºæ–‡å­—å¹¶å»é™¤ç›¸åº”å•å…ƒæµ‹è¯•ã€‚ç®€åŒ–äº† `_prepare_weights` çš„è·¯å¾„åˆ¤æ–­é€»è¾‘ã€‚

---

### Fix MoE for the Transformers modelling backend (#34436)
**SHA**: `679ca5d` | ğŸ”— [æŸ¥çœ‹æäº¤](https://github.com/vllm-project/vllm/commit/679ca5d8d346ede84c9cbba5d6a8789723c295c0)

**ğŸ¯ å˜æ›´ç±»å‹**ï¼šä»£ç é‡æ„  
**âš¡ é‡è¦ç¨‹åº¦**ï¼šğŸŸ¢ ä½  
**ğŸ“‹ æ‘˜è¦**ï¼šåœ¨ Transformers MoE å®ç°ä¸­ï¼Œè°ƒæ•´æ„é€ é¡ºåºï¼Œå°†è‡ªå®šä¹‰è·¯ç”±å‡½æ•°é€šè¿‡ `kwargs` ä¼ é€’ç»™åŸºç±»ï¼Œå¹¶æ”¹ä¸ºä½¿ç”¨ `runner.forward` è¿›è¡Œå‰å‘è®¡ç®—ï¼Œå»é™¤å†—ä½™çš„ `super().__init__` è°ƒç”¨ã€‚

---

### [Docs] Spec decoding docs warning removal (#34439)
**SHA**: `334c715` | ğŸ”— [æŸ¥çœ‹æäº¤](https://github.com/vllm-project/vllm/commit/334c715e0f4f4de2d3de90bd0b9bba59df143eda)

**ğŸ¯ å˜æ›´ç±»å‹**ï¼šæ–‡æ¡£æ›´æ–°  
**âš¡ é‡è¦ç¨‹åº¦**ï¼šğŸŸ¢ä½  
**ğŸ“‹ æ‘˜è¦**ï¼šç§»é™¤ spec decoding æ–‡æ¡£ä¸­å…³äºæ€§èƒ½æœªä¼˜åŒ–çš„è­¦å‘Šï¼Œåªä¿ç•™ä¸ pipeline parallelism ä¸å…¼å®¹çš„è­¦ç¤ºã€‚

---

### [BUG] Reset running requests when clearing cache for pause/resume (#34382)
**SHA**: `7b5a8b4` | ğŸ”— [æŸ¥çœ‹æäº¤](https://github.com/vllm-project/vllm/commit/7b5a8b4a9dd6eb26057e3c8e0fa07db0d89f6d54)

**ğŸ¯ å˜æ›´ç±»å‹**ï¼šä»£ç é‡æ„  
**âš¡ é‡è¦ç¨‹åº¦**ï¼šğŸŸ¢ ä½  
**ğŸ“‹ æ‘˜è¦**ï¼šåœ¨ `pause_generation` ä¸­æ¸…ç†ç¼“å­˜æ—¶ï¼Œè°ƒç”¨ `reset_prefix_cache` å¹¶ä¼ å…¥ `reset_running_requests=True`ï¼Œç¡®ä¿æš‚åœ/æ¢å¤æ—¶åŒæ—¶é‡ç½®æ­£åœ¨è¿è¡Œçš„è¯·æ±‚ã€‚

---

