# æ¯æ—¥æ›´æ–°æŠ¥å‘Šï¼ˆ2026-01-07ï¼‰

## vllm-project/vllm

| æäº¤æ—¶é—´ | ä½œè€… | æäº¤ä¿¡æ¯ |
|----------|------|----------|
| 2026-01-07 23:53:54 | Kate Cheng | [Perf][Kernels] Enable FlashInfer DeepGEMM swapAB on SM90 (for W8A8 Linear Op) (#29213) |
| 2026-01-07 22:45:49 | R3hankhan | [OpenAI] Extend VLLMValidationError to additional validation parameters (#31870) |
| 2026-01-07 21:44:36 | Cyrus Leung | [Chore] Migrate V0 attention utils (#31891) |
| 2026-01-07 21:08:29 | Jared Wen | [Refactor] GLM-ASR Modeling (#31779) |
| 2026-01-07 19:25:03 | vllmellm | [ROCm][AITER] fix wrong argument passed to  AITER `flash_attn_varlen_func` (#31880) |
| 2026-01-07 17:18:52 | Andy Liu | [Bugfix][MTP] Fix GLM4 MoE fp8 loading with MTP on (#31757) |
| 2026-01-07 17:00:16 | BlankR | [Misc] Improve error messages for unsupported types and parameters (#30593) |
| 2026-01-07 16:18:28 | maang | [Model] Cleanup: Remove redundant manual definition of `make_empty_intermediate_tensors` in GLM-4-MoE (#31869) |
| 2026-01-07 16:10:29 | sihao_li | [XPU]fallback to TRITON_ATTN on xpu when use float32 dtype (#31762) |
| 2026-01-07 16:07:16 | weiyu | [Refactor][TPU] Remove torch_xla path and use tpu-inference (#30808) |
| 2026-01-07 15:36:13 | xuebwang-amd | [Bugfix][Kernel] fix bias adding in triton kernel implemented fused moe (#31676) |
| 2026-01-07 14:55:03 | Kevin McKay | [Bugfix][Hardware][AMD] Consolidate FP8 min/max values helper function (#31106) |
| 2026-01-07 14:49:39 | â„ğ• ğ•ğ•ğ• ğ•¨ ğ•„ğ•’ğ•Ÿ | [BugFix] LoRA: Support loading base_layer of experts (#31104) |
| 2026-01-07 14:45:10 | tianshu-Michael-yu | [Bugfix] Fix race condition in async-scheduling for vlm model (#31841) |
| 2026-01-07 14:42:20 | tjp_zju | refactor: find_loaded_library (#31866) |
| 2026-01-07 13:31:34 | Lucas Wilkinson | [Attention][3/n] Remove usage of deprecated `seq_lens_cpu` and `num_computed_tokens_cpu` CommonAttentionMetadata properties (#31850) |
| 2026-01-07 13:04:53 | vllmellm | [ROCm][AITER] bugfix accuracy regression in ROCM_AITER_TRITON_MLA backend (#31816) |
| 2026-01-07 12:34:04 | Cyrus Leung | [Chore] Try remove `init_cached_hf_modules` (#31786) |
| 2026-01-07 12:08:47 | Jack Yang | fixed mypy warnings for files vllm/v1/attention with TEMPORARY workaround (#31465) |
| 2026-01-07 11:48:13 | Tyler Michael Smith | Change warning in get_current_vllm_config to report caller's line number (#31855) |
| 2026-01-07 11:27:40 | Cyrus Leung | [Doc] Update release docs (#31799) |
| 2026-01-07 10:09:32 | Ce Zhao | [Model] Enable LoRA support for PaliGemma (#31656) |
| 2026-01-07 10:02:42 | Yihua Cheng | [1/2][lmcache connector] clean up lmcache multi-process adapter  (#31838) |
| 2026-01-07 09:37:51 | Lucas Kabela | [Misc][BE] Type coverage for vllm/compilation [1/3] (#31554) |
| 2026-01-07 09:13:24 | vSeamar | [Frontend] Implement robust video frame recovery for corrupted videos (#29197) |
| 2026-01-07 09:12:23 | Andreas Karatzas | [ROCm][CI] Fix plugin tests (2 GPUs) failures on ROCm and removing `VLLM_FLOAT32_MATMUL_PRECISION` from all ROCm tests (#31829) |
| 2026-01-07 08:31:52 | Angela Yi | [CI] Add warmup run in test_fusion_attn (#31183) |
| 2026-01-07 07:46:56 | Cyrus Leung | [Bugfix] Handle mistral tokenizer in get_hf_processor (#31817) |
| 2026-01-07 07:23:11 | Andreas Karatzas | [ROCm][CI] Pinning timm lib version to fix ImportError in Multi-Modal Tests (Nemotron) (#31835) |
| 2026-01-07 07:21:15 | Andreas Karatzas | [ROCm][CI] Fix ModernBERT token classification test numerical accuracy on ROCm (#31820) |
| 2026-01-07 05:21:42 | Matthew Bonanni | [Spec Decode][UX] Add acceptance stats to `vllm bench serve` report (#31739) |
| 2026-01-07 04:24:19 | Elvir CrnÄeviÄ‡ | Report error log after vllm bench serve (#31808) |
| 2026-01-07 04:11:26 | Nikhil G | Fix RecursionError in MediaWithBytes unpickling (#31191) |
| 2026-01-07 03:10:18 | Li, Jiang | [Quantization][Refactor] Move CPU GPTQ kernel into MP linear (#31801) |
| 2026-01-07 02:50:43 | Charlie Fu | [ROCm][CI] Fix tests/compile unit tests (#28895) |
| 2026-01-07 02:50:37 | Benjamin Chislett | [Perf] Async Scheduling + Speculative Decoding + Structured Outputs (#29821) |
| 2026-01-07 01:57:56 | Yakine Tahtah | [Bugfix] Fix GLM-4 MoE router logits dtype for data parallel chunking (#31055) |
| 2026-01-07 01:36:24 | Masataro Asai | make 500: InternalServerError more informative (#20610) |
| 2026-01-07 01:32:55 | Ning Xie | [Log] add log about gpu worker init snapshot and requested memory (#29493) |
| 2026-01-07 01:32:46 | Vadim Gimpelson | [PERF] Speed-up of GDN attention decode part (Qwen3-Next) (#31722) |
| 2026-01-07 01:32:14 | Lucas Wilkinson | [Attention][2/n] Remove usage of deprecated `seq_lens_cpu` and `num_computed_tokens_cpu` CommonAttentionMetadata properties (#31774) |
| 2026-01-07 01:07:19 | Jinzhen Lin | [Quantization][MoE] remove unused ep logic from moe marlin (#31571) |
| 2026-01-07 00:00:40 | roikoren755 | [NemotronH] Use ReplicatedLinear for fc1_latent_proj (#31807) |

### ğŸ“Š ç»Ÿè®¡æ‘˜è¦
> æœ¬æ—¥å…± 43 ä¸ªæäº¤ | ğŸ”´é«˜ 2 | ğŸŸ¡ä¸­ 20 | ğŸŸ¢ä½ 21
## ğŸ“‹ ç›®å½•

- [vllm-project/vllm](#vllm-project-vllm)
  - [ğŸ“Š ç»Ÿè®¡æ‘˜è¦](#-ç»Ÿè®¡æ‘˜è¦)
  - [ğŸ”´ é«˜é‡è¦åº¦å˜æ›´ (2)](#-ğŸ”´-é«˜é‡è¦åº¦å˜æ›´-2)
    - [[Refactor][TPU] Remove torch_xla path and use t...](#refactortpu-remove-torch_xla-path-and-use-tpu-inference-30808)
    - [[Quantization][Refactor] Move CPU GPTQ kernel i...](#quantizationrefactor-move-cpu-gptq-kernel-into-mp-linear-31801)
  - [ğŸŸ¡ ä¸­é‡è¦åº¦å˜æ›´ (20)](#-ğŸŸ¡-ä¸­é‡è¦åº¦å˜æ›´-20)
    - [[Perf][Kernels] Enable FlashInfer DeepGEMM swap...](#perfkernels-enable-flashinfer-deepgemm-swapab-on-sm90-for-w8a8-linear-op)
    - [[OpenAI] Extend VLLMValidationError to addition...](#openai-extend-vllmvalidationerror-to-additional-validation-parameters-31870)
    - [[Chore] Migrate V0 attention utils (#31891)](#chore-migrate-v0-attention-utils-31891)
    - [[Refactor] GLM-ASR Modeling (#31779)](#refactor-glm-asr-modeling-31779)
    - [[Misc] Improve error messages for unsupported t...](#misc-improve-error-messages-for-unsupported-types-and-parameters-30593)
    - [[Bugfix][Hardware][AMD] Consolidate FP8 min/max...](#bugfixhardwareamd-consolidate-fp8-min-max-values-helper-function-31106)
    - [[BugFix] LoRA: Support loading base_layer of ex...](#bugfix-lora-support-loading-base_layer-of-experts-31104)
    - [refactor: find_loaded_library (#31866)](#refactor-find_loaded_library-31866)
    - [[Chore] Try remove `init_cached_hf_modules` (#3...](#chore-try-remove-init_cached_hf_modules-31786)
    - [fixed mypy warnings for files vllm/v1/attention...](#fixed-mypy-warnings-for-files-vllm-v1-attention-with-temporary-workaround-3)
    - [[Misc][BE] Type coverage for vllm/compilation [...](#miscbe-type-coverage-for-vllm-compilation-1-3-31554)
    - [[Frontend] Implement robust video frame recover...](#frontend-implement-robust-video-frame-recovery-for-corrupted-videos-29197)
    - [[Spec Decode][UX] Add acceptance stats to `vllm...](#spec-decodeux-add-acceptance-stats-to-vllm-bench-serve-report-31739)
    - [Fix RecursionError in MediaWithBytes unpickling...](#fix-recursionerror-in-mediawithbytes-unpickling-31191)
    - [[ROCm][CI] Fix tests/compile unit tests (#28895)](#rocmci-fix-tests-compile-unit-tests-28895)
    - [[Perf] Async Scheduling + Speculative Decoding ...](#perf-async-scheduling-speculative-decoding-structured-outputs-29821)
    - [[Bugfix] Fix GLM-4 MoE router logits dtype for ...](#bugfix-fix-glm-4-moe-router-logits-dtype-for-data-parallel-chunking-31055)
    - [[Log] add log about gpu worker init snapshot an...](#log-add-log-about-gpu-worker-init-snapshot-and-requested-memory-29493)
    - [[Attention][2/n] Remove usage of deprecated `se...](#attention2-n-remove-usage-of-deprecated-seq_lens_cpu-and-num_computed_)
    - [[Quantization][MoE] remove unused ep logic from...](#quantizationmoe-remove-unused-ep-logic-from-moe-marlin-31571)
  - [ğŸŸ¢ ä½é‡è¦åº¦å˜æ›´ (21)](#-ğŸŸ¢-ä½é‡è¦åº¦å˜æ›´-21)
    - [[ROCm][AITER] fix wrong argument passed to  AIT...](#rocmaiter-fix-wrong-argument-passed-to-aiter-flash_attn_varlen_func)
    - [[Bugfix][MTP] Fix GLM4 MoE fp8 loading with MTP...](#bugfixmtp-fix-glm4-moe-fp8-loading-with-mtp-on-31757)
    - [[Model] Cleanup: Remove redundant manual defini...](#model-cleanup-remove-redundant-manual-definition-of-make_empty_intermedia)
    - [[XPU]fallback to TRITON_ATTN on xpu when use fl...](#xpufallback-to-triton_attn-on-xpu-when-use-float32-dtype-31762)
    - [[Bugfix][Kernel] fix bias adding in triton kern...](#bugfixkernel-fix-bias-adding-in-triton-kernel-implemented-fused-moe-31676)
    - [[Bugfix] Fix race condition in async-scheduling...](#bugfix-fix-race-condition-in-async-scheduling-for-vlm-model-31841)
    - [[Attention][3/n] Remove usage of deprecated `se...](#attention3-n-remove-usage-of-deprecated-seq_lens_cpu-and-num_computed_)
    - [[ROCm][AITER] bugfix accuracy regression in ROC...](#rocmaiter-bugfix-accuracy-regression-in-rocm_aiter_triton_mla-backend-3)
    - [Change warning in get_current_vllm_config to re...](#change-warning-in-get_current_vllm_config-to-report-caller-s-line-number-31)
    - [[Doc] Update release docs (#31799)](#doc-update-release-docs-31799)
    - [[Model] Enable LoRA support for PaliGemma (#31656)](#model-enable-lora-support-for-paligemma-31656)
    - [[1/2][lmcache connector] clean up lmcache multi...](#1-2lmcache-connector-clean-up-lmcache-multi-process-adapter-31838)
    - [[ROCm][CI] Fix plugin tests (2 GPUs) failures o...](#rocmci-fix-plugin-tests-2-gpus-failures-on-rocm-and-removing-vllm_floa)
    - [[CI] Add warmup run in test_fusion_attn (#31183)](#ci-add-warmup-run-in-test_fusion_attn-31183)
    - [[Bugfix] Handle mistral tokenizer in get_hf_pro...](#bugfix-handle-mistral-tokenizer-in-get_hf_processor-31817)
    - [[ROCm][CI] Pinning timm lib version to fix Impo...](#rocmci-pinning-timm-lib-version-to-fix-importerror-in-multi-modal-tests)
    - [[ROCm][CI] Fix ModernBERT token classification ...](#rocmci-fix-modernbert-token-classification-test-numerical-accuracy-on-roc)
    - [Report error log after vllm bench serve (#31808)](#report-error-log-after-vllm-bench-serve-31808)
    - [make 500: InternalServerError more informative ...](#make-500-internalservererror-more-informative-20610)
    - [[PERF] Speed-up of GDN attention decode part (Q...](#perf-speed-up-of-gdn-attention-decode-part-qwen3-next-31722)
    - [[NemotronH] Use ReplicatedLinear for fc1_latent...](#nemotronh-use-replicatedlinear-for-fc1_latent_proj-31807)
#### ğŸ”´ é«˜é‡è¦åº¦å˜æ›´ (2)

### RefactorTPU-Remove-torch_xla-path-and-use-tpu-inference-30808
**SHA**: `e759637` | ğŸ”— [æŸ¥çœ‹æäº¤](https://github.com/vllm-project/vllm/commit/e7596371a403903218ded3a9f446981fde5737f5)

**ğŸ¯ å˜æ›´ç±»å‹**ï¼šé‡æ„ / æ¶æ„å˜æ›´ / ä¾èµ–è¿ç§»  
**âš¡ é‡è¦ç¨‹åº¦**ï¼šğŸ”´é«˜  

**ğŸ“‹ å˜æ›´æ‘˜è¦**  
- å°† vLLM é¡¹ç›®å†…éƒ¨å¯¹ **TPUï¼ˆtorchâ€‘xlaï¼‰** çš„å®ç°å½»åº•ç§»é™¤ï¼Œæ‰€æœ‰åŸæœ‰ TPU ç›¸å…³ä»£ç ï¼ˆæ¨¡å‹åŠ è½½ã€æ³¨æ„åŠ›åç«¯ã€KVâ€‘cache å¤„ç†ã€LoRA/XLA è‡ªå®šä¹‰ç®—å­ã€æµ‹è¯•å¥—ä»¶ç­‰ï¼‰è¢«åˆ é™¤ã€‚  
- æ–°å¢å¯¹å¤–éƒ¨æ’ä»¶ **`tpu_inference`** çš„é€‚é…ï¼šåœ¨ `vllm/platforms/tpu.py` ä¸­ä»…ä¿ç•™ä¸€ä¸ªè½»é‡åŒ…è£…ï¼Œå®é™…çš„ TPU è¿è¡Œæ—¶ã€æ³¨æ„åŠ›å®ç°ã€åˆ†å¸ƒå¼é€šä¿¡ç­‰å…¨éƒ¨äº¤ç”± `tpu_inference` æä¾›ã€‚  
- å¯¹å¹³å°æ£€æµ‹ã€åç«¯æšä¸¾ã€KVâ€‘transferã€é‡åŒ–ç­‰æ¨¡å—åšäº†ç›¸åº”çš„ **æ¡ä»¶åŒ–** è°ƒæ•´ï¼Œå»æ‰äº†å¯¹ `torch_xla` çš„ç¡¬ä¾èµ–ã€‚  
- å¤§é‡æµ‹è¯•æ–‡ä»¶ï¼ˆTPU å•å…ƒæµ‹è¯•ã€æ€§èƒ½å›å½’ã€LoRA XLA è‡ªå®šä¹‰ç®—å­ç­‰ï¼‰è¢«åˆ é™¤ï¼Œä»“åº“çš„ CI å°†ä¸å†ç›´æ¥ç¼–è¯‘/è¿è¡Œè¿™äº›æµ‹è¯•ã€‚  

---

## ğŸ” æŠ€æœ¯æ´å¯Ÿ

### 1. æ¶æ„å½±å“
| ç»´åº¦ | å˜åŒ–å‰ | å˜åŒ–å | å½±å“ |
|------|--------|--------|------|
| **TPU è¿è¡Œæ—¶** | vLLM è‡ªå·±å®ç°çš„ `torch_xla`/`torch_xla.experimental.custom_kernel`ã€è‡ªç ” `TpuCommunicator`ã€`TPUModelLoader`ã€`TPUWorker` ç­‰ï¼Œå®Œæ•´çš„ TPU æ ˆåœ¨ä»£ç åº“å†…ã€‚ | å®Œå…¨ä¾èµ–å¤–éƒ¨ **`tpu_inference`** åŒ…ï¼Œ`vllm` åªæä¾›å¹³å°æŠ½è±¡å±‚ï¼Œæ‰€æœ‰å®ç°ï¼ˆæ³¨æ„åŠ›ã€KVâ€‘cacheã€åˆ†å¸ƒå¼ã€ç¼–è¯‘ç¼“å­˜ï¼‰è½¬ç§»åˆ°æ’ä»¶ã€‚ | ä»£ç ä½“ç§¯å¤§å¹…ç¼©å‡ï¼Œæ ¸å¿ƒåº“ä¸å†ç»´æŠ¤å¤æ‚çš„ TPU ç»†èŠ‚ï¼›ä½† **æ’ä»¶å¿…è£…** æˆä¸ºè¿è¡Œ TPU æ¨ç†çš„å‰ç½®æ¡ä»¶ã€‚ |
| **æ³¨æ„åŠ›åç«¯** | `AttentionBackendEnum` åŒ…å« `PALLAS`ï¼ˆTPU ä¸“ç”¨å®ç°ï¼‰ï¼Œå¯¹åº”æ–‡ä»¶ `vllm/attention/backends/pallas.py`ï¼ˆå·¨é‡è‡ªå®šä¹‰ kernelã€KVâ€‘cache å†™å…¥é€»è¾‘ï¼‰ã€‚ | `PALLAS` æ¡ç›®è¢«åˆ é™¤ï¼Œå¹³å°å±‚åœ¨ `tpu_inference` ä¸­æä¾›è‡ªå·±çš„æ³¨æ„åŠ›å®ç°ã€‚`vllm` ä»…ä¿ç•™ GPU/CPU/ROCM/Mla ç­‰åç«¯ã€‚ | å¤±å»å†…éƒ¨å¯ç›´æ¥åˆ‡æ¢çš„ TPU æ³¨æ„åŠ›å®ç°ï¼›è‹¥ `tpu_inference` çš„å®ç°å‡ºç°å…¼å®¹æ€§é—®é¢˜ï¼ŒvLLM æœ¬èº«éš¾ä»¥å¿«é€Ÿå›æ»šã€‚ |
| **KVâ€‘Cache ä¸åˆ†å¸ƒå¼é€šä¿¡** | è‡ªç ” `tpu_communicator.py`ã€`tpu_distributed_utils.py`ã€`distributed/kv_transfer/*` ä¸­é’ˆå¯¹ XLA çš„ sharding ä¸ `kv_cache_update_op` è‡ªå®šä¹‰ç®—å­ã€‚ | åˆ é™¤è¿™äº›æ–‡ä»¶ï¼Œç›¸å…³ä»£ç æ”¹ä¸º **ä¸ä½¿ç”¨ `_use_pallas` æ ‡å¿—**ï¼ˆå³ç»Ÿä¸€èµ°éâ€‘Pallas è·¯å¾„ï¼‰ï¼Œå®é™…çš„ KVâ€‘cache åˆ†é…ä¸ä¼ è¾“äº¤ç»™ `tpu_inference`ï¼ˆå†…éƒ¨å®ç°ï¼‰ã€‚ | ä»£ç è·¯å¾„ç®€åŒ–ï¼Œæ½œåœ¨çš„ XLAâ€‘specific bug è¢«å¤–éƒ¨æ’ä»¶å¸æ”¶ï¼›ä½† vLLM å¯¹ KVâ€‘cache çš„ç»†ç²’åº¦æ§åˆ¶ï¼ˆå¦‚è·¨å±‚å…±äº«ï¼‰å¯èƒ½å—é™ã€‚ |
| **é‡åŒ–è·¯å¾„** | åŒ…å« `tpu_int8` é‡åŒ–å®ç°ã€å¯¹åº”çš„ `Int8TpuConfig`ã€è‡ªå®šä¹‰ XLA kernel (`quantized_matmul_int8`)ã€‚ | å®Œå…¨åˆ é™¤ `tpu_int8` ç›¸å…³ä»£ç ï¼Œé‡åŒ–ä»…ä¿ç•™ GPU/CPU/ROCM è·¯å¾„ã€‚ | TPU ä¸Šçš„ **int8 é‡åŒ–** ä¸å†å—å®˜æ–¹æ”¯æŒï¼Œè‹¥ä¸šåŠ¡éœ€è¦åªèƒ½ä¾èµ– `tpu_inference` æä¾›çš„æ–¹æ¡ˆï¼ˆå½“å‰ä¸å­˜åœ¨ï¼‰ã€‚ |
| **æµ‹è¯•å¥—ä»¶** | å¤§é‡ `tests/v1/tpu`ã€`tests/tpu` ä¸‹çš„å•å…ƒ/æ€§èƒ½/LoRA/å¤šæ¨¡æ€ç­‰ testï¼Œè¦†ç›– XLA è·¨å±‚é€»è¾‘ã€‚ | å…¨éƒ¨åˆ é™¤ï¼ŒCI å°†ä¸å†æ‰§è¡Œè¿™äº›æµ‹è¯•ã€‚ | **é£é™©**ï¼šç¼ºå°‘å›å½’ä¿éšœï¼Œæ’ä»¶æ›´æ–°åè‹¥å‡ºç°é—®é¢˜åªèƒ½é€šè¿‡æ’ä»¶è‡ªèº«çš„æµ‹è¯•å‘ç°ï¼›åŒæ—¶ä¹Ÿé™ä½äº† CI è¿è¡Œæ—¶é•¿ã€‚ |

### 2. æ€§èƒ½å½±å“
- **æ­£é¢**ï¼š  
  - `tpu_inference` æ˜¯ä¸“é—¨ä¸º TPU æ¨ç†è®¾è®¡çš„æ’ä»¶ï¼Œå†…éƒ¨å¯èƒ½å·²ç»å®ç°äº†æ›´é«˜æ•ˆçš„ **Pallas/Flashâ€‘Attention**ã€**XLA ç¼–è¯‘ç¼“å­˜**ã€**è·¨è®¾å¤‡ sharding**ï¼Œç†è®ºä¸Šèƒ½ä¸æˆ–è¶…å‡ºåŸæœ‰å®ç°çš„æ€§èƒ½ã€‚  
  - ç§»é™¤è‡ªç ”çš„ `torch_xla` è‡ªå®šä¹‰ kernelï¼ˆå¦‚ `bgmv_*`ã€`kv_cache_update_op`ï¼‰åï¼Œé¿å…äº†é¢å¤–çš„ç¼–è¯‘å¼€é”€å’Œæ½œåœ¨çš„ **å›¾è†¨èƒ€**ï¼ˆgraph explosionï¼‰é—®é¢˜ã€‚  

- **è´Ÿé¢**ï¼š  
  - è¿ç§»åˆ°å¤–éƒ¨æ’ä»¶åï¼Œ**é¦–æ¬¡åŠ è½½**ä¼šé¢å¤–è§¦å‘æ’ä»¶çš„åˆå§‹åŒ–ï¼ˆå¦‚ `xr.use_spmd()`ã€`xm.xla_device()`ï¼‰ï¼Œè‹¥æ’ä»¶çš„å¯åŠ¨æ—¶é—´è¾ƒé•¿ä¼šå¯¼è‡´ coldâ€‘start å»¶è¿Ÿã€‚  
  - åŸæœ‰çš„ **KVâ€‘cache å†™å…¥**è‡ªå®šä¹‰ç®—å­åœ¨ XLA ä¸­è¢«ä¸“é—¨è°ƒä¼˜ï¼Œè‹¥æ’ä»¶å®ç°é‡‡ç”¨æ›´é€šç”¨çš„è·¯å¾„ï¼Œå¯èƒ½åœ¨ **å¤§ batch / é•¿ä¸Šä¸‹æ–‡** åœºæ™¯å‡ºç°æ›´é«˜çš„ SMEM / VMEM ä½¿ç”¨ï¼Œè¿›è€Œè§¦å‘ OOMã€‚  
  - ç”±äºéƒ¨åˆ† **KVâ€‘cache å…±äº«**ã€**è·¨å±‚åˆ†ç‰‡** é€»è¾‘å·²è¢«ç®€åŒ–ï¼Œå†…å­˜å ç”¨åœ¨æç«¯æ¨¡å‹ï¼ˆå¦‚ 70Bï¼‰ä¸Šå¯èƒ½ä¸Šå‡ ~10â€‘15%ã€‚  

### 3. å®‰å…¨è€ƒè™‘
- **æ”»å‡»é¢æ”¶ç¼©**ï¼šåˆ é™¤äº†å¤§é‡è‡ªç ” XLA custom opï¼ˆ`bgmv_*`ã€`kv_cache_update_op`ï¼‰ä»¥åŠå¯¹åº”çš„ C++/JAX glueï¼Œé™ä½äº†æ½œåœ¨çš„ **ä»£ç æ³¨å…¥** æˆ– **æœªæ£€æŸ¥è¾“å…¥** çš„é£é™©ã€‚  
- **ä¾èµ–å¤–éƒ¨æ’ä»¶**ï¼šå¼•å…¥ `tpu_inference` åï¼Œå®‰å…¨é£é™©è½¬ç§»è‡³è¯¥æ’ä»¶çš„ä¾›åº”é“¾ï¼ˆç‰ˆæœ¬ç­¾åã€å®¡è®¡ã€ä¾èµ–çš„ç¬¬ä¸‰æ–¹åº“ï¼‰ã€‚è‹¥æ’ä»¶æœªè¿›è¡Œä¸¥æ ¼çš„å®‰å…¨å®¡è®¡ï¼Œå¯èƒ½å¸¦æ¥ **ä¾›åº”é“¾æ”»å‡»**ã€‚  
- **ç¯å¢ƒå˜é‡**ï¼šä»ä¿ç•™ `USE_TPU_INFERENCE`ã€`VLLM_XLA_CACHE_PATH` ç­‰ç¯å¢ƒå˜é‡ï¼Œè‹¥è¢«æ¶æ„ä¿®æ”¹å¯èƒ½å¯¼è‡´ **ç¼“å­˜æ³„æ¼** æˆ– **è·¯å¾„éå†**ã€‚å»ºè®®åœ¨ç”Ÿäº§ç¯å¢ƒåŠ å›ºç¯å¢ƒå˜é‡çš„æ¥æºã€‚  

### 4. å¯ç»´æŠ¤æ€§ä¸å¯æ‰©å±•æ€§
- **å¯ç»´æŠ¤æ€§æå‡**ï¼š  
  - TPU ç›¸å…³ä»£ç é‡ä» **çº¦ 10k è¡Œ**ï¼ˆåŒ…æ‹¬æ¨¡å‹åŠ è½½ã€æ³¨æ„åŠ›ã€KVã€LoRAã€æµ‹è¯•ï¼‰å‰Šå‡è‡³ **å‡ ç™¾è¡Œ**ï¼Œç»´æŠ¤æˆæœ¬å¤§å¹…é™ä½ã€‚  
  - å¯¹å¹³å°æŠ½è±¡çš„å®ç°å˜å¾—æ›´åŠ ç»Ÿä¸€ï¼ˆCPU/GPU/TPU ç»Ÿä¸€èµ° `current_platform`ï¼‰ï¼Œæ–°å¹³å°çš„æ¥å…¥åªéœ€åœ¨ `tpu_inference` ä¸­å®ç°å³å¯ã€‚  

- **å¯æ‰©å±•æ€§å—é™**ï¼š  
  - åªè¦ `tpu_inference` æŒç»­ç»´æŠ¤å¹¶å…¬å¼€ APIï¼Œç”¨æˆ·æ‰èƒ½åœ¨ `vllm` 

---

### QuantizationRefactor-Move-CPU-GPTQ-kernel-into-MP-linear-31801
**SHA**: `8becf14` | ğŸ”— [æŸ¥çœ‹æäº¤](https://github.com/vllm-project/vllm/commit/8becf146bdc42bb7ad3acb4af374d58de65c4432)

**ğŸ¯ å˜æ›´ç±»å‹**ï¼šæ¶æ„å˜æ›´ / é‡æ„  
**âš¡ é‡è¦ç¨‹åº¦**ï¼šğŸ”´ é«˜  
**ğŸ“‹ å˜æ›´æ‘˜è¦**ï¼š  
1. å°†åŸæœ‰çš„ CPUâ€‘GPTQ é‡åŒ–å®ç°ä»ç‹¬ç«‹çš„ `cpu_gptq` é‡åŒ–æ¨¡å—è¿ç§»è‡³å¤šå¡ï¼ˆMPï¼‰çº¿æ€§ç®—å­æ¡†æ¶ `mixed_precision`ï¼Œå¹¶ä»¥ `CPUWNA16LinearKernel` ç»Ÿä¸€å®ç° CPUâ€‘WNA16ï¼ˆGPTQï¼‰è·¯å¾„ã€‚  
2. åˆ é™¤ `CPUGPTQConfig`ã€`CPUGPTQLinearMethod` ä»¥åŠç›¸å…³çš„å‚æ•°ç±»ï¼Œå‰”é™¤ `cpu_gptq` é‡åŒ–æ–¹æ³•çš„æ³¨å†Œä¸é…ç½®å…¥å£ã€‚  
3. æ·»åŠ å¯¹ CPUâ€‘Marlinâ€‘å…¼å®¹é‡åŒ–ç±»å‹çš„æŸ¥è¯¢ä¸åˆ¤å®šï¼Œå®ç°å¯¹ `uint4`ï¼ˆAWQï¼‰ä¸ `uint4b8`ï¼ˆGPTQï¼‰ä¸¤ç§ 4â€‘bit é‡åŒ–çš„ç»Ÿä¸€æ”¯æŒã€‚  

**ğŸ¯ å½±å“èŒƒå›´**ï¼š  
- `vllm/model_executor/layers/quantization/__init__.py`ï¼ˆé‡åŒ–æ–¹æ³•æ³¨å†Œï¼‰  
- `vllm/model_executor/layers/quantization/cpu_wna16.py`ï¼ˆGPTQ é…ç½®ä¸çº¿æ€§æ–¹æ³•è¢«ç§»é™¤ï¼‰  
- `vllm/model_executor/layers/quantization/kernels/mixed_precision/`ï¼ˆæ–°å¢ `cpu.py`ï¼Œä¿®æ”¹ `__init__.py`ã€`exllama.py`ï¼‰  
- `vllm/model_executor/layers/quantization/gptq_marlin.py`ï¼ˆå…¼å®¹æ€§åˆ¤æ–­ï¼‰  
- `vllm/model_executor/layers/quantization/utils/marlin_utils.py`ï¼ˆCPUâ€‘Marlin æ”¯æŒæŸ¥è¯¢ï¼‰  
- ç›¸å…³æµ‹è¯• `tests/quantization/test_cpu_wna16.py`ï¼ˆåŠ å…¥ä¸å¸¦ `g_idx` çš„æ¨¡å‹ï¼‰  

---

## ğŸ” æŠ€æœ¯æ´å¯Ÿ

| ç»´åº¦ | å½±å“åˆ†æ |
|------|----------|
| **æ¶æ„å½±å“** | - **ç»Ÿä¸€ MP çº¿æ€§ç®—å­**ï¼šåŸå…ˆ `cpu_gptq` é‡‡ç”¨ç‹¬ç«‹ `QuantizeMethodBase` å®ç°ï¼Œç°è¢«æŠ½è±¡ä¸º `MPLinearKernel` çš„å­ç±» `CPUWNA16LinearKernel`ã€‚è¿™è®© CPUã€CUDAã€XPU ç­‰å¹³å°çš„é‡åŒ–å®ç°æ²¿ç”¨åŒä¸€å¥— â€œMP Kernelâ€ æ¥å£ï¼Œé™ä½ä»£ç é‡å¤åº¦ã€‚<br>- **é…ç½®å…¥å£ç®€åŒ–**ï¼š`cpu_gptq` é‡åŒ–æ–¹æ³•ä» `QUANTIZATION_METHODS` ä¸­ç§»é™¤ï¼Œç”¨æˆ·åªèƒ½é€šè¿‡ `cpu_awq` + `desc_act=False`ï¼ˆå³ GPTQï¼‰æ¥ä½¿ç”¨ã€‚<br>- **å¹³å°åˆ¤å®šé›†ä¸­**ï¼š`current_platform.is_cpu()`ã€`is_cuda_alike()` ç­‰ç»Ÿä¸€æ”¾åœ¨ kernel åˆ¤å®šä¸ Marlin æ”¯æŒæŸ¥è¯¢ä¸­ï¼Œæå‡å¯æ‰©å±•æ€§ã€‚ |
| **æ€§èƒ½å½±å“** | - **æƒé‡å¸ƒå±€è½¬æ¢**ï¼š`CPUWNA16LinearKernel._process_gptq_weights` å¤ç”¨åŸ `cpu_gptq` çš„ weight unpackâ€‘pack é€»è¾‘ï¼Œä¿æŒç›¸åŒçš„å†…å­˜å¸ƒå±€ï¼ˆ16â€‘channel blockè½¬ç½®ï¼‰ï¼Œç†è®ºä¸Šä¸åº”å‡ºç°æ€§èƒ½å€’é€€ã€‚<br>- **è¿è¡Œæ—¶åˆ†æ”¯**ï¼š`can_implement` åœ¨æ¯æ¬¡ kernel é€‰æ‹©æ—¶ä¼šæ£€æŸ¥è¾“å…¥å°ºå¯¸æ˜¯å¦ä¸º 32 çš„å€æ•°ã€groupâ€‘size æ˜¯å¦ä¸ºå¶æ•°ç­‰é™åˆ¶ï¼Œè‹¥ä¸æ»¡è¶³åˆ™å›é€€åˆ° fallback implï¼ˆå¦‚ `cpu_wna16` çš„å¸¸è§„å®ç°ï¼‰ï¼Œå¯èƒ½å¯¼è‡´å°‘æ•°æ¨¡å‹é™çº§åˆ°è¾ƒæ…¢è·¯å¾„ã€‚<br>- **Marlin å…¼å®¹æŸ¥è¯¢**ï¼šæ–°å¢å¯¹ CPUâ€‘Marlinï¼ˆå³ `cpu_gemm_wna16`ï¼‰çš„é‡åŒ–ç±»å‹æŸ¥è¯¢ï¼Œä½¿å¾—åœ¨ CPU ä¸Šå¯ä»¥ç›´æ¥å¤ç”¨åŸæœ‰é«˜æ•ˆçš„ GEMM å®ç°ï¼Œè€Œä¸æ˜¯çº¯ Python å®ç°ï¼Œé¢„è®¡å¯æå‡ 1.5â€‘2Ã— çš„ååã€‚ |
| **å®‰å…¨è€ƒè™‘** | - ç§»é™¤ `cpu_gptq` çš„ç‹¬ç«‹å®ç°åï¼Œä¸å†æœ‰é¢å¤–çš„ `set_weight_attrs` æˆ–è‡ªå®šä¹‰ `weight_loader` è°ƒç”¨ï¼Œæ”»å‡»é¢ç•¥æœ‰é™ä½ã€‚<br>- æ–°å¢çš„ `cpu.py` åªè°ƒç”¨å·²å®¡è®¡çš„ `_custom_ops.cpu_gemm_wna16`ï¼Œæœªå¼•å…¥æ–°çš„ C++/CUDA ä»£ç ï¼Œå®‰å…¨é£é™©å¯æ§ã€‚ |
| **å¯ç»´æŠ¤æ€§** | - **ä»£ç é‡å¤§å¹…ä¸‹é™**ï¼š`cpu_wna16.py` åˆ é™¤ 326 è¡Œï¼Œæ˜¾è‘—é™ä½ç»´æŠ¤è´Ÿæ‹…ã€‚<br>- **ç»Ÿä¸€é”™è¯¯ä¿¡æ¯**ï¼š`can_implement` è¿”å› (bool, reason) ç»Ÿä¸€è§„æ ¼ï¼Œä¾¿äºè°ƒè¯•å’Œæ—¥å¿—ã€‚<br>- **æµ‹è¯•è¦†ç›–**ï¼šæ–°å¢å¯¹ä¸å« `g_idx`ï¼ˆå³ä¸ä½¿ç”¨ activation orderï¼‰çš„æ¨¡å‹çš„æµ‹è¯•ï¼Œé˜²æ­¢å›å½’ã€‚ |
| **å…¼å®¹æ€§** | - **å‘åå…¼å®¹**ï¼š`cpu_gptq` é‡åŒ–æ–¹æ³•å·²è¢«ç§»é™¤ï¼Œè‹¥ä¸‹æ¸¸ç”¨æˆ·åœ¨é…ç½®æ–‡ä»¶ä¸­ä»å†™ `"cpu_gptq"`ï¼Œä¼šè§¦å‘ `ModelConfig` æ ¡éªŒé”™è¯¯ã€‚<br>- **æ¨¡å‹å…¼å®¹**ï¼šå¯¹å·²ä½¿ç”¨ GPTQï¼ˆ4â€‘bitï¼‰æ¨¡å‹çš„åŠ è½½ä¿æŒä¸å˜ï¼Œåªæ˜¯å†…éƒ¨å®ç°è·¯å¾„åˆ‡æ¢ã€‚<br>- **å¹³å°å…¼å®¹**ï¼šCPUâ€‘only ç¯å¢ƒéœ€è¦ `torch._C._cpu._is_amx_tile_supported()` æ‰èƒ½ä½¿ç”¨ AMX åŠ é€Ÿï¼Œå¦åˆ™å›é€€åˆ°å‘é‡å®ç°ã€‚ |
| **å½±å“çš„ä¸šåŠ¡ä»·å€¼** | - ä¸º CPU ç¯å¢ƒæä¾›ä¸ CUDA/ROCM ç›¸åŒçš„ MPâ€‘Kernel æ¡†æ¶ï¼Œç»Ÿä¸€é‡åŒ–ç”Ÿæ€ï¼Œé™ä½ç”¨æˆ·å­¦ä¹ æˆæœ¬ã€‚<br>- é€šè¿‡ Marlinâ€‘style å®ç°æå‡ CPUâ€‘GPTQ æ¨ç†æ€§èƒ½ï¼Œæ‹“å®½ vLLM åœ¨æ—  GPU åœºæ™¯çš„é€‚ç”¨èŒƒå›´ã€‚ |

---

## âš ï¸ æ½œåœ¨é£é™©

1. **é…ç½®å…¼å®¹æ€§**ï¼šæ—§ç‰ˆé…ç½®æ–‡ä»¶ä»ä¿ç•™ `"cpu_gptq"` å­—æ®µä¼šå¯¼è‡´å¯åŠ¨æ—¶æŠ¥é”™ï¼Œéœ€è¦åœ¨æ–‡æ¡£æˆ–è¿ç§»è„šæœ¬ä¸­æé†’ç”¨æˆ·ã€‚  
2. **å°ºå¯¸é™åˆ¶å›é€€**ï¼š`can_implement` å¯¹ `input`ã€`output` å¿…é¡»æ˜¯ 32 çš„å€æ•°ã€`group_size` å¿…é¡»ä¸ºå¶æ•°çš„ç¡¬æ€§æ£€æŸ¥ï¼Œè‹¥ç”¨æˆ·çš„æ¨¡å‹ä¸æ»¡è¶³ä¼šè‡ªåŠ¨å›é€€åˆ°æ™®é€šï¼ˆéâ€‘Marlinï¼‰å®ç°ï¼Œå¯èƒ½å‡ºç°æ€§èƒ½ä¸‹é™ã€‚  
3. **AMX æ£€æµ‹è¯¯å·®**ï¼š`torch._C._cpu._is_amx_tile_supported()` ä¾èµ–åº•å±‚ CPU ç‰¹æ€§æ£€æµ‹ï¼ŒæŸäº›è™šæ‹ŸåŒ–/å®¹å™¨ç¯å¢ƒå¯èƒ½è¿”å› `False`ï¼Œå¯¼è‡´æœªèƒ½ä½¿ç”¨ AMX åŠ é€Ÿã€‚  
4. **test å¤±è¯¯**ï¼šæ–°å¢çš„æ¨¡å‹åˆ—è¡¨åŒ…å« `Qwen/Qwen1.5-0.5B-Chat-GPTQ-Int4`ï¼Œå¦‚æœè¯¥æ¨¡å‹çš„å…ƒæ•°æ®æˆ–æƒé‡æ ¼å¼ä¸å·²æœ‰æ¨¡å‹ä¸å®Œå…¨ä¸€è‡´ï¼ˆä¾‹å¦‚ç¼ºå°‘ `g_idx`ï¼‰ï¼Œå¯èƒ½è§¦å‘æœªè¦†ç›–çš„ edge caseã€‚  
5. **å¤šå¡ï¼ˆTPï¼‰åœºæ™¯**ï¼šè™½ç„¶ kernel å·²å®ç° `partition_weight_shape` æ£€æŸ¥ï¼Œä½†åœ¨ Tensor Parallel >1 æ—¶ï¼Œ`g_idx` çš„å¤åˆ¶/åˆ†ç‰‡é€»è¾‘æ˜¯å¦å®Œå…¨å…¼å®¹ä»éœ€é€šè¿‡ CI å¤šå¡æµ‹è¯•éªŒè¯ã€‚  

---

## ğŸ’¡ å…³æ³¨å»ºè®®

| å¯¹è±¡ | å»ºè®® |
|------|------|
| **å¼€å‘è€…** | - åœ¨å‘å¸ƒæ–°ç‰ˆæœ¬æ—¶ï¼Œæä¾›è¿ç§»æŒ‡å—ï¼š`cpu_gptq` â†’ `cpu_awq`ï¼ˆ`desc_act=False`ï¼‰æˆ–ç›´æ¥ä½¿ç”¨ `"cpu_awq"` + `dynamic` é…ç½®ã€‚<br>- åœ¨ CI ä¸­æ–°å¢å¤šå¡ï¼ˆTP=2/4ï¼‰CPUâ€‘GPTQ çš„å›å½’æµ‹è¯•ï¼ŒéªŒè¯ `g_idx` åˆ†ç‰‡é€»è¾‘ã€‚<br>- å°† `cpu_gptq` ç›¸å…³æ–‡æ¡£å…¨éƒ¨åˆ é™¤æˆ–æ ‡è®°ä¸ºå·²åºŸå¼ƒï¼Œé¿å…æ··æ·†ã€‚ |
| **ç”¨æˆ·** | - æ£€æŸ¥è‡ªå®šä¹‰é‡åŒ–é…ç½®æ–‡ä»¶ä¸­æ˜¯å¦ä»ä½¿ç”¨ `"cpu_gptq"`ï¼Œæ”¹ä¸º `"cpu_awq"` å¹¶åœ¨ `dynamic` ä¸­ç¡®ä¿ `desc_act=False`ï¼ˆå³ GPTQ).<br>- å¯¹äºé 32 æ•´æ•°å€çš„å±‚ï¼Œé¢„æœŸä¼šé™çº§åˆ°æ™®é€šå®ç°ï¼Œè‹¥å¯¹æ€§èƒ½æœ‰ä¸¥æ ¼è¦æ±‚ï¼Œè¯·è€ƒè™‘å¯¹æ¨¡å‹è¿›è¡Œåˆ†å—æˆ–é‡è®­ç»ƒï¼Œä½¿å…¶æ»¡è¶³å°ºå¯¸è¦æ±‚ã€‚ |
| **è¿è¥/éƒ¨ç½²** | - åœ¨ CPUâ€‘Only ç¯å¢ƒä¸­ç¡®è®¤ `torch._C._cpu._is_amx_tile_supported()` èƒ½å¦æ£€æµ‹åˆ° AMXï¼Œå¦‚æœæ²¡æœ‰ï¼Œå¯é€šè¿‡ç¯å¢ƒå˜é‡æˆ–ç¼–è¯‘é€‰é¡¹å…³é—­ AMX æ£€æµ‹ï¼Œä»¥å…è¯¯åˆ¤å¯¼è‡´ fallbackã€‚<br>- ç›‘æ§æ–°ç‰ˆæœ¬ä¸­ `cpu_gemm_wna16` çš„è°ƒç”¨è®¡æ•°ä¸æ—¶å»¶ï¼Œç¡®ä¿æ€§èƒ½æå‡å®é™…è½åœ°ã€‚ |

--- 

**æ€»ä½“ç»“è®º**ï¼šæœ¬æ¬¡æ”¹åŠ¨é€šè¿‡æŠŠ CPUâ€‘GPTQ å®ç°è¿å…¥ç»Ÿä¸€çš„ MPâ€‘Linear Kernelï¼Œæ˜¾è‘—æå‡ä»£ç å¯ç»´æŠ¤æ€§å¹¶ä¸º CPU ç¯å¢ƒæä¾›äº†ä¸ GPU ç±»ä¼¼çš„é«˜æ•ˆé‡åŒ–è·¯å¾„ã€‚åªè¦å®Œæˆé…ç½®è¿ç§»å’Œå°ºå¯¸å…¼å®¹æ£€æŸ¥ï¼Œæ•´ä½“é£é™©å¯æ§ï¼Œä¸”æœ‰æœ›åœ¨æ—  GPU åœºæ™¯ä¸‹å¸¦

---

#### ğŸŸ¡ ä¸­é‡è¦åº¦å˜æ›´ (20)

### PerfKernels-Enable-FlashInfer-DeepGEMM-swapAB-on-SM90-for-W8A8-Linear-Op...
**SHA**: `cc6dafa` | ğŸ”— [æŸ¥çœ‹æäº¤](https://github.com/vllm-project/vllm/commit/cc6dafaef2bc6b0a3ea0d80efc93985fce6bc8b9)

**ğŸ¯ å˜æ›´ç±»å‹**ï¼šåŠŸèƒ½å¢å¼º  
**âš¡ é‡è¦ç¨‹åº¦**ï¼šğŸŸ¡ ä¸­  

**ğŸ“‹ å˜æ›´æ‘˜è¦**  
- æ–°å¢ç¯å¢ƒå˜é‡ `VLLM_BLOCKSCALE_FP8_GEMM_FLASHINFER`ï¼Œé»˜è®¤å…³é—­ï¼Œç”¨äºåœ¨ Hopperï¼ˆSM90ï¼‰ä¸Šå¯ç”¨ FlashInfer çš„ FP8â€¯+â€¯BF16 blockâ€‘scale GEMMï¼ˆswapABï¼‰å®ç°ã€‚  
- åœ¨ `fp8_utils.py` ä¸­å®ç°äº† `_flashinfer_fp8_blockscale_gemm_impl`ï¼Œä½¿ç”¨ `torch.cond` æ ¹æ® batchâ€‘size åŠ¨æ€åˆ‡æ¢ FlashInferï¼ˆMâ€¯<â€¯32ï¼‰æˆ– DeepGEMMï¼ˆMâ€¯â‰¥â€¯32ï¼‰ï¼Œå¹¶å®Œæˆ customâ€‘op æ³¨å†Œã€‚  
- `W8A8BlockFp8LinearOp.apply` å¢åŠ å¯¹ FlashInfer å¯ç”¨æ€§çš„æ£€æµ‹ä¸è°ƒç”¨è·¯å¾„ã€‚  
- `vllm/utils/flashinfer.py` æ–°å¢æ£€æµ‹å‡½æ•° `has_flashinfer_fp8_blockscale_gemm`ã€`is_flashinfer_fp8_blockscale_gemm_supported` ä¸é€‰æ‹©å‡½æ•° `should_use_flashinfer_for_blockscale_fp8_gemm`ã€‚  
- æ–°å¢å¯¹åº”å•å…ƒæµ‹è¯• `test_w8a8_block_fp8_flashinfer_matmul`ï¼Œä»…åœ¨æ»¡è¶³ SM90ã€FlashInfer å®‰è£…ä»¥åŠå°ºå¯¸å¯¹é½æ—¶è¿è¡Œã€‚  

**ğŸ¯ å½±å“èŒƒå›´**  
- ç¯å¢ƒå˜é‡ã€é…ç½®è¯»å– (`envs.py`)  
- FP8 é‡åŒ–è·¯å¾„ (`model_executor/layers/quantization/utils/fp8_utils.py`)  
- FlashInfer è¾…åŠ©å·¥å…· (`utils/flashinfer.py`)  
- ç›¸å…³å•å…ƒæµ‹è¯• (`tests/kernels/quantization/test_block_fp8.py`)  

**ğŸ’¡ å…³æ³¨å»ºè®®**  
1. éƒ¨ç½²å‰ç¡®è®¤æœåŠ¡å™¨ä¸º Hopperï¼ˆSM90ï¼‰å¹¶å·²æ­£ç¡®å®‰è£… FlashInferï¼ˆå« `fp8_blockscale_gemm_sm90`ï¼‰ï¼Œå¦åˆ™ä¼šè‡ªåŠ¨å›è½è‡³ DeepGEMMã€‚  
2. å¦‚éœ€ä½¿ç”¨è¯¥åŠ é€Ÿï¼Œè¯·æ˜¾å¼è®¾ç½®ç¯å¢ƒå˜é‡ `VLLM_BLOCKSCALE_FP8_GEMM_FLASHINFER=1`ï¼Œå¹¶åœ¨å¯åŠ¨è„šæœ¬ä¸­æ£€æŸ¥ `vllm.utils.flashinfer.is_flashinfer_fp8_blockscale_gemm_supported()`ã€‚  
3. æ³¨æ„ `torch.cond` åªåœ¨ `torch.compile` åœºæ™¯ä¸‹ä¿è¯å›¾æ•è·ï¼Œæœªå¼€å¯ç¼–è¯‘æ—¶ä»ä¼šèµ°æ™®é€š Python åˆ†æ”¯ã€‚  
4. å¯¹äºé Hopper GPU æˆ–æœªå®‰è£… FlashInfer çš„ç¯å¢ƒï¼Œç¡®ä¿ä»èƒ½æ­£å¸¸å›é€€åˆ°åŸæœ‰ DeepGEMM å®ç°ï¼Œé¿å…å› ç¼ºå°‘ä¾èµ–å¯¼è‡´å¯åŠ¨å¤±è´¥ã€‚  
5. è¿›è¡Œæ€§èƒ½ä¸æ•°å€¼éªŒè¯ï¼ˆå°¤å…¶æ˜¯ Mâ€¯<â€¯32 ä¸ Mâ€¯â‰¥â€¯32 åˆ‡æ¢ç‚¹ï¼‰ï¼Œç¡®ä¿ç²¾åº¦ä¿æŒåœ¨ 0.1â€¯% ä»¥å†…ã€‚  

> è¯¥æ”¹åŠ¨ä¸ºå¯é€‰åŠŸèƒ½ï¼Œé»˜è®¤å…³é—­ï¼Œç¡®ä¿ç°æœ‰ç”Ÿäº§ç¯å¢ƒä¸å—å½±å“ï¼›è‹¥å¼€å¯ï¼Œå¯åœ¨ Hopper ä¸Šè·å¾—æ˜¾è‘—çš„ FP8â€¯W8A8 çº¿æ€§å±‚åŠ é€Ÿã€‚

---

### OpenAI-Extend-VLLMValidationError-to-additional-validation-parameters-31870
**SHA**: `1ab055e` | ğŸ”— [æŸ¥çœ‹æäº¤](https://github.com/vllm-project/vllm/commit/1ab055efe6b7f9abdd8774ed64ead1b83dd00253)

**ğŸ¯ å˜æ›´ç±»å‹**ï¼šåŠŸèƒ½å¢å¼ºï¼ˆç»Ÿä¸€å¹¶ç»†åŒ–å¼‚å¸¸ç±»ï¼‰  
**âš¡ é‡è¦ç¨‹åº¦**ï¼šğŸŸ¡ ä¸­  
**ğŸ“‹ å˜æ›´æ‘˜è¦**ï¼šæ–°å¢ `vllm.exceptions.VLLMValidationError`ï¼Œå°†åŸæ¥æ•£è½åœ¨ `protocol.py` çš„è‡ªå®šä¹‰å¼‚å¸¸æŠ½ç¦»ä¸ºç‹¬ç«‹æ¨¡å—ï¼Œå¹¶åœ¨é‡‡æ ·å‚æ•°ã€è¾“å…¥å¤„ç†ã€OpenAI æ¥å£ç­‰å¤šå¤„æ”¹ç”¨è¯¥å¼‚å¸¸æ¥æºå¸¦å‚æ•°å/éæ³•å€¼ä¿¡æ¯ï¼›ç›¸åº”çš„é”™è¯¯å¤„ç†å…¥å£ä¹Ÿæ”¹ä¸ºç›´æ¥æ¥å— `Exception` å¯¹è±¡ï¼Œé¿å…åœ¨ `create_error_response` ä¸­æ‰‹åŠ¨ `str()`ã€‚

**ğŸ¯ å½±å“èŒƒå›´**  
- `vllm/exceptions.py`ï¼ˆæ–°æ¨¡å—ï¼‰  
- `vllm/entrypoints/openai/*`ï¼ˆapi_serverã€protocolã€serving_*ã€rendererï¼‰  
- `vllm/sampling_params.py`ã€`vllm/v1/engine/input_processor.py`ï¼ˆå‚æ•°æ ¡éªŒï¼‰  
- ç›¸å…³çš„ import è·¯å¾„ä»¥åŠå¼‚å¸¸æ•è·é€»è¾‘

**ğŸ’¡ å…³æ³¨å»ºè®®**  
1. **å…¼å®¹æ€§æ£€æŸ¥**ï¼šç¡®è®¤é¡¹ç›®å…¶ä»–ä½ç½®ä»æ•è· `ValueError` çš„ä»£ç èƒ½å¤Ÿå…¼å®¹ `VLLMValidationError`ï¼ˆå®ƒæ˜¯ `ValueError` å­ç±»ï¼ŒåŸºæœ¬å®‰å…¨ï¼‰ã€‚  
2. **æ–‡æ¡£åŒæ­¥**ï¼šåœ¨ API æ–‡æ¡£å’Œå¼‚å¸¸è¯´æ˜ä¸­åŠ å…¥ `VLLMValidationError`ï¼Œå¹¶æ³¨æ˜ `parameter`ã€`value` å­—æ®µçš„å«ä¹‰ã€‚  
3. **å•å…ƒæµ‹è¯•**ï¼šä¸ºæ–°å¢å¼‚å¸¸çš„ `__str__`ã€å‚æ•°ä¼ é€’ä»¥åŠ `create_error_response` å¯¹å¼‚å¸¸å¯¹è±¡çš„å¤„ç†ç¼–å†™å›å½’æµ‹è¯•ï¼Œç¡®ä¿è¿”å›çš„ OpenAI é”™è¯¯ç»“æ„ä¿æŒä¸å˜ã€‚  
4. **ä¾èµ–å®¡æŸ¥**ï¼šæœç´¢ä»£ç åº“ä¸­ä»ç„¶ `from vllm.entrypoints.openai.protocol import VLLMValidationError` çš„æ®‹ç•™å¼•ç”¨ï¼Œå…¨éƒ¨æ”¹ä¸º `vllm.exceptions`ï¼Œé˜²æ­¢è¿è¡Œæ—¶å¯¼å…¥é”™è¯¯ã€‚  
5. **æ—¥å¿—ä¸ç›‘æ§**ï¼šå¼‚å¸¸æ•è·å¤„å·²æ”¹ä¸º `logger.exception`ï¼Œæ³¨æ„æ—¥å¿—æ ¼å¼ä¸è¢«é‡å¤åŒ…è£…ï¼Œå¿…è¦æ—¶åœ¨ `create_error_response` ä¸­ä¿ç•™åŸå§‹å¼‚å¸¸æ ˆä¾›è°ƒè¯•ã€‚  

æ€»ä½“è€Œè¨€ï¼Œæ­¤æ¬¡æŠ½è±¡æå‡äº†é”™è¯¯ä¿¡æ¯çš„å¯è¯»æ€§å’Œç»Ÿä¸€æ€§ï¼Œé£é™©ä¸»è¦åœ¨ import è·¯å¾„çš„å®Œæ•´è¿ç§»å’Œç¡®ä¿å·²æœ‰æµ‹è¯•è¦†ç›–æ‰€æœ‰å¼‚å¸¸è·¯å¾„ã€‚é’ˆå¯¹ä»¥ä¸Šå»ºè®®è¿›è¡Œæ£€æŸ¥å³å¯é¡ºåˆ©å®Œæˆåˆå¹¶ã€‚

---

### Chore-Migrate-V0-attention-utils-31891
**SHA**: `b665bbc` | ğŸ”— [æŸ¥çœ‹æäº¤](https://github.com/vllm-project/vllm/commit/b665bbc2d4277feebf12a6fa38f24d367b5ed25e)

**ğŸ¯ å˜æ›´ç±»å‹**ï¼šé‡æ„ï¼ˆV0â€¯â†’â€¯V1â€¯attention utilsè¿ç§»ï¼‰  
**âš¡ é‡è¦ç¨‹åº¦**ï¼šğŸŸ¡ ä¸­  

**ğŸ“‹ å˜æ›´æ‘˜è¦**  
- å°† `vllm.attention.backends.utils` ä¸­çš„å¸¸é‡ `PAD_SLOT_ID`ã€`MLADims` ä¸å‡½æ•° `get_mla_dims`è¿ç§»è‡³ `vllm.v1.attention.backends.utils`ï¼ˆæˆ– `vllm.v1.attention.backends.mla.common`ï¼‰ï¼Œå¹¶åˆ é™¤åŸæ–‡ä»¶ã€‚  
- æ›´æ–°æ‰€æœ‰ä½¿ç”¨è¯¥è·¯å¾„çš„å†…éƒ¨å¼•ç”¨ï¼ŒåŒ…æ‹¬ Mambaã€GDNâ€‘Attnã€MLAã€GPU blockâ€‘table ä»¥åŠå¯¹åº”å•å…ƒæµ‹è¯•ã€‚  
- é€šè¿‡åœ¨ `vllm/v1/attention/backends/mla/common.py` ä¸­é‡æ–°å®ç° `MLADims` ä¸ `get_mla_dims`ï¼Œç¡®ä¿ V1 ä»£ç ç‹¬ç«‹äº V0ã€‚  

**ğŸ¯ å½±å“èŒƒå›´**  
- `vllm/attention/backends/*`ï¼ˆå·²åˆ é™¤ï¼‰  
- `vllm/v1/attention/backends/*`ï¼ˆgdn_attnã€mlaã€utilsï¼‰  
- `vllm/model_executor/layers/mamba/ops/*`ã€`vllm/v1/worker/gpu/block_table.py`  
- æµ‹è¯•æ¨¡å— `tests/kernels/mamba/*`  

**ğŸ’¡ å…³æ³¨å»ºè®®**  
1. **å…¼å®¹æ€§**ï¼šé¡¹ç›®å¤–éƒ¨è‹¥ä»é€šè¿‡æ—§è·¯å¾„ (`vllm.attention.backends.utils`) å¯¼å…¥ `PAD_SLOT_ID`ï¼Œå°†æŠ›å‡º `ImportError`ã€‚å¯è€ƒè™‘åœ¨æ—§æ¨¡å—åŠ å…¥è½»é‡çš„è½¬å‘ï¼ˆ`from vllm.v1.attention.backends.utils import *`ï¼‰ä½œä¸ºåºŸå¼ƒå…¼å®¹å±‚ã€‚  
2. **ç»Ÿä¸€å®ç°**ï¼š`MLADims` ä¸ `get_mla_dims` ç°åœ¨åœ¨ `mla/common.py` å®šä¹‰ï¼Œè¯·ç¡®è®¤å…¶å®ƒ V1 å­æ¨¡å—ä¸å†åœ¨å…¶ä»–ä½ç½®é‡å¤å®ç°ï¼Œä»¥å…å‡ºç°ç±»å‹ä¸ä¸€è‡´ã€‚  
3. **æ–‡æ¡£ä¸ç¤ºä¾‹**ï¼šæ›´æ–° API æ–‡æ¡£ã€`README` å’Œç¤ºä¾‹ä»£ç ä¸­çš„ import è·¯å¾„ï¼Œé˜²æ­¢ç”¨æˆ·æ··æ·†ã€‚  
4. **å…¨é‡å›å½’**ï¼šè¿è¡Œå®Œæ•´æµ‹è¯•ï¼ˆåŒ…æ‹¬ GPU/TPU ç¯å¢ƒï¼‰ä»¥éªŒè¯ Tritonâ€‘ç›¸å…³ kernel åœ¨æ–° import ä¸‹ä»èƒ½æˆåŠŸç¼–è¯‘ä¸æ‰§è¡Œã€‚  
5. **å‘å¸ƒè¯´æ˜**ï¼šåœ¨ä¸‹ä¸€ä¸ªå‘å¸ƒçš„ changelog ä¸­æ³¨æ˜ â€œattention utils å·²è¿ç§»è‡³ v1 å‘½åç©ºé—´â€ï¼Œå¹¶æä¾›è¿ç§»æŒ‡å¼•ã€‚  

æ€»ä½“æ¥çœ‹ï¼Œæ­¤æ¬¡è¿ç§»æ¸…æ™°åˆ’åˆ†äº† V0 ä¸ V1 å®ç°ï¼Œæå‡ä»£ç ç»„ç»‡åº¦ã€‚åªè¦åšå¥½å‘åå…¼å®¹æé†’ä¸å…¨æµ‹å›å½’ï¼Œé£é™©å¯æ§ã€‚

---

### Refactor-GLM-ASR-Modeling-31779
**SHA**: `9741387` | ğŸ”— [æŸ¥çœ‹æäº¤](https://github.com/vllm-project/vllm/commit/974138751bdb8e41743d0beac0ac4c5d89308c2f)

**ğŸ¯ å˜æ›´ç±»å‹**ï¼šåŠŸèƒ½å¢å¼ºã€é‡æ„  
**âš¡ é‡è¦ç¨‹åº¦**ï¼šğŸŸ¡ ä¸­  

**ğŸ“‹ å˜æ›´æ‘˜è¦**  
- åœ¨ `vllm/model_executor/models/glmasr.py` ä¸­å®ç°äº†å…¨æ–°çš„ GLMâ€‘ASR éŸ³é¢‘ç¼–ç å™¨ï¼šæ–°å¢ **RotaryEmbedding**ã€**QKVParallelLinear**ã€**MMEncoderAttention**ï¼Œå¹¶ä½¿ç”¨å¹¶è¡Œçº¿æ€§å±‚å®ç° GQAã€é‡åŒ–å’Œ TP æ”¯æŒã€‚  
- æ›¿æ¢åŸ `AudioFlamingo3*` å®ç°ï¼Œæ–°å¢ `GlmAsrMultiModalProjector`ã€`GlmAsrProcessingInfo`ã€è‡ªå®šä¹‰ `DataParser/Processor`ï¼Œå¹¶å¯¹æƒé‡åŠ è½½åšäº† q/k/v â†’ qkv æ˜ å°„ã€‚  
- `glmasr_utils.py` ä¸­åŠ å…¥å¯¹å·ç§¯è¾“å‡ºé•¿åº¦çš„ç»Ÿä¸€è®¡ç®—é€»è¾‘ã€‚  

**ğŸ¯ å½±å“èŒƒå›´**  
- `vllm/model_executor/models/glmasr.py`ï¼ˆéŸ³é¢‘å¡”ã€æŠ•å½±ã€å¤„ç†ä¿¡æ¯ã€è§£æå™¨ã€processorï¼‰  
- `vllm/model_executor/models/glmasr_utils.py`ï¼ˆé•¿åº¦è®¡ç®—ï¼‰  
- ç›¸å…³çš„æ¨¡å‹é…ç½®ã€æƒé‡åŠ è½½è·¯å¾„ä»¥åŠå¤šæ¨¡æ€è¾“å…¥çš„æ„é€ é€»è¾‘ã€‚  

**ğŸ’¡ å…³æ³¨å»ºè®®**  
1. **æƒé‡å…¼å®¹**ï¼šç¡®è®¤ `packed_modules_mapping` èƒ½æ­£ç¡®æ˜ å°„ HuggingFace çš„ `q_proj/k_proj/v_proj` æƒé‡ï¼Œé¿å…é—æ¼åç½®ã€‚  
2. **TP/é‡åŒ–**ï¼šåœ¨å¤šæœºç¯å¢ƒä¸‹éªŒè¯ `tp_size` ä¸ `num_heads`ã€`num_kv_heads` çš„æ•´é™¤å…³ç³»ï¼Œå¦åˆ™ä¼šè§¦å‘ shape é”™è¯¯ã€‚  
3. **Mergeâ€‘factor ä¸å·ç§¯**ï¼š`_process_audio_input` ä¸­å¯¹åºåˆ—é•¿åº¦çš„æˆªæ–­ä¸ reshape å¿…é¡»ä¿æŒ `seq_len % merge_ratio == 0`ï¼Œå»ºè®®æ·»åŠ æ–­è¨€å¹¶åœ¨æ–‡æ¡£ä¸­è¯´æ˜ã€‚  
4. **dtype å¯¹é½**ï¼šaudio tower çš„å·ç§¯æƒé‡ dtype ä¸è¾“å…¥ç‰¹å¾å¯¹é½ï¼ˆå·²åœ¨ä»£ç ä¸­ `.to(dtype=...)`ï¼‰ï¼Œä½†åœ¨æ··åˆç²¾åº¦æ¨¡å¼ä¸‹è¯·ç¡®ä¿ `self.config.dtype` ä¸ `torch_dtype` ä¸€è‡´ã€‚  
5. **å¤šæ¨¡æ€å­—æ®µ**ï¼š`_glmasr_field_config` ç°åœ¨æ”¯æŒ chunked ä¸é chunked ä¸¤ç§è·¯å¾„ï¼Œæµ‹è¯•æ—¶è¯·è¦†ç›–ä¸¤ç§ `hf_inputs`ï¼ˆå¸¦/ä¸å¸¦ `chunk_counts`ï¼‰çš„æƒ…å†µã€‚  
6. **å›å½’æµ‹è¯•**ï¼šè¿è¡ŒåŒ…å« GLMâ€‘ASR çš„å…¨é“¾è·¯æ¨ç†ï¼ˆæ–‡æœ¬+éŸ³é¢‘ï¼‰å’Œå•æ¨¡æ€ï¼ˆä»…æ–‡æœ¬ï¼‰ç¡®ä¿æ—§ APIï¼ˆå¦‚ `AudioFlamingo3*`ï¼‰å·²å®Œå…¨è¿ç§»ã€‚  

æ€»ä½“æ¥çœ‹ï¼Œæ”¹åŠ¨æ˜¾è‘—æå‡äº† GLMâ€‘ASR åœ¨ vLLM ä¸­çš„æ‰§è¡Œæ•ˆç‡å’Œå¹¶è¡Œèƒ½åŠ›ï¼Œä½†éœ€è¦åœ¨å¤šæœºã€é‡åŒ–åŠ chunkâ€‘å¤„ç†åœºæ™¯ä¸‹åšå……åˆ†éªŒè¯ã€‚

---

### Misc-Improve-error-messages-for-unsupported-types-and-parameters-30593
**SHA**: `0790f07` | ğŸ”— [æŸ¥çœ‹æäº¤](https://github.com/vllm-project/vllm/commit/0790f07695c72fe203e95f6d8c8ff15c8003e754)

**ğŸ¯ å˜æ›´ç±»å‹**ï¼šå…¶ä»–ï¼ˆé”™è¯¯ä¿¡æ¯æ”¹è¿›ï¼‰  
**âš¡ é‡è¦ç¨‹åº¦**ï¼šğŸŸ¡ ä¸­  
**ğŸ“‹ å˜æ›´æ‘˜è¦**ï¼šæœ¬æ¬¡æäº¤ç»Ÿä¸€æå‡äº†å¤šä¸ªæ¨¡å—åœ¨é‡åˆ°ä¸æ”¯æŒçš„ dtypeã€å‚æ•°æˆ–é…ç½®æ—¶çš„å¼‚å¸¸æç¤ºï¼Œæ”¹ä¸ºæ›´å…·å¯è¯»æ€§çš„â€¯`ValueError`â€¯ä¿¡æ¯å¹¶åˆ—å‡ºåˆæ³•å–å€¼èŒƒå›´ï¼Œå¸®åŠ©ä½¿ç”¨è€…å¿«é€Ÿå®šä½é—®é¢˜ã€‚  
**ğŸ¯ å½±å“èŒƒå›´**ï¼š  
- `benchmarks/cutlass_benchmarks/sparse_benchmarks.py`ï¼ˆç¨€ç–åŸºå‡†ï¼‰  
- `vllm/attention/ops/chunked_prefill_paged_decode.py`ï¼ˆFP8 KV Cacheï¼‰  
- `vllm/config/lora.py`ï¼ˆLoRA é…ç½®æ ¡éªŒï¼‰  
- `vllm/distributed/device_communicators/pynccl_wrapper.py`ï¼ˆNCCL dtype æ˜ å°„ï¼‰  
- `vllm/distributed/kv_transfer/.../vllm_v1_adapter.py`ï¼ˆKV block ID æ›´æ–°ï¼‰  
- `vllm/model_executor/layers/quantization/*`ï¼ˆAutoâ€‘Roundã€Compressed Tensorsã€MXFP4 ç­‰ï¼‰  
- å¤šä¸ªæ¨¡å‹å®ç°ï¼ˆErnie45â€‘VLã€Graniteâ€‘Speechã€Minimaxâ€‘Textâ€‘01ï¼‰  

**ğŸ’¡ å…³æ³¨å»ºè®®**ï¼š  
1. **æµ‹è¯•å…¼å®¹**ï¼šè‹¥å·²æœ‰å•å…ƒæµ‹è¯•æ–­è¨€æ—§å¼‚å¸¸å­—ç¬¦ä¸²ï¼Œéœ€è¦åŒæ­¥æ›´æ–°é¢„æœŸä¿¡æ¯ã€‚  
2. **æ–‡æ¡£åŒæ­¥**ï¼šåœ¨å¯¹åº”æ¨¡å—çš„ä½¿ç”¨æ–‡æ¡£æˆ– API è¯´æ˜ä¸­åŠ å…¥åˆæ³•å–å€¼åˆ—è¡¨ï¼Œä»¥å…äº§ç”Ÿä¿¡æ¯ä¸ä¸€è‡´ã€‚  
3. **å¼‚å¸¸æ•è·**ï¼šä¸šåŠ¡ä¾§å¦‚æœ‰åŸºäºå¼‚å¸¸å­—ç¬¦ä¸²åšé€»è¾‘åˆ†æ”¯çš„ä»£ç ï¼Œè¯·æ”¹ä¸ºæ•è·å¼‚å¸¸ç±»å‹æˆ–æ£€æŸ¥ `exception.args` ä¸­çš„å…³é”®å­—æ®µï¼Œè€Œéå®Œæ•´æ–‡æœ¬ã€‚  
4. **å›é€€å…¼å®¹**ï¼šåœ¨å‡çº§è¿‡ç¨‹ä¸­ï¼Œå»ºè®®å…ˆåœ¨å¼€å‘ç¯å¢ƒéªŒè¯æ¨¡å‹åŠ è½½ã€FP8 æ¨ç†ç­‰è·¯å¾„æ˜¯å¦ä»èƒ½é¡ºåˆ©è¿è¡Œï¼Œç¡®ä¿æ–°å¼‚å¸¸ä¿¡æ¯ä¸ä¼šæ„å¤–ä¸­æ–­å·²æœ‰è„šæœ¬ã€‚  

æ•´ä½“æ¥çœ‹ï¼Œæ­¤æ¬¡æ”¹åŠ¨ä»…å½±å“é”™è¯¯æŠ¥å‘Šå±‚é¢ï¼Œå¯¹åŠŸèƒ½å®ç°æ— å®è´¨æ€§æ”¹åŠ¨ï¼Œä½†æå‡äº†è°ƒè¯•å‹å¥½åº¦ï¼Œå»ºè®®åœ¨ä¸‹ä¸€ä¸ªå‘å¸ƒå‘¨æœŸä¸­åŒæ­¥æ›´æ–°æ–‡æ¡£å’Œæµ‹è¯•ç”¨ä¾‹ã€‚

---

### BugfixHardwareAMD-Consolidate-FP8-min/max-values-helper-function-31106
**SHA**: `4614c5a` | ğŸ”— [æŸ¥çœ‹æäº¤](https://github.com/vllm-project/vllm/commit/4614c5a539282e6a8055d3b370b0f58c6f094c25)

**ğŸ¯ å˜æ›´ç±»å‹**ï¼šBugfix / Refactorï¼ˆç»Ÿä¸€ FP8 é‡åŒ–çš„ min/max å¸®åŠ©å‡½æ•°ï¼‰  
**âš¡ é‡è¦ç¨‹åº¦**ï¼šğŸŸ¡ ä¸­  
**ğŸ“‹ å˜æ›´æ‘˜è¦**ï¼š  
- ä¸º ROCmâ€¯fp8â€¯fnuzï¼ˆMI300ï¼‰æƒ…å½¢æ–°å¢ `get_fp8_min_max()`ï¼Œç»Ÿä¸€è¿”å› `(-224.0,â€¯224.0)`ï¼Œå¦åˆ™ä½¿ç”¨ PyTorch `torch.finfo` çš„æ ‡å‡†å€¼ã€‚  
- æ‰€æœ‰åŸå…ˆç¡¬ç¼–ç  `224/240/448` çš„åœ°æ–¹æ”¹ä¸ºè°ƒç”¨è¯¥å‡½æ•°ï¼Œé¿å…äº†é‡å¤å®ç°å’Œæ½œåœ¨ä¸ä¸€è‡´ã€‚  
- æ–°å¢å•å…ƒæµ‹è¯• `test_fp8_min_max_helper.py`ï¼Œé€šè¿‡ `unittest.mock` éªŒè¯åœ¨æ ‡å‡†å¹³å°ã€fnuz å¹³å°ä»¥åŠéâ€‘fnuz å¹³å°çš„è¿”å›å€¼ã€‚  

**ğŸ¯ å½±å“èŒƒå›´**ï¼š  
- `vllm/model_executor/layers/quantization/utils/quant_utils.py`ï¼ˆæ–°å¢å‡½æ•°ï¼‰  
- `input_quant_fp8.pyã€fp8_utils.pyã€quant_utils.pyã€deep_gemm.py` ä¸­çš„é‡åŒ–å®ç°å‡æ”¹ä¸ºä½¿ç”¨æ–°å‡½æ•°  
- æµ‹è¯•ç›®å½• `tests/kernels/quantization/` å¢åŠ ä¸“å±æµ‹è¯•  
- ä¾èµ– `current_platform` åˆ¤å®šçš„æ‰€æœ‰ FP8 é‡åŒ–è·¯å¾„ï¼ˆåŒ…æ‹¬åŠ¨æ€ perâ€‘token / perâ€‘tensorã€deepâ€‘gemmã€group quantï¼‰  

**ğŸ’¡ å…³æ³¨å»ºè®®**ï¼š  
- è¯·ç¡®è®¤ `current_platform.is_fp8_fnuz()` åœ¨é ROCm ç¯å¢ƒä»è¿”å› `False`ï¼Œå¦åˆ™ä¼šè¯¯ç”¨ 224 ä¸Šé™ã€‚  
- è‹¥æœªæ¥å¢åŠ å…¶ä»–è‡ªå®šä¹‰ FP8 dtypeï¼ˆä¾‹å¦‚ e5m2ï¼‰ï¼Œéœ€åœ¨ `get_fp8_min_max()` ä¸­è¡¥å……å¯¹åº”é€»è¾‘ï¼Œé¿å…æ—§ç¡¬ç¼–ç æ®‹ç•™ã€‚  
- è¿è¡Œå®Œæ•´ CIï¼ˆåŒ…æ‹¬ ROCmâ€‘only æµ‹è¯•ï¼‰éªŒè¯æ•°å€¼ç²¾åº¦ä¸å—å½±å“ï¼›å°¤å…¶å…³æ³¨åŠ¨æ€é‡åŒ–æ¨¡å‹çš„å‰å‘è¯¯å·®ã€‚  
- æ–‡æ¡£ä¸­å¯åŠ å…¥ `get_fp8_min_max` çš„ä½¿ç”¨è¯´æ˜ï¼Œæç¤ºå¼€å‘è€…ä¸è¦è‡ªè¡Œç¡¬ç¼–ç  FP8 è¾¹ç•Œã€‚  

æ€»ä½“è€Œè¨€ï¼Œæ­¤æ¬¡æ”¹åŠ¨æå‡äº†ä»£ç å¯ç»´æŠ¤æ€§ï¼Œé™ä½äº†å¹³å°ç‰¹åŒ–é”™è¯¯çš„é£é™©ï¼Œå½±å“èŒƒå›´å—é™äºé‡åŒ–è·¯å¾„ï¼Œé£é™©ä¸­ç­‰ï¼Œå»ºè®®åœ¨åˆå¹¶å‰å®Œæ•´è·‘ä¸€æ¬¡ ROCmâ€‘GPU çš„å›å½’æµ‹è¯•ã€‚

---

### BugFix-LoRA:-Support-loading-base_layer-of-experts-31104
**SHA**: `4829148` | ğŸ”— [æŸ¥çœ‹æäº¤](https://github.com/vllm-project/vllm/commit/482914849cf9ce61d3e0dffaa35096bb34de58f5)

**ğŸ¯ å˜æ›´ç±»å‹**ï¼šBugFixï¼ˆLoRAâ€¯â†’â€¯æ”¯æŒåŠ è½½ä¸“å®¶çš„ `base_layer`ï¼‰  
**âš¡ é‡è¦ç¨‹åº¦**ï¼šğŸŸ¡ ä¸­  

**ğŸ“‹ å˜æ›´æ‘˜è¦**  
1. `SharedFusedMoE.make_expert_params_mapping` å¢æ·» `model` å‚æ•°ï¼Œå¹¶åœ¨å†…éƒ¨æ£€æµ‹æ¨¡å‹æ˜¯å¦å­˜åœ¨ä»¥ `.base_layer.` ä¸ºå‰ç¼€çš„å­æ¨¡å—ï¼Œä»¥å†³å®šæƒé‡æ˜ å°„çš„å‰ç¼€ã€‚  
2. æ‰€æœ‰ä½¿ç”¨è¯¥å·¥å…·å‡½æ•°çš„ MoE å®ç°ï¼ˆçº¦ 40 å¤„ï¼‰ç»Ÿä¸€æ”¹ä¸ºä¼ å…¥ `self`ï¼Œç¡®ä¿èƒ½å¤Ÿä¾æ®å®é™…æ¨¡å‹ç»“æ„ç”Ÿæˆæ­£ç¡®çš„å‚æ•°åã€‚  
3. æ˜ å°„å­—ç¬¦ä¸²ä¸­åŠ å…¥ `base_layer` å‰ç¼€ï¼Œå…¼å®¹ LoRAâ€‘style æƒé‡çš„åŠ è½½è·¯å¾„ã€‚  

**ğŸ¯ å½±å“èŒƒå›´**  
- `vllm/model_executor/layers/fused_moe/layer.py`ï¼ˆæ ¸å¿ƒæ˜ å°„é€»è¾‘ï¼‰  
- ç»å¤§å¤šæ•° MoE æ¨¡å‹å®ç°æ–‡ä»¶ï¼ˆ`afmoe.pyã€bailing_moe.pyã€deepseek_*.pyã€gpt_oss.pyã€mixtral.py` ç­‰ï¼‰ï¼Œå‡ ä¹æ‰€æœ‰å¸¦ä¸“å®¶å±‚çš„æ¨¡å‹ã€‚  

**ğŸ’¡ å…³æ³¨å»ºè®®**  
1. **å…¼å®¹æ€§**ï¼š`make_expert_params_mapping` ç°åœ¨ä¾èµ– `model.named_parameters()`ï¼Œåœ¨æç«¯æ¨¡å‹ï¼ˆå¦‚å‚æ•°æ‡’åŠ è½½æˆ–åªåœ¨ forward ä¸­åˆ›å»ºï¼‰å¯èƒ½æŠ¥é”™ã€‚å»ºè®®åœ¨æ–‡æ¡£ä¸­è¯´æ˜ä»…åœ¨å®Œæ•´æ¨¡å‹å®ä¾‹åŒ–åä½¿ç”¨ã€‚  
2. **å‰ç¼€æ‹¼æ¥**ï¼šç°æœ‰å®ç°ä¼šäº§ç”Ÿ `experts.base_layer.w13_` æˆ– `experts.base_layer.w2_`ï¼Œç¡®è®¤åœ¨ `load_weights` è¿‡ç¨‹çš„è·¯å¾„åŒ¹é…é€»è¾‘ä¹ŸåŒæ­¥åŠ å…¥ `base_layer` å‰ç¼€ï¼Œé˜²æ­¢å‡ºç° â€œå‚æ•°æœªæ‰¾åˆ°â€ çš„è­¦å‘Šã€‚  
3. **æ€§èƒ½**ï¼šéå†æ‰€æœ‰å‚æ•°ä»¥æ£€æŸ¥ `".base_layer."` çš„å¼€é”€åœ¨æ¨¡å‹åˆå§‹åŒ–é˜¶æ®µä»å¯æ¥å—ï¼Œä½†è‹¥é¢‘ç¹è°ƒç”¨ï¼ˆå¦‚åœ¨å¾ªç¯ä¸­é‡æ–°ç”Ÿæˆæ˜ å°„ï¼‰ï¼Œå¯è€ƒè™‘ç¼“å­˜ç»“æœã€‚  
4. **æµ‹è¯•è¦†ç›–**ï¼šå¢åŠ  LoRAâ€‘enabled MoE æ¨¡å‹çš„å•å…ƒæµ‹è¯•ï¼ŒéªŒè¯ `base_layer` å‰ç¼€åœ¨æƒé‡åŠ è½½ã€å‚æ•°åˆ‡åˆ†å’Œæ¢¯åº¦å›ä¼ ä¸­çš„å®Œæ•´æ€§ã€‚  
5. **å›æ»šå…¼å®¹**ï¼šè‹¥å·²æœ‰è€æ¨¡å‹ä¸åŒ…å« `base_layer`ï¼Œæ˜ å°„ä»åº”ä¿æŒåŸæ ·ã€‚å»ºè®®ä¿ç•™å¯¹ `base_layer` ä¸ºç©ºå­—ç¬¦ä¸²çš„åˆ†æ”¯ï¼Œé¿å…ç ´åæ—§æƒé‡æ–‡ä»¶çš„å…¼å®¹ã€‚  

æ€»ä½“è€Œè¨€ï¼Œæ­¤æ¬¡æ”¹åŠ¨åœ¨ä¿è¯ LoRA æƒé‡å¯åŠ è½½çš„åŒæ—¶ï¼Œå¯¹æ‰€æœ‰ MoE å®ç°åšäº†ç»Ÿä¸€æ”¹é€ ï¼Œå½±å“é¢å¹¿ä½†é£é™©å¯æ§ã€‚å®Œæˆä¸Šè¿°éªŒè¯åå³å¯åˆå…¥ä¸»çº¿ã€‚

---

### refactor:-find_loaded_library-31866
**SHA**: `55caa60` | ğŸ”— [æŸ¥çœ‹æäº¤](https://github.com/vllm-project/vllm/commit/55caa6051d675148aba009c85618c6d3adf85091)

**ğŸ¯ å˜æ›´ç±»å‹**ï¼šé‡æ„  
**âš¡ é‡è¦ç¨‹åº¦**ï¼šğŸŸ¡ ä¸­  

**ğŸ“‹ å˜æ›´æ‘˜è¦**  
- å°† `find_loaded_library` å®ç°ç»Ÿä¸€æŠ½å–åˆ° `vllm.utils.system_utils`ï¼ŒåŸå…ˆåˆ†æ•£åœ¨ `cumem.py` ä¸ `cuda_wrapper.py` çš„é‡å¤ä»£ç è¢«åˆ é™¤ã€‚  
- ä¸¤å¤„è°ƒç”¨æ”¹ä¸ºç›´æ¥å¯¼å…¥æ–°å‡½æ•°ï¼Œä¿æŒåŸæœ‰åŠŸèƒ½ä¸å˜ã€‚

**ğŸ¯ å½±å“èŒƒå›´**  
- `vllm/device_allocator/cumem.py`  
- `vllm/distributed/device_communicators/cuda_wrapper.py`  
- `vllm/utils/system_utils.py`ï¼ˆæ–°å¢å®ç°ï¼‰  

**ğŸ’¡ å…³æ³¨å»ºè®®**  
1. **å¹³å°å…¼å®¹**ï¼šå½“å‰å®ç°ä¾èµ– `/proc/self/maps`ï¼Œä»…åœ¨ç±» Unix ç³»ç»Ÿå¯ç”¨ã€‚å»ºè®®åœ¨å‡½æ•°å…¥å£æ·»åŠ  `if not sys.platform.startswith('linux'):` çš„å®‰å…¨è¿”å›æˆ–æŠ›å‡ºæ˜ç¡®å¼‚å¸¸ï¼Œé¿å…åœ¨ Windows/macOS ç¯å¢ƒä¸‹å‡ºç° `FileNotFoundError`ã€‚  
2. **å¼‚å¸¸å¤„ç†**ï¼šè¯»å– `/proc/self/maps` å¯èƒ½å› æƒé™ä¸è¶³æˆ–æ–‡ä»¶ç¼ºå¤±å¤±è´¥ï¼Œå»ºè®®æ•è· `OSError` å¹¶è®°å½•æ—¥å¿—åè¿”å› `None`ï¼Œé˜²æ­¢å¯åŠ¨æ—¶å´©æºƒã€‚  
3. **æ€§èƒ½/ç¼“å­˜**ï¼šè¯¥å‡½æ•°åœ¨åŒä¸€è¿›ç¨‹å†…å¯èƒ½è¢«å¤šæ¬¡è°ƒç”¨ï¼Œè€ƒè™‘åŠ è£…é¥°å™¨ `@functools.lru_cache(maxsize=None)`ï¼Œå‡å°‘ç£ç›˜ I/Oã€‚  
4. **å•å…ƒæµ‹è¯•**ï¼šè¡¥å……é’ˆå¯¹ `system_utils.find_loaded_library` çš„è·¨å¹³å°/å¼‚å¸¸è·¯å¾„æµ‹è¯•ï¼Œç¡®ä¿é‡æ„åè¡Œä¸ºä¿æŒä¸€è‡´ã€‚  
5. **æ–‡æ¡£ä¸å¯¼å‡º**ï¼šå¦‚æœé¡¹ç›®ä½¿ç”¨ `__all__` æ§åˆ¶å¯¼å‡ºï¼Œè¯·åœ¨ `system_utils.py` ä¸­åŠ å…¥å¯¹åº”æ¡ç›®ï¼Œå¹¶åœ¨ CHANGELOG ä¸­è®°å½•æ­¤ API ç§»åŠ¨ã€‚  

æ€»ä½“æ¥çœ‹ï¼Œæ­¤æ¬¡é‡æ„æå‡äº†ä»£ç å¯ç»´æŠ¤æ€§ï¼Œé£é™©ä¸»è¦é›†ä¸­åœ¨å¹³å°ä¾èµ–ä¸é”™è¯¯å¤„ç†ï¼ŒæŒ‰ä¸Šè¿°å»ºè®®ç»†åŒ–å³å¯å®‰å…¨åˆå…¥ã€‚

---

### Chore-Try-remove-`init_cached_hf_modules`-31786
**SHA**: `aafd4d2` | ğŸ”— [æŸ¥çœ‹æäº¤](https://github.com/vllm-project/vllm/commit/aafd4d23548ae54adeca1d4898cc15a4d2c390ac)

**ğŸ¯ å˜æ›´ç±»å‹**ï¼šé‡æ„ / æ¸…ç†  
**âš¡ é‡è¦ç¨‹åº¦**ï¼šğŸŸ¡ ä¸­  
**ğŸ“‹ å˜æ›´æ‘˜è¦**ï¼šæœ¬æ¬¡æäº¤å‰”é™¤äº† `init_cached_hf_modules` çš„è°ƒç”¨ï¼Œæ”¹ä¸ºåœ¨ `WorkerWrapperBase` åˆå§‹åŒ–æ—¶ä¸å†æ¥å— `vllm_config` å‚æ•°ï¼Œè€Œæ˜¯ä»…åœ¨ `init_worker` æ—¶æ³¨å…¥é…ç½®ã€‚ç›¸å…³çš„æµ‹è¯• fixtureã€`MultiprocExecutor`ã€`RayExecutor`ã€`UniProcExecutor` ä»¥åŠ GPU/TPU worker çš„æ‡’å¯¼å…¥ä»£ç å‡åŒæ­¥æ›´æ–°ã€‚  

**ğŸ¯ å½±å“èŒƒå›´**  
- `vllm/v1/worker/worker_base.py`ï¼ˆæ ¸å¿ƒï¼‰  
- `vllm/v1/executor/*`ï¼ˆå¤šè¿›ç¨‹ã€å•è¿›ç¨‹ã€Rayï¼‰  
- `vllm/v1/worker/gpu_worker.pyã€tpu_worker.py`ï¼ˆç§»é™¤ `trust_remote_code` æ¡ä»¶ä¸‹çš„å¯¼å…¥ï¼‰  
- æµ‹è¯•ç›®å½•ä¸‹çš„ `conftest.py`ï¼ˆæ›´æ–° `WorkerWrapperBase` è°ƒç”¨ï¼‰  
- `vllm/utils/import_utils.py`ï¼ˆåˆ é™¤ `init_cached_hf_modules`ï¼‰  

**ğŸ’¡ å…³æ³¨å»ºè®®**  
1. **åŠŸèƒ½éªŒè¯**ï¼š`trust_remote_code=True` æ—¶ä»èƒ½æ­£å¸¸åŠ è½½ Huggingâ€‘Face åŠ¨æ€æ¨¡å—ï¼Œç¡®ä¿åœ¨æœªæ˜¾å¼è°ƒç”¨ `init_cached_hf_modules` çš„ä»£ç è·¯å¾„ä¸‹ï¼Œ`transformers` çš„åˆå§‹åŒ–ä¸ä¼šè¢«é—æ¼ã€‚  
2. **å‘åå…¼å®¹**ï¼šç¬¬ä¸‰æ–¹é¡¹ç›®å¦‚æœç›´æ¥å®ä¾‹åŒ– `WorkerWrapperBase(vllm_config=â€¦)`ï¼Œä¼šæ”¶åˆ°å‚æ•°é”™è¯¯ã€‚å¯åœ¨æ–‡æ¡£æˆ–è¿ç§»æŒ‡å—ä¸­æ ‡æ˜æ­¤æ„é€ å‡½æ•°å·²ä¸å†æ¥å— `vllm_config`ã€‚  
3. **æµ‹è¯•è¦†ç›–**ï¼šè¿è¡Œå®Œæ•´å•å…ƒ/é›†æˆæµ‹è¯•ï¼Œç‰¹åˆ«æ˜¯æ¶‰åŠè¿œç¨‹ä»£ç åŠ è½½ã€GPU/TPU worker å¯åŠ¨çš„åœºæ™¯ï¼Œç¡®è®¤æ²¡æœ‰å› åˆ é™¤æ‡’å¯¼å…¥å¯¼è‡´çš„ `ImportError`ã€‚  
4. **æ€§èƒ½æ£€æŸ¥**ï¼šè™½ç„¶ç§»é™¤äº†æ‡’åˆå§‹åŒ–ï¼Œä½†å®é™…å¯åŠ¨æˆæœ¬å·²è½¬ç§»è‡³ `init_worker`ï¼Œè¯·å…³æ³¨å¯åŠ¨æ—¶é—´æ˜¯å¦æœ‰è½»å¾®å›é€€ã€‚  

æ€»ä½“æ¥çœ‹ï¼Œæ­¤æ¬¡ä¿®æ”¹ç®€åŒ–äº† Worker åŒ…è£…å±‚çš„è´£ä»»åˆ’åˆ†ï¼Œå‡å°‘ä¸å¿…è¦çš„è·¨è¿›ç¨‹ä¾èµ–ï¼Œé£é™©ä¸»è¦åœ¨äº `trust_remote_code` åœºæ™¯çš„å…¼å®¹æ€§ï¼Œå»ºè®®åœ¨ CI ä¸­åŠ å…¥ç›¸åº”çš„å›å½’æµ‹è¯•ã€‚

---

### fixed-mypy-warnings-for-files-vllm/v1/attention-with-TEMPORARY-workaround-3...
**SHA**: `0a2c2dc` | ğŸ”— [æŸ¥çœ‹æäº¤](https://github.com/vllm-project/vllm/commit/0a2c2dc3f14620de291e67d6d26fca72b09f5617)

**ğŸ¯ å˜æ›´ç±»å‹**ï¼šå…¶ä»–ï¼ˆmyâ€‘py è­¦å‘Šæ•´æ”¹ï¼‰  
**âš¡ é‡è¦ç¨‹åº¦**ï¼šğŸŸ¡ ä¸­  
**ğŸ“‹ å˜æ›´æ‘˜è¦**ï¼šæœ¬æ¬¡æäº¤å¯¹ `vllm/v1/attention` ç›¸å…³ä»£ç åšäº†å¤§é‡ç±»å‹æ³¨è§£å’Œç»“æ„æ€§é‡æ„ï¼Œä»¥æ¶ˆé™¤ mypy è­¦å‘Šã€‚æ ¸å¿ƒæªæ–½åŒ…æ‹¬ï¼šå°† `AttentionType` æ”¹ä¸º `Enum`ï¼Œç»Ÿä¸€ `block_size` ä¸ºå¿…é€‰ `int`ï¼ˆå¹¶åœ¨è°ƒç”¨æ–¹ç»Ÿä¸€å¤„ç† `None`ï¼‰ï¼Œä¸ºå„åç«¯å®ç°è¡¥å…¨å¿…éœ€å±æ€§å¹¶åŠ å…¥ `AssertionError` æ£€æŸ¥ï¼Œæ‰©å±• `AttentionImpl`/`AttentionMetadata` çš„åŸºç±»ä½¿ç”¨ï¼Œç»†åŒ– `tools/pre_commit/mypy.py` çš„æ£€æŸ¥è·¯å¾„ã€‚  

**ğŸ¯ å½±å“èŒƒå›´**ï¼š  
- `vllm/attention/backends/*`ï¼ˆFlashAttentionã€FlashInferã€Flexã€GDNã€Mambaã€MLA ç³»åˆ—ç­‰ï¼‰  
- `vllm/v1/attention/backends/*`ï¼ˆå„åç«¯å®ç°ï¼‰  
- `vllm/v1/kv_cache_interface.py`ã€`vllm/model_executor/layers/attention_layer_base.py`  
- `tools/pre_commit/mypy.py`ï¼ˆCI æ£€æŸ¥é…ç½®ï¼‰  

**ğŸ’¡ å…³æ³¨å»ºè®®**ï¼š  
1. **è¿è¡Œæ—¶æ–­è¨€**ï¼šæ–°å¢çš„ `assert self.vllm_flash_attn_version is not None`ã€`self.dcp_world_size != -1` ç­‰æ–­è¨€åœ¨ç¼ºå¤±å¯¹åº”ç¯å¢ƒæ—¶ä¼šç›´æ¥æŠ¥é”™ï¼Œè¯·åœ¨ CI/å•æµ‹ä¸­è¦†ç›–æ—  FlashAttention æˆ– DCP åœºæ™¯ï¼Œç¡®è®¤å¼‚å¸¸ä¿¡æ¯å‹å¥½ã€‚  
2. **`block_size` å‚æ•°**ï¼šå°† `block_size` ä» `int | None` æ”¹ä¸ºå¿…å¡« `int`ï¼Œä½†éƒ¨åˆ†è°ƒç”¨ä»ä¼  `None`ï¼ˆå¦‚ FlashAttention åç«¯ï¼‰ã€‚å·²åœ¨å±€éƒ¨åš `| None` å¤„ç†ï¼Œå»ºè®®ç»Ÿä¸€åœ¨ä¸Šå±‚ç»Ÿä¸€è½¬åŒ–ä¸ºé»˜è®¤å€¼æˆ–æ˜¾å¼ `None` æ£€æŸ¥ï¼Œé˜²æ­¢é—æ¼å¯¼è‡´ `TypeError`ã€‚  
3. **æšä¸¾å…¼å®¹**ï¼š`AttentionType` æ”¹ä¸º `str, Enum`ï¼Œç¡®ä¿æ—§ä»£ç ä»å¯é€šè¿‡å­—ç¬¦ä¸²æ¯”è¾ƒï¼›ä½†è‹¥æœ‰ `isinstance(..., str)` çš„æ˜¾å¼æ£€æŸ¥ï¼Œéœ€åŒæ­¥æ›´æ–°ã€‚  
4. **ç±»å‹å¯¼å…¥ä¸å‰å‘å…¼å®¹**ï¼šå¤§é‡ `# type: ignore` ä¸ `Protocol` ç”¨æ³•å¯èƒ½åœ¨ä½ç‰ˆæœ¬ mypy ä¸‹ä»æŠ¥é”™ï¼Œå»ºè®®åœ¨ `pyproject.toml` é”å®š mypy ç‰ˆæœ¬æˆ–åœ¨ CI ä¸­åŠ å…¥ `--strict` æ£€æµ‹ã€‚  
5. **å›å½’æµ‹è¯•**ï¼šé‡ç‚¹è·‘åŒ…å«æ¨¡å‹æ¨ç†ã€specâ€‘decodeã€DCPã€MLAã€FlashInfer ç­‰ç‰¹æ€§çš„å®Œæ•´é›†æˆæµ‹è¯•ï¼Œç¡®ä¿æ–°æ–­è¨€å’Œç±»å‹æ”¹åŠ¨æœªå½±å“æ€§èƒ½æˆ–åŠŸèƒ½ã€‚  

æ€»ä½“è€Œè¨€ï¼Œæ­¤æ¬¡æ•´æ”¹æ˜¾è‘—æå‡ä»£ç å¯ç»´æŠ¤æ€§å’Œé™æ€æ£€æŸ¥è¦†ç›–ï¼Œä½†å› å¼•å…¥äº†å¤šå¤„è¿è¡Œæ—¶æ–­è¨€å’Œæ›´ä¸¥æ ¼çš„ç±»å‹è¦æ±‚ï¼ŒåŠ¡å¿…é€šè¿‡å®Œæ•´çš„åŠŸèƒ½å›å½’ï¼Œé˜²æ­¢åœ¨ç”Ÿäº§ç¯å¢ƒå‡ºç°æ„å¤–å´©æºƒã€‚

---

### MiscBE-Type-coverage-for-vllm/compilation-1/3-31554
**SHA**: `873480d` | ğŸ”— [æŸ¥çœ‹æäº¤](https://github.com/vllm-project/vllm/commit/873480d133f3e32743a0e187b03da1e67635bdc2)

**ğŸ¯ å˜æ›´ç±»å‹**ï¼šåŠŸèƒ½å¢å¼º & ç±»å‹å®‰å…¨ï¼ˆä¸º vllm/compilation å¤§é‡æ·»åŠ /å®Œå–„äº†ç±»å‹æ³¨è§£ï¼‰  
**âš¡ é‡è¦ç¨‹åº¦**ï¼šğŸŸ¡ ä¸­  

**ğŸ“‹ å˜æ›´æ‘˜è¦**  
- ä¸ºç¼–è¯‘ç®¡ç†ã€ç¼“å­˜ã€Passã€Patternã€CUDAGraphã€monitor ç­‰æ ¸å¿ƒæ¨¡å—è¡¥å…¨è¿”å›å€¼ã€å‚æ•°çš„ `typing`ï¼ˆ`Generator`ã€`Callable[..., Any]`ã€`ParamSpec`ã€`Literal`ã€`Optional[str]` ç­‰ï¼‰ï¼Œå¹¶ç»Ÿä¸€ä½¿ç”¨ `-> None`ã€`-> bool`ã€`-> str` ç­‰æ˜¾å¼ç­¾åã€‚  
- éƒ¨åˆ†æ„é€ å‡½æ•°å’Œå…¬å…±å‡½æ•°çš„å‚æ•°ç±»å‹ä» `str` æ”¾å®½ä¸º `str | None`ï¼Œå¹¶åœ¨ `CUDAGraphEntry` è°ƒç”¨å‰åŠ å…¥ `assert batch_descriptor is not None`ã€‚  
- æ–°å¢ `set_inductor_configã€set_functorch_configã€validate_cudagraph_capturing_enabled` ç­‰å‡½æ•°çš„è¿”å›æ³¨è§£ï¼Œæ”¹å†™ `contextmanager` ä¸ºæ˜¾å¼ `Generator`ã€‚  
- å¼•å…¥ `ParamSpec`/`TypeVar` ä»¥ä¿æŒåŒ…è£…å‡½æ•°ç­¾åä¸å˜ï¼Œé‡æ„ `enable_fake_mode`ã€`pass_context`ã€`InductorPass` ç­‰å®ç°ç»†èŠ‚ã€‚  

**ğŸ¯ å½±å“èŒƒå›´**  
- `vllm/compilation` åŒ…å…¨é“¾è·¯ï¼š`CompilerManager`ã€`InductorPass`ã€`VllmInductorPass`ã€`InductorStandaloneAdaptor`ã€`InductorPass`ã€`collective_fusion`ã€`sequence_parallelism`ã€`partition_rules`ã€`monitor`ã€`cuda_graph` ç­‰ã€‚  
- å¯¹å¤– API ä¸­ `compile_contextã€initialize_cacheã€compileã€loadã€set_model_tagã€set_inductor_config` ç­‰å‡½æ•°ç­¾åå·²å˜æ›´ï¼Œè°ƒç”¨æ–¹é¡»ä¼ å…¥/æ¥å—ç›¸åŒçš„å¯é€‰ç±»å‹ã€‚  

**ğŸ’¡ å…³æ³¨å»ºè®®**  
1. **å…¼å®¹æ€§æ£€æŸ¥**ï¼šç¡®ä¿æ‰€æœ‰å†…éƒ¨è°ƒç”¨å·²æ›´æ–°ä¸ºæ–°ç­¾åï¼ˆå°¤å…¶æ˜¯ `compile_context`ã€`initialize_cache`ã€`set_inductor_config`ï¼‰ï¼Œå¹¶ä¸ºæ—§ç‰ˆæœ¬ç•™å‡ºå…¼å®¹åŒ…è£…ï¼ˆå¦‚æ¥å— `str` å¹¶è‡ªåŠ¨è½¬æˆ `Optional[str]`ï¼‰ã€‚  
2. **ç±»å‹æ£€æŸ¥**ï¼šåœ¨ CI ä¸­åŠ å…¥ `mypy --strict` æˆ–ç­‰ä»·å·¥å…·ï¼ŒéªŒè¯æ–°å¢æ³¨è§£æœªäº§ç”Ÿæœªè¦†ç›–çš„ `Any`ã€‚  
3. **è¿è¡Œæ—¶æ–­è¨€**ï¼š`assert batch_descriptor is not None` å¯èƒ½åœ¨å¼‚å¸¸è·¯å¾„è§¦å‘ï¼Œå»ºè®®æ”¹ä¸ºæå‰å‚æ•°æ ¡éªŒå¹¶æŠ›å‡ºæ¸…æ™°å¼‚å¸¸ã€‚  
4. **æ–‡æ¡£åŒæ­¥**ï¼šæ›´æ–° `docs` ä¸ README ä¸­çš„å‡½æ•°ç­¾åè¯´æ˜ï¼Œæ ‡æ˜ `device` å‚æ•°ç°åœ¨æ¥å— `None`ã€‚  
5. **æµ‹è¯•è¦†ç›–**ï¼šå¢åŠ é’ˆå¯¹ `device=None`ã€`compile_range` ä¸ºå•å°ºå¯¸/å¤šå°ºå¯¸ã€`cudagraph` æ•è·é”™è¯¯ç­‰åœºæ™¯çš„å•å…ƒæµ‹è¯•ï¼Œé˜²æ­¢å› ç±»å‹æ”¾å®½å¯¼è‡´é€»è¾‘åˆ†æ”¯é—æ¼ã€‚  

æ€»ä½“æ¥çœ‹ï¼Œæ­¤æ¬¡æäº¤æå‡äº†ä»£ç å¯è¯»æ€§ä¸é™æ€æ£€æŸ¥èƒ½åŠ›ï¼Œä½†å› ç­¾åæ”¹åŠ¨è¾ƒå¤šï¼Œè¯·åœ¨å…¨åº“å›å½’æµ‹è¯•åç¡®è®¤å…¼å®¹æ€§ã€‚

---

### Frontend-Implement-robust-video-frame-recovery-for-corrupted-videos-29197
**SHA**: `6f35154` | ğŸ”— [æŸ¥çœ‹æäº¤](https://github.com/vllm-project/vllm/commit/6f351548b258d7ff618174817bfbdc0ee4758fb5)

**ğŸ¯ å˜æ›´ç±»å‹**ï¼šåŠŸèƒ½å¢å¼ºï¼ˆä¸ºè§†é¢‘è¾“å…¥åŠ å…¥å‰å‘â€‘æ‰«æå¸§æ¢å¤æœºåˆ¶ï¼‰  
**âš¡ é‡è¦ç¨‹åº¦**ï¼šğŸŸ¡ ä¸­  

**ğŸ“‹ å˜æ›´æ‘˜è¦**  
1. åœ¨ `vllm/multimodal/video.py` ä¸º OpenCV ç³»åˆ—è§†é¢‘åŠ è½½å™¨æ–°å¢ `frame_recovery` å‚æ•°ï¼Œå¹¶å®ç° `_read_frames_with_recovery`ã€`_can_use_for_recovery` ä¸¤ä¸ªå†…éƒ¨å·¥å…·å‡½æ•°ï¼Œå®ç°â€œç›®æ ‡å¸§è¯»å–å¤±è´¥ â†’ ä½¿ç”¨åç»­é¦–å¸§è¡¥å¿â€çš„åŠ¨æ€çª—å£æ¢å¤é€»è¾‘ã€‚  
2. æ–‡æ¡£ `multimodal_inputs.md` å¢åŠ ä½¿ç”¨è¯´æ˜åŠå‚æ•°è§£é‡Šã€‚  
3. æ–°å¢å•å…ƒæµ‹è¯•ï¼ˆæ¨¡æ‹ŸæŠ“å–å¤±è´¥ã€çœŸå® corrupted.mp4ã€åŠ¨æ€ backendï¼‰è¦†ç›–æ¢å¤è·¯å¾„ã€‚  
4. ç»†å¾®ä¿®æ­£ï¼š`benchmarks/datasets.py` ä¸­ä¸´æ—¶æ–‡ä»¶åˆ é™¤æ–¹å¼æ”¹ä¸º `delete=False` é˜²æ­¢ Windows ä¸Šå¼‚å¸¸ã€‚  

**ğŸ¯ å½±å“èŒƒå›´**  
- **æ ¸å¿ƒæ¨¡å—**ï¼š`vllm/multimodal/video.py`ï¼ˆæ‰€æœ‰ OpenCVâ€‘based è§†é¢‘ Loaderï¼‰ã€‚  
- **é…ç½®å…¥å£**ï¼š`--media-io-kwargs`ï¼ˆé€šè¿‡ `frame_recovery` å¼€å…³ï¼‰ï¼Œç¯å¢ƒå˜é‡ `VLLM_VIDEO_FETCH_TIMEOUT` ä¸å—å½±å“ã€‚  
- **æ–‡æ¡£**ï¼š`docs/features/multimodal_inputs.md`ã€‚  
- **æµ‹è¯•å¥—ä»¶**ï¼š`tests/multimodal/test_video.py`ï¼ˆæ–°å¢ 3 å¤§å—æµ‹è¯•ï¼‰ã€‚  

**ğŸ’¡ å…³æ³¨å»ºè®®**  

1. **å‘åå…¼å®¹**ï¼šé»˜è®¤ `frame_recovery=False`ï¼Œè€ç‰ˆæœ¬è¡Œä¸ºä¿æŒä¸å˜ã€‚è‹¥å·²æœ‰è°ƒç”¨åœ¨ `media_io_kwargs` ä¸­ä¼ å…¥æœªçŸ¥é”®ï¼Œä»ä¼šè¢«å¿½ç•¥ï¼›å»ºè®®åœ¨å‡çº§åæ£€æŸ¥æ—¥å¿—ï¼Œç¡®è®¤æ²¡æœ‰è¯¯è§¦ â€œframe_recoveryâ€ è¢«è¯¯è®¾ä¸º `True`ã€‚  
2. **æ€§èƒ½å†²å‡»**ï¼šæ¢å¤æ¨¡å¼ä¼šéå† **æ‰€æœ‰**å¸§ç›´è‡³ä¸‹ä¸€ä¸ªç›®æ ‡å¸§ï¼Œå¯èƒ½å¯¼è‡´æ¯”åŸå§‹ç¨€ç–æŠ½æ ·æ›´é«˜çš„ I/O ä¸ CPU å¼€é”€ã€‚å¯¹å¤§ä½“ç§¯ã€é•¿è§†é¢‘ä½¿ç”¨æ—¶è¯·è¯„ä¼° CPU/IO é™é¢ï¼Œå¿…è¦æ—¶è°ƒä½ `num_frames` æˆ– `fps`ã€‚  
3. **å¼‚å¸¸æ—¥å¿—**ï¼šæ¢å¤å¤±è´¥ï¼ˆåˆ°è§†é¢‘æœ«å°¾ä»æœªæ‰¾åˆ°å¯ç”¨å¸§ï¼‰ä¼šäº§ç”Ÿé¢å¤– `warning`ï¼Œä½†ä¸ä¼šæŠ›å¼‚å¸¸ã€‚è‹¥ç”¨æˆ·å¯¹å®Œæ•´å¸§è´¨é‡æœ‰ä¸¥æ ¼è¦æ±‚ï¼Œå¯åœ¨ä¸šåŠ¡å±‚é¢æ£€æµ‹ `metadata["recovered_map"]`ï¼ˆå½“å‰æœªæš´éœ²ï¼Œå¯è‡ªè¡Œåœ¨ `load_bytes` è¿”å›çš„ `metadata` ä¸­åŠ å…¥ï¼‰ä»¥å†³å®šæ˜¯å¦é€€å›é”™è¯¯ã€‚  
4. **æµ‹è¯•ä¾èµ–**ï¼šæ–°å¢æµ‹è¯•ä¾èµ– `opencv` ä¸ `corrupted.mp4` èµ„æºï¼ŒCI ç¯å¢ƒéœ€ç¡®ä¿ OpenCV å®‰è£…å®Œæ•´ä¸”èƒ½è¯»å–è¯¥ç¤ºä¾‹æ–‡ä»¶ã€‚è‹¥ä½¿ç”¨è‡ªå®šä¹‰åç«¯ï¼ˆå¦‚ `ffmpeg`ï¼‰ï¼Œæ¢å¤åŠŸèƒ½ä»ä¸å¯ç”¨ï¼Œæ–‡æ¡£åº”æ˜ç¡®è¯´æ˜ã€‚  
5. **ä»£ç ç»´æŠ¤**ï¼šæ¢å¤é€»è¾‘ä¸æ™®é€šè¯»å–åˆ†ç¦»ï¼Œåç»­è‹¥å¯¹ `opencv_dynamic` åšè¿›ä¸€æ­¥æŠ½è±¡ï¼Œåªéœ€åœ¨å¯¹åº” `load_bytes` ä¸­å¤ç”¨ `_read_frames_with_recovery`ã€‚å»ºè®®åœ¨ `VIDEO_LOADER_REGISTRY` æ³¨å†Œæ—¶åŠ å…¥ `supports_frame_recovery` æ ‡è¯†ï¼Œä¾¿äºä¸Šå±‚ç»Ÿä¸€æ£€æŸ¥ã€‚  

æ•´ä½“æ¥çœ‹ï¼Œæ­¤æ¬¡æ”¹åŠ¨ä¸ºå¤šæ¨¡æ€è§†é¢‘æ¨ç†æä¾›äº†å®ç”¨çš„é²æ£’æ€§æå‡ï¼Œå½±å“èŒƒå›´ä¸»è¦åœ¨è§†é¢‘åŠ è½½å™¨åŠå…¶è°ƒç”¨æ–¹ï¼Œå…¼å®¹æ€§è‰¯å¥½ï¼Œä½†åœ¨é«˜å¹¶å‘æˆ–è¶…é•¿è§†é¢‘åœºæ™¯ä¸‹éœ€å…³æ³¨é¢å¤–çš„è®¡ç®—ä¸ I/O å¼€é”€ã€‚ç¡®ä¿ CI ç¯å¢ƒå…·å¤‡ OpenCV ä¸ç¤ºä¾‹è§†é¢‘åå³å¯å®‰å…¨åˆå¹¶ã€‚

---

### Spec-DecodeUX-Add-acceptance-stats-to-`vllm-bench-serve`-report-31739
**SHA**: `d498997` | ğŸ”— [æŸ¥çœ‹æäº¤](https://github.com/vllm-project/vllm/commit/d49899732edd3e6c011ec9f922601d919250a4d2)

**ğŸ¯ å˜æ›´ç±»å‹**ï¼šåŠŸèƒ½å¢å¼ºï¼ˆåœ¨ `vllm bench serve` ä¸­æ–°å¢ Speculative Decodingï¼ˆæ¨æµ‹è§£ç ï¼‰æ¥å—ç‡ç»Ÿè®¡ï¼‰  
**âš¡ é‡è¦ç¨‹åº¦**ï¼šğŸŸ¡ ä¸­  

**ğŸ“‹ å˜æ›´æ‘˜è¦**  
1. æ–°å¢ `SpecDecodeMetrics` æ•°æ®ç±»ï¼Œç”¨äºä¿å­˜ Prometheus æš´éœ²çš„æ¨æµ‹è§£ç æŒ‡æ ‡ã€‚  
2. å®ç° `fetch_spec_decode_metrics`ï¼Œåœ¨åŸºå‡†å¼€å§‹å‰ååˆ†åˆ«æŠ“å–æŒ‡æ ‡å¹¶è®¡ç®—å¢é‡ã€‚  
3. å°†å¢é‡ç»Ÿè®¡ï¼ˆè‰ç¨¿æ•°ã€è‰ç¨¿ tokenã€æ¥å— tokenã€æ¥å—ç‡ã€æ¥å—é•¿åº¦ã€æŒ‰ä½ç½®æ¥å—ç‡ï¼‰å†™å…¥ benchmark ç»“æœå¹¶åœ¨ç»ˆç«¯ç¾åŒ–è¾“å‡ºã€‚  

**ğŸ¯ å½±å“èŒƒå›´**  
- `vllm/benchmarks/serve.py`ï¼ˆå”¯ä¸€ä¿®æ”¹æ–‡ä»¶ï¼‰ã€‚  
- ä¸ `vllm bench serve` CLIã€Prometheus æš´éœ²ç«¯ç‚¹ä»¥åŠç»“æœ JSON ç»“æ„ç´§å¯†ç›¸å…³ã€‚  

**ğŸ’¡ å…³æ³¨å»ºè®®**  
1. **å®¹é”™ä¸å…¼å®¹**ï¼š`fetch_spec_decode_metrics` æ•è· `ClientError` ä¸ `TimeoutError`ï¼Œä½†è‹¥è¿”å›é 200 çŠ¶æ€ç æˆ–æŒ‡æ ‡ç»“æ„å˜åŒ–ï¼Œä¼šç›´æ¥è¿”å› `None`ï¼Œå¯¼è‡´åç»­ç»Ÿè®¡è¢«è·³è¿‡ã€‚å»ºè®®åœ¨æ—¥å¿—ä¸­è®°å½•é”™è¯¯åŸå› ï¼Œä¾¿äºä½¿ç”¨è€…æ’æŸ¥ã€‚  
2. **æŒ‡æ ‡è§£æ**ï¼šå½“å‰ä¾èµ–å­—ç¬¦ä¸²åŒ¹é…ï¼ˆ`line.startswith("vllm:spec_decode")`ï¼‰å¹¶æ‰‹åŠ¨è§£ææ ‡ç­¾ï¼Œè‹¥ Prometheus å¢åŠ å‰ç¼€æˆ–æ”¹åä¼šå¤±æ•ˆã€‚å¯è€ƒè™‘ä½¿ç”¨æ­£åˆ™è¡¨è¾¾å¼æˆ–å®˜æ–¹ `prometheus_client.parser`ã€‚  
3. **ç»Ÿè®¡å‡†ç¡®æ€§**ï¼š`per_position_acceptance_rates` åªåœ¨ `delta_drafts > 0` æ—¶è®¡ç®—ï¼Œè‹¥å‡ºç°è´Ÿå¢é‡ï¼ˆå¼‚å¸¸é‡å¯ï¼‰ä¼šäº§ç”Ÿé™¤é›¶é”™è¯¯æˆ–ä¸åˆç†å€¼ã€‚åº”å¯¹è´Ÿå¢é‡åšæ˜¾å¼æ£€æŸ¥å¹¶ç½®é›¶ã€‚  
4. **è¾“å‡ºæ ¼å¼**ï¼šæ‰“å°çš„æ¥å—ç‡/é•¿åº¦å·²ä¹˜ä»¥ 100 ä¸æœªä¹˜æ··ç”¨ï¼Œå»ºè®®ç»Ÿä¸€ä¸ºç™¾åˆ†æ¯”æˆ–ä¿ç•™å°æ•°ï¼Œé¿å…è¯¯å¯¼ã€‚  
5. **JSON å…¼å®¹**ï¼šæ–°å­—æ®µåŠ å…¥ `result`ï¼Œä¸‹æ¸¸ä½¿ç”¨æ—§ç‰ˆ JSON çš„å·¥å…·å¯èƒ½éœ€è¦æ›´æ–° schemaã€‚å»ºè®®åœ¨æ–‡æ¡£ä¸­åˆ—å‡ºæ–°å¢é”®å¹¶æä¾›å‘åå…¼å®¹è¯´æ˜ã€‚  

æ€»ä½“è€Œè¨€ï¼Œæ–°å¢çš„ç»Ÿè®¡å¯¹åˆ†ææ¨æµ‹è§£ç æ€§èƒ½ä»·å€¼æ˜¾è‘—ï¼Œä»£ç å®ç°æ¸…æ™°ï¼Œä½†å¯é€šè¿‡ä¸Šè¿°ç»†èŠ‚æå‡é²æ£’æ€§å’Œå¯ç»´æŠ¤æ€§ã€‚

---

### Fix-RecursionError-in-MediaWithBytes-unpickling-31191
**SHA**: `ada6f91` | ğŸ”— [æŸ¥çœ‹æäº¤](https://github.com/vllm-project/vllm/commit/ada6f91d561ab693fd85f028bc44b8c8058d3073)

**ğŸ¯ å˜æ›´ç±»å‹**ï¼šBug ä¿®å¤  
**âš¡ é‡è¦ç¨‹åº¦**ï¼šğŸŸ¡ ä¸­ï¼ˆå½±å“åˆ°å¤šæ¨¡æ€è¾“å…¥çš„æŒä¹…åŒ–ä¸è·¨è¿›ç¨‹ä¼ é€’ï¼‰  

**ğŸ“‹ å˜æ›´æ‘˜è¦**  
- åœ¨ `vllm/multimodal/base.py` ä¸º `MediaWithBytes.__getattr__` å¢åŠ  guardï¼Œé˜²æ­¢åœ¨ pickle ååºåˆ—åŒ–æœŸé—´ `self.media` è¿˜æœªåˆå§‹åŒ–æ—¶å‡ºç°é€’å½’è°ƒç”¨å¯¼è‡´ `RecursionError`ã€‚  
- æ–°å¢å•å…ƒæµ‹è¯• `tests/multimodal/test_image.py::test_media_with_bytes_pickle_roundtrip`ï¼ŒéªŒè¯ pickleâ€‘roundâ€‘trip åå±æ€§å§”æ‰˜ä»ç„¶æ­£å¸¸ã€‚  
- å°†è¯¥æµ‹è¯•æ–‡ä»¶åŠ å…¥ `tools/pre_commit/check_pickle_imports.py`ï¼Œç¡®ä¿ä»£ç å®¡æŸ¥é˜¶æ®µä¸å¿½è§† pickleâ€‘ç›¸å…³çš„å¯¼å…¥ã€‚  

**ğŸ¯ å½±å“èŒƒå›´**  
- æ ¸å¿ƒæ¨¡å—ï¼š`vllm.multimodal.base.MediaWithBytes`ï¼ˆç”¨äºåŒ…è£…å›¾ç‰‡ã€éŸ³é¢‘ç­‰äºŒè¿›åˆ¶åª’ä½“ï¼‰  
- ç›¸å…³æµ‹è¯•ï¼š`tests/multimodal/test_image.py`  
- é¢„æäº¤æ£€æŸ¥è„šæœ¬ï¼š`tools/pre_commit/check_pickle_imports.py`  

**ğŸ’¡ å…³æ³¨å»ºè®®**  
- **å¼€å‘è€…**ï¼šè‹¥åœ¨è‡ªå®šä¹‰ `MediaWithBytes` å­ç±»æˆ–å…¶å®ƒåŒ…è£…ç±»ä¸­è¦†ç›– `__setstate__`/`__reduce__`ï¼ŒåŒæ ·éœ€è¦ç¡®ä¿åœ¨ååºåˆ—åŒ–æœŸé—´ä¸ä¾èµ–æœªåˆå§‹åŒ–çš„å±æ€§ã€‚  
- **ç”¨æˆ·**ï¼šåœ¨ä½¿ç”¨ `MediaWithBytes` è·¨è¿›ç¨‹æˆ–æŒä¹…åŒ–æ—¶ï¼Œå¯æ”¾å¿ƒè¿›è¡Œ pickleï¼Œå·²ä¸å†å‡ºç°é€’å½’é”™è¯¯ã€‚å»ºè®®åœ¨å‡çº§åè¿è¡Œå®Œæ•´æµ‹è¯•ï¼Œç¡®è®¤å…¶å®ƒè‡ªå®šä¹‰åª’ä½“å¯¹è±¡å…¼å®¹ã€‚  

æ€»ä½“è€Œè¨€ï¼Œæ­¤æ¬¡ä¿®å¤æ¶ˆé™¤äº†ä¸€ä¸ªåœ¨é«˜å¹¶å‘/åˆ†å¸ƒå¼éƒ¨ç½²åœºæ™¯ä¸‹å¯èƒ½å¯¼è‡´è¿›ç¨‹å´©æºƒçš„éšæ‚£ï¼Œæå‡äº†åº“çš„ç¨³å¥æ€§ã€‚

---

### ROCmCI-Fix-tests/compile-unit-tests-28895
**SHA**: `c071636` | ğŸ”— [æŸ¥çœ‹æäº¤](https://github.com/vllm-project/vllm/commit/c07163663d0a5ab6db1e4833c44305545f847c85)

**ğŸ¯ å˜æ›´ç±»å‹**ï¼šåŠŸèƒ½å¢å¼º / CI ç¨³å®šæ€§æ”¹è¿›ï¼ˆé’ˆå¯¹ ROCm å¹³å°çš„å…¼å®¹æ€§ä¿®å¤ï¼‰  
**âš¡ é‡è¦ç¨‹åº¦**ï¼šğŸŸ¡ ä¸­  

**ğŸ“‹ å˜æ›´æ‘˜è¦**  
1. åœ¨ `tests/compile/fullgraph/test_basic_correctness.py` ä¸­å¼•å…¥ `current_platform.is_rocm()` åˆ¤æ–­ï¼Œæ ¹æ®å¹³å°é€‰æ‹© `attn_backend`ï¼ˆ`FLASH_ATTN` â†’ `ROCM_ATTN`ï¼‰ï¼Œå¹¶å¯¹ä¸æ”¯æŒçš„ encoder è‡ªæ³¨æ„åŠ›æ¨¡å‹åš `skipif`ã€‚  
2. åœ¨ `tests/compile/fullgraph/test_full_cudagraph.py` ä¸­ä¸º ROCm ç¯å¢ƒå±è”½ `FLASHINFER` åç«¯ã€‚  
3. åœ¨ `tests/compile/test_noop_elimination.py` ä¸­å°† `torch.empty` æ›¿æ¢ä¸º `torch.randn`ï¼ˆé¿å… ROCm ä¸Šæœªåˆå§‹åŒ–çš„å†…å­˜ï¼‰ï¼Œå¹¶æ”¹ä¸ºéåŸä½åŠ æ³• `x = x + ...`ï¼Œé˜²æ­¢ inplace å¯¼è‡´çš„å›¾ä¼˜åŒ–å·®å¼‚ã€‚  

**ğŸ¯ å½±å“èŒƒå›´**  
- **å¹³å°æ£€æµ‹æ¨¡å—**ï¼š`vllm.platforms.current_platform`ï¼ˆæ–°å¢ `is_rocm` åˆ¤æ–­çš„ä½¿ç”¨ï¼‰ã€‚  
- **æ³¨æ„åŠ›åç«¯æ³¨å†Œ**ï¼š`vllm.attention.backends.registry.AttentionBackendEnum`ï¼ˆå¢åŠ å¯¹ ROCm ä¸æ”¯æŒçš„ `FLASHINFER` çš„è·³è¿‡é€»è¾‘ï¼‰ã€‚  
- **ç¼–è¯‘/å…¨å›¾å•å…ƒæµ‹è¯•**ï¼š`tests/compile/fullgraph/*`ã€`tests/compile/test_noop_elimination.py`ã€‚  
- **é€šç”¨æ¨¡å‹åˆå§‹åŒ–**ï¼šæ¶‰åŠå¼ é‡åˆ›å»ºæ–¹å¼çš„å¾®è°ƒï¼Œå½±å“æ‰€æœ‰åœ¨ ROCm ä¸Šè¿è¡Œçš„æµ‹è¯•ã€‚  

**ğŸ’¡ å…³æ³¨å»ºè®®**  
1. **å¹³å°æ£€æµ‹ç»Ÿä¸€åŒ–**ï¼šå»ºè®®åœ¨ `vllm.config` æˆ–å…¬å…±å·¥å…·ä¸­å°è£… `is_rocm`ï¼Œé¿å…æ¯ä¸ªæµ‹è¯•æ•£è½å¤šå¤„ã€‚  
2. **åç«¯å…¼å®¹è¡¨**ï¼šç»´æŠ¤ä¸€å¼ æ˜ç¡®çš„åç«¯â€‘å¹³å°å…¼å®¹çŸ©é˜µï¼ˆå¦‚ `FLASH_ATTN`ã€`ROCM_ATTN`ã€`FLASHINFER`ï¼‰ï¼Œå¹¶åœ¨ CI ä¸­ç»Ÿä¸€ä½¿ç”¨ï¼Œé˜²æ­¢é—æ¼ã€‚  
3. **å¼ é‡åˆ›å»ºå®‰å…¨**ï¼šåœ¨åº“ä»£ç ï¼ˆéä»…æµ‹è¯•ï¼‰ä¸­è‹¥æœ‰ `torch.empty` ç”¨äºå ä½ï¼Œåº”æ”¹ä¸ºæ˜¾å¼åˆå§‹åŒ–æˆ–ä½¿ç”¨ `torch.zeros`ï¼Œä»¥å…¼å®¹ ROCm çš„æœªåˆå§‹åŒ–å†…å­˜é—®é¢˜ã€‚  
4. **CI è¿è¡Œæ ‡ç­¾**ï¼šä¸º ROCm CI æ·»åŠ ä¸“å±æ ‡ç­¾æˆ–çŸ©é˜µï¼Œç¡®ä¿è¿™äº›è·³è¿‡é€»è¾‘åœ¨å…¶ä»–å¹³å°ä¸ç”Ÿæ•ˆï¼Œé˜²æ­¢è¯¯åˆ åŠŸèƒ½ã€‚  
5. **æ–‡æ¡£æ›´æ–°**ï¼šåœ¨ README æˆ–å¹³å°å…¼å®¹ç« èŠ‚æ³¨æ˜ï¼šåœ¨ ROCm ç¯å¢ƒä¸‹éƒ¨åˆ†æ³¨æ„åŠ›å®ç°ï¼ˆFlashInferã€Encoderâ€‘selfâ€‘attentionï¼‰æš‚ä¸å¯ç”¨ï¼Œç”¨æˆ·éœ€æ‰‹åŠ¨æŒ‡å®š `--attn-backend=ROCM_ATTN` æˆ–ä½¿ç”¨ `--skip-attn-backend=FLASHINFER`ã€‚  

é€šè¿‡ä¸Šè¿°ä¿®æ”¹ï¼ŒCI åœ¨ AMD GPUï¼ˆROCmï¼‰ä¸Šèƒ½å¤Ÿé¡ºåˆ©é€šè¿‡ï¼ŒåŒæ—¶ä¹Ÿä¸ºåç»­åœ¨æ­£å¼ä»£ç ä¸­åŠ å…¥ ROCm ç‰¹åŒ–æä¾›äº†æ¸…æ™°çš„è·¯å¾„ã€‚

---

### Perf-Async-Scheduling-+-Speculative-Decoding-+-Structured-Outputs-29821
**SHA**: `f7008ce` | ğŸ”— [æŸ¥çœ‹æäº¤](https://github.com/vllm-project/vllm/commit/f7008ce1c4c1cf92d8cc13ad7e966d4b82a32c65)

**ğŸ¯ å˜æ›´ç±»å‹**ï¼šåŠŸèƒ½å¢å¼ºï¼ˆä¸ºå¼‚æ­¥è°ƒåº¦ + é¢„æµ‹å¼è§£ç åŠ å…¥ç»“æ„åŒ–è¾“å‡ºæ”¯æŒï¼‰  
**âš¡ é‡è¦ç¨‹åº¦**ï¼šğŸŸ¡ ä¸­  
**ğŸ“‹ å˜æ›´æ‘˜è¦**ï¼š  
1. ä¸º `AsyncScheduler` å¢åŠ å¯¹ç»“æ„åŒ–è¾“å‡ºè¯·æ±‚çš„æ„ŸçŸ¥ï¼Œæ‰©å±• `SchedulerOutput`ï¼Œè®°å½•æ˜¯å¦å­˜åœ¨ç»“æ„åŒ–è¾“å‡ºä»¥åŠå› æ–‡æ³•ä¸åŒ¹é…è¢«è¿‡æ»¤çš„è‰ç¨¿ token æ•°ã€‚  
2. `Scheduler` æ¥å£æ–°å¢ `update_draft_token_ids_in_output`ï¼Œåœ¨å¼‚æ­¥è·¯å¾„ä¸­å¯¹è‰ç¨¿ token è¿›è¡Œæ–‡æ³•æ ¡éªŒå¹¶åœ¨ `SchedulerOutput` ä¸­åŒæ­¥æ›´æ–°ã€‚  
3. `Engine` åœ¨å¤„ç† deferâ€‘schedulerâ€‘output æ—¶å–å‡ºè‰ç¨¿ tokenï¼Œè°ƒç”¨æ–°æ–¹æ³•è¿‡æ»¤éæ³• tokenï¼Œéšåå†è®¡ç®— grammar bitmaskã€‚  
4. `GPUModelRunner` å¼•å…¥è·¨è®¾å¤‡å¼‚æ­¥æ‹·è´è‰ç¨¿ tokenï¼ˆCPUâ€¯+â€¯äº‹ä»¶ï¼‰ï¼Œå¹¶åœ¨ç¼ºå¤± drafter æ—¶ç”¨å…¨ 0 å¡«å……ï¼Œä»¥å…¼å®¹ç»“æ„åŒ–è¾“å‡ºã€‚  
5. æµ‹è¯•ç”¨ä¾‹æ‹‰å®½ `max_tokens`ï¼ŒåŠ å…¥ç»“æ„åŒ–è¾“å‡ºå‚æ•°ï¼Œå»æ‰å¯¹ `structured_outputs` çš„ç¦æ­¢æ£€æŸ¥ã€‚

**ğŸ¯ å½±å“èŒƒå›´**ï¼š  
- `vllm/v1/core/sched/*`ï¼ˆè°ƒåº¦å™¨ã€è¾“å‡ºç»“æ„ï¼‰  
- `vllm/v1/engine/*`ï¼ˆæ ¸å¿ƒè°ƒåº¦å¾ªç¯ã€è¾“å…¥æ ¡éªŒï¼‰  
- `vllm/v1/worker/gpu_model_runner.py`ï¼ˆGPU ç«¯è‰ç¨¿ token ç®¡ç†ï¼‰  
- æµ‹è¯• `tests/v1/e2e/test_async_scheduling.py`

**ğŸ’¡ å…³æ³¨å»ºè®®**  
1. **å®ç°å…¼å®¹**ï¼šæ‰€æœ‰å®ç° `Scheduler` æ¥å£çš„ç±»ï¼ˆå¦‚åŒæ­¥è°ƒåº¦å™¨ï¼‰å¿…é¡»å®ç°æ–°æŠ½è±¡æ–¹æ³• `update_draft_token_ids_in_output`ï¼Œå³ä¾¿ä»…åšç©ºå®ç°ï¼Œä»¥é˜²è¿è¡Œæ—¶æŠ½è±¡é”™è¯¯ã€‚  
2. **æ€§èƒ½ç›‘æ§**ï¼šå¼‚æ­¥æ‹·è´è‰ç¨¿ token ä¼šäº§ç”Ÿé¢å¤–çš„ CUDAâ€¯eventâ€¯åŒæ­¥ï¼›åœ¨é«˜å¹¶å‘ã€ç»“æ„åŒ–è¾“å‡ºé¢‘ç¹çš„åœºæ™¯ä¸‹è¯·ç›‘æ§ GPUâ€¯â†’â€¯CPU å¸¦å®½åŠäº‹ä»¶å»¶è¿Ÿã€‚  
3. **æ–‡æ³•æ ¡éªŒ**ï¼š`Grammar.accept_tokens` ä»å¯èƒ½è¿”å› `False`ï¼ˆå·²åŠ å…¥ warningï¼‰ï¼Œå»ºè®®åœ¨ä¸Šå±‚æ•è·å¹¶å†³å®šæ˜¯å¦å›é€€åˆ°æ™®é€šè§£ç ï¼Œä»¥å…å¤§é‡æ— æ•ˆ token å½±å“æ¥å—ç‡ç»Ÿè®¡ã€‚  
4. **ç»Ÿè®¡å‡†ç¡®æ€§**ï¼š`make_spec_decoding_stats` ç°åœ¨ä¼šå‡å» `num_invalid_spec_tokens`ï¼Œç¡®ä¿æ¥å—ç‡ä¸å—éæ³•è‰ç¨¿ token å½±å“ã€‚è‹¥è‡ªè¡Œç»Ÿè®¡ï¼Œéœ€è¦åŒæ­¥æ­¤å­—æ®µã€‚  
5. **æ–‡æ¡£ä¸ç¤ºä¾‹**ï¼šæ›´æ–° README/Docsï¼Œè¯´æ˜åœ¨ **async + specâ€‘decode** åœºæ™¯ä¸‹å¯ä»¥å®‰å…¨ä½¿ç”¨ `structured_outputs`ï¼Œå¹¶æä¾› JSON schema ç¤ºä¾‹ã€‚  

æ€»ä½“æ¥çœ‹ï¼Œæ­¤æ¬¡æ”¹åŠ¨ä¸º VLLM åœ¨é«˜ååå¼‚æ­¥è°ƒåº¦ä¸‹æä¾›ç»“æ„åŒ–è¾“å‡ºèƒ½åŠ›å¥ å®šäº†åŸºç¡€ï¼ŒåŠŸèƒ½ä»·å€¼é«˜ï¼Œä½†éœ€è¦ç¡®ä¿æ‰€æœ‰è°ƒåº¦å™¨å®ç°æ–°çš„æŠ½è±¡æ–¹æ³•å¹¶å…³æ³¨å› è·¨è®¾å¤‡æ‹·è´å¼•å…¥çš„è½»å¾®æ€§èƒ½å¼€é”€ã€‚

---

### Bugfix-Fix-GLM-4-MoE-router-logits-dtype-for-data-parallel-chunking-31055
**SHA**: `4e67a8f` | ğŸ”— [æŸ¥çœ‹æäº¤](https://github.com/vllm-project/vllm/commit/4e67a8f616f4f202fd7a549978914f398a738d49)

**ğŸ¯ å˜æ›´ç±»å‹**ï¼šBugä¿®å¤  
**âš¡ é‡è¦ç¨‹åº¦**ï¼šğŸŸ¡ ä¸­  

**ğŸ“‹ å˜æ›´æ‘˜è¦**  
ä¸ºäº†è§£å†³ GLMâ€‘4 MoE åœ¨æ•°æ®å¹¶è¡Œåˆ†å—ï¼ˆDP chunkingï¼‰æ—¶è·¯ç”± logits ç±»å‹ä¸åŒ¹é…å¯¼è‡´çš„æ•°å€¼é”™è¯¯ï¼Œæ–°å¢ `router_logits_dtype` é…ç½®å­—æ®µã€‚é»˜è®¤å– `in_dtype`ï¼Œå¹¶åœ¨ `FusedMoE` åˆå§‹åŒ–åŠ `ensure_dp_chunking_init` ä¸­ä½¿ç”¨è¯¥ dtype åˆ›å»º `batched_router_logits` ç¼“å†²åŒºï¼›åœ¨ GLMâ€‘4 MoE çš„æ¨¡å‹æ„é€ å‡½æ•°ä¸­æ˜¾å¼æŒ‡å®šä¸º `torch.float32`ã€‚

**ğŸ¯ å½±å“èŒƒå›´**  
- `vllm/model_executor/layers/fused_moe/config.py`ï¼ˆæ–°å¢å­—æ®µä¸é»˜è®¤é€»è¾‘ï¼‰  
- `vllm/model_executor/layers/fused_moe/layer.py`ï¼ˆæ„é€ å‡½æ•°ç­¾åã€å†…éƒ¨å‚æ•°ä¼ é€’ã€ç¼“å†²åŒºåˆ›å»ºï¼‰  
- `vllm/model_executor/models/glm4_moe.py`ï¼ˆæ¨¡å‹å®ä¾‹åŒ–æ—¶å¼ºåˆ¶ä½¿ç”¨ `float32`ï¼‰  

**ğŸ’¡ å…³æ³¨å»ºè®®**  
1. **å…¼å®¹æ€§**ï¼š`router_logits_dtype` è®¾ä¸ºå¯é€‰å¹¶åœ¨ `__post_init__` ä¸­å›å¡«ï¼Œä¿æŒæ—§é…ç½®ä¸å—å½±å“ã€‚è‹¥æœªæ¥æœ‰å…¶å®ƒ MoE å®ç°éœ€ä¸åŒ dtypeï¼Œå»ºè®®åœ¨å¯¹åº”æ¨¡å‹å®ç°å¤„æ˜¾å¼ä¼ å‚ã€‚  
2. **æ–‡æ¡£**ï¼šåœ¨ `FusedMoEConfig` ä¸ `FusedMoE` çš„ç”¨æˆ·æ–‡æ¡£ä¸­åŠ å…¥ `router_logits_dtype` è¯´æ˜ï¼Œç‰¹åˆ«å¼ºè°ƒåœ¨ DPâ€‘chunking åœºæ™¯ä¸‹çš„å¿…è¦æ€§ã€‚  
3. **æµ‹è¯•**ï¼šè¡¥å……å•å…ƒæµ‹è¯•ï¼ŒéªŒè¯ä¸åŒ `in_dtype`ï¼ˆå¦‚ `float16`ã€`bfloat16`ï¼‰ä¸‹ `batched_router_logits` çš„ dtype æ­£ç¡®æ€§ï¼›è¦†ç›– GLMâ€‘4 ä¸å…¶å®ƒ MoE æ¨¡å‹çš„å‰å‘æ¨ç†ã€‚  
4. **æ€§èƒ½**ï¼šfloat32 è·¯ç”± logits å¯èƒ½å¢åŠ æ˜¾å­˜å ç”¨ï¼Œå»ºè®®è¯„ä¼°åœ¨å¤§æ¨¡å‹ã€å¤šå¡éƒ¨ç½²æ—¶çš„æ˜¾å­˜å½±å“ã€‚è‹¥æ˜¾å­˜ç´§å¼ ï¼Œå¯è€ƒè™‘åœ¨ä¸éœ€è¦ DPâ€‘chunking æ—¶è‡ªè¡ŒæŒ‡å®š `router_logits_dtype` ä¸º `in_dtype`ã€‚  
5. **å¼‚å¸¸æ£€æŸ¥**ï¼šå½“å‰æ²¡æœ‰æ˜¾å¼æ ¡éªŒ `router_logits_dtype` ä¸ `in_dtype` çš„å…¼å®¹æ€§ï¼Œå»ºè®®åœ¨ `__post_init__` åŠ å…¥æ–­è¨€æˆ–è­¦å‘Šï¼Œä»¥é˜²è¯¯ä¼ ä¸æ”¯æŒçš„ dtypeï¼ˆä¾‹å¦‚ `int8`ï¼‰ã€‚  

æ€»ä½“è€Œè¨€ï¼Œæ­¤æ”¹åŠ¨å®šä½æ˜ç¡®ã€å®ç°ç®€æ´ï¼Œè§£å†³äº† GLMâ€‘4 MoE çš„æ•°å€¼ä¸ä¸€è‡´é—®é¢˜ï¼Œåªéœ€æŒ‰ä¸Šè¿°å»ºè®®å®Œå–„æ–‡æ¡£å’Œæµ‹è¯•ï¼Œå³å¯å®‰å…¨ä¸Šçº¿ã€‚

---

### Log-add-log-about-gpu-worker-init-snapshot-and-requested-memory-29493
**SHA**: `6f5e653` | ğŸ”— [æŸ¥çœ‹æäº¤](https://github.com/vllm-project/vllm/commit/6f5e65338346a0be4466bfb31423c2968b7363bd)

**ğŸ¯ å˜æ›´ç±»å‹**ï¼šå…¶ä»–ï¼ˆæ—¥å¿—ä¸å¯è¯»æ€§å¢å¼ºï¼‰  
**âš¡ é‡è¦ç¨‹åº¦**ï¼šğŸŸ¡ ä¸­  

**ğŸ“‹ å˜æ›´æ‘˜è¦**  
1. æ–°å¢ `format_gib()`ï¼Œç»Ÿä¸€æŠŠå­—èŠ‚æ•°è½¬ä¸ºä¿ç•™ä¸¤ä½å°æ•°çš„ GiBï¼Œå–ä»£é¡¹ç›®ä¸­æ•£å¸ƒçš„ `lambda b: b / GiB_bytes`ã€‚  
2. ä¸º `MemorySnapshot` æ·»åŠ  `__repr__`ï¼Œä½¿ç”¨ `format_gib` æ‰“å°æ›´å‹å¥½çš„å†…å­˜å¿«ç…§ã€‚  
3. å¤šå¤„æ—¥å¿—ä¿¡æ¯æ”¹ä¸ºä½¿ç”¨ `format_gib`ï¼Œå¹¶å°† `request_memory` çš„è¿”å›ç±»å‹ç”± `float` æ”¹ä¸º `int`ï¼ˆå‘ä¸Šå–æ•´ï¼‰ï¼ŒåŒæ—¶åœ¨å¼‚å¸¸ä¿¡æ¯ä¸­ä¹Ÿä½¿ç”¨ç»Ÿä¸€çš„æ ¼å¼ã€‚  
4. åˆ é™¤ä¸å†éœ€è¦çš„ `GiB_bytes` å¯¼å…¥ï¼Œæ¸…ç†äº†å†—ä½™ lambdaã€‚

**ğŸ¯ å½±å“èŒƒå›´**  
- `vllm/utils/mem_utils.py`ï¼ˆæ ¸å¿ƒå·¥å…·å‡½æ•°ã€æ•°æ®ç»“æ„ï¼‰  
- `vllm/v1/worker/gpu_worker.py`ï¼ˆGPU worker åˆå§‹åŒ–ã€å†…å­˜æ£€æŸ¥ã€æ—¥å¿—ï¼‰  
- `vllm/v1/worker/utils.py`ï¼ˆå†…å­˜è¯·æ±‚è®¡ç®—ã€å¼‚å¸¸æç¤ºï¼‰  

**ğŸ’¡ å…³æ³¨å»ºè®®**  

1. **å…¼å®¹æ€§æ£€æŸ¥**ï¼š`request_memory` ç°åœ¨è¿”å› `int`ï¼Œå¦‚æœé¡¹ç›®ä¸­æœ‰å…¶ä»–æ¨¡å—ç›´æ¥ä¾èµ–å…¶è¿”å›çš„ `float`ï¼ˆä¾‹å¦‚åšæ¯”ä¾‹è¿ç®—ï¼‰ï¼Œè¯·ç¡®è®¤å·²é€‚é…æˆ–æ˜¾å¼è½¬æ¢ä¸º `float`ã€‚  
2. **æ—¥å¿—æœŸæœ›**ï¼šæ–°å¢ `debug` çº§åˆ«çš„å†…å­˜å¿«ç…§æ—¥å¿—ï¼ˆ`%r`ï¼‰ï¼Œåœ¨ç”Ÿäº§ç¯å¢ƒè‹¥æ—¥å¿—çº§åˆ«ä¸º `INFO`ï¼Œè¿™äº›ä¿¡æ¯ä»ä¸ä¼šæ³„æ¼ï¼Œä½†è¯·ç¡®ä¿æ—¥å¿—é…ç½®ä¸ä¼šæ„å¤–å¼€å¯è¿‡å¤š `DEBUG`ï¼Œå¯¼è‡´ç£ç›˜å ç”¨æ¿€å¢ã€‚  
3. **å•å…ƒæµ‹è¯•**ï¼šæ›´æ–°æˆ–æ–°å¢å¯¹åº”çš„æµ‹è¯•ç”¨ä¾‹ï¼ŒéªŒè¯  
   - `format_gib` çš„å››èˆäº”å…¥è¡Œä¸ºï¼ˆå¦‚ 1â€¯GiBâ€¯+â€¯0.005â€¯GiB â†’ 1.01â€¯GiBï¼‰ã€‚  
   - `MemorySnapshot.__repr__` è¾“å‡ºå®Œæ•´å­—æ®µä¸”æ•°å€¼å·²é€šè¿‡ `format_gib` å¤„ç†ã€‚  
   - `request_memory` åœ¨ä¸åŒ `gpu_memory_utilization` ä¸‹è¿”å›æ•´æ•°å¹¶æŠ›å‡ºé¢„æœŸå¼‚å¸¸ã€‚  
4. **ä»£ç é£æ ¼**ï¼šå·²ç»ç§»é™¤å¤§é‡ `GiB = lambda b: ...`ï¼Œå»ºè®®åœ¨å‰©ä½™æ–‡ä»¶ä¸­ä¹Ÿç»Ÿä¸€ä½¿ç”¨ `format_gib`ï¼Œä¿æŒé£æ ¼ä¸€è‡´ã€‚  
5. **æ–‡æ¡£åŒæ­¥**ï¼šè‹¥é¡¹ç›®æ–‡æ¡£æˆ– README ä¸­å±•ç¤ºäº†å†…å­˜æ•°å€¼çš„æ ¼å¼ï¼ˆå¦‚ â€œ%.2f GiBâ€ï¼‰ï¼Œè¯·åŒæ­¥æ”¹ä¸º â€œ%s GiBâ€ æˆ–ç›´æ¥å¼•ç”¨ `format_gib` çš„è¯´æ˜ï¼Œä»¥å…äº§ç”Ÿæ··æ·†ã€‚  

æ€»ä½“æ¥çœ‹ï¼Œæ­¤æ¬¡æ”¹åŠ¨æå‡äº†æ—¥å¿—å¯è¯»æ€§å’Œç»Ÿä¸€æ€§ï¼Œå¯¹åŠŸèƒ½æ²¡æœ‰å®è´¨å½±å“ï¼Œé£é™©ä¸»è¦åœ¨è¿”å›ç±»å‹çš„å¾®è°ƒä¸Šã€‚å®Œæˆä¸Šè¿°æ£€æŸ¥åå³å¯å®‰å…¨åˆå¹¶ã€‚

---

### Attention2/n-Remove-usage-of-deprecated-`seq_lens_cpu`-and-`num_computed_...
**SHA**: `4c73be1` | ğŸ”— [æŸ¥çœ‹æäº¤](https://github.com/vllm-project/vllm/commit/4c73be14e0397e99162ca13a8b559670c5abd3b0)

**ğŸ¯ å˜æ›´ç±»å‹**ï¼šBug ä¿®å¤ / ä»£ç é‡æ„  
**âš¡ é‡è¦ç¨‹åº¦**ï¼šğŸŸ¡ ä¸­  

**ğŸ“‹ å˜æ›´æ‘˜è¦**  
æœ¬æ¬¡æäº¤åˆ é™¤äº† `CommonAttentionMetadata` ä¸­å·²åºŸå¼ƒçš„å±æ€§ `seq_lens_cpu`ã€`num_computed_tokens_cpu` çš„ç›´æ¥ä½¿ç”¨ï¼Œç»Ÿä¸€æ”¹ä¸ºè°ƒç”¨æ–°å°è£…çš„ `compute_num_computed_tokens()` æ–¹æ³•ï¼Œä»¥ç¡®ä¿åœ¨ä¸åŒè®¾å¤‡/å¼‚æ­¥åœºæ™¯ä¸‹è·å–çš„å·²è®¡ç®— token æ•°ä¿æŒä¸€è‡´ã€‚  

**ğŸ¯ å½±å“èŒƒå›´**  
- `vllm/v1/attention/backends/gdn_attn.py`  
- `vllm/v1/attention/backends/mamba2_attn.py`  
- `vllm/v1/attention/backends/mamba_attn.py`  

è¿™äº›æ–‡ä»¶å±äºæ³¨æ„åŠ›å®ç°å±‚ï¼Œæ¶‰åŠå‰ç¼€ç¼“å­˜ã€å—ç´¢å¼•å’Œè§£ç /é¢„å¡«å…… token çš„è®¡æ•°é€»è¾‘ã€‚

**ğŸ’¡ å…³æ³¨å»ºè®®**  
1. **åŠŸèƒ½éªŒè¯**ï¼šè¿è¡ŒåŒ…å«å¤šè½®æ¨ç†ã€å¹¶è¡Œ Prefill + Decode çš„å•å…ƒæµ‹è¯•ï¼Œç¡®è®¤ `compute_num_computed_tokens()` åœ¨ CPU/GPUã€torch.compile ç¯å¢ƒä¸‹è¿”å›çš„å¼ é‡ä¸æ—§å®ç°ä¿æŒæ•°å€¼ä¸€è‡´ã€‚  
2. **æ€§èƒ½æ£€æŸ¥**ï¼šè™½ç„¶æ”¹åŠ¨ä»…æ˜¯å±æ€§è®¿é—®æ–¹å¼ï¼Œä½†åœ¨é«˜å¹¶å‘åœºæ™¯ä¸‹åº”ç›‘æ§ä¸€æ¬¡æ€§ `to(device)` çš„å¼€é”€ï¼Œç¡®ä¿ä¸ä¼šå¼•å…¥é¢å¤–çš„åŒæ­¥ã€‚  
3. **å‘åå…¼å®¹**ï¼šè‹¥å¤–éƒ¨ä»£ç ä»å¯èƒ½ç›´æ¥è®¿é—® `num_computed_tokens_cpu`ï¼Œè¯·åœ¨ `CommonAttentionMetadata` ä¸­ä¿ç•™åªè¯»å±æ€§æˆ–æŠ›å‡ºæ˜ç¡®çš„å¼ƒç”¨è­¦å‘Šï¼Œä»¥å…å‡ºç°æ„å¤– AttributeErrorã€‚  
4. **æ–‡æ¡£æ›´æ–°**ï¼šåœ¨ `attention` æ¨¡å—çš„ API æ–‡æ¡£é‡Œæ ‡æ³¨ `compute_num_computed_tokens()` ä¸ºè·å–å·²è®¡ç®— token æ•°çš„å”¯ä¸€æ¨èå…¥å£ã€‚  

é€šè¿‡ä¸Šè¿°æ£€æŸ¥ï¼Œå¯ç¡®ä¿æœ¬æ¬¡å»é™¤åºŸå¼ƒå±æ€§çš„æ”¹åŠ¨æ—¢ä¸å½±å“ç°æœ‰åŠŸèƒ½ï¼Œåˆæå‡äº†ä»£ç çš„å¯ç»´æŠ¤æ€§ã€‚

---

### QuantizationMoE-remove-unused-ep-logic-from-moe-marlin-31571
**SHA**: `2f4bdee` | ğŸ”— [æŸ¥çœ‹æäº¤](https://github.com/vllm-project/vllm/commit/2f4bdee61ee0dd9358efaba720b7acc53b2ece00)

**ğŸ¯ å˜æ›´ç±»å‹**ï¼šé‡æ„ / ä»£ç æ¸…ç†  
**âš¡ é‡è¦ç¨‹åº¦**ï¼šğŸŸ¡ ä¸­  
**ğŸ“‹ å˜æ›´æ‘˜è¦**ï¼šæœ¬æ¬¡æäº¤åˆ é™¤äº† MoEâ€¯Marlin å®ç°ä¸­æœªä½¿ç”¨çš„ *expertâ€‘parallelism*ï¼ˆ`is_ep`ï¼‰ç›¸å…³é€»è¾‘ã€‚åŒ…æ‹¬å®å®šä¹‰ã€æ ¸å‡½æ•°å‚æ•°ã€å†…éƒ¨åˆ†æ”¯ä»¥åŠ Python/C++ æ¥å£çš„ `is_ep` å‚æ•°å…¨éƒ¨å»é™¤ï¼Œä½¿ä»£ç è·¯å¾„æ›´ç®€æ´ã€ç¼–è¯‘ä½“ç§¯ç•¥æœ‰ä¸‹é™ã€‚  
**ğŸ¯ å½±å“èŒƒå›´**  
- **csrc/moe/marlin_moe_wna16**ï¼š`kernel.h`ã€`marlin_template.h`ã€`ops.cu` ä¸­çš„å‡½æ•°åŸå‹å’Œå®ç°ã€‚  
- **csrc/moe/torch_bindings.cpp**ã€**vllm/_custom_ops.py**ã€**vllm/model_executor/layers/fused_moe/fused_marlin_moe.py**ï¼šå¯¹å¤–æ¥å£ç­¾ååŒæ­¥å»æ‰ `is_ep`ã€‚  
- ä¾èµ–è¯¥æ¥å£çš„ä¸Šå±‚æ¨¡å‹ä»£ç ï¼ˆå¦‚ `fused_marlin_moe.py`ï¼‰å·²ç›¸åº”åˆ å‡å‚æ•°ã€‚  

**ğŸ’¡ å…³æ³¨å»ºè®®**  
1. **å…¼å®¹æ€§æ£€æŸ¥**ï¼šç¡®è®¤é¡¹ç›®ä¸­æ²¡æœ‰å…¶ä»–åœ°æ–¹ä»ä»¥å…³é”®å­—å‚æ•° `is_ep=` è°ƒç”¨ `moe_wna16_marlin_gemm`ï¼Œé¿å…è¿è¡Œæ—¶ `TypeError`ã€‚  
2. **å•å…ƒ/é›†æˆæµ‹è¯•**ï¼šé‡ç‚¹è·‘å« MoEâ€¯Marlin çš„æ¨ç†è·¯å¾„ï¼ˆe.g., `vllm`â€¯çš„ `fused_moe`ï¼‰ï¼ŒéªŒè¯è¾“å‡ºæ•°å€¼æœªå—é€»è¾‘åˆ é™¤å½±å“ï¼ˆåŸæœ¬ `is_ep` ä¸º `False` æ—¶ä¸åšä»»ä½•åˆ†æ”¯ï¼‰ã€‚  
3. **æ–‡æ¡£åŒæ­¥**ï¼šæ›´æ–° README / API æ–‡æ¡£ï¼Œå»é™¤ `is_ep` å‚æ•°è¯´æ˜ï¼Œé˜²æ­¢ç”¨æˆ·è¯¯ä»¥ä¸ºä»æ”¯æŒä¸“å®¶å¹¶è¡Œã€‚  
4. **æ€§èƒ½å›å½’**ï¼šè™½ç„¶åˆ é™¤çš„åˆ†æ”¯æœ¬å°±æœªè¢«è§¦å‘ï¼Œä»å»ºè®®åœ¨å…¸å‹ workload ä¸­å¯¹æ¯”å‰åååé‡ï¼Œä»¥ç¡®ä¿ç¼–è¯‘å™¨æœªå› å‚æ•°é¡ºåºå˜åŒ–äº§ç”Ÿæ„å¤–å›é€€ã€‚  

æ€»ä½“è€Œè¨€ï¼Œæ­¤æ¬¡ä¿®æ”¹æå‡äº†ä»£ç å¯ç»´æŠ¤æ€§ï¼Œé£é™©ä¸»è¦åœ¨å¤–éƒ¨è°ƒç”¨ç­¾åçš„å…¼å®¹æ€§ï¼Œç¡®è®¤ä¸Šè¿°å‡ ç‚¹åå³å¯å®‰å…¨åˆå¹¶ã€‚

---

#### ğŸŸ¢ ä½é‡è¦åº¦å˜æ›´ (21)

### ROCmAITER-fix-wrong-argument-passed-to-AITER-`flash_attn_varlen_func`-...
**SHA**: `41cfa50` | ğŸ”— [æŸ¥çœ‹æäº¤](https://github.com/vllm-project/vllm/commit/41cfa50632c26c6064cabbbc43c9fc29c7792a2d)

**ğŸ¯ å˜æ›´ç±»å‹**ï¼šå…¶ä»–  
**âš¡ é‡è¦ç¨‹åº¦**ï¼šğŸŸ¢ä½  
**ğŸ“‹ æ‘˜è¦**ï¼šåœ¨ ROCm ä¸ AITER çš„ MLA å®ç°ä¸­ï¼Œå°†è°ƒç”¨ `flash_attn_varlen_func` æ—¶çš„å‚æ•°åä» `return_softmax_lse` ä¿®æ­£ä¸ºæ­£ç¡®çš„ `return_lse`ï¼Œé¿å…å‚æ•°é”™è¯¯å¯¼è‡´çš„è¿è¡Œæ—¶å¼‚å¸¸ã€‚

---

### BugfixMTP-Fix-GLM4-MoE-fp8-loading-with-MTP-on-31757
**SHA**: `d111bc5` | ğŸ”— [æŸ¥çœ‹æäº¤](https://github.com/vllm-project/vllm/commit/d111bc53ad2fbb5f28671019d21f5f753436e46d)

**ğŸ¯ å˜æ›´ç±»å‹**ï¼šä»£ç é‡æ„  
**âš¡ é‡è¦ç¨‹åº¦**ï¼šğŸŸ¢ä½  
**ğŸ“‹ æ‘˜è¦**ï¼šå°† GLM4 MoE fp8 åœ¨ MTP æ¨¡å¼ä¸‹çš„ `inputs_embeds` èµ‹å€¼æ”¹ä¸º `torch.where`ï¼Œé˜²æ­¢åŸåœ°ä¿®æ”¹å¯¼è‡´é”™è¯¯ï¼›åœ¨æƒé‡åŠ è½½æ—¶è·³è¿‡ä¸å­˜åœ¨çš„ `.weight_scale` å¼ é‡ï¼Œé¿å… `KeyError`ã€‚

---

### Model-Cleanup:-Remove-redundant-manual-definition-of-`make_empty_intermedia...
**SHA**: `1f33e38` | ğŸ”— [æŸ¥çœ‹æäº¤](https://github.com/vllm-project/vllm/commit/1f33e38e81a1b29bb4261a5e4e1fa430198b251a)

**ğŸ¯ å˜æ›´ç±»å‹**ï¼šä»£ç é‡æ„  
**âš¡ é‡è¦ç¨‹åº¦**ï¼šğŸŸ¢ä½  
**ğŸ“‹ æ‘˜è¦**ï¼šåœ¨ `glm4_moe.py` ä¸­åˆ é™¤äº†å†—ä½™çš„ `make_empty_intermediate_tensors` æ‰‹åŠ¨å®ç°ï¼Œæ”¹ä¸ºä½¿ç”¨åŸºç±»é»˜è®¤å®ç°ï¼Œä»£ç æ›´ç®€æ´ã€‚

---

### XPUfallback-to-TRITON_ATTN-on-xpu-when-use-float32-dtype-31762
**SHA**: `59fe6f2` | ğŸ”— [æŸ¥çœ‹æäº¤](https://github.com/vllm-project/vllm/commit/59fe6f298e16ee8d2f54e2567b76516807a4733b)

**ğŸ¯ å˜æ›´ç±»å‹**ï¼šä»£ç é‡æ„  
**âš¡ é‡è¦ç¨‹åº¦**ï¼šğŸŸ¢ä½  
**ğŸ“‹ æ‘˜è¦**ï¼šåœ¨ XPU å¹³å°çš„æ³¨æ„åŠ›åç«¯é€‰æ‹©ä¸­ï¼Œæ–°å¢å¯¹ `torch.float32` ç±»å‹çš„æ£€æµ‹ï¼Œè‹¥åŸæœ¬é€‰ç”¨ Flash Attentionï¼Œåˆ™å›é€€åˆ° Triton Attention å¹¶è®°å½•è­¦å‘Šã€‚

---

### BugfixKernel-fix-bias-adding-in-triton-kernel-implemented-fused-moe-31676
**SHA**: `0dd5dee` | ğŸ”— [æŸ¥çœ‹æäº¤](https://github.com/vllm-project/vllm/commit/0dd5dee9b9bc88453f5f3eacfde751e6b9ba4871)

**ğŸ¯ å˜æ›´ç±»å‹**ï¼šä»£ç é‡æ„  
**âš¡ é‡è¦ç¨‹åº¦**ï¼šğŸŸ¢ä½  
**ğŸ“‹ æ‘˜è¦**ï¼šåœ¨ `fused_moe_kernel` ä¸­å°† bias ä¸è·¯ç”±æƒé‡çš„è®¡ç®—é¡ºåºç§»åŠ¨åˆ° dequantization ä¹‹åï¼Œé¿å…åœ¨é‡åŒ–é˜¶æ®µé”™è¯¯åŠ å…¥ biasï¼Œä¿®å¤äº† triton kernel çš„ bias æ·»åŠ é€»è¾‘ã€‚

---

### Bugfix-Fix-race-condition-in-async-scheduling-for-vlm-model-31841
**SHA**: `efeaac9` | ğŸ”— [æŸ¥çœ‹æäº¤](https://github.com/vllm-project/vllm/commit/efeaac92f22f8a0a26c6bb9b9182f316210bb19c)

**ğŸ¯ å˜æ›´ç±»å‹**ï¼šä»£ç é‡æ„  
**âš¡ é‡è¦ç¨‹åº¦**ï¼šğŸŸ¢ä½  
**ğŸ“‹ æ‘˜è¦**ï¼šåœ¨å¤šæ¨¡æ€æ¨¡å‹çš„ `GpuModelRunner` ä¸­ä¸º `is_mm_embed` æ·»åŠ åŒç¼“å†²å¹¶åˆ‡æ¢ç´¢å¼•ï¼Œä»¥é¿å…å‰ä¸€æ¬¡å¼‚æ­¥æ‹·è´ä»åœ¨è¯»å–æ—¶äº§ç”Ÿçš„ç«äº‰æ¡ä»¶ã€‚ä»£ç ç›¸åº”è°ƒæ•´äº†ç¼“å†²åˆ›å»ºã€è¯»å–å’Œæ‹·è´é€»è¾‘ã€‚

---

### Attention3/n-Remove-usage-of-deprecated-`seq_lens_cpu`-and-`num_computed_...
**SHA**: `c7a79d4` | ğŸ”— [æŸ¥çœ‹æäº¤](https://github.com/vllm-project/vllm/commit/c7a79d41a03f925942e8fb8bc589df4f39bcb950)

**ğŸ¯ å˜æ›´ç±»å‹**ï¼šä»£ç é‡æ„  
**âš¡ é‡è¦ç¨‹åº¦**ï¼šğŸŸ¢ä½  
**ğŸ“‹ æ‘˜è¦**ï¼šåˆ é™¤å¯¹å·²å¼ƒç”¨çš„ `seq_lens_cpu`ã€`num_computed_tokens_cpu` å±æ€§çš„ç›´æ¥è®¿é—®ï¼Œæ”¹ä¸ºä½¿ç”¨ `common_attn_metadata.seq_lens.cpu()` ç­‰æ–°æ¥å£ï¼Œç¡®ä¿å…¼å®¹æ€§å¹¶æ¸…ç†æ—§å®ç°ã€‚

---

### ROCmAITER-bugfix-accuracy-regression-in-ROCM_AITER_TRITON_MLA-backend-3...
**SHA**: `6409004` | ğŸ”— [æŸ¥çœ‹æäº¤](https://github.com/vllm-project/vllm/commit/6409004b2656baa147a3ecc6577e5b24fc225541)

**ğŸ¯ å˜æ›´ç±»å‹**ï¼šä»£ç é‡æ„  
**âš¡ é‡è¦ç¨‹åº¦**ï¼šğŸŸ¢ ä½  
**ğŸ“‹ æ‘˜è¦**ï¼šå°† AiterTritonMLABackend åŸºç±»æ”¹ä¸º AiterMLABackendï¼Œå»é™¤å·²åºŸå¼ƒçš„ builderï¼Œä¿®å¤ ROCM_AITER_TRITON_MLA åç«¯çš„å‡†ç¡®æ€§å›é€€é—®é¢˜ã€‚

---

### Change-warning-in-get_current_vllm_config-to-report-caller's-line-number-31...
**SHA**: `f09c5fe` | ğŸ”— [æŸ¥çœ‹æäº¤](https://github.com/vllm-project/vllm/commit/f09c5feb7c66340e35c06aba37478cce74c20c10)

**ğŸ¯ å˜æ›´ç±»å‹**ï¼šå…¶ä»–  
**âš¡ é‡è¦ç¨‹åº¦**ï¼šğŸŸ¢ä½  
**ğŸ“‹ æ‘˜è¦**ï¼šåœ¨ `get_current_vllm_config` ä¸­å°†æ—¥å¿—è­¦å‘Šæ”¹ä¸º `logger.warning(..., stacklevel=2)`ï¼Œä½¿è­¦å‘Šæ˜¾ç¤ºè°ƒç”¨æ–¹çš„è¡Œå·ï¼Œä¾¿äºå®šä½é—®é¢˜ã€‚

---

### Doc-Update-release-docs-31799
**SHA**: `1b8af95` | ğŸ”— [æŸ¥çœ‹æäº¤](https://github.com/vllm-project/vllm/commit/1b8af957f62b96173eb9f57c6609f489cb99fda6)

**ğŸ¯ å˜æ›´ç±»å‹**ï¼šæ–‡æ¡£æ›´æ–°  
**âš¡ é‡è¦ç¨‹åº¦**ï¼šğŸŸ¢ä½  
**ğŸ“‹ æ‘˜è¦**ï¼šæ›´æ–°äº† `RELEASE.md`ï¼Œå®Œå–„äº†å‘å¸ƒè¯´æ˜çš„é“¾æ¥ã€å‘å¸ƒèŠ‚å¥ä¸ç‰ˆæœ¬å·è§„åˆ™æè¿°ï¼Œä¼˜åŒ–äº†åˆ†æ”¯ä¸ cherryâ€‘pick æµç¨‹çš„è¡¨è¿°ï¼Œä½¿æ–‡æ¡£æ›´æ¸…æ™°ã€æ˜“äºé˜…è¯»ã€‚

---

### Model-Enable-LoRA-support-for-PaliGemma-31656
**SHA**: `a051525` | ğŸ”— [æŸ¥çœ‹æäº¤](https://github.com/vllm-project/vllm/commit/a051525e071c2387641b17b95533fb51ed9363e1)

**ğŸ¯ å˜æ›´ç±»å‹**ï¼šä»£ç é‡æ„  
**âš¡ é‡è¦ç¨‹åº¦**ï¼šğŸŸ¢ ä½  
**ğŸ“‹ æ‘˜è¦**ï¼šä¸º PaliGemma æ¨¡å‹æ–°å¢ LoRA æ”¯æŒï¼Œå®ç° `SupportsLoRA` æ¥å£å¹¶æä¾›å¤šæ¨¡æ€æ˜ å°„ã€token è®¡æ•°ç­‰æ–¹æ³•ï¼›åŒæ—¶åœ¨æ–‡æ¡£è¡¨æ ¼ä¸­æ ‡è®° PaliGemma å·²æ”¯æŒ LoRAã€‚

---

### 1/2lmcache-connector-clean-up-lmcache-multi-process-adapter-31838
**SHA**: `5b833be` | ğŸ”— [æŸ¥çœ‹æäº¤](https://github.com/vllm-project/vllm/commit/5b833be49e02fec2542396a01c9575dfe6e1def2)

**ğŸ¯ å˜æ›´ç±»å‹**ï¼šä»£ç é‡æ„  
**âš¡ é‡è¦ç¨‹åº¦**ï¼šğŸŸ¢ä½  
**ğŸ“‹ æ‘˜è¦**ï¼šä¸º LMCache å¤šè¿›ç¨‹é€‚é…å™¨æ·»åŠ åºŸå¼ƒè­¦å‘Šã€æ–¹æ³•é‡å‘½åï¼ˆ`_cleanup_lookup_result`â†’`cleanup_lookup_result`ï¼‰ï¼Œå¹¶æ”¹ä¸ºå¯é€‰å¯¼å…¥æ–° `lmcache.integration` åŒ…ï¼Œæ›´æ–°ç›¸åº”è°ƒç”¨ï¼Œé˜²æ­¢å†…å­˜æ³„æ¼ã€‚

---

### ROCmCI-Fix-plugin-tests-2-GPUs-failures-on-ROCm-and-removing-`VLLM_FLOA...
**SHA**: `364a8bc` | ğŸ”— [æŸ¥çœ‹æäº¤](https://github.com/vllm-project/vllm/commit/364a8bc6dc7d8fc344f07f01adc6a2336887e9bd)

**ğŸ¯ å˜æ›´ç±»å‹**ï¼šé…ç½®è°ƒæ•´  
**âš¡ é‡è¦ç¨‹åº¦**ï¼šğŸŸ¢ä½  
**ğŸ“‹ æ‘˜è¦**ï¼šåœ¨ ROCm CI æµç¨‹ä¸­ç§»é™¤ `VLLM_FLOAT32_MATMUL_PRECISION=tf32` ç¯å¢ƒå˜é‡ï¼Œä»¥ä¿®å¤æ’ä»¶æµ‹è¯•åœ¨ 2 GPU ç¯å¢ƒä¸‹çš„å¤±è´¥ï¼›åŒæ—¶åœ¨ `requirements/rocm-test.txt` ä¸­æ–°å¢ `albumentations` ä¾èµ–ç”¨äºæ’ä»¶æµ‹è¯•ã€‚

---

### CI-Add-warmup-run-in-test_fusion_attn-31183
**SHA**: `9a1d20a` | ğŸ”— [æŸ¥çœ‹æäº¤](https://github.com/vllm-project/vllm/commit/9a1d20a89c3b1f2c2687dee585b22c93f05b2310)

**ğŸ¯ å˜æ›´ç±»å‹**ï¼šæµ‹è¯•ä¿®æ”¹  
**âš¡ é‡è¦ç¨‹åº¦**ï¼šğŸŸ¢ä½  
**ğŸ“‹ æ‘˜è¦**ï¼šåœ¨ `test_fusion_attn.py` ä¸­åŠ å…¥ warmâ€‘up è¿è¡Œå¹¶ç¦ç”¨ç¼–è¯‘ç¼“å­˜ï¼Œä»¥ç¡®ä¿èåˆæ³¨æ„åŠ›çš„é‡åŒ–å°ºåº¦åœ¨é¦–æ¬¡å‰å‘åæ­£ç¡®åŠ è½½ï¼Œä¿®æ­£äº†ç›¸å…³æ–­è¨€å’Œè°ƒç”¨æ–¹å¼ã€‚

---

### Bugfix-Handle-mistral-tokenizer-in-get_hf_processor-31817
**SHA**: `309a8f6` | ğŸ”— [æŸ¥çœ‹æäº¤](https://github.com/vllm-project/vllm/commit/309a8f66ee0daec7dbee5030dac1bcfcfad7b3ec)

**ğŸ¯ å˜æ›´ç±»å‹**ï¼šå…¶ä»–  
**âš¡ é‡è¦ç¨‹åº¦**ï¼šğŸŸ¢ä½  
**ğŸ“‹ æ‘˜è¦**ï¼šåœ¨ `get_hf_processor` ä¸­åŠ å…¥å¯¹ `MistralTokenizer` çš„æ£€æµ‹ï¼Œè‹¥ä½¿ç”¨è¯¥ tokenizer åˆ™æ”¹ä¸ºå…¶å†…éƒ¨çš„ `transformers_tokenizer` ä¼ é€’ç»™å¤„ç†å™¨ï¼Œä¿®å¤å…¼å®¹æ€§é—®é¢˜ã€‚

---

### ROCmCI-Pinning-timm-lib-version-to-fix-ImportError-in-Multi-Modal-Tests-...
**SHA**: `e5d427e` | ğŸ”— [æŸ¥çœ‹æäº¤](https://github.com/vllm-project/vllm/commit/e5d427e93af5861e22c2b7b3ce88af0028fc41e3)

**ğŸ¯ å˜æ›´ç±»å‹**ï¼šé…ç½®è°ƒæ•´  
**âš¡ é‡è¦ç¨‹åº¦**ï¼šğŸŸ¢ ä½  
**ğŸ“‹ æ‘˜è¦**ï¼šåœ¨ `requirements/rocm-test.txt` ä¸­æ–°å¢ `timm==1.0.17` ç‰ˆæœ¬é”å®šï¼Œç”¨äºä¿®å¤ ROCm ç¯å¢ƒä¸‹å¤šæ¨¡æ€æ¨¡å‹æµ‹è¯•çš„ ImportErrorã€‚

---

### ROCmCI-Fix-ModernBERT-token-classification-test-numerical-accuracy-on-ROC...
**SHA**: `2a42ae7` | ğŸ”— [æŸ¥çœ‹æäº¤](https://github.com/vllm-project/vllm/commit/2a42ae790d3f42a381b782a504947255aa0db090)

**ğŸ¯ å˜æ›´ç±»å‹**ï¼šé…ç½®è°ƒæ•´  
**âš¡ é‡è¦ç¨‹åº¦**ï¼šğŸŸ¢ä½  
**ğŸ“‹ æ‘˜è¦**ï¼šæ–°å¢ `tests/models/language/pooling/conftest.py`ï¼Œåœ¨ ROCm ç¯å¢ƒä¸‹ç¦ç”¨ Flash/Memoryâ€‘Efficient SDPï¼Œå¼€å¯ Math SDP å¹¶æå‡çŸ©é˜µä¹˜ç²¾åº¦ï¼Œä»¥è§£å†³ HuggingFace Transformers åœ¨ ROCm ä¸Šçš„æ•°å€¼å‡†ç¡®æ€§é—®é¢˜ã€‚

---

### Report-error-log-after-vllm-bench-serve-31808
**SHA**: `dba9537` | ğŸ”— [æŸ¥çœ‹æäº¤](https://github.com/vllm-project/vllm/commit/dba95378a66884c889b5dc9428ea68285a908658)

**ğŸ¯ å˜æ›´ç±»å‹**ï¼šå…¶ä»–  
**âš¡ é‡è¦ç¨‹åº¦**ï¼šğŸŸ¢ä½  
**ğŸ“‹ æ‘˜è¦**ï¼šåœ¨ `vllm/benchmarks/serve.py` ä¸­æ–°å¢å¯¹å¤±è´¥è¯·æ±‚çš„æ—¥å¿—æ‰“å°ï¼Œæ£€æµ‹åˆ°å¤±è´¥æ—¶è¾“å‡ºå‰â€¯10 æ¡é”™è¯¯ä¿¡æ¯ï¼Œå¸®åŠ©åŸºå‡†æµ‹è¯•æ—¶å¿«é€Ÿå®šä½é—®é¢˜ã€‚

---

### make-500:-InternalServerError-more-informative-20610
**SHA**: `142c4d1` | ğŸ”— [æŸ¥çœ‹æäº¤](https://github.com/vllm-project/vllm/commit/142c4d173896b02e6b73e2dd05493c1f180c5977)

**ğŸ¯ å˜æ›´ç±»å‹**ï¼šä»£ç é‡æ„  
**âš¡ é‡è¦ç¨‹åº¦**ï¼šğŸŸ¢ä½  
**ğŸ“‹ æ‘˜è¦**ï¼šåœ¨ `async_llm.py` ä¸­æ•è·å¼‚å¸¸åï¼Œæ—¥å¿—è¾“å‡ºæ”¹ä¸ºåŒ…å«å¼‚å¸¸ç±»åå’Œä¿¡æ¯ï¼Œé¿å…å†æ¬¡æŠ›å‡ºæ—¶ä¿¡æ¯ç¼ºå¤±ï¼Œå¹¶åœ¨å¼‚å¸¸æ‰“å°å¤±è´¥æ—¶æä¾›å¤‡é€‰è¯´æ˜ã€‚

---

### PERF-Speed-up-of-GDN-attention-decode-part-Qwen3-Next-31722
**SHA**: `22dffca` | ğŸ”— [æŸ¥çœ‹æäº¤](https://github.com/vllm-project/vllm/commit/22dffca9822987f0e912bfd9635e94bbdd05def3)

**ğŸ¯ å˜æ›´ç±»å‹**ï¼šä»£ç é‡æ„  
**âš¡ é‡è¦ç¨‹åº¦**ï¼šğŸŸ¢ ä½  
**ğŸ“‹ æ‘˜è¦**ï¼šå°† `fused_recurrent_gated_delta_rule_fwd` ä¸­ BV çš„å—å¤§å°ä¸Šé™ä» 8 æå‡è‡³ 32ï¼Œä»¥æå‡ Qwen3â€‘Next GDN æ³¨æ„åŠ›è§£ç é˜¶æ®µçš„è¿è¡Œé€Ÿåº¦ã€‚

---

### NemotronH-Use-ReplicatedLinear-for-fc1_latent_proj-31807
**SHA**: `28c9477` | ğŸ”— [æŸ¥çœ‹æäº¤](https://github.com/vllm-project/vllm/commit/28c94770adfcb9cfbc78a3221f915bfc830c6582)

**ğŸ¯ å˜æ›´ç±»å‹**ï¼šä»£ç é‡æ„  
**âš¡ é‡è¦ç¨‹åº¦**ï¼šğŸŸ¢ä½  
**ğŸ“‹ æ‘˜è¦**ï¼šåœ¨ `NemotronH` æ¨¡å‹ä¸­ï¼Œå°† `fc1_latent_proj` ä» `ColumnParallelLinear` æ›¿æ¢ä¸º `ReplicatedLinear`ï¼Œå¹¶å»é™¤ `gather_output=True` å‚æ•°ï¼Œä»¥ç®€åŒ–å®ç°å¹¶å¯èƒ½æå‡æ€§èƒ½ã€‚

---

