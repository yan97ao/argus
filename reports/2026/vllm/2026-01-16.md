# æ¯æ—¥æ›´æ–°æŠ¥å‘Šï¼ˆ2026-01-16ï¼‰

## vllm-project/vllm

| æäº¤æ—¶é—´ | ä½œè€… | æäº¤ä¿¡æ¯ |
|----------|------|----------|
| 2026-01-16 22:11:01 | Ilya Markov | [EPLB][BugFix]Possible deadlock fix (#32418) |
| 2026-01-16 16:22:53 | rasmith | [CI][AMD] Skip test_permute_cols since the kernel is not used and not built for ROCm (#32444) |
| 2026-01-16 16:22:45 | Cyrus Leung | [Chore] Replace swish with silu (#32459) |
| 2026-01-16 16:17:44 | Micah Williamson | [ROCm][CI] Skip Qwen3-30B-A3B-MXFP4A16 Eval Test On Non-CUDA Platforms (#32460) |
| 2026-01-16 15:31:10 | Rabi Mishra | fix(rocm): Enable non-gated MoE (is_act_and_mul=False) support on ROCm (#32244) |
| 2026-01-16 15:13:58 | Hongxin Xu | [Bugfix] Refactor to support DP parallel in R3 (#32306) |
| 2026-01-16 14:23:22 | Lucas Wilkinson | [CI] Breakup h200 tests (#30499) |
| 2026-01-16 14:17:04 | wang.yuqi | [Frontend][1/n] Make pooling entrypoints request schema consensus \| CompletionRequest  (#32395) |
| 2026-01-16 13:17:12 | XiongfeiWei | [Bug] Add TPU backend option (#32438) |
| 2026-01-16 12:23:54 | cjackal | [bugfix] Fix online serving crash when text type response_format is received (#26822) |
| 2026-01-16 11:21:55 | Kebe | [Bugfix] [DeepSeek-V3.2] fix sparse_attn_indexer padding (#32175) |
| 2026-01-16 11:04:16 | ltd0924 | [Model] Add Step3vl 10b (#32329) |
| 2026-01-16 08:55:57 | Micah Williamson | [ROCm][CI] Enable AITER Unified Attention On ROCm For gpt-oss Test (#32431) |
| 2026-01-16 08:52:49 | Matthew Bonanni | [CI] Fix LM Eval Large Models (H100) (#32423) |
| 2026-01-16 08:45:44 | Michael Goin | Add thread_n=64 support to Marlin MoE (#32360) |
| 2026-01-16 08:15:05 | TomerBN-Nvidia | [Feat] Support non-gated MoE with Marlin, NVFP4 CUTLASS, FP8, INT8, compressed-tensors (#32257) |
| 2026-01-16 06:59:38 | Wentao Ye | [Refactor] Remove unused file (#32422) |
| 2026-01-16 04:53:40 | Yongye Zhu | [MoE Refactor][17/N] Apply Refactor to Bf16 (#31827) |
| 2026-01-16 04:13:08 | Aleksandr Malyshev | [ROCM] DSfp4 mla projection gemms weight dynamic quantization (#32238) |
| 2026-01-16 04:01:41 | Richard Zou | [BugFix] Python file source reading can fail on UnicodeDecodeError (#32416) |
| 2026-01-16 02:56:18 | TJian | [ROCm] [CI] [Release] Rocm wheel pipeline with sccache (#32264) |
| 2026-01-16 02:55:11 | Michael Goin | [UX] Use kv_offloading_backend=native by default (#32421) |
| 2026-01-16 02:19:12 | Lucas Wilkinson | [BugFix] Fix `assert x_s.shape[-1] == x_q.shape[-1] // group_shape[1]` in Blackwell Quantized MoE Test (#32362) |
| 2026-01-16 01:18:24 | Matthias Gehre | [Attention][AMD] Make flash-attn optional (#30361) |
| 2026-01-16 01:07:08 | smit kadvani | fixing podman build issue (#32131) |
| 2026-01-16 01:06:23 | Wentao Ye | [Feature] Support async scheduling + PP (#32359) |
| 2026-01-16 00:59:23 | Woosuk Kwon | [Model Runner V2] Support FlashInfer backend & Fix CUDA Graph bug [1/2] (#32348) |
| 2026-01-16 00:35:47 | Pleaplusone | [ROCm][Bugfix] Disable hip sampler to fix deepseek's accuracy issue on ROCm (#32413) |

### ğŸ“Š ç»Ÿè®¡æ‘˜è¦
> æœ¬æ—¥å…± 28 ä¸ªæäº¤ | ğŸ”´é«˜ 2 | ğŸŸ¡ä¸­ 12 | ğŸŸ¢ä½ 14
## ğŸ“‹ ç›®å½•

- [vllm-project/vllm](#vllm-project-vllm)
  - [ğŸ“Š ç»Ÿè®¡æ‘˜è¦](#-ç»Ÿè®¡æ‘˜è¦)
  - [ğŸ”´ é«˜é‡è¦åº¦å˜æ›´ (2)](#-ğŸ”´-é«˜é‡è¦åº¦å˜æ›´-2)
    - [[Frontend][1/n] Make pooling entrypoints request schema c...](#4ae77df)
    - [[ROCm] [CI] [Release] Rocm wheel pipeline with sccache (#...](#41c544f)
  - [ğŸŸ¡ ä¸­é‡è¦åº¦å˜æ›´ (12)](#-ğŸŸ¡-ä¸­é‡è¦åº¦å˜æ›´-12)
    - [[Chore] Replace swish with silu (#32459)](#180e981)
    - [fix(rocm): Enable non-gated MoE (is_act_and_mul=False) su...](#b66b0d6)
    - [[Bugfix] Refactor to support DP parallel in R3 (#32306)](#03da3b5)
    - [[CI] Breakup h200 tests (#30499)](#14ce524)
    - [[bugfix] Fix online serving crash when text type response...](#35bf5d0)
    - [[Model] Add Step3vl 10b (#32329)](#7095025)
    - [Add thread_n=64 support to Marlin MoE (#32360)](#83239ff)
    - [[Feat] Support non-gated MoE with Marlin, NVFP4 CUTLASS, ...](#c277fbd)
    - [[MoE Refactor][17/N] Apply Refactor to Bf16 (#31827)](#31c2925)
    - [[ROCM] DSfp4 mla projection gemms weight dynamic quantiza...](#8c11001)
    - [[UX] Use kv_offloading_backend=native by default (#32421)](#1be5a73)
    - [[Feature] Support async scheduling + PP (#32359)](#b34474b)
  - [ğŸŸ¢ ä½é‡è¦åº¦å˜æ›´ (14)](#-ğŸŸ¢-ä½é‡è¦åº¦å˜æ›´-14)
    - [[EPLB][BugFix]Possible deadlock fix (#32418)](#c9a5330)
    - [[CI][AMD] Skip test_permute_cols since the kernel is not ...](#6ca4f40)
    - [[ROCm][CI] Skip Qwen3-30B-A3B-MXFP4A16 Eval Test On Non-C...](#b84c426)
    - [[Bug] Add TPU backend option (#32438)](#73f635a)
    - [[Bugfix] [DeepSeek-V3.2] fix sparse_attn_indexer padding ...](#5de6dd0)
    - [[ROCm][CI] Enable AITER Unified Attention On ROCm For gpt...](#46f8a98)
    - [[CI] Fix LM Eval Large Models (H100) (#32423)](#bcf2333)
    - [[Refactor] Remove unused file (#32422)](#aca5c51)
    - [[BugFix] Python file source reading can fail on UnicodeDe...](#bd292be)
    - [[BugFix] Fix `assert x_s.shape[-1] == x_q.shape[-1] // gr...](#c36ba69)
    - [[Attention][AMD] Make flash-attn optional (#30361)](#0474133)
    - [fixing podman build issue (#32131)](#74e4bb1)
    - [[Model Runner V2] Support FlashInfer backend & Fix CUDA G...](#6218034)
    - [[ROCm][Bugfix] Disable hip sampler to fix deepseek's accu...](#77c16df)
#### ğŸ”´ é«˜é‡è¦åº¦å˜æ›´ (2)

### [Frontend][1/n] Make pooling entrypoints request schema consensus | CompletionRequest  (#32395)
**SHA**: `4ae77df` | ğŸ”— [æŸ¥çœ‹æäº¤](https://github.com/vllm-project/vllm/commit/4ae77dfd42041dc2defe21f6ccf76aecb4478812)

**ğŸ¯ å˜æ›´ç±»å‹**ï¼šåŠŸèƒ½å¢å¼º / é‡æ„ / æ¶æ„å˜æ›´  
**âš¡ é‡è¦ç¨‹åº¦**ï¼šğŸ”´é«˜  
**ğŸ“‹ å˜æ›´æ‘˜è¦**ï¼š  
1. å¯¹â€¯vLLMâ€¯çš„ *pooling*ï¼ˆåˆ†ç±»ã€åµŒå…¥ã€ç‰¹å¾æŠ½å–ã€è¯„åˆ†ï¼‰å…¥å£ç‚¹è¿›è¡Œç»Ÿä¸€åŒ–æ”¹é€ ï¼ŒæŠ½å–å‡ºå…¬å…±è¯·æ±‚æ¨¡å‹ `PoolingBasicRequestMixin`â€¯å’Œ `CompletionRequestMixin`ï¼Œå¹¶è¿ç§»åŸå…ˆæ•£è½åœ¨ `score_utils`ã€`score/`ã€`classify/`ã€`embed/`ã€`pooling/` ä¸­çš„é‡å¤å®ç°ã€‚  
2. åœ¨ `vllm/entrypoints/openai/api_server.py` ä¸­ç§»é™¤åŸå§‹çš„ poolingã€embeddingã€classificationã€scoreâ€‘service åˆå§‹åŒ–ä»£ç ï¼Œæ”¹ä¸ºåœ¨ `vllm/entrypoints/pooling/__init__.py` çš„ `init_pooling_state` ä¸­ç»Ÿä¸€åˆ›å»ºå¹¶æŒ‚è½½åˆ° `state`ã€‚  
3. æ›´æ–°æ–‡æ¡£ã€ç¤ºä¾‹ä»£ç ä»¥åŠå¤§é‡æµ‹è¯•ç”¨ä¾‹ï¼Œä½¿å…¶ä½¿ç”¨æ–°çš„è¯·æ±‚/å“åº” schemaï¼ˆç»Ÿä¸€çš„ `model`, `input`, `truncate_prompt_tokens`, `add_special_tokens` ç­‰å­—æ®µï¼‰ï¼Œå¹¶åŠ å…¥å¯¹ tokenâ€‘idsã€ç©ºè¾“å…¥ã€æ‰¹é‡è¯·æ±‚ç­‰åœºæ™¯çš„è¦†ç›–ã€‚  
4. è°ƒæ•´äº†å¤šæ¨¡æ€ score utils çš„ import è·¯å¾„ï¼Œä½¿å…¶å½’å±äº `vllm.entrypoints.pooling.score.utils`ï¼Œå¹¶åŒæ­¥ä¿®æ”¹æ‰€æœ‰å¼•ç”¨ã€‚  

---

### ğŸ” æŠ€æœ¯æ´å¯Ÿ

| ç»´åº¦ | å½±å“æè¿° |
|------|----------|
| **æ¶æ„å½±å“** | - å¼•å…¥ **`vllm.entrypoints.pooling.base`** åŒ…ï¼Œç»Ÿä¸€ `PoolingBasicRequestMixin`ã€`CompletionRequestMixin`ï¼Œå®ç° **è¯·æ±‚æ¨¡å‹å¤ç”¨**ï¼Œé™ä½ä»£ç é‡å¤åº¦ã€‚<br>- `init_pooling_state` å°† **æ‰€æœ‰ pooling ç›¸å…³æœåŠ¡çš„åˆ›å»ºé€»è¾‘é›†ä¸­**ï¼Œä¾¿äºåç»­æ’ä»¶åŒ–ã€è·¨ä»»åŠ¡çš„ç»Ÿä¸€æ²»ç†ã€‚<br>- `api_server` ä¸­åŸæ¥çš„æ˜¾å¼å®ä¾‹åŒ–è¢«åˆ é™¤ï¼Œé¿å…äº†åœ¨ `init_app_state` ä¸­å‡ºç°å¤§é‡æ¡ä»¶åˆ†æ”¯ï¼Œæå‡å¯ç»´æŠ¤æ€§ã€‚ |
| **æ€§èƒ½å½±å“** | - è¿ç§»ä¸º mixin å¹¶æœªæ”¹å˜è¿è¡Œæ—¶è·¯å¾„ï¼Œé™¤å»å°‘é‡ import é‡å®šä½å¤–ï¼Œ**è¯·æ±‚å¤„ç†ã€æ¨¡å‹æ¨ç†ã€token åŒ–ç­‰æ ¸å¿ƒæµç¨‹ä¿æŒä¸å˜**ã€‚<br>- æ–°å¢çš„ `random_uuid` ç”Ÿæˆåœ¨æ¯ä¸ªè¯·æ±‚å¯¹è±¡ä¸­ä»æ˜¯ O(1) å¼€é”€ï¼Œå‡ ä¹å¯å¿½ç•¥ã€‚ |
| **å®‰å…¨è€ƒè™‘** | - åªæ¶‰åŠ **å†…éƒ¨ä»£ç ç»„ç»‡**ï¼Œæœªå¼•å…¥å¤–éƒ¨ä¾èµ–æˆ–ç½‘ç»œäº¤äº’ï¼Œå®‰å…¨é£é™©æä½ã€‚<br>- ç»Ÿä¸€äº† `request_id` çš„ç”Ÿæˆæ–¹å¼ï¼Œé˜²æ­¢å› æ‰‹åŠ¨çœç•¥å¯¼è‡´çš„æ—¥å¿—è¿½è¸ªç›²åŒºã€‚ |
| **å¯ç»´æŠ¤æ€§** | - é€šè¿‡ **Mixin** æ¶ˆé™¤åœ¨å¤šä¸ªåè®®æ–‡ä»¶ä¸­é‡å¤å£°æ˜çš„ `modelã€userã€truncate_prompt_tokensã€priorityã€request_id` ç­‰å­—æ®µï¼Œåç»­è‹¥è¦æ›´æ”¹å­—æ®µå±æ€§ï¼Œåªéœ€åœ¨åŸºç±»é‡Œä¿®æ”¹ä¸€æ¬¡ã€‚<br>- æ‰€æœ‰ **score_utils** ç°åœ¨ä½äº `pooling/score` å‘½åç©ºé—´ï¼Œé¿å…äº†å†å²çš„ â€œæ··ç”¨â€ å¯¼è‡´çš„å¾ªç¯å¯¼å…¥ã€‚ |
| **å…¼å®¹æ€§** | - **å¯¼å…¥è·¯å¾„å˜æ›´**ï¼ˆå¦‚ `vllm.entrypoints.score_utils` â†’ `vllm.entrypoints.pooling.score.utils`ï¼‰å°†å¯¼è‡´ä½¿ç”¨æ—§è·¯å¾„çš„ç¬¬ä¸‰æ–¹ä»£ç æŠ¥ `ImportError`ã€‚<br>- å…¬å¼€çš„ APIï¼ˆå¦‚ `POST /classify`ã€`POST /embed`ã€`POST /pooling`ï¼‰çš„ **JSON schema** åŸºæœ¬ä¿æŒä¸å˜ï¼Œåªæ˜¯å­—æ®µé¡ºåº/é»˜è®¤å€¼çš„å®ç°ç»†èŠ‚æœ‰æ‰€æ›´æ–°ï¼›å·²æœ‰å®¢æˆ·ç«¯è‹¥ä¾èµ–å­—æ®µé¡ºåºæˆ–æ˜¾å¼æ£€æŸ¥ `priority`/`request_id` çš„å­˜åœ¨ï¼Œå¯èƒ½å‡ºç°å…¼å®¹æ€§é—®é¢˜ã€‚ |
| **æµ‹è¯•è¦†ç›–** | - å¤§å¹…æ‰©å……äº† **online æµ‹è¯•**ï¼ˆtokenâ€‘idsã€ç©ºåˆ—è¡¨ã€æ‰¹é‡è¯·æ±‚ã€æˆªæ–­å¼‚å¸¸ï¼‰ä»¥åŠ **ç«¯åˆ°ç«¯è°ƒç”¨**ï¼ˆ`/v1/models`ã€`/tokenize`ã€`/invocations`ï¼‰ï¼Œæå‡å›å½’ä¿éšœã€‚<br>- åˆ é™¤çš„æ—§ç¤ºä¾‹æ–‡ä»¶ `openai_classification_client.py` å·²è¢«æ–°ç¤ºä¾‹ `classification_online.py` æ›¿ä»£ï¼Œæ–‡æ¡£åŒæ­¥ã€‚ |

---

### âš ï¸ æ½œåœ¨é£é™©

1. **ç ´åå‘åå…¼å®¹**  
   * å¯¼å…¥è·¯å¾„æ›´æ”¹ä¼šç«‹å³å½±å“æ‰€æœ‰ä¾èµ– `vllm.entrypoints.score_utils`ã€`vllm.entrypoints.score` ç­‰æ¨¡å—çš„å¤–éƒ¨é¡¹ç›®ã€‚<br>* è‹¥ç”¨æˆ·è‡ªè¡Œå®ç°è‡ªå®šä¹‰ `ScoreContentPartParam` å¹¶ä»æ—§ä½ç½®å¯¼å…¥ï¼Œä»£ç å°†å¤±æ•ˆã€‚  

2. **åˆå§‹åŒ–é¡ºåºé—®é¢˜**  
   * `init_pooling_state` ä¾èµ– `engine_client.get_supported_tasks()` ä¸ `process_chat_template` çš„å¼‚æ­¥è°ƒç”¨ï¼›è‹¥æœªæ¥åœ¨ `engine_client` ä¸­åŠ å…¥æ–°çš„ä»»åŠ¡æˆ–æ›´æ”¹è¿”å›ç»“æ„ï¼Œå¯èƒ½å¯¼è‡´ `state.openai_serving_*` ä¸º `None`ï¼Œè¿›è€Œåœ¨è·¯ç”±å±‚é¢è¿”å› 500ã€‚  

3. **è¯·æ±‚å­—æ®µå†²çª**  
   * `CompletionRequestMixin` ä¸­çš„ `input` å…è®¸ `list[int] | list[list[int]] | str | list[str]`ï¼Œä½†æŸäº›æ¨¡å‹åœ¨ `add_special_tokens=False` æ—¶ä»ä¼šè‡ªåŠ¨æ·»åŠ  BOS/EOSï¼Œå¯¼è‡´ **éšæ€§è¡Œä¸ºä¸ä¸€è‡´**ï¼ˆå‚è§æµ‹è¯• `test_add_special_tokens` ä¸­çš„ FIXMEï¼‰ã€‚  

4. **æ—¥å¿—/ç›‘æ§è¿ç§»**  
   * `request_logger` ä»åœ¨ `init_pooling_state` ä¸­åˆ›å»ºï¼Œæ—§ç‰ˆ `api_server` ç›´æ¥ä½¿ç”¨ `state.request_logger`ï¼Œè¿ç§»åè‹¥æœ‰å¤–éƒ¨ç›‘æ§ä»å¼•ç”¨æ—§è·¯å¾„ä¼šå¤±æ•ˆã€‚  

5. **æ–‡æ¡£åŒæ­¥**  
   * READMEã€API æ–‡æ¡£ã€OpenAI å…¼å®¹æ€§è¯´æ˜éœ€åŒæ­¥æ›´æ–°ï¼Œå¦åˆ™ç”¨æˆ·åœ¨é˜…è¯»æ—§æ–‡æ¡£æ—¶ä¼šäº§ç”Ÿè¯¯å¯¼ã€‚  

---

### ğŸ’¡ å…³æ³¨å»ºè®®

| å—ä¼— | å»ºè®® |
|------|------|
| **é¡¹ç›®ç»´æŠ¤è€…** | - åœ¨ **vLLM** ç‰ˆæœ¬å·ä¸­åŠ å…¥ **é‡å¤§ (major) å˜æ›´**ï¼Œå¹¶åœ¨ `CHANGELOG` ä¸­æ ‡æ³¨ â€œPooling API é‡æ„ï¼Œæ—§ `score_utils` å°†åœ¨ vX.Y+1 ä¸­ç§»é™¤â€ã€‚<br>- æä¾› **å…¼å®¹å±‚**ï¼ˆå¦‚åœ¨ `vllm.entrypoints` ä¸­æ·»åŠ  `score_utils = pooling.score.utils` çš„å¯¼å…¥åˆ«åï¼‰ä½œä¸ºä¸´æ—¶æ¡¥æ¥ï¼Œç»™ç”Ÿæ€ä¼™ä¼´ 1â€‘2 å‘¨çš„è¿ç§»çª—å£ã€‚<br>- ä¸º `init_pooling_state` æ·»åŠ  **å¼‚å¸¸æ•è·æ—¥å¿—**ï¼Œç¡®ä¿å¦‚æœ `supported_tasks` è¯»å–å¤±è´¥ä¸ä¼šå¯¼è‡´æ•´ä¸ªæœåŠ¡å™¨å¯åŠ¨å¤±è´¥ã€‚ |
| **ç¬¬ä¸‰æ–¹å¼€å‘è€…** | - æ›´æ–°ä»£ç ä¸­æ‰€æœ‰ `vllm.entrypoints.score_utils`ã€`vllm.entrypoints.score` çš„ import ä¸ºæ–°è·¯å¾„ `vllm.entrypoints.pooling.score.utils`ã€‚<br>- è‹¥ç›´æ¥æ„é€ è¯·æ±‚ä½“ï¼Œè¯·å‚è€ƒ **`PoolingBasicRequestMixin`** ä¸ **`CompletionRequestMixin`** çš„å­—æ®µå®šä¹‰ï¼Œå°¤å…¶æ³¨æ„ `add_special_tokens` åœ¨æŸäº›æ¨¡å‹ä¸Šä»è¢«å¼ºåˆ¶å¼€å¯ã€‚ |
| **æµ‹è¯•/CI è´Ÿè´£äºº** | - å°† **æ–°æµ‹è¯•å¥—ä»¶**ï¼ˆåŒ…æ‹¬ `test_empty_input_error`ã€`test_truncate_prompt_tokens`ï¼‰çº³å…¥ CIï¼Œç¡®ä¿åœ¨ä¸åŒæ¨¡å‹/ç¡¬ä»¶ï¼ˆCPUã€CUDAã€ROCmï¼‰ä¸Šå‡é€šè¿‡ã€‚<br>- æ·»åŠ  **å…¼å®¹æ€§å›é€€æµ‹è¯•**ï¼šåœ¨åŒä¸€è¿›ç¨‹ä¸­åˆ†åˆ«å¯¼å…¥æ—§è·¯å¾„ä¸æ–°è·¯å¾„ï¼ŒéªŒè¯ä¸¤è€…è¿”å›ç›¸åŒçš„ Pydantic æ¨¡å‹ã€‚ |
| **è¿ç»´/å®‰å…¨å®¡è®¡** | - è™½ç„¶æœ¬æ¬¡æ”¹åŠ¨ä¸æ¶‰åŠå¤–éƒ¨ç½‘ç»œï¼Œä½†ä»å»ºè®® **å®¡è®¡** `init_pooling_state` ä¸­çš„å¼‚æ­¥è°ƒç”¨æ˜¯å¦å­˜åœ¨æœªæ•è·çš„å¼‚å¸¸ï¼Œä»¥é˜²æœåŠ¡åœ¨å¯åŠ¨æ—¶å› ç½‘ç»œæ³¢åŠ¨æˆ–æ¨¡å‹åŠ è½½å¤±è´¥è¿›å…¥ä¸å¯ç”¨çŠ¶æ€ã€‚ |
| **æ–‡æ¡£ç¼–è¾‘è€…** | - åœ¨ **OpenAIâ€‘compatible Server** æ–‡æ¡£ç« èŠ‚ä¸­æ›´æ–°ç¤ºä¾‹æ–‡ä»¶è·¯å¾„ã€è¯·æ±‚å­—æ®µè¯´æ˜åŠ **â€œè¿ç§»æŒ‡å—â€**ï¼Œå¹¶åœ¨ â€œå¸¸è§é”™è¯¯â€ ä¸­åŠ å…¥ `add_special_tokens` å¯èƒ½æ— æ•ˆçš„æç¤ºã€‚ |

---

**æ€»ä½“ç»“è®º**  
æ­¤è½®æäº¤é€šè¿‡ **æŠ½è±¡ä¸ç»Ÿä¸€** å¤§å¹…æå‡äº† pooling ç›¸å…³å…¥å£ç‚¹çš„å¯ç»´æŠ¤æ€§ï¼Œæ¶ˆé™¤äº†å¤šå¤„é‡å¤ä»£ç ï¼Œä¸”å¯¹å¤–éƒ¨è¡Œä¸ºå‡ ä¹ä¿æŒä¸å˜ã€‚å”¯ä¸€éœ€è¦é‡ç‚¹å…³æ³¨çš„æ˜¯ **å‘åå…¼å®¹çš„ç ´å**ï¼ˆå¯¼å…¥è·¯å¾„åŠæ½œåœ¨çš„å­—æ®µè¡Œä¸ºå·®å¼‚ï¼‰ï¼Œå»ºè®®åœ¨å‘å¸ƒæ–° major ç‰ˆæœ¬æ—¶æä¾›å…¼å®¹å±‚å¹¶åœ¨æ–‡æ¡£ä¸­æ˜ç¡®

---

### [ROCm] [CI] [Release] Rocm wheel pipeline with sccache (#32264)
**SHA**: `41c544f` | ğŸ”— [æŸ¥çœ‹æäº¤](https://github.com/vllm-project/vllm/commit/41c544f78a4d8264adec86dcf8d338c62193bf68)

**ğŸ¯ å˜æ›´ç±»å‹**ï¼šåŠŸèƒ½å¢å¼ºï¼ˆæ–°å¢ ROCm Wheel Release CI æµæ°´çº¿ã€ç¼“å­˜æœºåˆ¶ã€SCCache åŠ é€Ÿã€è‡ªåŠ¨ç´¢å¼•å’Œå‘å¸ƒè„šæœ¬ï¼‰  
**âš¡ é‡è¦ç¨‹åº¦**ï¼šğŸ”´ é«˜  
**ğŸ“‹ å˜æ›´æ‘˜è¦**ï¼š  
- åœ¨ Buildkite ä¸­åŠ å…¥å®Œæ•´çš„ ROCm Wheel Release æµæ°´çº¿ï¼ŒåŒ…æ‹¬æ‰‹åŠ¨é…ç½®è¾“å…¥ã€Baseâ€‘wheel æ„å»ºã€vLLM Wheel æ‰“åŒ…ã€S3 ä¸Šä¼ åŠ Release æ³¨é‡Šã€‚  
- Dockerfile ç³»åˆ—ï¼ˆ`Dockerfile.rocm_base`ã€`Dockerfile.rocm`ï¼‰åŠ å…¥å¯é€‰ SCCache æ”¯æŒã€ç¯å¢ƒå˜é‡å°è£…ã€ä»¥åŠä¸“ç”¨äº Wheel Release çš„ `build_vllm_wheel_release` é˜¶æ®µã€‚  
- æ–°å¢ç¼“å­˜è„šæœ¬ `cache-rocm-base-wheels.sh`ã€ä¸Šä¼ è„šæœ¬ `upload-rocm-wheels.sh`ã€æ³¨é‡Šè„šæœ¬ `annotate-rocm-release.sh`ï¼Œå¹¶åœ¨ `generateâ€‘nightlyâ€‘index.py` ä¸­åŠ å…¥ ROCmâ€‘variant å¤„ç†ä¸ PEPâ€‘503 åŒ…åè§„èŒƒåŒ–ã€‚  
- æ–°å¢ä¾èµ–å›ºå®šè„šæœ¬ `pin_rocm_dependencies.py`ï¼Œåœ¨æ„å»º Wheel æ—¶å°†è‡ªå®šä¹‰ ROCm è½®å­ï¼ˆtorchã€tritonã€torchvisionã€amdsmi ç­‰ï¼‰ç²¾ç¡®é’‰ä½åˆ° `requirements/rocm.txt`ã€‚  

**ğŸ¯ å½±å“èŒƒå›´**ï¼š  
- **CI/CD**ï¼š`.buildkite/release-pipeline.yaml`ï¼ˆæ–°å¢ 5+ æ­¥ï¼‰ï¼Œæ‰€æœ‰ ROCm ç›¸å…³çš„ Buildkite ä»»åŠ¡ã€‚  
- **Docker é•œåƒ**ï¼š`docker/Dockerfile.rocm_base`ã€`docker/Dockerfile.rocm`ï¼ˆæ–°å¢ SCCache ARG/ENVï¼Œæ–°å¢ Wheelâ€‘Release é˜¶æ®µï¼‰ã€‚  
- **å‘å¸ƒæµç¨‹**ï¼šS3 Bucket `vllm-wheels`ï¼ˆæ–°å¢ `rocm/` å‰ç¼€ã€Cacheã€Nightlyã€ç‰ˆæœ¬ç›®å½•ï¼‰ã€‚  
- **ä»£ç åº“**ï¼š`tools/vllm-rocm/pin_rocm_dependencies.py`ã€`generate-nightly-index.py`ï¼ˆå˜æ›´ï¼‰ä»¥åŠç›¸å…³çš„ä¾èµ–æ–‡ä»¶ (`requirements/rocm*.txt`)ã€‚  

**ğŸ” æŠ€æœ¯æ´å¯Ÿ**  

| ç»´åº¦ | å½±å“ |
|------|------|
| **æ¶æ„å½±å“** | 1. å¼•å…¥äº† **å››å±‚æµæ°´çº¿**ï¼ˆè¾“å…¥ â†’ Baseâ€‘wheel â†’ vLLMâ€‘wheel â†’ Upload â†’ Annotateï¼‰ï¼Œä½¿ ROCm æ‰“åŒ…è·¯å¾„ä¸ CUDA å®Œå…¨ç‹¬ç«‹ã€‚<br>2. Docker é•œåƒå±‚æ¬¡åŠ å…¥ **SCCache**ï¼ˆå¯é€‰ï¼‰ä»¥åŠ **/install** ç›®å½•çš„è‡ªå®šä¹‰è½®å­æ‹·è´ï¼Œå½¢æˆ â€œWheelâ€‘Release ä¸“ç”¨â€ é•œåƒï¼Œä»…åœ¨ Release Pipeline ä¸­ä½¿ç”¨ï¼Œé¿å…äº†å¯¹æ™®é€š `rocm` é•œåƒçš„æ°¸ä¹…ä½“ç§¯è†¨èƒ€ã€‚ |
| **æ€§èƒ½å½±å“** | - **SCCache**ï¼šåœ¨å¼€å¯ `USE_SCCACHE=1` æ—¶ï¼ŒGPUâ€‘ç¼–è¯‘ï¼ˆPyTorchã€TorchVisionã€FAã€AIterã€Mori ç­‰ï¼‰å¯ä»¥æ˜¾è‘—å¤ç”¨å‰ä¸€æ¬¡ç¼–è¯‘äº§ç‰©ï¼ŒCI Build æ—¶é—´é¢„è®¡ä» 2â€‘3h ç¼©çŸ­è‡³ â‰¤â€¯1hã€‚<br>- **Cacheâ€‘Key**ï¼šåŸºäº Dockerfile å†…å®¹ + Python/ROCM æ¶æ„ Arg ç”Ÿæˆçš„ SHAï¼Œç¼“å­˜å‘½ä¸­å¯ç›´æ¥è·³è¿‡å…¨éƒ¨ç¼–è¯‘å’Œ Docker buildï¼Œæå¤§æå‡ Nightly/Dev æäº¤çš„äº¤ä»˜é€Ÿåº¦ã€‚ |
| **å®‰å…¨è€ƒè™‘** | 1. **SCCache äºŒè¿›åˆ¶ä¸‹è½½**ï¼šç›´æ¥ä» GitHub Release æ‹‰å– tarballï¼Œæœªæ ¡éªŒ SHAâ€‘256ï¼Œå­˜åœ¨ä¾›åº”é“¾ç¯¡æ”¹é£é™©ã€‚å»ºè®®åœ¨ CI æ­¥éª¤ä¸­åŠ å…¥æ ¡éªŒæˆ–ä½¿ç”¨å®˜æ–¹å·²ç­¾åçš„åŒ…ã€‚<br>2. **S3 è®¿é—®å¯†é’¥**ï¼šè„šæœ¬é€šè¿‡ç¯å¢ƒå˜é‡æ³¨å…¥ï¼ˆBuildkite secretï¼‰ï¼Œè‹¥æ³„éœ²ä¼šå¯¼è‡´æœªæˆæƒå†™å…¥ `vllm-wheels`ï¼Œéœ€è¦ç¡®ä¿ IAM è§’è‰²ä»…æ‹¥æœ‰ `PutObject` æƒé™ä¸”è·¯å¾„å—é™ (`rocm/` å‰ç¼€)ã€‚<br>3. **Wheel Pin è„šæœ¬**ï¼šå¯¹ `requirements/rocm.txt` è¿›è¡Œå°±åœ°ä¿®æ”¹å¹¶å¤‡ä»½ï¼Œè‹¥è„šæœ¬åœ¨é”™è¯¯çš„å·¥ä½œç›®å½•æ‰§è¡Œå¯èƒ½è¯¯æ”¹å…¶ä»–åˆ†æ”¯çš„æ–‡ä»¶ã€‚å»ºè®®åœ¨ Docker æ„å»ºé˜¶æ®µä½¿ç”¨åªè¯»æŒ‚è½½æˆ–å¤åˆ¶åå†ä¿®æ”¹ã€‚ |
| **å¯ç»´æŠ¤æ€§** | - **è„šæœ¬åˆ†ç¦»**ï¼š`cacheâ€‘rocmâ€‘baseâ€‘wheels.sh`ã€`uploadâ€‘rocmâ€‘wheels.sh`ã€`annotateâ€‘rocmâ€‘release.sh` å„è‡ªèŒè´£å•ä¸€ï¼Œæ˜“äºå•ç‹¬æµ‹è¯•ã€‚<br>- **Pin è„šæœ¬**ï¼šç›´æ¥è§£æ wheel æ–‡ä»¶åï¼Œç¡¬ç¼–ç äº† â€œtorch-ã€triton-ã€torchvision- â€¦â€ çš„æ˜ å°„ï¼Œæ–°å¢æˆ–æ›´æ”¹è½®å­åç§°æ—¶éœ€åŒæ­¥æ›´æ–°è„šæœ¬ã€‚<br>- **generateâ€‘nightlyâ€‘index.py** ç°åœ¨å¯¹ ROCm variant è¿›è¡Œè‡ªåŠ¨ç»§æ‰¿ï¼Œé€»è¾‘ç¨å¾®å¤æ‚ï¼Œå»ºè®®åŠ å…¥å•å…ƒæµ‹è¯•è¦†ç›– variant è§£æã€package name è§„èŒƒåŒ–è·¯å¾„ã€‚ |
| **å…¼å®¹æ€§** | - å¯¹ç°æœ‰ CUDA æµæ°´çº¿å½±å“æœ€å°ï¼Œå› ä¸ºæ‰€æœ‰æ–°å¢ ARG/ENV å‡æœ‰é»˜è®¤å€¼ä¸”ä»…åœ¨ `rocm` ç›¸å…³æ­¥éª¤ä¸­ä¼ é€’ã€‚<br>- `requirements/rocm.txt` ç§»é™¤ `fastsafetensors`ï¼ˆè½¬ç§»è‡³ testï¼‰ï¼Œè‹¥ç”¨æˆ·åœ¨éâ€‘Release ç¯å¢ƒç›´æ¥ `pip install -r requirements/rocm.txt`ï¼Œä¼šç¼ºå°‘è¯¥ä¾èµ–ï¼Œéœ€åœ¨æ–‡æ¡£ä¸­æ˜ç¡®è¯´æ˜ã€‚ |

**âš ï¸ æ½œåœ¨é£é™©**  

1. **SCCache ä¸‹è½½/è¿è¡Œå¤±è´¥**ï¼šç½‘ç»œæ³¢åŠ¨æˆ– GitHub Release è¢«åˆ å¯¼è‡´æ„å»ºå¡æ­»ã€‚  
2. **ç¼“å­˜é”®å†²çª**ï¼šå½“ä»… Python ç‰ˆæœ¬æˆ– GPU arch å˜æ›´è€Œ Dockerfile æœªå˜ï¼Œç¼“å­˜ä»å‘½ä¸­å¯¼è‡´ä½¿ç”¨æ—§çš„ Base é•œåƒï¼Œå¯èƒ½äº§ç”Ÿ ABI ä¸åŒ¹é…ã€‚  
3. **S3 å¹¶å‘å†™å†²çª**ï¼šå¤šæ¡ Release æ„å»ºåŒæ—¶å†™åŒä¸€ `rocm/<commit>/` å‰ç¼€ï¼Œå¯èƒ½äº§ç”Ÿè¦†ç›–æˆ–éƒ¨åˆ†æ–‡ä»¶ç¼ºå¤±ã€‚  
4. **Pin è„šæœ¬è¯¯å†™**ï¼šå¦‚æœè‡ªå®šä¹‰è½®å­æ–‡ä»¶åä¸ç¬¦åˆé¢„

---

#### ğŸŸ¡ ä¸­é‡è¦åº¦å˜æ›´ (12)

### [Chore] Replace swish with silu (#32459)
**SHA**: `180e981` | ğŸ”— [æŸ¥çœ‹æäº¤](https://github.com/vllm-project/vllm/commit/180e981d567a3f6db76078b210b582e59d10672b)

**ğŸ¯ å˜æ›´ç±»å‹**ï¼šé‡æ„ / è½»é‡åŠŸèƒ½å¢å¼º  
**âš¡ é‡è¦ç¨‹åº¦**ï¼šğŸŸ¡ ä¸­  
**ğŸ“‹ å˜æ›´æ‘˜è¦**ï¼š  
- å°†è‡ªå®ç°çš„ `Swish` æ¿€æ´»å±‚ç»Ÿä¸€æ”¹ä¸º PyTorch å®˜æ–¹å®ç° `nn.SiLU`ï¼Œå¹¶åœ¨ `get_activation` ä¸­ç»Ÿä¸€ç®¡ç†æ¿€æ´»å‡½æ•°æ˜ å°„ã€‚  
- ä¸º `get_activation` å¢åŠ  `"identity"` æ”¯æŒå¹¶åœ¨æœªåŒ¹é…åˆ°å·²çŸ¥åç§°æ—¶æŠ› `NotImplementedError`ï¼Œå–ä»£åŸæ¥çš„é»˜è®¤ä¸º `nn.Identity`ã€‚  
- `GLU` ä¸ `phi4mm` çš„å·ç§¯æ¨¡å—æ”¹ç”¨ `get_activation` è·å–æ¿€æ´»å‡½æ•°ï¼Œå»é™¤å†—ä½™ `Swish` ç±»å®ç°ã€‚  

**ğŸ¯ å½±å“èŒƒå›´**ï¼š  
- `vllm/model_executor/models/phi4mm_utils.py`ï¼ˆæ¿€æ´»å‡½æ•°è·å–ã€GLUã€å·ç§¯å±‚ï¼‰  
- å¯èƒ½é—´æ¥å½±å“æ‰€æœ‰ä½¿ç”¨ `phi4mm` æ¨¡å‹çš„æ¨ç†è·¯å¾„ä»¥åŠè‡ªå®šä¹‰æ¿€æ´»åç§°çš„é…ç½®æ–‡ä»¶ã€‚  

**ğŸ’¡ å…³æ³¨å»ºè®®**ï¼š  
1. **å…¼å®¹æ€§**ï¼šåŸå…ˆå¯¹æœªçŸ¥æ¿€æ´»åç§°ä¼šé»˜è®¤ä¸º `nn.Identity`ï¼Œç°åœ¨æ”¹ä¸ºæŠ›å¼‚å¸¸ã€‚è‹¥å¤–éƒ¨ä»£ç ä»ä¼šä¼ é€’è¯¸å¦‚ `"none"`ã€`""` ç­‰éæ ‡å‡†åç§°ï¼Œéœ€è¦æå‰åœ¨é…ç½®å±‚åšæ ¡éªŒæˆ–ä¿æŒå‘åå…¼å®¹çš„åˆ«åã€‚  
2. **PyTorch ç‰ˆæœ¬**ï¼š`nn.SiLU` éœ€ PyTorchâ‰¥1.7ï¼Œç¡®ä¿é¡¹ç›®çš„æœ€ä½ä¾èµ–æ»¡è¶³ï¼Œå¦åˆ™åœ¨æ—§ç¯å¢ƒä¸‹ä¼šæŠ¥ `AttributeError`ã€‚å¯åœ¨ `setup.cfg`/`requirements.txt` ä¸­æ˜ç¡®è¯´æ˜ã€‚  
3. **æ–‡æ¡£ & ç¤ºä¾‹**ï¼šæ›´æ–°æ¿€æ´»å‡½æ•°åˆ—è¡¨è¯´æ˜ï¼Œæ·»åŠ å¯¹ `"identity"` çš„è¯´æ˜ï¼Œä»¥åŠå¯¹ `"swish"` å·²è¢«æ˜ å°„ä¸º `SiLU` çš„æç¤ºï¼Œé˜²æ­¢ç”¨æˆ·å›°æƒ‘ã€‚  
4. **æµ‹è¯•**ï¼šå»ºè®®åœ¨ CI ä¸­åŠ å…¥é’ˆå¯¹ `get_activation` çš„å•å…ƒæµ‹è¯•ï¼Œè¦†ç›– `"relu"`ã€`"gelu"`ã€`"swish"`ã€`"sigmoid"`ã€`"identity"` ä»¥åŠå¼‚å¸¸è·¯å¾„ï¼Œç¡®ä¿æœªæ¥æ”¹åŠ¨ä¸ç ´åæ¿€æ´»æ˜ å°„ã€‚  
5. **ä»£ç æ¸…ç†**ï¼šç¡®è®¤é¡¹ç›®å…¶å®ƒæ–‡ä»¶ä¸å†ç›´æ¥å¼•ç”¨å·²åˆ é™¤çš„ `Swish` ç±»ï¼Œé¿å… `ImportError`ã€‚è‹¥æœ‰å†å²æ¨¡å‹æƒé‡ä¾èµ–è‡ªå®šä¹‰ `Swish`ï¼Œè¿è¡Œæ—¶ä»å…¼å®¹ï¼ˆå› ä¸º `nn.SiLU` ä¸ `Swish` è®¡ç®—ç›¸åŒï¼‰ï¼Œä½†å¯è€ƒè™‘ä¿ç•™å…¼å®¹å±‚æˆ–è¿ç§»è„šæœ¬ã€‚  

æ€»ä½“è€Œè¨€ï¼Œæ­¤æ¬¡æ”¹åŠ¨æå‡äº†ä»£ç å¯ç»´æŠ¤æ€§ä¸æ€§èƒ½ï¼ˆä½¿ç”¨åŸç”Ÿå®ç°ï¼‰ï¼Œä½†éœ€æ³¨æ„æ¿€æ´»åç§°æ ¡éªŒä¸æœ€ä½ PyTorch ç‰ˆæœ¬çš„å…¼å®¹æ€§ã€‚å»ºè®®åœ¨å‘å¸ƒè¯´æ˜ä¸­æ˜ç¡®è¿™äº›ç‚¹ï¼Œå¹¶è¡¥å……ç›¸åº”çš„å•å…ƒæµ‹è¯•ã€‚

---

### fix(rocm): Enable non-gated MoE (is_act_and_mul=False) support on ROCm (#32244)
**SHA**: `b66b0d6` | ğŸ”— [æŸ¥çœ‹æäº¤](https://github.com/vllm-project/vllm/commit/b66b0d6abb955f9209a0d88b1dc245f4c1c9ff98)

**ğŸ¯ å˜æ›´ç±»å‹**ï¼šBug ä¿®å¤ / åŠŸèƒ½å¢å¼º  
**âš¡ é‡è¦ç¨‹åº¦**ï¼šğŸŸ¡ ä¸­  

**ğŸ“‹ å˜æ›´æ‘˜è¦**  
1. åœ¨ ROCm ç¯å¢ƒä¸‹ï¼ŒåŸå…ˆçš„ AITERâ€¯Fusionâ€¯MoE å®ç°ä»…åœ¨ `is_act_and_mul=True`ï¼ˆå³ä½¿ç”¨ gated æ¿€æ´»ï¼‰æ—¶å¯ç”¨ï¼Œå¯¼è‡´ `is_act_and_mul=False` çš„ MoE åœ¨ ROCm ä¸Šç›´æ¥æŠ¥ `NotImplementedError`ã€‚  
2. æœ¬æ¬¡æ”¹åŠ¨å°† AITERâ€¯ç›¸å…³å¼€å…³ä¸ `is_act_and_mul` ç»‘å®šï¼Œåªæœ‰åœ¨æ¿€æ´»â€‘ä¹˜ä¸º gated æ—¶æ‰å¯ç”¨ AITERâ€¯fusionï¼›åŒæ—¶æ”¾å®½å¹³å°æ£€æµ‹æ¡ä»¶ï¼Œå…è®¸åœ¨ ROCmï¼ˆä»¥åŠ CUDAï¼‰ä¸Šä½¿ç”¨é gated MoEã€‚  

**ğŸ¯ å½±å“èŒƒå›´**  
- `vllm/model_executor/layers/fused_moe/layer.py` â€“ AITERâ€¯fusion æ ‡å¿—ä¸å¹³å°å…¼å®¹æ€§æ£€æŸ¥ã€‚  
- `vllm/model_executor/layers/fused_moe/unquantized_fused_moe_method.py` â€“ æ–°å¢ `rocm_aiter_moe_enabled` æ ‡å¿—ã€‚  
- ç›¸å…³é…ç½®ç±» `FusedMoEConfig`ï¼ˆ`is_act_and_mul`ï¼‰çš„è¡Œä¸ºåœ¨ ROCm ä¸Šå¾—åˆ°ä¿®æ­£ã€‚  

**ğŸ’¡ å…³æ³¨å»ºè®®**  
- **å¼€å‘è€…**ï¼šç¡®è®¤ `rocm_aiter_ops.is_fused_moe_enabled()` ä¸ `is_fusion_moe_shared_experts_enabled()` åœ¨ç›®æ ‡ ROCm ç‰ˆæœ¬ä¸Šè¿”å›é¢„æœŸå€¼ï¼›è‹¥ä»éœ€è¦é gated MoE çš„ AITER åŠ é€Ÿï¼Œéœ€ç­‰å¾…ä¸Šæ¸¸å®ç°æˆ–è‡ªè¡Œå®ç°å¯¹åº” kernelã€‚  
- **ç”¨æˆ·**ï¼šåœ¨ ROCm ç¯å¢ƒä¸‹ä½¿ç”¨ `is_act_and_mul=False` æ—¶ï¼Œè¯·ç¡®ä¿ `enable_fmoe`ï¼ˆæˆ–ç›¸å…³ç¯å¢ƒå˜é‡ï¼‰å·²å…³é—­ï¼Œä»¥é¿å…ä¸å¿…è¦çš„å›é€€ï¼›åŒæ—¶ä¿å­˜ `vllm` ç‰ˆæœ¬æ›´æ–°æ—¥å¿—ï¼Œä»¥è·å¾—æ–°åŠ å…¥çš„å…¼å®¹æ€§æ£€æŸ¥ã€‚  
- **æµ‹è¯•**ï¼šæ–°å¢å¯¹ ROCm + é gated MoE çš„å•å…ƒ/é›†æˆæµ‹è¯•ï¼ŒéªŒè¯åœ¨ä¸å¯ç”¨ AITER æ—¶æ¨¡å‹åŠŸèƒ½å®Œæ•´ä¸”æ€§èƒ½ä¸å—å¼‚å¸¸å½±å“ã€‚

---

### [Bugfix] Refactor to support DP parallel in R3 (#32306)
**SHA**: `03da3b5` | ğŸ”— [æŸ¥çœ‹æäº¤](https://github.com/vllm-project/vllm/commit/03da3b52ef6f3f3d9af5c1942c93a9ace7c2a6bf)

**ğŸ¯ å˜æ›´ç±»å‹**ï¼šåŠŸèƒ½å¢å¼ºï¼ˆä¸º MoEâ€¯Routedâ€¯Experts å¼•å…¥æ•°æ®å¹¶è¡Œ (DP) æ”¯æŒï¼‰  
**âš¡ é‡è¦ç¨‹åº¦**ï¼šğŸŸ¡ ä¸­  

**ğŸ“‹ å˜æ›´æ‘˜è¦**  
1. å°† `RoutedExpertsCapturer` ä»åªè¯» `ModelConfig` æ”¹ä¸ºä½¿ç”¨ç»Ÿä¸€çš„ `VllmConfig`ï¼Œå¹¶åœ¨åˆå§‹åŒ–æ—¶è®°å½• `data_parallel_rank`ã€‚  
2. å…±äº«å†…å­˜çš„åç§°ä¸é”æ–‡ä»¶åŠ å…¥ DPâ€‘rank åç¼€ï¼Œé¿å…å¤š DP å®ä¾‹å†²çªã€‚  
3. `capture` é€šè¿‡ `forward_context.get_forward_context()` è¯»å–è·¨ DP çš„ token è¾¹ç•Œä¿¡æ¯ï¼Œåªå†™å…¥å½“å‰ DP è´Ÿè´£çš„åˆ‡ç‰‡ã€‚  
4. `RoutedExpertsReader.attach_buffer`ã€è°ƒåº¦å™¨ (`scheduler.py`) ä»¥åŠ `GPUModelRunner` ç›¸åº”æ”¹ä¸ºä¼ é€’ `vllm_config`ï¼Œå¹¶åœ¨è¯»å–å…±äº«å†…å­˜å‰è®¾ç½® `dp_rank`ã€‚  

**ğŸ¯ å½±å“èŒƒå›´**  
- `vllm/model_executor/layers/fused_moe/routed_experts_capturer.py`ï¼ˆæ ¸å¿ƒå®ç°ï¼‰  
- `vllm/v1/core/sched/scheduler.py`ï¼ˆè°ƒåº¦å™¨åˆ›å»º readerï¼‰  
- `vllm/v1/worker/gpu_model_runner.py`ï¼ˆåˆå§‹åŒ– capturerï¼‰  
- æ–°å¢/ä½¿ç”¨ `vllm/forward_context.py`ï¼ˆè·å– DP å…ƒæ•°æ®ï¼‰  

**ğŸ’¡ å…³æ³¨å»ºè®®**  
1. **DPâ€‘rank å¯¹é½**ï¼šç¡®ä¿ `VllmConfig.parallel_config.data_parallel_rank` ä¸å®é™…è¿›ç¨‹çš„ DPâ€‘rank å®Œå…¨ä¸€è‡´ï¼Œå¦åˆ™å…±äº«å†…å­˜è¯»å–ä¼šé”™ä½ã€‚  
2. **è·¨ DP è¾¹ç•Œ**ï¼šå•å…ƒæµ‹è¯•éœ€è¦†ç›– â€œå• DPâ€ ä¸ â€œå¤š DPâ€ ä¸¤ç§è·¯å¾„ï¼Œç‰¹åˆ«æ˜¯ `capture` ä¸­çš„ `start_loc / end_loc` è®¡ç®—ã€‚  
3. **å…±äº«å†…å­˜æ¸…ç†**ï¼šå¤š DP è¿›ç¨‹é€€å‡ºæ—¶ä»éœ€ç»Ÿä¸€é‡Šæ”¾ `shm`ï¼Œé˜²æ­¢æ®‹ç•™å¯¼è‡´åç»­å®ä¾‹åˆ›å»ºå†²çªã€‚  
4. **å‘åå…¼å®¹**ï¼šæ—§ç‰ˆä»…ä½¿ç”¨ `ModelConfig` çš„ä»£ç ä»å¯å·¥ä½œï¼Œä½†æ¨èè¿ç§»åˆ° `VllmConfig`ï¼›æ³¨æ„åœ¨è‡ªå®šä¹‰è„šæœ¬ä¸­æ›´æ–°å¯¹åº”å‚æ•°ã€‚  
5. **æ€§èƒ½ç›‘æ§**ï¼šDP åˆ‡ç‰‡åæ¯ä¸ªè¿›ç¨‹åªå†™å…¥è‡ªå·±è´Ÿè´£çš„ tokenï¼Œç†è®ºä¸Šå¯æ¶ˆé™¤ä¸å¿…è¦çš„æ‹·è´ï¼Œå»ºè®®åœ¨å¤§è§„æ¨¡ DP åœºæ™¯ä¸‹å¯¹å…±äº«å†…å­˜å¸¦å®½è¿›è¡ŒåŸºå‡†æµ‹è¯•ã€‚  

æ•´ä½“æ¥çœ‹ï¼Œæ­¤æ¬¡é‡æ„ä¸º MoEâ€¯Routedâ€¯Experts åœ¨å¤šèŠ‚ç‚¹/å¤šå¡ DP åœºæ™¯ä¸‹æä¾›äº†å¯é çš„å…±äº«å†…å­˜æœºåˆ¶ï¼Œæå‡äº†å¹¶è¡Œå¯æ‰©å±•æ€§ã€‚åç»­æ³¨æ„ä¸Šè¿°ç»†èŠ‚å³å¯å¹³æ»‘è¿ç§»ã€‚

---

### [CI] Breakup h200 tests (#30499)
**SHA**: `14ce524` | ğŸ”— [æŸ¥çœ‹æäº¤](https://github.com/vllm-project/vllm/commit/14ce524249df0ccadab549ad0fa6a737bf0adb61)

**å˜æ›´ç±»å‹**ï¼šåŠŸèƒ½å¢å¼º / é‡æ„  
**é‡è¦ç¨‹åº¦**ï¼šğŸŸ¡ ä¸­  

**å˜æ›´æ‘˜è¦**  
- CI é…ç½®æ‹†åˆ†ï¼Œæ–°å¢ H100â€‘Fusionã€Distributed Fusionã€Sequenceâ€‘Parallel ç­‰ä¸“å±æ­¥éª¤ï¼Œå¹¶å°†éƒ¨åˆ† H200â€¯Fusion æµ‹ä¾‹ç§»é™¤ã€‚  
- å¤§å¹…é‡æ„ `tests/compile/distributed/test_fusions_e2e.py`ï¼šæŠ½å–å…¬å…±æ¨¡å‹ã€åŒ¹é…ã€è¿è¡Œå·¥å…·åˆ°æ–°æ¨¡å— `tests/compile/fusion_test_utils.py`ï¼Œå¹¶åœ¨ `test_fusion_attn.py` ä¸­å¤ç”¨ã€‚  
- æ–°å¢ `test_attn_quant` ç”¨ä¾‹ï¼Œç»Ÿä¸€åœ¨ H100/Blackwell ç¯å¢ƒä¸‹éªŒè¯æ³¨æ„åŠ›â€‘é‡åŒ–èåˆï¼Œå¹¶åŠ å…¥å›¾åˆ†åŒºã€cudagraph ç›¸å…³æ§åˆ¶ã€‚  
- å°å¹…æ›´æ–°æ³¨é‡ŠæŒ‡å‘æ–°æµ‹è¯•è·¯å¾„ã€‚

**å½±å“èŒƒå›´**  
- CI ä½“ç³»ï¼ˆ`.buildkite/test-pipeline.yaml`ï¼‰å’Œå¯¹åº”çš„ GPU èµ„æºæ ‡ç­¾ã€‚  
- ç¼–è¯‘/èåˆæµ‹è¯•ï¼š`tests/compile/*`ã€`tests/compile/distributed/*`ã€‚  
- å…¬å…±å·¥å…·æ¨¡å— `tests/compile/fusion_test_utils.py`ã€‚  
- `vllm/env_override.py` æ³¨é‡Šæ›´æ–°ã€‚

**å…³æ³¨å»ºè®®**  
1. **CI æ­¥éª¤**ï¼šç¡®è®¤ `optional: true` ä¸ `gpu: h100/h200` é…ç½®åœ¨æœºå™¨æ± ä¸­çœŸå®å¯ç”¨ï¼Œé¿å…å› æ ‡ç­¾ä¸åŒ¹é…å¯¼è‡´æ­¥éª¤ç›´æ¥è·³è¿‡ã€‚  
2. **æµ‹è¯•å…¼å®¹æ€§**ï¼š`test_attn_quant` ä¸­çš„ `has_device_capability(90)` ä¸ `is_blackwell()` åˆ¤æ–­éœ€è¦†ç›– H200 åœºæ™¯ï¼Œé˜²æ­¢åœ¨ä»…æœ‰ H200 çš„ç¯å¢ƒä¸­è¯¯æŠ¥è·³è¿‡ã€‚  
3. **æ¨¡å—å¼•ç”¨**ï¼š`fusion_test_utils` è¢«å¤šä¸ªæµ‹è¯•å¯¼å…¥ï¼Œæ£€æŸ¥ `__init__` æˆ–ç›¸å¯¹è·¯å¾„æ˜¯å¦å¯¼è‡´å¾ªç¯ä¾èµ–æˆ–å¯¼å…¥æ…¢å¯åŠ¨ã€‚  
4. **ç¯å¢ƒå˜é‡**ï¼š`VLLM_DISABLE_COMPILE_CACHE`ã€`VLLM_WORKER_MULTIPROC_METHOD` åœ¨æ–°ç”¨ä¾‹ä¸­ä»éœ€æ˜¾å¼è®¾ç½®ï¼Œç¡®ä¿ä¸å—ç¼“å­˜å½±å“ã€‚  
5. **æ—¥å¿—æ–­è¨€**ï¼šæ­£åˆ™ `r"fusion_attn.py:\d+] Fused quant onto (\d+) attention nodes"` ä¾èµ–å†…éƒ¨æ—¥å¿—æ ¼å¼ï¼Œè‹¥ upstream æ”¹åŠ¨éœ€åŒæ­¥æ›´æ–°ã€‚  

æ€»ä½“è€Œè¨€ï¼Œé‡æ„æå‡äº†ä»£ç å¯ç»´æŠ¤æ€§å¹¶ç»†åŒ–äº† GPUâ€‘specific æµ‹è¯•ï¼Œä½†éœ€åœ¨ CI ç¯å¢ƒå’Œè®¾å¤‡æ£€æµ‹é€»è¾‘ä¸Šåšå……åˆ†éªŒè¯ï¼Œé˜²æ­¢æ–°æ­¥éª¤å› ç¡¬ä»¶æ ‡ç­¾æˆ–æ—¥å¿—å˜æ›´è€Œå¤±æ•ˆã€‚

---

### [bugfix] Fix online serving crash when text type response_format is received (#26822)
**SHA**: `35bf5d0` | ğŸ”— [æŸ¥çœ‹æäº¤](https://github.com/vllm-project/vllm/commit/35bf5d08e8e4345805cebf08b29777f217ddf879)

**ğŸ¯ å˜æ›´ç±»å‹**ï¼šBug ä¿®å¤  
**âš¡ é‡è¦ç¨‹åº¦**ï¼šğŸŸ¡ ä¸­  

**ğŸ“‹ å˜æ›´æ‘˜è¦**  
- è§£å†³äº†åœ¨ OpenAI æ¥å£æ”¶åˆ° `response_format={"type":"text"}` æ—¶å¯¼è‡´æœåŠ¡å´©æºƒçš„é—®é¢˜ã€‚  
- é‡æ„äº† `response_format` åˆ° `StructuredOutputsParams` çš„æ˜ å°„é€»è¾‘ï¼Œç»Ÿä¸€ä½¿ç”¨ `dataclasses.replace` åˆå¹¶å¢é‡ä¿®æ”¹ï¼Œé¿å…åœ¨ `structured_outputs` ä¸º `None` æ—¶ç›´æ¥å±æ€§èµ‹å€¼å¯¼è‡´çš„ç©ºæŒ‡é’ˆã€‚  
- ä¸º `StructuredOutputsParams.__post_init__` æ·»åŠ äº† â€œè‡³å°‘å¿…é¡»æŒ‡å®šä¸€ç§çº¦æŸâ€ çš„æ ¡éªŒï¼Œé˜²æ­¢å…¨éƒ¨ä¸º `None` æ—¶è¯¯ç”¨ã€‚  
- å¢åŠ äº† `test_response_format_text` å•å…ƒæµ‹è¯•ï¼ŒéªŒè¯è¿”å›çš„ `content` å­—æ®µå§‹ç»ˆéç©ºã€‚  

**ğŸ¯ å½±å“èŒƒå›´**  
- `vllm/entrypoints/openai/chat_completion/protocol.py`ã€`vllm/entrypoints/openai/completion/protocol.py`ï¼ˆå“åº”æ ¼å¼ â†’ ç»“æ„åŒ–è¾“å‡ºçš„æ˜ å°„ï¼‰  
- `vllm/entrypoints/openai/responses/serving.py`ï¼ˆç»“æ„åŒ–è¾“å‡ºçš„å·¥å…·æ¨ç†è·¯å¾„ï¼‰  
- `vllm/sampling_params.py`ï¼ˆçº¦æŸæ ¡éªŒï¼‰  
- `vllm/tool_parsers/abstract_tool_parser.py`ï¼ˆå·¥å…·è°ƒç”¨æ—¶ç»“æ„åŒ–è¾“å‡ºåˆå§‹åŒ–ï¼‰  
- æ–°å¢çš„æµ‹è¯•æ–‡ä»¶ `tests/entrypoints/openai/test_chat.py`  

**ğŸ’¡ å…³æ³¨å»ºè®®**  
1. **å…¼å®¹æ€§æ£€æŸ¥**ï¼š`StructuredOutputsParams.__post_init__` ç°åœ¨åœ¨â€œæ— çº¦æŸâ€æƒ…å†µä¸‹æŠ›å¼‚å¸¸ï¼Œç¡®è®¤åœ¨æ‰€æœ‰è°ƒç”¨è·¯å¾„ï¼ˆå°¤å…¶æ˜¯æ—§ç‰ˆå®¢æˆ·ç«¯æˆ–å†…éƒ¨å·¥å…·é“¾ï¼‰å·²æ˜¾å¼è®¾å®šè‡³å°‘ä¸€ç§çº¦æŸï¼Œå¦åˆ™ä¼šå‡ºç°å¯åŠ¨é”™è¯¯ã€‚  
2. **ä»£ç è·¯å¾„å®Œæ•´æ€§**ï¼š`replace` ç”¨äºåˆå¹¶æ–°é”®å€¼æ—¶ï¼Œéœ€è¦ç¡®ä¿ `structured_outputs` å·²ç»æ˜¯ `StructuredOutputsParams` å®ä¾‹ï¼›è‹¥æœªæ¥å¼•å…¥å­ç±»æˆ–ä»£ç†å¯¹è±¡ï¼Œå¯èƒ½éœ€è¦é¢å¤–ç±»å‹ä¿æŠ¤ã€‚  
3. **æ€§èƒ½å½±å“**ï¼šå¼•å…¥ `replace` ä¸ä¸€æ¬¡æ€§ `dict` æ„é€ çš„æˆæœ¬æä½ï¼ŒåŸºæœ¬ä¸å½±å“ååï¼›ä½†è‹¥å¤§é‡å¹¶å‘è¯·æ±‚é¢‘ç¹è§¦å‘æ­¤è·¯å¾„ï¼Œå»ºè®®åœ¨ CI ä¸­åŠ å…¥å‹åŠ›æµ‹è¯•ä»¥ç¡®è®¤æ— æ„å¤–å›å½’ã€‚  
4. **æµ‹è¯•è¦†ç›–**ï¼šå½“å‰ä»…æ–°å¢äº† `text` ç±»å‹çš„æ­£å‘æµ‹è¯•ï¼Œå»ºè®®è¡¥å……è´Ÿå‘æµ‹è¯•ï¼ˆå¦‚ä¼ å…¥æœªçŸ¥ `type`ã€ç¼ºå¤±å¿…éœ€å­—æ®µç­‰ï¼‰ï¼Œä»¥åŠåœ¨ `completion` è·¯å¾„ä¸‹çš„å¯¹åº”éªŒè¯ï¼Œé˜²æ­¢ç±»ä¼¼é”™è¯¯å†æ¬¡æ³„éœ²ã€‚  
5. **æ–‡æ¡£æ›´æ–°**ï¼šåœ¨ OpenAI æ¥å£æ–‡æ¡£ä¸­æ˜ç¡®è¯´æ˜ `response_format` æ”¯æŒ `text`ã€`json_object`ã€`json_schema`ã€`structural_tag` å››ç§ç±»å‹ï¼Œå¹¶æç¤ºè‡³å°‘ä¸€ç§ç»“æ„åŒ–çº¦æŸå¿…é¡»ç”Ÿæ•ˆã€‚  

æ•´ä½“æ¥çœ‹ï¼Œæ­¤æ¬¡æ”¹åŠ¨ä¿®å¤äº†å…³é”®çš„çº¿ä¸Šå´©æºƒï¼Œä»£ç ç»“æ„æ›´ä¸ºç»Ÿä¸€ä¸”åŠ å…¥äº†é˜²å¾¡æ€§æ£€æŸ¥ï¼Œé£é™©å¯æ§ã€‚å»ºè®®åœ¨ä¸‹ä¸€ä¸ªå‘å¸ƒå‘¨æœŸå‰å®Œæˆå…¼å®¹æ€§å›å½’éªŒè¯å¹¶åŒæ­¥æ–‡æ¡£ã€‚

---

### [Model] Add Step3vl 10b (#32329)
**SHA**: `7095025` | ğŸ”— [æŸ¥çœ‹æäº¤](https://github.com/vllm-project/vllm/commit/709502558c3efa658b2b49c7019f9dc67929764d)

**å˜æ›´æ¦‚è¿°**  
æœ¬æ¬¡ PR ä¸º vLLM æ–°å¢å¯¹ **StepVLâ€‘10B**ï¼ˆ`stepfun-ai/Step3-VL-10B`ï¼‰æ¨¡å‹çš„æ”¯æŒã€‚æ ¸å¿ƒå·¥ä½œåŒ…æ‹¬ï¼š

1. **æ–‡æ¡£ & æ³¨å†Œ**ï¼šåœ¨ `supported_models.md`ã€æ¨¡å‹æ³¨å†Œè¡¨ `tests/models/registry.py`ã€æ‰§è¡Œå™¨æ³¨å†Œ `vllm/model_executor/models/registry.py` ä¸­åŠ å…¥ `StepVLForConditionalGeneration` æ¡ç›®ã€‚  
2. **å®ç°æ–‡ä»¶**ï¼šæ–°å¢ `vllm/model_executor/models/step_vl.py`ï¼Œå¤åˆ¶å¹¶æ”¹å†™è‡ª `Step3VLForConditionalGeneration`ï¼Œå®ç°äº†å®Œæ•´çš„è§†è§‰ç¼–ç å™¨ï¼ˆPerceptionEncoderï¼‰ä»¥åŠä¸è¯­è¨€æ¨¡å‹çš„æ¡¥æ¥é€»è¾‘ã€‚  
3. **æƒé‡æ˜ å°„**ï¼šæä¾› `hf_to_vllm_mapper` ç”¨äºæŠŠåŸ HF æƒé‡åç§°è½¬æ¢ä¸º vLLM å†…éƒ¨ç»“æ„ã€‚  

**å½±å“èŒƒå›´**  
- **æ¨¡å‹æ³¨å†Œä½“ç³»**ï¼š`ModelRegistry`ã€`tests/models/registry` ä»¥åŠæ–‡æ¡£å‡å—å½±å“ã€‚  
- **å¤šæ¨¡æ€æ‰§è¡Œè·¯å¾„**ï¼šæ–°å¢ `PerceptionEncoder`ã€`vit_large_projector`ï¼Œä»¥åŠ DP/TP ä¸¤ç§å¹¶è¡Œæ¨¡å¼çš„åˆ†æ”¯ã€‚  
- **æƒé‡åŠ è½½**ï¼š`WeightsMapper` éœ€è¦ä¿è¯æ‰€æœ‰å­å­—ç¬¦ä¸²æ˜ å°„è¦†ç›– HF checkpointã€‚  

**å…³æ³¨ç‚¹ä¸å»ºè®®**  

| å…³é”®ç‚¹ | è¯´æ˜ | å»ºè®® |
|--------|------|------|
| **å¹¶è¡Œæ¨¡å¼å…¼å®¹** | `use_data_parallel` é€šè¿‡ `mm_encoder_tp_mode == "data"` æ§åˆ¶ï¼Œè½¬å…¥ `run_dp_sharded_vision_model`ã€‚è‹¥ç”¨æˆ·åœ¨ TP ç¯å¢ƒä¸‹ä½¿ç”¨é»˜è®¤æ¨¡å¼ï¼Œå¯èƒ½è§¦å‘ä¸åŒ¹é…çš„å¼ é‡åˆ’åˆ†ã€‚ | åœ¨ `__init__` ä¸­åŠ å…¥æ–­è¨€ï¼Œè‹¥ `use_data_parallel` ä¸º `True` ä¸” `tp_size>1` ç»™å‡ºæ˜ç¡®é”™è¯¯æç¤ºã€‚ |
| **ROPE2D å¿…é¡»å¯ç”¨** | `PerceptionEncoder` åœ¨æ„é€ æ—¶å¼ºåˆ¶ `use_rope2d=True`ï¼Œå¦åˆ™æŠ›å¼‚å¸¸ã€‚å¤–éƒ¨é…ç½®è‹¥æœªåŒæ­¥å¯èƒ½å¯¼è‡´æ¨¡å‹åŠ è½½å¤±è´¥ã€‚ | åœ¨æ¨¡å‹é…ç½®æ£€æŸ¥é˜¶æ®µï¼ˆå¦‚ `vllm_config.model_config.multimodal_config`ï¼‰æå‰æ ¡éªŒå¹¶ç»™å‡ºå‹å¥½é”™è¯¯ä¿¡æ¯ã€‚ |
| **æƒé‡æ˜ å°„å®Œæ•´æ€§** | ç›®å‰ä»…æ˜ å°„äº† `attn`ã€`mlp` çš„å…³é”®å­å±‚ï¼Œè‹¥ HF checkpoint ä¸­å‡ºç°æ–°å¢å­æ¨¡å—ï¼ˆä¾‹å¦‚ `norm`ã€`positional_embedding`ï¼‰å°†æ¼åŠ è½½ã€‚ | åœ¨åŠ è½½ååŠ å…¥ä¸€æ¬¡æ€§å¯¹æ¯”æ£€æŸ¥ï¼š`assert all(param in state_dict for param in expected_keys)`ï¼Œå¹¶åœ¨ç¼ºå¤±æ—¶ç»™å‡ºè­¦å‘Šã€‚ |
| **å†…å­˜å ç”¨** | `vision_model` è¾“å‡ºå½¢çŠ¶ä¸º `(B, N, C)`ï¼Œéšåç» `ColumnParallelLinear` æŠ•å°„åˆ°æ–‡æœ¬éšè—ç»´åº¦ï¼Œ10B å‚æ•°æ¨¡å‹åœ¨å¤šå¡ä¸‹ä»å¯èƒ½å‡ºç° OOMã€‚ | å»ºè®®åœ¨ `vllm_config` ä¸­åŠ å…¥ `max_num_image_tokens` é™åˆ¶ï¼Œå¹¶åœ¨ `forward` å‰å¯¹ `image_features` åš `torch.cuda.amp.autocast` æˆ– `torch.utils.checkpoint`ï¼ˆæ¢¯åº¦æ£€æŸ¥ç‚¹ï¼‰æ”¯æŒã€‚ |
| **å•å…ƒæµ‹è¯•** | ä»…åœ¨ `tests/models/registry.py` æ·»åŠ äº†æ³¨å†Œé¡¹ï¼Œç¼ºå°‘é’ˆå¯¹è§†è§‰å‰ç½®ã€æŠ•å°„å’Œå¹¶è¡Œæ¨¡å¼çš„åŠŸèƒ½éªŒè¯ã€‚ | æ–°å¢ `tests/models/test_stepvl.py`ï¼ŒåŒ…æ‹¬ï¼šâ‘  è¯»å– HF checkpoint å¹¶æ£€æŸ¥æƒé‡æ˜ å°„ï¼›â‘¡ èµ°é€š `forward`ï¼ˆå¸¦/ä¸å¸¦å›¾ç‰‡ï¼‰å¹¶è¿”å› logitsï¼›â‘¢ åœ¨ dataâ€‘parallel ä¸ tensorâ€‘parallel ä¸¤ç§æ¨¡å¼ä¸‹åˆ†åˆ«è·‘ä¸€æ¬¡ã€‚ |
| **ä¾èµ–å¯¼å…¥** | æ–°æ–‡ä»¶å¼•ç”¨ `run_dp_sharded_vision_model`ã€`maybe_prefix`ã€`WeightsMapper`ï¼Œè¿™äº›åœ¨åŒç›®å½•ä¸‹å·²æœ‰ï¼Œä½†æœªåœ¨ `__all__` ä¸­å¯¼å‡ºã€‚è‹¥å¤–éƒ¨ `__init__` ä¾èµ– `*` å¯¼å…¥å¯èƒ½æŠ¥é”™ã€‚ | åœ¨ `vllm/model_executor/models/__init__.py` ä¸­åŠ å…¥ `from .step_vl import StepVLForConditionalGeneration`ï¼Œå¹¶åœ¨ `__all__` æ›´æ–°ã€‚ |
| **ç±»å‹æ³¨è§£ä¸æ–‡æ¡£** | ç±»/å‡½æ•°çš„è¿”å›ç±»å‹æ ‡æ³¨ç¼ºå¤±ï¼Œæ–‡æ¡£å­—ç¬¦ä¸²ä»…æœ‰ç®€è¦è¯´æ˜ã€‚ | å®Œå–„ `StepVLForConditionalGeneration.__init__`ã€`_get_vision_model_output`ã€`_process_image_features` ç­‰å…³é”®æ–¹æ³•çš„ docstring ä¸ `typing` æ³¨è§£ï¼Œæé«˜å¯è¯»æ€§ä¸ IDE æ”¯æŒã€‚ |

**æ€»ä½“è¯„ä»·**  
æ­¤æ¬¡æ”¹åŠ¨å®ç°äº†å¯¹ StepVLâ€‘10B çš„å®Œæ•´æ¥å…¥ï¼Œä»£ç ç»“æ„æ¸…æ™°ä¸”å¤ç”¨äº† Step3VL çš„å®ç°ï¼Œç¬¦åˆ vLLM çš„æ¨¡å‹æ‰©å±•è§„èŒƒã€‚è‹¥æŒ‰ç…§ä¸Šè¿°å»ºè®®è¡¥é½å¹¶è¡Œæ£€æŸ¥ã€æƒé‡å®Œæ•´æ€§æ ¡éªŒä»¥åŠæµ‹è¯•è¦†ç›–ï¼Œå¯è¿›ä¸€æ­¥æå‡ç¨³å®šæ€§å¹¶é™ä½ç”¨æˆ·åœ¨å¤§æ¨¡å‹éƒ¨ç½²æ—¶çš„è°ƒè¯•æˆæœ¬ã€‚

---

### Add thread_n=64 support to Marlin MoE (#32360)
**SHA**: `83239ff` | ğŸ”— [æŸ¥çœ‹æäº¤](https://github.com/vllm-project/vllm/commit/83239ff19ac6638ee85a51c3829e25680d3543c8)

**ğŸ¯ å˜æ›´ç±»å‹**ï¼šåŠŸèƒ½å¢å¼º  
**âš¡ é‡è¦ç¨‹åº¦**ï¼šğŸŸ¡ ä¸­  

**ğŸ“‹ å˜æ›´æ‘˜è¦**  
æœ¬æ¬¡æäº¤ä¸º Marlin MoE å®ç°åŠ å…¥ `thread_n = 64` çš„æ”¯æŒã€‚é€šè¿‡åœ¨ `generate_kernels.py`ã€`ops.cu` ä¸­æ‰©å±• `THREAD_CONFIGS` ä¸å¯¹åº”çš„ CUDA çº¿ç¨‹é…ç½®è¡¨ï¼Œå¹¶åœ¨ `marlin_utils_fp8.py` ä¸­æ”¹å†™ `w13` æƒé‡é‡åŒ–æ—¶çš„ç»´åº¦è®¡ç®—ï¼Œä½¿å…¶èƒ½å¤Ÿæ­£ç¡®å¤„ç† `n = w13_n`ï¼ˆå³ `weight.size(1)`ï¼‰ï¼Œä»è€Œå…¼å®¹æ–°çš„çº¿ç¨‹è§„æ¨¡ã€‚  

**ğŸ¯ å½±å“èŒƒå›´**  
- `csrc/moe/marlin_moe_wna16`ï¼ˆCUDA æ ¸å¿ƒä»£ç ã€çº¿ç¨‹é…ç½®ç”Ÿæˆï¼‰  
- `vllm/model_executor/layers/quantization/utils/marlin_utils_fp8.py`ï¼ˆFP8 MoE æƒé‡å‡†å¤‡ï¼‰  

**ğŸ’¡ å…³æ³¨å»ºè®®**  
1. **åŠŸèƒ½éªŒè¯**ï¼šåœ¨ä¸åŒ batchâ€‘sizeï¼ˆå°æ‰¹ã€å¤§æ‰¹ï¼‰ä¸‹è·‘å®Œæ•´çš„ MoE æ¨ç†/è®­ç»ƒåŸºå‡†ï¼Œç¡®ä¿æ–° `thread_n=64` é…ç½®ä¸ä¼šå‡ºç°ç»´åº¦ä¸åŒ¹é…æˆ–æº¢å‡ºé”™è¯¯ã€‚  
2. **æ€§èƒ½å›å½’**ï¼šå¯¹æ¯”åŸæœ‰ `thread_n=128/128`ã€`64/128` é…ç½®çš„ååå’Œå»¶è¿Ÿï¼Œç¡®è®¤æ–°å¢é…ç½®åœ¨å®é™…ç¡¬ä»¶ï¼ˆå°¤å…¶æ˜¯æ”¯æŒ 64â€‘N çš„ GPUï¼‰ä¸Šå¸¦æ¥é¢„æœŸæå‡ã€‚  
3. **ä»£ç ä¸€è‡´æ€§**ï¼š`THREAD_CONFIGS` ä¸ `ops.cu` ä¸­çš„æ•°ç»„é¡ºåºä¿æŒä¸€è‡´ï¼›å»ºè®®åœ¨ä¸¤å¤„æŠ½å–å…¬å…±å¸¸é‡æˆ–ç”Ÿæˆè„šæœ¬ï¼Œé˜²æ­¢æœªæ¥æ‰‹å·¥æ·»åŠ æ—¶å‡ºç°é—æ¼ã€‚  
4. **å•å…ƒæµ‹è¯•**ï¼šåŠ å…¥é’ˆå¯¹ `prepare_fp8_moe_layer_for_marlin` çš„æµ‹è¯•ï¼ŒéªŒè¯ `w13_n` çš„è®¡ç®—ä¸é‡æ’é€»è¾‘åœ¨ `thread_n=64` åœºæ™¯ä¸‹ä»ç„¶æ­£ç¡®ã€‚  
5. **æ–‡æ¡£æ›´æ–°**ï¼šåœ¨ Marlin MoE ä½¿ç”¨è¯´æ˜é‡Œæ ‡æ³¨æ–°æ”¯æŒçš„ `thread_n=64` å‚æ•°åŠå…¶é€‚ç”¨çš„ GPU æ¶æ„æˆ– batchâ€‘size èŒƒå›´ã€‚  

æ€»ä½“è€Œè¨€ï¼Œæ­¤æ”¹åŠ¨ä¸º Marlin MoE æä¾›äº†æ›´ç»†ç²’åº¦çš„çº¿ç¨‹è°ƒåº¦é€‰é¡¹ï¼Œè‹¥é€šè¿‡å……åˆ†æµ‹è¯•å¯æå‡åœ¨ç‰¹å®šç¡¬ä»¶ä¸Šçš„æ•ˆç‡ã€‚

---

### [Feat] Support non-gated MoE with Marlin, NVFP4 CUTLASS, FP8, INT8, compressed-tensors (#32257)
**SHA**: `c277fbd` | ğŸ”— [æŸ¥çœ‹æäº¤](https://github.com/vllm-project/vllm/commit/c277fbdf31f49c15049fe361ef92a7e34abc7b74)

**å˜æ›´æ¦‚è§ˆ**  
æœ¬æ¬¡ PR ä¸º vLLM MoEï¼ˆMixtureâ€‘ofâ€‘Expertsï¼‰å±‚å¼•å…¥ **éé—¨æ§ (nonâ€‘gated)â€¯MoE** çš„å®Œæ•´æ”¯æŒï¼Œå¹¶åœ¨å¤šå¤„ç»Ÿä¸€ **activation å‚æ•°** çš„ä¼ é€’æ–¹å¼ã€‚æ ¸å¿ƒå®ç°åŒ…æ‹¬ï¼š

| æ–¹å‘ | å…³é”®æ”¹åŠ¨ |
|------|----------|
| **åç«¯** | æ–°å¢ `marlin` ä½œä¸º NVFP4â€‘GEMM é€‰é¡¹ï¼ˆ`VLLM_NVFP4_GEMM_BACKEND=marlin`ï¼‰ï¼Œå¹¶åœ¨ `ModelOptNvFp4`ã€`FlashInfer`ã€`CUTLASS` ç­‰ oracle ä¸­åŠ å…¥å¯¹åº”åˆ¤æ–­ã€‚ |
| **æ¿€æ´»å‡½æ•°** | å°†åŸå…ˆ `Callable` â†’ `str`ï¼Œç»Ÿä¸€ä½¿ç”¨ `apply_moe_activation`ï¼Œå¹¶å®ç° `relu2_no_mul`ã€`silu`ã€`swigluoai` ç­‰åˆ†æ”¯ã€‚éé—¨æ§åœºæ™¯ä½¿ç”¨ `relu2_no_mul`ï¼ˆå³ `reluÂ²`ï¼‰å¹¶åœ¨ `utils.apply_moe_activation` ä¸­å®ç°åŸä½ `relu`+`square`ã€‚ |
| **æƒé‡å¸ƒå±€** | ä»¥ `w13_num_shards = 2`ï¼ˆé—¨æ§ï¼‰æˆ– `1`ï¼ˆéé—¨æ§ï¼‰åŒºåˆ† `w1/w3` åˆå¹¶åç»´åº¦ï¼Œæ‰€æœ‰ `*_moe`ã€`*_marlin`ã€`*_cutlass` ä¸­å¯¹åº”çš„ `intermediate_size`ã€workspaceã€cache å¤§å°ç»Ÿä¸€æŒ‰ `shards` è®¡ç®—ã€‚ |
| **è·¯ç”±/æƒé‡æ£€æŸ¥** | `check_moe_marlin_supports_layer` ç§»é™¤å¯¹æ¿€æ´»å¿…é¡»ä¸º `silu` çš„é™åˆ¶ï¼Œä»…ä¿ç•™å½¢çŠ¶ã€åˆ†ç»„ã€routerâ€‘weight çº¦æŸã€‚ |
| **æµ‹è¯•** | æ–°å¢ `test_fused_marlin_moe_non_gated`ï¼Œè¦†ç›– `relu2_no_mul` ä¸ `silu` ä¸¤ç§éé—¨æ§æ¿€æ´»çš„æ•°å€¼å¯¹é½ã€‚ |
| **å…¶å®ƒ** | - `envs.py` æ–°å¢ `marlin` é€‰é¡¹ã€‚<br>- å¤šå¤„ `assert activation.endswith("_no_mul")`ã€`is_act_and_mul` åˆ¤å®šè¿ç§»è‡³å±‚çº§é…ç½®ã€‚<br>- `quantization`ã€`compressed_tensors`ã€`awq_marlin` ç­‰æ¨¡å—ç›¸åº”æ”¹å†™ï¼Œä»¥æ”¯æŒ `activation` ä¼ é€’å¹¶ç§»é™¤ä»…é™ `silu` çš„ç¡¬ç¼–ç ã€‚ |

---

### å—å½±å“æ¨¡å—
- `vllm/model_executor/layers/fused_moe/*`ï¼ˆcutlassã€marlinã€utilsã€layerï¼‰  
- `vllm/model_executor/layers/quantization/*`ï¼ˆmodeloptã€fp8ã€gptq_marlinã€awq_marlinã€compressed_tensorsï¼‰  
- `vllm/model_executor/layers/quantization/utils/*`ï¼ˆflashinfer_fp4_moeã€marlin_utilsã€marlin_utils_fp4ï¼‰  
- `vllm/envs.py`ï¼ˆæ–°å¢åç«¯é€‰é¡¹ï¼‰  
- å•å…ƒæµ‹è¯• `tests/kernels/moe/*`

### æ½œåœ¨é£é™©
1. **å…¼å®¹æ€§**ï¼š`is_act_and_mul=False` ä»…åœ¨ CUDA ç¯å¢ƒä¸‹å®ç°ï¼Œä¸”ä»…é™ `marlin` ä¸ `flashinfer_cutlass` åç«¯ã€‚è‹¥ç”¨æˆ·åœ¨ ROCm æˆ–æœªå¼€å¯ `marlin`ï¼Œä»ä¼šè§¦å‘ `NotImplementedError`ã€‚  
2. **å†…å­˜å¸ƒå±€**ï¼š`w13_num_shards` åŠ¨æ€æ”¹å˜å¯¼è‡´çš„ workspace å¤§å°è®¡ç®—é”™è¯¯ï¼ˆå°¤å…¶åœ¨æå¤§ batchâ€‘sizeã€expertâ€‘count ç»„åˆä¸‹ï¼‰ï¼Œéœ€åœ¨ CI ä¸­åŠ å…¥æ›´å¤§è§„æ¨¡çš„éšæœºæµ‹è¯•ã€‚  
3. **æ¿€æ´»å®ç°å·®å¼‚**ï¼š`relu2_no_mul` ç°åœ¨åœ¨ `apply_moe_activation` ä¸­å…ˆ `F.relu(inplace=True)` å† `torch.square`ï¼Œè¿™ä¸åŸå…ˆ `torch.square(F.relu(input), out=output)` çš„é¡ºåºä¿æŒä¸€è‡´ï¼Œä½†åœ¨ autograd ä¸­ä¼šäº§ç”Ÿä¸¤æ¬¡ç®—å­ï¼Œå¯èƒ½å½±å“æ¢¯åº¦æ£€æŸ¥æˆ–æ€§èƒ½ã€‚  
4. **åºåˆ—åŒ–/åŠ è½½**ï¼šæƒé‡ä¿å­˜æ—¶ä»ä½¿ç”¨ `2 * intermediate_size` ç»´åº¦ï¼›åœ¨éé—¨æ§æ¨¡å¼ä¸‹åŠ è½½åä¼šå¤šå‡ºæœªä½¿ç”¨çš„åˆ‡ç‰‡ï¼Œéœ€è¦ç¡®è®¤ `state_dict`/`ckpt` å…¼å®¹æ€§ã€‚  

### å»ºè®®
- **æ–‡æ¡£**ï¼šåœ¨ MoE é…ç½®ç« èŠ‚æ˜ç¡®è¯´æ˜ `is_act_and_mul=False` çš„å‰ç½®æ¡ä»¶ï¼ˆCUDA + Marlin/FlashInferâ€‘CUTLASSï¼‰ï¼Œå¹¶æä¾› `VLLM_NVFP4_GEMM_BACKEND` çš„ä½¿ç”¨ç¤ºä¾‹ã€‚  
- **æ£€æŸ¥**ï¼šåœ¨ `Layer.__init__` ä¸­åŠ å…¥å¯¹ `vllm.envs.VLLM_NVFP4_GEMM_BACKEND` ä¸ `is_act_and_mul` çš„ä¸€è‡´æ€§æ ¡éªŒï¼Œé˜²æ­¢ç”¨æˆ·åœ¨ä¸æ”¯æŒçš„åç«¯ä¸Šè¯¯è®¾ã€‚  
- **å•å…ƒæµ‹è¯•**ï¼šè¡¥å……è·¨å¹³å°ï¼ˆROCmï¼‰å’Œä¸åŒ `backend`ï¼ˆcutlassã€marlinã€flashinferâ€‘cutlassï¼‰ç»„åˆçš„è´Ÿæµ‹è¯•ï¼Œç¡®ä¿æŠ›å‡ºé¢„æœŸå¼‚å¸¸ã€‚  
- **æ€§èƒ½åŸºå‡†**ï¼šå¯¹æ¯” `silu` ä¸ `relu2_no_mul` åœ¨ Marlin/FlashInfer åç«¯çš„ååé‡ï¼Œç¡®è®¤æ–°å®ç°æ²¡æœ‰å¼•å…¥æ˜¾è‘—å›é€€ã€‚  

æ€»ä½“æ¥çœ‹ï¼Œæ”¹åŠ¨å®ç°äº†éé—¨æ§ MoE çš„å…¨é“¾è·¯æ”¯æŒï¼Œä»£ç ç»“æ„æ›´ç»Ÿä¸€ï¼Œæ¿€æ´»å‡½æ•°æŠ½è±¡ä¹Ÿæ›´çµæ´»ã€‚ä½†éœ€åœ¨æ–‡æ¡£ã€é”™è¯¯æç¤ºä»¥åŠå¤§è§„æ¨¡å…¼å®¹æ€§æµ‹è¯•ä¸Šè¿›ä¸€æ­¥å®Œå–„ï¼Œä»¥é™ä½ç”¨æˆ·åœ¨ä¸åŒç¡¬ä»¶/åç«¯ä¸‹çš„ä½¿ç”¨é£é™©ã€‚

---

### [MoE Refactor][17/N] Apply Refactor to Bf16 (#31827)
**SHA**: `31c2925` | ğŸ”— [æŸ¥çœ‹æäº¤](https://github.com/vllm-project/vllm/commit/31c29257c852c429a655dd35a1c373ccd46f97da)

**å˜æ›´ç±»å‹**ï¼šåŠŸèƒ½å¢å¼º / é‡æ„  
**é‡è¦ç¨‹åº¦**ï¼šğŸŸ¡ ä¸­  
**å˜æ›´æ‘˜è¦**ï¼šæœ¬æ¬¡ PR å¯¹ MoEï¼ˆMixtureâ€‘ofâ€‘Expertsï¼‰åç«¯å®ç°è¿›è¡Œæ¨¡å—åŒ–é‡æ„ï¼Œå¹¶æ–°å¢ä¸€æ‰¹ GSMâ€‘8K è¯„ä¼°é…ç½®æ–‡ä»¶ï¼ˆBF16ã€FlashInferâ€‘CUTLASSã€TRITON ç­‰ç»„åˆï¼‰ã€‚æ ¸å¿ƒæ”¹åŠ¨åœ¨ `vllm/model_executor/layers/fused_moe/unquantized_fused_moe_method.py` ä¸ `vllm/model_executor/layers/fused_moe/oracle/unquantized.py` ä¸­ï¼Œå®ç°äº†åç«¯ç»Ÿä¸€é€‰æ‹©ã€æƒé‡æ ¼å¼è½¬æ¢ä»¥åŠ Kernel åˆ›å»ºçš„æŠ½è±¡å±‚ã€‚

### å…³é”®å®ç°
| æ–‡ä»¶ | ä¸»è¦æ”¹åŠ¨ |
|------|----------|
| `oracle/unquantized.py` | æ–°å¢ `UnquantizedMoeBackend` æšä¸¾ã€`select_unquantized_moe_backend`ã€`convert_to_unquantized_kernel_format`ã€`make_unquantized_moe_kernel` å››ä¸ªå·¥å…·å‡½æ•°ï¼Œå®ç°ï¼š<br>1ï¸âƒ£ æ ¹æ® EP/DPã€å¹³å°ã€ç¯å¢ƒå˜é‡è‡ªåŠ¨å†³å®šåç«¯ï¼ˆFlashInferâ€‘CUTLASSã€ROCmâ€‘AITERã€TRITONã€CPUã€XPUï¼‰ã€‚<br>2ï¸âƒ£ å¯¹ä¸åŒåç«¯è¿›è¡Œæƒé‡ shuffle / w13â†”w31 å˜æ¢ã€‚<br>3ï¸âƒ£ æ ¹æ®åç«¯è¿”å›å¯¹åº”çš„ Modular Kernel å¹¶æŒ‡æ˜æ˜¯å¦ä½¿ç”¨ inplaceã€‚ |
| `unquantized_fused_moe_method.py` | å¤§å¹…åº¦é‡æ„ï¼š<br>â€¢ åˆ é™¤ç›´æ¥å¯¼å…¥ FlashInferã€AITERã€Triton çš„å®ç°ï¼Œæ”¹ä¸ºç»Ÿä¸€èµ° `oracle` æ¥å£ã€‚<br>â€¢ åœ¨ `__init__` ä¸­ä¿å­˜ `self.unquantized_backend`ã€‚<br>â€¢ æ–°å¢ç§æœ‰æ–¹æ³• `_setup_kernel`ï¼Œè´Ÿè´£ï¼šâ‘  è°ƒç”¨ `convert_to_unquantized_kernel_format` è¿›è¡Œæƒé‡æ ¼å¼åŒ–ï¼›â‘¡ è°ƒç”¨ `make_unquantized_moe_kernel` æ„é€  `self.kernel` ä¸ `self.use_inplace`ã€‚<br>â€¢ å…¶å®ƒå¹³å°åˆ†æ”¯ï¼ˆXPUã€CPUã€CUDAï¼‰å‡æ”¹ä¸ºä¾æ® `self.unquantized_backend` åˆ¤å®šã€‚<br>â€¢ `maybe_make_prepare_finalize`ã€`process_weights_after_loading`ã€`forward_cuda` ç­‰é€»è¾‘ç›¸åº”è°ƒæ•´ã€‚ |
| é…ç½®æ–‡ä»¶ | åœ¨ `tests/evals/gsm8k/configs/moe-refactor*` ç›®å½•æ–°å¢ 8 ä»½ BF16â€‘TRITON/FlashInferâ€‘CUTLASS é…ç½®ï¼Œè¦†ç›– Qwen3â€‘30Bâ€‘A3Bã€Llamaâ€‘4â€‘Scoutã€Mixtralâ€‘8x7B ä¸‰ä¸ªæ¨¡å‹çš„ EP/DP åœºæ™¯ã€‚ |

### å½±å“èŒƒå›´
- **æ¨¡å‹åŠ è½½ä¸æ¨ç†è·¯å¾„**ï¼šæ‰€æœ‰ä½¿ç”¨ `UnquantizedFusedMoEMethod` çš„æ¨¡å‹ç°åœ¨ä¼šå…ˆèµ°åç«¯é€‰æ‹©å‡½æ•°ã€‚è‹¥å¹³å°æˆ–ç¯å¢ƒå˜é‡ä¸æ»¡è¶³åŸæœ‰ FlashInferâ€‘CUTLASS æ¡ä»¶ï¼Œå°†è‡ªåŠ¨å›é€€åˆ° Triton æˆ– AITERï¼Œä¿è¯ä¸å†å‡ºç° â€œbackend undefinedâ€ çš„ç¡¬ç¼–ç é”™è¯¯ã€‚  
- **è¯„ä¼°è„šæœ¬**ï¼šæ–°å¢çš„ GSMâ€‘8K é…ç½®åœ¨ CI ä¸­ä¼šè§¦å‘å¯¹åº”çš„ BF16 è¯„ä¼°ï¼Œç¡®ä¿æ–°åç«¯çš„æ•°å€¼ç²¾åº¦ä¸ååé‡ç¬¦åˆæœŸæœ›ã€‚  
- **å¹³å°å…¼å®¹æ€§**ï¼šæ–°å¢å¯¹ XPU/CPU çš„æ˜¾å¼å¤„ç†ï¼›åŸæœ‰ `current_platform.is_*` åˆ¤æ–­è¢«ç»Ÿä¸€å°è£…ï¼Œé™ä½è·¨å¹³å°å·®å¼‚å¯¼è‡´çš„ç»´æŠ¤æˆæœ¬ã€‚  

### é£é™© & å»ºè®®
1. **åç«¯é»˜è®¤è¿”å›**ï¼š`select_unquantized_moe_backend` åœ¨ä¸å­˜åœ¨åŒ¹é…å¹³å°æ—¶ä»ä¼šè¿”å› `backend`ï¼ˆæœªåˆå§‹åŒ–ï¼‰ï¼Œå¯èƒ½æŠ›å‡º `UnboundLocalError`ã€‚å»ºè®®åœ¨å‡½æ•°æœ«å°¾æ·»åŠ  `else: backend = UnquantizedMoeBackend.CPU` æˆ–æŠ›å‡ºæ˜ç¡®å¼‚å¸¸ã€‚  
2. **ç¯å¢ƒå˜é‡ä¸ EP/DP äº’æ–¥**ï¼š`flashinfer_cutlass_moe_enabled` ä»ä¾èµ– `use_ep` ä¸” `dp_size == 1`ï¼Œä½† `select_unquantized_moe_backend` å·²æŠŠ `use_dp` ä¼ å…¥ã€‚è‹¥åç»­å¼•å…¥ DP æ”¯æŒçš„ FlashInferï¼Œéœ€è¦åŒæ­¥æ›´æ–°åˆ¤å®šé€»è¾‘ã€‚  
3. **`self.kernel` å¯èƒ½ä¸º `None`**ï¼šåœ¨ `forward_cuda` é‡Œç›´æ¥ `assert self.kernel`ï¼Œè‹¥åœ¨ XPU/CPU ç­‰ä¸æ”¯æŒçš„åç«¯è¿”å› `None`ï¼ˆå·²åœ¨ `UNSUPPORTED_BACKEND` ä¸­åˆ—å‡ºï¼‰ï¼Œä»ä¼šè§¦å‘æ–­è¨€ã€‚å»ºè®®åœ¨é GPU è·¯å¾„ä½¿ç”¨å¯¹åº”çš„ `cpu_fused_moe`/`ipex` å®ä¾‹ï¼Œè€Œéå¼ºåˆ¶æ–­è¨€ã€‚  
4. **æµ‹è¯•è¦†ç›–**ï¼šç¡®ä¿ CI å¯¹æ‰€æœ‰å¹³å°ï¼ˆCUDAã€ROCmã€CPUï¼‰å‡è¿è¡Œä¸€æ¬¡ `select_unquantized_moe_backend`ï¼Œå¹¶éªŒè¯ `make_unquantized_moe_kernel` è¿”å›çš„ kernel æ˜¯å¦èƒ½æ­£å¸¸æ‰§è¡Œã€‚  
5. **æ–‡æ¡£åŒæ­¥**ï¼šREADME/æ¨¡å‹éƒ¨ç½²æ–‡æ¡£ä¸­å…³äº `VLLM_USE_FLASHINFER_MOE_FP16`ã€`VLLM_USE_XPU` ç­‰å˜é‡çš„è¯´æ˜éœ€è¦æ›´æ–°ï¼Œé¿å…ç”¨æˆ·åœ¨ä¸æ”¯æŒçš„ç¡¬ä»¶ä¸Šè¯¯è®¾ã€‚

### æ€»ç»“
æ­¤æ¬¡é‡æ„æŠŠ MoE åç«¯çš„é€‰æ‹©ã€æƒé‡è½¬æ¢ã€Kernel åˆ›å»ºæŠ½è±¡ä¸ºç‹¬ç«‹æ¨¡å—ï¼Œæ˜¾è‘—æå‡äº†ä»£ç å¯ç»´æŠ¤æ€§å’Œè·¨å¹³å°æ‰©å±•æ€§ã€‚åªè¦è¡¥é½åç«¯é»˜è®¤è¿”å›ä¸å¼‚å¸¸å¤„ç†ï¼Œå¹¶åœ¨ CI ä¸­è¦†ç›–æ‰€æœ‰åˆ†æ”¯ï¼Œå³å¯å¹³æ»‘ä¸Šçº¿ã€‚å»ºè®®åœ¨ä¸‹ä¸€ä¸ªè¿­ä»£ä¸­åŠ å…¥ DPâ€‘FlashInfer çš„å®éªŒå®ç°ï¼Œä»¥è¿›ä¸€æ­¥æå‡ BF16 åœºæ™¯ä¸‹çš„ååã€‚

---

### [ROCM] DSfp4 mla projection gemms weight dynamic quantization (#32238)
**SHA**: `8c11001` | ğŸ”— [æŸ¥çœ‹æäº¤](https://github.com/vllm-project/vllm/commit/8c11001ba2110134df3c3aecc63f2559ad1f5996)

**å˜æ›´æ¦‚è¿°**  
æœ¬æ¬¡æäº¤åœ¨ ROCmâ€‘AITer è·¯å¾„ä¸Šæ–°å¢å¯¹ **FP4ï¼ˆmxfp4ï¼‰BMM** çš„æ”¯æŒï¼Œå¹¶åœ¨ `mla_attention` ä¸­åŠ å…¥ç›¸åº”çš„é‡åŒ–ã€è°ƒç”¨è·¯å¾„ã€‚æ ¸å¿ƒæ”¹åŠ¨åŒ…æ‹¬ï¼š

| æ–‡ä»¶ | ä¸»è¦æ”¹åŠ¨ |
|------|----------|
| `vllm/_aiter_ops.py` | æ–°å¢ç¯å¢ƒå˜é‡ `VLLM_ROCM_USE_AITER_FP4BMM`ã€å¯¹åº”çš„å¼€å…³ `_FP4BMM_ENABLED`ï¼Œå®ç° `is_fp4bmm_enabled` æ£€æµ‹å¹¶æä¾› `batched_gemm_a16wfp4` åŒ…è£…ã€‚ |
| `vllm/envs.py` | å£°æ˜é»˜è®¤å¼€å¯ `VLLM_ROCM_USE_AITER_FP4BMM`ï¼Œå¹¶åœ¨ `env_var_map` ä¸­åŠ å…¥è§£æã€‚ |
| `mla_attention.py` | åœ¨æ¨¡å‹åŠ è½½æ—¶ä¾æ® `is_fp4bmm_enabled` ä¸æƒé‡ dtypeï¼ˆbf16ï¼‰å†³å®šæ˜¯å¦å¯¹ KVâ€‘proj æƒé‡é‡åŒ–ä¸º mxfp4ï¼›ç›¸åº”åœ°åœ¨å‰å‘è®¡ç®—ä¸­è°ƒç”¨ `batched_gemm_a16wfp4` æ›¿ä»£ fp8/bmmã€‚ |
| `quark/utils.py` | æ–°å¢ `quark_quantize_weight_to_mxfp4`ï¼Œåˆ©ç”¨ `dynamic_mxfp4_quant` å®Œæˆ 2â€‘ç»´ â†’ 4â€‘ä½å‹ç¼©ã€‚ |

**å½±å“èŒƒå›´**  
- **æ¨¡å‹åŠ è½½è·¯å¾„**ï¼šKVâ€‘proj æƒé‡å¯èƒ½è¢«å®æ—¶é‡åŒ–ä¸º MXFP4ï¼Œæ”¹å˜äº† `self.W_K`ã€`self.W_V` çš„å­˜å‚¨å½¢æ€å’Œå°ºåº¦ã€‚  
- **å‰å‘æ¨ç†**ï¼šåœ¨ `is_fp4bmm_enabled` ä¸º true ä¸”æƒé‡ä¸º bf16 æ—¶ï¼Œæ‰€æœ‰ KVâ€‘proj çš„çŸ©é˜µä¹˜è½¬ä¸º `batched_gemm_a16wfp4`ï¼ˆFP4ï¼‰ï¼Œå¦åˆ™ä»èµ°åŸæœ‰ fp8 æˆ– fp16 è·¯å¾„ã€‚  
- **ç¯å¢ƒå˜é‡**ï¼šç”¨æˆ·å¯é€šè¿‡ `VLLM_ROCM_USE_AITER_FP4BMM` æ§åˆ¶è¯¥ç‰¹æ€§å¼€å¯/å…³é—­ã€‚  

**å»ºè®®**  

1. **æ ¸å¯¹ç¡¬ä»¶å…¼å®¹æ€§**ï¼šFP4 BMM ä¾èµ– AIter æä¾›çš„ Triton kernelï¼Œä»…åœ¨æ”¯æŒçš„ AMD GPUï¼ˆMI200 ç³»åˆ—ç­‰ï¼‰ä¸Šå¯ç”¨ã€‚è‹¥ç¡¬ä»¶ä¸åŒ¹é…ï¼Œè¯·åœ¨éƒ¨ç½²è„šæœ¬ä¸­æ˜¾å¼å…³é—­ `VLLM_ROCM_USE_AITER_FP4BMM=0`ã€‚  
2. **éªŒè¯æ•°å€¼ç²¾åº¦**ï¼šFP4 é‡åŒ–ä¼šå¼•å…¥é¢å¤–è¯¯å·®ï¼Œå»ºè®®åœ¨å…³é”®ä¸šåŠ¡æ¨¡å‹ä¸Šè¿›è¡Œå¯¹æ¯”æµ‹è¯•ï¼ˆFP4 vs fp16/fp8ï¼‰ï¼Œç¡®è®¤è¯¯å·®åœ¨å¯æ¥å—èŒƒå›´ã€‚  
3. **ç›‘æ§åŠ è½½æ—¶é—´**ï¼šåœ¨ FP4 è·¯å¾„ä¸‹ä¸å†è¿›è¡Œ fp8 çš„é¢„ç¼–è¯‘å¾ªç¯ï¼Œä½†ä»ä¼šåœ¨é¦–æ¬¡è°ƒç”¨ `batched_gemm_a16wfp4` æ—¶è§¦å‘ä¸€æ¬¡ Triton ç¼–è¯‘ï¼Œé¦–æ¬¡æ¨ç†å¯èƒ½ç•¥æ…¢ã€‚å¯ä½¿ç”¨ `VLLM_LOG_LEVEL=DEBUG` æ£€æŸ¥ç¼–è¯‘æ—¥å¿—ã€‚  
4. **ä¿æŒå‘åå…¼å®¹**ï¼šé»˜è®¤å¼€å¯è¯¥ç‰¹æ€§ï¼Œè‹¥å‡ºç°å¼‚å¸¸ï¼Œå¯é€šè¿‡ç¯å¢ƒå˜é‡å›é€€åˆ° fp8/fp16ï¼›ä»£ç å·²ä¿ç•™æ—§è·¯å¾„çš„å®ç°ï¼Œä¸ä¼šå½±å“å·²æœ‰è„šæœ¬ã€‚  
5. **å•å…ƒæµ‹è¯•**ï¼šå»ºè®®æ–°å¢é’ˆå¯¹ `quark_quantize_weight_to_mxfp4` çš„å¼ é‡ç»´åº¦ã€dtype æ ¡éªŒæµ‹è¯•ï¼›ä»¥åŠåœ¨ `mla_attention` ä¸­å¯¹ `is_fp4bmm_enabled` ä¸º True/False ä¸¤ç§æƒ…å½¢çš„å‰å‘è·¯å¾„åšå›å½’ã€‚  

æ€»ä½“è€Œè¨€ï¼Œæ­¤æ¬¡æ”¹åŠ¨ä¸º ROCm ç¯å¢ƒæä¾›äº†æ›´é«˜ååé‡çš„ FP4 BMM é€‰é¡¹ï¼Œæå‡äº†é‡åŒ–æ¨ç†çš„æ½œåœ¨æ€§èƒ½ï¼Œä½†éœ€åœ¨å®é™…éƒ¨ç½²å‰éªŒè¯ç¡¬ä»¶æ”¯æŒä¸æ•°å€¼ç²¾åº¦ã€‚

---

### [UX] Use kv_offloading_backend=native by default (#32421)
**SHA**: `1be5a73` | ğŸ”— [æŸ¥çœ‹æäº¤](https://github.com/vllm-project/vllm/commit/1be5a73571ab2e2570b79a7474c98c496cc80de2)

**ğŸ¯ å˜æ›´ç±»å‹**ï¼šåŠŸèƒ½å¢å¼º  
**âš¡ é‡è¦ç¨‹åº¦**ï¼šğŸŸ¡ ä¸­  

**ğŸ“‹ å˜æ›´æ‘˜è¦**  
1. å°† `kv_offloading_backend` çš„é»˜è®¤å€¼ä» `None` æ”¹ä¸º `"native"`ï¼Œå¹¶åœ¨æ³¨é‡Šä¸­æ˜ç¡®åªæœ‰åœ¨ `kv_offloading_size` è¢«è®¾ç½®æ—¶æ‰ä¼šå¯åŠ¨ KV ç¼“å­˜ offloadingã€‚  
2. `_post_init_kv_transfer_config` é€»è¾‘æ”¹ä¸ºå…ˆæ£€æŸ¥ `kv_offloading_size` æ˜¯å¦ä¸º `None`ï¼Œè‹¥æ˜¯ç›´æ¥è¿”å›ï¼Œä¸å†å› ä»…è®¾ç½® backend è€ŒæŠ›å¼‚å¸¸ã€‚  
3. `EngineArgs`ã€`CacheConfig` ä¸­ç›¸åº”å­—æ®µçš„ç±»å‹ä»å¯é€‰æ”¹ä¸ºå¿…é€‰ï¼ˆé»˜è®¤å€¼ä¸º `"native"`ï¼‰ï¼Œå¹¶æ–°å¢å•å…ƒæµ‹è¯•éªŒè¯ â€œåªè®¾å¤§å°ã€é»˜è®¤ä½¿ç”¨ nativeâ€ çš„è¡Œä¸ºã€‚

**ğŸ¯ å½±å“èŒƒå›´**  
- `vllm/config/cache.py`ã€`vllm/config/vllm.py`ã€`vllm/engine/arg_utils.py` çš„é…ç½®è§£æè·¯å¾„ã€‚  
- KV è½¬ç§»ç›¸å…³çš„è¿è¡Œæ—¶åˆå§‹åŒ– (`KVTransferConfig`)ã€‚  
- å•å…ƒæµ‹è¯• `tests/v1/kv_connector/unit/test_config.py`ã€‚

**ğŸ’¡ å…³æ³¨å»ºè®®**  
- **æ–‡æ¡£åŒæ­¥**ï¼šç¡®ä¿ç”¨æˆ·æ‰‹å†Œã€ç¤ºä¾‹å’Œ CLI help ä¸­è¯´æ˜ â€œè‹¥ä»…é…ç½® `kv_offloading_size`ï¼Œoffloading é»˜è®¤ä½¿ç”¨ nativeâ€ã€‚  
- **å‘åå…¼å®¹**ï¼šæ—§ç‰ˆä»…è®¾ç½® `kv_offloading_backend`ï¼ˆæœªè®¾å¤§å°ï¼‰çš„ç”¨æˆ·ç°åœ¨ä¼šå¾—åˆ°æ—  offloading è€Œéå¼‚å¸¸ï¼Œå»ºè®®åœ¨å‘å¸ƒè¯´æ˜ä¸­ç»™å‡ºè¿ç§»æŒ‡å¼•ã€‚  
- **ç±»å‹å®‰å…¨**ï¼š`KVOffloadingBackend` ä»ä¿æŒå­—ç¬¦ä¸²æšä¸¾ï¼Œè‹¥æœªæ¥åŠ å…¥æ–°åç«¯ï¼Œéœ€åœ¨é»˜è®¤å€¼ä¿æŒ `"native"` çš„åŒæ—¶æ›´æ–°éªŒè¯é€»è¾‘ã€‚  
- **ç›‘æ§æ€§èƒ½**ï¼šé»˜è®¤å¼€å¯ native offloading å¯èƒ½å¢åŠ  CPU å†…å­˜å ç”¨ï¼Œå»ºè®®åœ¨ CI/benchmark ä¸­åŠ å…¥å¯¹ä¸åŒ `kv_offloading_size` çš„æ€§èƒ½åŸºå‡†ï¼Œä»¥é˜²æ„å¤–å›é€€ã€‚  

æ•´ä½“æ¥çœ‹ï¼Œæ­¤æ¬¡æ”¹åŠ¨ç®€åŒ–äº† KV offloading çš„é…ç½®è·¯å¾„ï¼Œæå‡äº†é»˜è®¤ä½“éªŒï¼Œä½†éœ€ç•™æ„æ–‡æ¡£ä¸å…¼å®¹æ€§ã€‚

---

### [Feature] Support async scheduling + PP (#32359)
**SHA**: `b34474b` | ğŸ”— [æŸ¥çœ‹æäº¤](https://github.com/vllm-project/vllm/commit/b34474bf2c207f2a7f08f6c830c71c3f85c82630)

**ğŸ¯ å˜æ›´ç±»å‹**ï¼šåŠŸèƒ½å¢å¼ºï¼ˆæ–°å¢ async schedulingâ€¯+â€¯pipelineâ€‘parallel æ”¯æŒï¼‰  
**âš¡ é‡è¦ç¨‹åº¦**ï¼šğŸŸ¡ ä¸­  

**ğŸ“‹ å˜æ›´æ‘˜è¦**  
1. `VllmConfig.__post_init__` å»æ‰äº† â€œasyncâ€¯+â€¯PPâ€¯>â€¯1 ä¸å…¼å®¹â€ çš„ç¡¬æ€§æ ¡éªŒï¼Œåªåœ¨ `async_scheduling=None` æ—¶é»˜è®¤å¼€å¯ asyncï¼Œé™¤é speculative ä¸ Eagle ä¸åŒ¹é…ã€‚  
2. `Scheduler.schedule` å¢åŠ  `if self.use_pp and request.num_output_placeholders > 0`ï¼Œåœ¨ PP åœºæ™¯ä¸‹é¿å…å¯¹åŒä¸€ request å†æ¬¡è°ƒåº¦å ä½ tokenï¼ˆæš‚æ—¶é™åˆ¶ PPâ€¯+â€¯asyncï¼‰ã€‚  
3. `MultiprocExecutor / RayExecutor.max_concurrent_batches` æ”¹ä¸º `pp_size = self.parallel_config.pipeline_parallel_size; return 2 if pp_size <= 1 and self.scheduler_config.async_scheduling else pp_size`ï¼Œä½¿ PPâ€¯>â€¯1 æ—¶æ‰¹æ¬¡æ•°ä¸ PP å¤§å°ä¿æŒä¸€è‡´ã€‚  
4. æµ‹è¯•åŠ©æ‰‹ `create_scheduler` è¡¥å…… `pipeline_parallel_size` å‚æ•°å¹¶ä¼ å…¥ `ParallelConfig`ã€‚

**ğŸ¯ å½±å“èŒƒå›´**  
- æ ¸å¿ƒè°ƒåº¦ (`vllm/v1/core/sched/scheduler.py`)  
- é…ç½®ä¸åˆå§‹åŒ– (`vllm/config/vllm.py`)  
- å¤šè¿›ç¨‹/ Ray æ‰§è¡Œå™¨å¹¶å‘æ§åˆ¶ (`vllm/v1/executor/*_executor.py`)  
- æµ‹è¯•å·¥å…· (`tests/v1/core/utils.py`)

**ğŸ’¡ å…³æ³¨å»ºè®®**  
- **å…¼å®¹æ€§æ£€æŸ¥**ï¼šè™½ç„¶ç¡¬æ€§æŠ¥é”™å·²å»é™¤ï¼Œä½†åœ¨ `async_scheduling=True` ä¸” `pipeline_parallel_size>1` æ—¶ä»ä¼šè§¦å‘è°ƒåº¦è·³è¿‡é€»è¾‘ï¼Œå®é™…è¡¨ç°ä¸º **asyncâ€¯+â€¯PP ä¸å¯ç”¨**ã€‚å»ºè®®åœ¨ `__post_init__` ä¸­åŠ å…¥æ˜ç¡®çš„è­¦å‘Šæˆ–æŠ›å¼‚å¸¸ï¼Œé˜²æ­¢ç”¨æˆ·è¯¯ä»¥ä¸ºä¸¤è€…å…¼å®¹ã€‚  
- **å ä½è·³è¿‡çš„å‰¯ä½œç”¨**ï¼šå½“å‰å®ç°ä¼šåœ¨ PP åœºæ™¯ä¸‹ç›´æ¥è·³è¿‡æ‰€æœ‰å¸¦å ä½çš„ requestï¼Œå¯èƒ½å¯¼è‡´ç”Ÿæˆåœæ»ï¼ˆå°¤å…¶åœ¨é•¿åºåˆ—æˆ–å¤š request åœºæ™¯ï¼‰ã€‚åº”åœ¨åç»­å®ç°ä¸­æ”¹ä¸º **åˆ†ç‰‡è°ƒåº¦**ï¼Œè€Œä¸æ˜¯ç®€å•è·³è¿‡ã€‚  
- **å¹¶å‘æ‰¹æ¬¡æ•°**ï¼š`max_concurrent_batches` ç°åœ¨åœ¨ PPâ€¯>â€¯1 ä¸” async æ‰“å¼€æ—¶è¿”å› `pp_size`ï¼Œè¿™å¯¹èµ„æºåˆ©ç”¨æ˜¯æ­£ç¡®çš„ï¼Œä½†è¦ç¡®è®¤ downstream å¯¹ `max_concurrent_batches` çš„å‡è®¾ï¼ˆå¦‚ â€œ2 ä¸º async ä¸Šé™â€ï¼‰å·²åŒæ­¥æ›´æ–°ã€‚  
- **æ–‡æ¡£/ç¤ºä¾‹**ï¼šæ›´æ–° README ä¸ API æ–‡æ¡£ï¼Œè¯´æ˜ â€œasync scheduling ç›®å‰ä»…åœ¨ pipeline_parallel_size=1 ä¸‹å®Œæ•´æ”¯æŒâ€ï¼Œå¹¶ç»™å‡ºå¦‚ä½•æ˜¾å¼å…³é—­ async æˆ–è®¾ç½® `pipeline_parallel_size` çš„ç¤ºä¾‹ã€‚  
- **æµ‹è¯•è¦†ç›–**ï¼šæ–°å¢é’ˆå¯¹ â€œasyncâ€¯+â€¯PP>1â€ çš„å•å…ƒ/é›†æˆæµ‹è¯•ï¼ŒéªŒè¯è°ƒåº¦æ˜¯å¦è¢«å®‰å…¨åœ°é˜»æ–­æˆ–ç»™å‡ºè­¦å‘Šï¼Œé˜²æ­¢å›å½’ã€‚  

æ€»ä½“æ¥è¯´ï¼Œæ­¤æäº¤ä¸º async è°ƒåº¦å¥ å®šäº†æ¡†æ¶ï¼Œä½†ä»éœ€å®Œå–„ PPâ€¯+â€¯async çš„å®é™…è°ƒåº¦å®ç°ä¸ç”¨æˆ·æç¤ºï¼Œé¿å…åœ¨ç”Ÿäº§ç¯å¢ƒä¸­å‡ºç°ä¸æ˜“å¯Ÿè§‰çš„ç”Ÿæˆåœé¡¿ã€‚

---

#### ğŸŸ¢ ä½é‡è¦åº¦å˜æ›´ (14)

### [EPLB][BugFix]Possible deadlock fix (#32418)
**SHA**: `c9a5330` | ğŸ”— [æŸ¥çœ‹æäº¤](https://github.com/vllm-project/vllm/commit/c9a533079cc8c991c527eab029dbc990b4dc9d5d)

**ğŸ¯ å˜æ›´ç±»å‹**ï¼šä»£ç é‡æ„  
**âš¡ é‡è¦ç¨‹åº¦**ï¼šğŸŸ¢ä½  
**ğŸ“‹ æ‘˜è¦**ï¼šåœ¨ EPLB `move_to_workspace` ä¸­å°†éé˜»å¡è·å–é”æ”¹ä¸ºé˜»å¡é‡è¯•ï¼Œæœ€å¤šå°è¯• 6 æ¬¡ï¼ˆæ¯æ¬¡ 10â€¯sï¼‰ï¼Œè¶…æ—¶åæŠ›å¼‚å¸¸ï¼Œé˜²æ­¢å¯èƒ½çš„æ­»é”ã€‚

---

### [CI][AMD] Skip test_permute_cols since the kernel is not used and not built for ROCm (#32444)
**SHA**: `6ca4f40` | ğŸ”— [æŸ¥çœ‹æäº¤](https://github.com/vllm-project/vllm/commit/6ca4f400d8b6c83a40af5c338b2ac55a8effdd76)

**ğŸ¯ å˜æ›´ç±»å‹**ï¼šæµ‹è¯•ä¿®æ”¹  
**âš¡ é‡è¦ç¨‹åº¦**ï¼šğŸŸ¢ä½  
**ğŸ“‹ æ‘˜è¦**ï¼šåœ¨ ROCm ç¯å¢ƒä¸­æ£€æµ‹ä¸åˆ° `permute_cols` å†…æ ¸æ—¶ï¼Œç›´æ¥è·³è¿‡ `test_permute_cols`ï¼Œé¿å…æ„å»ºå¤±è´¥ã€‚

---

### [ROCm][CI] Skip Qwen3-30B-A3B-MXFP4A16 Eval Test On Non-CUDA Platforms (#32460)
**SHA**: `b84c426` | ğŸ”— [æŸ¥çœ‹æäº¤](https://github.com/vllm-project/vllm/commit/b84c426a8c48c25db6a4a1a14860e845347db1c1)

**ğŸ¯ å˜æ›´ç±»å‹**ï¼šæµ‹è¯•ä¿®æ”¹  
**âš¡ é‡è¦ç¨‹åº¦**ï¼šğŸŸ¢ ä½  
**ğŸ“‹ æ‘˜è¦**ï¼šåœ¨ GSM8K æ­£ç¡®æ€§æµ‹è¯•ä¸­åŠ å…¥å¹³å°æ£€æµ‹ï¼Œé CUDA ç¯å¢ƒä¸‹è‹¥æ¨¡å‹ä¸º Qwen3-30B-A3B-MXFP4A16ï¼Œåˆ™ç›´æ¥è·³è¿‡è¯¥æµ‹è¯•ï¼Œä»¥é¿å… Marlin å†…æ ¸ä¸æ”¯æŒçš„é—®é¢˜ã€‚

---

### [Bug] Add TPU backend option (#32438)
**SHA**: `73f635a` | ğŸ”— [æŸ¥çœ‹æäº¤](https://github.com/vllm-project/vllm/commit/73f635a75f8a7b6655d45a26e34ac7b9a3ad11fd)

**ğŸ¯ å˜æ›´ç±»å‹**ï¼šä»£ç é‡æ„  
**âš¡ é‡è¦ç¨‹åº¦**ï¼šğŸŸ¢ä½  
**ğŸ“‹ æ‘˜è¦**ï¼šåœ¨ `UnquantizedMoeBackend` ä¸­åŠ å…¥ `TPU` é€‰é¡¹ï¼Œå¹¶åœ¨å¹³å°æ£€æµ‹é€»è¾‘ä¸­å®ç°å¯¹ TPU çš„è¯†åˆ«ä¸æ—¥å¿—è®°å½•ã€‚

---

### [Bugfix] [DeepSeek-V3.2] fix sparse_attn_indexer padding (#32175)
**SHA**: `5de6dd0` | ğŸ”— [æŸ¥çœ‹æäº¤](https://github.com/vllm-project/vllm/commit/5de6dd0662da663aa57127e82499d2c2d604c3d0)

**ğŸ¯ å˜æ›´ç±»å‹**ï¼šä»£ç é‡æ„ / Bugfix  
**âš¡ é‡è¦ç¨‹åº¦**ï¼šğŸŸ¢ä½  
**ğŸ“‹ æ‘˜è¦**ï¼šä¿®å¤ DeepSeekâ€‘V3.2 ä¸­ `sparse_attn_indexer` çš„ padding é€»è¾‘ï¼Œæ–°å¢å¯¹ `weights` çš„æ­£ç¡®æ‰“åŒ…ä¸å±•å¼€ï¼Œå¹¶ç»Ÿä¸€ä½¿ç”¨ `padded_weights`ï¼ŒåŒæ­¥ `topk_indices` çš„åˆ‡ç‰‡èŒƒå›´ï¼Œä»¥é¿å…ç»´åº¦ä¸åŒ¹é…å’Œæ½œåœ¨çš„æ¨ç†é”™è¯¯ã€‚

---

### [ROCm][CI] Enable AITER Unified Attention On ROCm For gpt-oss Test (#32431)
**SHA**: `46f8a98` | ğŸ”— [æŸ¥çœ‹æäº¤](https://github.com/vllm-project/vllm/commit/46f8a982b191e3a3d3a1eccaf18b184c391ac2ac)

**ğŸ¯ å˜æ›´ç±»å‹**ï¼šæµ‹è¯•ä¿®æ”¹  
**âš¡ é‡è¦ç¨‹åº¦**ï¼šğŸŸ¢ä½  
**ğŸ“‹ æ‘˜è¦**ï¼šåœ¨ `tests/entrypoints/openai/test_serving_chat.py` ä¸­ï¼Œå¼•å…¥ `is_aiter_found_and_supported` æ£€æµ‹ ROCm ä¸Šçš„ AITER æ”¯æŒï¼ŒåŠ¨æ€åˆ‡æ¢æ³¨æ„åŠ›åç«¯å¹¶åœ¨éœ€è¦æ—¶è®¾ç½® `VLLM_ROCM_USE_AITER=1` ç¯å¢ƒå˜é‡ï¼Œä»¥è§£å†³ gptâ€‘oss åœ¨ ROCm ä¸Šçš„å…¼å®¹æ€§é—®é¢˜ã€‚

---

### [CI] Fix LM Eval Large Models (H100) (#32423)
**SHA**: `bcf2333` | ğŸ”— [æŸ¥çœ‹æäº¤](https://github.com/vllm-project/vllm/commit/bcf2333cd6514543f579d9bb6d309c5b8a0bfd0d)

**ğŸ¯ å˜æ›´ç±»å‹**ï¼šä»£ç é‡æ„  
**âš¡ é‡è¦ç¨‹åº¦**ï¼šğŸŸ¢ä½  
**ğŸ“‹ æ‘˜è¦**ï¼šåœ¨ `input_quant_fp8.py` ä¸­ï¼Œ`forward_cuda` çš„ `group_shape` å‚æ•°æ”¹ä¸ºåœ¨é™æ€æ¨¡å¼ä¸‹æ˜¾å¼ä¼ é€’ `(row, col)` å…ƒç»„ï¼Œå¦åˆ™ä¸º `None`ï¼Œæå‡äº†ä»£ç å¯è¯»æ€§å¹¶é¿å…æ½œåœ¨çš„ç±»å‹é”™è¯¯ã€‚

---

### [Refactor] Remove unused file (#32422)
**SHA**: `aca5c51` | ğŸ”— [æŸ¥çœ‹æäº¤](https://github.com/vllm-project/vllm/commit/aca5c514876303913c686866cd7571638e512064)

**ğŸ¯ å˜æ›´ç±»å‹**ï¼šä»£ç é‡æ„  
**âš¡ é‡è¦ç¨‹åº¦**ï¼šğŸŸ¢ä½  
**ğŸ“‹ æ‘˜è¦**ï¼šåˆ é™¤äº† `vllm/entrypoints/pooling/embed/conftest.py`ï¼Œè¯¥æ–‡ä»¶æœªè¢«ä½¿ç”¨ï¼Œç§»é™¤åä¸å½±å“åŠŸèƒ½ï¼Œä»…å‡å°‘äº† 28 è¡Œå†—ä½™ä»£ç ã€‚

---

### [BugFix] Python file source reading can fail on UnicodeDecodeError (#32416)
**SHA**: `bd292be` | ğŸ”— [æŸ¥çœ‹æäº¤](https://github.com/vllm-project/vllm/commit/bd292be0c0fcdd139576fd83c8715af2eab4ca4f)

**ğŸ¯ å˜æ›´ç±»å‹**ï¼šå…¶ä»–  
**âš¡ é‡è¦ç¨‹åº¦**ï¼šğŸŸ¢ä½  
**ğŸ“‹ æ‘˜è¦**ï¼šåœ¨ `backends.py` ä¸­è¯»å–æ–‡ä»¶æ—¶åŒæ—¶æ•è· `UnicodeDecodeError`ï¼Œé¿å…å› ç¼–ç é—®é¢˜å¯¼è‡´è¯»å–å¤±è´¥å¹¶è®°å½•è­¦å‘Šã€‚

---

### [BugFix] Fix `assert x_s.shape[-1] == x_q.shape[-1] // group_shape[1]` in Blackwell Quantized MoE Test (#32362)
**SHA**: `c36ba69` | ğŸ”— [æŸ¥çœ‹æäº¤](https://github.com/vllm-project/vllm/commit/c36ba69bda2602a75aeee70f201987e10c2dd238)

**ğŸ¯ å˜æ›´ç±»å‹**ï¼šä»£ç é‡æ„  
**âš¡ é‡è¦ç¨‹åº¦**ï¼šğŸŸ¢ä½  
**ğŸ“‹ æ‘˜è¦**ï¼šå°† `scaled_decrypt` ä¸­å¯¹æ ‡é‡çš„æ£€æŸ¥ä» `x_s.ndim == 0` æ”¹ä¸º `x_s.numel() == 1`ï¼Œå¹¶ä½¿ç”¨ `reshape(1,1)` ç»Ÿä¸€æ ‡é‡å¼ é‡å½¢çŠ¶ï¼Œä¿®å¤ Blackwell é‡åŒ– MoE æµ‹è¯•ä¸­çš„æ–­è¨€é”™è¯¯ã€‚

---

### [Attention][AMD] Make flash-attn optional (#30361)
**SHA**: `0474133` | ğŸ”— [æŸ¥çœ‹æäº¤](https://github.com/vllm-project/vllm/commit/047413375c9de380213cb97fca4ce70915876939)

**ğŸ¯ å˜æ›´ç±»å‹**ï¼šä»£ç é‡æ„  
**âš¡ é‡è¦ç¨‹åº¦**ï¼šğŸŸ¢ä½  
**ğŸ“‹ æ‘˜è¦**ï¼šåœ¨ ROCm ç¯å¢ƒä¸‹ï¼Œå°†å¯¹ `flash_attn` çš„ç›´æ¥å¯¼å…¥æ”¹ä¸ºå¯é€‰ï¼›è‹¥æœªå®‰è£…ï¼Œåˆ™æä¾› `flash_attn_varlen_func` å ä½å®ç°ï¼Œè°ƒç”¨æ—¶æŠ›å‡ºæ˜ç¡®çš„ ImportError æç¤ºï¼Œä»è€Œé¿å…æ¨¡å—åŠ è½½å¤±è´¥ã€‚

---

### fixing podman build issue (#32131)
**SHA**: `74e4bb1` | ğŸ”— [æŸ¥çœ‹æäº¤](https://github.com/vllm-project/vllm/commit/74e4bb1c5af5d809c48631df44eec13140c6ff4b)

ğŸ¯ å˜æ›´ç±»å‹ï¼šé…ç½®è°ƒæ•´  
âš¡ é‡è¦ç¨‹åº¦ï¼šğŸŸ¢ä½  
ğŸ“‹ æ‘˜è¦ï¼šåœ¨ `docker/Dockerfile.rocm` ä¸­ä¸º `VLLM_REPO` ä¸ `VLLM_BRANCH` æ·»åŠ  `ENV` æŒ‡ä»¤ï¼Œä½¿ Podman æ„å»ºæ—¶å¯æ­£ç¡®è¯»å–è¿™äº›å‚æ•°ï¼Œè§£å†³æ„å»ºå¤±è´¥é—®é¢˜ã€‚

---

### [Model Runner V2] Support FlashInfer backend & Fix CUDA Graph bug [1/2] (#32348)
**SHA**: `6218034` | ğŸ”— [æŸ¥çœ‹æäº¤](https://github.com/vllm-project/vllm/commit/6218034dd7f9a56596e4fd8c8c8fc1d8011ed9c2)

**ğŸ¯ å˜æ›´ç±»å‹**ï¼šä»£ç é‡æ„  
**âš¡ é‡è¦ç¨‹åº¦**ï¼šğŸŸ¢ä½  
**ğŸ“‹ æ‘˜è¦**ï¼šåœ¨ `cudagraph_utils.py` ä¸­æ–°å¢å¯¹ mixedâ€‘mode CUDA graph çš„æ£€æµ‹ï¼Œé¿å…åœ¨é FULL æ¨¡å¼ä¸‹ä½¿ç”¨ï¼›åœ¨ `model_runner.py` ä¸­å°†æ³¨æ„åŠ›åç«¯æ”¯æŒæ‰©å±•è‡³ `FLASHINFER`ï¼Œå¹¶æä¾›æ›´å‹å¥½çš„é”™è¯¯æç¤ºã€‚

---

### [ROCm][Bugfix] Disable hip sampler to fix deepseek's accuracy issue on ROCm (#32413)
**SHA**: `77c16df` | ğŸ”— [æŸ¥çœ‹æäº¤](https://github.com/vllm-project/vllm/commit/77c16df31df16d09b2198b485a6d54cc14e98b69)

**ğŸ¯ å˜æ›´ç±»å‹**ï¼šä»£ç é‡æ„  
**âš¡ é‡è¦ç¨‹åº¦**ï¼šğŸŸ¢ä½  
**ğŸ“‹ æ‘˜è¦**ï¼šåœ¨ ROCm è·¯å¾„ä¸­æ–°å¢ `DISABLE_AITER_SAMPLER` æ ‡å¿—å¹¶é»˜è®¤å…³é—­ aiter samplerï¼Œé˜²æ­¢ DeepSeek ç²¾åº¦é—®é¢˜ï¼Œæ”¹ä¸ºä½¿ç”¨åŸç”Ÿé‡‡æ ·å®ç°ã€‚

---

