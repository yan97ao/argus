# 每日更新报告（2026-01-25）

## sgl-project/sglang

| 提交时间 | 作者 | 提交信息 |
|----------|------|----------|
| 2026-01-25 22:43:22 | Mick | [diffusion] refactor: remove useless lazy-import cache-dit codes (#17659) |
| 2026-01-25 22:38:13 | Simo Lin | remove self managed protocols as it has been replaced with official oai spec (#17711) |
| 2026-01-25 22:35:59 | Simo Lin | update to use official openai protocol crate (#17710) |
| 2026-01-25 22:15:03 | Simo Lin | use published reasoning parser crate (#17709) |
| 2026-01-25 20:40:47 | Zhengbo Wang | [Refactor] Use is_in_ci() utility in JIT kernel benchmarks (#17118) |
| 2026-01-25 17:17:47 | Makcum888e | revert row from https://github.com/sgl-project/sglang/pull/17584/ (#17701) |
| 2026-01-25 15:39:48 | Makcum888e | [Refactore] [CI] Remove redundant CI test runs step 2 (#17584) |
| 2026-01-25 15:34:02 | xjx471258437 | Support PD disaggregation with different TP/DP size for Qwen3-Next (#16056) |
| 2026-01-25 14:10:43 | Ke Bao | Fix swa memory pool size with spec (#17630) |
| 2026-01-25 13:10:14 | Mohammad Miadh Angkad | [DeepSeek-V3.2] Fix TRT-LLM NSA in target_verify/draft_extend (#17662) |
| 2026-01-25 11:18:15 | Alison Shao | Add PyTorch .bin file validation to CI weight validation (#17533) |
| 2026-01-25 10:54:46 | Kangyan-Zhou | Fix slash command handler trigger condition by trimming the comments (#17691) |
| 2026-01-25 10:10:48 | Chen Shen | [diffusion]: Fix ZImage SP sharding for caption and latent (#17301) |
| 2026-01-25 07:31:01 | Xinyuan Tong | fix: Refactor register_image_processor to use kwarg instead of positional arg (#17685) |
| 2026-01-25 04:24:44 | Kangyan-Zhou | Temporarily disable lora overlap loading test due to flakiness (#17683) |
| 2026-01-25 04:06:18 | Kangyan-Zhou | Fix NSA indexer test and move it to pre commit test (#17682) |
| 2026-01-25 03:46:08 | Kangyan-Zhou | Fix test timeout issue in pr-test (#17681) |

### 📊 统计摘要
> 本日共 17 个提交 | 🔴高 2 | 🟡中 8 | 🟢低 7
## 📋 目录

- [sgl-project/sglang](#sgl-project-sglang)
  - [📊 统计摘要](#-统计摘要)
  - [🔴 高重要度变更 (2)](#-🔴-高重要度变更-2)
    - [remove self managed protocols as it has been replaced wit...](#7a1d7ab)
    - [use published reasoning parser crate (#17709)](#6af22f8)
  - [🟡 中重要度变更 (8)](#-🟡-中重要度变更-8)
    - [update to use official openai protocol crate (#17710)](#8db2802)
    - [[Refactor] Use is_in_ci() utility in JIT kernel benchmark...](#fb61164)
    - [[Refactore] [CI] Remove redundant CI test runs step 2 (#1...](#d1042e0)
    - [Support PD disaggregation with different TP/DP size for Q...](#9bd92ba)
    - [Fix swa memory pool size with spec (#17630)](#30ece5e)
    - [Add PyTorch .bin file validation to CI weight validation ...](#9121f22)
    - [[diffusion]: Fix ZImage SP sharding for caption and laten...](#59f027a)
    - [fix: Refactor register_image_processor to use kwarg inste...](#37c04c2)
  - [🟢 低重要度变更 (7)](#-🟢-低重要度变更-7)
    - [[diffusion] refactor: remove useless lazy-import cache-di...](#b105dad)
    - [revert row from https://github.com/sgl-project/sglang/pul...](#64d8099)
    - [[DeepSeek-V3.2] Fix TRT-LLM NSA in target_verify/draft_ex...](#1674b9e)
    - [Fix slash command handler trigger condition by trimming t...](#b829b79)
    - [Temporarily disable lora overlap loading test due to flak...](#69a7a70)
    - [Fix NSA indexer test and move it to pre commit test (#17682)](#137eb5b)
    - [Fix test timeout issue in pr-test (#17681)](#8656a14)
#### 🔴 高重要度变更 (2)

### remove self managed protocols as it has been replaced with official oai spec (#17711)
**SHA**: `7a1d7ab` | 🔗 [查看提交](https://github.com/sgl-project/sglang/commit/7a1d7ab47b583b180da6cac6dc8d86a4e24b95cb)

**🎯 变更类型**：架构变更 / 重构  
**⚡ 重要程度**：🔴高  

**📋 变更摘要**  
本次提交在 `sgl-model-gateway/src/protocols` 目录下一次性删除了 75xx 行代码，涉及 **builders、chat、classify、common、completion、embedding、event_types、generate、messages、parser、rerank、responses、sampling_params、tokenize、validated、worker_spec** 等全部自研协议定义与实现。提交信息说明 “remove self managed protocols as it has been replaced with official oai spec”，意在彻底抛弃 SGLang 自行维护的协议层，统一使用官方 OpenAI（OpenAI‑compatible）规范。

---

## 🎯 影响范围

| 受影响模块/组件 | 关键功能 |
|----------------|----------|
| `sgl-model-gateway/src/protocols/*`（全部） | Chat Completion、Completions、Embedding、Classify、Rerank、Responses、Generate、Tokenize/Detokenize、Worker 管理、事件上报、内部 Builder、验证器等 |
| 依赖这些协议的 **路由 / handler**、**服务间 RPC**、**持久化/日志**、**单元/集成测试** | 编译会报错；运行时会出现未实现的 API；旧的持久化数据格式可能不兼容 |
| 与 **SGLang‑extension**（如 reasoning 参数、tool‑call 迁移、流式增量事件）相关的业务逻辑 | 需要迁移到官方规范的等价字段或自行实现兼容层 |
| `crate::protocols::builders`、`crate::protocols::validated` 等公用工具 | 被所有业务代码 Import，用法全部失效 |
| 外部使用者（SDK、第三方服务） | 破坏兼容性，必须升级到新版本的网关或适配新协议 |

---

## 🔍 技术洞察

### 架构影响
1. **统一协议层**  
   - 通过删除自研协议，网关将直接使用 OpenAI 官方的请求/响应模型（`ChatCompletionRequest/Response`、`CompletionRequest/Response`、`EmbeddingRequest/Response`、等）。  
   - 减少了协议层的分叉，提升了 **代码可维护性** 与 **文档一致性**，未来的 OpenAI 规范升级只需要改动少量适配层。

2. **模块解耦**  
   - 原有 `builders`、`validated`、`event_types` 等跨模块的公共依赖被完整移除，降低了内部耦合。  
   - 但同样意味着 **所有业务逻辑必须重新引用新的结构体**，若仍使用旧字段将导致编译错误。

3. **向后兼容性缺失**  
   - 旧协议的 **自定义字段**（如 `separate_reasoning`、`stream_reasoning`、`skip_special_tokens`、`return_hidden_states`、`tool_choice` 的旧实现）在官方规范中可能不存在或命名不同。  
   - 若网关仍在内部使用这些特性，需要在新协议上实现 **适配层**（如在 request 里手动填充 `tool_choice`、`logit_bias` 等）。

### 性能影响
- **编译时间 & 二进制体积**：删除近 8 万字符的代码，编译缓存更小，二进制文件减约 **200‑300 KB**（视具体依赖而定）。  
- **运行时开销**：  
  - 过去的 **Builder** 只在对象构造阶段产生少量堆分配，删除后对性能几乎没有负面影响。  
  - **ValidatedJson** 提供的自动校验被移除，若直接使用 `axum::Json`，则请求体的 **serde::de** 仍会执行校验（字段类型、`#[serde(default)]`），但 **业务层自定义的 `Validate`** 检查消失。若新协议不自行实现等价校验，可能导致不合法请求进入业务层，进而产生运行时错误或安全隐患。

### 安全考虑
| 项目 | 影响 |
|------|------|
| **输入校验** | 原 `ValidatedJson` 使用 `validator` crate 对所有请求进行 **字段范围、互斥关系、正则/EBNF** 等深度校验。移除后若直接依赖 `serde`，只能检查结构体能否反序列化，业务层仍需自行实现等价校验。缺失这些约束会提升 **DoS（恶意大 payload）**、**非法参数触发未定义行为** 的风险。 |
| **错误信息一致性** | 旧实现返回 OpenAI‑compatible 错误结构（`error.type`, `code` 等），新实现若使用官方库则保持一致；若自行返回则需确保不泄露内部实现细节。 |
| **事件上报** | `event_types` 删除意味着 **Response 生命周期事件**（如 `response.created`）不再自动产生。若监控系统依赖这些事件，需要在新代码中显式上报。否则监控盲区可能导致隐蔽故障。 |
| **Auth/权限** | `worker_spec`、`worker_config` 里原有的 `api_key`、`disable_health_check` 等字段被删除。若仍需要对 worker 进行细粒度控制，必须在新协议或配置中心重新实现。 |

### 可维护性 & 代码质量
- **代码量大幅下降**，CI 通过率预计提升（编译错误、lint 错误减少）。  
- **文档同步成本降低**，只需维护官方 OpenAI 文档与少量 SGLang‑extension。  
- 迁移后 **统一的 `serde` 标签** 与 **OpenAPI 生成** 更容易保持同步。

---

## ⚠️ 潜在风险

| 风险 | 描述 | 严重度 | 触发条件 |
|------|------|--------|----------|
| **编译破坏** | 任何仍然 `use crate::protocols::...` 的代码将编译失败。 | 高 | 开发分支、第三方 SDK |
| **运行时异常** | 某些业务在运行时仍假设旧字段（如 `separate_reasoning`）存在。 | 中 | 已上线服务的旧请求格式 |
| **安全回退** | 输入校验层被削弱，可能接受非法或恶意请求。 | 中 | 高流量、外部不可信客户端 |
| **监控缺失** | 删除 `event_types` 导致监控/日志系统失去关键事件上报。 | 低 | 依赖这些事件进行 SLA 计算 |
| **功能回退** | 原有的 **tool_choice**、**parallel_tool_calls** 等高级特性在官方规范中可能不完全对应，导致用户无法使用某些工具调用模式。 | 中 | 使用 SGLang‑specific 工具链的用户 |
| **持久化

---

### use published reasoning parser crate (#17709)
**SHA**: `6af22f8` | 🔗 [查看提交](https://github.com/sgl-project/sglang/commit/6af22f8dbf4852d3aec9df7c20a7b8361c9b2ddf)

**🎯 变更类型**：架构变更 / 重构 / 依赖替换  

**⚡ 重要程度**：🔴高  

**📋 变更摘要**：  
本次提交将原本在 `sgl-model-gateway` 中自行实现的 **Reasoning Parser**（包括 parser trait、多个模型专用实现、注册/池化机制以及大量单元测试）全部移除，改为直接使用外部发布的 Rust crate `reasoning-parser = "1.0.0"`。`Cargo.toml` 中新增依赖，`src/lib.rs` 的 `pub mod reasoning_parser` 改为 `pub use reasoning_parser;`，其余所有内部实现文件被删除。项目从内部维护一套完整的推理块解析逻辑，转向使用标准化、由社区维护的实现。

---

**🎯 影响范围**  
- **sgl-model-gateway**：核心网络层、模型调度、日志采集等模块在运行时会通过 `reasoning_parser` crate 获取 `ParserFactory`、`ParserRegistry`、`ReasoningParser` 等 API。  
- **依赖树**：新增 `reasoning-parser` 及其自身的依赖（`regex`、`memchr`、`url` 等），对构建时间、二进制体积产生影响。  
- **单元测试/CI**：原有的内部测试被删除；若项目 CI 依赖这些测试来验证解析行为，需要补充对外部 crate 的兼容性测试。  
- **文档/示例**：项目中原有的 `README.md`（reasoning_parser 章节）被删除，使用方需要查阅 `reasoning-parser` 官方文档。

---

**🔍 技术洞察**  

| 维度 | 影响描述 |
|------|----------|
| **架构影响** | 1. **职责划分更清晰**：解析功能交由专门的 crate 维护，gateway 代码聚焦于请求路由、模型调用等业务层。<br>2. **模块耦合度降低**：原来的内部实现与其它模块（如 `policies`、`observability`）通过 `pub mod` 暴露，改为依赖外部库后只保留抽象接口，降低了内部代码的侵入性。<br>3. **向后兼容风险**：如果外部 crate 的 API（如 `ParserFactory::new`、`ParserRegistry::get_pooled`）在后续 1.x 版本发生破坏性改动，gateway 将直接受影响。建议使用 `Cargo.toml` 中的 `=1.0.0` 或 `~1.0` 锁定兼容范围。 |
| **性能影响** | - **运行时开销**：外部 crate 采用了 `tokio::sync::Mutex` 与 `Arc<RwLock>` 实现 parser 池，与原实现基本一致，理论上不会出现性能回退。<br>- **二进制体积**：新增 `regex`、`memchr`、`url`、`reasoning-parser` 本身的依赖，导致最终产物大小约增加 200~300 KB（取决于编译优化）。<br>- **启动/热加载**：ParserFactory 初始化时会注册所有默认解析器，和原实现相同的惰性创建策略不会引入额外延迟。|
| **安全考虑** | 1. **外部依赖审计**：`reasoning-parser` 目前只有 1.0.0 版，依赖链相对简单，未发现高危 CVE；但仍需在 CI 中加入 `cargo audit` 检查。<br>2. **输入合法性**：旧实现已实现 `ParseError::BufferOverflow`、`Utf8Error` 等防护，外部 crate 同样提供相同错误类型，确保不会因缓冲区溢出导致 DoS。<br>3. **供应链风险**：使用公开 crate 会把代码审计责任部分转移给社区，建议在内部保留对关键函数（如 `detect_and_parse_reasoning`）的单元测试，以捕获潜在回归。 |
| **可维护性** | - **代码量大幅下降**（删除约 3 KB Rust 代码），降低了维护成本。<br>- **统一化**：所有模型的解析规则统一在一个 crate 中，新增模型只需要在 `reasoning-parser` 侧提交 PR，gateway 本身无需改动。<br>- **测试负担转移**：原有 700 行单元测试随代码一起删除，后续需要在 gateway 项目层补充对 `ParserFactory` 基本行为的回归测试。 |
| **兼容性** | 通过 `pub use reasoning_parser;` 仍保持原有的公共路径 (`sgl_model_gateway::reasoning_parser::*`) 不变，外部调用者无需修改 import。若外部 crate 改名或模块结构变化，需要同步更新 `pub use`。 |

---

**⚠️ 潜在风险**  

1. **依赖版本突变**：`reasoning-parser` 若在 2.0 版本中删除或更改关键 trait（`ReasoningParser`）或工厂方法，gateway 将编译失败。  
2. **行为差异**：内部实现与外部 crate 在边界情况（例如极端缓存溢出、部分 token 拼接、unicode 兼容）可能存在细微差异，未同步的单元测试可能导致生产环境异常。  
3. **二进制膨胀**：新增 `regex`、`memchr`、`url` 等库，可能在资源受限的部署环境（如 edge 推理节点）引入额外的内存占用。  
4. **许可证兼容**：`reasoning-parser` 的许可证（MIT/Apache‑2.0）需与项目整体许可证兼容，确保合法分发。  
5. **CI/CD 失效**：若项目的 CI 流程依赖内部 parser 的代码覆盖率指标，删除后会导致统计失真。  

---

**💡 关注建议**  

1. **版本锁定**  
   - 在 `Cargo.toml` 使用 `reasoning-parser = "=1.0.0"` 或 `~1.0`，并在 `Cargo.lock` 中锁定。定期运行 `cargo update -p reasoning-parser` 并评估变更日志。  

2. **补充兼容性测试**  
   - 在 `sgl-model-gateway` 中新增一套 **黑盒测试**：使用 `ParserFactory::new()`，对每个已知模型（deepseek‑r1、qwen3、kimi、glm45、step3、minimax）执行一次完整的 `detect_and_parse_reasoning` 与流式增量解析，确保返回的 `ParserResult` 与历史实现保持一致。  

3. **监控与熔断**  
   - 在解析入口（如 `service_discovery` 或 `protocols`）加入异常计数与阈值报警，若 `ParseError::BufferOverflow` 或 `ParseError::Utf8Error` 频率异常升高，触发熔断或降级（直接返回原文本）。  

4. **安全审计**  
   - 将 `cargo audit`、`cargo deny` 纳入 CI，自动检测 `reasoning-parser` 及其传递依赖的安全漏洞。  

5. **文档更新**  
   - 在项目 README 或开发者手册中注明 **Reasoning Parser** 现在来源于 `reasoning-parser` crate，提供对应的文档链接、版本号及常见配置示例。  

6. **回滚预案**  
   - 保持本地分支（例如 `feature/keep-internal-reasoning-parser`）以便在外部 crate 出现重大回退时，可快速切回内部实现并重新发布。  

7. **二进制体积监控**  
   - 使用 `cargo bloat` 或 `size` 命令监控因新依赖导致的体积增长，必要时在 `reasoning-parser` 上打开 `default-features = false`，仅启用必要的特性（如 `regex`）以减小体积。  

---

**总结**  
本次改动通过引入成熟的 `reasoning-parser` crate，实现了 **职责分离、代码量削减**，对整体架构是一次积极的精简。只要严格管理依赖版本、补齐兼容性测试并做好安全审计，风险可控，长期维护收益

---

#### 🟡 中重要度变更 (8)

### update to use official openai protocol crate (#17710)
**SHA**: `8db2802` | 🔗 [查看提交](https://github.com/sgl-project/sglang/commit/8db2802b2da06f9d4c4ad8db2fb9ec3c06e5d156)

**🎯 变更类型**：重构 / 功能增强  
**⚡ 重要程度**：🟡 中  

**📋 变更摘要**  
1. 在 `sgl-model-gateway/Cargo.toml` 中加入官方 `openai-protocol = "1.0.0"`（开启 `axum` feature），并在根 `lib.rs` 中把原项目自定义的 `protocols` 模块替换为该 crate 的公开接口。  
2. 删除 `JobStatus` 的手工构造函数（`pending/processing/failed`），以及 `FlushCacheResult`、`WorkerLoadsResult` 的 `IntoResponse` 实现，改为依赖 `openai-protocol` 提供的统一响应结构。  
3. 相应地精简 `worker_manager.rs` 的导入，去掉 `serde_json::json!` 宏的使用。  

**🎯 影响范围**  
- `sgl-model-gateway/src/core/job_queue.rs`（JobStatus 构造被移除）  
- `sgl-model-gateway/src/core/worker_manager.rs`（所有自定义 `IntoResponse` 实现被删）  
- `sgl-model-gateway/src/lib.rs`（重新导出 `openai_protocol`）  
- Cargo 依赖层面：新增 `openai-protocol`、可能影响编译与运行时行为。  

**💡 关注建议**  
1. **兼容性检查**：确认项目其他位置（如路由、测试）是否仍依赖被删除的 `JobStatus::*` 方法或自定义响应结构，如有需迁移到 `openai-protocol` 的对应类型或自行实现包装。  
2. **功能验证**：跑完整的单元/集成测试，重点验证 **flush cache**、**worker loads** 接口的返回格式是否仍符合前端/第三方调用约定。  
3. **特性开启**：确保 `openai-protocol` 在 `Cargo.toml` 中启用了 `axum` feature，否则 `IntoResponse` 实现会缺失。  
4. **文档更新**：更新 README 或 API 文档，说明现在使用官方 OpenAI 协议标准，原有自定义字段可能已被统一或删除。  
5. **回退路径**：若出现不兼容问题，可暂时保留旧实现（通过 feature flag）并在后续版本统一迁移。  

总体来看，此次改动提升了协议的一致性和可维护性，但需要在项目内部彻底替换旧的手写响应逻辑，防止运行时 500 错误或类型冲突。

---

### [Refactor] Use is_in_ci() utility in JIT kernel benchmarks (#17118)
**SHA**: `fb61164` | 🔗 [查看提交](https://github.com/sgl-project/sglang/commit/fb61164f278cb3b10bd4adf4c374917aab94dcf3)

**🎯 变更类型**：重构  
**⚡ 重要程度**：🟡 中  
**📋 变更摘要**：将 JIT kernel 基准测试脚本中判断 CI 环境的散乱实现统一为 `sglang.jit_kernel.benchmark.utils.is_in_ci()`，去除直接读取 `os.getenv` 的代码。  
**🎯 影响范围**：  
- `python/sglang/jit_kernel/benchmark/bench_per_tensor_quant_fp8.py`  
- `python/sglang/jit_kernel/benchmark/bench_qknorm.py`  
- `python/sglang/jit_kernel/benchmark/bench_rmsnorm.py`  
- 新增/引用的 `sglang/jit_kernel/benchmark/utils.py`（如果尚未存在）  

**💡 关注建议**  

1. **确保 `is_in_ci` 实现可靠**：检查 `sglang/jit_kernel/benchmark/utils.py` 是否已覆盖原先的两种环境变量（`CI`、`GITHUB_ACTIONS`），并兼容自定义 CI 标志，防止出现误判导致基准测试在本地异常跳过或在 CI 中误执行。  
2. **保持向后兼容**：若外部脚本仍直接依赖 `os.getenv` 判断 CI，建议在 `utils.is_in_ci` 中保留相同的返回逻辑，或在文档中注明推荐使用该函数。  
3. **测试覆盖**：添加单元测试验证 `is_in_ci` 在不同环境变量组合下的返回值，并确认基准脚本在 CI 与本地运行时行为一致。  
4. **导入路径检查**：确认 `sglang.jit_kernel.benchmark.utils` 已加入 `__init__.py`，并在发布的 wheel 中包含该模块，防止 import 错误。  
5. **代码整洁**：移除已废弃的 `import os`（已在每个文件中删除），确保 `flake8`/`pylint` 报告不再出现未使用的导入。  

总体来说，此次改动属于轻量级重构，提升了代码可维护性和统一性，只要 `is_in_ci` 实现完整并加入相应测试，即可安全合并。

---

### [Refactore] [CI] Remove redundant CI test runs step 2 (#17584)
**SHA**: `d1042e0` | 🔗 [查看提交](https://github.com/sgl-project/sglang/commit/d1042e0d62d26de95ccfb7ba33d54a28f8452fb0)

**🛠️ 变更类型**：重构 / CI 改进  
**⚡ 重要程度**：🟡 中  

**🔎 变更概览**  
1️⃣ 将所有 CI 相关脚本统一搬移到 `scripts/ci/<backend>/`（`cuda、amd、npu`）以及公共工具 `scripts/ci/utils/` 中。  
2️⃣ 相应地，CI workflow（`.github/workflows/*.yml`）全部改为调用新路径的脚本；同时把原来的 `ci_coverage_report.py`、`ci_install_dependency.sh`、`ci_install_gateway_dependencies.sh`、`ci_install_deepep.sh` 等文件迁入 `utils/` 或 `cuda/` 子目录。  
3️⃣ 更新了部分脚本内部的相对路径（如 `killall_sglang.sh`、`prevalidate_cached_models.py`、`cleanup_hf_cache.py` 等），并修正了 import 路径以适配新的目录层级。  
4️⃣ 对 `release/utils.py` 中的路径常量做了同样的上移处理。  

**📦 影响范围**  
- **CI 工作流**：`ci-coverage-overview.yml、execute-notebook.yml、nightly-test‑*、pr-*-test.yml` 等 30+ workflow。  
- **脚本层级**：`scripts/ci/amd/*、scripts/ci/cuda/*、scripts/ci/npu/*、scripts/ci/utils/*`。  
- **内部调用**：`scripts/ci/ci_install_dependency.sh`、`scripts/ci/ci_coverage_report.py`、`scripts/ci/slash_command_handler.py` 等被多处引用，均已改为新路径。  
- **文档/发布**：`release-docs.yml`、`scripts/release/utils.py` 受路径改动影响。  

**💡 关注建议**  

| 建议 | 说明 |
|------|------|
| **CI 本地验证** | 在本地克隆仓库后，使用 `act` 或 Docker 手动跑一次关键 workflow（如 `nightly-test‑amd.yml`）确保所有脚本路径均已更新，防止遗漏导致 CI 失效。 |
| **搜索残余路径** | 用全局搜索 `scripts/ci/ci_`、`scripts/ci/amd_ci_` 等关键字，确认没有遗漏的旧路径引用（包括 README、脚本注释、第三方 CI 配置）。 |
| **文档同步** | 更新项目文档或贡献指南中关于 CI 脚本位置的说明，避免新贡献者仍查找旧路径。 |
| **兼容性包装** | 若社区中仍有自定义 CI 使用旧路径，可考虑在根目录添加轻量的兼容 shim（如 `scripts/ci/ci_install_dependency.sh` 简单转发到 `scripts/ci/cuda/ci_install_dependency.sh`），降低升级破坏性。 |
| **路径硬编码审查** | 检查所有 Python 脚本中 `sys.path.insert` 的相对路径是否仍然正确，尤其是 `ci_coverage_report.py`、`cleanup_hf_cache.py`、`prevalidate_cached_models.py`，确保 `REPO_ROOT` 计算逻辑与新目录结构匹配。 |
| **单元测试覆盖** | 为 `scripts/ci/utils/*` 中的工具函数（如 `runner_utilization_report.py`）补充少量单元测试，防止未来改动引入隐蔽错误。 |
| **CI 运行时环境** | 确认 Docker 镜像中已复制新的 `scripts/ci/*` 目录，否则容器启动后仍会报 “file not found”。必要时在 `Dockerfile` 中更新 `COPY` 指令。 |

**总结**  
本次提交的核心是将 CI 脚本按硬件后端进行模块化划分，提升可维护性和可读性。只要所有 workflow 与脚本内部的路径均已同步，新结构将使后续新增后端（如新芯片）更易扩展。但因为路径变动涉及大量 workflow，务必在合并前完成完整的 CI 预跑和全仓搜索，防止遗漏导致 CI 失效或文档指引错误。保持 `scripts/ci` 目录的统一入口（例如提供旧路径的软链接）可以进一步降低迁移风险。祝调试顺利！

---

### Support PD disaggregation with different TP/DP size for Qwen3-Next (#16056)
**SHA**: `9bd92ba` | 🔗 [查看提交](https://github.com/sgl-project/sglang/commit/9bd92ba0f6e8040c2f9fb211a50c5094d4cb5d53)

**🎯 变更类型**：功能增强（支持 PD Disaggregation 在不同 TP/DP 大小下的 Qwen3‑Next Mamba 状态切片）  

**⚡ 重要程度**：🟡 中  

**📋 变更摘要**  
1. 在 `KVArgs` 中新增 `state_dim_per_tensor`，用于记录每个 Mamba 状态张量在 TP 维度上的切分大小。  
2. 在预填（prefill）和解码（decode）初始化 KV‑manager 时，将该信息从 `HybridLinearKVPool`（Mamba）中读取并写入 `kv_args`。  
3. 在 Mooncake 通信层 (`conn.py`) 扩展注册信息结构，携带状态切片尺寸并在 ZMQ 消息中进行序列化/反序列化。  
4. 实现 `_send_mamba_state_slice`，在 `attn_tp_size` 与目标 rank 的 `dst_attn_tp_size` 不同的情况下完成跨 TP 切片的状态转移逻辑（包括维度、偏移、字节数计算）。  
5. 为 `MemoryPool` 增加 `get_state_dim_per_tensor`，统一获取 Mamba 状态的切片维度。  
6. 新增单元测试 `TestDisaggregationHybridAttentionMambaDPDecode`，覆盖 prefill‑tp=2 → decode‑tp=2/dp=2 场景并验证 GSM8K 准确率。  

**🎯 影响范围**  
- `python/sglang/srt/disaggregation/**`（KV 参数、Mooncake 连接、prefill/decode 协议）  
- `python/sglang/srt/mem_cache/memory_pool.py`（状态维度获取）  
- 相关的 hybrid KV‑pool 实现 (`HybridLinearKVPool`)  
- 单元测试套件 `test/srt/test_disaggregation_hybrid_attention.py`  

**💡 关注建议**  

1. **协议向后兼容**：新增的 ZMQ 字段在旧版服务端/客户端上会被忽略吗？建议在 `KVArgsRegisterInfo.from_zmq` 中加入长度检查并在缺失字段时回退到空列表，防止解码错误。  

2. **维度校验**：在 `_send_mamba_state_slice` 中对 `src_bytes_per_dim`、`dst_bytes_per_dim` 做整数除检查，防止非整除导致的偏移错误。可在调试模式下抛出明确异常。  

3. **性能评估**：切片转移会产生额外的 memcpy 与跨节点通信，建议在 CI 中加入基准测试，记录不同 TP/DP 配置下的吞吐与延迟，确保“性能可能受影响”不成为回归。  

4. **文档同步**：更新 README / API 文档，说明在使用 `--enable-dp-attention` 时必须开启 `state_dim_per_tensor` 并确保所有节点使用相同的 Mamba 配置（层数、conv_dim、head_num 等）。  

5. **异常信息**：对于非 MLA 模型仍不支持不同 TP 的情况，当前抛出 `RuntimeError`，建议使用更易定位的错误码或包装在专用异常类中，以便调用方捕获并给出可执行的降级方案。  

6. **测试覆盖**：当前新增测试覆盖了 `tp=2 → dp=2` 场景，建议再补充 `tp=4 → tp=2`、`tp=1 → dp=4` 等组合，确保切片逻辑在所有方向上均可工作。  

总体而言，改动为 Mamba‑Hybrid 模型在 PD Disaggregation 环境下提供了必要的切片支持，代码结构清晰，风险主要在协议兼容与字节对齐上。按上述建议完善后即可合并。

---

### Fix swa memory pool size with spec (#17630)
**SHA**: `30ece5e` | 🔗 [查看提交](https://github.com/sgl-project/sglang/commit/30ece5e1d6caba2af61e23878ed7ffd4afce9c9c)

**🎯 变更类型**：Bug 修复 / 功能增强  
**⚡ 重要程度**：🟡 中  

**📋 变更摘要**  
1. 为 MiMoV2MTP 等 Hybrid‑SWA 模型在 `model_config` 中补全 `swa_attention_layer_ids` 与 `full_attention_layer_ids` 的返回值。  
2. 重构 `ModelRunner.set_num_tokens_hybrid_swa`，新增对“全 SWA”情形的专门处理、页面对齐函数、分母合法性校验，并统一在所有层都有 SWA 时直接使用 `max_total_num_tokens`。  
3. 调整 `init_memory_pool` 中对 Speculative（draft）工作者的缓存大小设置逻辑，去除对 Hybrid‑SWA 的强制禁用，并在非 draft worker 时同步 `draft_runner_cache_size` 与 `max_num_reqs`。  
4. 在 `server_args` 中删除对 speculative decoding 时自动关闭 Hybrid‑SWA 的旧实现。  

**🎯 影响范围**  
- `python/sglang/srt/configs/model_config.py`（模型配置）  
- `python/sglang/srt/model_executor/model_runner_kv_cache_mixin.py`（KV‑cache 分配与页面对齐）  
- `python/sglang/srt/server_args.py`（启动参数与模型特化处理）  

**💡 关注建议**  

1. **页面对齐的边界**：`align_page_size` 使用 `x // page_size * page_size`，若 `x < page_size` 会得到 `0`，进而导致 `full_max_total_num_tokens`/`swa_max_total_num_tokens` 为 0 并触发后续 `RuntimeError`。建议在对齐前加上 `max(x, page_size)` 或在返回前检查是否为 0。  
2. **分母合法性**：新增 `assert denominator > 0` 防止除零，但在 `swa_full_tokens_ratio` 为 0 的情况下仍会得到 `full_max_total_num_tokens = total_tokens / full_layers_num`，这会把所有内存分配给 full‑attention 层，需确认业务是否允许。  
3. **全 SWA 情形**：当 `full_layers_num == 0` 时直接 `self.max_total_num_tokens = self.swa_max_total_num_tokens`，但后续仍会执行 `logger.info` 之后的 `return`，确保后面的 `self.max_total_num_tokens = self.full_max_total_num_tokens` 不会被错误触发。  
4. **Speculative 与 Hybrid‑SWA 的交互**：现在 draft worker 会使用 `draft_runner_cache_size`（已根据 SWA 调整）进行 KV‑cache 分配，非 draft worker 会把最终 `max_total_num_tokens` 写回 `server_args`。请在多卡/DP 场景下验证 `max_num_reqs` 的同步逻辑是否仍符合原有的 `max_running_requests // dp_size` 计算。  
5. **回归测试**：  
   - 运行包含 MiMoV2MTP、GPT‑OSS（使用 TRT‑LLM MHA）以及普通全注意力模型的全套单元/集成测试。  
   - 特别检查在 `--speculative-algorithm=speculative` + `--use-hybrid-swa` 组合下，draft worker 是否出现 OOB 错误。  
   - 验证 `--mem-fraction-static` 较小值时不会因对齐导致 “Not enough memory” 异常。  

总体来看，本次改动解决了 Hybrid‑SWA 在 Speculative 模式下内存池大小计算错误的问题，提升了模型部署的可靠性。只要在上述边界条件（page_size、ratio 为 0）以及多卡同步上做好回归验证，即可平稳上线。

---

### Add PyTorch .bin file validation to CI weight validation (#17533)
**SHA**: `9121f22` | 🔗 [查看提交](https://github.com/sgl-project/sglang/commit/9121f2265644af2fd9803fc491206684956c8168)

**🎯 变更类型**：功能增强（CI 权重文件完整性校验）  
**⚡ 重要程度**：🟡 中  
**📋 变更摘要**：在 `ci_weight_validation.py` 中新增对 PyTorch `.bin` 权重文件的完整性校验。通过 `torch.load(..., weights_only=True, mmap=False)` 读取文件，以捕获下载截断、文件损坏等异常，并在 CI 中对单文件、分片和缓存目录进行统一清理和重新下载。  

**🎯 影响范围**  
- `python/sglang/srt/model_loader/ci_weight_validation.py`（核心校验逻辑）  
- 依赖 `torch` 库的 CI 环境（需要 PyTorch ≥ 2.0 支持 `weights_only` 参数）  
- 与模型加载、缓存管理相关的 CI 流程（`ci_validate_and_cleanup_local_snapshot`、`_validate_weights_after_download`、`ci_validate_and_clean_hf_cache`）  

**💡 关注建议**  

1. **兼容性**：`torch.load(..., weights_only=True)` 仅在 PyTorch 2.0+ 可用。若 CI 或用户机器使用旧版 PyTorch，会抛出 `TypeError`。建议在函数开头做版本检测或回退到传统 `torch.load(..., map_location='cpu')`，并在文档中注明最低 PyTorch 版本要求。  

2. **性能**：对大模型（数十 GB）执行完整读取会显著增加 CI 时延和资源占用。可以考虑在非 CI 场景加入 `mmap=True`（只映射），或提供 `--quick-check` 参数，以在本地调试时跳过完整读取。  

3. **异常与日志**：当前捕获所有异常并返回 `False`，这会把合法但不被 `torch.load` 识别的文件（如自定义加载器）误判为损坏。建议细化异常处理，仅对 `RuntimeError`、`OSError` 等读取错误记录为 corruption，其余异常重新抛出或记录为未知错误。  

4. **依赖注入**：函数内部直接 `import torch`，如果在没有安装 torch 的环境运行（例如仅做语法检查的 lint），会导致 ImportError。可改为在模块顶部统一导入，或在 CI 脚本中确保已安装对应依赖。  

5. **单文件列表**：在 `_validate_sharded_model` 中仅处理后缀为 `bin` 的分片文件。若未来出现 `.pt`、`.ckpt` 等其他二进制格式，需同步添加对应分支。  

6. **测试覆盖**：建议补充单元测试：① 正常、完整的 `.bin` 能被通过；② 截断或手动破坏的文件能够触发 `False` 并产生日志；③ 低版本 PyTorch 环境下函数的回退行为。  

总体来看，此次改动提升了模型下载的鲁棒性，避免因隐藏的二进制损坏导致后续运行异常。但需注意 PyTorch 版本兼容、读取开销以及异常分类，以免在生产或 CI 环境产生意外的构建失败。

---

### [diffusion]: Fix ZImage SP sharding for caption and latent (#17301)
**SHA**: `59f027a` | 🔗 [查看提交](https://github.com/sgl-project/sglang/commit/59f027a8c834ab358580b75958d01d916a7df678)

**🎯 变更类型**：功能增强（为 ZImage 流水线加入空间‑分片（SP）以及 caption 分片）  
**⚡ 重要程度**：🟡 中——涉及分布式推理路径，若使用不当会导致结果不一致或崩溃，但对单卡运行影响不大。  

**📋 变更摘要**  
1. 在 `zimage.py` 中新增 `SEQ_LEN_MULTIPLE / PATCH_SIZE / F_PATCH_SIZE` 参数并实现 `_ceil_to_multiple`、`_build_zimage_sp_plan`、`_shard_cap` 等工具函数。  
2. 基于 SP 并行度 (`get_sp_world_size`, `get_sp_parallel_rank`) 动态决定在宽/高维度上是否交换、如何对 latent、caption 做切分、填充及局部拼接。  
3. 重写 `shard_latents_for_sp`、`gather_latents_for_sp`、`post_denoising_loop`，以及 `create_rotary_embeds` 的分片路径，使得在多 GPU（或多节点）上只处理局部 token，最后通过 `sequence_model_parallel_all_gather` 统一。  

**🎯 影响范围**  
- `sglang.multimodal_gen.configs.pipeline_configs.zimage.ZImagePipelineConfig`（核心配置类）  
- `sglang.multimodal_gen.runtime.distributed.*`（通信与并行状态）  
- 依赖该配置的所有 ZImage 生成路径（包括 `zimage-turbo`、`zimage-base` 等模型）。  

**💡 关注建议**  
1. **分布式环境验证**：在 2、4、8 张卡的 SP 环境下跑完整的文本‑图像生成脚本，比对与单卡 `sp_size=1` 的输出（数值、图片质量）是否保持一致。  
2. **边界条件测试**：使用奇数宽高、极小 batch、以及 `raw_latent_shape` 已经被填充的情况，确保 `swap_hw`、`pad_lat`、`img_pad_len` 等分支不会出现负维或越界。  
3. **兼容性检查**：确认旧版模型在不启用 SP（环境变量/启动参数保持默认）时仍走旧的 `PipelineConfig` 分支，不会因为新增字段导致序列化/加载错误。  
4. **性能基准**：记录分片前后每一步（sharding、all‑gather、post‑process）的 GPU 时间，确保分片带来的通信开销低于空间划分带来的显存/算力收益。  
5. **代码审查**：`_ceil_to_multiple` 对 `m<=0` 的容错处理合理；但在 `shard_latents_for_sp` 中对 `latents.dim()!=5` 的直接返回可能在未来加入新的维度时需要同步更新。  

整体来看，本次改动为 ZImage 引入了可伸缩的空间‑并行方案，若配合正确的启动参数即可显著降低单卡显存占用；同时也引入了若干形状填充和坐标计算的细节，建议在多卡 CI 中加入回归测试以防止隐藏的维度错位。

---

### fix: Refactor register_image_processor to use kwarg instead of positional arg (#17685)
**SHA**: `37c04c2` | 🔗 [查看提交](https://github.com/sgl-project/sglang/commit/37c04c2245d0f9011ee8c4035eee84c6c6716bae)

**🎯 变更类型**：Bug 修复  
**⚡ 重要程度**：🟡 中  

**📋 变更摘要**  
将 `register_image_processor` 中对 `AutoImageProcessor.register` 的调用方式由位置参数改为关键字参数 `slow_image_processor_class`，避免了在新版 HuggingFace 🤗 Transformers 中因签名变更导致的 TypeError。代码更显式，兼容性更好。

**🎯 影响范围**  
- `python/sglang/srt/configs/utils.py`（核心注册工具）  
- 任何依赖 `register_image_processor` 的自定义镜像处理器插件或加载逻辑。  

**💡 关注建议**  
1. **回归测试**：执行完整的单元/集成测试，确保自定义图片处理器仍能成功注册并在推理链路中被调用。  
2. **兼容性检查**：若项目中有手动调用 `AutoImageProcessor.register`（使用旧的 positional 参数），请同步改为关键字参数或直接使用本函数包装。  
3. **文档同步**：更新相关文档或示例代码，注明 `register_image_processor` 采用关键字参数，以防误用。  
4. **依赖锁定**：确认项目的 `transformers` 版本在 4.x 以上，避免因 API 回退导致遗漏。  

此改动仅影响注册机制，功能行为保持不变，风险低，但建议在升级 HuggingFace 依赖后跑一次完整的模型加载链路验证。

---

#### 🟢 低重要度变更 (7)

### [diffusion] refactor: remove useless lazy-import cache-dit codes (#17659)
**SHA**: `b105dad` | 🔗 [查看提交](https://github.com/sgl-project/sglang/commit/b105dad5dac56d149febea9a23d57b07f56b666a)

**🎯 变更类型**：代码重构  
**⚡ 重要程度**：🟢低  
**📋 摘要**：删除了原先用于 `cache‑dit` 的惰性导入实现，改为在 `__init__.py` 中直接导入相关符号，并相应地在 `teacache.py` 中加入对 `DiTConfig` 的显式引用。这样简化了缓存模块的导入逻辑，去除了不再使用的代码。

---

### revert row from https://github.com/sgl-project/sglang/pull/17584/ (#17701)
**SHA**: `64d8099` | 🔗 [查看提交](https://github.com/sgl-project/sglang/commit/64d809937ac046f216cf5e3cde330f5220a42b5e)

**🎯 变更类型**：代码重构  
**⚡ 重要程度**：🟢低  
**📋 摘要**：将 `scripts/release/utils.py` 中 `get_repo_root` 的路径返回层级从四级目录上移至三级，修正了仓库根路径的定位。

---

### [DeepSeek-V3.2] Fix TRT-LLM NSA in target_verify/draft_extend (#17662)
**SHA**: `1674b9e` | 🔗 [查看提交](https://github.com/sgl-project/sglang/commit/1674b9ef4494ca4acbb0eeda4119aa02aac09b7a)

**🎯 变更类型**：代码重构  
**⚡ 重要程度**：🟢低  
**📋 摘要**：在 `nsa_backend.py` 中新增 TRT‑LLM NSA 实现，仅支持 `target_verify`/`draft_extend` 场景，加入 `seq_lens` 参数传递并添加相应断言。

---

### Fix slash command handler trigger condition by trimming the comments (#17691)
**SHA**: `b829b79` | 🔗 [查看提交](https://github.com/sgl-project/sglang/commit/b829b797ef91f55d2a990df0746892eafae68f0b)

**🎯 变更类型**：配置调整  
**⚡ 重要程度**：🟢低  
**📋 摘要**：修正 slash‑command‑handler 工作流触发条件，将原先的 `startsWith` 检查改为 `contains`，并说明使用原因，以便处理带有前导空白或换行的评论指令。

---

### Temporarily disable lora overlap loading test due to flakiness (#17683)
**SHA**: `69a7a70` | 🔗 [查看提交](https://github.com/sgl-project/sglang/commit/69a7a70e474755ba4b07a2be31c1d42a76b20e47)

**🎯 变更类型**：测试修改  
**⚡ 重要程度**：🟢 低  
**📋 摘要**：在 `test_lora_overlap_loading.py` 中通过 `register_cuda_ci` 参数 `disabled` 暂时关闭了因输出不一致而不稳定的 LoRA 重叠加载测试。

---

### Fix NSA indexer test and move it to pre commit test (#17682)
**SHA**: `137eb5b` | 🔗 [查看提交](https://github.com/sgl-project/sglang/commit/137eb5b95cb18640dd223845ff9e70d81f437997)

**🎯 变更类型**：测试修改  
**⚡ 重要程度**：🟢低  
**📋 摘要**：将 NSA 索引器测试从 nightly 移至 stage‑b 小规模 GPU 套件，新增 `qk_nope_head_dim` 配置项并在模型初始化中传递。

---

### Fix test timeout issue in pr-test (#17681)
**SHA**: `8656a14` | 🔗 [查看提交](https://github.com/sgl-project/sglang/commit/8656a146a606d4c27a5f5bafcdddbbe82949ed1a)

**🎯 变更类型**：配置调整  
**⚡ 重要程度**：🟢 低  
**📋 摘要**：将 `.github/workflows/pr-test.yml` 中所有 CI 作业的 `timeout-minutes` 从 60 分钟提升至 240 分钟，以解决测试超时问题。

---

