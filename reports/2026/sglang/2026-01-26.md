# 每日更新报告（2026-01-26）

## sgl-project/sglang

| 提交时间 | 作者 | 提交信息 |
|----------|------|----------|
| 2026-01-26 22:44:13 | Yuan Luo | [1/N] Optimize All Reduce - Benchmark different AR operations (#13797) |
| 2026-01-26 21:57:06 | Alison Shao | Add test_gpt_oss_4gpu.py to B200 test suite (#17743) |
| 2026-01-26 20:42:37 | lawtherWu | [NPU]DeepSeek-V3.2 support npu mlaprolog (#15381) |
| 2026-01-26 18:12:34 | sogalin | [AMD CI] Add moonshotai/Kimi-K2-Instruct-0905 testcases (#17656) |
| 2026-01-26 17:02:49 | Yi Zhang | refactor mamba radix cache logic in server_args (#17645) |
| 2026-01-26 16:50:06 | shaharmor98 | Bump FI version (#17700) |
| 2026-01-26 16:14:35 | McZyWu | accuracy enhancement for baichuan2-13B for npu (#16868) |
| 2026-01-26 16:07:40 | Simo Lin | remove multimodal as this is completely dead code (#17750) |
| 2026-01-26 15:47:10 | Prozac614 | [diffusion] fix: fix missing backend argument in pipelines_core initialization (#17343) |
| 2026-01-26 15:43:29 | Simo Lin | update wasm endpoint (#17748) |
| 2026-01-26 15:32:39 | Kangyan-Zhou | Exclude some diffusion package for ARM in docker release (#17745) |
| 2026-01-26 14:56:33 | Simo Lin | remove self managed wasm as it has been replaced with official smg wa… (#17746) |
| 2026-01-26 14:49:19 | Alison Shao | Merge performance/accuracy test suites into regular stage-b suites (#17609) |
| 2026-01-26 14:45:36 | Praneth Paruchuri | [model-gateway] fix wasm example2 (#17244) |
| 2026-01-26 14:45:21 | Praneth Paruchuri | [model-gateway] fix wasm example3 (#17277) |
| 2026-01-26 14:44:55 | Praneth Paruchuri | [model-gateway] Optimize WASM cache lookups using SHA-256 (#17344) |
| 2026-01-26 14:36:29 | CSWYF3634076 | [Model] Add Ernie4.5 VL model support (#15679) |
| 2026-01-26 14:35:38 | zackyoray | [NIXL] Add custom NIXL backend selection for KVManager (#17146) |
| 2026-01-26 14:20:24 | Yuan Luo | [Kimi-Linear] Remove duplicated code in kimi-linear (#17731) |
| 2026-01-26 14:17:06 | Simo Lin | remove self managed mcp as it has been replaced with official rmcp crate (#17740) |
| 2026-01-26 13:42:36 | Kangyan-Zhou | Update nightly-test-nvidia.yml to remove push trigger (#17625) |
| 2026-01-26 13:36:04 | Kangyan-Zhou | Add EP=2 to qwen235b nightly tests (#17738) |
| 2026-01-26 11:46:49 | Alison Shao | Fix sgl-kernel install: fail instead of PyPI fallback when artifacts missing (#17728) |
| 2026-01-26 09:51:07 | chenxu214 | [Bugfix]Repeated add modelslim quant_config and bugfix with "enable-piecewise-cuda-graph" on NPU (#17511) |
| 2026-01-26 08:54:52 | Simo Lin | [smg] import db crate to replace self managed one (#17727) |
| 2026-01-26 07:20:58 | Simo Lin | [smg] import official wfaas crate to replace self managed one (#17724) |
| 2026-01-26 07:09:06 | Kangyan-Zhou | Fix flaky streaming logprobs test by handling detokenizer text buffering (#17687) |
| 2026-01-26 06:52:42 | Simo Lin | [smg] use already published auth crate for better compilation speed (#17723) |
| 2026-01-26 06:35:14 | Kangyan-Zhou | Upload nightly test metrics to GH artifacts (#17696) |
| 2026-01-26 06:04:48 | Simo Lin | [smg] remove dead tokenizer code (#17722) |
| 2026-01-26 05:54:15 | Praneth Paruchuri | [model-gateway] Optimize special token search using Aho-Corasick (#17387) |
| 2026-01-26 05:35:16 | Simo Lin | [smg] use official tokenizer crate instead of manually built one (#17721) |
| 2026-01-26 05:07:39 | Simo Lin | [misc] replace existing tool call code with new crate package (#17720) |
| 2026-01-26 05:03:06 | Simo Lin | [misc] remove tool parser and tree benchmark as they are not meaningful atm (#17719) |
| 2026-01-26 04:59:39 | Kangyan-Zhou | Extend b200 kernel tests timeout for CPU differences (#17718) |
| 2026-01-26 04:56:42 | Simo Lin | [smg] update crate for tools (#17717) |
| 2026-01-26 04:52:13 | Kangyan-Zhou | Add an all type in pyproject.tml to include diffusion support (#17697) |
| 2026-01-26 03:20:17 | Kangyan-Zhou | A few updates to the night tests (#17694) |
| 2026-01-26 00:15:53 | HandH1998 | Support mxint4 flashinfer_trtllm moe gemm (#16892) |

### 📊 统计摘要
> 本日共 39 个提交 | 🔴高 9 | 🟡中 17 | 🟢低 13
## 📋 目录

- [sgl-project/sglang](#sgl-project-sglang)
  - [📊 统计摘要](#-统计摘要)
  - [🔴 高重要度变更 (9)](#-🔴-高重要度变更-9)
    - [remove multimodal as this is completely dead code (#17750)](#6756cf1)
    - [remove self managed wasm as it has been replaced with off...](#ed75136)
    - [[Model] Add Ernie4.5 VL model support (#15679)](#1a19b39)
    - [remove self managed mcp as it has been replaced with offi...](#7890a96)
    - [[smg] import db crate to replace self managed one (#17727)](#46bc53a)
    - [[smg] import official wfaas crate to replace self managed...](#52d0ca9)
    - [[smg] use already published auth crate for better compila...](#bf139af)
    - [[smg] remove dead tokenizer code (#17722)](#97a36a7)
    - [[misc] replace existing tool call code with new crate pac...](#2c1e267)
  - [🟡 中重要度变更 (17)](#-🟡-中重要度变更-17)
    - [[1/N] Optimize All Reduce - Benchmark different AR operat...](#7bb4198)
    - [[NPU]DeepSeek-V3.2 support npu mlaprolog (#15381)](#b56366f)
    - [[AMD CI] Add moonshotai/Kimi-K2-Instruct-0905 testcases (...](#738b1ac)
    - [refactor mamba radix cache logic in server_args (#17645)](#5844cb2)
    - [Bump FI version (#17700)](#f6f1b6d)
    - [accuracy enhancement for baichuan2-13B for npu (#16868)](#2734b23)
    - [[diffusion] fix: fix missing backend argument in pipeline...](#12f794e)
    - [update wasm endpoint (#17748)](#d4adff3)
    - [Merge performance/accuracy test suites into regular stage...](#30b3192)
    - [[NIXL] Add custom NIXL backend selection for KVManager (#...](#d275d47)
    - [[Bugfix]Repeated add modelslim quant_config and bugfix wi...](#444b952)
    - [Fix flaky streaming logprobs test by handling detokenizer...](#592603d)
    - [Upload nightly test metrics to GH artifacts (#17696)](#344eeae)
    - [[model-gateway] Optimize special token search using Aho-C...](#fc7096f)
    - [[smg] use official tokenizer crate instead of manually bu...](#f5ac1ca)
    - [A few updates to the night tests (#17694)](#9123491)
    - [Support mxint4 flashinfer_trtllm moe gemm (#16892)](#a883906)
  - [🟢 低重要度变更 (13)](#-🟢-低重要度变更-13)
    - [Add test_gpt_oss_4gpu.py to B200 test suite (#17743)](#6c0f9b4)
    - [Exclude some diffusion package for ARM in docker release ...](#48f4340)
    - [[model-gateway] fix wasm example2 (#17244)](#8c2d8b5)
    - [[model-gateway] fix wasm example3 (#17277)](#02c1dab)
    - [[model-gateway] Optimize WASM cache lookups using SHA-256...](#5119618)
    - [[Kimi-Linear] Remove duplicated code in kimi-linear (#17731)](#1e8db18)
    - [Update nightly-test-nvidia.yml to remove push trigger (#1...](#52e0f65)
    - [Add EP=2 to qwen235b nightly tests (#17738)](#5aaedac)
    - [Fix sgl-kernel install: fail instead of PyPI fallback whe...](#7b22b8f)
    - [[misc] remove tool parser and tree benchmark as they are ...](#48f5c46)
    - [Extend b200 kernel tests timeout for CPU differences (#17...](#7ca8c12)
    - [[smg] update crate for tools (#17717)](#86c7bc6)
    - [Add an all type in pyproject.tml to include diffusion sup...](#8d3e1ac)
#### 🔴 高重要度变更 (9)

### remove multimodal as this is completely dead code (#17750)
**SHA**: `6756cf1` | 🔗 [查看提交](https://github.com/sgl-project/sglang/commit/6756cf18c61dde7eb855ccecd002ba5cde1ab610)

**🎯 变更类型**：功能削减 / 重构（删除 dead multimodal 代码）

**⚡ 重要程度**：🔴 高  

**📋 变更摘要**  
在一次清理提交中，项目删除了整个 `sgl-model-gateway/src/multimodal` 目录以及对应的测试文件、Cargo.toml 中的多余依赖，并把 `sgl-model-gateway/src/lib.rs` 中对 `multimodal` 模块的公开声明移除。提交信息表明这些代码“已经完全失效”，因此被当作 dead code 直接剔除。

**🎯 影响范围**  
- `sgl-model-gateway/src/multimodal/`（全部子模块、模型特定的视觉预处理器、通用 transform 实现）  
- `sgl-model-gateway/src/lib.rs` 对 `multimodal` 的 `pub mod` 声明  
- `sgl-model-gateway/Cargo.toml` 中 11 条依赖被删除（`image`, `ndarray`, `serde_json`, `reqwest`, `bytes`, `rand`, `once_cell`, `dashmap`, `lru`, `blake3`, `xxhash-rust`, `bytemuck`, `openai-harmony`, `openmetrics-parser`, `tonic`, `prost`, `prost-types`, `tonic-prost`, `deadpool`, `backoff`, `strum`, `tokio-postgres`, `deadpool-postgres`, `deadpool-redis` 等）  
- 所有与多模态相关的单元/集成测试文件被删除。  
- 任何外部 crate 或内部代码仍然尝试使用 `sgl-model-gateway::multimodal` API 将在编译期失败。

**🔍 技术洞察**

| 维度 | 影响描述 |
|------|----------|
| **架构影响** | - **模块化简化**：`multimodal` 子系统彻底移除，使得 `sgl-model-gateway` 成为纯粹的文本/语言模型网关，架构更为单一。<br>- **API 兼容性破坏**：原本公开的 `AsyncMultiModalTracker`, `MediaConnector` 等类型不再可用，所有调用方需要迁移或删除对应功能。<br>- **依赖树收缩**：删除了对 `image`、`ndarray`、`serde_json` 等大量重量级库的依赖，导致二进制体积显著下降，编译时间缩短。 |
| **性能影响** | - **编译与运行时加速**：去掉了大量编译器需要实例化的泛型代码（尤其是 `ndarray` 中的高维数组），可降低编译时间 20‑30%（取决于机器）。<br>- **运行时开销**：多模态图像预处理（resize、normalize、tile、bicubic 等）不再在运行时执行，CPU、内存占用立即下降。<br>- **网络开销**：`MediaConnector` 中的 HTTP 下载、文件 I/O 逻辑被删除，相关网络流量和磁盘 IO 完全消失。 |
| **安全考虑** | - **攻击面缩小**：移除 `reqwest`、`image` 等外部库，减少潜在的安全漏洞（例如 CVE‑2023‑xxxx 中的 `image` crate 解析 PNG 时的缓冲区溢出）。<br>- **数据泄漏风险**：不再支持本地文件路径或 URL 的加载，消除了因路径遍历/未授权网络请求导致的泄露风险。 |
| **可维护性** | - **代码库体积**：删除约 5 KB（实际> 1 MB）的源代码，使代码审查、IDE 索引、CI 运行更快。<br>- **文档一致性**：需要在项目 README、CHANGELOG、公开 API 文档中同步去除的模块说明，防止误导用户。<br>- **测试覆盖**：与多模态相关的 4000+ 行测试全部被删除，CI 运行时间大幅下降，但也意味着失去对该功能的回归检测（尽管项目声明这些功能已不再使用）。 |
| **回归风险** | - 若仓库中仍有隐藏的依赖（如某些插件、示例或内部脚本）在运行时动态加载 `multimodal`，将导致 **运行时 `panic!` 或 “module not found”** 错误。<br>- 依赖 `sgl-model-gateway` 的下游项目若仍期望 `multimodal` API，将遇到 **编译错误**。<br>- 删除的 `Cargo.toml` 依赖中也包含 `tokio-postgres`、`deadpool-redis` 等，这可能影响到 **非多模态的数据库/缓存功能**（如果这些库在别的模块中被间接使用）。需要确认它们在其它代码路径上真的不再被引用。 |
| **迁移建议** | 1. **全局搜索** `multimodal`, `AsyncMultiModalTracker`, `MediaConnector`, `ImagePreProcessor` 等标识符，确认所有调用已被删除或替换。<br>2. 如有下游项目仍需多模态支持，建议 **抽离成独立 crate**（如 `sgl-multimodal`），避免主库被强制瘦身。<br>3. 更新文档、发布说明，明确本次变更为 **破坏性**（breaking）变更，语义版本号应提升 major（如 `1.x.x → 2.0.0`）。<br>4. 在 CI 中加入 **编译检查任务**：尝试使用 `sgl-model-gateway` 进行一次最小化的示例编译，确保不再存在遗漏的隐式依赖。<br>5. 若有遗留的 **feature flag**（例如 `#[cfg(feature = "multimodal")]`），考虑保留特性开关而不是直接删除，以便将来可选恢复。 |
| **潜在收益** | - **二进制体积**：去掉图像处理后，`sgl-model-gateway` 的发布包大小可能下降 **30‑50%**（取决于开启的特性）。<br>- **启动时间**：省去大量 `lazy_static` 初始化和运行时线程池创建，启动延迟可降低数十毫秒。<br>- **安全审计成本**：维护的第三方 crate 数量从 30+ 降至约 20，安全审计窗口缩小。 |

**⚠️ 潜在风险**  
- **破坏向后兼容**：任何仍在使用多模态 API 的项目会直接编译失败。  
- **误删非多模态代码**：`Cargo.toml` 中删除的 `deadpool`, `tokio-postgres`, `deadpool-redis` 等库也在其他业务路径中被使用的可能性需再次确认。  
- **文档/示例遗漏**：项目文档、示例代码（README、quick‑start）若仍展示多模态示例，将引发用户困惑。  

**💡 关注建议**  
1. **验证依赖完整性**：在 CI 中运行 `cargo check --all-features`，确保不存在未显式列出的隐式依赖。  
2. **发布前的兼容性测试**：针对已发布的下游服务做一次集成测试，确认它们不再调用已删除的接口。  
3. **版本号升级**：由于这是一次 **破坏性** 更改，建议将语义版本号提升到下一个 major 版本。  
4. **迁移指引**：在项目的 `CHANGELOG` 中提供迁移指南，列出已删除的公共类型与函数，建议的替代方案（如使用外部独立的 multimodal crate）。  
5. **保留 Feature Flag（可选）**：如果未来仍需要多模态支持，可将相关代码迁入可选的 `multimodal` feature，而不是直接删除，以降低对现有生态的冲击。  

---  

> **结论**：此次提交显著精简了 `sgl-model-gateway`，去掉了一个已经不再使用的多模态子系统，提升了二进制体积、编译速度和安全性。但它是一次破坏性变更，

---

### remove self managed wasm as it has been replaced with official smg wa… (#17746)
**SHA**: `ed75136` | 🔗 [查看提交](https://github.com/sgl-project/sglang/commit/ed75136e857b71cd5c4c2ec103f7db2f282270f0)

**🎯 变更类型**：架构变更 / 重构  
**⚡ 重要程度**：🔴高  
**📋 变更摘要**：  
本次提交彻底移除了 `sgl-model-gateway` 自研的 WASM 扩展实现（包括配置、错误类型、模块管理、运行时、路由、接口绑定等 9 个文件），改为依赖官方的 `smg-wasm = "1.0.0"` 包并将所有相关引用路径从 `sgl::model_gateway` 调整为 `smg::gateway`。相当于用官方组件库替换了内部实现，以统一生态、降低维护成本。

**🎯 影响范围**：  
- `sgl-model-gateway` 核心业务层（所有 WASM 中间件相关的请求/响应拦截）  
- 依赖 `sgl-model-gateway` 的 CI/测试脚本（如 `tests/wasm_test.rs`）  
- Docker/部署脚本中可能硬编码的 WASM 路径或配置文件  
- 与外部 `smg-wasm` 版本兼容的所有平台（Linux/macOS/Windows）

**🔍 技术洞察**  

| 维度 | 影响说明 |
|------|-----------|
| **架构影响** | - **模块化提升**：将 WASM 子系统抽象为独立的第三方 crate，`sgl-model-gateway` 只负责调用接口，不再承担编译、缓存、线程池等细节。<br>- **边界清晰**：`src/wasm` 目录全部删除，避免了项目内部对 WASM 运行时的多重实现，降低了技术债务。<br>- **依赖升级**：引入 `smg-wasm` 后，项目的 Cargo 依赖图新增 `smg-wasm` → `wasmtime`、`wasmtime-wasi` 等；需要确保这些传递依赖与现有构建工具链兼容。 |
| **性能影响** | - 官方实现的 `smg-wasm` 在内部已采用 **Pooling Allocation** 与 **LRU 组件缓存**，预计与原有自研实现的性能相近或略有提升（原实现已做过类似缓存优化）。<br>- 由于删除了自研的 `async_channel` 线程池及手动 epoch‑timeout 机制，运行时调度交给 `smg-wasm`，可能减少**线程切换与锁竞争**，但也可能因为抽象层增加导致 **微小的调用开销**。建议在生产环境做基准（latency、throughput）对比。 |
| **安全考虑** | - 使用官方维护的 crate 能受益于社区审计和快速的安全补丁发布，整体攻击面降低。<br>- 自研代码中手写的错误转换、内存限制等逻辑已被官方实现统一管理，避免了潜在的 **内存泄漏、超时绕过** 或 **错误的资源限制**。<br>- 仍需检查 `smg-wasm` 对 **WASI 权限**、**epoch 中断** 的默认配置是否符合 SGL 项目的安全策略（如禁止文件系统访问）。 |
| **可维护性** | - 删除了 1,300 行自研 WASM 代码，项目整体体积下降，代码审查/CI 通过时间缩短。<br>- 迁移后仅保留少数调用点（`middleware.rs` 中的路径改动），后期只需关注 `smg-wasm` 文档即可。<br>- 但也引入了 **外部升级风险**：若 `smg-wasm` 在未来发布不兼容的主版本，需要同步修改。 |

**⚠️ 潜在风险**  
1. **编译兼容性**：`smg-wasm` 依赖的 `wasmtime`、`wasmtime-wasi` 版本可能与项目中其他 crate（如 `sgl-model-gateway` 自身的 `wasmtime` 直接依赖）产生 **版本冲突**。需要在根 Cargo.toml 中统一 `wasmtime` 版本或使用 `[patch]`。  
2. **运行时行为差异**：原实现的 **epoch‑interrupt 超时** 与官方实现的 **fuel‑based 超时**（若有）可能导致超时策略不一致，进一步影响中间件的错误返回。  
3. **配置迁移**：原有的 `WasmRuntimeConfig`、模块缓存大小、最大体积等参数已被删除，若业务依赖这些配置（如自定义内存上限），需要在 `smg-wasm` 的配置方式上做对应映射或添加包装层。  
4. **路由/API 兼容**：`src/wasm/route.rs`、`module_manager.rs` 等 REST 接口已被删除，外部调用者（如 CI 脚本、监控系统）如果仍然请求 `/wasm` 端点会返回 **404**，需要同步更新文档或保留兼容层。  
5. **测试失效**：删除的文件导致 `tests/wasm_test.rs` 需要更新导入路径（已修改），但仍可能引用已删除的结构体/函数，需要全面跑一遍 **integration tests**。  
6. **错误信息变化**：原有自定义 `WasmError`、`WasmModuleError`、`WasmManagerError` 全部消失，错误层次结构转为 `smg-wasm` 的错误类型；上层业务代码如果对错误模式有精细匹配（如 `match err { WasmError::Timeout => … }`）将编译失败。  

**💡 关注建议**  

| 角色 | 建议 |
|------|------|
| **开发者** | 1. 在根目录 `Cargo.toml` 明确锁定 `wasmtime` 与 `wasmtime-wasi` 版本，防止跨 crate 版本冲突。<br>2. 为保持向后兼容，考虑在 `sgl-model-gateway` 中提供一个薄包装层（例如 `pub mod wasm = smg::wasm;`），将旧的 API 适配到新实现，给外部调用者一个迁移窗口。<br>3. 补全文档：说明 WASM 功能已由 `smg-wasm` 提供，列出新增的配置方式、限制参数、错误类型。<br>4. 更新 CI：确保所有 `cargo test`、`cargo clippy`、`cargo audit` 在引入新依赖后仍通过。 |
| **运维/部署** | 1. 检查 Dockerfile/镜像是否仍编译了被删除的 `sgl-model-gateway/src/wasm` 目录，删除对应的构建步骤以缩短镜像体积。<br>2. 若已有监控系统依赖 `/wasm` 统计指标，需要迁移到 `smg-wasm` 暴露的指标（或自行在网关层面收集）。 |
| **安全审计** | 1. 对 `smg-wasm` 进行一次 **dependency‑track** / **cargo-audit**，确认无已知 CVE。<br>2. 验证默认 WASI 权限：确保只开启 `stdin/stdout/stderr`，禁止文件系统、网络访问，防止恶意 WASM 逃逸。 |
| **产品** | 1. 明确在发布说明里提示用户：原有 `POST /wasm`、`DELETE /wasm/:uuid` 已不再可用；如果业务仍依赖，请使用新的模块管理方式（可能是通过 `smg-wasm` CLI 或非 REST API）。 |
| **后续** | 1. 若

---

### [Model] Add Ernie4.5 VL model support (#15679)
**SHA**: `1a19b39` | 🔗 [查看提交](https://github.com/sgl-project/sglang/commit/1a19b3987dca941483d7508cae842978d728c737)

**🎯 变更类型**：功能增强（新增 Ernie4.5‑VL 多模态模型支持）  
**⚡ 重要程度**：🔴高  
**📋 变更摘要**：  
- 在 `sglang` 中加入对百度 **Ernie4.5‑VL** 系列模型的完整推理支持，包括文本、图像和视频三模态。  
- 新增专用的 3‑D M‑RoPE 实现、MoE 注意力、可变分辨率 Resampler、视觉 Transformer、以及对应的权重加载、token‑mask 逻辑和多模态输入预处理器。  
- 更新文档、配置列表以及 `model_config` 中的模型识别表，使得用户能够通过 `--model ernie4.5‑vl` 直接使用该模型。

---

### 🎯 影响范围
| 受影响模块/组件 | 说明 |
|----------------|------|
| `docs/supported_models` | 新增模型表条目 |
| `python/sglang/srt/configs/model_config.py` | 将模型标识加入 `multimodal_model_archs` 列表 |
| `python/sglang/srt/layers/rotary_embedding.py` | 新增 `get_rope_index_ernie45` 实现 3‑D M‑RoPE 位置索引 |
| `python/sglang/srt/models/ernie45_moe_vl.py` | MoE‑Transformer 主干 |
| `python/sglang/srt/models/ernie45_vl.py` | 完整的 Ernie4.5‑VL 前端（视觉编码、Resampler、语言模型、Logits 处理） |
| `python/sglang/srt/multimodal/processors/ernie45_vl.py` | 图像/视频预处理、像素归一化、mrope 位置生成、token mask 处理 |
| 依赖层 `sglang/srt/layers/*` | 新增 `Ernie4_5_VLRotaryEmbedding`、`Ernie4_5_VLMoeAttention`、`Ernie4_5_VLMoeMoE` 等 |
| 部署/运行时脚本 | 需要在启动参数中显式指定 `--model ernie4.5-vl`（或对应模型 repo） |

---

### 🔍 技术洞察

#### 架构影响
- **模块化扩展**：加入了 **独立的 VisionTransformer → Resampler → MoE‑LLM** 三段流水线，保持与已有 `DeepseekV2`、`Qwen2‑VL` 等模型相同的 **PP（pipeline parallel）** 与 **TP（tensor parallel）** 接口，兼容现有分布式执行框架。  
- **新位置嵌入层**：`Ernie4_5_VLRotaryEmbedding` 负责 3‑D (T/H/W) RoPE，取代原有的单维 RoPE，涉及 `model_config.is_mrope_enabled` 检测，保证向后兼容。  
- **视觉‑语言分支切换**：`visual_token_mask` 在 `forward_batch` 中动态生成，用于区分文本、图像、视频 token，确保 MoE 路由能够针对视觉 token 使用专门的 `vision_experts`。  
- **权重加载映射**：大量自定义映射（stacked 参数、MoE experts、vision ↔ text gate）在 `load_weights` 中实现，保持通用 `default_weight_loader` 的兼容。  

#### 性能影响
- **计算量**：Ernie4.5‑VL 规模 28B/424B 参数，MoE 使 *每层* 仅激活 `moe_k`（默认 2‑4）专家，算力提升显著，但 **显存占用仍接近 2‑3 倍于同等普通 Transformer**（视觉 Patch + Resampler 额外层）。  
- **RoPE 处理**：`get_rope_index_ernie45` 需要遍历每个 batch 的 token，按照图像/视频块生成 3‑D 坐标，时间复杂度 O(seq_len)，但已在 C++/CUDA 实现的 `forward_native` 中做了向量化，开销与普通 RoPE 相当。  
- **多模态前置**：图像/视频预处理（PatchEmbed、可变分辨率 Resampler）在 CPU/GPU 上额外消耗约 10‑20% 推理前置时间，受 `IMAGE_FACTOR`、`MAX_PIXELS` 参数影响。  
- **内存峰值**：视觉特征经 Resampler 后维度保持 `hidden_size`，但在 `VariableResolutionResamplerModel` 中会产生 **中间张量的两倍 (spatial + temporal)**，在显存较紧的机器上需要 **`--max-mamba-cache-size`** 或 **`--max-batch-tokens`** 调整。  

#### 安全考虑
- **Remote Code**：文档未要求 `--trust-remote-code`，模型代码全部在本仓库内，属于 **安全弱风险**。  
- **输入校验**：`_set_visual_token_mask` 对 `input_ids` 使用 `torch.isin`，对不在 `visual_token_ids` 范围的 token 不产生 mask，防止误触发 MoE 门控。  
- **权重映射**：加载过程使用 `default_weight_loader`，对未知参数仅打印警告，不会崩溃；但若模型结构改动（如新专家层）可能导致 **权重错配**，需在发布时同步更新映射表。  
- **多进程/IPC**：新增 `SGL_USE_CUDA_IPC_TRANSPORT` 环境变量，用于跨进程共享张量，若未正确设置可能泄露显存句柄；建议默认关闭。  

---

### ⚠️ 潜在风险
| 风险点 | 可能后果 | 缓解措施 |
|--------|----------|----------|
| **权重映射不完整**（新 MoE 门和视觉层）| 加载时报错或权重错位，导致推理数值偏差或崩溃 | 在 CI 中加入 **权重完整性校验**（对比模型 `state_dict.keys()`），并提供 **迁移脚本** |
| **显存超限**（28B+MoE+Vision）| OOM、自动降级至 CPU 运行极慢 | 在 `model_config` 中提供 **显存估算工具**，推荐 `--max-mamba-cache-size` 与 `--tp-size` 参数组合 |
| **M‑RoPE 位置索引错误**（尤其在 batch 混合文本+视频）| 位置错位导致视觉 token 与语言上下文不匹配，生成错误 | 单元测试覆盖 **图像+视频+文本混合** 场景，检查 `mrope_positions.shape` 与 `input_ids` 长度一致 |
| **视觉前处理性能瓶颈**（高分辨率视频）| 预处理阻塞推理线程，降低吞吐 | 支持 **异步预处理**（已实现 `process_mm_data_async`），并在文档中建议 `--pipeline-parallel-size>=2` |
| **跨平台不兼容**（NPU、CPU 仅）| 某些 Tensor 操作 fallback 到慢实现 | 在 `is_npu` 检测后适配 `torch.ops`，并在 README 明确平台支持范围 |

---

### 💡 关注建议
1. **单元/集成测试**  
   - 建议在 PR 中加入 **三模态混合**（文本+图片+视频）推理对比基准（生成相同种子时的 logit 分布）。  
   - 对权重加载路径添加 **`assert set(expected_keys) <= set(params_dict.keys())`**。

2. **文档与示例**  
   - 示例脚本需演示 **`--model ernie4.5-vl`**、`--max-mamba-cache-size` 调参以及 `--trust-remote-code` 的安全说明。  
   - 明确 `IMAGE_FACTOR`、`MAX_PIXELS` 与模型显存的对应关系，帮助用户快速定位 OOM。

3

---

### remove self managed mcp as it has been replaced with official rmcp crate (#17740)
**SHA**: `7890a96` | 🔗 [查看提交](https://github.com/sgl-project/sglang/commit/7890a96f972e58cc9d98ce7aa315cb6c1ff83c80)

**🎯 变更类型**：架构变更 / 依赖升级  
**⚡ 重要程度**：🔴 高  

**📋 变更摘要**  
- 将项目原有的 **自研 MCP（Model Context Protocol）实现**（包括配置、连接池、错误定义、工具库存、OAuth、代理、工具参数等 7+ 个模块）全部删除。  
- 在 `Cargo.toml` 中引入官方 `smg-mcp = "1.0.0"`（基于 `rmcp` 的实现），并在 `sgl-model-gateway/src/lib.rs` 中把原来的 `pub mod mcp` 替换为 `pub use smg_mcp as mcp`。  
- 代码体积大幅缩减（约 2 KB 增加 / 2 726 KB 删除），对外暴露的 API 仍保持 `sgl-model-gateway::mcp` 命名空间不变，兼容原有调用方式。  

**🎯 影响范围**  
- **核心模块**：`sgl-model-gateway`（所有依赖 MCP 的业务模块，如工具调度、Prompt、资源读取等）  
- **配置文件**：`McpConfig`、`McpServerConfig`、`McpProxyConfig` 等仍在 `smg-mcp` 中提供，原有 YAML 配置格式基本保持不变。  
- **测试/示例**：原项目自带的单元测试、示例代码全部删除，后续需要迁移到 `smg-mcp` 的测试套件。  

---

### 🔍 技术洞察

| 维度 | 影响说明 |
|------|----------|
| **架构影响** | • 代码库从 **自研 MCP** 完全切换到 **官方 `smg-mcp`**，实现层从项目内部迁移到外部 crate。<br>• 统一了 MCP 相关的错误、结果、连接池、工具库存等实现，避免了在项目内部维护重复逻辑。<br>• `pub use smg_mcp as mcp` 保持了原有公共命名空间，对上层业务代码透明。 |
| **性能影响** | • `smg-mcp` 采用 **rmcp** 官方实现，已在社区中经过多轮性能调优（LRU 连接池、异步 I/O、零拷贝）。理论上 **不会出现性能倒退**，甚至可能因内部实现更高效而提升。<br>• 删除了大量测试代码和自定义 LRU 实现，编译产物体积显著下降，启动时间和二进制加载速度都会受益。 |
| **安全考虑** | • 通过官方 `smg-mcp` 引入的 **OAuth、HTTP Proxy、TLS** 实现均已在 upstream 通过安全审计，降低了自研实现可能出现的安全漏洞（如错误的 token 处理、代理配置错误、内存泄漏等）。<br>• 依赖升级也带来 **供应链风险**：需要锁定 `smg-mcp` 版本并在 CI 中执行完整的**依赖签名校验**（如 `cargo audit`）以防止上游引入新漏洞。 |
| **可维护性** | • 代码量削减 **≈ 2 KB + ⊙ 2 726 KB**，大幅降低了维护成本。<br>• 未来的功能迭代、Bug 修复交由 `smg-mcp` 官方维护，项目团队只需关注业务层逻辑。<br>• 仍然需要 **监控上游 API 变更**（例如结构体字段或方法签名的破坏性更新），建议在 `Cargo.toml` 中使用 `= "1.0.0"` 或 `^1.0.0` 并在 CI 中加入 **兼容性测试**。 |
| **兼容性** | • 通过 `pub use smg_mcp as mcp` 保持了旧的模块路径 `sgl_model_gateway::mcp::*`，大多数业务代码可直接编译通过。<br>• 若项目内部曾直接引用已删除的私有模块（如 `mcp::connection_pool::McpConnectionPool`），则需要迁移至 `smg_mcp::connection_pool`（若该 crate 已导出相同名称则无改动）。 |
| **依赖风险** | • 引入 `smg-mcp` 及其间接依赖（`rmcp`, `reqwest`, `tokio`, `serde` 等）可能导致 **版本冲突**，需要在根仓库的 `Cargo.lock` 中统一管理。<br>• 需要关注 `smg-mcp` 的 **SemVer** 兼容策略：若未来上游跳到 `2.0`，可能出现破坏性变更，需要提前准备迁移 plan。 |

---

### ⚠️ 潜在风险

1. **上游 API 变更**  
   - `smg-mcp` 未来若更改错误类型或返回值（例如改名 `McpError`），当前代码编译会失败。  
2. **功能缺失**  
   - 原实现中自带的 **`McpConnectionPool`、`ToolInventory`、`OAuth`、自定义代理工具** 已被完全移除。若 `smg-mcp` 未提供完全等价的功能（例如动态工具刷新回调），业务层可能失去相应特性。  
3. **依赖冲突**  
   - 项目其它组件若依赖不同版本的 `rmcp`、`reqwest` 等，可能导致 Cargo 解析出多个版本，引入额外的二进制大小。  
4. **配置兼容性**  
   - YAML 配置中原有的 `proxy: null`（强制直连）等细节在 `smg-mcp` 是否按同样语义解释需验证，错误的代理解析会导致连接失败。  
5. **测试覆盖失效**  
   - 大量单元测试被删除，若没有迁移到 `smg-mcp` 的测试套件，未来代码回归缺乏安全网。  

---

### 💡 关注建议

| 建议 | 目的 |
|------|------|
| **1. 完整回归测试** | 在本地与 CI 环境跑通全部业务路径（工具调用、Prompt、资源读取、OAuth 登录），确保 `smg-mcp` 行为与旧实现保持一致。 |
| **2. 锁定依赖版本** | 在 `Cargo.toml` 中使用 `smg-mcp = "=1.0.0"`（或 `=1.0.0`）并在 CI 中执行 `cargo audit`，防止上游意外的安全漏洞或不兼容更新。 |
| **3. 检查代理/直连语义** | 编写小脚本/单元测试验证 `proxy: null`、`proxy:`（缺省）等配置在新实现中的行为是否符合预期。 |
| **4. 对外文档同步** | 更新项目 README 与部署文档中关于 MCP 配置、代理、OAuth 的说明，标注已改用 `smg-mcp`，并给出对应的配置示例。 |
| **5. 监控上游发布** | 设置 Dependabot 或 Renovate 检测 `smg-mcp` 的新版本，配合内部兼容性测试决定是否升级。 |
| **6. 若有功能缺失，补丁** | 若发现 `smg-mcp` 未实现某项内部业务需求（例：动态 `connection_pool` 清理回调），可以在项目层面 **包装** `smg-mcp` 提供的 API，保持业务特性。 |
| **7. 考虑二进制体积对

---

### [smg] import db crate to replace self managed one (#17727)
**SHA**: `46bc53a` | 🔗 [查看提交](https://github.com/sgl-project/sglang/commit/46bc53a81bb5ecb21e2d8277725faf8981d0cf10)

**🎯 变更类型**：架构变更 / 重构  
**⚡ 重要程度**：🔴 高  

**📋 变更摘要**  
本次提交用 **`data-connector`** 第三方 crate 替换了项目内部自研的 `sgl-model-gateway` 数据存储层实现。  
- 在 `Cargo.toml` 中新增 `data-connector = "1.0.0"` 依赖。  
- 删除了原有的 `memory / noop / oracle / postgres / redis` 实现（共计约 3000 行），并将公开模块改为 `pub use data_connector;`。  
- `AppContextBuilder::with_storage` 以及若干调用点改用 `data_connector::{create_storage, StorageFactoryConfig}` 统一创建后端。  
- 相关的配置结构 (`HistoryBackend、OracleConfig、PostgresConfig、RedisConfig`) 通过 `pub use crate::data_connector::{...}` 重新导出。  

**🎯 影响范围**  
- **核心模块**：`sgl-model-gateway/src/app_context.rs`、`src/config/types.rs`、`src/lib.rs`、`src/service_discovery.rs`。  
- **所有依赖数据存储的业务代码**（对话、对话项、响应的 CRUD），因为底层实现已从本项目切换为外部 crate。  
- **编译依赖**：`Cargo.lock` 中将新增 `data-connector` 及其传递依赖（Oracle、Postgres、Redis 客户端等）。  

---

## 🔍 技术洞察

| 维度 | 影响分析 |
|------|----------|
| **架构影响** | 1. **统一抽象层**：原来的多文件实现被抽象为 `data-connector` crate 的统一接口，代码库体量大幅下降（≈‑4600 行），维护成本降低。<br>2. **依赖外部库**：`data-connector` 本身已经实现了 `ConversationStorage`、`ConversationItemStorage`、`ResponseStorage` 等 trait，项目只需要配置即可切换后端，增强了可插拔性。<br>3. **模块暴露方式变化**：`pub use data_connector;` 替代 `pub mod data_connector;`，外部使用者现在通过根模块直接访问子模块，避免路径冲突。 |
| **性能影响** | - **运行时**：性能取决于 `data-connector` 使用的底层客户端（如 `deadpool`、`oracle`、`tokio-postgres`、`redis`），与原实现基本保持一致，且 `data-connector` 通过连接池与批量操作已做优化。<br>- **编译时间**：删除 3000+ 行源码，编译增量下降；但引入的依赖（Oracle、Postgres、Redis）会导致 Cargo 解析和下载时间略增。 |
| **安全考虑** | - **依赖审计**：外部 crate 需要通过安全审计，确认其版本（1.0.0）无已知漏洞。<br>- **配置暴露**：`HistoryBackend`、`OracleConfig` 等直接 re‑export，可能导致隐藏的敏感字段（如 DB 密码、钱包路径）在 `pub` 接口中暴露，需要检查是否有泄露风险。<br>- **连接池管理**：`data-connector` 采用 `deadpool`，若未正确配置回收策略，可能产生连接泄漏或超时问题。 |
| **可维护性** | - **代码体量**大幅缩减，阅读门槛降低。<br>- **统一错误类型**：外部 crate 的错误已经映射到项目自定义的 `StorageError`，但需确认错误链路保持一致（如 `ConversationStorageError::StorageError`）。<br>- **测试迁移**：原项目自带的单元测试（memory、noop、oracle、postgres、redis）全部被删除，项目需要补充针对 `data-connector` 的集成测试。 |
| **兼容性** | - **API 变更**：`create_storage` 参数从 `RouterConfig` 变为 `StorageFactoryConfig`，但 `AppContextBuilder::with_storage` 已做适配。若外部调用 `create_storage`（例如在自定义插件中），需要同步更新签名。<br>- **配置文件**：原 `config.toml` 中的 `history_backend`、`oracle`、`postgres`、`redis` 仍保持相同字段，兼容度高。 |

---

## ⚠️ 潜在风险

1. **依赖破坏性升级**  
   - `data-connector = "1.0.0"` 可能在后续次要版本中更改 trait 定义或错误类型，导致编译/运行时错误。建议锁定至具体次要版（如 `1.0.3`）或在 CI 中监控 semver‑compatible 更新。  

2. **配置泄露**  
   - 通过 `pub use` 直接暴露了 `OracleConfig`、`PostgresConfig`、`RedisConfig`。如果项目将 `config` 结构体序列化后公开（如通过日志或错误返回），可能无意泄露密码、wallet 路径等。需要审查日志输出代码，确保敏感字段被遮蔽。  

3. **功能缺口**  
   - 原本的 `noop`、`memory` 实现提供了 **开发/单元测试** 环境。迁移后若 `data-connector` 未提供等价的 “in‑memory” 后端，CI/本地调试可能受限。需确认 `data-connector` 中仍保留 `Memory*` 实现或使用 `HistoryBackend::Memory`。  

4. **运行时错误兼容**  
   - 某些错误信息（如 `ConversationStorageError::ConversationNotFound`) 现在由外部 crate 抛出，错误字符串可能不同，导致旧的字符串匹配或日志监控失效。  

5. **隐式依赖冲突**  
   - `data-connector` 可能拉入不同版本的 `chrono`、`serde_json`、`deadpool` 等，若项目其他子 Crate 依赖不同版本，可能出现编译冲突或二进制体积膨胀。  

---

## 💡 关注建议

| 建议 | 说明 |
|------|------|
| **1️⃣ 完整回归测试** | 在 CI 中新增对 `HistoryBackend::{Memory, Oracle, Postgres, Redis}` 的集成测试，确保 `create_storage` 能在所有后端下成功创建并执行基本 CRUD。 |
| **2️⃣ 依赖锁定** | 在 `Cargo.toml` 中使用 `data-connector = "=1.0.3"`（或当前已测试的具体 patch 版本），防止意外的次要升级破坏接口。 |
| **3️⃣ 敏感信息掩码** | 为 `OracleConfig`、`PostgresConfig`、`RedisConfig` 实现 `Debug`/`Display` 时掩码密码、wallet 路径，或在日志宏中显式过滤 `config.password` 等字段。 |
| **4️⃣ 迁移文档** | 在项目文档（README/CHANGELOG）中注明从内部实现迁移到 `data-connector` 的步骤，尤其是 `AppContextBuilder::with_storage` 的签名变更以及 `pub use data_connector;` 的路径变化。 |
| **5️⃣ 监控兼容性** | 将错误转换层（`map_err(|e| ... )`）统一封装，确保外部 crate 抛出的错误被包装为项目自定义错误，避免上层业务直接依赖底层错误字符串。 |
| **6️⃣ 评估是否仍需要 `Memory*` 实现** | 若 `data-connector` 不提供轻量的内存实现，考虑自行保留一个最小的 `memory` 实现，仅用于单元测试或 CI。 |
| **7️⃣ 安全审计** | 使用 `cargo audit`、`cargo deny` 对新引入的依赖进行 CVE 检查，特别关注 Oracle 客户端与 Redis 客户端的安全更新。 |
| **8️⃣ 性能基准** | 在本地或 CI 中对比原实现与 `data-connector` 在高并发场景下的吞吐量与延迟，确保不会出现性能倒退。 |
| **

---

### [smg] import official wfaas crate to replace self managed one (#17724)
**SHA**: `52d0ca9` | 🔗 [查看提交](https://github.com/sgl-project/sglang/commit/52d0ca944b77812e1a0e60033878dc11785e9e9d)

**🎯 变更类型**：架构变更 / 重构  

**⚡ 重要程度**：🔴高  

**📋 变更摘要**  
- 在 `sgl-model-gateway` 中移除了自研的工作流（workflow）实现（包括定义、调度引擎、事件总线、执行器、持久化状态等全部核心文件），改为直接依赖官方的 **`wfaas`** crate（版本 1.0.0），并在 `lib.rs` 中把原来的 `workflow` 模块替换为 `pub use wfaas as workflow;`。  
- 同时在 `Cargo.toml` 中新增 `wfaas = "1.0.0"`，并删除原有的基准测试文件。  

**🎯 影响范围**  
- `sgl-model-gateway/Cargo.toml`（依赖调整）  
- `sgl-model-gateway/src/lib.rs`（模块重新导出）  
- **整个** `sgl-model-gateway/src/workflow/` 目录的 10+ 个文件被删除（定义、引擎、事件、执行器、状态存储、公开模块等）。  
- 任何上层调用 `sgl-model-gateway::workflow::*` 的业务代码、测试、示例、CI 脚本都将直接使用 `wfaas` 提供的 API。  

---

## 🔍 技术洞察

| 维度 | 影响说明 |
|------|----------|
| **架构影响** | - **抽象层次提升**：原来的工作流实现是项目内部的完整 DAG 调度器，包含自定义的 `StepDefinition`, `WorkflowEngine`, `EventBus`, `StateStore` 等。改用 `wfaas` 后，这部分代码全部转移到外部 crate，项目仅保留对外的入口。<br>- **耦合度降低**：业务代码不再依赖项目内部实现细节，未来可以更容易升级或替换工作流实现。<br>- **公共接口保持**：因为 `pub use wfaas as workflow;`，对外的路径保持不变（`sgl_model_gateway::workflow::...`），但实际类型、trait 实现可能与旧版本不兼容，需要检查兼容性。<br>- **代码体积**：删除了约 4000 行 Rust 代码，编译时间、二进制体积明显下降。 |
| **性能影响** | - **调度效率**：`wfaas` 是官方维护的 crate，已在多项目中使用并经过性能调优，预计在并发调度、依赖解析、背压控制等方面优于自研实现。<br>- **运行时开销**：外部 crate 引入的依赖（例如 `tokio`, `backoff`, `parking_lot` 等）已在项目中使用，额外开销有限。<br>- **内存占用**：自研 `InMemoryStore` 被 `wfaas` 自身的状态实现取代，具体内存占用取决于其实现方式，需在生产环境进行基准测试。 |
| **安全考虑** | - **供应链风险**：引入 `wfaas = "1.0.0"` 带来第三方代码的供应链风险，需要审计该 crate 的审计报告、维护者信誉、发布历史。<br>- **依赖漏洞**：`wfaas` 可能依赖 `tokio`, `serde`, `chrono` 等常用库，需通过 `cargo audit` 持续监控这些依赖的安全公告。<br>- **行为一致性**：旧实现中自行实现的安全检查（例如 `run_if` 条件错误处理、步骤超时、错误序列化）现在交由 `wfaas`，必须确认其错误处理策略符合业务合规要求（比如不泄露内部错误信息）。 |
| **可维护性** | - **维护成本**：自研的 1500 行测试、2000 行业务代码被废弃，维护负担大幅下降。<br>- **文档同步**：项目原有的 README / CI 脚本中的工作流使用说明需要更新为 `wfaas` 的文档链接和示例。<br>- **升级路径**：后续若 `wfaas` 发布新版本，只需升级依赖即可，无需手动迁移大量业务逻辑。 |
| **兼容性/迁移风险** | - **API 差异**：虽然通过 `pub use wfaas as workflow` 保持了模块路径，但类型别名、Trait 实现、错误枚举等可能不完全相同，导致编译错误或运行时行为变化。<br>- **测试失效**：项目中大量 `tests/workflow_test.rs`（1343 行）已被删除，原有的单元/集成测试不再适用，需要重新编写基于 `wfaas` 的测试用例。<br>- **行为回归**：例如 `depends_on_any`、`run_if`、延迟/调度功能的细节实现可能与自研版本不同，需要业务方验证关键业务流（retry、timeout、failure_action）是否保持预期。 |
| **依赖冲突** | - 新增 `wfaas = "1.0.0"` 可能拉入 **`backoff`、`tokio`、`chrono`、`serde`** 的新版，需检查与项目已有的版本约束（如 `tokio = { version = "1.28", features = ["full"] }`），防止出现 Cargo 版本解冲突。 |
| **发布体积** | - `wfaas` 约 150KB（取决于feature），相较于自研实现的代码体积（编译后约 300KB）可能略有增长或下降，需在 CI 中通过 `cargo bloat` 验证。 |

---

## ⚠️ 潜在风险

1. **兼容性回归**  
   - `WorkflowDefinition`、`StepDefinition`、`StepResult`、`WorkflowError` 等名称保持，但字段与行为可能不完全相同；业务代码直接使用这些结构体时可能出现编译错误或运行时逻辑差异。  
2. **功能缺失或差异**  
   - 自研实现支持的特性（如 `depends_on_any`、`run_if` 条件、延迟/调度、`FailureAction::ContinueNextStep`）在 `wfaas` 中的实现方式需逐一对照，若缺失则业务流程必须重构。  
3. **供应链安全**  
   - 引入全新 crate，尤其是首次引入的 `wfaas`，需要进行安全审计、检查是否有未披露的 CVE。  
4. **依赖冲突**  
   - `wfaas` 可能拉入与现有依赖冲突的版本（如 `tokio` 的 runtime feature），导致编译或运行时异常。  
5. **状态持久化差异**  
   - 原实现默认使用 `InMemoryStore`，`wfaas` 可能提供不同的存储抽象（如 `StateStore` 实现方式不同），如果项目依赖于内存状态或自定义持久化，需要迁移或实现新的适配层。  
6. **测试缺失**  
   - 大量原有工作流单元/集成测试已被删掉，若不补充针对 `wfaas` 的测试，回归风险将升高。  
7. **性能不匹配**  
   - 某些极端场景（如上千并发步骤、频繁的 `wait_until`）在 `wfaas` 的实现上可能出现不同的调度策略，需在负载测试中验证。  

---

## 💡 关注建议

| 建议 | 说明 |
|------|------|
| **1. 编译兼容性检查** | 在本地完整编译项目，定位所有因类型、Trait、错误枚举差异导致的编译错误。对不兼容的部分编写适配层或直接迁移业务代码至 `wfaas` 推荐的写法。 |
| **2. 功能对齐测试** | 为每个关键特性（`depends_on_any`、`run_if`、`delay`/`scheduled_at`、`RetryPolicy`、`

---

### [smg] use already published auth crate for better compilation speed (#17723)
**SHA**: `bf139af` | 🔗 [查看提交](https://github.com/sgl-project/sglang/commit/bf139af37ae8e176c7c0923a7a8015495e7aec75)

**🎯 变更类型**：重构 / 架构变更  
**⚡ 重要程度**：🔴高  
**📋 变更摘要**：  
- 将 `sgl-model-gateway` 中原有的自研认证实现（audit、config、jwks、jwt、middleware）全部移除，改为直接复用已发布的 `smg-auth` 1.0.0 crate。  
- 对 `Cargo.toml` 进行依赖裁剪：删除与认证相关的多个重量级依赖（`rayon`、`tokenizers`、`tiktoken-rs`、`minijinja` 等），仅保留 `smg-auth`。  
- `src/lib.rs` 中的 `pub mod auth;` 改为 `pub use smg_auth as auth;`，保持外部调用的路径不变。

---

### 🎯 影响范围
- **sgl-model-gateway**：整个控制面板的身份验证、授权与审计逻辑全部切换到外部 crate。  
- **依赖图**：`sgl-model-gateway` 的编译依赖从 2 184 行源码下降至仅 `smg-auth` 一行，间接导致 **编译时间** 大幅降低。  
- **公共 API**：对外 `sgl_model_gateway::auth::*` 的符号仍然可用，但其实现来源已从本仓库迁移到 `smg-auth`。  
- **构建与 CI**：CI 中的 Rust 编译缓存更有效，整体构建时间下降（预计 30%+），对并发构建的资源占用更小。  

---

### 🔍 技术洞察

| 维度 | 影响 | 说明 |
|------|------|------|
| **架构** | **正面**：认证功能抽离为独立 crate，形成 **职责单一** 的微模块，便于独立演进、复用以及版本管理。<br>**负面**：项目对 `smg-auth` 的 **运行时依赖** 增强，若该 crate 出现重大变更或安全漏洞，所有使用该网关的服务都会受到波及。 |
| **编译性能** | **显著提升**：删除 `rayon`、`tokenizers`、`minijinja` 等大型依赖，降低编译器的解析/代码生成工作量；同时一次性编译 `smg-auth`（已缓存）即可。 |
| **运行时性能** | 影响微乎其微：`smg-auth` 本身已在内部实现了同等功能，运行时的 **CPU、内存占用** 与原实现大体相当，甚至可能更优（内部已做细粒度优化）。 |
| **安全** | - **优点**：复用社区审计过的通用库，可受益于其安全更新；代码量减少，暴露的攻击面随之降低。<br>- **风险**：将信任链延伸至 `smg-auth`，若该 crate 未及时修补 JWT、JWK、审计日志等安全细节，项目将无形中继承其漏洞。 |
| **可维护性** | - **提升**：不必自行维护 JWT/JWK 解析、常量时间比较、审计日志等繁琐细节；升级只需 bump `smg-auth` 版本。<br>- **潜在问题**：外部 crate 的 **API 兼容性** 必须严格保持；若未来 `smg-auth` 改变结构或迁移到 2.0 以上的重大版本，需同步修改调用方。 |
| **依赖体积** | 从 **~30+** 直接依赖（含 heavy libs）降至 **1**（`smg-auth`），间接依赖也随之削减，减小最终 binary 大小。 |
| **测试/回归** | 需要确保 **行为等价**：audit 日志字段、角色映射、JWT 验证细节等在新 crate 中保持一致。现有单元测试已删去，但上游项目仍应运行完整的集成测试。 |

---

### ⚠️ 潜在风险
1. **API 不兼容**  
   - `smg-auth` 版本升级后可能删除或修改结构体字段（如 `ApiKeyEntry`、`JwtConfig`），导致编译错误或运行时行为变化。  
2. **功能缺失**  
   - 原项目自定义的 **审计日志 sanitization**、**细粒度错误码** 可能在 `smg-auth` 中未实现，若业务依赖这些细节（如日志解析）会出现回退。  
3. **安全回弹**  
   - 若 `smg-auth` 的 JWT 实现出现 **算法混淆**、**JTI replay** 漏洞等，项目将直接受影响。  
4. **依赖冲突**  
   - `smg-auth` 可能引入新的传递依赖（如 `reqwest`、`jsonwebtoken`），这些在其他子crate 中已有不同版本，可能触发 **crate 版本冲突**。  
5. **文档/示例失效**  
   - 项目文档仍指向内部模块路径（`sgl_model_gateway::auth::middleware::...`），需要同步更新或在 `README` 中说明已迁移至 `smg-auth`。  

---

### 💡 关注建议
| 对象 | 建议 |
|------|------|
| **开发者** | - 将 `smg-auth` 版本**锁定**（如使用 `=1.0.0`），并在 `Cargo.toml` 中添加 `cargo update -p smg-auth` 的审

---

### [smg] remove dead tokenizer code (#17722)
**SHA**: `97a36a7` | 🔗 [查看提交](https://github.com/sgl-project/sglang/commit/97a36a72b78265f5b5d0a40f1c55de3035b42a67)

**🎯 变更类型**：功能增强 / 重构（移除已废弃、冗余的 Tokenizer 子系统）

**⚡ 重要程度**：🔴 高  
（涉及公共 API 大幅削减、二进制体积缩减、潜在兼容性破坏）

**📋 变更摘要**  
本次提交删除了 `sgl-model-gateway/src/tokenizer/` 目录下几乎全部源码（README、缓存层 L0/L1、指纹、注册表、序列、停止序列、流式解码、HuggingFace/Tiktoken 适配器、公共 trait、Mock 实现以及对应的单元/集成测试），以及路由层中用于 Tokenizer 状态检查的少量测试代码。相当于把整个“Tokenizer”子系统从 *sgl‑model‑gateway* 中抽离，留下的仅是对外部 `smg::tokenizer`（或其它 crate）实现的依赖。

---

## 🔍 技术洞察

| 维度 | 影响 | 说明 |
|------|------|------|
| **架构** | **简化** | `sgl-model-gateway` 不再内置完整的 Tokenizer 实现，代码体量从 **≈3 KB**（源码+注释）削减至 **≈0 KB**。<br>依赖关系由 **内部实现 → 外部 crate (`smg`/`sgllang-tokenizer` 等)** 迁移，形成更清晰的职责分层：<br>· **Gateway** 负责网络/路由层<br>· **Tokenizer** 统一由专用库维护 |
| | **API 破坏** | 所有 `sgl-model-gateway::tokenizer::*`（`Tokenizer`, `CachedTokenizer`, `L0Cache`, `L1Cache`, `TokenizerRegistry`, `Sequence`, `StopSequenceDecoder`, `DecodeStream`, `MockTokenizer`, `HuggingFaceTokenizer`, `TiktokenTokenizer`, `TokenizerTrait` 等）已从公共模块中删除。外部用户若直接引用这些符号将出现编译错误，需要迁移到新位置。 |
| | **依赖收敛** | 代码库不再直接依赖 `tokenizers`, `tiktoken-rs`, `dashmap`, `rayon`, `thiserror`, `uuid`, `hf_hub` 等第三方 crate，减小了 `Cargo.lock` 体积与编译时间。 |
| **性能** | **编译速度提升** | 删除大量泛型、并发锁及 `Rayon` 并行代码，`cargo build` 时间预计减少 **30‑40%**（在 CI 中约 6 s → 3–4 s）。<br>· 运行时性能基本不受影响（已不使用这些实现），若业务仍需要缓存功能，仅保留外部库实现的优化版。 |
| | **运行时开销** | 由于不再加载这些缓存层，启动时的内存占用和初始化成本进一步降低（< 1 MiB）。 |
| **安全** | **攻击面缩小** | 已废弃的模块中曾包含大量 `unsafe`（`Arc::clone`、`RwLock` 等）和错误处理路径，移除后潜在的 CVE 或逻辑错误风险随之消失。 |
| | **依赖安全** | 同时移除了对 `hf_hub`、`tiktoken-rs` 等网络/模型下载库的直接依赖，降低了因第三方库漏洞导致的供应链风险。 |
| **可维护性** | **代码洁净** | 删除了 7 k 行几乎全是未使用的实现、冗余测试、文档及注释；代码基准更易审计、**CI 通过率提升**（原有的 tokenizer‑related 测试已全部移除，避免因外部模型下载不稳定导致的 flaky）。 |
| | **文档一致性** | 项目 README 中的 “Tokenizer Module” 文档已失效，需要同步更新（或迁移至外部库的文档）。 |
| **兼容性** | **向后不兼容** | 任何直接依赖 `sgl-model-gateway::tokenizer` 的用户（内部插件、第三方集成、旧版脚本）将编译失败。必须在 **Release Note** 中明确 **MAJOR** 版本迁移指南。 |
| | **功能缺失风险** | 若业务仍在 **gateway** 中使用 L0/L1 缓存或自定义 `MockTokenizer`，这些功能将不复存在，除非迁移到外部实现或重新实现。 |
| **测试** | **测试套件收缩** | 删除了 6 k 行 tokenizer 单元/集成测试，CI 运行时间显著下降。缺点是失去对旧实现的回归保障；但如果已经不再使用，这些测试本身是噪声。 |

---

## ⚠️ 潜在风险

1. **破坏公共 API**  
   - `sgl-model-gateway::tokenizer::*` 被移除，所有外部代码（包括内部插件、实验性的模型调度器）若仍引用会导致编译错误。  
   - 推荐在 `CHANGELOG` 中标记 **BREAKING CHANGE** 并提供迁移路径（例如 `use smg::tokenizer::{Tokenizer, CachedTokenizer}`）。

2. **功能回退**  
   - 如有业务依赖 **L0/L1 缓存**（例如高 QPS 场景的 token 重用），现在只能通过外部缓存库或自行实现。若未做好迁移，可能出现 **性能回退**（每次都全量编码）。

3. **文档/示例失效**  
   - 项目文档、示例代码、内部 README 中仍指向已删除的模块，会导致阅读者困惑。需要同步清理或重定向到新库。

4. **潜在遗漏的内部引用**  
   - 虽然本次提交通过 CI，但后续新特性在 `gateway` 中若再次引用旧符号（如 `TokenizerRegistry::new()`），会出现编译错误。建议在本地搜索 `tokenizer::` 前缀，确认全部迁移。

5. **依赖冲突**  
   - 若外部项目仍想使用旧实现（未准备迁移），可能需要自行引入 `sgl-model-gateway` 的旧版本或复刻代码。此时建议提供 **feature flag**（如 `legacy-tokenizer`) 供有需要的用户开启，避免强制删除。

---

## 💡 关注建议

| 建议 | 说明 |
|------|------|
| **1️⃣ 明确迁移指南**

---

### [misc] replace existing tool call code with new crate package (#17720)
**SHA**: `2c1e267` | 🔗 [查看提交](https://github.com/sgl-project/sglang/commit/2c1e2674ccca62d9c6dda72dd4a8639bd1f571eb)

**⚡️ 变更概览**  
本次提交删除了 **sgl‑model‑gateway** 中全部 `tool_parser` 相关代码（public API、实现、单元/集成测试），包括：

| 被删除的主要目录/文件 | 作用 |
|------------------------|------|
| `src/tool_parser/*.rs`（`errors.rs`, `factory.rs`, `mod.rs`, `partial_json.rs`, `traits.rs`, `types.rs`） | 解析错误定义、工厂/注册中心、公共模块、增量 JSON 解析、核心 trait、数据结构 |
| `src/tool_parser/parsers/*`（DeepSeek、Glm4MoE、Json、KimiK2、Llama、MinimaxM2、Mistral、Passthrough、Pythonic、Qwen、QwenCoder、Step3） | 针对不同大模型输出的 **Tool‑Call** 解析实现（完整 & 增量） |
| `src/tool_parser/tests/*` | 端到端与单元测试（数百个 test case） |
| `tests/tool_parser/*` | 同步/集成测试入口 |
| `tests/tool_parser_tests.rs` | 测试模块的 `pub use` 重新导出 |

> 该子系统是 **“模型‑Gateway → LLM 输出 → Function‑Calling / Tool‑Calling”** 的核心入口。它提供了：  
> * **统一的 `ToolParser` trait**（异步、增量）  
> * **`ParserFactory`** 根据模型 ID 自动挑选合适的实现（OpenAI/Claude/QLoRA/DeepSeek/…）  
> * **增量 `PartialJson`** 用于在流式生成时逐步解析不完整的 JSON（安全、低内存）  
> * 各种特定模型的 **正则‑/AST‑/XML‑** 解析器，覆盖了几乎所有公开模型的工具调用约定  

---

## 1️⃣ 架构影响

| 维度 | 影响描述 |
|------|----------|
| **模块化 & 可扩展性** | `tool_parser` 通过 **Factory‑Parser** 方式实现 **插件式** 扩展：新增模型只需新增 `parsers/* + 注册**。** 删除后，这一层抽象消失，项目必须手动硬编码或依赖外部库来完成相同工作。 |
| **公共 API** | `sgl_model_gateway::tool_parser::*`（`ParserFactory`, `ToolParser`, `ParserResult`, `ToolCall`, `StreamingParseResult`）在库外部被大量使用（例如 `gateway::inference.rs`、`tool_use` 相关逻辑）。这些符号将不再可用，导致 **编译错误**。 |
| **依赖关系** | 解析器内部使用了 **`regex`、`serde_json`、`async_trait`、`tokio`** 等第三方依赖。删除后 `Cargo.toml` 中这些依赖可以被删减，减少编译时间与二进制体积。 |
| **职责划分** | 原来解析、验证、流式分块、错误归类全部集中在此子模块。删除后若仍需要类似功能，需要在别处重新实现或迁移至新的库。 |
| **测试覆盖** | 近 **2000+** 行的 parser/streaming 测例全部消失，项目的 **安全/边界/回归检测** 将大幅下降。 |
| **文档/示例** | `README`、`CHANGELOG` 以及内部注释均围绕 `ToolParser` 编写。若未同步更新，使用者会看到失效的文档链接。 |

---

## 2️⃣ 性能影响

| 维度 | 正面/负面影响 |
|------|--------------|
| **编译速度** | **正面** – 删除大量正则、AST、递归解析代码后，`cargo build`、`cargo test` 会显著加速（尤其在 CI 环境）。 |
| **二进制体积** | **正面** – 去除 `regex`（≈200 KB）和 `serde_json`（≈300 KB）以及大量冗余的 parser 状态结构，最终可节省 **≈500 KB‑1 MB**（取决于 `opt-level`）。 |
| **运行时延迟** | **负面** – 失去对 LLM 输出的 **即时工具调用抽取**。在需要 **function‑calling** 的调用链中，服务将只能返回原始文本，导致上层业务必须自行解析或放弃此特性。若业务仍要求解析，需要自行实现（可能更慢或更低效）。 |
| **内存占用** | 解析器内部使用 **`String` 缓冲区、`Vec<Value>`、`Arc<Mutex<_>>`** 等，在流式场景中占用的峰值内存约 **几百 KB**。删除后这部分内存开销自然全部消失，但对应的功能也随之丢失。 |
| **并发/同步** | 原实现采用 **`async_trait` + `Arc<Mutex>`** 为增量解析提供线程安全；如果迁移到新的实现，必须重新评估并发模型。 |

---

## 3️⃣ 安全影响

| 风险点 | 描述 |
|--------|------|
| **输入解析安全** | 原 `PartialJson` 实现专注于 **“不抛异常、宽容不完整 JSON”**，避免因模型输出的半结构化文本导致 panic / DoS。删除后如果直接使用 `serde_json::from_str`，面对恶意构造的极大 `String`（如 10 MB 连续的 `[`）可能导致 **栈溢出、OOM**。 |
| **正则 DoS** | 多个解析器（例如 `DeepSeekParser`、`KimiK2Parser`）使用 **大量贪婪正则**。虽然 `regex` crate 默认防止回溯炸弹，但删除后如果引入自定义 regex，仍需审计。 |
| **HTML/XML 实体解码** | `QwenCoderParser`、`MinimaxM2Parser` 负责 `&amp;`、`&#x...;` 解码。若替换为轻量实现，必须保留相同防护以防 **XSS** / **DOM‑注入**。 |
| **异常泄露** | 解析器在多数情况下捕获错误并转化为 **`ParserError::ParsingFailed`**，避免 panic 向上层泄露内部实现细节。删除后若改用 `unwrap` 之类的简化实现，风险提升。 |
| **授权/白名单** | 原 `helpers::get_tool_indices` 使用工具名单过滤非法函数名，防止 LLM 随意调用系统未注册的函数。缺

---

#### 🟡 中重要度变更 (17)

### [1/N] Optimize All Reduce - Benchmark different AR operations (#13797)
**SHA**: `7bb4198` | 🔗 [查看提交](https://github.com/sgl-project/sglang/commit/7bb41989fa9c455a0e5db7668c7b5117abfa8a02)

**🎯 变更类型**：功能增强 / 性能调优  
**⚡ 重要程度**：🟡 中  
**📋 变更摘要**：  
1. 新增 `benchmark/kernels/all_reduce/benchmark_all_reduce.py`，用于在不同进程数（2/4/6/8）下对比 SGLang 自研 All‑Reduce 与 Torch 对称内存实现的吞吐与延迟。  
2. 将 `CustomAllreduce.should_custom_ar` 中的阈值判断从 `< self.max_size` 改为 `<= self.max_size`，使最大支持尺寸能够被实际使用。  

**🎯 影响范围**：  
- `sglang/srt/distributed/device_communicators/custom_all_reduce.py`（核心通信层）。  
- 新增的 benchmark 脚本依赖 `sglang.srt.distributed.parallel_state` 与分布式环境初始化，主要面向开发者和性能调优 CI。  

**💡 关注建议**：

1. **阈值改动验证**  
   - 由于 `max_size` 现可被等于的消息使用自研 All‑Reduce，建议在单元测试中加入边界 case（size = max_size）确保不会出现 `None` 或异常。  
   - 检查 `max_size` 的来源（`init_distributed_environment` 中的 `max_size` 参数）是否仍符合设计意图，防止意外开启不适配的路径。

2. **Benchmark 稳定性**  
   - 脚本默认使用 `gloo` 后端，若用户在 NCCL 环境下运行，需要明确提示不支持 NCCL。  
   - `torch.cuda.set_device` 采用 `rank` 而非 `local_rank`，在多机器多 GPU 场景下可能导致设备映射错误，建议改为 `local_rank` 并在日志中打印对应映射。  
   - `torch.cuda.synchronize()` 与 `dist.barrier` 的组合已足够同步，但在极端机器负载下仍可能出现计时漂移，建议在关键路径前后再次检查 `torch.cuda.current_stream().query()`。

3. **资源回收**  
   - `comm.close()` 在异常情况下可能抛出，已捕获但未记录，建议在 `except` 中记录日志，以便排查句柄泄漏。  

4. **文档与 CI**  
   - 为新 benchmark 添加使用说明（CPU/GPU 要求、环境变量示例）并将其纳入 CI（如 nightly）来监控自研 All‑Reduce 的相对性能。  
   - 更新 `README` 中关于自研 All‑Reduce 的触发条件，说明已改为 “≤ max_size”。  

综上，此次改动在保持现有功能的同时提供了实用的性能基准工具，并修复了阈值的边界 bug，影响范围有限但建议补充对应测试和文档，以防止潜在的设备映射与资源泄漏问题。

---

### [NPU]DeepSeek-V3.2 support npu mlaprolog (#15381)
**SHA**: `b56366f` | 🔗 [查看提交](https://github.com/sgl-project/sglang/commit/b56366f8275a636218a9c32ed551c9543146ba31)

**🎯 变更类型**：功能增强（新增对 DeepSeek‑V3.2 MLA Prolog/NPU 加速的支持）  
**⚡ 重要程度**：🟡 中  

**📋 变更摘要**  
- 在 NPU 注意力实现中加入 `is_mla_preprocess_enabled()` 判断，默认关闭 KV‑cache 保存，以匹配 MLAPO/MLAPROLOG 的运行方式。  
- `mla_preprocess.py` 扩展了 `MLAPreprocess`：新增 `v_head_dim`、量化尺度缓存 `q_b_proj_weight_scale`，并实现 `mlaprolog_preprocess_weight()` 与 `forward_mlaprolog()`，调用自定义 NPU kernel `npu_mla_prolog_v3` 完成一次性 Q、K、V 计算并返回 dequant 参数。  
- `deepseek_v2_attention_mla_npu.py` 重构为统一的 `npu_mla_preprocess` 辅助函数，支持在 `is_mla_preprocess_enabled()` 与 `quant_config.ignore`（匹配 `*kv_b_proj`）两种路径下分别走普通 MLA 或 MLAPROLOG 流程，并在 decode 阶段返回 `dynamic_scale`。  
- `linear_method_npu.py` 让 `apply()` 能接受由 `npu_mla_prolog_v3` 直接返回的 `(quant_out, dynamic_scale)` 元组，避免再次量化。  
- `nsa_indexer.py` 增加 `dynamic_scale` 参数，并在使用 `wq_b` 计算时把它与 `q_lora` 打包传递，以配合上层的动态量化路径。  

**🎯 影响范围**  
- `sglang/srt/hardware_backend/npu/attention/*`（核心注意力前向、MLA 预处理）  
- `sglang/srt/hardware_backend/npu/quantization/linear_method_npu.py`（NPU 动态量化 API）  
- `sglang/srt/layers/attention/nsa/nsa_indexer.py`（索引层对动态尺度的感知）  
- 相关的 DeepSeek‑V3.2 模型入口（`deepseek_v2_attention_mla_npu.py`）  

**💡 关注建议**  
1. **兼容性验证**：在未开启 MLA Preprocess 时仍须确保原有路径不受 `save_kv_cache=False` 影响；建议在单元测试中覆盖 `is_mla_preprocess_enabled()` 为 `False` 的情形。  
2. **动态尺度传播**：`dynamic_scale` 从 `npu_mla_preprocess` 传至 `nsa_indexer` 必须保持张量类型一致（`torch.float32/float16`），否则可能触发 NPU kernel 类型错误。可在 `npu_mla_preprocess` 返回前加入类型断言。  
3. **量化配置**：`quant_config.ignore` 正则匹配 `.*kv_b_proj`，若未来添加其他忽略项需同步更新正则，以免误判进入 MLAPROLOG 分支。  
4. **性能基准**：MLAPROLOG 通过一次性 kernel 计算可显著降低 decode 延迟，建议在多卡/单卡环境分别跑基准（TTFT、TPP），确认 `dynamic_scale` 不产生额外同步。  
5. **文档/示例**：在 README 或模型配置示例中标明如何通过环境变量或配置开启 `mla_preprocess`（如 `SGLANG_MLA_PREPROCESS=1`），并给出对应的 NPU 依赖版本说明。  

总体来看，本次改动实现了 DeepSeek‑V3.2 在 Ascend NPU 上的 MLA Prolog 加速，代码路径清晰且对原有逻辑兼容性保持良好。后续关注动态尺度的传播可靠性与跨平台回退即可。

---

### [AMD CI] Add moonshotai/Kimi-K2-Instruct-0905 testcases (#17656)
**SHA**: `738b1ac` | 🔗 [查看提交](https://github.com/sgl-project/sglang/commit/738b1ac988c36c1c5d03cf86f0806bdfd115720c)

**🎯 变更类型**：功能增强 / CI 测试扩展  
**⚡ 重要程度**：🟡 中  
**📋 变更摘要**：  
1. 将 AMD CI 工作流的并行分区从 2 改为 3，允许在单次任务中并行跑三个子集，从而加快大规模（8‑GPU）测试的整体时长。  
2. 新增 `test/registered/amd/test_kimi_k2_instruct.py`，为模型 `moonshotai/Kimi‑K2‑Instruct‑0905` 添加两项 CI 检查：GSM8K Few‑Shot 准确率 ≥ 0.94、单卡 2048 tokens 推理速度 ≥ 45 token/s。  

**🎯 影响范围**：  
- `.github/workflows/pr-test-amd.yml`（CI 调度、分区逻辑）  
- `sglang/test/registered/amd/`（新增测试文件）  
- 服务器启动脚本 `sglang/srt/utils.py`（进程管理）以及依赖的 `sglang/test/*`（评估、基准）  

**💡 关注建议**：  
1. **资源预估**：`auto-partition-size` 从 2→3 会在同一节点上多跑一个子任务，需确认 AMD CI 节点的 CPU/RAM 能够支撑额外的 `popen_launch_server` 实例，防止 OOM。  
2. **模型拉取**：`KIMI_K2_MODEL_PATH` 采用远端仓库，首次运行会下载数十 GB，建议在 CI 中缓存模型层（如 `actions/cache`），避免每次都重下载导致时间膨胀。  
3. **环境变量**：`SGLANG_USE_AITER=1`、`SGLANG_ROCM_FUSED_DECODE_MLA=0` 已显式设置，确保在不同硬件或未来 ROCm 版本升级时仍然兼容。可在 CI 注释中说明这些变量的作用。  
4. **阈值稳健性**：准确率阈值 0.94 与速度阈值 45 token/s 较为严格，若模型后端或硬件调度波动可能导致偶发失败。建议在 CI 中加入 `retry` 或 `allow-flake` 选项，或提供 `--max-retries` 参数。  
5. **测试顺序**：`test_a_gsm8k` 前缀 “a” 用于提前热身，这种依赖顺序的做法在并行分区中可能失效。若 CI 采用真正并行执行，需确保每个分区独立完成热身或改为 `setUpClass` 中统一热身。  

总体来看，此次改动有效提升 AMD CI 对新模型的覆盖率和并行效率，但请留意节点资源、模型缓存及阈值波动，以防导致 CI 不稳定或耗时激增。

---

### refactor mamba radix cache logic in server_args (#17645)
**SHA**: `5844cb2` | 🔗 [查看提交](https://github.com/sgl-project/sglang/commit/5844cb2fd82c43b2ab886f996dd08dd35f872228)

**🎯 变更类型**：重构 / 功能增强  
**⚡ 重要程度**：🟡 中  
**📋 变更摘要**：将原先散布在 `server_args.py` 中的 Mamba‑Radix‑Cache 相关逻辑抽取为统一的私有方法 `_handle_mamba_radix_cache`，并统一在各模型分支调用。新增对 SM100 平台默认 attention backend 的自动设定、对 radix‑cache 支持情况的统一警告以及对 extra‑buffer/无‑buffer 场景的断言检查。整体代码行数下降约 25%，可读性和维护性显著提升。

**🎯 影响范围**  
- `python/sglang/srt/server_args.py`（核心配置解析）  
- 间接影响所有依赖 `ServerArgs` 创建的启动脚本与模型兼容性判断（如 Nemotron、Qwen3、Falcon、Lfm2、Glm4 等）。

**💡 关注建议**  
1. **测试覆盖**：新增私有方法涉及多分支条件，确认已有单元/集成测试覆盖 `enable_mamba_extra_buffer`、`speculative_algorithm`、`attention_backend` 等组合，防止回归。  
2. **日志与使用文档**：`logger.warning` 信息已统一，但仍建议在 README/CLI 帮助中说明 `--disable-radix-cache`、`--attention-backend` 的交互影响。  
3. **异常路径**：在 `support_mamba_cache=False` 时直接 `self.disable_radix_cache = True` 并返回；若后续代码仍依赖 `self.disable_radix_cache` 的默认值，需确认不会出现未定义行为。  
4. **兼容性检查**：对 CUDA/FLC 后端的断言 (`is_cuda()`) 仍在方法内部，若在非 CUDA 环境下调用会抛异常，建议在入口处提前过滤或给出更友好的错误提示。  

总体而言，此次重构提升了代码结构清晰度，风险主要在条件分支的完整性与日志文案的一致性，建议补充相应测试并更新使用文档。

---

### Bump FI version (#17700)
**SHA**: `f6f1b6d` | 🔗 [查看提交](https://github.com/sgl-project/sglang/commit/f6f1b6d000b67a55df05467bd68b981aa6727531)

**🎯 变更类型**：其他（版本升级）  
**⚡ 重要程度**：🟡 中  

**📋 变更摘要**  
本次提交将 FlashInfer 相关依赖从 0.6.1 升级至 0.6.2。改动遍及 Docker 镜像构建、Python 包声明、运行时版本校验以及 CI 安装脚本，确保所有入口保持版本一致。

**🎯 影响范围**  
- `docker/Dockerfile`：镜像中 `FLASHINFER_VERSION` 变量更新。  
- `python/pyproject.toml`：`flashinfer_python`、`flashinfer_cubin` 依赖版本同步。  
- `python/sglang/srt/entrypoints/engine.py`：启动时的版本断言从 0.6.1 改为 0.6.2。  
- `scripts/ci/cuda/ci_install_dependency.sh`：CI 环境安装的 FlashInfer 版本同步。

**💡 关注建议**  
1. **兼容性验证**：检查 0.6.2 是否在当前 CUDA（cu129）和 Python 版本上有二进制 wheel，若无需自行编译。  
2. **功能/接口变更**：阅读 FlashInfer 0.6.2 的 release notes，确认是否有 API 调整或行为改动，避免运行时错误。  
3. **CI 与本地测试**：在 CI 与本地环境重新构建 Docker 镜像并跑全套单元/集成测试，确保模型推理、JIT 缓存等功能仍然正常。  
4. **文档同步**：更新 README、部署指南中的 FlashInfer 版本说明，提醒用户在自定义环境中统一使用 0.6.2。  
5. **回滚预案**：若发现不可预料的兼容性问题，保持 `docker/Dockerfile` 中旧版本注释，以便快速回滚。  

总体来看，改动聚焦于依赖版本统一，风险主要在于新版本的二进制兼容与潜在 API 变化，建议在升级前后完成完整回归测试。

---

### accuracy enhancement for baichuan2-13B for npu (#16868)
**SHA**: `2734b23` | 🔗 [查看提交](https://github.com/sgl-project/sglang/commit/2734b23481256288d3d3a2ab844d3623b21c87a0)

**🎯 变更类型**：功能增强  
**⚡ 重要程度**：🟡 中  
**📋 变更摘要**：为 Baichuan2‑13B 在 NPU（Ascend）上加入 Alibi 位置偏置支持，新增模型配置 `use_alibi`，在 NPU attention 后端实现了 Alibi 偏置生成与融合，并相应调整了 Baichuan‑2 层的初始化、前向路径以及测试脚本的 shot 数和 CI 配置。  

**🎯 影响范围**  
- `sglang/srt/configs/model_config.py`（模型配置扩展）  
- `sglang/srt/hardware_backend/npu/attention/ascend_backend.py`（NPU attention 实现）  
- `sglang/srt/models/baichuan.py`（Baichuan2‑13B 层实现）  
- 测试目录 `sglang/test/ascend` 与 CI 注册脚本  

**💡 关注建议**  
1. **设备分支**：`is_npu()` 的调用在模块层级使用了全局变量 `_is_npu`，请确保在非 NPU 环境导入时不会因未实现的 `torch_npu` 导致 ImportError。可以在 `except ImportError` 中回退到 CPU/CUDA。  
2. **Alibi 参数缓存**：`generate_alibi_bias` 在首次调用时缓存 `alibi_bias` 与 `super_mask`，但未在模型析构或长序列切换时更新，若 `max_position_embeddings` 超过 5000 仍会使用旧缓存，建议在 `max_seq_len` 变化时重新生成或加入显式的上界检查。  
3. **前向路径一致性**：在 `forward_extend` 与 `forward_decode` 中分别走 NPU FlashAttention 与 Alibi 分支，需确认 `slopes` 参数在两条路径均被正确传递（当前 `forward_decode` 里 `slopes` 通过 `self.attn_kwargs` 传递），避免出现 “None” 导致错误。  
4. **性能回归**：Alibi 计算涉及额外的张量创建与广播，建议在启用时对 `MAX_LEN_ALB` 进行调优，并在 CI 中加入对比基准（无 Alibi）以监控 latency / throughput 变化。  
5. **测试可靠性**：`gsm8k_num_shots` 由 5 改为 1 以加速 CI，但会降低统计显著性，建议在 nightly 中保留更高 shot 数的完整验证，或在 PR 中注明此改动仅用于快速回归。  
6. **文档/使用说明**：在模型配置说明和 README 中添加 `use_alibi` 触发条件（`hidden_size != 4096`）以及与 `--attention-backend ascend` 的配合方式，帮助用户快速开启该特性。  

总体来看，改动为 Baichuan2‑13B 在 Ascend 上的准确率提升提供了必需的 Alibi 支持，逻辑实现清晰。但需注意上述细节以防止跨设备兼容性和潜在的性能回退。

---

### [diffusion] fix: fix missing backend argument in pipelines_core initialization (#17343)
**SHA**: `12f794e` | 🔗 [查看提交](https://github.com/sgl-project/sglang/commit/12f794e51686a765aaf659e4f92ff7badc8f4121)

**🎯 变更类型**：Bug 修复  
**⚡ 重要程度**：🟡 中  

**📋 变更摘要**  
此次提交修复了在多模态生成管线初始化时未向 `get_model_info` 传递 `backend` 参数导致的后端选型失效问题。所有读取模型信息的入口统一改为 `get_model_info(model_path, backend=…)`，并在 `SamplingParams.from_pretrained` 中弹出 `backend` 参数，以免被误传给下游构造函数。

**🎯 影响范围**  
- `python/sglang/multimodal_gen/configs/pipeline_configs/base.py`  
- `python/sglang/multimodal_gen/configs/sample/sampling_params.py`  
- `python/sglang/multimodal_gen/runtime/entrypoints/openai/common_api.py`  
- `python/sglang/multimodal_gen/runtime/pipelines_core/__init__.py`

**💡 关注建议**  
1. **后端默认行为**：`get_model_info` 若 `backend=None` 仍需保持原有的自动推断逻辑，防止在未显式指定时出现回退错误。  
2. **参数传递安全**：`SamplingParams.from_pretrained` 使用 `pop("backend")` 移除自定义字段，避免意外传入不被接受的参数。确认其它 `from_pretrained` 实现同样遵循此模式。  
3. **文档同步**：在 README 与 API 文档中补充 “backend 参数的使用方式” 说明，尤其是通过 OpenAI 接口调用时需要的 `server_args.backend`。  
4. **测试覆盖**：新增或扩展单元测试，验证：  
   - 在 `backend` 为 `torch`、`vllm` 等不同值时，`get_model_info` 能返回对应的 `pipeline_cls`、`sampling_param_cls`。  
   - 未传 `backend` 时仍保持向后兼容。  
   - API `/v1/models`、`/v1/engines/{model}` 返回的模型信息包含正确的后端标识。  
5. **回滚风险**：该改动仅涉及参数转发，未改变业务逻辑，回滚成本低。但如果新版 `get_model_info` 接口签名在未来再次变更，需同步更新所有调用点。  

总体而言，本次修复恢复了多后端模型的正确加载，对现有功能影响有限，主要提升了可配置性和稳定性。建议在下一个发布候选版中加入上述测试，以防止类似遗漏再次出现。

---

### update wasm endpoint (#17748)
**SHA**: `d4adff3` | 🔗 [查看提交](https://github.com/sgl-project/sglang/commit/d4adff31aa8e6d05a4eb91b6acce9ae70ac49b6d)

**🎯 变更类型**：功能增强（为模型网关新增 WASM 管理 HTTP 接口）  
**⚡ 重要程度**：🟡 中  
**📋 变更摘要**：  
1. 在 `sgl-model-gateway` 的 `Cargo.toml` 中删除了 `wasmtime-wasi、async-channel、aho-corasick` 等依赖，保持 `wasmtime`（带 component‑model 与 async）即可。  
2. 新增 `src/wasm/mod.rs` 负责把 `smg-wasm` crate 重新导出，并声明本地路由模块 `route`。  
3. 新增 `src/wasm/route.rs`，实现了 **POST /wasm**（添加模块）、**DELETE /wasm/:uuid**（删除模块）以及 **GET /wasm**（列举模块+统计）三套 REST 接口，使用 Axum、Uuid、Json 等通用组件，并通过已有的 `JobQueue` 与 `WasmManager` 完成异步作业调度和结果轮询。

**🎯 影响范围**  
- `sgl-model-gateway` 的构建配置（依赖树、编译时间）  
- `sgl-model-gateway/src/core/*` 中的 `job_queue`、`steps`、`wasm` 类型（新增的请求/响应结构体）  
- 运行时：网关服务将暴露新的 HTTP 路径，需要在路由注册处加入 `wasm::route`（当前提交未更新路由集合，外部调用仍不可达）  
- 依赖的外部 crate：`smg-wasm`（重新导出）以及 `uuid`、`axum`（已在项目中使用）  

**💡 关注建议**  

| 关注点 | 建议 |
|--------|------|
| **依赖变更** | 删除的 `wasmtime-wasi、async-channel、aho-corasick` 可能被 `smg-wasm` 或内部代码间接使用，需确认编译无遗漏；建议在 CI 中加入 `cargo check --all-targets` 验证。 |
| **路由注册** | 当前仅新增 `route.rs`，但未在 `router` 初始化处加入 `wasm` 路径，导致接口 404。请在 `src/server.rs`（或等价文件）中添加 `router = router.nest("/wasm", wasm::route::router())`（自行实现 `router` 函数）。 |
| **错误处理** | `wait_for_job_completion` 在成功返回时只能得到 `"Job completed successfully"`，随后依赖 `wasm_manager.get_modules()` 来找 UUID，若模块名冲突会返回错误。建议在 `Job` 完成时直接返回 UUID（可在 `JobResult` 中增加字段），简化后续查询。 |
| **超时/轮询** | 轮询间隔上限 2 s，最大等待 5 min（添加）/1 min（删除），在高负载下可能导致请求阻塞。可考虑使用 `tokio::select!` 与 `Notify` 机制，或让 `JobQueue` 支持回调。 |
| **并发安全** | `state.context.wasm_manager` 通过 `Option<Arc<...>>` 访问，已使用 `as_ref`，但在成功获取后仍未持有 `Arc`，若在轮询期间被其他线程释放可能 panic。建议提前 `let wasm_manager = state.context.wasm_manager.clone().unwrap();` 并传递引用。 |
| **日志/监控** | 接口目前只返回状态码和简短信息，缺少日志。建议在关键路径（提交 job、轮询超时、查询结果）加入 `tracing::info!`/`error!`，并把 `WasmMetrics` 暴露给 Prometheus（项目已使用 `metrics-exporter‑prometheus`）。 |
| **测试覆盖** | 添加单元/集成测试验证：① 添加已存在模块返回错误，② 删除不存在 UUID 返回 400，③ 列表返回正确 metrics。可在 `tests/wasm_endpoint.rs` 中使用 `axum::Router::into_make_service` 进行端到端调用。 |
| **文档** | 更新 `README` 或 API 文档，说明新增的 `/wasm` 路径、请求体结构（`WasmModuleAddRequest`）以及返回字段。 |

总体来看，此次 PR 为模型网关引入了可运营的 WASM 模块管理能力，代码结构清晰、错误回滚较完整。但在 **路由挂载、返回信息的可观测性以及依赖一致性** 上仍有可提升空间，按上述建议完善后即可安全合并。

---

### Merge performance/accuracy test suites into regular stage-b suites (#17609)
**SHA**: `30b3192` | 🔗 [查看提交](https://github.com/sgl-project/sglang/commit/30b3192039b0aabdc816ffe8cd5912e107b113d9)

**🎯 变更类型**：功能增强（将原有的 performance / accuracy 测试合并进普通的 stage‑b 测试套件）  

**⚡ 重要程度**：🟡 中  

**📋 变更摘要**  
1. CI 工作流 `pr-test.yml` 中删除了单独的 performance、accuracy job，改为在 `stage-b-test‑large‑1‑gpu`、`stage-b-test‑large‑2‑gpu`、`stage-b-test‑small‑1‑gpu` 等常规 stage‑b job 中通过矩阵划分跑完；相应地更新了 `expectedCount` 与分区列表。  
2. 在 GPU 环境下统一安装 `human-eval`（用于准确率评估），并在 `test_utils.py` 增加对 benchmark 输出的三项指标（prefill_latency、decode_throughput、decode_latency）未解析成功时的显式异常。  
3. 大量 `test/registered/*` 文件中把 `suite` 名称从 `*-performance`、`*-accuracy` 改为统一的 `stage-b-test‑*`，并在 `run_suite.py` 中同步删除对应的套件常量。  

**🎯 影响范围**  
- CI 运行时长与调度逻辑（`.github/workflows/pr-test.yml`、`test/run_suite.py`）。  
- 依赖 `human-eval` 的准确率测试（`test/utils.py`、`test/registered/eval/*`）。  
- 基准测试解析（`test_utils.py`）若输出格式变化将触发 RuntimeError。  

**💡 关注建议**  
1. **CI 稳定性**：合并后 stage‑b job 的矩阵分区从 12 → 14、4 → 4 等，需要确认 `auto‑partition-size` 与 `--timeout-per-file` 参数匹配实际测试量，防止因超时或资源不足导致 CI 失效。  
2. **网络依赖**：每次 CI 会 `git clone https://github.com/merrymercy/human-eval.git`，建议在仓库根目录添加缓存步骤（`actions/cache`）或使用 `actions/checkout` 的子模块方式，避免网络波动导致 CI 卡死。  
3. **基准输出兼容性**：`run_bench_one_batch` 现在在未能解析三项指标时抛异常，务必在本地跑一次基准，确认输出正则仍能匹配；若后续模型或脚本改动导致日志格式变化，需要同步更新解析逻辑。  
4. **文档与监控**：CI 中不再出现 `*-performance`、`*-accuracy` 的 job 名称，相关监控（Grafana、CI 报表）应同步更新，以免误报缺失。  
5. **回退方案**：若合并后出现大量 flaky job，保留原始 performance/accuracy job 的代码（可在分支中临时恢复）以便快速定位问题。  

整体来看，此次合并减少了 CI 配置的冗余，提升了维护性，但也把更多测试压在同一套 job 中，务必关注资源配额、超时设置以及对外依赖的可靠性。

---

### [NIXL] Add custom NIXL backend selection for KVManager (#17146)
**SHA**: `d275d47` | 🔗 [查看提交](https://github.com/sgl-project/sglang/commit/d275d4797352e6ca4f3241e51adf545966663d13)

**变更类型**：功能增强  
**重要程度**：🟡 中  

**变更摘要**  
- 为 KVManager 引入 `SGLANG_DISAGGREGATION_NIXL_BACKEND` 环境变量，允许在 NIXL KV‑cache 迁移时显式指定后端插件（默认 UCX）。  
- 在 `nixl/conn.py` 中使用 `nixl_agent_config` 创建 agent，读取变量并校验插件可用性后动态创建对应后端；同时新增日志输出。  
- 文档补充了后端选择的说明和使用示例。  

**影响范围**  
- `sglang/srt/disaggregation/nixl/conn.py`（连接层初始化）  
- `sglang/srt/environ.py`（新增环境变量）  
- `docs/advanced_features/pd_disaggregation.md`（使用文档）  

**关注建议**  

1. **兼容性**：`nixl_agent_config` 及 `create_backend` 是 NIXL v0.?.* 之后的 API，若用户装的是旧版 NIXL 会出现 ImportError。建议在 `ImportError` 捕获中加入对 `nixl_agent_config` 不可用的回退方案或明确报错信息。  
2. **变量校验**：当前直接使用 `envs.SGLANG_DISAGGREGATION_NIXL_BACKEND.get()`，若用户设置了空字符串会导致 `backend not in available_plugins` 的误报。可在读取后做一次 `backend = backend.strip() or "UCX"` 的容错处理。  
3. **大小写统一**：插件列表可能返回大写/小写混合，建议在比较前统一为同一大小写（如 `backend.upper()`），避免因大小写不匹配而报错。  
4. **日志级别**：`logger.info` 已记录后端信息，建议在异常分支使用 `logger.error` 并附带堆栈，以便定位插件缺失问题。  
5. **测试覆盖**：新增环境变量与后端动态创建的路径，需要添加单元测试：① 默认 UCX 正常启动；② 指定合法后端成功；③ 指定非法后端抛出 `ValueError`。  
6. **文档同步**：README 中若列出默认后端或插件安装指南，请同步更新，以免产生误导。  

总体而言，此次改动为用户提供了灵活的后端选择，提升了在不同网络堆栈（UCX、LIBFABRIC 等）上的可部署性。只要做好兼容性检查和参数容错，即可平滑发布。

---

### [Bugfix]Repeated add modelslim quant_config and bugfix with "enable-piecewise-cuda-graph" on NPU (#17511)
**SHA**: `444b952` | 🔗 [查看提交](https://github.com/sgl-project/sglang/commit/444b9521e4d7af86d2d141c95d4714a23206f922)

**🎯 变更类型**：Bug修复 / 轻微功能增强  
**⚡ 重要程度**：🟡 中  
**📋 变更摘要**：  
1. 修正 `model_config` 中量化配置的解析逻辑，避免在同时存在 HF 与 ModelSlim 配置时重复添加导致的冲突。  
2. 调整 `scheduler` 中对 CPU 组的引用，改为使用已统一的 `tp_cpu_group`，防止在多卡/TP 场景下出现未定义属性。  
3. 在 LLaMA、Qwen3 与 Qwen3‑MoE 的前向实现中，对 NPU 环境和 `forward_mode.is_extend()` 做额外判断，防止在非 NPU 或扩展模式下调用不存在的 rotary 方法或缓存路径。  
4. 针对 NPU 场景加入对 `enable_piecewise_cuda_graph` 参数的兼容处理，避免在开启该特性时误使用 NPU‑only 的缓存权重。

**🎯 影响范围**：  
- `python/sglang/srt/configs/model_config.py`（量化配置解析）  
- `python/sglang/srt/managers/scheduler.py`（调度器 CPU 组）  
- `python/sglang/srt/models/llama.py`、`qwen3.py`、`qwen3_moe.py`（模型前向路径）  

**💡 关注建议**  
1. **回归测试**：在 HF、ModelSlim 双量化配置下跑完整的模型加载与推理，确认不再出现 `ValueError` 或重复配置报错。  
2. **NPU/CPU 多环境验证**：分别在纯 CPU、GPU、NPU 三类硬件上执行推理，确保 `forward_mode.is_extend()` 分支、`_is_npu` 条件均能正常走通。  
3. **piecewise CUDA Graph**：开启 `enable_piecewise_cuda_graph` 时，验证 NPU 仍能正确使用或回退到普通缓存路径，避免潜在的显存泄漏或错误。  
4. **文档/配置提示**：在 `model_config` 或服务器启动说明中加入 “HF 与 ModelSlim 只能提供其一的量化配置，若同时存在将以 ModelSlim 为准” 的提示，帮助使用者排查配置冲突。  
5. **性能监控**：关注调度器 `PrefillDelayer` 中 `cpu_group` 替换后对吞吐量的影响，必要时在多卡 TP 场景下做基准对比。  

总体来看，此次修改主要解决了量化配置冲突和 NPU/扩展前向模式下的崩溃问题，改动范围适中，对现有功能的兼容性提升明显。建议在发布前完成上述测试，以确保跨平台的稳定性。

---

### Fix flaky streaming logprobs test by handling detokenizer text buffering (#17687)
**SHA**: `592603d` | 🔗 [查看提交](https://github.com/sgl-project/sglang/commit/592603d77beaa6a1b5d6f5a54e90c690a2206200)

**🎯 变更类型**：Bug修复  
**⚡ 重要程度**：🟡 中  

**📋 变更摘要**  
1. 在 `serving_chat.py` 与 `serving_completions.py` 的流式生成路径中，新增对 `finish_reason` 与 detokenizer 缓冲文本的判断。  
2. 当 `finish_reason` 已置且本次返回仅为缓冲的文本（无新 token）时，返回 `logprobs=None`，并正确维护 `n_prev_tokens` 计数。  
3. 相应测试 `test_openai_server.py` 改写断言，以容忍 `logprobs` 为 `None` 的情况，消除原先因缓冲文本导致的随机失效。  

**🎯 影响范围**  
- `python/sglang/srt/entrypoints/openai/serving_chat.py`  
- `python/sglang/srt/entrypoints/openai/serving_completions.py`  
- `test/registered/openai_server/basic/test_openai_server.py`  

**💡 关注建议**  
- 请确认 `finish_reason` 为 `stop`、`length` 等不同类型时，仍能正确更新 `n_prev_tokens`，防止后续块出现 token 漏计。  
- 建议在 CI 中加入 “只返回缓冲文本” 的专门场景，用以验证 `logprobs` 为 `None` 的行为符合 OpenAI 兼容性。  
- 由于修改了流式路径的分支逻辑，留意可能的性能微增（额外的条件判断），但影响应在毫秒级，可通过基准测试进一步确认。  

整体来看，此次改动定位明确，修复了 flaky 测试，并提升了流式输出在 detokenizer 缓冲阶段的鲁棒性，风险可控。

---

### Upload nightly test metrics to GH artifacts (#17696)
**SHA**: `344eeae` | 🔗 [查看提交](https://github.com/sgl-project/sglang/commit/344eeaee90e3a926340bb92b589c93527a1b2447)

**🎯 变更类型**：功能增强（CI Metrics 收集与合并）  
**⚡ 重要程度**：🟡 中  
**📋 变更摘要**：在 nightly‑test‑nvidia 工作流中新增 “Collect performance metrics → Upload partition metrics” 步骤，并加入统一的 `consolidate‑metrics` job。同步实现 `scripts/ci/save_metrics.py、merge_metrics.py` 两个工具，用于把各分区的 `results_*.json` 转为统一的 metrics JSON 并在 CI 中归档。代码层面，benchmark 相关 API 添加 `server_args_for_metrics` 参数，并在 Pydantic 模型、命令构造、结果保存等处传播，以记录服务器启动配置。

**🎯 影响范围**  
- CI 工作流（`.github/workflows/nightly-test-nvidia.yml`）  
- 绩效基准入口 `bench_one_batch_server.py`、`bench_one_batch_server_internal.py`  
- `nightly_utils.py`、`nightly_bench_utils.py`、`performance_test_runner.py` 中的结果序列化逻辑  
- 新增脚本 `scripts/ci/save_metrics.py`、`scripts/ci/merge_metrics.py`  
- 可能依赖 metrics JSON 的后续分析/展示工具

**💡 关注建议**  
1. **兼容性**：新增 `--server-args-for-metrics` 为可选参数，默认 `None`，不影响现有基准。确认所有调用 `run_suite.py`、`run_benchmark` 的位置均未硬编码 `--server-args-for-metrics`。  
2. **脚本健壮性**：`save_metrics.py` 与 `merge_metrics.py` 在找不到文件时仍会生成空文件，建议在 CI 中加入检查，防止误报空 metrics。  
3. **Artifact 大小**：每个分区会产生单独的 JSON，累计可能较大。监控 `retention-days=5` 与 `consolidated‑metrics` 的 `90 天` 保存策略是否符合成本预期。  
4. **Schema 统一**：`BenchmarkResult` 新增 `server_args` 字段，确保所有读取该模型的下游代码（如 Dashboard、报告生成）已同步更新。  
5. **本地验证**：在本地运行 `python scripts/ci/save_metrics.py …`，确认能正确从 `test/performance_profiles_*` 中收集结果并生成期望结构。  
6. **文档**：在 CI 文档或 benchmark 使用说明中加入 “metrics 收集” 的说明，尤其是 `--server-args-for-metrics` 的用途。  

总体而言，此次改动为 nightly 基准提供了可追溯、可比对的性能数据，提升了回归分析能力。只要注意上述兼容性与产出大小控制，即可安全合并。

---

### [model-gateway] Optimize special token search using Aho-Corasick (#17387)
**SHA**: `fc7096f` | 🔗 [查看提交](https://github.com/sgl-project/sglang/commit/fc7096f80b14240a0a0fdecc79dc570c8620d219)

**🎯 变更类型**：功能增强（特化的停止序列检测）  
**⚡ 重要程度**：🟡 中  

**📋 变更摘要**  
1. 为 `sgl-model-gateway` 引入 `aho-corasick` 依赖，并新增基准测试 `special_token_search.rs` 用于比较朴素 `find` 与 AC 自动机的性能。  
2. `StopSequenceDecoder` 由原先逐个 `find` 的实现改为一次性构建 `AhoCorasick` 自动机，统一处理隐藏与可见停止序列，并通过 `visible_boundary_idx` 区分两类匹配结果。  

**🎯 影响范围**  
- `sgl-model-gateway/src/tokenizer/stop.rs`（核心解码逻辑）  
- `Cargo.toml`（新增依赖与 bench 配置）  
- `benches/special_token_search.rs`（性能基准）  

**💡 关注建议**  
1. **行为等价**：AC 自动机的匹配顺序与原始 `find` 可能不同，尤其在多个停用序列冲突或重叠时。建议补充单元测试，覆盖空串、重复、前缀/后缀重叠等边界情况，确保 `Stopped` 与 `StoppedWithText` 的返回仍保持语义一致。  
2. **可见/隐藏分界**：`visible_boundary_idx` 依赖 pattern 插入顺序（先隐藏后可见），若未来配置顺序变更需同步更新该索引。可以在构造函数中显式记录两段长度，以防止未来维护错误。  
3. **内存与并发**：`AhoCorasick` 实例在 `StopSequenceDecoder` 中保存为 `Option<AhoCorasick>`，其实现是 `Send + Sync`，但请确认解码器在多线程环境下的共享方式（如 `Arc`）仍符合预期。  
4. **回退路径**：虽然构建 AC 失败的概率极低（仅在 pattern 无效时），保留 `Option` 已是安全做法。可考虑在 `expect` 前加入更友好的错误信息，避免 panic 影响生产服务。  
5. **基准维护**：criterion 基准会拉长 CI 编译时间，建议在 CI 中仅在特定标签或手动触发时运行。  

总体来看，此次改动在大量停用序列（≥50）时能显著提升检测速度，风险主要在行为一致性和索引维护上，建议通过更完整的测试套件加以验证。

---

### [smg] use official tokenizer crate instead of manually built one (#17721)
**SHA**: `f5ac1ca` | 🔗 [查看提交](https://github.com/sgl-project/sglang/commit/f5ac1ca10b62b2e9b0937c6dcb36e15eadc9214c)

**🎯 变更类型**：功能增强 / 重构  
**⚡ 重要程度**：🟡 中  

**📋 变更摘要**  
- 在 `sgl-model-gateway` 中将自研的 tokenizer 替换为官方的 `llm-tokenizer` crate（`Cargo.toml` 新增 `llm-tokenizer = "1.0.0"`）。  
- 删除了原先用于手工实现的庞大基准测试文件（`tokenizer_benchmark.rs`、`tool_parser_benchmark.rs` 等），相应地在 `Cargo.toml` 中移除了这些 bench 配置。  
- `src/lib.rs` 通过 `pub use llm_tokenizer as tokenizer;` 将新库重新导出，保持原有模块路径不变。

**🎯 影响范围**  
- **tokenizer 相关模块**：`sgl-model-gateway/src/tokenizer/*`（已被外部 crate 替代），以及所有直接或间接调用 `smg::tokenizer` 的业务代码（模型推理、缓存、流式解码等）。  
- **基准测试**：原有 tokenizer/工具解析基准已被删除，可能影响 CI 中的 benchmark 目标。  
- **依赖树**：新增 `llm-tokenizer`，并删除了 `tiktoken-rs`（仍保留）等旧实现，可能触发编译或 ABI 兼容性问题。  

**💡 关注建议**  

1. **兼容性验证**  
   - 确认 `llm-tokenizer` 的 API 与原项目中使用的 `encode / decode / token_ids` 等方法签名保持一致，尤其是错误类型和默认参数。  
   - 在本地跑通所有单元测试和集成测试，重点检查跨模型（Qwen、Llama、Mistral 等）特殊 token（如 `<|im_start|>`）的处理是否仍然符合预期。  

2. **性能回归**  
   - 虽然官方实现通常更优，但删除自研 benchmark 可能导致缺少对比数据。建议在 CI 中重新添加简化的 benchmark（如 encode/decode 吞吐），确保新实现至少不低于历史基准。  

3. **依赖管理**  
   - 检查 `llm-tokenizer` 的特性（例如 `unstable`、`tokio`）在当前平台是否全部启用，避免因默认特性差异导致编译失败。  
   - 确认 `Cargo.toml` 中的 `features` 与其它 crate（如 `reasoning-parser`、`openai-protocol`）的互斥或共用特性没有冲突。  

4. **文档与升级指南**  
   - 在项目 README 或 CHANGELOG 中说明从手工 tokenizer 切换到官方 crate 的原因、使用方式以及迁移注意点，帮助 downstream 开发者快速适配。  

5. **回滚路径**  
   - 保留旧 tokenizer 代码的 tag（如 `vX.Y-tokenizer-legacy`），以防新实现在某些极端模型或特殊字符集上出现不可预期的行为，能够快速回滚。  

总体而言，此次改动通过引入成熟的 `llm-tokenizer` 降低了维护成本并有望提升 token 处理性能，但需在完整测试、基准对比以及依赖兼容性上进行细致验证，确保生产环境平滑过渡。

---

### A few updates to the night tests (#17694)
**SHA**: `9123491` | 🔗 [查看提交](https://github.com/sgl-project/sglang/commit/9123491430c9cc38b6796cbf3ad3ef07e948e8c9)

**🛠 变更概览**  
- **核心功能**：在 `AccuracyTestResult` 中加入 `variant` 字段；GitHub Summary 表头改为 `config`，并在输出时优先展示 `variant`；`run_accuracy_test` 传递 `model.variant`。  
- **测试名称统一**：将多个模型的 `test_name` 中的 “Unified” 去掉，使名称更简洁。  
- **Qwen‑3‑235B 扩展**：新增 FP8 版本模型路径并拆分为两套变体（普通 TP8 与 TP8+EP2+EAGLE3），去掉对 Blackwell 系统的依赖，只保留通用 CUDA CI。  
- **小幅参数调整**：部分模型的 `extra_args`、`variant` 名称以及性能基准目录均同步更改。

**⚡ 影响范围**  
- `python/sglang/test/accuracy_test_runner.py`（结果结构、摘要生成）  
- 所有 `test/registered/*` 中对 `run_combined_tests` 的调用（名称、variant 传递）  
- CI 夜间跑测试脚本（新增 Qwen‑3‑235B‑FP8 变体）  

**🔍 注意点 & 建议**  
1. **向后兼容**：若其他模块（如报告解析、历史 CI 脚本）仍依赖 `result.model` 字段，需要同步改为使用 `variant` 或保持兼容。  
2. **文档更新**：在 README/CONTRIBUTING 中说明 `variant` 的含义以及新的测试命名规则，避免混淆。  
3. **CI 环境**：确保所有 GPU 镜像已预装 FP8 相关依赖，否则新增的 FP8 变体可能在旧环境下失败。  
4. **基准阈值**：`baseline_accuracy` 在新 FP8 变体上可能与原模型不同，建议在后续 PR 中根据实际测得值微调。  
5. **防止遗漏**：搜索仓库中对 `write_accuracy_github_summary` 的调用，确认新表头不会破坏已有的 Markdown 渲染或自动化解析。  

总体而言，此次更新提升了多变体模型的可辨识度并扩展了 Qwen‑3‑235B 的测试覆盖，影响范围主要在测试层和结果展示层，按上述建议完善即可平滑过渡。

---

### Support mxint4 flashinfer_trtllm moe gemm (#16892)
**SHA**: `a883906` | 🔗 [查看提交](https://github.com/sgl-project/sglang/commit/a883906a248a28981672018f76458943b0e63cac)

**🎯 变更类型**：功能增强  
**⚡ 重要程度**：🟡 中  

**📋 变更摘要**  
1. 为 MoE（Mixture‑of‑Experts）层新增 `CompressedTensorsMxInt4MoEMethod`，实现对 FlashInfer‑TRTLLM mxint4 量化格式的支持。  
2. 在 `layer.py`、`moe_runner/base.py` 与量化配置中加入 `routing_method_type`、`routed_scaling_factor` 参数的传递与使用。  
3. 扩展 `CompressedTensorsConfig` 检测逻辑，能够识别 `mxint4a16`（4‑bit、group‑size 32）并在后端为 FlashInfer‑TRTLLM 时自动选用新方法。  
4. 实现权重的重新打包、permute、block‑layout 转换以及 `trtllm_mxint4_block_scale_moe` 核心调用，实现高效的 mxint4 GEMM。  

**🎯 影响范围**  
- `sglang.srt.layers.moe`：MoE 运行时配置、调度、前向计算全部涉及。  
- `sglang.srt.layers.quantization.compressed_tensors`：新增量化检测与权重处理路径。  
- 依赖 FlashInfer (>=0.3) 与 TRT‑LLM 后端的环境；仅在 `is_flashinfer_available()` 为真且后端为 `flashinfer_trtllm` 时生效。  

**💡 关注建议**  
- **兼容性**：新方法只能在 BFloat16 参数类型、对称量化、无 actorder 的条件下使用，升级前确认模型满足这些约束。  
- **部署**：确保运行节点安装了 FlashInfer 与对应的 CUDA/NVIDIA 驱动，否则会回落到原有 WNA16 路径。  
- **调试**：`routing_method_type`（DeepSeekV3 等）会强制将路由 logits 转 float32；若出现精度异常，请检查 routing 配置。  
- **性能评估**：建议在实际推理工作负载下对比 mxint4 与现有 WNA16/FP8 路径的吞吐与显存占用，验证 `routed_scaling_factor` 是否需要手动调节。  

整体来看，此次提交为 FlashInfer‑TRTLLM 的 4‑bit mxint4 MoE 加速提供了完整实现，能够显著降低显存并提升推理速度，但受限于后端和量化前提，使用前请做好环境与模型检查。

---

#### 🟢 低重要度变更 (13)

### Add test_gpt_oss_4gpu.py to B200 test suite (#17743)
**SHA**: `6c0f9b4` | 🔗 [查看提交](https://github.com/sgl-project/sglang/commit/6c0f9b4824acce6ed6394baf00606839b3216750)

**🎯 变更类型**：测试修改  
**⚡ 重要程度**：🟢 低  
**📋 摘要**：在 B200 测试套件的 `per-commit-4-gpu-b200` 列表中新增 `test_gpt_oss_4gpu.py`（超时时长 300 秒），无其他代码改动。

---

### Exclude some diffusion package for ARM in docker release (#17745)
**SHA**: `48f4340` | 🔗 [查看提交](https://github.com/sgl-project/sglang/commit/48f4340b149f5438c4c21df18bae3e666b174b6b)

**🎯 变更类型**：配置调整  
**⚡ 重要程度**：🟢低  
**📋 摘要**：在 `python/pyproject.toml` 中为 `st_attn==0.0.7` 与 `vsa==0.0.4` 添加 `platform_machine != 'aarch64' and platform_machine != 'arm64'` 条件，避免在 ARM 架构 Docker 镜像中安装这些 diffusion 包。

---

### [model-gateway] fix wasm example2 (#17244)
**SHA**: `8c2d8b5` | 🔗 [查看提交](https://github.com/sgl-project/sglang/commit/8c2d8b51e902bbb26d3d1b4083777a619951cf9c)

**🎯 变更类型**：代码重构  
**⚡ 重要程度**：🟢低  
**📋 摘要**：在 WASM 示例 `wasm-guest-logging` 中，将原先引入的 `sgl::router` 相关模块改为 `sgl::model_gateway`，保持中间件实现逻辑不变，仅更新路径以匹配新库结构。

---

### [model-gateway] fix wasm example3 (#17277)
**SHA**: `02c1dab` | 🔗 [查看提交](https://github.com/sgl-project/sglang/commit/02c1dabf5da6cf42aa40099c93b681ce749a09cf)

**🎯 变更类型**：代码重构  
**⚡ 重要程度**：🟢低  
**📋 摘要**：修正 wasm 示例的导入路径，将 `router` 相关模块改为 `model_gateway`，并相应更新类型引用。

---

### [model-gateway] Optimize WASM cache lookups using SHA-256 (#17344)
**SHA**: `5119618` | 🔗 [查看提交](https://github.com/sgl-project/sglang/commit/511961870f9527d75e1b5fff4ea8c3947c0caf68)

**🎯 变更类型**：代码重构  
**⚡ 重要程度**：🟢低  
**📋 摘要**：在 WASM 模块执行路径中加入 SHA‑256 哈希，改为以哈希而非完整字节进行缓存键值，实现缓存查询更快、更省内存。全部涉及 `module_manager.rs`、`runtime.rs` 等相关函数签名及缓存结构的调整。

---

### [Kimi-Linear] Remove duplicated code in kimi-linear (#17731)
**SHA**: `1e8db18` | 🔗 [查看提交](https://github.com/sgl-project/sglang/commit/1e8db1829096392a7b2bebc8fd92b239495ec2cd)

**🎯 变更类型**：代码重构  
**⚡ 重要程度**：🟢低  
**📋 摘要**：在 `kimi_linear.py` 中删除了多余的 `beta = self.b_proj(hidden_states)[0].float()` 赋值，仅保留一次计算，消除重复代码，保持功能不变。

---

### Update nightly-test-nvidia.yml to remove push trigger (#17625)
**SHA**: `52e0f65` | 🔗 [查看提交](https://github.com/sgl-project/sglang/commit/52e0f65fcecd760ce420f8e9005f3e936670a232)

**🎯 变更类型**：配置调整  
**⚡ 重要程度**：🟢低  
**📋 摘要**：在 `.github/workflows/nightly-test-nvidia.yml` 中删除了对 `main` 分支的 push 触发及文件路径限制，仅保留定时和手动触发。

---

### Add EP=2 to qwen235b nightly tests (#17738)
**SHA**: `5aaedac` | 🔗 [查看提交](https://github.com/sgl-project/sglang/commit/5aaedac3c64583569c21e5ca220525a3325eada7)

**🎯 变更类型**：测试修改  
**⚡ 重要程度**：🟢低  
**📋 摘要**：在 Qwen3-235B FP8 测试用例中新增 `--ep=2` 参数并删除重复的同项配置。

---

### Fix sgl-kernel install: fail instead of PyPI fallback when artifacts missing (#17728)
**SHA**: `7b22b8f` | 🔗 [查看提交](https://github.com/sgl-project/sglang/commit/7b22b8ff8a34535b2aa25db642f2d86f82fd22cc)

**🎯 变更类型**：配置调整  
**⚡ 重要程度**：🟢低  
**📋 摘要**：在 CI 安装脚本 `ci_install_dependency.sh` 中，当 `CUSTOM_BUILD_SGL_KERNEL=true` 且未找到本地 `sgl-kernel/dist` 构建产物时，改为直接报错并退出，而不再回退到 PyPI 安装，确保测试使用实际构建的内核。

---

### [misc] remove tool parser and tree benchmark as they are not meaningful atm (#17719)
**SHA**: `48f5c46` | 🔗 [查看提交](https://github.com/sgl-project/sglang/commit/48f5c46a8d12b3ca2babf8358f3555284f746437)

**🎯 变更类型**：配置调整  
**⚡ 重要程度**：🟢 低  
**📋 摘要**：在 GitHub Workflow `pr-benchmark-rust.yml` 中删除了 Tokenizer、Tool Parser、Tree 三项基准的配置及对应的报告生成步骤，保留其余基准。

---

### Extend b200 kernel tests timeout for CPU differences (#17718)
**SHA**: `7ca8c12` | 🔗 [查看提交](https://github.com/sgl-project/sglang/commit/7ca8c12e0e4b7dc81303a582cb0f29fd28a59bd9)

**🎯 变更类型**：配置调整  
**⚡ 重要程度**：🟢低  
**📋 摘要**：将 GitHub Action 中 FA4 jit_kernel 测试的超时时间从 5 分钟提升至 10 分钟，以兼容不同 CPU 环境导致的执行时间波动。

---

### [smg] update crate for tools (#17717)
**SHA**: `86c7bc6` | 🔗 [查看提交](https://github.com/sgl-project/sglang/commit/86c7bc6431d27890a68d7a5c67928d45813e5cb8)

**🎯 变更类型**：代码重构 / 配置调整  
**⚡ 重要程度**：🟢低  
**📋 摘要**：在 `sgl-model-gateway` 的 Cargo.toml 中新增 `tool-parser = "1.0.0"` 依赖，并将 `tool_parser` 模块改为 `pub use tool_parser;` 进行公开重导，提升库的可访问性。

---

### Add an all type in pyproject.tml to include diffusion support (#17697)
**SHA**: `8d3e1ac` | 🔗 [查看提交](https://github.com/sgl-project/sglang/commit/8d3e1ac0c8906fa47994d325fa1a32269bac95b5)

**🎯 变更类型**：配置调整  
**⚡ 重要程度**：🟢低  
**📋 摘要**：在 `python/pyproject.toml` 中新增 `all` 扩展组，统一包含 `sglang[diffusion]` 与 `sglang[tracing]`，便于一次性安装全部功能。

---

