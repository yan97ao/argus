# 每日更新报告（2026-01-17）

## sgl-project/sglang

| 提交时间 | 作者 | 提交信息 |
|----------|------|----------|
| 2026-01-17 21:29:22 | Michael | Revert "[Diffusion] Move diffusion time embedding to jit kernel" (#17257) |
| 2026-01-17 17:12:51 | fzyzcjy | Change routing policy API to be async to support more policies (#17048) |
| 2026-01-17 16:48:15 | Zehuan Li | [DLLM] Implement initial dynamic batching for diffusion LLM (#14883) |
| 2026-01-17 16:47:37 | Yi Zhang | [BUGFIX] fix radix cache memory consumption to avoid OOM (#17191) |
| 2026-01-17 15:47:49 | Mick | [diffusion] chore: clean srt imports (#17252) |
| 2026-01-17 15:21:42 | Nan Jiang | fix: fix regression and unclear pattern (#16561) |
| 2026-01-17 15:06:20 | Hudson Xing | fix(ci): skip offline mode for LoRA scenarios (#17248) |
| 2026-01-17 12:24:59 | Mick | [diffusion] doc: add instruction for adding performance baseline of new model (#17249) |
| 2026-01-17 12:21:22 | Xiaoyu Zhang | [Diffusion] Move diffusion time embedding to jit kernel (#16879) |
| 2026-01-17 11:59:04 | fzyzcjy | Support integration tests with Redis binary (#17045) |
| 2026-01-17 11:58:43 | fzyzcjy | Tiny remove unused code (#17047) |
| 2026-01-17 11:58:35 | fzyzcjy | Fix imbalancedness for manual policy min group mode for requests without routing id (#17044) |
| 2026-01-17 10:32:22 | siyu | Add an env var to allow transferring small metadata via TCP for PD (#16951) |
| 2026-01-17 10:20:47 | zijiexia | [Docs] minor update on ep docs (#17242) |
| 2026-01-17 09:56:56 | Stefan He | Disable PCG for draft worker (#16354) |
| 2026-01-17 09:36:25 | Baizhou Zhang | [2/n] deepseek_v2.py Refactor: Migrate MHA forward method in deepseek_v2.py (#16817) |
| 2026-01-17 09:24:05 | b8zhong | [Fix] `flashinfer_trtllm` `intermediate_size` assertion with Qwen3 + TP=8 (#16824) |
| 2026-01-17 06:48:36 | Mohammad Miadh Angkad | Fix benchmark import for should_use_tensor_core (#17232) |
| 2026-01-17 05:53:21 | Chang Su | [model-gateway] Refine `TokenizerRegisty.load()` to handle duplication (#17230) |
| 2026-01-17 05:52:56 | Alison Shao | Increase 5090 test parallelism from 4 to 8 (#17233) |
| 2026-01-17 05:25:13 | Douglas Yang | fix: ci failure monitor reorganization (#17165) |
| 2026-01-17 05:15:34 | Lingjun Wen | [BugFix]: Fix `sglang.bench_one_batch` (#16925) |
| 2026-01-17 02:53:36 | Chang Su | refactor: unify registration through tokenizer_registration workflow (#17187) |
| 2026-01-17 01:52:06 | Makcum888e | [Refactor] [CI] Remove redundant CI test runs  (#17217) |
| 2026-01-17 01:42:50 | Alison Shao | Add CI Coverage Overview workflow with detailed test listings (#16842) |
| 2026-01-17 01:18:16 | Yi Zhong | Add olmo3 in supported docs (#13672) |
| 2026-01-17 00:48:30 | Baizhou Zhang | Update flashinfer to 0.6.1 (#15551) |
| 2026-01-17 00:10:52 | Yongfei Xu | [DeepSeek V3.1/V3.2] Optimize fused moe configs for H20 & H20-3E based on swapab (#17133) |

### 📊 统计摘要
> 本日共 28 个提交 | 🔴高 5 | 🟡中 13 | 🟢低 10
## 📋 目录

- [sgl-project/sglang](#sgl-project-sglang)
  - [📊 统计摘要](#-统计摘要)
  - [🔴 高重要度变更 (5)](#-🔴-高重要度变更-5)
    - [Change routing policy API to be async to support more pol...](#9c25306)
    - [fix: fix regression and unclear pattern (#16561)](#dd99f81)
    - [[2/n] deepseek_v2.py Refactor: Migrate MHA forward method...](#8b9e935)
    - [fix: ci failure monitor reorganization (#17165)](#d2ec128)
    - [refactor: unify registration through tokenizer_registrati...](#a7f5677)
  - [🟡 中重要度变更 (13)](#-🟡-中重要度变更-13)
    - [Revert "[Diffusion] Move diffusion time embedding to jit ...](#53609e5)
    - [[DLLM] Implement initial dynamic batching for diffusion L...](#d2c8638)
    - [[BUGFIX] fix radix cache memory consumption to avoid OOM ...](#737a118)
    - [[diffusion] chore: clean srt imports (#17252)](#dc743fe)
    - [fix(ci): skip offline mode for LoRA scenarios (#17248)](#8ce64aa)
    - [[Diffusion] Move diffusion time embedding to jit kernel (...](#2cdd437)
    - [Support integration tests with Redis binary (#17045)](#a7b5f75)
    - [Tiny remove unused code (#17047)](#305c1a5)
    - [[Fix] `flashinfer_trtllm` `intermediate_size` assertion w...](#d36f6f0)
    - [[model-gateway] Refine `TokenizerRegisty.load()` to handl...](#4229de3)
    - [Add CI Coverage Overview workflow with detailed test list...](#b4fce99)
    - [Update flashinfer to 0.6.1 (#15551)](#a046758)
    - [[DeepSeek V3.1/V3.2] Optimize fused moe configs for H20 &...](#82a1b64)
  - [🟢 低重要度变更 (10)](#-🟢-低重要度变更-10)
    - [[diffusion] doc: add instruction for adding performance b...](#eb76818)
    - [Fix imbalancedness for manual policy min group mode for r...](#c824ddd)
    - [Add an env var to allow transferring small metadata via T...](#e18e005)
    - [[Docs] minor update on ep docs (#17242)](#166396c)
    - [Disable PCG for draft worker (#16354)](#43779f2)
    - [Fix benchmark import for should_use_tensor_core (#17232)](#b0701f0)
    - [Increase 5090 test parallelism from 4 to 8 (#17233)](#2e14407)
    - [[BugFix]: Fix `sglang.bench_one_batch` (#16925)](#7f8353a)
    - [[Refactor] [CI] Remove redundant CI test runs  (#17217)](#3e968ab)
    - [Add olmo3 in supported docs (#13672)](#ec9b48e)
#### 🔴 高重要度变更 (5)

### Change routing policy API to be async to support more policies (#17048)
**SHA**: `9c25306` | 🔗 [查看提交](https://github.com/sgl-project/sglang/commit/9c2530642ca4df047ec79bdec51d723c8877b88d)

**🎯 变更类型**：功能增强 / 架构变更  

**⚡ 重要程度**：🔴高  

**📋 变更摘要**  
- 将路由策略的统一接口 `LoadBalancingPolicy` 从同步 `fn select_worker(&self, …) -> Option<usize>` 改为 **异步** `async fn select_worker(&self, …) -> Option<usize>`，并使用 `async_trait` 进行实现。  
- 所有内置策略（Manual、RoundRobin、Random、PowerOfTwo、PrefixHash、ConsistentHashing、Bucket、CacheAware）相继实现新的 async 方法。  
- 路由调用方（gRPC、HTTP、PD 路由、worker selection 阶段）以及基准测试和单元测试均改为 **await** 该方法，并在必要处显式创建或复用 `tokio::runtime::Runtime`。  
- 测试从同步 `#[test]` 迁移到 `#[tokio::test]`，确保异步执行环境。  

**🎯 影响范围**  
- **核心模块**：`src/policies/*`（几乎全部策略实现）。  
- **接口层**：`src/policies/mod.rs`（Trait 定义）。  
- **路由层**：`src/routers/grpc/common/stages/worker_selection.rs`、`src/routers/http/router.rs`、`src/routers/http/pd_router.rs`。  
- **基准测试**：`sgl-model-gateway/benches/manual_policy_benchmark.rs`。  
- **单元/集成测试**：所有涉及路由策略的测试文件。  
- **依赖**：引入 `async_trait` crate，新增 `tokio` runtime 依赖（已在项目中）。  

**🔍 技术洞察**  

| 维度 | 影响分析 |
|------|----------|
| **架构影响** | 1. **API 破坏**：`LoadBalancingPolicy` 由同步改为异步，所有外部实现必须迁移，属于一次向上兼容的重大改动。<br>2. **统一调度模型**：异步化为将来加入需要 I/O（如 Mesh 同步、远程缓存等）的路由策略提供统一入口，消除“同步‑异步混用”导致的阻塞。<br>3. **运行时依赖**：每一次路由选择现在必须在 `tokio` 上下文中执行，增加对异步运行时的显式依赖。 |
| **性能影响** | - **额外调度开销**：`async/await` 会产生状态机和微小的栈转移开销，理论上略微增加每次路由的延迟（通常 < 100 µs，实际影响可通过基准测试验证）。<br>- **并发提升**：在需要 I/O（如 Mesh 状态同步）时，异步化可以避免阻塞线程，从总体吞吐提升更明显。<br>- **基准测试更新**：新增 `Runtime::new()` 在每个基准分支中创建，可能导致基准测量的噪声，建议改为全局共享 `Runtime`。 |
| **安全考虑** | - 改动本身不引入新的安全风险。<br>- 需注意 **异常传播**：之前同步 `select_worker` 直接返回 `Option`; 现在若实现内部使用 `await` 并触发 `panic!`，会传播至运行时，建议在策略实现中捕获并记录错误而不是直接 panic，以免影响服务可用性。 |
| **可维护性** | - 使用 `async_trait` 让实现保持相同的函数签名，降低迁移成本。<br>- 统一所有策略为 async，后续新增需要 I/O 的策略无需再次改动公共接口。<br>- 代码量略增（`async`、`await`、`SelectWorkerInfo<'_>` 生命周期标注），但结构清晰。 |
| **兼容性** | - **内部**：所有现有策略已同步迁移，编译通过。<br>- **外部**：任何第三方实现 `LoadBalancingPolicy` 必须更新为 async；如有需求，可提供一个 **同步包装**（如 `SyncPolicyAdapter`) 供旧实现平滑迁移。 |

**⚠️ 潜在风险**  
1. **编译破坏**：外部插件或示例代码仍使用旧同步签名，会导致编译错误。  
2. **运行时创建过多**：基准测试和部分业务路径中频繁 `Runtime::new()` 可能导致线程池资源浪费或调度竞争。  
3. **阻塞调用误用**：策略实现如果在 `select_worker` 中使用阻塞 `std::thread::sleep`、`Mutex::lock` 等，可能在异步上下文中引起线程阻塞，降低并发性能。  
4. **忘记 `await`**：未在调用侧加入 `.await` 将导致编译错误或返回 `Future` 而非实际结果，易漏检。  
5. **生命周期错误**：`SelectWorkerInfo<'_>` 引入显式生命周期，若传递临时引用错误可能出现生命周期冲突。  
6. **错误传播**：若策略内部 `await` 产生 `Result::Err`（如网络错误），当前接口仍返回 `Option`; 可能掩盖错误根因，需要在策略内部统一日志/Metric。  

**💡 关注建议**  
- **文档升级**：在项目 README / API 文档中清晰标注 `LoadBalancingPolicy` 为 async，提供迁移指南和示例包装器。  
- **同步兼容层**：考虑实现 `SyncLoadBalancingPolicyAdapter`，内部使用 `tokio::runtime::Handle::current().block_on`，帮助旧实现平滑过渡。  
- **统一 Runtime**：在服务启动时创建一个全局 `tokio::Runtime`（或使用 `#[tokio::main]`），在基准测试中复用而非每次 `new()`，以获得更真实的性能数据。  
- **性能基准**：在迁移后重新跑全套 `cargo bench`，对比关键路径（选路延迟、吞吐）与旧版本，确保异步化带来的开销在可接受范围内。  
- **审计策略实现**：检查所有 `select_worker` 实现，确保没有阻塞操作；如有必要使用 `tokio::task::spawn_blocking` 包装。  
- **错误处理统一**：在

---

### fix: fix regression and unclear pattern (#16561)
**SHA**: `dd99f81` | 🔗 [查看提交](https://github.com/sgl-project/sglang/commit/dd99f818e0aa692d616ef36b81f1d05b7c0eb027)

**🎯 变更类型**：Bug修复  

**⚡ 重要程度**：🔴 高  

**📋 变更摘要**：  
本次提交对 `communicator.py` 与多平台的 `LayerNorm` 实现进行了一系列参数签名的统一和逻辑调整，核心是将原先通过 `**kwargs` 传递的 `post_residual_addition` 参数显式化。此改动消除了在不同后端（CUDA、CPU、NPU、HIP、XPU）之间因参数不匹配导致的回归错误，并澄清了残差加后处理的调用路径，提升了代码可读性和可维护性。  

**🎯 影响范围**：  
- `python/sglang/srt/layers/communicator.py`（Attention 前后残差处理）  
- `python/sglang/srt/layers/layernorm.py`（多平台 LayerNorm 实现）  
- `python/sglang/srt/models/qwen3.py`（Qwen‑3 模型前向）  
- `python/sglang/srt/layers/quantization/modelslim/modelslim.py`（模型瘦身模块）  

### 🔍 技术洞察  

| 维度 | 影响分析 |
|------|----------|
| **架构影响** | - 将隐式 `**kwargs` 参数改为显式 `post_residual_addition`，统一了 `prepare_attn` 与所有 LayerNorm 前向函数的签名。<br>- 通过显式参数，调用链变得清晰：`Communicator → LayerNorm → 后端实现`，降低了跨模块误用的风险。<br>- 对 `LayerNorm` 类的 `forward_*` 方法删除了冗余 `**kwargs`，避免了不必要的字典构造和解包开销。 |
| **性能影响** | - 显式参数消除了 `kwargs.get` 的运行时查找，微幅提升 CPU 路径上的函数调用开销（尤其在高频率的前向传播中）。<br>- 仍保留原有的 fused kernel（如 `fused_add_rmsnorm`、`torch_npu.npu_add_rms_norm`）调用路径，未改变计算路径，性能基本保持不变或略有提升。 |
| **安全考虑** | - 参数显式化防止了未预料的关键字冲突或注入，提升了 API 的输入验证能力。<br>- 未引入新的外部依赖或文件读写，安全风险可视为 **零**。 |

### ⚠️ 潜在风险  

1. **兼容性**：若外部代码仍然通过 `**kwargs` 方式传递 `post_residual_addition`（或其他键），会触发 `TypeError`。需要在升级说明中提醒用户更新调用方式。  
2. **未同步的分支**：项目中可能存在未使用 `post_residual_addition` 的旧实现或实验分支，合并时需确认这些分支已同步此签名修改。  
3. **测试覆盖**：虽然核心路径已覆盖，但建议补充单元测试，验证在 `post_residual_addition=None`、张量形状不匹配、不同设备（CPU/GPU/NPU）下的行为一致性。  

### 💡 关注建议  

- **升级指南**：在发布日志中明确指出 `prepare_attn` 与所有 `LayerNorm` 前向函数现在接受 `post_residual_addition` 参数，旧的 `**kwargs` 调用方式已废弃。  
- **代码审查**：后续新增的自定义层或调度器若需在残差后添加张量，请直接使用显式参数，避免再次使用 `**kwargs`。  
- **性能监控**：在大模型推理基准上对比修改前后每层的时延，确保 fused kernel 的使用率未因签名变化而下降。  
- **回滚计划**：若出现不兼容的第三方插件导致运行时错误，可临时在 `communicator.py` 添加兼容层（读取 `kwargs`），但应在下一个版本中彻底移除。  

---  

**结论**：本次提交通过显式化 `post_residual_addition` 参数，修复了由于参数传递不一致引起的回归问题，并提升了代码的可读性和安全性。风险主要集中在向后兼容性上，建议在文档和测试层面做好相应支持。总体而言，此修改属于高优先级的 **Bug修复**，对项目的稳定性和长期可维护性有显著正面影响。

---

### [2/n] deepseek_v2.py Refactor: Migrate MHA forward method in deepseek_v2.py (#16817)
**SHA**: `8b9e935` | 🔗 [查看提交](https://github.com/sgl-project/sglang/commit/8b9e9357fe2850f17e4ca5a64d9387f2f02619d8)

**🎯 变更类型**：重构 / 功能增强  
**⚡ 重要程度**：🔴 高  

**📋 变更摘要**  
1. 将 Deepseek‑V2 中的多头注意力（MHA）前向逻辑抽取到独立的 *Mixin*（`ForwardBatchDeepSeekMHAMixin` 与 `DeepseekMHAForwardMixin`），并在 `ForwardBatch` 与 `DeepseekV2AttentionMLA` 中多重继承使用。  
2. 新增 `forward_batch_deepseek_mha_mixin.py` 实现前向所需的前缀缓存、Chunked KV、MHA‑ONE‑SHOT 等元数据管理与批处理工具（包括 Triton KV‑index 生成）。  
3. 精简 `deepseek_v2.py`：移除重复的前向准备、Chunked‑KV、One‑Shot、KV‑buffer 相关实现，改为调用 Mixin 中统一实现。  
4. 新增 `attention_forward_methods` 包，统一 `AttnForwardMethod` 与 `DeepseekMHAForwardMixin` 的导出；并在 `forward_methods.py` 中对 `MHA_ONE_SHOT` 的描述做了文字更新。  
5. 在 `attention_backend_handler.py` 中抽取 `MHA_ONE_SHOT_SUPPORTED_BACKENDS` 常量，统一后端兼容检查。  

**🎯 影响范围**  
- `python/sglang/srt/model_executor/forward_batch_info.py`（`ForwardBatch`）  
- `python/sglang/srt/models/deepseek_v2.py`（`DeepseekV2AttentionMLA`）  
- `python/sglang/srt/models/deepseek_common/attention_forward_methods/*`（新 mixin 与 forward 方法枚举）  
- `python/sglang/srt/models/deepseek_common/attention_backend_handler.py`（后端支持列表）  
- 关联的 Triton kernel (`create_chunked_prefix_cache_kv_indices`)  

**🔍 技术洞察**  

| 维度 | 影响 | 说明 |
|------|------|------|
| **架构** | **正向**：MHA 前向实现从模型类中抽离，形成**职责单一**的 mixin；`ForwardBatch` 继承同一 mixin，实现 **元数据统一管理**（prefix chunk、kv indices、one‑shot 标记）。<br>**潜在风险**：多重继承导致属性冲突（如同名属性 `mha_one_shot`、`prefix_chunk_*`），跨模型复用时需确保不被意外覆盖。 |
| **性能** | **保持不变**：核心算子（`attn_mha`、`concat_mla_k`、`merge_state_v2`）仍在 C++/Triton 中执行，Python 层仅搬运元数据。<br>**可能提升**：`prepare_chunked_prefix_cache_info` 与 `prepare_chunked_kv_indices` 只在首个需要时执行，避免在后续 batch 中重复创建；kv‑indices 生成统一使用 Triton，减少 Python 循环开销。 |
| **可维护性** | 代码重复度大幅下降：`deepseek_v2.py` 中原本超过 600 行的前向逻辑被迁入 mixin，后续修改只需在单一文件中完成。<br>文档/注释集中于 mixin，降低新成员学习成本。 |
| **安全** | 此次改动仅涉及内部数据结构与算子调用，不引入外部 I/O、网络或文件系统访问；未增加安全攻击面。 |
| **兼容性** | 新增的 `MHA_ONE_SHOT_SUPPORTED_BACKENDS` 常量用于统一后端判断，减少硬编码风险。<br>但需要确认所有旧的后端名称（如 `"fa3"`、`"flashinfer"`）均已在该列表中；若有自定义后端未列出，`_support_mha_one_shot` 会误判为不支持。 |
| **依赖** | 引入 `sgl_kernel.concat_mla_k`、`sgl_kernel.merge_state_v2` 等 kernel；这些在原代码中已有，未新增外部依赖。 |

**⚠️ 潜在风险**  

1. **属性冲突**：`ForwardBatch` 现在同时继承自 `ForwardBatchDeepSeekMHAMixin`。若后续在其他模型的 `ForwardBatch` 中新增同名属性或方法，可能导致意外覆盖或类型错误。  
2. **后端兼容性**：`MHA_ONE_SHOT_SUPPORTED_BACKENDS` 只能覆盖当前已知后端，若未来添加新后端（如自研的 “flashx”），需要同步更新该列表，否则 `MHA_ONE_SHOT` 将被错误禁用。  
3. **Triton kernel 兼容**：`create_chunked_prefix_cache_kv_indices` 使用 `BLOCK_SIZE = 512`，在某些显存极小或特殊硬件（如老旧 GPU）上可能触发资源不足或性能退化。  
4. **测试覆盖**：大量代码迁移后，原有单元/集成测试是否全部覆盖了新 mixin 的路径尚不明确，可能出现遗漏的回归错误（尤其是 chunked‑kv 与 one‑shot 组合的边界情况）。  
5. **序列化/检查点**：模型 checkpoint 中保存的 `ForwardBatch` 实例可能依赖旧属性名称；迁移后恢复旧 checkpoint 时需确保属性映射兼容（如 `mha_one_shot`、`prefix_chunk_*`）。  

**💡 关注建议**  

1. **增补单元测试**  
   - 为 `ForwardBatchDeepSeekMHAMixin` 补齐 `prepare_chunked_prefix_cache_info`、`prepare_chunked_kv_indices`、`fetch_mha_one_shot_kv_indices` 的独立测试。  
   - 覆盖 **所有** `AttnForwardMethod`（MHA、MHA_ONE_SHOT、MHA_CHUNKED_KV）在不同 `sum_prefix_length` 与 `extend_prefix_lens` 场景下的前向路径。  

2. **回归验证**  
   - 在已知工作负载（prefill、decode、batch‑size‑100）上对比 **性能基线**（latency、throughput）与改动前，确保没有回归。  
   - 特别关注 **极限前缀长度**（> 1M token）和 **极小 batch**（batch‑size=1）两端的行为。  

3. **文档同步**  
   - 更新 `README` / `docs` 中关于 **Chunked Prefix Cache**、**MHA ONE‑SHOT** 的说明，指出新 mixin 的使用方式与属性意义。  
   - 在 `attention_backend_handler.py` 中添加注释，说明 `MHA_ONE_SHOT_SUPPORTED_BACKENDS` 的扩展方式。  

4. **兼容性检查**  
   - 在启动脚本中加入 **assert**，验证 `forward_batch` 实例拥有所有 mixin 定义的属性（如 `prefix_chunk_idx`），防止在其他模型中遗漏继承。  
   - 为自定义后端提供 **注册 Hook**（如 `register_mha_one_shot_backend(name)`)），避免硬编码列表带来的维护负担。  

5. **资源监控**  
   - 监控 Triton kernel 的 **SM 利用率** 与 **共享内存占用**，特别是 `create_chunked_prefix_cache_kv_indices`，确保 `BLOCK_SIZE=512` 在目标硬件上仍能保持高 occupancy。  

6. **安全审计**  
   - 虽然目前未涉及外部输入，但建议在后续引入 **输入合法性检查**（如 `prefix_chunk_len`、`num_prefix_chunks` 是否超出合理范围）时，加入断言或异常以防止潜在的 **DoS**（异常大的请求导致显存爆炸）。  

**结论**  
本次提交通过 **抽象化** 与 **代码复用** 大幅提升了 DeepSeek‑V2 MHA 前向实现的结构清晰度和可维护性，且对核心算子性能基本保持不变。风险主要集中在属性冲突、后端兼

---

### fix: ci failure monitor reorganization (#17165)
**SHA**: `d2ec128` | 🔗 [查看提交](https://github.com/sgl-project/sglang/commit/d2ec128bbfe1d652598ca84845e6b52f679b7068)

**🎯 变更类型**：Bug修复 / 性能优化 / 重构 / 架构变更  
**⚡ 重要程度**：🔴高  

**📋 变更摘要**  
1. 重构 `ci_failures_analysis.py`，在分页请求的 Link Header 解析上加入异常保护，防止因非法格式导致运行中断。  
2. 为 GitHub CI 日志解析新增 “最后运行的测试” 推断逻辑，兼容因超时/进程异常截断的日志，并在测试摘要缺失时返回 `incomplete` 标记。  
3. 在 CI 监控报告中加入 **测试级别** 的详细统计（失败次数、连续失败、超时标记），并实现 **Runner‑specific test failure** 分析，以定位机器相关的 flaky 测试。  
4. 报告生成的 Markdown 大幅增强：可折叠的测试列表、超时标记(⏱️)、高亮连续失败、失败率排序、Runner 健康信息等。  

**🎯 影响范围**  
- `scripts/ci_monitor/ci_failures_analysis.py`（核心逻辑、数据结构、报告生成）  
- CI 监控 CI/CD pipeline（GitHub Actions）使用的自动化报告  

**🔍 技术洞察**  

| 维度 | 影响分析 |
|------|----------|
| **架构影响** | - 新增 `self.test_summaries`、`find_last_running_test`、`analyze_runner_specific_test_failures` 等成员方法，扩展了原有的单一 “作业 – 失败” 结构为 **作业 → 测试 → Runner** 三层关联。<br>- 报告对象 `generate_failure_report` 现在接受四类子报告（job_test_failures、job_test_failures_general、runner_test_failures、online_runners），提升了模块化程度。 |
| **性能影响** | - 解析日志时使用正则和多次循环，尤其在 `parse_test_summary` → `find_last_running_test` 中会遍历完整日志并向上搜索最多 10 行；对超大日志（>1 MB）略有额外开销，但 CI 作业日志通常在几百 KB 以内，影响可忽略。<br>- 对分页的 `Link` 解析加入 `try/except`，在异常时提前终止分页，防止无限循环。<br>- 新增 `defaultdict` 结构用于 Runner‑specific 统计，内存随分析的 Run 数线性增长，单次 CI 执行仍在数十 MB 范围。 |
| **安全考虑** | - 代码仅在 CI 环境内部运行，未增加外部依赖。<br>- 新增的调试 `print` 语句会输出 URL、日志大小等信息，可能在公开 CI 日志时泄露内部仓库路径或 runner ID，建议在生产 CI 中使用 `logging` 并对敏感信息进行筛选。 |
| **可维护性** | - 逻辑拆分为多个小函数（`find_last_running_test`、`analyze_runner_specific_test_failures`），代码可读性提升。<br>- 大量 Markdown 拼接仍采用手写字符串，后续可考虑抽象为模板或使用 `jinja2`，降低维护成本。 |
| **兼容性** | - 对已有 CI 监控报告格式做了向后兼容：如果没有 `test_summary`，仍会返回空 dict，旧的消费方不会崩溃。<br>- 新增的 `incomplete` 标记在旧版报告解析器中会被忽略，不产生误报。 |

**⚠️ 潜在风险**  
1. **分页中止导致数据缺失**：当 `Link` Header 解析异常时 `next_url` 设为 `None`，后续分页将提前停止，可能漏掉部分作业数据。  
2. **误判超时为失败**：`find_last_running_test` 依据 “server_args” 前的文件路径进行推断，若日志中出现类似字段但并非测试上下文，可能把非测试步骤误标记为 “last_running”。  
3. **报告体积膨胀**：在大规模仓库（数千次 CI）下，`test_summaries`、`runner_test_failures` 可能占用大量内存，导致 CI 容器 OOM。  
4. **信息泄露**：`print` 输出的 runner 名称、ID、job URL 在公开 CI 日志时可能暴露内部资源。  

**💡 关注建议**  
- **分页容错**：在 `get_*` 系列函数中加入对 `next_url` 为 `None` 时的警告，并提供手动重试或回退到单页请求的选项。  
- **超时推断校准**：为 `find_last_running_test` 增加正则限定只匹配 `sglang/test/` 或 `tests/` 路径，降低误判概率。  
- **资源限制**：在 CI 作业入口（`scripts/ci_monitor/run.sh`）加入 `ulimit -v` 或 Python 内存限制（`resource.setrlimit`），防止 OOM。  
- **日志脱敏**：将所有 `print` 替换为 `logging`，并在 CI 环境变量 `CI_LOG_SENSITIVE=false` 时自动隐藏 runner ID、URL 等。  
- **单元/集成测试**：为新加入的解析函数编写测试用例（包含正常、异常、超时三种日志），确保未来改动不破坏推断准确性。  
- **文档更新**：在项目的 CI 监控文档中说明 “超时标记 ⏱️” 与 “连续失败 🔥” 的含义，以及如何在报告页面快速定位问题。  

---  
此变更在功能上极大提升了 CI 监控的可观测性，能够帮助 SGLang 团队快速定位 runner 级别或测试级别的 flaky 问题。但需要注意分页容错、日志泄漏与内存使用的潜在风险，建议在正式部署前完成上述风险缓解措施。

---

### refactor: unify registration through tokenizer_registration workflow (#17187)
**SHA**: `a7f5677` | 🔗 [查看提交](https://github.com/sgl-project/sglang/commit/a7f5677abe9f3e6638430031ec3ba65a0bc9e391)

**🎯 变更类型**：重构 / 架构变更  
**⚡ 重要程度**：🔴 高  

**📋 变更摘要**  
1. 将模型网关中所有 Tokenizer 的加载与注册统一到新的异步工作流 `tokenizer_registration`，取代之前在 `AppContextBuilder` 中的同步加载逻辑。  
2. 引入 `TokenizerConfigRequest`（包含可选缓存配置）作为统一的注册请求结构，所有入口（启动时、worker 连接、REST API）均走同一套流程。  
3. 将原有的本地加载、缓存包装、日志打印等散落在多个模块的代码迁移并精简，使 `AppContextBuilder` 只负责创建空的 `TokenizerRegistry`。  

---

**🎯 影响范围**  
- **核心模块**：`sgl-model-gateway/src/app_context.rs`, `src/core/steps/*`（新增 `tokenizer_registration.rs`、修改 `worker/local` 步骤）  
- **配置层**：`src/config/types.rs`（`TokenizerCacheConfig::to_option`）  
- **路由/处理层**：`src/routers/tokenize/handlers.rs`（API 调用）  
- **服务器启动流程**：`src/server.rs`（启动时提交 tokenizer job）  
- **公共导出**：`src/core/steps/mod.rs`（导出 `TokenizerCacheConfig`）  

---

**🔍 技术洞察**

| 维度 | 影响分析 |
|------|----------|
| **架构影响** | • **单一职责**：Tokenizer 加载、缓存、去重、错误处理全部聚合在 `tokenizer_registration` 工作流中，降低了模块之间的耦合。<br>• **统一入口**：`TokenizerConfigRequest` 成为唯一的输入模型，所有入口（CLI、worker、HTTP）使用相同的校验与包装路径，避免出现“启动时加载成功、worker 连接时加载失败”之类的不一致行为。<br>• **解耦 AppContextBuilder**：Builder 只负责创建空的 `TokenizerRegistry`，不再承担 I/O，提升启动时的可预测性和可测试性。 |
| **性能影响** | • **异步化**：Tokenizer 加载改为异步（`factory::create_tokenizer_async_with_chat_template`），在高并发环境下不会阻塞主线程，提升启动与 worker 注册的吞吐。<br>• **缓存一致性**：缓存层仅在 **配置开启** 时才包装（`TokenizerCacheConfig::to_option`），默认行为保持原有性能基准。<br>• **潜在延迟**：首次使用 tokenizer 前可能仍在后台加载（尤其是启动时提交的 job），若请求在加载完成前到达，会触发 Registry 的 `load` 再次尝试，带来额外的 I/O 延迟。 |
| **安全考虑** | • **统一校验**：所有源（本地路径、HF model ID）统一通过 `factory::create_tokenizer_async_with_chat_template`，保留原有的路径/模型 ID 验证逻辑，没有额外风险。<br>• **错误信息传播**：加载错误统一封装成 `String` 并记录在 `WorkflowError`，不泄露底层实现细节。<br>• **Job 队列**：Job 提交失败时仅记录 warn，不会导致 panic，保持服务可用。 |
| **可维护性** | • **代码量下降**：`AppContextBuilder` 中的 200 行冗余加载代码被删除，代码可读性提升。<br>• **测试覆盖**：新增 `TokenizerConfigRequest` 序列化/反序列化单元测试，验证 `cache_config` 字段的可选性。<br>• **模块边界清晰**：Tokenizer 注册工作流独立，后续可以更容易加入如 **限流、审计**、**多租户** 等扩展。 |
| **兼容性** | • 对外接口（API、CLI）保持不变，唯一的行为差异是 **默认不启用缓存** 对于 API 发起的注册（因为 `cache_config: None`），这与之前的实现一致。<br>• 老的 `--tokenizer-path` 参数仍能生效，因为启动时会自动提交对应的 `AddTokenizer` Job。 |

---

**⚠️ 潜在风险**  

| 风险点 | 说明 | 可能影响 |
|--------|------|----------|
| **启动时 Tokenizer 未就绪** | `startup` 会提交 tokenizer Job 并立即继续初始化 workers。若后续 worker 或请求在 tokenizer 完成前就需要它，`TokenizerRegistry::load` 会再次触发加载，导致两次重复 I/O（网络下载或磁盘读取）。 | 响应延迟、临时失效、增加带宽/磁盘压力。 |
| **Job Queue 未初始化** | `SubmitTokenizerJobStep` 依赖 `worker_job_queue.get()`. 若其他代码路径在 `JobQueue` 尚未准备好时调用此步骤，会产生 `warn` 并跳过注册，导致模型后续无法使用 tokenizer。 | 功能缺失、潜在“模型不可用”错误。 |
| **缓存配置不一致** | API 注册默认 `cache_config: None`，而启动/worker 注册可能开启缓存。若业务依赖缓存行为（如 L0 缓存命中率），不同路径下的行为不一致。 | 性能基准难以统一，调优时易产生误判。 |
| **重复注册** | `TokenizerRegistry::load` 已具备去重逻辑，但 `SubmitTokenizerJobStep` 在提交前未检查是否已有相同 `model_id` 的 tokenizer，导致短时间内产生多个相同的 Job。虽然最终 Registry 会合并，但可能造成工作流排队压力。 | 队列积压、短暂的资源浪费。 |
| **错误传播** | `SubmitTokenizerJobStep` 将 `is_retryable` 设为 `false`，若 Job 提交因网络（如内部 RPC）临时失败，系统不会自动重试，可能导致 tokenizers 永久缺失。 | 稳定性下降。 |
| **向后兼容性** | 移除了 `maybe_tokenizer` 方法，若有第三方插件直接调用该私有函数（unlikely），会编译错误。 | 编译错误。 |

---

**💡 关注建议**  

1. **启动顺序**  
   - 在 `startup` 中提交 tokenizer Job 后，**可选**等待其完成（如 `job_queue.wait_until_finished(&tokenizer_id)`）或在 `RouterManager` 初始化前检查 `TokenizerRegistry` 是否已包含对应模型。这样可以避免第一次请求出现“加载中”错误。  

2. **Job Queue 健康检查**  
   - 在 `SubmitTokenizerJobStep` 前添加一个断言，确保 `worker_job_queue` 已经 `Some`. 若为 `None`，立即返回错误并让工作流标记为可重试，防止 silently 跳过。  

3. **统一缓存策略**  
   - 将 `cache_config` 参数也暴露在 API（`AddTokenizer`）的请求体中，或在 `handlers.rs` 根据全局 `router_config.tokenizer_cache` 自动填充默认值。这样可以保证在所有路径下缓存策略一致。  

4. **去重提前检查**  
   - 在 `SubmitTokenizerJobStep` 提交前，先调用 `app_context.tokenizer_registry.contains(&model_id)`（已实现）并 **记录 debug**，避免产生无意义的 Job。  

5. **可观测性**  
   - 为 `TokenizerRegistration` 工作流添加 **metrics**（如 “tokenizer_load_success_total”、“tokenizer_load_failure_total”），以及 **latency histogram**，便于监控加载过程的成功率和时延。  

6. **错误重试策略**  
   - 虽然 `SubmitTokenizerJobStep` 本身

---

#### 🟡 中重要度变更 (13)

### Revert "[Diffusion] Move diffusion time embedding to jit kernel" (#17257)
**SHA**: `53609e5` | 🔗 [查看提交](https://github.com/sgl-project/sglang/commit/53609e5e5b2aa00eb60c9a9a61d9b31b38aa0067)

**变更类型**：功能增强 / 重构  
**重要程度**：🟡 中  

**变更摘要**  
本次提交撤销此前将 Diffusion 时间步嵌入搬迁至 `jit_kernel` 的改动，改为在 `sgl‑kernel` 中直接实现。删除了原有的 CUDA `.cuh` 文件和 Python 包装层，新增 `sgl_kernel/elementwise/timestep_embedding` CUDA 实现并在 C++/Python 接口中注册。相关调用从 `sglang.jit_kernel.timestep_embedding` 替换为 `sgl_kernel.elementwise.timestep_embedding`，并同步更新测试、CMake 与 `__init__.py`。  

**影响范围**  
- `sgl_kernel` 核心库（CUDA kernel、OP 注册、Python binding）  
- `sglang` 多模态生成层 `visual_embedding.py` 中的时间步嵌入调用  
- 单元测试 `sgl_diffusion/test_timestep_embedding.py`  
- 删除的 `jit_kernel` 相关文件可能影响仍依赖旧路径的第三方代码  

**关注建议**  
1. **输入 dtype 兼容**：新实现强制输出为 `float32`，但测试中加入了 `int32/int64` 输入，当前 kernel 仅接受浮点类型，会触发 `RuntimeCheck`。建议在 Python 接口中加入显式的 `t = t.to(torch.float32)` 或在 C++ 层做安全的类型转换，以免出现隐藏的类型错误。  
2. **向后兼容**：如果已有用户仍通过 `sglang.jit_kernel.timestep_embedding` 调用，考虑在 `sglang/jit_kernel/__init__.py` 中保留一个兼容包装，内部转发至 `sgl_kernel.elementwise.timestep_embedding`，避免突发的 ImportError。  
3. **性能基准**：新增的 kernel 与原 `jit_kernel` 实现性能基本持平，但在极大 batch（>16k）时仍需验证显存占用与并行度。建议在 CI 中加入大批量/大维度的性能回归测试。  
4. **构建与分发**：`CMakeLists.txt` 已加入新 `.cu` 文件，确认发布的 wheel 包已包含对应编译产物；否则用户在没有源码编译的环境下会因缺失符号报错。  
5. **文档同步**：更新 `README`/API 文档，说明新入口 `sgl_kernel.timestep_embedding` 的使用方式、默认 `dtype` 为 `float32`，并标注已不再支持 `jit_kernel` 的直接调用。  

总体而言，此次重构把时间步嵌入搬回核心库，提高了可维护性与统一性，只需注意 dtype 兼容与向后兼容性即可确保平滑迁移。

---

### [DLLM] Implement initial dynamic batching for diffusion LLM (#14883)
**SHA**: `d2c8638` | 🔗 [查看提交](https://github.com/sgl-project/sglang/commit/d2c863878cd5f97496624c2c72c0e50860d7cf5b)

**🎯 变更类型**：功能增强（为 Diffusion LLM (dLLM) 实现初步的动态批处理）  
**⚡ 重要程度**：🟡 中  

**📋 变更摘要**  
- 在 `dllm/algorithm/low_confidence.py` 中加入对分块（block）级别的 mask 检测、置信度筛选以及多块返回的 token 列表，实现了动态批次长度的管理。  
- `dllm/config.py` 增加 `max_running_requests` 参数，统一从 server‑args 读取。  
- 新增 `DllmStagingReqs` 用于管理 dLLM 的 staging 请求集合，并在调度器 (`schedule_batch.py、schedule_policy.py、scheduler.py`) 中引入该结构，实现对 dLLM 请求的预取、限流、状态更新以及与 chunked‑prefill 的兼容。  
- 相关类型签名、结果容器 (`GenerationBatchResult.next_token_ids`) 改为支持 `List[torch.Tensor]`，并在 `scheduler_output_processor_mixin.py` 中相应处理多块返回。  
- 增加单元测试 `test_dllm_batching.py`，验证在 CUDA 环境下 dLLM 批处理的正确性（准确率 > 0.88）。  

**🎯 影响范围**  
- **核心调度层**：`schedule_policy.py`、`scheduler.py`、`schedule_batch.py`  
- **dLLM 配置 & 算法**：`dllm/config.py`、`dllm/algorithm/low_confidence.py`  
- **结果处理**：`scheduler_output_processor_mixin.py`、`utils.py`  
- **测试**：`test/registered/dllm/test_dllm_batching.py`  

**💡 关注建议**  
1. **并发限制**：`max_running_requests` 现在决定 dLLM 同时可运行的 block 数，需在部署文档中明确默认值及对显存的影响。  
2. **状态同步**：`DllmStagingReqs.filter_finished_reqs()` 与 `update_chunked_status()` 在不同调度阶段调用，确保在多 GPU/PP 场景下不会产生遗漏或重复计数。  
3. **返回结构兼容**：`GenerationBatchResult.next_token_ids` 由单 Tensor 改为 List，所有消费该字段的代码（包括用户侧的回调）需同步更新。  
4. **异常路径**：`LowConfidence.run` 中若 block 内无 mask 直接返回空列表，后续 `process_batch_result_dllm` 需正确跳过空块，防止 `IndexError`。建议在 `process_batch_result_dllm` 里加入 `if not result.next_token_ids: continue` 的防御性检查。  
5. **性能基准**：当前实现仍以正确性为主，批处理性能尚未优化。后续可在 `LowConfidence` 中加入向量化的阈值筛选与块合并逻辑，避免循环层级过深。  

总体来看，此次改动为 dLLM 引入了动态批处理的雏形，模块划分清晰，兼容性处理得当。但请重点关注并发限制、返回结构的向下兼容以及在多卡/流水线环境下的状态一致性。

---

### [BUGFIX] fix radix cache memory consumption to avoid OOM (#17191)
**SHA**: `737a118` | 🔗 [查看提交](https://github.com/sgl-project/sglang/commit/737a1183d69ae2b46cb7e04156610d3f6d18c881)

**🎯 变更类型**：Bug 修复  
**⚡ 重要程度**：🟡 中（避免 OOM，影响运行稳定性）  

**📋 变更摘要**  
- 在 `hiradix_cache.py`、`mamba_radix_cache.py`、`radix_cache.py`、`swa_radix_cache.py` 四个 RadixCache 实现的 `_split_node` 与 `_insert_helper` 中，将对 `value`（以及 `host_value`）的切片操作改为 `clone()`，防止切片得到的是原张量的视图而导致大块内存被意外保留。  
- 新增 `test_memory_allocated` 单元测试，使用大量具有公共前缀的序列在 CUDA 上插入，验证缓存占用与实际分配的显存量在合理比例内。  

**🎯 影响范围**  
- 核心模块：`python/sglang/srt/mem_cache/*`（四个缓存实现）  
- 测试套件：`test/registered/attention/test_radix_cache_unit.py`  

**💡 关注建议**  
1. **性能评估**：`clone()` 会产生一次显存拷贝，建议在 CI（尤其是 GPU）上跑基准，确认复制开销在可接受范围内。  
2. **内存释放**：确保在节点分裂后，旧张量不再被引用，以便 PyTorch 能及时释放显存；可在关键路径加上显式 `del` 或 `torch.cuda.empty_cache()`（仅在必要时）。  
3. **兼容性检查**：`clone()` 仅在张量上有效，若未来引入非 Tensor 类型的 `value`，需要添加类型判断或统一的 `deepcopy`/`copy` 接口。  
4. **文档更新**：在 RadixCache 的实现说明中加入 “切片会导致显存泄漏，请使用 `clone()`” 的提示，防止后续维护者误用。  

整体来看，此次修改通过显式复制解决了因视图共享导致的显存膨胀问题，提升了系统在大规模前缀共享场景下的稳健性。后续关注复制带来的 CPU/GPU 开销以及对其它缓存实现的同步更新即可。

---

### [diffusion] chore: clean srt imports (#17252)
**SHA**: `dc743fe` | 🔗 [查看提交](https://github.com/sgl-project/sglang/commit/dc743fe4ba850926b1943037d9d49306ed628390)

**🎯 变更类型**：功能增强 / 重构  
**⚡ 重要程度**：🟡 中  
**📋 变更摘要**：本次提交对 SGLang 多模态运行时进行了一系列清理和功能扩展。主要包括：  
1. 将 SRT‑related 类迁移到 `sglang.multimodal_gen.runtime.entrypoints.openai.protocol`，新增 `BaseReq`、`VertexGenerateReqInput` 数据结构并实现请求 ID 重新生成。  
2. 在 OpenAI 接口层重新实现 `ModelCard`（基于 Pydantic），避免循环依赖。  
3. 为自定义算子提供统一注册工具 `register_custom_op`（移植自 vLLM），并在 FlashAttention 后端改用新路径。  
4. `launch_server` 中实现跨平台安全的进程树终止逻辑（使用 `psutil`、`signal`、`threading`），并删除旧的 SRT `kill_process_tree` 实现。  
5. 细节性改动：日志信息精简、导入路径统一、对 `http_server` 的 Vertex 路由参数做显式导入等。

**🎯 影响范围**  
- `sglang.multimodal_gen.runtime.entrypoints.*`（http_server、openai 包）  
- `sglang.multimodal_gen.runtime.layers.utils`（自定义算子注册）  
- `sglang.multimodal_gen.runtime.layers.attention.backends.flash_attn`（算子调用）  
- `sglang.multimodal_gen.runtime.launch_server`（进程管理）  
- 相关测试/部署脚本中仍引用旧的 `sglang.srt.*` 路径的可能性。

**💡 关注建议**  
1. **兼容性检查**：确认外部项目（如使用 Vertex 接口或自定义算子的用户）已迁移到新的 `protocol` 包；旧的 `sglang.srt.*` 导入将失效。  
2. **进程终止安全**：`kill_process_tree` 现在会在主线程重置 `SIGCHLD`，请在多线程环境下确保不会误触其他信号处理器。  
3. **自定义算子注册**：新 `register_custom_op` 默认注册到 `sglang` 库，若已有同名算子需检查重复注册是否被静默跳过，避免意外行为。  
4. **Pydantic ModelCard**：`created` 字段使用运行时时间生成，保持向后兼容；若有持久化缓存，请注意时间变化。  
5. **测试覆盖**：新增的 `BaseReq.regenerate_rid`、`VertexGenerateReqInput` 以及进程终止路径均需单元测试，以防在容器/K8s 环境下出现权限或信号异常。  

整体来看，这次提交旨在去除 SRT 依赖、统一算子注册并提升服务器退出的可靠性。建议在升级前完成上述兼容性验证，并在 CI 中加入对应的回归测试。

---

### fix(ci): skip offline mode for LoRA scenarios (#17248)
**SHA**: `8ce64aa` | 🔗 [查看提交](https://github.com/sgl-project/sglang/commit/8ce64aa15516f75a11fa2af2f3af7933b48c00c4)

**🎯 变更类型**：Bug修复（CI 环境下 LoRA 场景误触离线模式）  
**⚡ 重要程度**：🟡 中  
**📋 变更摘要**：在 `test_utils._try_enable_offline_mode_if_cache_complete` 中加入对 LoRA 参数的检测。若命令行包含 `--enable-lora` 或 `--lora-paths`，直接返回 `None`，避免在 CI 中强制设 `HF_HUB_OFFLINE=1`，因为 LoRA 动态适配器需要在线下载。  

**🎯 影响范围**：  
- `python/sglang/test/test_utils.py`（CI 测试工具）  
- 受 LoRA 相关脚本和模型加载路径的 CI 用例影响。  

**💡 关注建议**：  
1. **参数检测完整性**：当前仅检测 `--enable-lora` 与 `--lora-paths`，若后续使用别名或配置文件开启 LoRA，可能仍触发离线模式。建议统一使用一个标识函数或在解析参数后统一判定。  
2. **日志与可追溯性**：`print` 输出已足够，但在大规模 CI 中建议改为 `logging.info`，并说明为何跳过离线。  
3. **兼容性回归**：离线模式的快速路径仍依赖 `HF_HUB_OFFLINE` 环境变量，确保此改动不影响已有的离线缓存验证。可在本地跑一次完整的离线 CI 测试确认。  
4. **文档更新**：在 CI 或 LoRA 使用指南中注明 “在 LoRA 场景下 CI 自动禁用离线模式”。  
5. **测试覆盖**：新增单元测试，验证当 `other_args` 包含上述标志时函数返回 `None`，且不设置环境变量。  

整体改动简洁、风险低，主要提升 CI 稳定性。后续若 LoRA 参数扩展，请同步更新此检测逻辑，防止离线模式误拦截。

---

### [Diffusion] Move diffusion time embedding to jit kernel (#16879)
**SHA**: `2cdd437` | 🔗 [查看提交](https://github.com/sgl-project/sglang/commit/2cdd4370bc9217e958fa340f1f1754ccf169c372)

**🎯 变更类型**：功能增强（将 diffusion 时间步嵌入从原有的 Torch‐C++ 实现在 JIT kernel 中重写）  
**⚡ 重要程度**：🟡 中  

**📋 变更摘要**  
1. 新增 CUDA JIT kernel `timestep_embedding.cuh`，使用模板实现对 fp16/bf16/fp32 输入的统一处理，并在 CUDA grid/block 组织上做了细粒度的向量化（float4）优化。  
2. 在 Python 层新增 `sglang.jit_kernel.timestep_embedding` 包装，加载并调用该 JIT module，取代原先 `sgl_kernel.elementwise.timestep_embedding`。  
3. 移除旧的 `sgl_diffusion/elementwise/timestep_embedding.cu` 实现，并在 CMake、头文件、`__init__`、`elementwise.py` 中相应删除导出。  
4. 调整相关测试，改为只接受 float16/bf16/float32 输入，更新导入路径。  

**🎯 影响范围**  
- **CUDA kernel 层**：`sgl_kernel` → `sglang.jit_kernel`（`csrc/diffusion/timestep_embedding.cuh`）  
- **Python 接口**：`sglang.jit_kernel.timestep_embedding` 替代 `sgl_kernel.elementwise.timestep_embedding`（`sglang/multimodal_gen/runtime/layers/visual_embedding.py`、测试文件）  
- **构建系统**：CMake、`sgl_kernel_ops.h`、`sgl_kernel/__init__.py`、`sgl_kernel/elementwise.py` 中的声明/导入被删除。  
- **依赖**：仅在 CUDA 环境下生效，仍要求 `dim % 8 == 0`。  

**💡 关注建议**  
1. **兼容性检查**：确保下游库（如 diffusers、自定义扩展）仍能够在没有 JIT kernel 的环境下回退到原实现；当前已在 `visual_embedding.py` 中捕获异常回退。  
2. **性能验证**：建议在不同 batch/dim 组合上对比旧实现与新 JIT 实现的吞吐与延迟，尤其在大 batch（>64k）时检查是否出现显存碎片或 kernel launch 失败。  
3. **错误信息**：`timestep_embedding` 仍强制输出 float32，若将来需要保持输入 dtype（e.g., fp16）以节约显存，需在 wrapper 中提供 `dtype` 参数并相应修改 kernel 输出类型。  
4. **构建清理**：`sgl-kernel` 仍保留对已删除文件的引用（如旧 CMake target），确保 CI 完全清除残余目标，以免出现未定义符号链接错误。  
5. **测试覆盖**：当前测试覆盖了三种 dtype 与多种 batch/dim，建议再加入极端 `dim`（如 1 048 576）以及 `max_period` 参数变动的场景，防止 overflow/数值误差。  

总体而言，本次迁移将时间步嵌入实现统一到 JIT kernel，提升了代码组织与潜在的 CUDA 性能，但需注意兼容性回退、显式 dtype 支持以及构建清理。

---

### Support integration tests with Redis binary (#17045)
**SHA**: `a7b5f75` | 🔗 [查看提交](https://github.com/sgl-project/sglang/commit/a7b5f75d8842451c855b9bb8a4715bffd321607e)

**🎯 变更类型**：功能增强（为模型网关的集成测试提供本地 Redis 支持）  
**⚡ 重要程度**：🟡 中  

**📋 变更摘要**  
1. CI 脚本统一改为 `ci_install_gateway_dependencies.sh`，新增在 Ubuntu 镜像中安装 `redis-server`。  
2. 在 `sgl-model-gateway/tests/common` 中加入 `redis_test_server.rs`，实现启动、健康检查、自动关闭的临时 Redis 实例，并提供 `get_shared_server` 供多测例共享。  
3. 将新模块导出到 `mod.rs`，供业务代码在测试中使用。  

**🎯 影响范围**  
- CI 工作流：`pr-benchmark-rust.yml`、`pr-test-rust.yml`（均会多装一个 `redis-server` 包）。  
- 测试代码：`sgl-model-gateway/tests/common/*`，以及后续可能引用 `redis_test_server` 的单元/集成测试。  
- 依赖：`redis` crate（已在项目中使用）以及系统层面的 `redis-server` 可执行文件。  

**💡 关注建议**  

1. **CI 环境兼容性**：`apt-get install redis-server` 只在基于 Debian/Ubuntu 的 Runner 上可用。若后期改用其他平台（如 macOS、Windows）需补充对应的安装方式或使用容器化方案。  
2. **端口冲突与并发**：使用 `portpicker::pick_unused_port()` 解决单实例冲突，但在并发 CI 任务中仍可能出现端口抢占。建议在 `ci_install_gateway_dependencies.sh` 中显式限制并行度，或在启动时捕获 `EADDRINUSE` 并重试。  
3. **资源清理**：`Drop` 实现已在进程退出时调用 `kill`，但 CI 中若测试异常提前结束，可能残留进程。可以在 CI 脚本中加入 `pkill -f redis-server` 的后置清理步骤，以防泄漏。  
4. **启动超时**：`wait_ready` 循环 200 次、每 100 ms，最多 20 s。若机器负载高可能超时导致 CI 失败。可以将超时阈值调低或在 `ci` 机器上预热 Redis（通过 `service redis-server start`）以提升稳定性。  
5. **安全性**：在 CI 环境启动未持久化的 Redis（`--save "" --appendonly no`）已经比较安全，但仍建议在生产代码库中避免硬编码二进制路径，使用 `which redis-server` 检查其可用性并给出明确错误信息。  
6. **文档和使用示例**：在 `README` 或测试指南中加入如何在本地运行 `cargo test --features=redis-tests`（或类似）并说明依赖的系统二进制，降低新人上手门槛。  

总体来看，此次改动为模型网关的集成测试提供了可靠的键值存储后端，提升了测试覆盖度。但需关注上述平台兼容、端口竞争、清理与超时等细节，以确保 CI 稳定、项目可移植。

---

### Tiny remove unused code (#17047)
**SHA**: `305c1a5` | 🔗 [查看提交](https://github.com/sgl-project/sglang/commit/305c1a575a4e988a48c5dbdfdbbd4c7366817c6e)

**🎯 变更类型**：重构（删除未使用的代码）  
**⚡ 重要程度**：🟡 中  

**📋 变更摘要**  
本次提交在 `sgl-model-gateway/src/core/retry.rs` 中彻底移除了 `RetryExecutor::execute_with_retry` 通用实现以及配套的单元测试。该函数原本用于对任意返回 `Result<T, ()>` 的 async 操作进行重试，并在内部实现了最大次数、指数退避与 `tokio::time::sleep`。代码被删除后，仅保留了针对 HTTP Response 的 `execute_response_with_retry` 实现及其测试。  

**🎯 影响范围**  
- **RetryExecutor**：公共 API `execute_with_retry` 不再可用，编译时若有其他模块调用会导致未定义错误。  
- **单元测试**：原来的 `test_execute_with_retry_success_after_failures` / `test_execute_with_retry_exhausted` 被删除，测试覆盖率相应下降。  
- **依赖方**：搜索项目内或外部使用 `RetryExecutor::execute_with_retry` 的代码（如自研的重试包装或第三方插件），需要改为使用 `execute_response_with_retry` 或自行实现类似逻辑。  

**💡 关注建议**  
1. **代码审查**：确认项目中没有任何显式或间接调用 `execute_with_retry`（包括在 `examples`、脚本或文档示例中）。若仍有引用，需迁移到 `execute_response_with_retry` 或自行实现。  
2. **兼容性**：若库对外提供此 API，建议在下一个大版本中标记为 **removed**，并在 release notes 中说明，以免用户升级后出现编译错误。  
3. **测试**：考虑补充一个更通用的重试工具（如 `RetryFuture`）的单元测试，确保未来的重试行为仍然得到验证。  
4. **文档**：更新 `README`、API 文档以及示例代码，删除或替换对已删除函数的说明。  

总体来看，此次删除是一次清理无用代码的轻量重构，对现有功能没有直接影响，但需要确保外部调用已同步调整，以避免因缺失 API 而产生的构建或运行时错误。

---

### [Fix] `flashinfer_trtllm` `intermediate_size` assertion with Qwen3 + TP=8 (#16824)
**SHA**: `d36f6f0` | 🔗 [查看提交](https://github.com/sgl-project/sglang/commit/d36f6f043ce881d7db7b08856e217cd1250b6c2f)

**🎯 变更类型**：Bug修复  
**⚡ 重要程度**：🟡 中  
**📋 变更摘要**：  
1. 为 FlashInfer‑TRTLLM MoE kernel 新增 `intermediate_size` 必须是 128 的整数倍的强制补齐逻辑，防止在 Qwen‑3 + TP=8 场景下触发断言。  
2. 将 CPU 与已补齐的 GPU 场景统一使用 `narrow_padded_param_and_loaded_weight` 读取权重，以兼容 padding 后的 expert 数据。  
3. 抽取 HF 配置中的量化方式为 `get_quantization_config`，简化 `server_args` 中对 `quantization_config.quant_method` 的读取并统一判定逻辑。  

**🎯 影响范围**：  
- `python/sglang/srt/layers/moe/fused_moe_triton/layer.py`（MoE 前向层及权重加载）  
- `python/sglang/srt/server_args.py`（模型启动时的量化与 MOE 参数默认值）  
- `python/sglang/srt/utils/common.py`（新增公共工具 `get_quantization_config`）  

**💡 关注建议**：  
- **内存兼容性**：`round_up(...,128)` 会让 `intermediate_size_per_partition` 向上取整，需确认在高并行度（TP=8）下不会导致显存超出预期。建议在 CI 中加入显存占用基准测试。  
- **后端一致性**：`use_padded_loading` 现在在 GPU 且使用 FlashInfer‑TRTLLM 时也会走 padded 路径，需确认其它非 FlashInfer‑TRTLLM 的 GPU 后端（如 Triton、FlashInfer‑MXFP4）不受影响。可以在 `is_flashinfer_trtllm_moe` 为 `True` 时加入额外的 `self.use_triton_kernels` 检查，防止误触。  
- **单元测试**：新增针对 `intermediate_size_per_partition` 自动对齐的测试用例，以及 `get_quantization_config` 在没有 `quantization_config`、值为 `None`、不同量化方式（fp8、mxfp4、modelopt_fp4）时的覆盖。  
- **文档更新**：在模型配置文档中说明 FlashInfer‑TRTLLM 对 `intermediate_size` 的 128‑倍数要求，以及自动补齐的行为，帮助使用者预估显存需求。  

总体来看，此次改动解决了 Qwen‑3 大模型在多卡部署时的致命断言，代码结构也更加模块化，但请关注补齐后的显存开销和对其他 MoE 后端的兼容性。

---

### [model-gateway] Refine `TokenizerRegisty.load()` to handle duplication (#17230)
**SHA**: `4229de3` | 🔗 [查看提交](https://github.com/sgl-project/sglang/commit/4229de3b13406fa5066de85d9ecd32f411f1337f)

**🟢 变更概览**  
本次提交对 **TokenizerRegistry.load** 进行了大幅重构，新增 `LoadOutcome`、`LoadError`，并将原来的 **ValidateTokenizerConfigStep** 合并到 `LoadTokenizerStep` 中，实现一次性校验‑去重‑加载。`TokenizerConfigRequest` 增加 `fail_on_duplicate` 字段，API 调用方在注册时可控制是否把重复当作错误。相关模块（本地 worker、router、服务器启动）均已相应更新，同时补充了大量单元测试，验证去重、输入校验、锁清理等路径。

**🔎 受影响的核心模块**  
- `sgl-model-gateway/src/tokenizer/registry.rs`（核心实现）  
- `sgl-model-gateway/src/core/steps/tokenizer_registration.rs`（工作流）  
- `sgl-model-gateway/src/core/steps/worker/local/*`（worker 调度）  
- `sgl-model-gateway/src/routers/tokenize/handlers.rs`、`src/server.rs`（入口层）  
- 公开的 `TokenizerRegistry` 接口（新增 `LoadError`、`LoadOutcome`）  

**✅ 关键改动要点**  
1. **输入校验** 迁入 `load()`，返回 `LoadError::EmptyName/EmptySource`。  
2. **去重逻辑** 统一返回 `LoadOutcome::AlreadyExists { id }`，避免工作流重复检测。  
3. **RAII 锁清理** 新增 `LoadingLockGuard`，确保 panic、提前返回时仍能释放 `loading_locks`，防止死锁。  
4. **fail_on_duplicate**：默认 `false`，router 端强制设为 `true` 以保持旧行为；worker 端保持 `false`，实现 “提交即使已存在”。  
5. **工作流简化**：移除 `ValidateTokenizerConfigStep`，`LoadTokenizerStep` 负责全部校验、去重、加载。  
6. **测试**：覆盖成功加载、重复加载、参数校验、锁清理（panic、早返回）等场景。

**⚠️ 潜在风险 & 建议**  
- **向后兼容**：`TokenizerRegistry.load` 签名从返回 `Result<String,String>` 改为 `Result<LoadOutcome,LoadError>`，虽已在库内部统一使用，但如果外部直接依赖旧签名会编译失败。建议在 `README` 或发布说明中明确迁移步骤。  
- **错误信息传播**：工作流现在只捕获 `LoadError`，但内部仍把 `String` 包装成 `LoadError::LoadFailed`。若上层希望区分 “加载失败” 与 “网络超时”等细节，可能需要后续细化错误枚举。  
- **fail_on_duplicate 的默认值** 已在 router 中强制设为 `true`，但其他自定义调用（比如自测脚本）若忘记设置，可能导致 silent‑skip 行为。可以在 `TokenizerConfigRequest` 的 `#[serde(default = "default_true")]` 为关键路径提供更安全的默认。  
- **锁清理** 已通过 RAII 实现，但仍应在高并发压测下验证 `loading_locks` 不会出现短暂的热点竞争导致性能下降。建议在基准测试中加入并发注册场景。  

**🚀 后续可考虑**  
- 将 `LoadOutcome` 与 `LoadError` 合并为统一的 `Result<LoadOutcome, LoadError>` 并实现 `From<LoadError> for WorkflowError`，进一步简化工作流错误处理。  
- 为 `TokenizerRegistry` 提供 `get_or_load` 类似的便利函数，直接返回已有 ID，减少业务层对 `fail_on_duplicate` 的判断。  

整体来看，此次重构提升了注册流程的鲁棒性与可维护性，去重与错误处理更集中，锁的安全释放也显著降低了潜在死锁风险。只需注意向后兼容提示并在高并发环境下验证性能即可。

---

### Add CI Coverage Overview workflow with detailed test listings (#16842)
**SHA**: `b4fce99` | 🔗 [查看提交](https://github.com/sgl-project/sglang/commit/b4fce9955a895ba18680a482a51131e8482cc82a)

**🎯 变更类型**：功能增强  
**⚡ 重要程度**：🟡 中  
**📋 变更摘要**：新增 GitHub Actions 工作流 `ci-coverage-overview.yml`，每日自动生成 CI 测试覆盖率报告；同时实现 `scripts/ci/ci_coverage_report.py`，可输出 Markdown（详情页、按文件夹/按套件分组）或 JSON，支持在 PR、手动触发时查看。  
**🎯 影响范围**  
- CI 配置：`.github/workflows/ci-coverage-overview.yml`  
- 报告脚本：`scripts/ci/ci_coverage_report.py`（依赖 `test/registered/**` 下的 `ci_register` 注册信息）  
- 可能的副作用：工作流在每次调度或 PR 时会拉取代码、安装 Python 3.10 并执行脚本，对 CI 时长有轻微增加。  

**💡 关注建议**  

1. **依赖路径安全**：脚本通过 `sys.path.insert` 直接定位 `ci_register`，若项目结构调整会导致导入失败。建议改为相对导入或在 `pyproject.toml` 中声明模块路径，提升可维护性。  
2. **异常容错**：`collect_all_tests` 对单文件解析失败仅打印警告，仍会继续。若大量文件解析错误，报告会失真。可考虑在 CI 步骤中捕获并标记为失败，或在输出报告中列出解析错误。  
3. **输出大小控制**：`json-export` 任务将完整报告写入 `ci_coverage.json` 并上传。随着测试数量增长，文件体积可能增大。建议提供 `--max-tests` 或分页选项，或在 GitHub Artifact 中设定大小限制。  
4. **模板一致性**：Markdown 中使用多层 `<details>`，在 GitHub UI 上表现良好，但若以后迁移至其他平台（例如内部文档系统），需要保持兼容。可以抽离渲染函数，统一生成表格/折叠结构。  
5. **CI 资源消耗**：工作流每次运行都会重新检出代码并安装依赖，若不需完整依赖仅解析注册文件，可在 job 中使用 `actions/setup-python` 后直接运行而不安装项目依赖，能进一步降低运行时间。  

总体来说，此次改动为可视化 CI 覆盖率提供了有价值的自动化入口，避免了手工统计的繁琐。只要在上述细节上做适当强化，就能在保持报告完整性的同时，最大化 CI 效率和代码库的可维护性。

---

### Update flashinfer to 0.6.1 (#15551)
**SHA**: `a046758` | 🔗 [查看提交](https://github.com/sgl-project/sglang/commit/a04675892eba54c8fda516956caaf47395636062)

**🎯 变更类型**：功能增强/依赖升级  
**⚡ 重要程度**：🟡 中  

**📋 变更摘要**  
本次提交将 FlashInfer 依赖从 0.5.3 升级至 0.6.1，并同步更新 Docker 镜像、`pyproject.toml`、CI 脚本以及代码中对 FlashInfer 接口的调用。由于 0.6.x 版本移除了 `tile_tokens_dim` 参数，相关调用全部删掉。另在 `is_fa3_default_architecture` 中加入 `MixtralForCausalLM`，提升对 Mixtral 系列模型的兼容。

**🎯 影响范围**  
- **构建/部署**：`docker/Dockerfile`、`scripts/ci/ci_install_dependency.sh`、`pyproject.toml` 中的版本号变化，需要重新构建镜像或重新安装依赖。  
- **运行时检查**：`engine.py` 中的版本断言已同步。  
- **核心算子**：`sglang/srt/layers/*`（MOE、量化、FlashInfer‑TRTLLM 等）调用签名改动，删除 `tile_tokens_dim` 参数。  
- **模型兼容**：`utils/common.py` 增加对 `MixtralForCausalLM` 的默认 FA3 架构识别。  

**💡 关注建议**  
1. **重新构建镜像或本地环境**，确保安装的 `flashinfer_python` 与 `flashinfer_cubin` 为 0.6.1，且 `INSTALL_FLASHINFER_JIT_CACHE` 与 Dockerfile 中的版本保持一致。  
2. **运行完整单元/集成测试**，重点覆盖 MOE、FP8、MXFP4 等量化路径，以及 Mixtral、Qwen 系列模型的推理，以捕获可能的 API 兼容性回归。  
3. 若项目仍需支持旧版 FlashInfer（如部分 CI 环境），可在 CI 脚本中加入条件分支或 Pin 旧版镜像。  
4. 检查第三方插件或自定义扩展是否仍引用已移除的 `tile_tokens_dim` 参数，必要时更新对应代码。  

总体来看，此次升级属于依赖升级与接口适配，风险主要在构建和运行时兼容性，完成上述检查后可安全推广。

---

### [DeepSeek V3.1/V3.2] Optimize fused moe configs for H20 & H20-3E based on swapab (#17133)
**SHA**: `82a1b64` | 🔗 [查看提交](https://github.com/sgl-project/sglang/commit/82a1b645bad31c3071220c1acd4171209c524013)

**变更概览**  
本次提交对 `benchmark/kernels/fused_moe_triton/tuning_fused_moe_triton_sep.py` 进行大幅重构，引入 `MoeInputs` 与 `KernelWrapper`，实现基于 CUDA Graph 的一次性捕获并复用，改写了 `benchmark_config` 的执行路径，统一使用 `KernelWrapper` 完成 kernel0 / kernel1 的 TMA 与非‑TMA 两种模式的测算。`BestConfigTrace` 也被改写为按 **BLOCK_SIZE_M** 记录每个块大小的最优配置（区分上行/下行 moe），并在调优阶段只保留最优 **M**。此外新增 `cmp_configs` 接口用于对比已有配置的实际跑分。配套的 JSON 配置文件（H20、H20‑3e、*_down*）也随之加入。最后在 `fused_moe_triton_kernels.py` 将 `C` 的 stride 顺序由 `(1,2)` 改为 `(-2,-1)`，修正可能的维度错误。

**影响范围**  
- **benchmark 子模块**：所有基准测量与自动调参逻辑均走新路径，原有 `override_config`、`silu_and_mul` 等已废弃。  
- **调优流程**：`BestConfigTrace` 结构变化后，原来直接返回单一最优配置的代码需改为查询 `config_dict(block_m)`。  
- **配置管理**：新增的 H20/H20‑3e 配置文件将被 `cmp_configs` 与调优脚本读取。  
- **内核实现**：stride 调整影响 `invoke_fused_moe_kernel` 的内存访问顺序，必须保持与 Triton kernel 定义一致。

**关注建议**  
1. **CUDA Graph 捕获**：`KernelWrapper` 使用 `inner_iter` 进行多次捕获，确保 `moe_inputs` 在图内不被重新分配；建议在不同 batch‑size、top‑k 场景下跑一次完整的 `prepare+forward_cost` 验证数值一致性。  
2. **配置选取**：`BestConfigTrace` 现在以 `BLOCK_SIZE_M` 为键，若外部仍使用 `trace.config` 旧属性会报错，请统一改为 `trace.config_dict(best_m)`。  
3. **stride 改动**：已改为负索引，确认 Triton kernel 中对应的 `C` 参数维度顺序是否已同步更新，否则可能导致错误的内存布局。  
4. **兼容性**：`cmp_configs` 功能对外新增参数 `--cmp-configs`，调用时需提供对应 JSON 文件，否则会提前退出。  
5. **性能验证**：在 H20 与 H20‑3e 两种硬件上分别跑 `tune` 与 `cmp_configs`，对比新旧基准（原代码 vs. 新 CUDA‑Graph）以及 TMA 开关的实际加速率，防止因图捕获导致的首次启动开销被误认为性能提升。  

总体来看，改动提升了基准测量的可复用性与调优效率，但新增的包装层与新配置格式需要在 CI/测试中加入对应的验证，以防止因图捕获或 stride 错误导致的运行时崩溃或数值偏差。

---

#### 🟢 低重要度变更 (10)

### [diffusion] doc: add instruction for adding performance baseline of new model (#17249)
**SHA**: `eb76818` | 🔗 [查看提交](https://github.com/sgl-project/sglang/commit/eb768189eeb18e2f33518f45a7fd0b5e3b57c122)

**🎯 变更类型**：文档更新  
**⚡ 重要程度**：🟢低  
**📋 摘要**：在 `contributing.md` 中细化了新增模型的贡献要求，加入了添加对应测试用例及更新 `perf_baselines.json` 基准的步骤说明。

---

### Fix imbalancedness for manual policy min group mode for requests without routing id (#17044)
**SHA**: `c824ddd` | 🔗 [查看提交](https://github.com/sgl-project/sglang/commit/c824ddd5811063550fbeaef656d02f376871dcb4)

**🎯 变更类型**：代码重构  
**⚡ 重要程度**：🟢低  
**📋 摘要**：在 ManualPolicy 中，为无 routing‑id 的请求，将 MinLoad/MinGroup 模式的 worker 选择从 `select_new_worker` 改为 `random_select`，避免负载不均，并新增对应单元测试验证随机选择行为。

---

### Add an env var to allow transferring small metadata via TCP for PD (#16951)
**SHA**: `e18e005` | 🔗 [查看提交](https://github.com/sgl-project/sglang/commit/e18e0057a409ddf023e2f38e3aea1ea8e961cfad)

**🎯 变更类型**：配置调整  
**⚡ 重要程度**：🟢低  
**📋 摘要**：在 `environ.py` 新增 `SGLANG_MOONCAKE_SEND_AUX_TCP` 环境变量（默认 False），并在 `conn.py` 中使用该变量，使在启用自定义内存池且类型为 NVLINK 时，可通过 TCP 发送小尺寸元数据以规避 NVLINK 传输问题。

---

### [Docs] minor update on ep docs (#17242)
**SHA**: `166396c` | 🔗 [查看提交](https://github.com/sgl-project/sglang/commit/166396ca4c26ffa5491346ebdb29e3b69d00d4b1)

**🎯 变更类型**：文档更新  
**⚡ 重要程度**：🟢低  
**📋 摘要**：在 `expert_parallelism.md` 中新增 Ascend NPU 融合 All-to-All 后端说明；修正 EPLB 启用标志描述，去除 `true` 参数。

---

### Disable PCG for draft worker (#16354)
**SHA**: `43779f2` | 🔗 [查看提交](https://github.com/sgl-project/sglang/commit/43779f27b750f10eccfb80651bf3e0326fe1f75d)

**🎯 变更类型**：代码重构  
**⚡ 重要程度**：🟢 低  
**📋 摘要**：在 `model_runner.py` 中新增对 `is_draft_worker` 的检测，禁止草稿工作线程使用分段 CUDA 图（Piecewise CUDA Graph），其余逻辑保持不变。

---

### Fix benchmark import for should_use_tensor_core (#17232)
**SHA**: `b0701f0` | 🔗 [查看提交](https://github.com/sgl-project/sglang/commit/b0701f02b3fe84dcb94a231a901752be978c921b)

**🎯 变更类型**：代码重构  
**⚡ 重要程度**：🟢 低  
**📋 摘要**：在 `benchmark/kernels/decoding_attention_triton/triton_flashinfer_cudnn.py` 中修正 `should_use_tensor_core` 的导入路径，从 `sglang.srt.utils` 改为 `sglang.srt.layers.attention.flashinfer_backend`，确保基准测试能够正确引用该函数。

---

### Increase 5090 test parallelism from 4 to 8 (#17233)
**SHA**: `2e14407` | 🔗 [查看提交](https://github.com/sgl-project/sglang/commit/2e144079832d048d81deb44466e1b1ba4c39a2ed)

**🎯 变更类型**：配置调整  
**⚡ 重要程度**：🟢低  
**📋 摘要**：将 PR 测试工作流的并行度从 4 提升至 8，以加快 5090 测试套件的执行速度。

---

### [BugFix]: Fix `sglang.bench_one_batch` (#16925)
**SHA**: `7f8353a` | 🔗 [查看提交](https://github.com/sgl-project/sglang/commit/7f8353aff3d902dbe97ca26a756ae3ca9564f753)

**🎯 变更类型**：代码重构  
**⚡ 重要程度**：🟢低  
**📋 摘要**：在 `prepare_extend_inputs_for_correctness_test` 中，为 `req.prefix_indices` 添加 `.to(req.prefix_indices.dtype)`，确保类型一致，防止因 dtype 不匹配导致的运行错误。

---

### [Refactor] [CI] Remove redundant CI test runs  (#17217)
**SHA**: `3e968ab` | 🔗 [查看提交](https://github.com/sgl-project/sglang/commit/3e968ab3693b59ed41b18ec5da45bf392f66e86d)

**🎯 变更类型**：配置调整  
**⚡ 重要程度**：🟢低  
**📋 摘要**：CI 工作流文件的过滤路径由通配 `python/*.toml` 改为具体的 `pyproject_*.toml`，以避免冗余的测试运行。

---

### Add olmo3 in supported docs (#13672)
**SHA**: `ec9b48e` | 🔗 [查看提交](https://github.com/sgl-project/sglang/commit/ec9b48ea9614721d05449e6dae8f15a699608ad6)

**🎯 变更类型**：文档更新  
**⚡ 重要程度**：🟢低  
**📋 摘要**：在 `docs/supported_models/generative_models.md` 中新增 OLMo‑3 模型的 HuggingFace 标识，完善了对 OLMo 系列模型的支持说明。

---

