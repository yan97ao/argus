# æ¯æ—¥æ›´æ–°æŠ¥å‘Šï¼ˆ2026-01-11ï¼‰

## sgl-project/sglang

| æäº¤æ—¶é—´ | ä½œè€… | æäº¤ä¿¡æ¯ |
|----------|------|----------|
| 2026-01-11 23:17:38 | Liangsheng Yin | [CI] reapply max-parallel in `stage-b-test-small-1-gpu` (#16906) |
| 2026-01-11 23:05:37 | Alison Shao | Enable /rerun-stage workflow URL lookup for fork PRs (#16851) |
| 2026-01-11 20:27:19 | Yibo Cai | [cpu/arm64] support run sglang on arm64 cpu (#14867) |
| 2026-01-11 18:18:29 | Baizhou Zhang | [Tiny] Rename test_sparse_flash_attn.py to fix CI (#16895) |
| 2026-01-11 17:03:00 | Wenyi Xu | [model-gateway] Add Redis support as a history backend (#16300) |
| 2026-01-11 16:08:26 | Adarsh Shirawalmath | [Diffusion] Docs for Diffusers backend (#16864) |
| 2026-01-11 15:53:38 | Baizhou Zhang | [CI]Move fa4 e2e test to 4-gpu-b200 runner (#16889) |
| 2026-01-11 15:31:28 | Johnny | [NVIDIA] upstream FA4 (#15182) |
| 2026-01-11 13:04:43 | Liangsheng Yin | Clarify the meaning of `cpu_group` / `entry_rank` when dp + tp is enabled. (#16876) |
| 2026-01-11 12:38:03 | Ratish P | [dpc]: unify DP controller load balancing and simplify dispatch logic (#16258) |
| 2026-01-11 12:03:43 | Alison Shao | Update est_time for stage-b-test-small-1-gpu tests (#16835) |
| 2026-01-11 11:31:38 | Leoyzen | Fix parallel tool call parsing bug when tool parameters contain arrays (#16345) |
| 2026-01-11 10:15:21 | Simo Lin | fix(gateway): rewrite gauge_histogram.rs for zero-allocation hot path (#16878) |
| 2026-01-11 10:10:42 | Mohammad Miadh Angkad | Tiny fix hicache kernel backend comparison (#16867) |
| 2026-01-11 09:34:09 | DarkSharpness | [Feature] Support JIT set kv cache (#16273) |
| 2026-01-11 09:19:59 | Minglei Zhu | [BugFix] fix gpt-oss-120b launch failure with --enable-piecewise-cuda-graph (#16757) |
| 2026-01-11 08:04:25 | Yuwei An | [tiny remove] remove torch_compile in parallel_state (#16865) |
| 2026-01-11 01:24:32 | Liangsheng Yin | [hot fix ci] Hot fix for the unregistered. (#16877) |

### ğŸ“Š ç»Ÿè®¡æ‘˜è¦
> æœ¬æ—¥å…± 18 ä¸ªæäº¤ | ğŸ”´é«˜ 3 | ğŸŸ¡ä¸­ 7 | ğŸŸ¢ä½ 8
## ğŸ“‹ ç›®å½•

- [sgl-project/sglang](#sgl-project-sglang)
  - [ğŸ“Š ç»Ÿè®¡æ‘˜è¦](#-ç»Ÿè®¡æ‘˜è¦)
  - [ğŸ”´ é«˜é‡è¦åº¦å˜æ›´ (3)](#-ğŸ”´-é«˜é‡è¦åº¦å˜æ›´-3)
    - [[model-gateway] Add Redis support as a history backend (#...](#3c16c58)
    - [fix(gateway): rewrite gauge_histogram.rs for zero-allocat...](#7c25687)
    - [[Feature] Support JIT set kv cache (#16273)](#d112f6a)
  - [ğŸŸ¡ ä¸­é‡è¦åº¦å˜æ›´ (7)](#-ğŸŸ¡-ä¸­é‡è¦åº¦å˜æ›´-7)
    - [Enable /rerun-stage workflow URL lookup for fork PRs (#16...](#17cb3c8)
    - [[cpu/arm64] support run sglang on arm64 cpu (#14867)](#2f4a6ad)
    - [[NVIDIA] upstream FA4 (#15182)](#b5493f6)
    - [Clarify the meaning of `cpu_group` / `entry_rank` when dp...](#09e2571)
    - [[dpc]: unify DP controller load balancing and simplify di...](#c0248d6)
    - [Update est_time for stage-b-test-small-1-gpu tests (#16835)](#cc25f9d)
    - [Fix parallel tool call parsing bug when tool parameters c...](#cf14feb)
  - [ğŸŸ¢ ä½é‡è¦åº¦å˜æ›´ (8)](#-ğŸŸ¢-ä½é‡è¦åº¦å˜æ›´-8)
    - [[CI] reapply max-parallel in `stage-b-test-small-1-gpu` (...](#cf1426a)
    - [[Tiny] Rename test_sparse_flash_attn.py to fix CI (#16895)](#f9fc50a)
    - [[Diffusion] Docs for Diffusers backend (#16864)](#7b089ae)
    - [[CI]Move fa4 e2e test to 4-gpu-b200 runner (#16889)](#8b5d426)
    - [Tiny fix hicache kernel backend comparison (#16867)](#ff97814)
    - [[BugFix] fix gpt-oss-120b launch failure with --enable-pi...](#a2c2c09)
    - [[tiny remove] remove torch_compile in parallel_state (#16...](#2a9344d)
    - [[hot fix ci] Hot fix for the unregistered. (#16877)](#78c4175)
#### ğŸ”´ é«˜é‡è¦åº¦å˜æ›´ (3)

### [model-gateway] Add Redis support as a history backend (#16300)
**SHA**: `3c16c58` | ğŸ”— [æŸ¥çœ‹æäº¤](https://github.com/sgl-project/sglang/commit/3c16c58619d1ac06cfda36373e0a1d64f2c9d8b2)

âš ï¸ LLMåˆ†æå¤±è´¥ï¼ˆå·²é‡è¯•3æ¬¡ï¼‰: APIè¯·æ±‚å¤±è´¥: HTTPSConnectionPool(host='integrate.api.nvidia.com', port=443): Read timed out. (read timeout=30)

*æš‚æ— åˆ†æ*

---

### fix(gateway): rewrite gauge_histogram.rs for zero-allocation hot path (#16878)
**SHA**: `7c25687` | ğŸ”— [æŸ¥çœ‹æäº¤](https://github.com/sgl-project/sglang/commit/7c25687c9ba35e4730effbb9cc2f2c4f8629e423)

âš ï¸ LLMåˆ†æå¤±è´¥ï¼ˆå·²é‡è¯•3æ¬¡ï¼‰: APIè¯·æ±‚å¤±è´¥: HTTPSConnectionPool(host='integrate.api.nvidia.com', port=443): Read timed out. (read timeout=30)

*æš‚æ— åˆ†æ*

---

### [Feature] Support JIT set kv cache (#16273)
**SHA**: `d112f6a` | ğŸ”— [æŸ¥çœ‹æäº¤](https://github.com/sgl-project/sglang/commit/d112f6a25bc857a4bd67115d258f6ec356f4bc38)

**ğŸ¯ å˜æ›´ç±»å‹**ï¼šåŠŸèƒ½å¢å¼º  
**âš¡ é‡è¦ç¨‹åº¦**ï¼šğŸ”´é«˜  
**ğŸ“‹ å˜æ›´æ‘˜è¦**ï¼šæœ¬æ¬¡æäº¤ä¸º SGLang å¼•å…¥äº† JIT ç¼–è¯‘çš„ KVâ€‘Cache å­˜å‚¨ç®—å­ï¼Œæ–°å¢äº† CUDAâ€¯Trion å®ç°çš„ `store_kvcache` å†…æ ¸ï¼Œå¹¶åœ¨ Python å±‚æä¾› `sglang.jit_kernel.kvcache.store_cache` æ¥å£ã€‚å†…æ ¸æ”¯æŒæŒ‰è¡Œå­—èŠ‚æ•°è‡ªåŠ¨åˆ†ç‰‡ã€PDL åŒæ­¥ï¼Œå¯åœ¨ CUDA Graph æ•è·æ¨¡å¼ä¸‹å¹¶è¡Œå†™å…¥ K/V ç¼“å­˜ã€‚åŒæ—¶åŠ å…¥äº†åŸºå‡†æµ‹è¯•ã€CI åˆ¤å®šå·¥å…·ä»¥åŠç›¸åº”çš„å•å…ƒæµ‹è¯•ï¼Œå¹¶åœ¨ `memory_pool.py` ä¸­å°†åŸæœ‰çš„é€å…ƒç´ æ‹·è´é€»è¾‘æ›¿æ¢ä¸ºè¯¥ JIT è·¯å¾„ï¼Œå®ç°æ›´é«˜çš„å†™å…¥æ•ˆç‡ã€‚

**ğŸ¯ å½±å“èŒƒå›´**ï¼š  
- `sglang/jit_kernel/kvcache.py`ï¼ˆPythonâ€¯JIT åŒ…è£…ï¼‰  
- `sglang/jit_kernel/csrc/elementwise/kvcache.cuh`ï¼ˆCUDAâ€¯C++ å†…æ ¸ï¼‰  
- `sglang/jit_kernel/norm.py`ï¼ˆQKâ€‘Norm JIT åå­—ä¸è·¯å¾„è°ƒæ•´ï¼‰  
- `sglang/srt/mem_cache/memory_pool.py`ï¼ˆKVâ€‘Cache å†™å…¥è·¯å¾„æ”¹ä¸º JITï¼‰  
- åŸºå‡†/æµ‹è¯•ä»£ç  `sglang/jit_kernel/benchmark/*`ã€`sglang/jit_kernel/tests/*`  
- ç›¸å…³ä¾èµ–å·¥å…· `utils.py`ã€`bench_qknorm.py`ï¼ˆå¼•å…¥ `flashinfer.rmsnorm`ï¼‰  

---

### ğŸ” æŠ€æœ¯æ´å¯Ÿ

#### æ¶æ„å½±å“
- **æ¨¡å—åŒ– JIT æ¥å£**ï¼šé€šè¿‡ `load_jit` åŠ¨æ€åŠ è½½ç¼–è¯‘å¥½çš„ CUDAâ€¯C++ åº“ï¼Œä¿æŒ Python å±‚ä¸åº•å±‚å®ç°çš„è§£è€¦ã€‚`register_custom_op` å°† JIT å‡½æ•°æ³¨å†Œä¸º SRT è‡ªå®šä¹‰ç®—å­ï¼Œç»Ÿä¸€èµ°åŒä¸€è°ƒåº¦å…¥å£ã€‚
- **ç»Ÿä¸€ KVâ€‘Cache å†™å…¥æŠ½è±¡**ï¼šåœ¨ `memory_pool.py` ä¸­å¼•å…¥ `_set_kv_buffer_impl`ï¼Œåœ¨æ•è· CUDA Graphã€æ™®é€šæ‰§è¡Œä»¥åŠ JIT åŠ é€Ÿä¸‰ç§è·¯å¾„ä¹‹é—´é€æ˜åˆ‡æ¢ï¼Œé™ä½ä¸Šå±‚ä¸šåŠ¡ä»£ç æ”¹åŠ¨ã€‚
- **PDLï¼ˆProducerâ€‘Consumer Dependency Layerï¼‰**ï¼šå†…æ ¸å¯é€‰å¯ç”¨ PDL ä»¥åœ¨å¤šæµç¯å¢ƒä¸‹æä¾›æ˜¾å¼ä¾èµ–åŒæ­¥ï¼Œæé«˜å¹¶è¡Œæ‹·è´çš„å®‰å…¨æ€§ã€‚å¯¹ä¸æ”¯æŒ PDL çš„ç¡¬ä»¶ä¼šè‡ªåŠ¨å›é€€ã€‚

#### æ€§èƒ½å½±å“
- **åŸºå‡†ç»“æœ**ï¼šæ–°å¢ `bench_store_cache.py` å¯¹æ¯” AOTã€JITã€`torch.compile`ã€åŒæµå®ç°å››ç§æ–¹æ¡ˆã€‚ç”±äº `store_kvcache` é‡‡ç”¨ warpâ€‘levelå‘é‡æ‹·è´ã€æŒ‰è¡Œåˆ†ç‰‡ï¼ˆ`num_split`ï¼‰ä»¥åŠæ½œåœ¨çš„ PDL åŒæ­¥ï¼Œå¯æ˜¾è‘—é™ä½æ¯ä¸ª token çš„ KV å†™å…¥å»¶è¿Ÿï¼ˆé¢„è®¡åœ¨ 30%â€‘70% ä¹‹é—´ï¼Œæ ¹æ®è¡Œå¤§å°åŠ batchâ€‘sizeï¼‰ã€‚
- **ç¼“å­˜å¯¹é½ä¼˜åŒ–**ï¼š`can_use_store_cache` å¯¹è¡Œå­—èŠ‚æ•°è¿›è¡Œæ£€æŸ¥ï¼Œä»…åœ¨æ»¡è¶³ 4â€‘byte å¯¹é½ä¸” `row_bytes % 1024/2048` æ—¶å¼€å¯ 2/4 åˆ†ç‰‡ï¼Œé¿å…ä¸å¿…è¦çš„åˆ†ç‰‡å¼€é”€ã€‚
- **CUDA Graph æ•è·**ï¼šåœ¨ `set_kv_buffer` ä¸­æ£€æµ‹ `get_is_capture_mode()`ï¼Œåœ¨æ•è·æ¨¡å¼ä¸‹ä½¿ç”¨åŒæµå¹¶è¡Œå†™å…¥ K ä¸ Vï¼Œè¿›ä¸€æ­¥æå‡ååã€‚

#### å®‰å…¨è€ƒè™‘
- **ç±»å‹ä¸å¯¹é½æ£€æŸ¥**ï¼š`can_use_store_cache` é€šè¿‡ `size % 4` ä¸ DLPack ç±»å‹æ ¡éªŒé¿å…éæ³•å†…å­˜è®¿é—®ã€‚è‹¥ä¸æ»¡è¶³æ¡ä»¶ï¼Œå†…æ ¸åŠ è½½ä¼šæŠ›å¼‚å¸¸å¹¶å›é€€åˆ°å®‰å…¨çš„ PyTorch å¤åˆ¶è·¯å¾„ã€‚
- **å¼‚å¸¸å®¹é”™**ï¼šåœ¨ `_jit_kvcache_module` åŠ è½½å¤±è´¥æ—¶ä¼šè®°å½•è­¦å‘Šå¹¶è¿”å› `False`ï¼Œä¸å½±å“æ•´ä½“è¿è¡Œï¼Œåªæ˜¯å¤±å»åŠ é€Ÿã€‚å•å…ƒæµ‹è¯•ç¡®ä¿åŠŸèƒ½æ­£ç¡®æ€§ã€‚
- **PDL ä½¿ç”¨å®‰å…¨**ï¼šPDL ä¾èµ–ç¡¬ä»¶/é©±åŠ¨æ”¯æŒï¼Œä»£ç åœ¨ `is_arch_support_pdl()` ä¸­åˆ¤æ–­ï¼Œè‹¥ä¸æ”¯æŒåˆ™ç¦ç”¨ PDLï¼Œé¿å…æ½œåœ¨çš„åŒæ­¥é”™è¯¯ã€‚

#### å¯ç»´æŠ¤æ€§
- **ä»£ç åˆ†å±‚æ¸…æ™°**ï¼šC++ å†…æ ¸ä½äº `csrc/elementwise/kvcache.cuh`ï¼ŒPython åŒ…è£…åœ¨ `jit_kernel/kvcache.py`ï¼Œä¸¤è€…é€šè¿‡ç»Ÿä¸€çš„ `make_cpp_args` ä¸ `load_jit` å…³è”ï¼Œåç»­è‹¥è¦æ”¹è¿›æˆ–è¿ç§»åˆ°å…¶ä»–åç«¯ï¼Œåªéœ€æ›´æ–°å¯¹åº”å±‚ã€‚
- **ç»Ÿä¸€æ³¨å†Œ**ï¼š`register_custom_op` å°† JIT ç®—å­çº³å…¥ SRT è‡ªå®šä¹‰ç®—å­ç³»ç»Ÿï¼Œä¿æŒç»Ÿä¸€çš„æ—¥å¿—ã€å¼‚å¸¸å¤„ç†ä¸è°ƒåº¦è·¯å¾„ï¼Œé™ä½æ•£è½çš„ç‰¹æ®Šå®ç°é£é™©ã€‚
- **æµ‹è¯•è¦†ç›–**ï¼š`tests/test_store_cache.py` è¦†ç›–äº†å¤š batchâ€‘size ä¸å¤šç»´åº¦çš„æ­£ç¡®æ€§éªŒè¯ï¼Œé€‚ç”¨äº CI å›å½’ã€‚

---

### âš ï¸ æ½œåœ¨é£é™©

| é£é™©ç‚¹ | è¯´æ˜ | å¯èƒ½åæœ | ç¼“è§£æªæ–½ |
|--------|------|----------|----------|
| **è¡Œå­—èŠ‚æ•°ä¸æ»¡è¶³å¯¹é½** | `can_use_store_cache` åªæ¥å— `size % 4 == 0`ï¼Œä¸”åˆ†ç‰‡è¦æ±‚ `size % 1024/2048` | JIT åŠ é€Ÿè¢«ç¦ç”¨ï¼Œå›é€€åˆ°åŸå§‹æ‹·è´ï¼Œå¯èƒ½å¯¼è‡´æ€§èƒ½å›é€€ | å·²æœ‰å›é€€è·¯å¾„ï¼›å¯åœ¨æ¨¡å‹é…ç½®é˜¶æ®µæå‰æ£€æŸ¥å¹¶æç¤ºç”¨æˆ·ã€‚ |
| **PDL å…¼å®¹æ€§** | éƒ¨åˆ†æ—§æ˜¾å¡/é©±åŠ¨ä¸æ”¯æŒ PDLï¼ŒåŒæ­¥ä¼šå›é€€ä¸ºå•æµ | æ€§èƒ½ä¸‹é™ï¼ˆå°¤å…¶åœ¨ capture æ¨¡å¼ä¸‹ï¼‰ | é€šè¿‡ `is_arch_support_pdl()` è‡ªåŠ¨å…³é—­ï¼›CI ç¯å¢ƒå¯æ¨¡æ‹Ÿä¸æ”¯æŒæƒ…å†µåšå›å½’ã€‚ |
| **CUDA Graph æ•è·å†²çª** | åœ¨æ•è·æ¨¡å¼ä¸‹åŒæ—¶ä½¿ç”¨åŒæµï¼Œéœ€è¦ç¡®ä¿ `alt_stream` é `None`ï¼Œä¸”ä¸è¢«å…¶å®ƒç®—å­å ç”¨ | å¯èƒ½å‡ºç°å†™å…¥é¡ºåºé”™è¯¯æˆ–ç«äº‰ | é€šè¿‡ `alt_stream` çš„å­˜åœ¨æ€§æ£€æŸ¥ä»¥åŠ `register_custom_op` çš„åŒæ­¥åŒ…è£…é¿å…ã€‚ |
| **åŠ¨æ€ç¼–è¯‘å¤±è´¥** | JIT ç¼–è¯‘å™¨åœ¨ç‰¹å®šç¡¬ä»¶/é©±åŠ¨ç»„åˆä¸Šå¯èƒ½æŠ¥é”™ï¼ˆä¾‹å¦‚ç¼–è¯‘å™¨ä¸å…¼å®¹ï¼‰ | ç¨‹åºæŠ›å¼‚å¸¸æˆ–ç›´æ¥é€€å‡º | æ•è·å¼‚å¸¸å¹¶å›é€€åˆ°æ™®é€šå®ç°ï¼›å»ºè®®åœ¨å‘å¸ƒå‰åœ¨å¤šç§ç¡¬ä»¶ä¸Šåš smoke testã€‚ |
| **ä»£ç è·¯å¾„åˆ†å‰** | `set_kv_buffer` ç°æœ‰é€»è¾‘åœ¨ `memory_pool.py` è¢« `_set_kv_buffer_impl` æ›¿ä»£ï¼Œè‹¥æœªå®Œæˆè¿ç§»ä¼šå‡ºç°ä¸ä¸€è‡´ | éšè”½çš„é”™è¯¯æˆ–æœªä½¿ç”¨ JIT è·¯å¾„ | é€šè¿‡ CI æ£€æŸ¥ `can_use_store_cache` çš„è°ƒç”¨è¦†ç›–ç‡ï¼Œç¡®ä¿æ‰€æœ‰ KV å†™å…¥å‡èµ°ç»Ÿä¸€å‡½æ•°ã€‚ |

---

### ğŸ’¡ å…³æ³¨å»ºè®®

1. **æ€§èƒ½ç›‘æ§**  
   - åœ¨ç”Ÿäº§ç¯å¢ƒå¼€å¯ `SGLANG_JIT_KVCACHE_STATS`ï¼ˆå¯è‡ªè¡Œå®ç°ï¼‰è®°å½•æ¯æ¬¡ `store_cache` çš„å®é™…è·¯å¾„ï¼ˆJIT/AOT/torchï¼‰ï¼Œå¯¹æ¯”é¢„æœŸæå‡ç‡ã€‚  
   - å¯¹ä¸åŒ `row_bytes`ï¼ˆå¦‚ 512â€¯Bã€1024â€¯Bã€2048â€¯Bï¼‰è¿›è¡ŒåŸºå‡†ï¼Œä»¥ç¡®ä¿åˆ†ç‰‡ç­–ç•¥åœ¨å®é™…å·¥ä½œè´Ÿè½½ä¸‹ä»å…·ä¼˜åŠ¿ã€‚

2. **å…¼å®¹æ€§éªŒè¯**  
   - åœ¨ CI ä¸­åŠ å…¥å¯¹ä¸æ”¯æŒ PDLã€å¯¹é½ä¸æ»¡è¶³çš„æ¨¡å‹é…ç½®çš„å›å½’æµ‹è¯•ï¼Œç¡®ä¿ä»£ç åœ¨æ‰€æœ‰åˆ†æ”¯ä¸‹å‡èƒ½æ­£ç¡®æ‰§è¡Œã€‚  
   - åœ¨æ–‡æ¡£ä¸­æ˜ç¡®è¯´æ˜ JIT åŠ é€Ÿçš„ç¡¬ä»¶è¦æ±‚ï¼ˆCUDAâ€¯>= 11.8ã€æ˜¾å¡ Compute Capability â‰¥ 8.0ï¼Œæ”¯æŒ PDLï¼‰ä»¥åŠè¡Œå­—èŠ‚å¯¹é½é™åˆ¶ã€‚

3. **é”™è¯¯æ—¥å¿—æå‡**  
   - åœ¨ `can_use_store_cache` ä¸ `_jit_kvcache_module` çš„å¼‚å¸¸æ•è·ä¸­åŠ å…¥ `exc_info=True`ï¼Œæ–¹ä¾¿å®šä½åŠ è½½å¤±è´¥çš„æ ¹å› ï¼ˆç¼–è¯‘å™¨ã€ç¬¦å·ç¼ºå¤±ç­‰ï¼‰ã€‚  
   - å¯¹ `store_cache` çš„å›é€€è·¯å¾„æ·»åŠ  `debug` çº§åˆ«æ—¥å¿—ï¼Œå¸®åŠ©è¿ç»´åˆ¤æ–­æ˜¯å¦çœŸçš„è¿›å…¥äº† JIT åŠ é€Ÿã€‚

4. **æ¥å£å‘åå…¼å®¹**  
   - ä¿æŒåŸæœ‰ `set_kv_buffer` çš„ç­¾åä¸å˜ï¼Œæ–°å¢ `row_bytes` ä¸ `num_split` å‚æ•°ä»…ä½œå†…éƒ¨ä¼˜åŒ–ï¼Œé¿å…ç ´åå·²æœ‰è°ƒç”¨æ–¹ã€‚  
   - æœªæ¥è‹¥è€ƒè™‘åœ¨å…¶ä»–ç®—å­ï¼ˆå¦‚ attention çš„ forwardï¼‰å¤ç”¨ JIT KV å†™å…¥ï¼Œå¯å°† `_set_kv_buffer_impl` æç‚¼ä¸ºå…¬å…±å·¥å…·å‡½æ•°ã€‚

5. **æ–‡æ¡£ä¸ç¤ºä¾‹**  
   - æ›´æ–° README/benchmark æ–‡æ¡£ï¼Œå±•ç¤º `bench_store_cache.py` çš„ä½¿ç”¨æ–¹å¼ä¸å…¸å‹åŠ é€Ÿæ•ˆæœã€‚  
   - åœ¨æ¨¡å‹éƒ¨ç½²è„šæœ¬ä¸­ç»™å‡º `SGLANG_JIT_KVCACHE=1` ç¯å¢ƒå˜é‡çš„ç¤ºä¾‹ï¼Œä»¥ä¾¿ç”¨æˆ·æ˜¾å¼å¼€å¯ã€‚

é€šè¿‡ä¸Šè¿°æªæ–½ï¼Œå¯æœ€å¤§åŒ–æœ¬æ¬¡ JIT KVâ€‘

---

#### ğŸŸ¡ ä¸­é‡è¦åº¦å˜æ›´ (7)

### Enable /rerun-stage workflow URL lookup for fork PRs (#16851)
**SHA**: `17cb3c8` | ğŸ”— [æŸ¥çœ‹æäº¤](https://github.com/sgl-project/sglang/commit/17cb3c8e499f4681fdf482ac3690201f612f1021)

**ğŸ¯ å˜æ›´ç±»å‹**ï¼šåŠŸèƒ½å¢å¼º  
**âš¡ é‡è¦ç¨‹åº¦**ï¼šğŸŸ¡ ä¸­  
**ğŸ“‹ å˜æ›´æ‘˜è¦**ï¼šä¸º PRâ€‘Test å·¥ä½œæµåŠ å…¥åŠ¨æ€ `run-name`ï¼Œåœ¨ `/rerunâ€‘stage` æ—¶å°†é˜¶æ®µåå’Œï¼ˆå¯¹ fork PRï¼‰æäº¤ SHA æ‹¼å…¥æ ‡é¢˜ã€‚`scripts/ci/slash_command_handler.py` ä¾æ®è¯¥ `display_title` è€Œé Job åç§°å»å®šä½æœ€è¿‘çš„ workflow runï¼Œå¹¶å°† fork PR çš„ `pr_head_sha` ä½œä¸ºæ–°å‚æ•°å‘åä¼ é€’ã€‚  

**ğŸ¯ å½±å“èŒƒå›´**  
- `.github/workflows/pr-test.yml`ã€`.github/workflows/pr-test-amd.yml`ï¼ˆCI å·¥ä½œæµï¼‰  
- `scripts/ci/slash_command_handler.py`ï¼ˆURL æŸ¥æ‰¾é€»è¾‘ï¼‰  

**ğŸ’¡ å…³æ³¨å»ºè®®**  

1. **å…¼å®¹æ€§**ï¼š`find_workflow_run_url` ç°åœ¨ä»…é€šè¿‡ `display_title` åŒ¹é…ï¼Œè‹¥å†å² run æœªä½¿ç”¨ `run-name`ï¼ˆæˆ– GitHub æš‚æœªè¿”å› `display_title`ï¼‰ï¼Œä¼šå¯¼è‡´æ‰¾ä¸åˆ° URLã€‚å»ºè®®ä¿ç•™åŸæœ‰é€šè¿‡ Job åç§°æ£€æŸ¥çš„å›é€€è·¯å¾„ï¼Œä»¥å…åœ¨æ—§ PR æˆ– GitHub API è¡Œä¸ºå˜åŠ¨æ—¶å‡ºé”™ã€‚  
2. **è¾“å…¥æ ¡éªŒ**ï¼šå·¥ä½œæµç°åœ¨ä¾èµ– `inputs.target_stage` ä¸ `inputs.pr_head_sha`ã€‚ç¡®è®¤åœ¨æ‰€æœ‰è°ƒç”¨ç‚¹ï¼ˆåŒ…æ‹¬æ‰‹å·¥è§¦å‘ã€scheduleï¼‰éƒ½æœ‰ç›¸åº” `inputs` å£°æ˜ï¼Œé˜²æ­¢å› ç¼ºå¤±å¯¼è‡´ `run-name` ä¸ºç©ºè€Œå½±å“åŒ¹é…ã€‚  
3. **æ—¥å¿—ä¸é”™è¯¯ä¿¡æ¯**ï¼šå·²æ·»åŠ  `print` è¾“å‡º `display_title`ï¼Œå»ºè®®æ”¹ä¸ºä½¿ç”¨ç»Ÿä¸€çš„æ—¥å¿—å‡½æ•°ï¼ˆ`logging`ï¼‰å¹¶åœ¨æ‰¾ä¸åˆ°åŒ¹é…æ—¶æä¾›æ›´æ˜ç¡®çš„æç¤ºï¼Œå¦‚â€œfallback to jobâ€‘name lookupâ€ã€‚  
4. **æƒé™**ï¼š`/rerun-stage` ä»éœ€è¦ `repo` æƒé™è¯»å– workflow runsã€‚è‹¥æ”¹ä¸ºä»…ä¾èµ– `display_title`ï¼Œå¯åœ¨åæœŸè€ƒè™‘ä½¿ç”¨æ›´è½»é‡çš„ APIï¼ˆ`GET /actions/runs`ï¼‰æ¥é™ä½è¯·æ±‚æ¬¡æ•°ã€‚  
5. **æµ‹è¯•**ï¼šåœ¨ fork PR åœºæ™¯ä¸‹éªŒè¯ï¼šâ‘  workflow æ­£ç¡®ç”Ÿæˆ `"[stage] <sha>"` æ ‡é¢˜ï¼›â‘¡ `slash_command_handler` èƒ½åœ¨ 30â€¯s å†…è¿”å›è¿è¡Œ URLã€‚ä¹Ÿè¦åœ¨é fork PRã€æ™®é€š push ç­‰æƒ…å½¢ä¸‹ç¡®ä¿ä»èƒ½æ­£å¸¸å®šä½ï¼ˆæ ‡é¢˜åº”ä¸º `"[stage]"`ï¼‰ã€‚  

æ€»ä½“ä¸Šï¼Œæ­¤æ¬¡æ”¹åŠ¨ç®€åŒ–äº† URL æŸ¥æ‰¾é€»è¾‘ï¼Œæå‡äº†å¯¹ fork PR çš„æ”¯æŒï¼Œä½†å»ºè®®åŠ å…¥æ—§æ–¹å¼å›é€€å¹¶å®Œå–„æ–‡æ¡£ï¼Œä»¥ç¡®ä¿åœ¨æ‰€æœ‰ CI ç¯å¢ƒä¸‹çš„å¯é æ€§ã€‚

---

### [cpu/arm64] support run sglang on arm64 cpu (#14867)
**SHA**: `2f4a6ad` | ğŸ”— [æŸ¥çœ‹æäº¤](https://github.com/sgl-project/sglang/commit/2f4a6addf3101342498b4528289c6fd053622530)

**å˜æ›´ç±»å‹**ï¼šåŠŸèƒ½å¢å¼ºï¼ˆæ–°å¢ arm64â€¯CPU æ”¯æŒï¼‰  
**é‡è¦ç¨‹åº¦**ï¼šğŸŸ¡ ä¸­  

**æ ¸å¿ƒå˜æ›´**  
1. **å¹³å°æ£€æµ‹**ï¼šåœ¨ `utils/common.py` ä¸­åŠ å…¥ `is_host_cpu_arm64()`ï¼Œå¹¶åœ¨ `is_cpu()`ã€`is_shm_available()` ä¸­æŠŠ arm64 è§†ä¸ºå¯ç”¨çš„ CPU ç±»å‹ã€‚  
2. **çº¿ç¨‹/å…±äº«å†…å­˜åˆå§‹åŒ–**ï¼š`model_executor/model_runner.py` åœ¨ CPU åˆ†æ”¯é‡Œæ”¹ä¸º `if _is_cpu_amx_available or _is_cpu_arm64`ï¼Œå¹¶ç›¸åº”æ›´æ–°è­¦å‘Šä¿¡æ¯ï¼Œç¡®ä¿ arm64 æœºå™¨ä¹Ÿä¼šèµ° OpenMP çº¿ç¨‹ç»‘å®šå’Œå…±äº«å†…å­˜ AllReduceã€‚  
3. **å±‚å®ç°æ¡ä»¶**ï¼š`layers/activation.py`ã€`layers/layernorm.py`ã€`layers/rotary_embedding.py` çš„å¹³å°åˆ¤æ–­è¢«ç®€åŒ–ï¼Œå»æ‰äº†å¯¹éâ€‘CUDA/éâ€‘NPU/éâ€‘AMXâ€‘CPU çš„å¼ºåˆ¶å›é€€ï¼Œé¿å…åœ¨ arm64 ä¸Šé”™è¯¯åœ°åŠ è½½ vllm å®ç°ã€‚  
4. **å¯¼å…¥è·¯å¾„**ï¼šåˆ é™¤äº†åœ¨éæ”¯æŒå¹³å°ä¸Šå¼ºåˆ¶ `from vllm.model_executor.layersâ€¦` çš„ä»£ç ï¼Œé˜²æ­¢åœ¨ arm64 ç¯å¢ƒä¸‹å‡ºç°ä¸å¿…è¦çš„ä¾èµ–ã€‚  

**å½±å“èŒƒå›´**  
- **sglang/srt/layers**ï¼ˆæ¿€æ´»ã€LayerNormã€RotaryEmbeddingï¼‰  
- **sglang/srt/model_executor**ï¼ˆCPU çº¿ç¨‹/å…±äº«å†…å­˜åˆå§‹åŒ–ï¼‰  
- **sglang/srt/utils**ï¼ˆå¹³å°æ£€æµ‹ä¸ CPU èƒ½åŠ›åˆ¤å®šï¼‰  

**å…³æ³¨å»ºè®®**  
- **å…¼å®¹æ€§**ï¼šç¡®è®¤åœ¨ x86â€¯CPUï¼ˆå« AMXï¼‰å’Œ arm64â€¯CPU ä¸Š `is_cpu()` çš„è¿”å›å€¼ç¬¦åˆé¢„æœŸï¼›è‹¥ä»éœ€åœ¨éâ€‘arm64/éâ€‘x86 ç¯å¢ƒè¿è¡Œï¼Œéœ€æ‰‹åŠ¨è®¾ç½® `SGLANG_USE_CPU_ENGINE=0` æˆ–è¡¥å……ç›¸åº”å›é€€å®ç°ã€‚  
- **ä¾èµ–**ï¼š`torch.cpu.is_available()` éœ€è¦ PyTorchâ€¯2.2+ï¼ˆæˆ–ç›¸åº”ç‰ˆæœ¬ï¼‰ï¼Œè¯·åœ¨ CI ä¸­åŠ å…¥ arm64â€‘docker é•œåƒçš„ä¾èµ–æ£€æŸ¥ã€‚  
- **æµ‹è¯•**ï¼šæ–°å¢å•å…ƒ/é›†æˆæµ‹è¯•ï¼Œè¦†ç›– `is_host_cpu_arm64()`ã€`is_shm_available()` åœ¨æ¨¡æ‹Ÿ arm64 ç¯å¢ƒä¸‹çš„è·¯å¾„ï¼›ä»¥åŠåœ¨çœŸå®çš„ aarch64 æœºå™¨ä¸Šè·‘ä¸€æ¬¡å®Œæ•´çš„ SGLang æ¨ç†ï¼Œä»¥éªŒè¯çº¿ç¨‹ç»‘å®šã€å…±äº«å†…å­˜ AllReduce ä¸åŸæœ‰ CUDA/NPU è·¯å¾„ä¿æŒä¸€è‡´çš„æ•°å€¼ç»“æœã€‚  
- **æ—¥å¿—**ï¼šæ—¥å¿—ä¿¡æ¯å·²æ›´æ–°ä¸º â€œonly intel amx backend and arm64 are supportedâ€ï¼Œå»ºè®®åœ¨æ–‡æ¡£ä¸­è¯´æ˜ arm64 éœ€è¦çš„ç¡¬ä»¶/OS è¦æ±‚ï¼ˆå¦‚æ”¯æŒ NEONã€Linuxâ€¯aarch64ï¼‰ã€‚  

æ€»ä½“è€Œè¨€ï¼Œæ­¤æ¬¡æ”¹åŠ¨ä¸º arm64 CPU æ‰“é€šäº†å¤§éƒ¨åˆ†åŠ é€Ÿè·¯å¾„ï¼Œä½†ä»éœ€åœ¨å®é™… arm64 ç¯å¢ƒä¸­åšå®Œæ•´å›å½’ï¼Œä»¥é˜²é—æ¼å¹³å°ç‰¹æœ‰çš„è¾¹ç•Œæƒ…å†µã€‚

---

### [NVIDIA] upstream FA4 (#15182)
**SHA**: `b5493f6` | ğŸ”— [æŸ¥çœ‹æäº¤](https://github.com/sgl-project/sglang/commit/b5493f65be22447af02edbfb6eb4cee71f2bc779)

âš ï¸ LLMåˆ†æå¤±è´¥ï¼ˆå·²é‡è¯•3æ¬¡ï¼‰: APIè¯·æ±‚å¤±è´¥: HTTPSConnectionPool(host='integrate.api.nvidia.com', port=443): Read timed out. (read timeout=30)

*æš‚æ— åˆ†æ*

---

### Clarify the meaning of `cpu_group` / `entry_rank` when dp + tp is enabled. (#16876)
**SHA**: `09e2571` | ğŸ”— [æŸ¥çœ‹æäº¤](https://github.com/sgl-project/sglang/commit/09e2571e2e427d3fa1dd4fbb676a285f9e6a6d03)

**ğŸ¯ å˜æ›´ç±»å‹**ï¼šåŠŸèƒ½å¢å¼º / é‡æ„  
**âš¡ é‡è¦ç¨‹åº¦**ï¼šğŸŸ¡ ä¸­  
**ğŸ“‹ å˜æ›´æ‘˜è¦**ï¼šåœ¨åŒæ—¶å¼€å¯ DPï¼ˆDataâ€‘Parallelï¼‰+ TPï¼ˆTensorâ€‘Parallelï¼‰æ—¶ï¼Œæ˜ç¡® `cpu_group` ä¸ `entry_rank` çš„å«ä¹‰ã€‚å°†åŸæ¥é€šè¿‡ `tp_worker` æš´éœ²çš„ TP/Attentionâ€‘TP æ¥å£ç»Ÿä¸€æ¬åˆ° `sglang.srt.distributed.parallel_state`ï¼Œå¹¶åœ¨è°ƒåº¦å™¨ä¸­æ–°å¢ `dp_tp_group / dp_tp_cpu_group` ä½œä¸ºè¯·æ±‚å±‚é¢çš„åè°ƒç»„ã€‚å¯¹åº”çš„å¹¿æ’­ã€å±éšœã€Profiler ç­‰å…¨éƒ¨æ”¹ä¸ºä½¿ç”¨è¯¥æ–°ç»„ã€‚

**ğŸ¯ å½±å“èŒƒå›´**  
- `python/sglang/srt/managers/scheduler.py`ï¼ˆæ ¸å¿ƒè°ƒåº¦é€»è¾‘ï¼‰  
- `scheduler_pp_mixin.py`ã€`scheduler_profiler_mixin.py`ï¼ˆå¹¿æ’­ã€å±éšœï¼‰  
- `disaggregation/prefill.py`ï¼ˆKV è½®è¯¢ï¼‰  
- `tp_worker.py`ï¼ˆå»é™¤æ—§çš„ getterï¼‰  
- ç›¸å…³ imports (`get_tp_group`, `get_attention_tp_group`)

**ğŸ’¡ å…³æ³¨å»ºè®®**  
1. **å…¼å®¹æ€§**ï¼šç¡®è®¤å…¶ä»–ä»£ç è·¯å¾„ï¼ˆä¾‹å¦‚æ—¥å¿—ã€ç›‘æ§æˆ–è‡ªå®šä¹‰æ’ä»¶ï¼‰ä»ç„¶ä½¿ç”¨ `self.cpu_group` æ—¶å·²å…¨éƒ¨è¿ç§»ä¸º `self.dp_tp_cpu_group`ï¼Œå¦åˆ™å¯èƒ½å‡ºç° `None` å¼•å‘çš„ `torch.distributed` é”™è¯¯ã€‚  
2. **DPâ€‘Attention å…³é—­æ—¶**ï¼š`dp_tp_group` ä¼šå›é€€åˆ°æ™®é€š TP ç»„ï¼Œ`dp_tp_cpu_group` å¿…é¡»å§‹ç»ˆéç©ºï¼›å»ºè®®åœ¨åˆå§‹åŒ–ååŠ å…¥æ–­è¨€æˆ–æ—¥å¿—æç¤ºã€‚  
3. **å•å…ƒ/é›†æˆæµ‹è¯•**ï¼šåˆ†åˆ«è·‘ DPâ€‘Attention æ‰“å¼€/å…³é—­ã€å•æœºå¤šå¡ã€è·¨æœºå¤šå¡ä¸‰ç§é…ç½®ï¼Œé‡ç‚¹éªŒè¯ KV è½®è¯¢ã€Multimodal è¾“å…¥å¹¿æ’­ä»¥åŠ Profiler çš„ barrier æ˜¯å¦ä»èƒ½æ­£å¸¸åŒæ­¥ã€‚  
4. **æ–‡æ¡£**ï¼šæ›´æ–° `cpu_group`ã€`entry_rank` çš„è¯´æ˜ï¼Œè§£é‡Šå…¶å·²ä¸å†ç›´æ¥å¯¹åº” TP ç»„ï¼Œè€Œæ˜¯æ ¹æ®æ˜¯å¦å¼€å¯ DPâ€‘Attention è‡ªåŠ¨åˆ‡æ¢ã€‚  
5. **æ€§èƒ½ç›‘æ§**ï¼šå› ä¸ºå¹¿æ’­æ”¹ä¸ºåŸºäº `dp_tp_cpu_group`ï¼ˆGlooï¼‰ï¼Œåœ¨å¤§è§„æ¨¡ TP åœºæ™¯ä¸‹ç•™æ„ç½‘ç»œå¼€é”€æ˜¯å¦å‡ºç°å›é€€ã€‚  

æ€»ä½“æ¥çœ‹ï¼Œå˜æ›´ä½¿è°ƒåº¦å™¨å¯¹ DP+TP åœºæ™¯çš„è¯­ä¹‰æ›´æ¸…æ™°ï¼Œé¿å…äº†ä¹‹å‰çš„ â€œTPâ€‘group ä¸ Attentionâ€‘TPâ€‘group æ··ç”¨â€ å¸¦æ¥çš„æ½œåœ¨é”™è¯¯ã€‚ä½†éœ€åœ¨å…¨é“¾è·¯æµ‹è¯•åç¡®è®¤æ‰€æœ‰æ—§æ¥å£å·²è¢«æ¸…ç†ï¼Œä»¥é˜²è¿è¡Œæ—¶ `AttributeError`ã€‚

---

### [dpc]: unify DP controller load balancing and simplify dispatch logic (#16258)
**SHA**: `c0248d6` | ğŸ”— [æŸ¥çœ‹æäº¤](https://github.com/sgl-project/sglang/commit/c0248d6f37cce10120feda25b7d384828392e036)

**ğŸ¯ å˜æ›´ç±»å‹**ï¼šåŠŸèƒ½å¢å¼ºï¼ˆç»Ÿä¸€ DP æ§åˆ¶å™¨çš„è´Ÿè½½å‡è¡¡å®ç°å¹¶å¯¹å¤–æä¾›æ›´ç›´è§‚çš„è°ƒåº¦ç­–ç•¥ï¼‰  
**âš¡ é‡è¦ç¨‹åº¦**ï¼šğŸŸ¡ ä¸­  
**ğŸ“‹ å˜æ›´æ‘˜è¦**  
æœ¬æ¬¡æäº¤æŠŠåŸå…ˆçš„ `shortest_queue` ä¸ `minimum_tokens` ä¸¤å¥—è´Ÿè½½å‡è¡¡å®ç°ï¼ˆåŸºäºå†…éƒ¨é˜Ÿåˆ—ä¸ 2â€¯ms çª—å£çš„é¢„ç®—è®¡ç®—ï¼‰æ•´ä½“æŠ›å¼ƒï¼Œæ”¹ä¸ºåŸºäº **ç´¯è®¡è¯·æ±‚æ•°** ä¸ **ç´¯è®¡ token æ•°** çš„ä¸¤ç§ç®€å•è°ƒåº¦æ–¹å¼ã€‚`DPBudget` åªä¿å­˜ `total_requests`ã€`total_tokens` ä¸¤ä¸ªåˆ—è¡¨ï¼Œ`dispatch()` æ ¹æ®æ‰€é€‰ `LoadBalanceMethod` è¿”å›å½“å‰æœ€è½»çš„ workerï¼Œå¹¶åœ¨åˆ†é…åå³æ—¶è‡ªå¢è®¡æ•°ã€‚ç›¸åº”çš„ CLI å‚æ•°ã€æ–‡æ¡£ä»¥åŠå¹³å°ç‰¹æ€§è¡¨ä¹ŸåŒæ­¥æ›´æ–°ã€‚

**ğŸ¯ å½±å“èŒƒå›´**  
- `python/sglang/srt/managers/data_parallel_controller.py`ï¼ˆæ ¸å¿ƒè°ƒåº¦é€»è¾‘ï¼‰  
- `python/sglang/srt/server_args.py`ï¼ˆCLI å‚æ•°æšä¸¾ï¼‰  
- `docs/advanced_features/server_arguments.md`ã€`docs/platforms/ascend_npu_support_features.md`ï¼ˆæ–‡æ¡£ï¼‰  
- å¯èƒ½å—å½±å“çš„å¤–éƒ¨é›†æˆï¼šä¾èµ– `--load-balance-method=shortest_queue` æˆ– `minimum_tokens` çš„ç”¨æˆ·è„šæœ¬/éƒ¨ç½²è„šæœ¬ã€‚

**ğŸ’¡ å…³æ³¨å»ºè®®**  

1. **å‘åå…¼å®¹**  
   - ç›®å‰åˆ é™¤äº† `shortest_queue`ã€`minimum_tokens`ï¼Œä½†æ—§ç‰ˆè„šæœ¬ä»å¯èƒ½ä½¿ç”¨å®ƒä»¬ã€‚å»ºè®®åœ¨ `LoadBalanceMethod.from_str` ä¸­åŠ å…¥å…¼å®¹å±‚ï¼ˆå¦‚æ˜ å°„åˆ° `total_requests`ï¼‰ï¼Œæˆ–åœ¨ CLI å‚æ•°ä¸­ä¿ç•™æ—§åå¹¶ç»™å‡ºè­¦å‘Šæç¤ºï¼Œä»¥å…ç›´æ¥æŠ¥é”™å¯¼è‡´ç”Ÿäº§ä¸­æ–­ã€‚  
2. **è°ƒåº¦å…¬å¹³æ€§**  
   - é‡‡ç”¨æœ€å°ç´¯è®¡è¯·æ±‚/Token çš„ â€œæœ€è½»è´Ÿè½½â€ ç­–ç•¥æ—¶ï¼Œè‹¥æŸ worker é•¿æ—¶é—´è¢«é€‰ä¸­è€ŒæœªåŠæ—¶é‡Šæ”¾è´Ÿè½½ï¼Œè®¡æ•°ä¼šæŒç»­å¢é•¿ï¼Œå¯¼è‡´åç»­è¯·æ±‚å€¾å‘äºå…¶ä»– workerã€‚è€ƒè™‘åœ¨é€‚å½“æ—¶æœºï¼ˆå¦‚æ¯ N ç§’ï¼‰å¯¹è®¡æ•°è¿›è¡Œè¡°å‡æˆ–é‡ç½®ï¼Œé˜²æ­¢æ°¸ä¹…æ€§å€¾æ–œã€‚  
3. **å¹¶å‘å®‰å…¨**  
   - `DPBudget.update_budget` ä¸ `dispatch` åœ¨å¤šçº¿ç¨‹ç¯å¢ƒä¸‹ç›´æ¥è¯»å†™ `total_requests / total_tokens` åˆ—è¡¨ï¼Œç¼ºå°‘é”ä¿æŠ¤ã€‚è‹¥ `DataParallelController` åœ¨å¤šä¸ªçº¿ç¨‹å¹¶è¡Œè°ƒç”¨ï¼Œå¯èƒ½å‡ºç°ç«äº‰æ¡ä»¶ã€‚å»ºè®®ä½¿ç”¨ `threading.Lock` åŒ…è£¹æ›´æ–°ä¸è¯»å–è¿‡ç¨‹ï¼Œæˆ–æ”¹ä¸º `collections.deque` + åŸå­è®¡æ•°å™¨ã€‚  
4. **ç›‘æ§ & æ—¥å¿—**  
   - æ–°çš„è°ƒåº¦é€»è¾‘ä¸å†äº§ç”Ÿ â€œbudget queue emptyâ€ ç­‰è°ƒåº¦æ—¥å¿—ã€‚è‹¥ç”¨æˆ·ä¾èµ–è¿™äº›æ—¥å¿—è¿›è¡Œæ€§èƒ½æ’æŸ¥ï¼Œå»ºè®®åœ¨ `dispatch` å‰ååŠ å…¥è°ƒåº¦ç›®æ ‡ã€å½“å‰è®¡æ•°çš„ INFO çº§åˆ«æ—¥å¿—ã€‚  
5. **æµ‹è¯•è¦†ç›–**  
   - æ·»åŠ é’ˆå¯¹ `total_requests`ã€`total_tokens` ä¸¤ç§æ–¹å¼çš„å•å…ƒæµ‹è¯•ï¼ŒéªŒè¯ï¼šâ‘  æ‰€æœ‰ DP workers æŠ¥é€è´Ÿè½½åèƒ½å¤Ÿæ­£ç¡®è¿”å›æœ€å°å€¼ï¼›â‘¡ å½“å‡ºç°å¹³å±€æ—¶æŒ‰ç…§ä»£ç çš„ tieâ€‘breakerï¼ˆè¯·æ±‚æ•°ï¼‰é€‰å–ï¼›â‘¢ `maybe_external_dp_rank_routing` ä»ç„¶å¯ä»¥è¦†ç›–è°ƒåº¦ã€‚  
6. **æ–‡æ¡£åŒæ­¥**  
   - æ–‡æ¡£å·²æ›´æ–°ï¼Œä½†ä»éœ€åœ¨ â€œå…¼å®¹æ€§è¯´æ˜â€ å°èŠ‚ä¸­æé†’ç”¨æˆ·æ–°æ—§å‚æ•°çš„å·®å¼‚ï¼Œé¿å…å‡çº§åå‡ºç° â€œunknown loadâ€‘balance methodâ€ çš„é”™è¯¯ã€‚

æ€»ä½“æ¥è¯´ï¼Œæ­¤æ¬¡é‡æ„æå¤§ç®€åŒ–äº† DP è´Ÿè½½å‡è¡¡çš„å®ç°è·¯å¾„ï¼Œé™ä½äº†ä»£ç å¤æ‚åº¦å’Œç»´æŠ¤æˆæœ¬ã€‚ä½†åœ¨ç”Ÿäº§ç¯å¢ƒå‡çº§å‰ï¼Œè¯·åŠ¡å¿…æ£€æŸ¥è„šæœ¬å…¼å®¹æ€§ã€å¹¶å‘å®‰å…¨ä»¥åŠè®¡æ•°è¡°å‡ç­–ç•¥ï¼Œä»¥ç¡®ä¿ç³»ç»Ÿçš„ç¨³å®šä¸å…¬å¹³è°ƒåº¦ã€‚

---

### Update est_time for stage-b-test-small-1-gpu tests (#16835)
**SHA**: `cc25f9d` | ğŸ”— [æŸ¥çœ‹æäº¤](https://github.com/sgl-project/sglang/commit/cc25f9df50e1578dd4313004f2f15a501b4c8337)

**ğŸ¯ å˜æ›´ç±»å‹**ï¼šå…¶ä»–ï¼ˆCI å…ƒæ•°æ®è°ƒæ•´ï¼‰  
**âš¡ é‡è¦ç¨‹åº¦**ï¼šğŸŸ¡ ä¸­  
**ğŸ“‹ å˜æ›´æ‘˜è¦**ï¼šæœ¬æ¬¡æäº¤ç»Ÿä¸€ä¿®æ”¹äº† `test/registered/**/*.py` ä¸­ `register_cuda_ci(..., suite="stage-b-test-small-1-gpu")` çš„ `est_time` å‚æ•°ã€‚å¤§å¤šæ•°æµ‹è¯•ç”¨ä¾‹çš„é¢„è®¡è¿è¡Œæ—¶é—´è¢«ä¸Šè°ƒï¼ˆå°‘æ•°ä¸‹è°ƒï¼‰ï¼Œä»¥æ›´è´´è¿‘å®é™…æ‰§è¡Œæ—¶é•¿ã€‚  

**ğŸ¯ å½±å“èŒƒå›´**ï¼š  
- æ‰€æœ‰å±äº **stage-b-test-small-1-gpu** CI é˜¶æ®µçš„å• GPU æµ‹è¯•ï¼ŒåŒ…æ‹¬ attentionã€backendã€deterministicã€gptâ€‘ossã€cudaâ€‘graphã€dllmã€hicacheã€loraã€mlaã€modelã€moeã€openai_serverã€opsã€quantã€schedulerã€specã€vlm ç­‰å­æ¨¡å—ã€‚  
- ä»…æ¶‰åŠ CI æ³¨å†Œæ–‡ä»¶ `sglang/test/ci/ci_register.py` ä¸­çš„å…ƒæ•°æ®ï¼Œä¸ä¼šå½±å“è¿è¡Œæ—¶é€»è¾‘æˆ–æ¨¡å‹ä»£ç ã€‚

**ğŸ’¡ å…³æ³¨å»ºè®®**ï¼š  
1. **éªŒè¯ä¼°ç®—å‡†ç¡®æ€§**ï¼šåœ¨ CI ç¯å¢ƒä¸‹è·‘ä¸€éå®Œæ•´çš„ `stage-b-test-small-1-gpu` å¥—ä»¶ï¼Œç¡®è®¤æ–° `est_time` èƒ½è¦†ç›–å®é™…è€—æ—¶ä¸”ä¸å¯¼è‡´è¶…æ—¶æˆ–èµ„æºæµªè´¹ã€‚  
2. **é˜²æ­¢è¯¯åˆ¤**ï¼šè‹¥éƒ¨åˆ†ç”¨ä¾‹å®é™…ä»ç„¶æ¯”æ–°ä¼°ç®—å¿«ï¼Œå¯èƒ½å¯¼è‡´ CI èµ„æºé—²ç½®ï¼›è‹¥å‡ºç°æ˜æ˜¾è¶…å‡ºï¼ŒåŠæ—¶å†è°ƒé«˜å¯¹åº”å€¼ã€‚  
3. **åŒæ­¥æ–‡æ¡£**ï¼šæ›´æ–°é¡¹ç›®çš„ CI è¯´æ˜æˆ– README ä¸­å…³äºå„æµ‹è¯•å¥—ä»¶çš„é¢„ä¼°æ—¶é—´ï¼Œä»¥å…æ–°è´¡çŒ®è€…è¯¯è§£ã€‚  
4. **ç›‘æ§æ³¢åŠ¨**ï¼šåç»­è‹¥ç¡¬ä»¶æˆ–ä¾èµ–åº“ï¼ˆå¦‚ CUDAã€PyTorchï¼‰å‡çº§å¯¼è‡´æ—¶é—´å˜åŒ–ï¼Œè®°å¾—åŒæ­¥è°ƒæ•´è¯¥å…ƒæ•°æ®ï¼Œä¿æŒ CI ç¨³å®šã€‚  

æ­¤æ¬¡ä¿®æ”¹ä¸»è¦æ˜¯æå‡ CI è°ƒåº¦çš„å‡†ç¡®æ€§ï¼Œå¯¹åŠŸèƒ½å®ç°æ²¡æœ‰ç›´æ¥å½±å“ï¼Œä½†éœ€ç¡®ä¿ä¼°ç®—ä¸å®é™…è¿è¡Œæ—¶é•¿ä¿æŒä¸€è‡´ï¼Œä»¥é¿å… CI å¤±è´¥æˆ–èµ„æºæµªè´¹ã€‚

---

### Fix parallel tool call parsing bug when tool parameters contain arrays (#16345)
**SHA**: `cf14feb` | ğŸ”— [æŸ¥çœ‹æäº¤](https://github.com/sgl-project/sglang/commit/cf14feba4d31b211e9c708f1ef07b3d91f46b381)

âš ï¸ LLMåˆ†æå¤±è´¥ï¼ˆå·²é‡è¯•3æ¬¡ï¼‰: APIè¯·æ±‚å¤±è´¥: HTTPSConnectionPool(host='integrate.api.nvidia.com', port=443): Read timed out. (read timeout=30)

*æš‚æ— åˆ†æ*

---

#### ğŸŸ¢ ä½é‡è¦åº¦å˜æ›´ (8)

### [CI] reapply max-parallel in `stage-b-test-small-1-gpu` (#16906)
**SHA**: `cf1426a` | ğŸ”— [æŸ¥çœ‹æäº¤](https://github.com/sgl-project/sglang/commit/cf1426a7b7740f4bd19b311710dd86b19addf36e)

**ğŸ¯ å˜æ›´ç±»å‹**ï¼šé…ç½®è°ƒæ•´  
**âš¡ é‡è¦ç¨‹åº¦**ï¼šğŸŸ¢ä½  
**ğŸ“‹ æ‘˜è¦**ï¼šå°† CI å·¥ä½œæµ `stage-b-test-small-1-gpu` çš„é»˜è®¤å¹¶è¡Œæ•°ä» 4 è°ƒæ•´ä¸º 3ï¼Œå¹¶ä½¿ç”¨åŠ¨æ€ `max-parallel` å‚æ•°ï¼Œä½¿é«˜ä¼˜å…ˆçº§ PR ä»å¯ä½¿ç”¨ 15 å¹¶è¡Œã€‚

---

### [Tiny] Rename test_sparse_flash_attn.py to fix CI (#16895)
**SHA**: `f9fc50a` | ğŸ”— [æŸ¥çœ‹æäº¤](https://github.com/sgl-project/sglang/commit/f9fc50acd63192d2e3d02a080a88aff57204cd89)

**ğŸ¯ å˜æ›´ç±»å‹**ï¼šæµ‹è¯•ä¿®æ”¹  
**âš¡ é‡è¦ç¨‹åº¦**ï¼šğŸŸ¢ ä½  
**ğŸ“‹ æ‘˜è¦**ï¼šå°† `test_sparse_flash_attn.py` é‡å‘½åä¸º `test_flash_attn_sparse.py`ï¼Œä»¥ç¬¦åˆ CI å¯¹æµ‹è¯•æ–‡ä»¶å‘½åçš„è¦æ±‚ï¼Œç¡®ä¿æŒç»­é›†æˆé¡ºç•…ã€‚

---

### [Diffusion] Docs for Diffusers backend (#16864)
**SHA**: `7b089ae` | ğŸ”— [æŸ¥çœ‹æäº¤](https://github.com/sgl-project/sglang/commit/7b089ae4e0cae55c827d878aa623e0fb086c3f61)

**ğŸ¯ å˜æ›´ç±»å‹**ï¼šæ–‡æ¡£æ›´æ–°  
**âš¡ é‡è¦ç¨‹åº¦**ï¼šğŸŸ¢ä½  
**ğŸ“‹ æ‘˜è¦**ï¼šåœ¨ `cli.md` ä¸­æ–°å¢ Diffusers åç«¯ç« èŠ‚ï¼Œè¯´æ˜ç›¸å…³å‘½ä»¤å‚æ•°ã€ä½¿ç”¨ç¤ºä¾‹åŠé…ç½®æ–¹å¼ï¼Œå¸®åŠ©ç”¨æˆ·é€šè¿‡ Diffusers è¿è¡Œ SGLang æ‰©æ•£æ¨¡å‹ã€‚

---

### [CI]Move fa4 e2e test to 4-gpu-b200 runner (#16889)
**SHA**: `8b5d426` | ğŸ”— [æŸ¥çœ‹æäº¤](https://github.com/sgl-project/sglang/commit/8b5d4263409ad9ea33d9a8c315c64ccfcd6e8ace)

**ğŸ¯ å˜æ›´ç±»å‹**ï¼šé…ç½®è°ƒæ•´  
**âš¡ é‡è¦ç¨‹åº¦**ï¼šğŸŸ¢ä½  
**ğŸ“‹ æ‘˜è¦**ï¼šå°† `test_flash_attention_4.py` ä¸­çš„ CI æ³¨å†Œä» `stage-b-test-large-1-gpu` ä¿®æ”¹ä¸º `stage-b-test-4-gpu-b200`ï¼Œä»¥åœ¨ 4â€‘GPU Blackwell B200 ç¯å¢ƒè¿è¡Œè¯¥é—ªå­˜æ³¨æ„åŠ›æµ‹è¯•ã€‚

---

### Tiny fix hicache kernel backend comparison (#16867)
**SHA**: `ff97814` | ğŸ”— [æŸ¥çœ‹æäº¤](https://github.com/sgl-project/sglang/commit/ff978142324540b7814911a900cca2bdba5c065e)

**ğŸ¯ å˜æ›´ç±»å‹**ï¼šä»£ç é‡æ„  
**âš¡ é‡è¦ç¨‹åº¦**ï¼šğŸŸ¢ä½  
**ğŸ“‹ æ‘˜è¦**ï¼šå°† `hicache_io_backend is "kernel"` çš„èº«ä»½æ¯”è¾ƒæ”¹ä¸º `== "kernel"`ï¼Œé¿å…ä½¿ç”¨ `is` æ¯”è¾ƒå­—ç¬¦ä¸²å¯¼è‡´çš„é€»è¾‘é”™è¯¯ã€‚```

---

### [BugFix] fix gpt-oss-120b launch failure with --enable-piecewise-cuda-graph (#16757)
**SHA**: `a2c2c09` | ğŸ”— [æŸ¥çœ‹æäº¤](https://github.com/sgl-project/sglang/commit/a2c2c09d7d2e146235a9f985b20375f6efa66c98)

**ğŸ¯ å˜æ›´ç±»å‹**ï¼šä»£ç é‡æ„  
**âš¡ é‡è¦ç¨‹åº¦**ï¼šğŸŸ¢ä½  
**ğŸ“‹ æ‘˜è¦**ï¼šåœ¨ `mxfp4.py` ä¸­å°† `upcast_from_mxfp` è°ƒç”¨çš„å‚æ•° `dtype` æ›¿æ¢ä¸º `target_dtype`ï¼Œå¹¶å¯¹é½å‚æ•°æ ¼å¼ï¼Œä½¿ä»£ç æ›´æ¸…æ™°ï¼Œä¿®å¤äº†åœ¨ `--enable-piecewise-cuda-graph` å¯åŠ¨æ—¶çš„å´©æºƒé—®é¢˜ã€‚

---

### [tiny remove] remove torch_compile in parallel_state (#16865)
**SHA**: `2a9344d` | ğŸ”— [æŸ¥çœ‹æäº¤](https://github.com/sgl-project/sglang/commit/2a9344d3200effb2fa25b372cfac6827ea350201)

**ğŸ¯ å˜æ›´ç±»å‹**ï¼šä»£ç é‡æ„  
**âš¡ é‡è¦ç¨‹åº¦**ï¼šğŸŸ¢ ä½  
**ğŸ“‹ æ‘˜è¦**ï¼šåœ¨ `parallel_state.py` ä¸ `model_runner.py` ä¸­ç§»é™¤ `torch_compile` å‚æ•°åŠå…¶ä¼ é€’ï¼Œç®€åŒ–æ¨¡å‹å¹¶è¡Œåˆå§‹åŒ–é€»è¾‘ã€‚

---

### [hot fix ci] Hot fix for the unregistered. (#16877)
**SHA**: `78c4175` | ğŸ”— [æŸ¥çœ‹æäº¤](https://github.com/sgl-project/sglang/commit/78c41758add971f99e317e0f6f5440339424251e)

**ğŸ¯ å˜æ›´ç±»å‹**ï¼šæµ‹è¯•ä¿®æ”¹  
**âš¡ é‡è¦ç¨‹åº¦**ï¼šğŸŸ¢ä½  
**ğŸ“‹ æ‘˜è¦**ï¼šåœ¨ `test/registered/utils/test_log_utils.py` ä¸­æ–°å¢å¯¹ `register_cpu_ci` çš„å¯¼å…¥å¹¶è°ƒç”¨ï¼Œä»¥åœ¨ CI ä¸­æ³¨å†Œè¯¥æµ‹è¯•ç”¨ä¾‹çš„é¢„ä¼°æ‰§è¡Œæ—¶é—´å’Œå¥—ä»¶ã€‚

---

