# 每日更新报告（2026-01-23）

## sgl-project/sglang

| 提交时间 | 作者 | 提交信息 |
|----------|------|----------|
| 2026-01-23 23:12:06 | Yi Zhong | add the fa4 mm backend and varlen func (#13539) |
| 2026-01-23 20:26:21 | akhilg-nv | [DeepSeek V3.2] Enable trtllm NSA with bf16 kvcache (#16758) |
| 2026-01-23 17:57:04 | Nicolas Castet | Support symmetric memory pre-allocation to avoid fragmentation (#17089) |
| 2026-01-23 16:04:16 | Alison Shao | Fix CI install failure when rerunning tests via workflow_dispatch (#17612) |
| 2026-01-23 15:36:05 | siyu | set cooldown_interval_minutes to 0 for liusy58 (#17637) |
| 2026-01-23 15:22:42 | Yuzhen Zhou | turn off dit_layerwise_offload for wan on rocm (#17569) |
| 2026-01-23 15:21:00 | Hexq0210 | [NPU] update doc for Ascend NPU (#17621) |
| 2026-01-23 15:17:31 | Even Zhou | [NPU] [CI] temporarily disable mtp test (#17614) |
| 2026-01-23 14:41:38 | Minglei Zhu | fix gpt-oss launch failure with piecewise cuda graph (#17532) |
| 2026-01-23 14:31:44 | Alison Shao | Re-enable unit-test-deepep-8-gpu and unit-test-backend-4-gpu-gb200 (#17438) |
| 2026-01-23 14:04:51 | Lianmin Zheng | Lazy import torchao (#17626) |
| 2026-01-23 13:48:52 | Bingxu Chen | [AMD CI] Add 2-GPU sgl-kernel Tests (#17555) |
| 2026-01-23 11:15:15 | JiaruiChang5268 | [NPU]bugfix: fix for dsv3.2 and dsvl2 (#17007) |
| 2026-01-23 11:02:32 | Ke Bao | Update mamba env setting (#17566) |
| 2026-01-23 10:53:45 | siyu | Skip mm feature pool init to avoid EPD OOM (#16388) |
| 2026-01-23 10:45:05 | YC Tseng | [AMD] CI - migrate perf test and fix stage-b-test-1-gpu-amd (#17340) |
| 2026-01-23 09:13:36 | amote-i | update dependence docs of npu (#17573) |
| 2026-01-23 08:29:08 | Alison Shao | Update test README with CI registry documentation and 5090/H100 guidance (#17368) |
| 2026-01-23 07:08:25 | MMuzzammil1 | Bugfix: Writing to storage when write-back method is chosen (#14718) |
| 2026-01-23 06:31:48 | hxie | configuration file support and nixl integration augmentation for hicache-storage-backend-extra-config (#16602) |
| 2026-01-23 06:00:11 | Jacob Gordon | refactor(benchmark): prevents variable shadowing (#17607) |
| 2026-01-23 05:57:08 | wufann | [AMD] Support ds3.2 on gfx942 platform (#17504) |
| 2026-01-23 03:45:47 | Jacob Gordon | refactor(codespell): corrects typos covered up by whitelist (#17601) |
| 2026-01-23 03:36:23 | Jacob Gordon | types: preps `SessionReqNode` for IDE-driven renames (#17602) |

### 📊 统计摘要
> 本日共 24 个提交 | 🔴高 1 | 🟡中 15 | 🟢低 8
## 📋 目录

- [sgl-project/sglang](#sgl-project-sglang)
  - [📊 统计摘要](#-统计摘要)
  - [🔴 高重要度变更 (1)](#-🔴-高重要度变更-1)
    - [configuration file support and nixl integration augmentat...](#13f8804)
  - [🟡 中重要度变更 (15)](#-🟡-中重要度变更-15)
    - [add the fa4 mm backend and varlen func (#13539)](#08fcda2)
    - [[DeepSeek V3.2] Enable trtllm NSA with bf16 kvcache (#16758)](#2fb3281)
    - [Support symmetric memory pre-allocation to avoid fragment...](#48e9daa)
    - [turn off dit_layerwise_offload for wan on rocm (#17569)](#2169025)
    - [[NPU] [CI] temporarily disable mtp test (#17614)](#69ac8b5)
    - [Re-enable unit-test-deepep-8-gpu and unit-test-backend-4-...](#d7dd0b8)
    - [Lazy import torchao (#17626)](#56e6652)
    - [[AMD CI] Add 2-GPU sgl-kernel Tests (#17555)](#50a2e43)
    - [[NPU]bugfix: fix for dsv3.2 and dsvl2 (#17007)](#c0b5a18)
    - [Update mamba env setting (#17566)](#7ace64d)
    - [Skip mm feature pool init to avoid EPD OOM (#16388)](#62e6a74)
    - [[AMD] CI - migrate perf test and fix stage-b-test-1-gpu-a...](#04a10c9)
    - [refactor(benchmark): prevents variable shadowing (#17607)](#a296c99)
    - [[AMD] Support ds3.2 on gfx942 platform (#17504)](#a921029)
    - [refactor(codespell): corrects typos covered up by whiteli...](#15b5117)
  - [🟢 低重要度变更 (8)](#-🟢-低重要度变更-8)
    - [Fix CI install failure when rerunning tests via workflow_...](#b23470e)
    - [set cooldown_interval_minutes to 0 for liusy58 (#17637)](#1734916)
    - [[NPU] update doc for Ascend NPU (#17621)](#69470db)
    - [fix gpt-oss launch failure with piecewise cuda graph (#17...](#2b2f317)
    - [update dependence docs of npu (#17573)](#0fec882)
    - [Update test README with CI registry documentation and 509...](#1e8e0cc)
    - [Bugfix: Writing to storage when write-back method is chos...](#2399af5)
    - [types: preps `SessionReqNode` for IDE-driven renames (#17...](#2c86a06)
#### 🔴 高重要度变更 (1)

### configuration file support and nixl integration augmentation for hicache-storage-backend-extra-config (#16602)
**SHA**: `13f8804` | 🔗 [查看提交](https://github.com/sgl-project/sglang/commit/13f88045b3290fd50800103c9da725e326a932be)

**🎯 变更类型**：功能增强 / 架构变更  
**⚡ 重要程度**：🔴 高  
**📋 变更摘要**：  
- 为 HiCache Storage Backend 增加了对 **配置文件**（JSON / TOML / YAML）的支持，使用 `@` 前缀来指示从文件读取额外配置。  
- 引入 `NixlBackendConfig` 类，实现配置的统一解析、插件选择以及后端初始化参数的传递。  
- 相应地更新了文档、命令行参数说明以及内部解析逻辑，使 NIXL 后端能够基于文件化配置自动选择和初始化插件。

**🎯 影响范围**：  
- `docs/advanced_features/*`（使用说明）  
- `sglang/srt/server_args.py`（CLI 参数描述）  
- `sglang/srt/mem_cache/hiradix_cache.py`（解析 `--hicache-storage-backend-extra-config`）  
- `sglang/srt/mem_cache/storage/nixl/nixl_utils.py`（新增 `NixlBackendConfig`、修改 `NixlBackendSelection`）  
- `sglang/srt/mem_cache/storage/nixl/hicache_nixl.py`（后端创建流程）  
- 新增示例配置文件 `nixl.config.toml.sample`  

---

### 🔍 技术洞察

| 维度 | 影响分析 |
|------|----------|
| **架构影响** | - 引入 **配置抽象层**（`NixlBackendConfig`），实现 **配置来源统一**（CLI JSON 字符串、文件或环境变量）。<br>- `NixlBackendSelection` 现在接受 `NixlBackendConfig`，在创建后端前自动提取对应插件的初始化参数，提升了后端插件化的可扩展性。<br>- 新增 `@` 前缀约定，使 CLI 与文件配置解耦，符合 “配置即代码” 的设计理念。 |
| **性能影响** | - 启动时多一次文件 I/O（读取 JSON/TOML/YAML），成本极低（毫秒级）。<br>- 通过配置文件可以精细调参（如 GDS batch size、IO pool），潜在提升 I/O 吞吐与延迟，尤其在大模型/高并发场景下收益明显。<br>- 代码路径仅在解析阶段执行，对运行时缓存/查询路径无额外开销。 |
| **安全考虑** | - **路径可信度**：`@` 后直接打开文件，若路径可被外部控制（例如容器中挂载的配置目录），可能导致任意文件读取或配置注入。建议限制相对路径或对路径进行白名单校验。<br>- **解析库风险**：引入 `tomllib`（Python 标准库）和 `PyYAML`，如果使用的 YAML 文件包含不可信的构造（如 `!!python/object`），可能触发代码执行。使用 `yaml.safe_load` 已是安全做法，但仍需在依赖说明中强调**仅支持安全模式**。<br>- **异常信息泄露**：解析错误直接打印异常堆栈，可能泄露系统路径。建议统一包装异常信息，仅返回 “配置解析失败”。 |
| **可维护性** | - 新增类与参数传递链路清晰，逻辑分层（解析 → 配置对象 → 选型 → 初始化），代码可读性提升。<br>- 文档同步完善，示例配置文件提供完整参考，降低新手上手成本。<br>- 需要在 `setup.cfg` / `requirements.txt` 中声明对 `PyYAML` 的可选依赖，防止在缺失时运行时报错。 |
| **兼容性** | - 仍保持原有 JSON‑string 形式的兼容（不以 `@` 开头时仍走旧路径），对已有用户零影响。<br>- 由于 `tomllib` 只在 Python 3.11+ 可用，若项目仍支持 3.10，需要在代码中加入回退至第三方 `tomli`（已在库中做了 `import tomllib`，在 3.10 环境会抛 ImportError）。建议在 `requirements` 中添加 `tomli; python_version < "3.11"`。 |

---

### ⚠️ 潜在风险

1. **文件路径安全**：`--hicache-storage-backend-extra-config "@config.toml"` 若传入相对路径或恶意路径，可能导致读取不受信任的配置文件。  
2. **依赖缺失**：在 Python 3.10 环境或未安装 `PyYAML` 时，`import yaml` 会失败，导致启动错误。  
3. **错误传播**：解析异常目前直接 `raise e`，如果配置文件语法错误会导致服务启动崩溃，影响可用性。  
4. **插件参数不匹配**：如果配置文件中出现不被对应插件支持的键，`agent.create_backend` 仍会收到这些键，可能导致后端初始化失败或产生不可预期行为。  
5. **环境变量冲突**：插件选择仍会参考 `SGLANG_HICACHE_NIXL_BACKEND_PLUGIN` 环境变量，若用户同时使用文件配置和环境变量，行为可能不一致，需要明确优先级。  

---

### 💡 关注建议

| 对象 | 建议 |
|------|------|
| **开发者** | - 为 `NixlBackendConfig` 添加 **路径白名单**（如仅允许 `./config/*.toml`）或 `os.path.abspath` 检查。<br>- 在 `requirements` 中声明 `PyYAML` 为 **optional**，并在缺失时提供友好错误提示。<br>- 为 Python < 3.11 添加兼容 `tomli` 的导入包装。<br>- 增加单元测试：<br>  - JSON 字符串、TOML、YAML 三种格式均能被正确解析；<br>  - `@` 前缀错误路径、空文件、语法错误的容错行为。 |
| **运维/用户** | - 推荐使用 **配置文件**（TOML）统一管理多插件参数，避免在命令行中写长 JSON。<br>- 确认配置文件所在目录的 **权限**（仅 root/sglang 用户可读），防止被篡改。<br>- 如使用对象存储（OBJ 插件），务必提前设置 `AWS_DEFAULT_BUCKET` 环境变量或在配置文件中 `bucket` 字段提供。 |
| **安全审计** | - 检查容器/机器上是否有不受信任的配置文件可被 `@` 引用。<br>- 对 `PyYAML` 版本进行锁定，确保只使用 `safe_load`。 |
| **文档** | - 在 CLI 参数说明中明确 `@` 前缀的使用规则与示例。<br>- 在 “HiCache 配置”章节加入 **安全最佳实践**（路径校验、权限要求）。 |

---

**总体结论**  
本次提交为 HiCache 的存储后端引入了配置文件化的能力，显著提升了可配置性、可维护性以及在复杂部署场景下的灵活度。对系统架构的影响局限在启动阶段，性能提升潜力大，安全风险主要集中在配置文件路径与解析库的使用上。只要在发布说明中加入依赖兼容性说明、路径安全检查以及异常容错处理，此改动的收益远大于潜在风险，值得合并。

---

#### 🟡 中重要度变更 (15)

### add the fa4 mm backend and varlen func (#13539)
**SHA**: `08fcda2` | 🔗 [查看提交](https://github.com/sgl-project/sglang/commit/08fcda2f634ac705226ee95d2cd05b86f69c6fe1)

**🎯 变更类型**：功能增强  
**⚡ 重要程度**：🟡 中  

**📋 变更摘要**  
- 为视觉（Vision）注意力层新增 FlashAttention 4（FA4）变长实现 `VisionFlash4Attention`，并在多模态注意力后端选项中加入 `fa4`。  
- 文档、CLI 参数及后端映射表同步更新；`is_blackwell` 重命名为 `is_blackwell_supported`，并在后端选择逻辑中相应改写。  

**🎯 影响范围**  
- `python/sglang/srt/layers/attention/vision.py`（核心注意力实现）  
- `python/sglang/srt/server_args.py`、`docs/advanced_features/*`（CLI 与文档）  
- 后端选择逻辑 `SrtAttentionBase._determine_attention_backend`  

**💡 关注建议**  
1. **硬件兼容性**：FA4 仅在支持 FlashAttention 4 的 GPU（如 NVIDIA Hopper/Blackwell）上可用，确保 `is_blackwell_supported()` 正确检测并在不支持时给出友好提示或回退。  
2. **依赖管理**：确认 `flash_attn_varlen_func` 已在项目依赖中锁定对应版本，避免运行时 `ImportError`；若未在 `requirements.txt` 标记，及时补充。  
3. **单元测试**：为 `VisionFlash4Attention` 编写覆盖变长序列、`SingletonCache` 以及空 `cu_seqlens` 的测试，防止因 shape/dtype 误差导致 CUDA 错误。  
4. **后端冲突检查**：当前仅对 `fa3` 在 Blackwell 上做了限制，建议同样在 `fa4` 选择时加入兼容性校验（如不支持的 GPU 抛出明确错误）。  
5. **文档一致性**：检查所有支持矩阵、CLI 帮助信息与实际实现保持同步，防止用户在 `--mm-attention-backend` 中选到不可用的后端。  

整体来看，新增 FA4 后端为多模态视觉任务提供了更高的吞吐与更低的延迟，影响范围集中在注意力层实现与参数解析，主要风险在于硬件和依赖的匹配。按以上建议补全检测与测试，可保障功能平稳上线。

---

### [DeepSeek V3.2] Enable trtllm NSA with bf16 kvcache (#16758)
**SHA**: `2fb3281` | 🔗 [查看提交](https://github.com/sgl-project/sglang/commit/2fb328109fb910a7a8027139d289740b5daaf907)

**🎯 变更类型**：功能增强（新增 TRT‑LLM 后端并扩展 NSA 自动配置）  
**⚡ 重要程度**：🟡 中  

**📋 变更摘要**  
1. 在 `nsa_backend.py` 中将后端类型扩展至 `"trtllm"`，并实现 `_forward_trtllm` 调用 FlashInfer 的 `trtllm_batch_decode_with_kv_cache_mla`。  
2. `server_args.py` 改为默认 `nsa_prefill_backend` / `nsa_decode_backend` 为 `None`，并加入 `_set_default_nsa_kv_cache_dtype`、`_set_default_nsa_backends` 两个自动化函数，根据 GPU 架构与 KV‑cache dtype 自动设定后端和 dtype。  
3. 更新 CLI 参数帮助信息，新增 `"trtllm"` 选项。  

**🎯 影响范围**  
- `sglang/srt/layers/attention/nsa_backend.py`（稀疏注意力实现）  
- `sglang/srt/server_args.py`（启动参数与默认后端选择）  
- 相关配置/模型加载路径（DeepSeek V3.2）  

**💡 关注建议**  
- 在 Hopper（SM10+）和 Blackwell（SM90）上分别跑 FP8 与 BF16 场景，验证 `trtllm` 解码路径的数值正确性与性能。  
- 检查 `flashinfer` 版本兼容性，防止 `import flashinfer.decode` 在未安装时导致启动失败。  
- 确认 `global_workspace_buffer` 在多进程/多卡环境下的安全性，避免跨卡共享造成 OOM。  
- 对已显式指定 `--nsa‑prefill‑backend` 或 `--nsa‑decode‑backend` 的用户，确保日志提醒能帮助其手动配置 `--kv-cache-dtype`，避免默认自动切换导致性能或精度差异。  
- 添加单元测试覆盖 `trtllm` 路径以及自动后端/dtype 推断逻辑，防止未来改动破坏默认行为。

---

### Support symmetric memory pre-allocation to avoid fragmentation (#17089)
**SHA**: `48e9daa` | 🔗 [查看提交](https://github.com/sgl-project/sglang/commit/48e9daadff64c0dc327bcb17223486af3b1a31a7)

**🎯 变更类型**：功能增强（对称内存预分配）  
**⚡ 重要程度**：🟡 中  

**📋 变更摘要**  
1. 新增环境变量 `SGLANG_SYMM_MEM_PREALLOC_GB_SIZE`（默认 4 GB），用于在开启 `--enable-symm-mem` 时预分配对称内存池，降低 OOM 场景下的显存碎片。  
2. 在 `ModelRunner` 中创建 `forward_stream` 并在该流上执行预分配；`Scheduler` 与 `TPWorker` 也相应传递该流。  
3. `server_args` 若开启对称内存且未显式设置预分配大小，会自动写入默认 4 GB 并给出警告。  
4. 文档、测试均同步更新，新增对称内存的端到端评估 case。  

**🎯 影响范围**  
- `python/sglang/srt/environ.py`、`scheduler.py`、`tp_worker.py`、`model_runner.py`、`server_args.py`  
- NCCL 对称内存池（pynccl_allocator）  
- GPU 显存管理、 overlapped 调度路径  
- 文档与 CI 测试  

**💡 关注建议**  
1. **显存边界检查**：预分配前应显式检测 `envs.SGLANG_SYMM_MEM_PREALLOC_GB_SIZE` 是否会超过当前 GPU 可用显存，避免启动即 OOM。  
2. **forward_stream 生命周期**：`forward_stream` 只在 `ModelRunner` 创建，确保 `Scheduler`、`TPWorker` 在使用前已完成 `ModelRunner` 的初始化，否则可能出现空指针。  
3. **环境变量默认值**：`EnvInt(-1)` 仍保留负数默认，建议在 `server_args` 中统一将其设为正数后再传递，防止在未开启 `--enable-symm-mem` 时误触预分配。  
4. **日志与监控**：预分配成功与否的日志已加入，建议在生产环境开启 `SGLANG_LOG_LEVEL=INFO` 以便追踪显存使用情况。  
5. **测试可靠性**：新增 `TestDeepseekV3FP4SymmetricMemory` 依赖 4 GPU 环境，CI 机器若显存不足可能导致 flaky，考虑在 CI 中增加显存检查或改为可配置的跳过条件。  

总体而言，改动实现了对称内存的预分配，能显著降低显存碎片风险，但需要在显存充足性和流管理上做好防护，以免在资源受限的部署场景出现启动失败。

---

### turn off dit_layerwise_offload for wan on rocm (#17569)
**SHA**: `2169025` | 🔗 [查看提交](https://github.com/sgl-project/sglang/commit/2169025b77844f1842d77a85775115a7923dc2ed)

**🎯 变更类型**：功能增强（平台‑WAN 适配）  
**⚡ 重要程度**：🟡 中  
**📋 变更摘要**：在 `Interface` 中新增 `enable_dit_layerwise_offload_for_wan_by_default` 默认返回 `True`，并在 ROCm 实现里覆盖为 `False`。`server_args.check_server_args` 在检测到 WAN pipeline 且用户未显式设置 `dit_layerwise_offload` 时，会依据当前平台的返回值自动打开或关闭该特性。  
**🎯 影响范围**：`python/sglang/multimodal_gen/runtime/platforms/interface.py`、`.../rocm.py`、`.../server_args.py`（以及所有依赖 `Platform` 判断的启动流程）。  

**💡 关注建议**  
1. **平台兼容性**：确保其他平台（CUDA、CPU 等）仍保持 `True`，避免意外性能回退；若未来新增平台需显式实现该方法。  
2. **回归测试**：在 ROCm 环境下运行 WAN 推理基准，验证关闭 DIT layerwise offload 真正提升性能；在 CUDA 环境下确认仍保持开启且不产生错误。  
3. **文档说明**：更新平台说明与 `--dit-layerwise-offload` 参数文档，明确默认行为随平台变化。  
4. **用户显式覆盖**：保证用户通过命令行或配置显式设置 `dit_layerwise_offload` 时能够覆盖自动判断，防止因默认值导致的意外行为。  

总体而言，此次改动对平台自适应性能调优有积极作用，风险主要在于新平台缺少实现导致默认 `True` 与实际不匹配，建议在 CI 中加入平台方法的存在性检查。

---

### [NPU] [CI] temporarily disable mtp test (#17614)
**SHA**: `69ac8b5` | 🔗 [查看提交](https://github.com/sgl-project/sglang/commit/69ac8b58f7030cd758a9f659037fd9f69f980a5d)

**🎯 变更类型**：CI/测试相关（临时禁用不稳定的 MTP 测试）  
**⚡ 重要程度**：🟡 中  
**📋 变更摘要**：  
- 将 `test/manual/ascend/test_ascend_deepseek_mtp.py` 重命名（保持文件路径不变），但实际内容未改动。  
- 删除 `test/srt/ascend/test_ascend_tp2_fia_bf16.py` 中的 throughput 验证逻辑，防止在 CI 环境下因性能波动导致测试失败。  
- 在 `test/srt/run_suite.py` 中将 `ascend/test_ascend_deepseek_mtp.py` 的入口注释掉，使其不再被 CI 调度执行。  

**🎯 影响范围**：  
- **测试套件**：`test/srt/ascend/` 相关的两个文件以及统一调度脚本 `run_suite.py`。  
- **CI 流程**：NPU（Ascend）CI 现在不再运行 MTP 相关的性能基准测试。  

**💡 关注建议**：  
1. **恢复测试**：该修改是临时性的，建议在 MTP 性能更稳定位后恢复 `throughput` 检查及对应的测试入口，避免长期缺失该维度的回归保障。  
2. **记录原因**：在项目的 CI/Testing 文档或对应 Issue 中注明禁用的具体原因（如硬件波动、基准不确定等），便于后续排查。  
3. **监控 flake**：若未来重新启用，考虑为 throughput 测试加入容忍阈值或重试机制，减少因偶发波动导致的 CI 失败。  
4. **代码清理**：禁用的代码块（如 `test_b_throughput`）若长期不使用，可考虑迁移到 `@unittest.skip` 装饰或单独的 “slow” 测试目录，以保持主测试文件的简洁。  

总体来说，此次提交仅影响 CI 环境的测试覆盖，不会影响生产代码功能，但应在稳定后及时恢复，以确保模型性能回归仍然受到验证。

---

### Re-enable unit-test-deepep-8-gpu and unit-test-backend-4-gpu-gb200 (#17438)
**SHA**: `d7dd0b8` | 🔗 [查看提交](https://github.com/sgl-project/sglang/commit/d7dd0b8832293437f8652a9a8fadb8a0ccbcc4d0)

**🎯 变更类型**：功能增强（CI 测试恢复）  
**⚡ 重要程度**：🟡 中  

**📋 变更摘要**  
- 将原先因 8‑GPU 机器 cudaHostRegister 报错而被注释的 `unit-test-deepep-8-gpu` 以及因 GB200 runner 维修而屏蔽的 `unit-test-backend-4-gpu-gb200` 重新启用。  
- 对 `.github/workflows/pr-test.yml` 中的调度条件、依赖 `wait-for-stage-b`、超时及步骤脚本路径做了细节调整。  
- 在 `test/srt/run_suite.py` 中恢复对应 test‑suite 列表，使 8‑GPU DeepEP 大模型测试能够被执行。

**🎯 影响范围**  
- CI 工作流（pr‑test.yml）  
- 测试套件定义（run_suite.py）  
- 依赖安装脚本 `scripts/ci/ci_install_deepep.sh` 的调用路径  

**💡 关注建议**  
1. **机器可用性**：8‑GPU H200 与 4‑GPU GB200 为稀缺资源，开启后会显著增加 CI 排队时间，请关注 runner 的健康状态和利用率。  
2. **失败容忍**：新增 `timeout-minutes` 与 `enable-retry` 标志，建议在 CI 里保留 `continue-on-error`，以防硬件偶发性错误导致整个流水线阻塞。  
3. **脚本路径**：工作流中改为 `scripts/ci/ci_install_deepep.sh`，确认该路径在所有分支均存在，防止因路径不一致导致安装失败。  
4. **监控 flaky**：8‑GPU DeepEP 大模型测试历史上存在 cudaHostRegister 相关不稳定，恢复后请密切观察 CI 失败率，必要时增加 `run-on-failure` 重跑或回退注释。  
5. **文档更新**：在 CI 说明或 CONTRIBUTING 中标记这两个新增阶段的触发条件（schedule / parallel‑dispatch），帮助贡献者了解何时会运行这些耗时测试。  

总体而言，此次改动恢复了重要的高并发/大模型回归测试，对代码可靠性有正向提升，但需留意硬件资源和潜在 flaky，建议在首次几轮 PR 中收集统计数据后再决定是否进一步优化。

---

### Lazy import torchao (#17626)
**SHA**: `56e6652` | 🔗 [查看提交](https://github.com/sgl-project/sglang/commit/56e6652d1d3f66803e395210da3a5e9055f587e0)

**🎯 变更类型**：功能增强 / 轻量化改造  
**⚡ 重要程度**：🟡 中  

**📋 变更摘要**  
1. **文档**：在安装说明中将强制重装的 `torch` 版本固定为 `2.9.1`，避免因依赖解析而误装 CPU 版 PyTorch。  
2. **配置注册**：`lfm2.py` 中去掉了注册完成后的日志输出，保持静默注册。  
3. **TorchAo 工具**：`torchao_utils.py` 实现 **懒加载**：在函数入口先判断 `torchao_config` 是否为空，若为空直接返回模型，避免不必要的 `torchao` 导入；并把相同判空逻辑提前，简化后续分支。

**🎯 影响范围**  
- **文档**：`docs/get_started/install.md` → 影响新手安装体验。  
- **配置系统**：`sglang/srt/configs/lfm2.py` → 影响模型配置加载（仍然会覆盖 HuggingFace 的 `Lfm2Config`）。  
- **模型量化路径**：`sglang/srt/layers/torchao_utils.py` → 影响所有使用 `apply_torchao_config_to_model` 的模型初始化，尤其在未安装 `torchao` 或未提供量化配置时的表现。

**💡 关注建议**  
1. **依赖兼容**：确认 `torch==2.9.1` 与项目当前支持的 CUDA/cuDNN 版本匹配，避免因固定版本导致的兼容性回滚。  
2. **可选依赖**：`torchao` 仍是可选依赖，建议在 `setup.cfg/pyproject.toml` 中声明 `torchao` 为 `extras_require["torchao"]`，并在文档中说明如何安装。  
3. **单元测试**：新增或更新测试，覆盖以下场景：  
   - `torchao_config` 为 `None`/空串时，模型返回未被修改。  
   - 各种 quant 配置（`int8wo`, `int8dq`, `int4wo-128` 等）是否能正确触发对应的 `quantize_` 调用。  
   - 在未安装 `torchao` 的环境下调用函数不抛异常。  
4. **日志一致性**：去除 `lfm2.py` 的注册日志后，若团队依赖该日志进行调试，建议在调试模式下额外打印（使用 `logging.debug`），以免失去可观测性。  
5. **文档同步**：更新其他平台的安装指引（如 AMD、TPU）以保持与此处统一的 `torch` 版本提示。  

总体来说，此次改动提升了安装过程的确定性，同时通过懒加载避免了在不需要量化时加载 `torchao`，对运行时性能和用户体验都有正面影响。后续关注兼容性测试和可选依赖的声明即可。

---

### [AMD CI] Add 2-GPU sgl-kernel Tests (#17555)
**SHA**: `50a2e43` | 🔗 [查看提交](https://github.com/sgl-project/sglang/commit/50a2e4345a25bc3dbbcab12d6afc8cf5f8970190)

**🎯 变更类型**：功能增强（CI 与测试覆盖）  
**⚡ 重要程度**：🟡 中  
**📋 变更摘要**：在 AMD CI workflow 中新增 `sgl-kernel-unit-test-2-gpu-amd` 阶段，使用 `linux-mi325-gpu-2` 机器执行两项针对多 GPU 环境的确定性 All‑Reduce 测试。对应的两份 Python 测试文件改为 pytest 形式，并加入 `skipif` 条件确保只有满足 2 GPU CUDA 环境时才运行。  

**🎯 影响范围**：  
- `.github/workflows/pr-test-amd.yml`（CI 流水线）  
- `sgl-kernel/tests/test_amd_deterministic_custom_allreduce.py`  
- `sgl-kernel/tests/test_amd_nccl_allreduce_determinism.py`  

**💡 关注建议**  
1. **CI 资源**：确认 `linux-mi325-gpu-2` runner 已在自建集群或 GitHub 自托管中可用，否则该作业会一直卡住。  
2. **环境变量**：`ensure_vram_clear.sh rocm` 与后续容器启动脚本需兼容多 GPU（尤其是显存清理），建议加入日志验证实际显卡数量。  
3. **测试可靠性**：两项测试内部仍使用 `torch.cuda.is_available()` 检查，若在 AMD GPU 上跑 ROCm，`torch.cuda` 为 `False`，导致全部跳过。考虑改为 `torch.backends.mps` 或 ROCm‑specific 检查，或在 CI 中使用 CUDA‑兼容的 AMD GPU（ROCm‑CUDA 兼容层）。  
4. **超时**：`timeout-minutes: 20` 对多进程启动和同步可能稍紧，建议在后续观察运行时长后适当调宽。  
5. **依赖锁定**：新增测试依赖 `pytest`，确保在 `amd_ci_install_dependency.sh` 中已显式安装对应版本，防止因版本差异导致 flaky。  

总体而言，此次改动提升了对 AMD 多 GPU 环境下确定性算子的回归覆盖，但需确保 CI 环境与测试条件匹配，避免出现“全部跳过”或资源不可用的情况。

---

### [NPU]bugfix: fix for dsv3.2 and dsvl2 (#17007)
**SHA**: `c0b5a18` | 🔗 [查看提交](https://github.com/sgl-project/sglang/commit/c0b5a180febef52bba4f1f3e974d364f6c96a10f)

**🎯 变更类型**：Bug 修复 / 功能增强  
**⚡ 重要程度**：🟡 中  

**📋 变更摘要**  
- 为 DeepSeek V2/V3.2 在 Ascend NPU 上的实现新增 `qk_nope_head_dim` 参数并在模型配置中传递。  
- 重构 `deepseek_v2_attention_mla_npu`：在支持 DeepSeek‑YARN RoPE 的情况下走专用分支，统一 NPU 事件/流同步逻辑，避免在 `alt_stream` 为 `None` 时出现空指针。  
- 在模型初始化中记录 `use_deepseek_yarn_rope` 标记。  
- 新增两套 NPU CI 测试，分别覆盖 DeepSeek‑V3.2‑Exp‑W8A8 文本模型和 DeepSeek‑VL2 VLM。  

**🎯 影响范围**  
- `python/sglang/srt/configs/model_config.py`（模型配置）  
- `python/sglang/srt/hardware_backend/npu/modules/deepseek_v2_attention_mla_npu.py`（NPU 注意力实现）  
- `python/sglang/srt/models/deepseek_v2.py`（模型构造）  
- 新增的 CI 测例 `test/registered/ascend/*`  

**💡 关注建议**  
1. **向后兼容**：新字段 `qk_nope_head_dim` 已在配置中添加，确认旧模型加载路径仍能得到默认值（若无该字段），防止旧模型报错。  
2. **流同步**：代码在 `alt_stream` 为 `None` 时已做分支，建议在文档或注释中明确 `alt_stream` 的使用场景与默认行为，以免用户自行关闭导致不确定的执行顺序。  
3. **性能验证**：虽然同步改造提升了稳定性，但可能引入额外的事件开销，建议在 CI 或本地 benchmark 中记录前后延迟对比。  
4. **测试覆盖**：新增的两套 NPU 测试覆盖了文本和多模态模型，后续若继续加入新模型（如 V3.3），请保持相同的注册方式并确保 `est_time` 合理。  

总体来看，此次提交修复了 DeepSeek‑V3.2/VL2 在 Ascend NPU 上因 RoPE 参数缺失和流同步不当导致的崩溃，改动局限于 NPU 注意力实现和模型配置，对 CPU/GPU 路径无影响。保持现有 CI 通过即可安全合并。

---

### Update mamba env setting (#17566)
**SHA**: `7ace64d` | 🔗 [查看提交](https://github.com/sgl-project/sglang/commit/7ace64d1d88de1dfd3cfb6622f3fcbba4fe7eef8)

**变更概览**  
- 为 Mamba 系列模型引入统一的环境变量管理：在 `sglang/srt/environ.py` 新增 `SGLANG_MAMBA_CONV_DTYPE`、`SGLANG_MAMBA_SSM_DTYPE`（以及已存在的 `SGLANG_DISABLE_OUTLINES_DISK_CACHE`），统一使用 `EnvStr/EnvBool` 包装。  
- `mamba_utils.py` 改为通过 `envs` 读取 dtype，而不再直接访问 `os.environ`。  
- `server_args.py` 中的环境变量写入统一改为 `envs.xxx.set(...)`。  
- 单元测试改为使用 `envs.xxx.override(...)` 的上下文管理器（`nullcontext` 兼容非‑Mamba 模型），并在 `test_mamba_unittest.py` 中相同处理。  

**影响范围**  
- **运行时配置**：所有依赖 Mamba dtype 的代码（`mamba_utils`、调度器、缓存）现在通过 `envs` 获得值。  
- **启动逻辑**：`ServerArgs._handle_environment_variables` 统一使用 `envs`，避免了对全局 `os.environ` 的散乱写入。  
- **测试体系**：对 Mamba 模型的 dtype 切换使用临时覆盖，保证并行测试之间不会相互污染。

**潜在风险 & 建议**  
1. **向后兼容**：项目中仍有直接 `os.getenv("SGLANG_MAMBA_…")` 的旧代码时，可能读取不到 `envs` 已设置的值。建议在迁移完成前保留一层兼容（如在 `environ.py` 中实现 `__getitem__`），或在文档中明确迁移路径。  
2. **初始化顺序**：`envs.SGLANG_MAMBA_*` 的默认值已在 `Envs` 中声明，`mamba_utils` 采用 `envs.xxx.get()` 确保运行时才读取，避免启动前读取旧的 `os.environ`。仍需确认没有在模块导入时提前调用 `mamba2_state_dtype()` 的情形。  
3. **测试覆盖**：新增 `MAMBA_MODEL_PATHS` 与 `nullcontext` 已覆盖非 Mamba 场景，建议在 CI 中加入对 `SGLANG_MAMBA_CONV_DTYPE`、`SGLANG_MAMBA_SSM_DTYPE` 的显式值切换测试，防止默认值被误改。  
4. **文档更新**：新增环境变量应在 README/部署手册中补充说明，尤其是 dtype 选项对显存/精度的影响。  

总体而言，此次改动提升了环境变量的可管理性与测试可靠性，风险主要在迁移期间的兼容性，按上述检查点逐项验证即可安全上线。

---

### Skip mm feature pool init to avoid EPD OOM (#16388)
**SHA**: `62e6a74` | 🔗 [查看提交](https://github.com/sgl-project/sglang/commit/62e6a749b0638c2c50059347040df6d3b6766984)

**🎯 变更类型**：功能增强  
**⚡ 重要程度**：🟡 中  

**📋 变更摘要**  
在 `get_mm_processor` 中加入 `**kwargs`，并在 `BaseMultimodalProcessor.__init__` 新增 `skip_mm_pool` 参数。若 `skip_mm_pool=True` 且启用了 CUDA‑IPC，则不再实例化 `MmItemMemoryPool`，从而避免在 EPD 环境下的 OOM。  

**🎯 影响范围**  
- `python/sglang/srt/disaggregation/encode_receiver.py`：调用 `get_mm_processor` 时新增 `skip_mm_pool=True`。  
- `python/sglang/srt/managers/multimodal_processor.py`：函数签名改为接受 `**kwargs` 并向下传递。  
- `python/sglang/srt/multimodal/processors/base_processor.py`：构造函数加入对 `skip_mm_pool` 的解析，条件性创建 CUDA‑IPC 池。  

**💡 关注建议**  
1. **向后兼容**：默认仍然创建池（`skip_mm_pool=False`），确保现有路径行为不变。若有子类重写 `__init__`，需显式接受 `**kwargs`，否则会因参数不匹配报错。  
2. **属性安全**：后续代码若直接访问 `self.cudaipc_mmfeature_pool`，需检查属性是否存在或提供统一的空实现，防止 `AttributeError`。  
3. **文档与测试**：在多模态处理模块的文档中注明 `skip_mm_pool` 的用途；补充单元测试覆盖 `skip_mm_pool=True` 与 `False` 两种路径，验证内存占用与功能正确性。  
4. **性能监控**：关闭池会导致频繁的显存分配/释放，建议在生产环境监控显存碎片与吞吐，必要时提供可配置的阈值或回退机制。  

总体而言，此改动通过可选关闭 CUDA‑IPC 池缓解了 OOM 风险，但需确保所有相关路径对缺失池的容错处理完整，并在文档与测试层面做好支撑。

---

### [AMD] CI - migrate perf test and fix stage-b-test-1-gpu-amd (#17340)
**SHA**: `04a10c9` | 🔗 [查看提交](https://github.com/sgl-project/sglang/commit/04a10c9bc2ef92708f34dc223bb68a9cec819acf)

**🎯 变更类型**：功能增强（CI AMD 平台迁移 & 新增 AMD‑专属测试套件）  
**⚡ 重要程度**：🟡 中  

**📋 变更摘要**  
- 将原有的 AMD 性能、准确率测试从单独的 `bash … unittest` 步骤统一迁移到 `run_suite.py`，并为 AMD 添加了全新的 stage 名称（如 `stage-b-test-small-1-gpu‑performance‑amd`、`stage-b-test-large-2-gpu‑accuracy‑amd` 等）。  
- 在 `.github/workflows/pr-test-amd.yml` 中重新组织 `needs`、`if` 条件，合并了多段 `performance‑test‑*` 为对应的 `stage‑b‑test‑*`，并统一使用 `run_suite.py --suite …` 运行。  
- 为所有受影响的测试文件（perf、accuracy、model、openai‑server）加入 `register_amd_ci` 注册，同时在若干测试中加入 `is_hip()` 检测并对 AMD 做阈值放宽或直接跳过。  
- `scripts/ci/slash_command_handler.py`、`test/run_suite.py` 的白名单同步更新，以识别新的 AMD stage。  

**🎯 影响范围**  
- CI 工作流：`.github/workflows/pr-test-amd.yml`（所有 AMD‑相关 jobs）  
- CI 注册模块：`sglang/test/ci/ci_register.py`（需支撑 `register_amd_ci`）  
- 性能/准确率测试代码：`test/registered/perf/*`、`test/registered/eval/*`、`test/registered/models/*`、`test/registered/openai_server/*`  
- 通用运行入口：`test/run_suite.py`（新增 suite 列表）  
- 辅助脚本：`scripts/ci/slash_command_handler.py`（rerun 关键字）  

**💡 关注建议**  

1. **验证 `run_suite.py` 对新 suite 的兼容性**  
   - 确认 `--auto-partition-id/size` 参数在 AMD 环境下仍能正确切分测试文件；若有遗漏会导致某些用例未被执行。  
   - 检查 `run_suite` 对 `--timeout-per-file` 的实现，确保在 AMD 容器中超时不会被误判为失败。

2. **确保 `register_amd_ci` 的实现与 `register_cuda_ci` 对等**  
   - 两者在 `ci_register.py` 中的行为应保持一致（如 `est_time`、`suite` 的映射），避免出现仅在 AMD 上出现的 “未注册” 或 “重复注册” 报错。

3. **阈值与跳过逻辑**  
   - 对 `is_hip()` 条件下的阈值放宽（如 GSM8K 准确率）以及 `@unittest.skipIf(is_hip())` 的使用，请确认这些测试在 ROCm 上的真正需求与期望，否则可能掩盖潜在的回归。  
   - 若后续需要恢复被跳过的测试，请准备对应的 ROCm‑兼容实现或基准。

4. **CI 资源与时间预算**  
   - 新增的 `stage‑b‑test‑large‑2‑gpu‑performance‑amd` 引入了 `part: [0,1]` 矩阵，可能会使整体 AMD CI 时长翻倍。建议在 `est_time` 参数上做好预估并在 GitHub Actions 中适当设置 `timeout-minutes`。  
   - 同时检查是否需要在 `needs` 中加入 `call-gate`（已修改），确保门禁逻辑不因新 stage 而意外阻塞。

5. **文档与使用提示**  
   - 在项目的 AMD CI 文档（README/CONTRIBUTING）中补充新 stage 名称与触发方式，帮助贡献者使用 `/rerun` 或手动触发时不产生混淆。  
   - 若用户在本地想复现 AMD 性能基准，提供相应的 `run_suite` 命令示例以及所需的 ROCm 环境变量说明。

**总结**：本次改动通过统一 `run_suite` 入口，显著简化了 AMD CI 的维护成本，但也引入了对 `run_suite` 参数、注册机制以及阈值差异的依赖。建议在 CI 机器上跑一遍完整的新 workflow，确保所有 stage 均被覆盖且不出现遗漏或超时后再合并。这样既保持了跨平台测试的一致性，又避免因 ROCm 与 CUDA 差异导致的误报。

---

### refactor(benchmark): prevents variable shadowing (#17607)
**SHA**: `a296c99` | 🔗 [查看提交](https://github.com/sgl-project/sglang/commit/a296c99ff4cd74b17d8c3a3b47d1e360a29f4ceb)

**🎯 变更类型**：重构  
**⚡ 重要程度**：🟡 中  
**📋 变更摘要**：在 `benchmark/reasoning_benchmark/answer_extraction.py` 中消除变量名重复导致的遮蔽（shadowing）问题。将原来的 `ans`、`pred` 循环变量分别改为 `answers`/`last_ans`、`each_ans`，并相应更新后续使用，保持原始逻辑不变，仅提升代码可读性与安全性。  

**🎯 影响范围**：`benchmark/reasoning_benchmark` 模块的答案抽取流程，进而影响所有基于该基准的推理评测。  

**💡 关注建议**：  
1. **功能等价验证**：运行现有的 benchmark 单元测试或对比相同输入的抽取结果，确保重构未改变返回值。  
2. **代码风格检查**：确认新的变量名未与其他作用域冲突，保持 PEP8 规范。  
3. **性能监控**：虽然改动仅是变量重命名，仍建议在大规模评测中监测 CPU/内存使用，确保没有意外的回归。  
4. **文档更新**：若有对 `extract_answer` 的使用说明，适当更新示例代码中的变量名称，以防阅读误导。  

总体而言，此次重构提升了代码的可维护性，对功能无直接影响，建议在 CI 中加入对该函数的回归测试以防止未来不慎恢复旧写法。

---

### [AMD] Support ds3.2 on gfx942 platform (#17504)
**SHA**: `a921029` | 🔗 [查看提交](https://github.com/sgl-project/sglang/commit/a921029b9783243cbf9fe8b50bafb8ee0b1a0e8c)

**🎯 变更类型**：功能增强（AMD gfx942/ROCm 7.0 支持）  
**⚡ 重要程度**：🟡 中  
**📋 变更摘要**：  
1. Docker 镜像的构建脚本扩展，新增 `gfx942‑rocm700` 分支的 TileLang 代码路径，并在 `GPU_ARCH`=gfx942 时走不同的依赖安装与编译流程。  
2. 代码层面对 FP8‑fnuz（`float8_e4m3fnuz`）类型做了统一检测 (`is_fp8_fnuz`)，并在 NSA、TileLang 及量化相关实现中依据检测结果切换 dtype、量化范围以及内核实现。  
3. TileLang 编译选项适配 AMD GFX95（即 gfx942）硬件，关闭/降级部分 FAST_MATH/warp 优化，以降低 LDS 使用。  

**🎯 影响范围**：  
- `docker/rocm.Dockerfile`（镜像构建、依赖、TileLang 代码来源）  
- `sglang/srt/layers/attention/nsa/*`（index_buf_accessor、nsa_indexer）  
- `sglang/srt/layers/attention/nsa/tilelang_kernel.py`（FP8 dtype、量化范围、TileLang PassConfig）  
- 量化工具 `sglang/srt/layers/quantization/fp8_kernel.py`（新增 `is_fp8_fnuz`）  

**💡 关注建议**  
1. **兼容性验证**：在 CI 中加入 gfx942‑rocm700 的完整构建与单元测试，确保旧的 gfx950 路径仍能正常编译运行；特别注意 `llvm-config` 的 shim 是否在两条路径下均生效。  
2. **FP8‑fnuz 路径**：确认所有 Torch tensor 创建路径（`torch.float8_e4m3fnuz`）在不支持该 dtype 的环境（如旧 ROCm 或 CUDA）会安全回退到 `float8_e4m3fn`，避免运行时类型错误。  
3. **性能基准**：对比 gfx950 与 gfx942（尤其是 LDS 限制下的 kernel 参数）在相同模型下的吞吐与显存占用，确保新 kernel 的 `block_I=32`、`threads=128` 配置真正降低 LDS 使用且不引入显著回退。  
4. **文档与示例**：在 README/部署指南中补充 `GPU_ARCH=gfx942-rocm700` 的使用说明，注明需要的 ROCm 7.0 以上版本以及可能的 `torch` 版本限制。  
5. **代码可维护性**：对 `is_fp8_fnuz` 的导入做一次统一封装，避免在多个文件中重复 `_is_fp8_fnuz = is_fp8_fnuz()`，降低未来增加新 dtype 支持时的改动成本。  

总体而言，此次 PR 为 AMD 新一代 GPU（gfx942）提供了必需的构建与运行时支持，改动集中在构建脚本和 FP8 量化路径上，风险主要在跨平台 dtype 回退和 kernel 参数调优，建议通过 CI 与基准测试进行充分验证后再正式发布。

---

### refactor(codespell): corrects typos covered up by whitelist (#17601)
**SHA**: `15b5117` | 🔗 [查看提交](https://github.com/sgl-project/sglang/commit/15b511771df0020ec817e9c2e189b8582972a2a0)

**🎯 变更类型**：重构（代码拼写 & 变量命名统一）  
**⚡ 重要程度**：🟡 中  

**📋 变更摘要**  
本次提交主要对 SRT（Streaming Runtime）模块中出现的拼写错误和不统一的变量名进行统一修正。包括：  
- 将 “kv boostrap” → “kv **bootstrap**”。  
- 将 `childs` → `children`，并相应更新所有引用。  
- 将 “boostrap room” → “bootstrap room”。  
- 将内部临时列表 `childs` → `children`（如 `schedule_policy` 中的遍历变量）。  

**🎯 影响范围**  
- `python/sglang/srt/managers/disagg_service.py`  
- `python/sglang/srt/managers/schedule_policy.py`  
- `python/sglang/srt/managers/scheduler.py`  
- `python/sglang/srt/managers/session_controller.py`  

这些文件涉及请求调度、会话树管理以及分布式服务启动，均属于核心业务逻辑。

**💡 关注建议**  
1. **兼容性检查**：`children` 与 `childs` 的 API 改动可能影响外部插件或自定义继承代码，建议在发布说明中明确该命名已统一为 `children`，并在文档中更新示例。  
2. **单元测试**：确保已有的单元测试覆盖 `SessionReqNode.clear_children`、`_get_dfs_priority` 等路径，防止因变量名改动导致遗漏。  
3. **日志/错误信息**：已同步错误信息中的拼写，建议统一使用 `bootstrap`，避免后续搜索时出现遗漏。  
4. **代码审计**：检查是否还有残留的 `childs`、`boostrap` 等旧拼写（包括注释、docstring），保持代码库的一致性。  

总体而言，此次重构仅涉及命名修正，对功能无实质影响，但需确认所有引用已同步，以避免运行时 `AttributeError`。

---

#### 🟢 低重要度变更 (8)

### Fix CI install failure when rerunning tests via workflow_dispatch (#17612)
**SHA**: `b23470e` | 🔗 [查看提交](https://github.com/sgl-project/sglang/commit/b23470e95a1d5c4e6a18bae54bd348e5bd924de3)

**🎯 变更类型**：代码重构  
**⚡ 重要程度**：🟢低  
**📋 摘要**：在 CI 安装脚本中，新增判断当 `CUSTOM_BUILD_SGL_KERNEL=true` 且 `sgl‑kernel/dist` 目录不存在时，回退至从 PyPI 安装 `sgl‑kernel`，防止工作流重跑时因缺少构建产物导致安装失败。

---

### set cooldown_interval_minutes to 0 for liusy58 (#17637)
**SHA**: `1734916` | 🔗 [查看提交](https://github.com/sgl-project/sglang/commit/17349168bb159a4e68ec7ac071aac4b8f67e5c60)

**🎯 变更类型**：配置调整  
**⚡ 重要程度**：🟢 低  
**📋 摘要**：将 CI 权限配置中用户 **liusy58** 的 `cooldown_interval_minutes` 从 60 调整为 0，允许其无需间隔即可重新触发 CI。

---

### [NPU] update doc for Ascend NPU (#17621)
**SHA**: `69470db` | 🔗 [查看提交](https://github.com/sgl-project/sglang/commit/69470dbc1fe3895ae2fe1d729362b6a9eeeba964)

**🎯 变更类型**：文档更新  
**⚡ 重要程度**：🟢低  
**📋 摘要**：在 Ascend NPU 支持模型文档中，将 `openai/gpt-oss-120b` 的支持状态从不支持（×）更正为支持（√），提升表格准确性。

---

### fix gpt-oss launch failure with piecewise cuda graph (#17532)
**SHA**: `2b2f317` | 🔗 [查看提交](https://github.com/sgl-project/sglang/commit/2b2f317383a451d8ec944bea3ee1da659b4421c6)

**🎯 变更类型**：代码重构  
**⚡ 重要程度**：🟢低  
**📋 摘要**：修复在使用分段 CUDA 图时 GPT‑OSS 启动失败的问题，调整相关核心启动逻辑以兼容 CUDA 图分段执行。

---

### update dependence docs of npu (#17573)
**SHA**: `0fec882` | 🔗 [查看提交](https://github.com/sgl-project/sglang/commit/0fec8820d1098043bee885ebd20f8a8fed4f629d)

**🎯 变更类型**：文档更新  
**⚡ 重要程度**：🟢低  
**📋 摘要**：将 Ascend NPU 文档中的 CANN 版本从 8.3.rc2 更新至 8.5.0，MemFabric 版本升至 1.0.5，Triton 安装方式改为直接 `pip install triton-ascend`，并相应更新镜像指令和依赖说明。

---

### Update test README with CI registry documentation and 5090/H100 guidance (#17368)
**SHA**: `1e8e0cc` | 🔗 [查看提交](https://github.com/sgl-project/sglang/commit/1e8e0cca2cceade9643519a9d984f5b506284e4b)

**🎯 变更类型**：文档更新  
**⚡ 重要程度**：🟢低  
**📋 摘要**：在 `test/README.md` 中加入 CI Registry 系统说明，补全注册函数示例，提供 1‑GPU（5090/H100）套件选型指南及运行示例，帮助用户更好地配置和执行 CI 测试。

---

### Bugfix: Writing to storage when write-back method is chosen (#14718)
**SHA**: `2399af5` | 🔗 [查看提交](https://github.com/sgl-project/sglang/commit/2399af55575f92daa30685b41775eb781c201554)

**🎯 变更类型**：其他  
**⚡ 重要程度**：🟢低  
**📋 摘要**：在写回模式下，删除正在写入的条目时先弹出节点，并在开启存储时调用 `write_backup_storage`，确保数据写入备份存储。

---

### types: preps `SessionReqNode` for IDE-driven renames (#17602)
**SHA**: `2c86a06` | 🔗 [查看提交](https://github.com/sgl-project/sglang/commit/2c86a065dbab0e0a9c2fde14a6056d1d9a27d061)

**🎯 变更类型**：代码重构  
**⚡ 重要程度**：🟢低  
**📋 摘要**：为 `SessionReqNode.__init__` 添加 `Optional["SessionReqNode"]` 类型注解并重新排版参数列表，便于 IDE 重命名与可读性提升。

---

