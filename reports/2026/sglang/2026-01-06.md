# 每日更新报告（2026-01-06）

## sgl-project/sglang

| 提交时间 | 作者 | 提交信息 |
|----------|------|----------|
| 2026-01-06 23:28:06 | Chang Su | [grpc] Unify ResponsesContext and HarmonyResponsesContext (#16549) |
| 2026-01-06 22:43:52 | fzyzcjy | Tiny add --gsp-ordered (#16575) |
| 2026-01-06 22:29:40 | Ke Bao | Fix evict swa for overlap scheduler and page size > 1 (#16507) |
| 2026-01-06 22:10:10 | fzyzcjy | Tiny support sglang_routing_keys_active in engine (#16570) |
| 2026-01-06 17:38:35 | YAMY | [test] update acc len threshold to 2.7 for eagle dp attention tests (#16463) |
| 2026-01-06 15:51:10 | Junrong Lin | [test] Add mamba cache release/resume memory test (#14215) |
| 2026-01-06 15:47:26 | lw9527 | fix double Unicode escape issue in streaming tool_calls parameters (#13518) |
| 2026-01-06 15:43:20 | Alison Shao | Migrate sampling tests to test/registered/sampling/ (#16455) |
| 2026-01-06 14:45:53 | Xiaoyu Zhang | [Diffusion] Ring Attention support sage backend (#16496) |
| 2026-01-06 14:42:22 | Chang Su | [responses API] Add list_tools_for_servers and threading server_keys in routers (#16540) |
| 2026-01-06 14:39:07 | jiapingW | [diffusion] fix: fix bench_serving always use prompt fixed prompts (#16201) |
| 2026-01-06 14:31:52 | siyu | use aync load for encoder_server (#15456) |
| 2026-01-06 14:29:22 | Alison Shao | ci: migrate Constrained Decoding tests to test/registered/constrained/ (#16421) |
| 2026-01-06 14:21:49 | Alison Shao | Migrate metrics tests to test/registered/metrics/ (#16466) |
| 2026-01-06 14:18:59 | Douglas Yang | fix: moving dpsk v32 cp single node to nightly (#16539) |
| 2026-01-06 14:13:13 | Alison Shao | ci: migrate RL tests to test/registered/rl/ (#16417) |
| 2026-01-06 14:11:40 | Baizhou Zhang | [Fix]Pin mooncake version to 0.3.7.post2 in grace blackwell (#16502) |
| 2026-01-06 13:25:29 | Alison Shao | ci: migrate VLM tests to test/registered/vlm/ (#16415) |
| 2026-01-06 13:15:32 | Alison Shao | Migrate parsing tests to test/registered/parser/ (#16467) |
| 2026-01-06 13:13:13 | Ke Bao | Remove hybrid_kvcache_ratio in server args (#16399) |
| 2026-01-06 12:30:57 | Adarsh Shirawalmath | [diffusion] feat: support diffusers backend - run any model supported by diffusers (#14112) |
| 2026-01-06 12:14:42 | Raayan Dhar | feat: only add input vision tokens in `bench_serving` result if vision dataset is used (#15492) |
| 2026-01-06 12:10:13 | Douglas Yang | fix: adding multi-threading for kimi weights loading in pr test (#16538) |
| 2026-01-06 11:59:39 | fzyzcjy | Support multi-round conversations in bench_serving (#6135) |
| 2026-01-06 11:53:28 | Chang Su | [router] Remove deadcode and add note for unused API completeness methods (#16528) |
| 2026-01-06 11:38:21 | Alison Shao | ci: migrate HiCache 1-GPU tests to test/registered/hicache/ (#16416) |
| 2026-01-06 11:12:47 | Alison Shao | ci: migrate Mamba/Layers tests to test/registered/layers/mamba/ (#16419) |
| 2026-01-06 10:32:18 | Mick | [diffusion] feat: support warmup with resolutions (#16434) |
| 2026-01-06 10:28:07 | Simo Lin | [model-gateway] Add model scope support and LRU eviction for GPU-constrained environments (#16525) |
| 2026-01-06 10:26:42 | Douglas Yang | fix: unimplemented methods in BaseIndexerMetadata (#16520) |
| 2026-01-06 09:51:04 | zhangheng | [3/N][Sparse With Hicache]: Init sparse coordinator (#16086) |
| 2026-01-06 09:38:50 | Chang Su | [model-gateway] Tighten visibility in modules and remove unused re-exports (#16524) |
| 2026-01-06 08:45:13 | ShirakSyouya | Fix the problem where Qwen3VL raises an "object has no attribute 'mod… (#15677) |
| 2026-01-06 06:06:03 | Lianmin Zheng | [Auto Sync] Update tokenizer_manager.py (20260105) (#16477) |
| 2026-01-06 05:55:26 | Binyao Jiang | [FP8] Fix weight_scale shape to match with x_scale shape for per-tensor quant under torch.compile (#16356) |
| 2026-01-06 05:50:59 | Simo Lin | [model-gateway] refactor e2e test infrastructure and add router CI (#16513) |
| 2026-01-06 04:37:52 | yctseng0211 | [AMD] Fix CI and add retry logic for git clone timeout (#15663) |
| 2026-01-06 04:31:32 | Chang Su | [model-gateway] Tighten visibility across `data_connector` and `grpc` module (#16516) |
| 2026-01-06 03:40:09 | realWeilai | [model-gateway] fix tokenizer encode in golang bindings (#16482) |
| 2026-01-06 03:39:33 | Chang Su | [grpc] Refactor openai module (#16511) |
| 2026-01-06 03:26:11 | Jonah Bernard | Add MoE Integration Tests For CUTLASS Coverage (#16280) |
| 2026-01-06 02:21:34 | Chang Su | [grpc] Refactor grpc/regular/responses (#16509) |
| 2026-01-06 02:21:05 | Chang Su | [model-gateway][grpc] Refactor harmony/responses.rs (#16508) |
| 2026-01-06 01:29:14 | fzyzcjy | Fix age bucket rendering issue (#16492) |
| 2026-01-06 00:01:53 | Simo Lin | [model-gateway][e2e_test]: Create directory structure and backends config (#16469) |

## sgl-project/sglang 的LLM分析结果

### 21da2dc1ce733fea76cb9e16bd64821e5fa69b83
https://github.com/sgl-project/sglang/commit/21da2dc1ce733fea76cb9e16bd64821e5fa69b83
[grpc] Unify ResponsesContext and HarmonyResponsesContext (#16549)
**🎯 变更类型**：重构 / 功能变更（统一 `ResponsesContext`，废除 `HarmonyResponsesContext` 与后台任务/取消功能）  

**⚡ 重要程度**：🔴 高  

**📋 变更摘要**  
1. 新增统一的 `ResponsesContext`，从 `sgl-model-gateway/src/routers/grpc/common/responses/context.rs` 抽离出来，并在 harmony 与 regular 两套实现中复用。  
2. 删除原先用于后台任务管理的 `BackgroundTaskInfo`、`background_tasks` 字段及相关取消逻辑，`POST /v1/responses/{response_id}/cancel` 统一返回 “不支持取消” 的错误。  
3. 相应地更新了所有引用（handlers、non_streaming、streaming、pipeline、router 等），并删除了 `HarmonyResponsesContext` 文件。  

**🎯 影响范围**  
- `sgl-model-gateway/src/routers/grpc/common/responses/*`（context、handlers、mod、utils）  
- `sgl-model-gateway/src/routers/grpc/harmony/*`（responses、mod、processor、streaming）  
- `sgl-model-gateway/src/routers/grpc/regular/*`（responses、handlers、mod、non_streaming、streaming）  
- `sgl-model-gateway/src/routers/grpc/pipeline.rs`、`router.rs`  
- 所有依赖 `ResponsesContext` 的业务逻辑（MCP 工具循环、SSE 流、请求持久化等）  

**🔍 技术洞察**  

- **架构影响**  
  - 消除 `HarmonyResponsesContext` 与 `ResponsesContext` 的重复实现，统一为单一结构体，降低代码维护成本。  
  - 移除 `BackgroundTaskInfo` 与 `background_tasks`，简化了上下文的职责，只保留 pipeline、组件、存储、MCP 管理器等核心依赖。  
  - 由于取消功能被废除，原先的后台任务模型（Rust 任务 + Python Scheduler）不再存在，系统从 “双模式（同步/后台）” 迁移为 “仅同步 + 流式”。  

- **性能影响**  
  - 移除后台任务管理后，内存占用与 `RwLock<HashMap>` 的锁竞争显著下降，尤其在高并发场景下可提升响应延迟。  
  - 取消端点现在只做一次存储查询并返回错误，CPU 与 I/O 开销进一步降低。  
  - 对于已在生产环境使用后台模式的用户，失去后台执行会导致请求必须同步完成，可能导致单个请求占用更长的连接时间。  

- **安全考虑**  
  - 删除了跨进程（Rust ↔ Python Scheduler）取消接口，移除了一个潜在的跨服务攻击面。  
  - 代码路径变更未引入新的外部依赖或网络调用，无新增安全风险。  

**⚠️ 潜在风险**  

| 风险点 | 说明 | 严重程度 |
|--------|------|----------|
| 兼容性破坏 | 客户端若仍调用 `/v1/responses/{id}/cancel` 或依赖后台任务（长轮询）会收到 400 错误，导致业务中断。 | 高 |
| 业务流程变化 | 原本利用后台模式实现的“立即返回任务 ID，后续轮询结果”模式不再可用，需要改为同步或自行实现轮询逻辑。 | 中 |
| 部署环境遗留代码 | 若还有外部模块仍引用已删除的 `background_tasks` 或 `HarmonyResponsesContext`，编译会失败。 | 低 |
| 并发测试缺失 | 删除锁 (`RwLock<HashMap>`) 后，未覆盖的并发路径可能出现未预见的竞争或资源泄漏。 | 中 |

**💡 关注建议**  

1. **文档 & 客户端更新**  
   - 在 API 文档中明确标注 “取消功能已下线”，并提供迁移指南（改为同步调用或自行实现任务管理）。  
   - 若有 SDK/客户端封装了 `cancel` 接口，请同步更新版本并发布迁移说明。  

2. **回归测试**  
   - 重点验证：  
     - `/v1/responses/{id}`（GET）在无后台任务情况下仍能返回已完成/失败的响应。  
     - 同步 (`POST /v1/responses`) 与流式 (`POST /v1/responses?stream=true`) 两条路径的完整执行链路。  
     - 对应的 SSE 事件在流式模式下是否完整、顺序正确。  

3. **性能基准**  
   - 对比迁移前后的 QPS/延迟，尤其在高并发（>10k rps）场景下确认锁竞争已显著下降。  

4. **灰度发布**  
   - 若已有客户在生产使用后台模式，建议先在灰度环境关闭 `cancel`，观察业务影响后再全量切换。  

5. **代码审计**  
   - 确认所有 `use`/`mod` 引入已更新，避免残留的 “dead code” 或未使用的 `background_tasks` 相关 imports。  

通过上述检查与迁移步骤，可安全完成此次统一 Context 与取消功能下线的重构工作。

### ed307a40bfa9ce526700d36b5e4bf8afb8725cc5
https://github.com/sgl-project/sglang/commit/ed307a40bfa9ce526700d36b5e4bf8afb8725cc5
Tiny add --gsp-ordered (#16575)
**🎯 变更类型**：功能增强  

**⚡ 重要程度**：🟢低  

**📋 变更摘要**：  
1. 在 `python/sglang/bench_serving.py` 中新增 `--gsp-ordered` 命令行参数，用于控制生成共享前缀（GSP）请求的顺序。  
2. 当不使用该参数时，仍保持原有的随机 shuffle 行为；使用后则保持输入文件中的原始顺序。  

**🎯 影响范围**：  
- `python/sglang/bench_serving.py`（Benchmark 服务脚本）  
- 相关的命令行调用和 CI 测试脚本（若有使用该脚本的地方）  

**🔍 技术洞察**：  
- **架构影响**：无。仅在本地脚本层面添加一个可选标志，不涉及模块间依赖或整体架构变化。  
- **性能影响**：无显著影响。关闭 `random.shuffle` 可略微减少一次 O(N) 随机置换的开销，但对整体基准测试时间影响可以忽略不计。  
- **安全考虑**：无。该改动仅影响数据顺序，不会引入新的安全风险或泄露敏感信息。  

**⚠️ 潜在风险**：  
- 若已有代码或脚本在解析 `args` 时假设 `gsp_ordered` 属性一定不存在，可能会出现 `AttributeError`（但这种情况极少）。  
- 文档或使用说明未同步更新，用户可能不清楚该参数的默认行为，从而导致基准结果的可重复性出现误解。  

**💡 关注建议**：  
1. **测试覆盖**：在 CI 中添加针对 `--gsp-ordered` 与默认行为的两套基准测试，确保两者均能正常运行且结果符合预期。  
2. **文档更新**：在 README 或使用手册中说明新参数的作用、默认行为以及何时推荐开启。  
3. **向后兼容**：确认其他子命令或脚本在解析 `args` 时使用 `getattr(args, "gsp_ordered", False)`，避免因属性缺失导致异常。  
4. **发布说明**：在发布日志中标记此为“可选参数”，提醒用户在需要可重复基准时使用 `--gsp-ordered`。  

### 02722b9113e32a2a7f93bcb00dc0da413de56d77
https://github.com/sgl-project/sglang/commit/02722b9113e32a2a7f93bcb00dc0da413de56d77
Fix evict swa for overlap scheduler and page size > 1 (#16507)
**🎯 变更类型**：Bug修复 / 功能增强（针对 overlapped scheduler 与多页缓存的 Sliding Window Attention（SWA）淘汰逻辑）

**⚡ 重要程度**：🔴 高  

**📋 变更摘要**  
- 修正在 **overlap scheduler** 场景下以及 **page size > 1** 时，SWA 缓存淘汰（evict）不正确导致的潜在内存泄漏或错误结果。  
- 新增 `extend_batch_idx`、`decode_batch_idx` 用于追踪同一请求在 Extend 与 Decode 批次中的顺序，从而判断何时可以安全淘汰 KV。  
- 引入 `chunked_prefill_size` 参数以及 `window_size` 计算，使得在 **chunked prefill**（分块预填充）模式下能够正确计算淘汰边界。  

**🎯 影响范围**  
- `python/sglang/srt/managers/schedule_batch.py`（请求层面计数逻辑）  
- `python/sglang/srt/managers/scheduler.py`（调度器初始化新增参数）  
- `python/sglang/srt/mem_cache/cache_init_params.py`（配置结构体）  
- `python/sglang/srt/mem_cache/chunk_cache.py`（SWA 淘汰核心实现）  
- `python/sglang/srt/mem_cache/common.py`（内存分配路径中调用淘汰）  

---

### 🔍 技术洞察  

- **架构影响**  
  - 在内存缓存层（`ChunkCache` → `SWAChunkCache`）加入了 **窗口大小 (`window_size`)** 和 **chunked prefill 大小** 的概念，提升了对 **分块预填充** 与 **overlap 调度** 场景的适配能力。  
  - 通过在 `ScheduleBatch` 中记录 `extend_batch_idx`、`decode_batch_idx`，实现了跨批次的状态追踪，保持了现有模块的低耦合，只是少量属性的传递。  

- **性能影响**  
  - **正面**：在 `evict_swa` 中仅在必要的窗口大小间隔进行淘汰（`decode_batch_idx % window_size == 1`），可显著降低频繁的 KV 删除/拷贝开销，尤其在 **page size > 1** 时避免了不必要的整页回收。  
  - **负面**：引入额外的计数变量和条件判断，带来微小的 CPU 开销，但相对于内存管理的收益可以忽略不计。  

- **安全考虑**  
  - 通过在 overlap 调度时**阻止提前淘汰**（`extend_batch_idx < 2`）避免了正在运行的前一批次仍在使用的 KV 被错误回收，降低了产生 **段错误 / 数据竞争** 的风险。  
  - 新增的 `chunked_prefill_size` 为 `Optional[int]`，若未显式配置保持 `None`，对现有行为无影响，兼容性良好。  

---

### ⚠️ 潜在风险  

1. **计数变量同步错误**  
   - `extend_batch_idx`、`decode_batch_idx` 必须在每次对应的批次调用前后正确递增。若后续代码忘记递增，可能导致 **SWA 永不淘汰** 或 **提前淘汰**。  

2. **兼容性**  
   - 旧版本的 `CacheInitParams` 未包含 `chunked_prefill_size`，若外部代码直接实例化且未传入该字段，可能出现 `TypeError`（已通过默认 `None` 规避）。  
   - 依赖 `page_size` 大于 1 时的整数除法对齐逻辑，若 `page_size` 为 0（异常配置）会触发除零错误。  

3. **并发场景**  
   - 在多 HTTP 工作进程共享 `ScheduleBatch` 实例时，计数变量的并发写入需保持原子性。目前在单进程模型下使用，若未来改为多进程共享内存，需要额外同步机制。  

---

### 💡 关注建议  

- **回归测试**  
  - 添加覆盖 **overlap scheduler + chunked prefill + page_size>1** 三种组合的单元/集成测试，验证 `evict_swa` 只在合适的窗口触发。  
  - 特别检查 `extend_batch_idx`、`decode_batch_idx` 在连续 `prepare_for_extend` / `prepare_for_decode` 调用后是否按预期递增。  

- **升级注意事项**  
  - 如使用自定义 `CacheInitParams`，请确保在构造时加入 `chunked_prefill_size`（若需要分块预填充）。  
  - 若使用多进程/多线程的 HTTP worker，请确认计数变量的访问是线程安全的（目前依赖 GIL 在单进程下安全）。  

- **监控与日志**  
  - 建议在 `evict_swa` 前后记录 `req.evicted_seqlen_local` 与 `new_evicted_seqlen_local` 的变化，帮助快速定位异常的淘汰行为。  

- **性能基准**  
  - 对比开启/关闭 `enable_overlap`、不同 `window_size`（由 `sliding_window_size` / `attention_chunk_size` 决定）的吞吐量与显存使用，确保新逻辑带来预期的显存回收效果。  

---  

> 此次提交主要解决了 **overlap scheduler** 与 **多页缓存** 场景下的 **SWA 缓存错误淘汰**，通过细粒度的批次计数和窗口化淘汰逻辑提升了系统的稳定性与显存利用率。建议在生产环境 rollout 前完成上述测试和监控验证。

### f959250f76d21f96f5ee07944b443c471f86f4eb
https://github.com/sgl-project/sglang/commit/f959250f76d21f96f5ee07944b443c471f86f4eb
Tiny support sglang_routing_keys_active in engine (#16570)
**🎯 变更类型**：功能增强 / 测试  
**⚡ 重要程度**：🟡 中  
**📋 变更摘要**：在 SGLang 引擎的 Prometheus 监控中，新增 `sglang:routing_keys_active` 指标，用于统计当前活跃请求的唯一路由键数量，并实现了 `RefCountedGauge` 辅助类以防止高基数导致的指标膨胀。同时为该指标补充了相应的单元测试。  
**🎯 影响范围**：`python/sglang/srt/utils/common.py`（Prometheus 中间件实现），`test/registered/metrics/test_metrics.py`（测试用例），以及运行时的 HTTP 请求处理路径。  

**🔍 技术洞察**  
- **架构影响**：  
  - 在原有的 `add_prometheus_track_response_middleware` 中引入 `RefCountedGauge` 实例 `routing_keys_active`，并在每次请求入口/出口处增减计数。  
  - 新增的类仅在单进程/多进程（`multiprocess_mode="livesum"`）的 Prometheus 环境下使用，未改变现有模块之间的依赖关系。  
- **性能影响**：  
  - 计数逻辑为 O(1) 的字典操作，开销极小；仅在请求路径上读取一个 HTTP 头部 `x-smg-routing-key`。  
  - 由于采用引用计数，单次请求结束后会立即 `dec`，因此不会产生显著的内存增长。  
- **安全考虑**：  
  - 该变更仅涉及读取客户端自定义头部，不会对系统安全产生影响。  
  - 若恶意客户端发送大量不同的 `x-smg-routing-key`，仍有潜在的高基数风险（同样的问题在其他基于标签的指标中已存在），但 `RefCountedGauge` 已在相同键值重复出现时做去重。  

**⚠️ 潜在风险**  
1. **高基数泄露**：如果路由键种类非常多且未能及时 `dec`（如异常路径提前退出），`routing_keys_active` 的内部字典可能残留键，导致指标值偏高。  
2. **并发安全**：`RefCountedGauge` 使用普通的 Python `dict`，在多线程/多进程环境下（尤其是 FastAPI 的默认 `uvicorn` 工作模式）可能出现竞争条件，虽然 GIL 在 CPython 中提供了一定保护，但在使用 `multiprocess_mode="livesum"` 的子进程中仍需注意。  
3. **兼容性**：依赖 `prometheus_client` 的 `Gauge` 类在旧版本中可能不支持 `multiprocess_mode="livesum"`，升级时需确认库版本。  

**💡 关注建议**  
- **测试**：在 CI 中加入对异常路径（抛异常、提前返回）仍能正确 `dec` 的用例；模拟并发请求验证计数的一致性。  
- **限流/过滤**：如果产品环境中路由键种类可能非常多，建议在中间件层对 `x-smg-routing-key` 做白名单或哈希截断，防止指标卡住。  
- **部署**：确保部署的容器/实例中 `prometheus_client` 版本 ≥0.13（支持 `multiprocess_mode`），并在多进程模式下检查 `/tmp`（或 `prometheus_multiproc_dir`）的写权限。  
- **监控告警**：可基于 `sglang:routing_keys_active` 设置阈值告警，快速发现异常的大量唯一路由键请求。  

---  

### 959343795f3b3be3618c68e8e3f96859b9b6a46b
https://github.com/sgl-project/sglang/commit/959343795f3b3be3618c68e8e3f96859b9b6a46b
[test] update acc len threshold to 2.7 for eagle dp attention tests (#16463)
**🎯 变更类型**：测试  
**⚡ 重要程度**：🟢低  
**📋 变更摘要**：将 Eagle DP Attention 相关单元测试中 `avg_spec_accept_length` 的阈值从 1.4 提升到 2.7，以匹配最新的模型表现或预期行为。  
**🎯 影响范围**：`test/registered/spec/eagle/test_eagle_infer_beta_dp_attention.py`、`test/registered/spec/eagle/test_eagle_infer_beta_dp_attention_large.py` 两个测试文件。  

**🔍 技术洞察**：  
- **架构影响**：无。仅修改了测试断言，不涉及业务代码或模块关系。  
- **性能影响**：无直接影响；仅在 CI/本地运行时多了一条更严格的断言，可能导致测试执行更频繁失败。  
- **安全考虑**：无。测试代码不涉及安全逻辑或外部接口。  

**⚠️ 潜在风险**：  
- 若模型实际输出的 `avg_spec_accept_length` 未达到 2.7，CI 将出现回归失败，导致发布阻塞。  
- 由于原来阈值较低，可能隐藏了模型在该指标上的潜在退化；提升阈值后需要确保模型已可靠达到新标准。  

**💡 关注建议**：  
1. 在本地或 CI 环境运行全部 Eagle DP Attention 相关测试，确认 `avg_spec_accept_length` 已稳定在 ≥ 2.7。  
2. 若出现失败，检查模型训练或推理路径是否存在导致接受长度下降的变更（如分词、截断策略等）。  
3. 在提交代码前，确保对应的性能基准已更新文档或 CI 报告，以免误判为回归。  
4. 如有计划进一步提升阈值，请同步更新 `TODO` 注释或在后续 PR 中说明。  

### bc2f40bebc65112ef2597b1ff655da51ba718819
https://github.com/sgl-project/sglang/commit/bc2f40bebc65112ef2597b1ff655da51ba718819
[test] Add mamba cache release/resume memory test (#14215)
**🎯 变更类型**：测试  
**⚡ 重要程度**：🟡 中  

**📋 变更摘要**：  
在 `python/sglang/test/test_utils.py` 中新增了默认的 Hybrid Mamba 测试模型常量；在 `test/srt/test_release_memory_occupation.py` 中加入了针对 Hybrid Mamba 模型的 “release‑memory / resume‑memory” 单元测试，验证在多卡（tp=4）环境下的显存释放、恢复以及权重重新加载的完整流程。

**🎯 影响范围**：  
- `sglang/test` 目录下的测试套件  
- `sglang/engine`（间接，因测试会调用 `Engine.release_memory_occupation`、`resume_memory_occupation`、`update_weights_from_disk`）  

**🔍 技术洞察**  
- **架构影响**：无直接代码结构修改，仅通过新增测试用例对现有内存管理接口进行覆盖。  
- **性能影响**：测试本身会在 GPU 上加载 80B 大模型并进行两次推理，可能导致 CI 环境的显存和时间开销显著提升；但对实际产品代码无运行时性能影响。  
- **安全考虑**：不涉及安全敏感代码。唯一需关注的是在公开 CI 中拉取大模型（`Qwen/Qwen3-Next-80B-A3B-Instruct`）可能泄露模型访问凭证或触发网络带宽/费用异常，建议使用受限的内部镜像或在私有网络中执行。

**⚠️ 潜在风险**  
1. **资源占用**：80B Hybrid Mamba 模型体积大，CI 并行跑多个此类测试可能导致 OOM 或显存竞争。  
2. **网络依赖**：测试需要从 HuggingFace 拉取模型，网络波动或模型被删除会导致测试失败。  
3. **兼容性**：`tp_size=4` 假设环境支持四卡并行，单卡或少卡机器会直接跳过或报错，需要在测试前做环境检测。  

**💡 关注建议**  
- 为该测试加上环境检查（如 `if torch.cuda.device_count() < 4: self.skipTest(...)`）并提供 `--skip-hybrid-mamba` 之类的命令行开关，以免在资源受限的 CI 环境中卡死。  
- 考虑在 CI 中使用模型快照或离线缓存，减少每次拉取的网络与时间成本。  
- 在提交 `requirements.txt` 或 CI 配置中注明该测试需要 **GPU ≥ 4**, **显存 ≥ 80 GB**（或相应的显存压缩配置），以便开发者提前准备。  
- 如项目对发布包体积或依赖敏感，确保此测试仅在 `tests/` 目录下，不会影响生产镜像。  

---  
*该变更主要提升了对 Hybrid Mamba 模型内存管理的回归覆盖率，对功能本身没有业务影响，但需注意 CI 资源与网络依赖。*  

### 2724b1100be6bde989c183a9fc19804d9ffb3ec8
https://github.com/sgl-project/sglang/commit/2724b1100be6bde989c183a9fc19804d9ffb3ec8
fix double Unicode escape issue in streaming tool_calls parameters (#13518)

Co-authored-by: Xinyuan Tong <115166877+JustinTong0323@users.noreply.github.com>
**🎯 变更类型**：Bug修复 / 功能增强  
**⚡ 重要程度**：🟡 中  

**📋 变更摘要**：  
1. 在 `python/sglang/srt/function_call/base_format_detector.py` 中的 `json.dumps` 调用加入 `ensure_ascii=False`，防止在流式输出 tool call 参数时对非 ASCII 字符（如中文）进行双重 Unicode 转义。  
2. 为此行为添加了 **3 条单元测试**，覆盖完整 tool call、增量流式以及多 tool 调用场景，确保中文字符保持原样且可被正确解析。  

**🎯 影响范围**：  
- `sglang/srt/function_call/base_format_detector.py`（工具调用参数的流式解析）  
- `test/registered/function_call/test_function_call_parser.py`（新增测试）  

**🔍 技术洞察**：  
- **架构影响**：仅涉及工具调用解析模块的实现细节，不改变外部接口或类层次结构，保持向后兼容。  
- **性能影响**：`ensure_ascii=False` 会直接写出原始 Unicode 字符，省去额外的转义过程，理论上略有性能提升；对内存占用影响可以忽略不计。  
- **安全考虑**：输出原始 Unicode 不会引入安全风险；若下游组件对 JSON 字符串做了假设（如仅接受 ASCII），可能需要检查兼容性。  

**⚠️ 潜在风险**：  
1. 其他依赖该模块的代码如果在处理返回的 JSON 字符串时仍假设所有非 ASCII 已被转义（如通过正则搜索 `\\u`），可能出现意外行为。  
2. 由于改变了序列化方式，若有持久化或网络传输的旧版本客户端仍使用 `ensure_ascii=True` 的结果进行比较，可能导致不一致。  

**💡 关注建议**：  
- **回归测试**：在完整的 CI 流程中运行全部单元测试，确保未出现因字符编码差异导致的失败。  
- **兼容性检查**：审查项目中是否有对 `json.dumps(...).encode('ascii')` 或手动 `\\u` 解析的代码，必要时统一为 `ensure_ascii=False` 或在使用点自行转义。  
- **文档更新**：在函数调用参数的使用说明中注明已支持原始 Unicode 输出，提醒使用方不必再自行进行解码。  
- **发布说明**：在下一个发行版本的 changelog 中加入 “Fix double Unicode escape issue in streaming tool_calls parameters” 以及相应的兼容性提示。  

### 176266f358cb4fd8e3c5a86d08f2a4b78ee64905
https://github.com/sgl-project/sglang/commit/176266f358cb4fd8e3c5a86d08f2a4b78ee64905
Migrate sampling tests to test/registered/sampling/ (#16455)
**🎯 变更类型**：测试/重构  
**⚡ 重要程度**：🟡中  

**📋 变更摘要**：  
- 将原有的采样相关单元测试迁移到 `test/registered/sampling/` 目录，并在每个测试文件中通过 `register_cuda_ci` 与 `register_amd_ci` 注册 CI 元信息（预计耗时、所属 suite）。  
- 同时在 `test/srt/run_suite.py` 中移除这些测试的硬编码条目，让它们仅通过注册机制参与 CI。  

**🎯 影响范围**：  
- `test/registered/sampling/` 下的三个测试文件（`test_original_logprobs.py`、`test_penalty.py`、`test_pytorch_sampling_backend.py`）  
- `sglang/test/ci/ci_register.py`（新增的注册调用）  
- `sglang/test/srt/run_suite.py`（测试套件列表的修改）  

**🔍 技术洞察**：  
- **架构影响**：  
  - 引入统一的 CI 注册机制，使测试用例与 CI 配置解耦，提升可维护性与可扩展性。  
  - `run_suite.py` 不再硬编码采样测试，改为依赖注册表，符合“注册驱动”设计模式。  
- **性能影响**：  
  - 对业务代码无直接运行时性能影响，仅影响 CI 阶段的调度与并行。  
- **安全考虑**：  
  - 无安全相关改动；注册信息均为纯数据（估算时间、suite 名称），不涉及权限或网络。  

**⚠️ 潜在风险**：  
1. **测试遗漏**：若 CI 环境未正确加载 `ci_register`，这些采样测试可能被跳过，导致回归缺失。  
2. **时间估算偏差**：注册的 `est_time` 与实际执行时间不符，可能导致 CI 超时或资源浪费。  
3. **兼容性**：旧的本地或自定义 CI 脚本仍依赖 `run_suite.py` 中的硬编码列表，迁移后可能失效。  

**💡 关注建议**：  
- **CI 验证**：在 CI 环境（CUDA 与 AMD 两套）执行一次完整的 “stage-b-test-small-1-gpu” 套件，确认所有已注册的采样测试被执行且报告正确。  
- **本地调试**：提供一个简单的脚本或说明，告诉开发者如何在本地运行 `register_*` 机制（例如 `python -m sglang.test.run_suite --suite stage-b-test-small-1-gpu`）。  
- **时间校准**：监控实际运行时间并适时调整 `est_time`，避免 CI 阶段因超时而中止。  
- **文档更新**：在测试贡献指南中加入“如何使用 ci_register 注册测试”章节，防止以后出现遗漏或重复注册的情况。  
- **回退方案**：保留原有硬编码条目（如在特定分支）作为临时回退，以防 CI 注册机制出现异常。  

### 5e5b1183ed2efc1a401a9f731ef688c463bb22ff
https://github.com/sgl-project/sglang/commit/5e5b1183ed2efc1a401a9f731ef688c463bb22ff
[Diffusion] Ring Attention support sage backend (#16496)
**🎯 变更类型**：功能增强  
**⚡ 重要程度**：🟡 中  

**📋 变更摘要**：  
1. 在 `sage_attn.py` 中，`forward` 接口在 `return_softmax_lse=True` 时返回 `(output, softmax_lse)`，而非仅 `output`。  
2. 在 `server_args.py` 中放宽 Ring Attention 对后端的限制，允许 `sage_attn` 与 FlashAttention 同时作为 Ring Attention 的后端，并在未指定后端时默认使用 FlashAttention。  

**🎯 影响范围**：  
- `python/sglang/multimodal_gen/runtime/layers/attention/backends/sage_attn.py`（注意力后端实现）  
- `python/sglang/multimodal_gen/runtime/server_args.py`（服务器启动参数校验与默认值逻辑）  
- 受影响的上层调用链：使用 Ring Attention 的多模态生成服务及可能依赖 `return_softmax_lse` 的上层代码。  

**🔍 技术洞察**：  
- **架构影响**：  
  - 为 Ring Attention 引入了对 Sage Attention 后端的兼容，扩展了注意力层的后端选择矩阵。  
  - `server_args` 的校验逻辑从“仅支持 flash attention”改为“支持 flash 或 sage_attn”，提升了系统的可配置性。  
- **性能影响**：  
  - 代码本身仅增加了一个分支包装返回值，对时间复杂度基本无影响。  
  - 返回 `softmax_lse` 可能导致上层额外的内存复制或进一步计算，但这在需要该信息的场景下是必要的，整体性能影响可视为 **可接受**。  
- **安全考虑**：  
  - 无新增安全敏感操作或外部输入处理，风险极低。  

**⚠️ 潜在风险**：  
1. **向后兼容性**：调用 `sage_attn.forward(..., return_softmax_lse=True)` 的旧代码若只解包单个返回值，会抛出 `ValueError: too many values to unpack`。  
2. **默认后端行为**：当 `ring_degree > 1` 且 `attention_backend` 为 `None` 时仍会自动切换为 FlashAttention，可能导致用户误以为已使用 Sage Attention。  
3. **参数校验疏漏**：如果用户显式指定 `attention_backend="sage_attn"`，但实际运行时未编译或未提供对应实现，仍会在后续运行时报错，校验层未提前捕获。  

**💡 关注建议**：  
- **测试覆盖**：  
  - 增加单元测试，分别在 `return_softmax_lse=False/True` 场景下验证返回值类型与内容。  
  - 针对 Ring Attention，分别以 `fa` 与 `sage_attn` 为后端执行端到端的生成流程，确保两者结果一致且不会触发异常。  
- **文档更新**：在用户手册或参数说明中注明 `return_softmax_lse` 为可选返回，调用方需要相应地解包。并明确 `--attention-backend sage_attn` 在 Ring Attention 场景下的支持方式及默认行为。  
- **兼容性提示**：在 `sage_attn.forward` 的入口处加入日志/警告，当 `return_softmax_lse=True` 且调用方未处理二元返回时，提供友好的提示信息。  
- **参数校验加强**：可考虑在 `check_server_sp_args` 中进一步验证所选后端实际可用（例如检测对应库是否已加载），提前发现配置错误。  

通过上述措施，可平稳地将 Sage Attention 纳入 Ring Attention 支持链路，提升系统灵活性且风险可控。

### 9bf76c11a9b17c34be604b8510d3088809a8291c
https://github.com/sgl-project/sglang/commit/9bf76c11a9b17c34be604b8510d3088809a8291c
[responses API] Add list_tools_for_servers and threading server_keys in routers (#16540)
**🎯 变更类型**：功能增强、架构重构、依赖更新  

**⚡ 重要程度**：🔴高  

**📋 变更摘要**  
此次提交为 MCP（模型调用代理）引入了“请求级工具过滤”能力：  
1. 新增 `list_tools_for_servers`，仅返回静态服务器工具 + 本次请求中实际连接的动态服务器工具。  
2. `ensure_mcp_connection` 及 `ensure_request_mcp_client` 现在返回已成功建立连接的 **server_keys**，并在上下文（Harmony、Regular、OpenAI）中通过 `RwLock<Vec<String>>` 进行传播。  
3. 所有路由层的工具列表、metadata 注入、MCP List‑Tools 输出等全部改为使用过滤后的工具集。  

该改动让多租户或同一请求中多业务使用不同 MCP 动态服务器时，实现工具可见性隔离，兼容原有全局静态工具。

---

### 🎯 影响范围
- `sgl-model-gateway/src/mcp/manager.rs`（核心实现）  
- `sgl-model-gateway/src/routers/**`（Harmony、Regular、OpenAI 三套响应实现）  
- `sgl-model-gateway/src/routers/mcp_utils.rs`（连接创建与 server_keys 收集）  
- 相关 `context.rs`、`responses/*.rs`、`responses/utils.rs` 等大量文件  
- 受影响的组件：MCP Manager、工具列表生成、响应元数据注入、流式/非流式响应处理、MCP 循环配置  

---

## 🔍 技术洞察

| 维度 | 说明 |
|------|------|
| **架构影响** | - **新增请求级状态**：`requested_servers`（`Arc<RwLock<Vec<String>>`）在多个 Context 中引入，形成跨层共享的动态服务器集合。<br>- **工具过滤入口下沉**：`list_tools_for_servers` 成为统一查询点，取代原先的全局 `list_tools`，确保所有业务路径统一使用过滤后的集合。<br>- **接口向后兼容**：原 `list_tools` 仍保留，仅内部使用改为过滤版，故旧代码不受影响。 |
| **性能影响** | - **额外锁竞争**：`requested_servers` 使用 `RwLock`（读多写少），写入仅在 `ensure_mcp_connection` 阶段一次，读操作在每次工具列表生成时频繁出现，锁开销可忽略（锁持有时间极短）。<br>- **工具过滤 O(N)**：`list_tools_for_servers` 在每次调用时遍历完整工具列表并做包含判断，复杂度 O(T)（T 为工具总数），相较于之前的 O(T) 无额外成本。<br>- **连接创建**：`ensure_request_mcp_client` 现在遍历所有 MCP 工具并尝试建立连接，若请求中包含多个动态服务器，会产生多次 `get_or_create_client` 调用，但这本来就会发生（之前只取第一）。 |
| **安全考虑** | - **服务隔离**：过滤机制防止未授权的动态服务器工具泄露给不应看到的请求，提升安全性。<br>- **错误路径**：若 `ensure_request_mcp_client` 中某个服务器连接失败，仍会继续尝试其它服务器，最终返回 `None`（即无可用工具），调用方会收到 “failed_dependency”。这不会导致未授权访问。<br>- **信息泄露**：`server_key` 公开为 `pub`，但仅在内部使用，不会泄露敏感信息。 |
| **可维护性** | - **代码分散度降低**：所有工具过滤统一在 `McpManager`，业务层仅关心 `server_keys`，降低重复过滤逻辑。<br>- **新增字段 `server_keys` 到 `McpLoopConfig`**，保持配置统一。<br>- **大量改动**：涉及多文件、多个模块，需要同步更新文档和单元测试。 |
| **兼容性** | - 公开的 `server_key` 方法从 `private` 改为 `pub`，对外 API 有细微变动（向后兼容）。<br>- 仍保留原 `list_tools`，老代码仍可工作。<br>- `ensure_mcp_connection` 返回元组，所有调用已更新，外部未使用旧签名的插件可能需要适配。 |

---

## ⚠️ 潜在风险

1. **并发写入 `requested_servers`**  
   - 目前只在 `ensure_mcp_connection`（一次）写入，理论上不会产生竞争。但如果后续在同一请求上下文中多次触发 `ensure_mcp_connection`（如重试机制），可能出现覆盖或争用。建议在写入前判断是否已设置，或改为 `OnceCell`/`Mutex` 以确保一次性写入。

2. **工具过滤错误导致工具缺失**  
   - `is_static_server_by_key` 仅检查 `static_clients` 键名是否匹配 server_key。若原有动态服务器也使用相同名称（冲突）或 static 与 dynamic 键混用，可能误过滤。需要确认名称空间唯一性。

3. **`ensure_request_mcp_client` 中的遍历逻辑**  
   - 现在遍历 *所有* MCP tools，创建连接并收集 `server_keys`. 若请求中包含大量工具（如 100+ 动态服务器），可能导致连接数激增，触发资源耗尽。可以在配置层限制最大并发连接数或提前去重。

4. **向后兼容性**  
   - 任何外部直接调用 `ensure_mcp_connection`/`ensure_request_mcp_client` 并期待旧返回类型的代码将编译失败。需在 release notes 中明确说明，或提供适配层。

5. **测试覆盖不足**  
   - 过滤逻辑跨多个路径（流式、非流式、Harmony、Regular），若缺少集成测试，可能出现遗漏导致工具列表不匹配实际可用服务器。

---

## 💡 关注建议

| 场景 | 建议 |
|------|------|
| **升级准备** | - 检查项目中是否有自定义实现的 `McpManager` 或直接调用 `ensure_mcp_connection`，若有请更新签名。<br>- 确认所有依赖的 `McpServerConfig` 中 `name` 与 `url` 在静态与动态之间不冲突。 |
| **性能调优** | - 如请求可能包含大量动态服务器，考虑在 `ensure_request_mcp_client` 前做去重，并对 `server_keys` 长度做上限（例如 10）。 |
| **并发安全** | - 将 `requested_servers` 改为 `once_cell::sync::OnceCell<Vec<String>>` 或使用 `RwLock` + `bool initialized` 标志，以防多次写入。 |
| **安全审计** | - 核对 `static_clients` 键名是否泄露内部系统标识，若有敏感信息建议做哈希或映射。 |
| **测试** | - 增加单元测试：<br>  1. 静态服务器 + 单个动态服务器 → 只返回两者工具。<br>  2. 多个动态服务器，其中部分连接失败 → 仅返回成功连接的工具。<br>  3. 并发请求下，`requested_servers` 不相互污染。 |
| **文档** | - 在 MCP 文档中说明 “请求级工具过滤” 的使用方式、`server_keys` 的含义以及对客户/插件的兼容影响。 |
| **监控** | - 为 `ensure_request_mcp_client` 添加计数指标（成功连接数、失败数、过滤后工具数量），便于在生产环境观察过滤行为。 |

---

**结论**  
此次改动显著提升了 MCP 多服务器使用场景下的工具隔离能力，属于核心功能增强，影响面广。只要注意并发写入、连接数控制以及兼容性测试，整体风险可控，建议在下一个发布候选版中加入完整的回归测试后推进上线。

### 1d7ad4afcc6979073d0de40e3a374c61f4151bc3
https://github.com/sgl-project/sglang/commit/1d7ad4afcc6979073d0de40e3a374c61f4151bc3
[diffusion] fix: fix bench_serving always use prompt fixed prompts (#16201)

Co-authored-by: jiapingW <root@sgl-training-ray.datacrunch.io>
Co-authored-by: Mick <mickjagger19@icloud.com>
**🎯 变更类型**：Bug修复  
**⚡ 重要程度**：🟡 中  
**📋 变更摘要**：在 `bench_serving.py` 中加入对数据集目录完整性的检查，并在自动下载脚本报错时解析缺失的系统命令，抛出更友好的异常信息。此修改旨在解决原来 Bench‑Serving 始终使用固定 Prompt 的问题，并提升脚本的容错能力。  

**🎯 影响范围**：`python/sglang/multimodal_gen/benchmarks/bench_serving.py`（仅此文件）  

**🔍 技术洞察**：  
- **架构影响**：无。仅在基准测试脚本层面新增辅助函数 `is_dir_not_empty` 与错误解析逻辑，不涉及核心库或模块间调用关系。  
- **性能影响**：微乎其微。额外的目录存在性与非空检查、正则匹配仅在首次下载或错误路径下执行，时间复杂度为 O(1)（文件系统查询）和 O(m)（stderr 长度），对整体基准测评性能几乎无影响。  
- **安全考虑**：暂无新增安全风险。错误信息仍通过 `RuntimeError` 直接抛出，可能泄露执行环境的命令行错误信息（如缺失工具名称），如有安全合规要求可考虑对异常信息做脱敏处理。  

**⚠️ 潜在风险**：  
1. **权限异常**：`is_dir_not_empty` 直接调用 `os.listdir`，在目录无读取权限时会抛出 `PermissionError`，导致脚本意外终止。  
2. **异常行为变更**：原先下载失败仅打印日志，现在会抛出 `RuntimeError`，调用方若未捕获该异常可能导致进程退出。  
3. **正则误报**：`re.findall(r"(\S+): command not found", result.stderr)` 假设错误信息固定为 “`xxx: command not found`”，在不同系统或本地化环境下可能匹配不到，从而失去提示作用。  

**💡 关注建议**：  
- 为 `is_dir_not_empty` 增加异常捕获（如 `except PermissionError: return False`），避免因权限问题导致脚本中断。  
- 在调用 `_auto_download_i2v_dataset` 的上层加入异常捕获或容错逻辑，以免 `RuntimeError` 未被处理导致基准测试整体失败。  
- 如项目需要跨平台支持，考虑对 `missing_packages` 的匹配方式做更宽松或本地化的适配。  
- 在 CI 或本地回归测试中加入以下场景：  
  1. 数据集目录已存在且完整 → 验证不触发下载逻辑。  
  2. 只缺少 `crop` 或 `origin` 子目录 → 验证会重新下载。  
  3. 下载脚本因缺少系统命令（如 `wget`）失败 → 验证抛出友好异常并列出缺失命令。  
- 若对异常信息的泄露有顾虑，可在抛出前对 `result.stderr` 做过滤，只保留必要的命令名称。  

### fba785c459d2b50e64ea9de44bd5dce3e72c7237
https://github.com/sgl-project/sglang/commit/fba785c459d2b50e64ea9de44bd5dce3e72c7237
use aync load for encoder_server (#15456)

Signed-off-by: liuanqi <liuanqi6@xiaomi.com>
Co-authored-by: Yuhao Yang <47235274+yhyang201@users.noreply.github.com>
Co-authored-by: liuanqi <liuanqi6@xiaomi.com>
**🎯 变更类型**：功能增强 / 性能优化  
**⚡ 重要程度**：🔴 高  
**📋 变更摘要**：在 `encode_server.py` 中引入基于 `ThreadPoolExecutor` 的并发 I/O 加载，实现对多模态数据（尤其是图片）的异步预处理。新增 `load_image / load_video / load_audio` 通用加载函数，并通过环境变量 `SGLANG_ENCODER_IMAGE_PROCESSOR_USE_GPU` 控制 ImageProcessor 的 GPU 使用。整体实现更加模块化、可并行化，显著降低编码服务的 I/O 阻塞时间。

**🎯 影响范围**：  
- `python/sglang/srt/disaggregation/encode_server.py`（核心服务逻辑）  
- `sglang.srt.utils` 中新增的 `load_image、load_video、load_audio`（多模态数据加载）  
- 环境变量配置及相关文档  

---

### 🔍 技术洞察

| 维度 | 影响描述 |
|------|----------|
| **架构影响** | - 在 `EncodeServer` 实例中新增 `io_executor`（线程池），并通过 `submit_data_loading_tasks`、`_flatten_and_load_images` 等方法实现 I/O 并行化。<br>- 将原先同步的 `load_images` 替换为异步 `await self._flatten_and_load_images`，导致调用链从阻塞改为协程化。<br>- 新增 `use_image_processor_gpu` 环境变量，使 ImageProcessor 的设备选择可配置，提升灵活性。 |
| **性能影响** | - I/O（图片/视频/音频）加载现在可并行执行，预计在高并发请求下整体编码延迟降低 20%~50%（取决于磁盘/网络带宽和 CPU 核数）。<br>- 通过 `max_workers`（默认 4）控制线程数，避免过度线程竞争。<br>- 额外的线程池会占用一定 CPU 与内存，需在资源受限的部署环境中调参。 |
| **安全考虑** | - 加载函数在异常捕获后抛出 `RuntimeError`，未对输入数据进行安全校验，若外部传入恶意文件仍可能触发异常或资源耗尽。<br>- 使用线程池执行 `load_*`，若底层库（如 Pillow、ffmpeg）存在线程安全问题，可能导致未定义行为。<br>- 环境变量暴露 GPU 使用开关，若误开启可能导致未授权的 GPU 计算。 |

---

**⚠️ 潜在风险**  

1. **线程安全风险**：部分第三方库（如 `PIL.Image`, `ffmpeg-python`）在多线程环境下可能不是完全线程安全，极端情况下会出现崩溃或数据损坏。  
2. **资源泄漏**：`ThreadPoolExecutor` 在服务器关闭时未显式 `shutdown`，可能导致进程残留线程，影响后续重启或容器退出。  
3. **兼容性回归**：原来的 `load_images` 被移除，若其他模块或自定义插件仍引用该函数，会报 ImportError。  
4. **配置误用**：`SGLANG_ENCODER_MM_LOAD_WORKERS`、`SGLANG_ENCODER_IMAGE_PROCESSOR_USE_GPU` 默认值不合理时（如工作线程数设为 0 或 GPU 开关误开），会导致性能下降或运行时错误。  
5. **异常处理传播**：`_load_single_item` 抛出 `RuntimeError`，但调用链中未捕获，可能导致协程任务整体被取消，影响服务可用性。

---

**💡 关注建议**  

- **测试覆盖**：为 `_flatten_and_load_images`、`submit_data_loading_tasks` 增加单元测试，覆盖单图、列表、嵌套列表三种输入结构，确保结果顺序与原 `load_images` 完全一致。  
- **资源管理**：在 `EncodeServer` 的 `shutdown`/`__del__` 中显式调用 `self.io_executor.shutdown(wait=False)`，防止线程泄漏。  
- **参数调优**：在部署文档中明确推荐的 `SGLANG_ENCODER_MM_LOAD_WORKERS`（依据机器 CPU 核数）以及 GPU 开关的使用场景。可考虑在启动时自动检测 CPU 核数并动态设定默认值。  
- **兼容性检查**：保留对旧 `load_images` 的兼容包装（如在 utils 中提供向后兼容的别名），或在升级指南中明确说明迁移步骤。  
- **异常容错**：在 `_encode` 调用处捕获 `RuntimeError`，返回明确的错误响应而不是让整个请求崩溃，提升服务稳健性。  
- **性能基准**：在真实负载下对比开启/关闭并行加载的端到端延迟与吞吐量，确认线程数设置对系统整体资源（CPU、IO、GPU）占用的平衡。  

通过以上措施，可最大化利用并行 I/O 带来的吞吐提升，同时降低因并发引入的潜在风险。

### 5cfa901b5739fdbb54840abd05150f3294fdca41
https://github.com/sgl-project/sglang/commit/5cfa901b5739fdbb54840abd05150f3294fdca41
ci: migrate Constrained Decoding tests to test/registered/constrained/ (#16421)
**🎯 变更类型**：重构 / CI 配置  
**⚡ 重要程度**：🟢 低  
**📋 变更摘要**：将受约束解码（Constrained Decoding）相关的测试文件迁移至 `test/registered/constrained/`，并通过 `sglang.test.ci.ci_register` 在 CI 中显式注册 CUDA 与 AMD 两套跑测配置。同步在 `test/srt/run_suite.py` 中删除了旧的硬编码入口，以避免重复加载。  

**🎯 影响范围**：  
- `test/registered/constrained/`（新增路径及注册代码）  
- `test/srt/run_suite.py`（测试入口列表）  
- CI 流水线的测试发现与调度逻辑  

**🔍 技术洞察**  
- **架构影响**：  
  - 将受约束解码测试从“直接路径+硬编码列表”方式转为 “注册表” 方式，遵循 **插件式注册** 设计模式，提升测试组织的可扩展性。  
  - 其他模块不受影响，仅 CI 注册模块 (`sglang.test.ci.ci_register`) 与运行套件入口 (`run_suite.py`) 发生修改。  

- **性能影响**：  
  - **时间**：注册过程仅在 CI 启动阶段执行，额外开销可忽略不计。  
  - **空间**：新增的注册函数占用极少内存，无显著变化。  

- **安全考虑**：  
  - 无涉及业务逻辑或生产代码的改动，未引入安全风险。  

**⚠️ 潜在风险**  
1. **测试遗漏**：若 `register_cuda_ci` / `register_amd_ci` 注册失败，受约束解码测试将不被执行，可能导致回归未被捕获。  
2. **CI 环境差异**：不同硬件环境（CUDA vs AMD）使用不同的 `est_time` 参数，若误配置可能导致 CI 超时或资源分配不均。  
3. **维护一致性**：`run_suite.py` 中的硬编码列表仍需手动同步更新，若后续新增/移动测试忘记更新注册表，可能出现重复或缺失。  

**💡 关注建议**  
- **CI 验证**：在 CI 流水线中加入一步检查，确认 `sglang.test.ci.ci_register` 已成功注册 `test_constrained_decoding.py`，并在报告中显示。  
- **文档同步**：在项目文档（如 `README.md` 或 CI 说明）中标注受约束解码测试的迁移路径与注册方式，防止新贡献者误将文件放回旧目录。  
- **回退策略**：保留旧测试文件（即使不再列入 `run_suite.py`）至少一个 CI 运行周期，以验证新注册机制的可靠性后再彻底删除。  
- **跨平台一致性**：确保 `est_time` 参数的数值依据真实运行时长经验证，避免因时间估算不准导致 CI 超时或资源浪费。  

---

### f27c6cdc2b6a9fe9a6c7da172f283a0772773d4f
https://github.com/sgl-project/sglang/commit/f27c6cdc2b6a9fe9a6c7da172f283a0772773d4f
Migrate metrics tests to test/registered/metrics/ (#16466)
**🎯 变更类型**：测试/配置/重构  
**⚡ 重要程度**：🟢低  
**📋 变更摘要**：将指标相关的单元测试迁移至 `test/registered/metrics/` 目录，并在对应文件中添加 CI 注册代码以声明运行时估计与套件标签；同时在 `test/srt/run_suite.py` 中移除对旧路径下测试文件的显式引用。此举旨在统一测试注册方式，提升 CI 可发现性。  

**🎯 影响范围**：  
- `test/registered/metrics/`（新增 `test_metrics.py`、`test_metrics_utils.py`）  
- `test/srt/run_suite.py`（测试套件清单）  
- CI 注册模块 `sglang.test.ci.ci_register`（新增 `register_cuda_ci`、`register_amd_ci`、`register_cpu_ci` 调用）  

**🔍 技术洞察**：  
- **架构影响**：无直接业务代码改动，仅更改了测试组织方式。测试注册从硬编码列表转为在测试文件内部通过 `ci_register` 动态声明，提升了模块化和可维护性。  
- **性能影响**：不涉及运行时业务代码，唯一潜在影响是 CI 调度时使用的 `est_time` 参数会影响资源分配，但对代码执行性能无影响。  
- **安全考虑**：无安全相关改动；新增的 CI 注册仅是元数据，未引入外部依赖或执行路径。  

**⚠️ 潜在风险**：  
1. **CI 未能正确发现新测试**：如果 CI 系统依赖 `run_suite.py` 的显式列表而非 `ci_register`，新的测试可能被遗漏。  
2. **估计时间不准确**：`est_time=32`（GPU/AMD）和 `est_time=1`（CPU）如果与实际执行时间偏差较大，可能导致 CI 资源调度不合理。  
3. **重复注册或冲突**：若同一测试文件在其他位置也被注册，可能产生重复执行。  

**💡 关注建议**：  
- **CI 验证**：确认 CI 流程已集成 `sglang.test.ci.ci_register`，能够自动收集并运行 `registered` 目录下的测试。运行一次完整的 CI 流水线以验证新测试被执行。  
- **时间估计校准**：观察实际执行时长，必要时调整 `est_time`，避免 CI 超时或资源浪费。  
- **文档同步**：更新项目文档（如 CONTRIBUTING 或测试指南），说明新的测试注册方式和目录结构，以防止开发者仍向旧路径添加测试。  
- **回归测试**：在本地执行 `pytest`（或相应测试命令）覆盖 `test/registered/metrics/`，确保测试本身仍通过。  

整体来看，此次迁移对功能实现没有影响，主要提升了测试组织的可维护性和 CI 可见度，风险可控。

### 5097e1e85b7a50a0b0fc634691e7d4b3aff22c2b
https://github.com/sgl-project/sglang/commit/5097e1e85b7a50a0b0fc634691e7d4b3aff22c2b
fix: moving dpsk v32 cp single node to nightly (#16539)
**🎯 变更类型**：重构 / 测试  
**⚡ 重要程度**：🟡 中  
**📋 变更摘要**：  
- 将 DeepSeek V3.2 CP 单机测试从原来的 `test/srt/` 位置迁移至 `test/registered/8-gpu-models/` 并标记为 nightly CI（`nightly=True`）。  
- 同时在 `test/srt/run_suite.py` 中删除对旧文件的引用，并彻底删除原始实现文件。  
- 新增的测试采用统一的 `run_combined_tests` 框架，支持准确率与性能两类评估，并加入对两种 CP 模式（`in-seq-split`、`round-robin-split`）的覆盖。

**🎯 影响范围**：  
- `test/registered/8-gpu-models/` 目录下的 CI 注册逻辑  
- `test/srt/run_suite.py`（CI 测试套件列表）  
- 删除的旧文件 `test/srt/test_deepseek_v32_cp_single_node.py`（不再参与测试）  

**🔍 技术洞察**：  
- **架构影响**：无业务代码改动，仅涉及测试框架的组织结构。迁移后统一使用 `register_cuda_ci` 与 `run_combined_tests`，提升测试可组合性和可维护性。  
- **性能影响**：测试本身的执行时间保持不变（原估计 360 秒），但使用 `run_combined_tests` 可能在多模型、多个 batch‑size 场景下复用启动过程，略微提升 CI 效率。  
- **安全考虑**：测试代码中仍然使用 `--trust-remote-code`，属于已存在的安全假设，无新增风险。  

**⚠️ 潜在风险**：  
1. **CI 注册遗漏**：若新文件路径或 `register_cuda_ci` 参数写错，nightly 测试可能不会被触发，导致回归检测缺失。  
2. **依赖冲突**：新测试依赖 `sglang.test.run_combined_tests` 等公共模块，若这些模块在未来版本中变更，可能导致该测试失效。  
3. **旧测试残留**：`test/srt/run_suite.py` 中仍有对其他已删除文件的引用（如果手动编辑不完整），会导致 `ImportError`。  

**💡 关注建议**：  
- 在本地或预备 CI 环境运行一次完整的 nightly‑8‑gpu‑common 套件，确认新注册的测试被正确发现并执行。  
- 检查 `register_cuda_ci` 的 `est_time` 与实际运行时长是否匹配，防止 CI 超时。  
- 保持 `test/registered/8-gpu-models/` 与 `test/srt/` 两套目录结构的同步文档，避免未来出现路径混淆。  
- 若后续新增或修改类似测试，建议统一使用 `run_combined_tests` 模式，减少重复的服务器启动/关闭逻辑。  

### 861a35fb6ee14cf2bc7f38407edfdcd7c25e99b7
https://github.com/sgl-project/sglang/commit/861a35fb6ee14cf2bc7f38407edfdcd7c25e99b7
ci: migrate RL tests to test/registered/rl/ (#16417)
**🎯 变更类型**：配置 / CI 测试迁移  
**⚡ 重要程度**：🟡 中  

**📋 变更摘要**  
- 将一批 RL（Reinforcement Learning）相关的测试从原有位置迁移到 `test/registered/rl/`，并通过统一的 `ci_register` 接口注册到 CI。  
- 在 AMD GPU CI 工作流中新增 `stage-b-test-large-2-gpu-amd` 任务，配套更新了 CI 脚本、slash‑command 处理、以及 `run_suite.py` 中的 AMD 测试套件列表。  

**🎯 影响范围**  
- `.github/workflows/pr-test-amd.yml`（CI 工作流）  
- `scripts/ci/*`（启动容器、依赖安装、测试执行脚本）  
- `scripts/ci/slash_command_handler.py`（CI rerun 支持）  
- `test/registered/rl/`（测试文件归档）  
- `test/run_suite.py`、`test/srt/run_suite.py`（测试套件注册与过滤）  

**🔍 技术洞察**  
- **架构影响**：  
  - 引入统一的 `ci_register` 注册机制，提升 CI 配置的可维护性与可扩展性。  
  - 新增的 `stage-b-test-large-2-gpu-amd` 任务在工作流 DAG 中作为 `stage-b` 的并行分支，依赖 `stage-a-test-1-amd` 与 `check-changes`，不会破坏现有模块依赖。  
- **性能影响**：  
  - 新增的 AMD 大模型测试（预计运行时 15~19 分钟）会延长 PR 的 CI 总时长，可能导致资源占用高峰。  
  - `fail-fast: false` 与矩阵并行配置已保证单个 runner 的超时控制，但整体流水线排队时间需关注。  
- **安全考虑**：  
  - 无代码执行路径变更，仅是 CI 配置与测试注册，未引入新的安全风险。  

**⚠️ 潜在风险**  
- **CI 失效风险**：新 job 的 runner (`linux-mi325-gpu-2`) 若不可用或镜像缺失，整体 CI 可能卡住。  
- **测试重复或遗漏**：部分原有 RL 测试在 `test/srt/run_suite.py` 中仍保留引用，被删除或注释的条目可能导致本地手动跑测试时找不到对应文件。  
- **资源超载**：新增大模型测试在 AMD GPU 上消耗显著显存与算力，可能触发 `ensure_vram_clear.sh` 脚本错误或导致其它并发任务 OOM。  

**💡 关注建议**  
- 在合并前在 AMD GPU runner 上手动触发一次完整 CI，验证 `stage-b-test-large-2-gpu-amd` 能成功拉起容器、安装依赖并通过测试。  
- 监控 CI 运行时长，若出现显著增长，考虑将该大模型测试拆分为独立的 “per‑commit‑large‑amd” 套件或使用更大的超时阈值。  
- 更新项目文档（如 CI 说明、测试目录结构），注明已迁移至 `test/registered/rl/`，并解释 `disabled` 标记的来源，以防后续贡献者误删。  
- 确认 `slash_command_handler.py` 中的新增 job 名称同步到所有相关的 CI 命令／bot 脚本，避免在 PR 中使用旧的 stage 名称导致 rerun 失效。  

### 6ffe1fc02faa6752b936c779eb2fca5b590b4928
https://github.com/sgl-project/sglang/commit/6ffe1fc02faa6752b936c779eb2fca5b590b4928
[Fix]Pin mooncake version to 0.3.7.post2 in grace blackwell (#16502)
**🎯 变更类型**：Bug修复 / 依赖更新  

**⚡ 重要程度**：🟡 中  

**📋 变更摘要**：  
- 在 `docker/Dockerfile` 中将 `mooncake-transfer-engine` 的版本固定为 `0.3.7.post2`，仅在构建环境变量 `GRACE_BLACKWELL=1` 时使用；其余情况仍使用最新的 `0.3.8`。  
- 通过条件化安装，解决 Grace Blackwell 环境对旧版 Mooncake 的兼容性问题，防止因自动升级导致的运行时错误。  

**🎯 影响范围**：  
- Docker 镜像构建过程  
- 运行在 Grace Blackwell 环境中的服务实例  
- 依赖 `mooncake-transfer-engine` 的所有业务逻辑（数据传输、模型部署等）  

**🔍 技术洞察**：  
- **架构影响**：无结构性改动，仅在容器构建脚本层面引入条件逻辑，对整体微服务架构保持透明。  
- **性能影响**：安装包版本变更对运行时性能影响微乎其微；唯一可能的差异是 `0.3.7.post2` 与 `0.3.8` 的包大小略有不同，导致 Docker 镜像层大小变化约 ±1‑2 MB。  
- **安全考虑**：  
  - 仍然使用官方 PyPI 包，未引入非官方来源。  
  - 降级至旧版可能丧失 `0.3.8` 中的安全修复，需要确认 `0.3.7.post2` 已包含关键安全补丁或在 Grace Blackwell 环境中不存在相应风险。  

**⚠️ 潜在风险**：  
1. **兼容性回退**：若未来 Grace Blackwell 环境升级，需要重新评估是否仍应锁定 `0.3.7.post2`，否则可能出现功能缺失。  
2. **缓存失效**：Docker 使用 `--mount=type=cache`，条件化安装可能导致缓存层不一致，引发镜像构建时出现“层不可复用”或旧缓存残留的风险。  
3. **环境变量误用**：若 `GRACE_BLACKWELL` 未显式设为 `1`（如空值或拼写错误），将默认安装 `0.3.8`，可能在预期使用旧版时导致意外升级。  

**💡 关注建议**：  
- **测试**：在 CI 中分别构建 `GRACE_BLACKWELL=1` 与默认两套镜像，验证关键业务流（如模型上传、数据传输）在各自版本下均能正常运行。  
- **文档**：在 Dockerfile 或项目 README 中说明 `GRACE_BLACKWELL` 环境变量的作用、取值范围及对应的 Mooncake 版本。  
- **安全审计**：检查 `0.3.7.post2` 的已知 CVE 列表，确保没有未修复的高危漏洞；如有，考虑在 Grace Blackwell 环境中同步上游安全补丁。  
- **后续计划**：记录此版本锁定的根本原因（兼容性/bug），为未来统一升级到 `0.3.8` 或更高版本提供可追溯的决策依据。  

### 73398e22d6c0c24e7505680336273cdfbb90499e
https://github.com/sgl-project/sglang/commit/73398e22d6c0c24e7505680336273cdfbb90499e
ci: migrate VLM tests to test/registered/vlm/ (#16415)
**🎯 变更类型**：重构 / CI 配置 / 测试组织  
**⚡ 重要程度**：🟡 中  

**📋 变更摘要**  
- 将 VLM（视觉语言模型）相关的单元测试迁移至 `test/registered/vlm/` 目录，并使用 `register_cuda_ci` 为每个测试用例注册 CI 参数（估算执行时间、所属套件）。  
- 更新 import 路径，从原先的相对路径 `test_vision_*_common` 改为统一的 `sglang.test.vlm_utils`。  
- 同时在 `test/srt/run_suite.py` 中移除已迁移测试的入口，防止重复执行。  

**🎯 影响范围**  
- `test/registered/vlm/` 目录下的 VLM 测试文件（`test_vision_chunked_prefill.py`, `test_vision_openai_server_a.py`, `test_vlm_input_format.py`）。  
- `python/sglang/test/vlm_utils.py`（提供共享测试工具）。  
- CI 运行脚本与 `test/srt/run_suite.py`（测试列表管理）。  

**🔍 技术洞察**  
- **架构影响**：  
  - 仅限于测试层面的组织重构，业务代码未受影响。  
  - 通过统一的 `register_cuda_ci` 装饰器，引入了模块化的 CI 注册机制，提升了测试用例的可发现性与可配置性。  
- **性能影响**：  
  - 无直接运行时性能变化。  
  - CI 中估算执行时间的新增字段帮助调度器更合理地分配 GPU 资源，间接提升整体 CI 吞吐。  
- **安全考虑**：  
  - 变更仅涉及测试代码与 CI 配置，未引入外部依赖或安全敏感操作，安全风险可视为 **无**。  

**⚠️ 潜在风险**  
1. **导入路径错误**：如果其他未迁移的测试仍依赖旧的 `test_vision_*_common`，可能出现 `ImportError`。  
2. **CI 注册失效**：`register_cuda_ci` 参数填写错误（如 `est_time` 与实际执行时间相差悬殊）可能导致 CI 资源调度不均，引起 timeout 或 GPU 空闲。  
3. **测试列表同步**：`run_suite.py` 中的手动删除若未覆盖所有入口，可能导致遗漏或重复执行。  

**💡 关注建议**  
- **回归验证**：在本地或预发布 CI 环境运行全部 VLM 测试，确保 import 路径已全部迁移且所有测试均通过。  
- **CI 参数校准**：监控实际运行时间，必要时微调 `est_time`，避免因时间估算不准导致的调度异常。  
- **文档同步**：更新项目的测试组织文档（如 CONTRIBUTING 或 CI 指南），说明新目录结构和 `register_cuda_ci` 的使用方式。  
- **持续维护**：后续新增 VLM 测试务必放置于 `test/registered/vlm/` 并使用同样的注册方式，防止再次出现目录散落的情况。  

### 17958c5f0d675a7915c1d621a3e2e54f24708490
https://github.com/sgl-project/sglang/commit/17958c5f0d675a7915c1d621a3e2e54f24708490
Migrate parsing tests to test/registered/parser/ (#16467)
**🎯 变更类型**：配置 / CI 流程扩展、测试注册  
**⚡ 重要程度**：🟡 中  

**📋 变更摘要**  
1. 在 GitHub Actions 工作流中新增 `stage-a-cpu-only` Job，用于在 CPU 环境下只跑解析器相关的轻量测试（`stage-a-cpu-only` suite）。  
2. 将该 stage 加入 slash‑command 重跑逻辑、`run_suite.py` 中的 per‑commit suite 列表，并在相应的 parser 测试文件中使用 `register_cpu_ci` 注册。  
3. 从 SRT（系统级回归）测试列表中移除这两个 parser 测试，使其仅在新建的 CPU‑only stage 中执行。  

**🎯 影响范围**  
- `.github/workflows/pr-test.yml`（CI 工作流）  
- `scripts/ci/slash_command_handler.py`（CI 触发脚本）  
- `test/registered/parser/*.py`（Parser 测试文件）  
- `test/run_suite.py`、`test/srt/run_suite.py`（测试套件配置）  

**🔍 技术洞察**  
- **架构影响**：  
  - 添加了专属的 CI stage，形成了“CPU‑only → parser 测试” 的模块化执行路径，保持了原有的 GPU/AMD stage 不受影响。  
  - 通过 `register_cpu_ci` 将测试元信息（预计耗时、所属 suite）显式绑定到 CI，提升了 CI 配置的可维护性。  
- **性能影响**：  
  - 该 stage 只跑两个轻量测试，预计每次约 5‑6 分钟，对整体 PR 检查时间影响有限。  
  - 通过在 CI 开头清理磁盘空间，可避免磁盘占用导致的磁盘 I/O 报错。  
- **安全考虑**：  
  - 无新增运行时代码，安全风险基本为 **无**。  

**⚠️ 潜在风险**  
1. **测试遗漏**：将 parser 测试从 SRT 列表中移除后，若 `stage-a-cpu-only` 因配置错误未执行，可能导致这些测试在主 CI 中完全失效。  
2. **CI 资源争用**：新增加的 Job 会占用额外的 Ubuntu runner ，在高并发时可能出现排队延迟。  
3. **Flaky/超时**：`est_time` 仅为 5‑6 分钟，若实际运行时间超过预估（例如因依赖下载慢），可能触发 timeout 导致 CI 失败。  
4. **兼容性**：`needs: [check-changes, call-gate]` 中的条件依赖于 `inputs.target_stage` 与 `needs.check-changes.outputs.main_package`，若这些输出在未来工作流改动中被更改，可能导致该 stage 被误屏蔽。  

**💡 关注建议**  
- **验证新 stage**：在合并前通过手动触发或 schedule 运行一次，确保 `stage-a-cpu-only` 能正确 checkout 代码、安装依赖并执行两个 parser 测试。  
- **监控执行时间**：在 CI 运行后查看实际耗时，若持续超过 10 分钟，考虑提升 `timeout-minutes` 或优化测试代码。  
- **回退措施**：保留 `test/srt/run_suite.py` 中对 parser 测试的注释（而非彻底删除），便于在 CI 出现异常时快速恢复到原有 SRT 测试路径。  
- **文档更新**：在项目的 CI 说明文档中加入对 `stage-a-cpu-only` 的解释，标明其目的、运行条件以及如何在本地调试。  
- **依赖锁定**：确保 `python/[dev]` 环境在 CI 中能够稳定安装，避免因为依赖变更导致解析器测试无法运行。  

通过上述检查与监控，可将新增的 CPU‑only parser 测试 stage 平稳引入项目 CI，提升专属解析器测试的可见性与隔离性，风险保持在可接受范围。

### 3aa11ca722ce25d6d1f291636b3bcdd7b3f43dd9
https://github.com/sgl-project/sglang/commit/3aa11ca722ce25d6d1f291636b3bcdd7b3f43dd9
Remove hybrid_kvcache_ratio in server args (#16399)
**🎯 变更类型**：重构 / 依赖更新 / 文档  

**⚡ 重要程度**：🟡 中  

**📋 变更摘要**  
本次提交移除了 `--hybrid-kvcache-ratio` 参数及其在模型配置中的相关逻辑，改为使用统一的 `--swa-full-tokens-ratio`（默认 0.8）来控制 SWA 层 KV 缓存占比。相应地更新了文档、`ServerArgs`、模型配置、混合模型检测函数以及 KV 缓存分配代码，实现了对 **Hybrid‑SWA** 的更简化判定及内存分配方式。

**🎯 影响范围**  
- `docs/basic_usage/llama4.md`（文档）  
- `python/sglang/srt/configs/model_config.py`（模型配置）  
- `python/sglang/srt/server_args.py`（CLI 参数）  
- `python/sglang/srt/managers/tp_worker.py`（worker 访问属性）  
- `python/sglang/srt/model_executor/model_runner_kv_cache_mixin.py`（KV 缓存分配逻辑）  
- 相关内部工具函数 `is_hybrid_swa_model`、`_derive_hybrid_model` 等  

**🔍 技术洞察**  

- **架构影响**  
  - 删除了 `ModelConfig` 中的 `hybrid_kvcache_ratio` 字段，简化了模型配置结构。  
  - 引入了 `is_hybrid_swa_model`，仅基于模型架构名称判断是否为 Hybrid‑SWA，去除了对 ``hybrid_kvcache_ratio``、上下文长度、attention chunk size 等多参数的依赖。  
  - `ServerArgs` 现在只保留 `swa_full_tokens_ratio`，旧参数仍通过 `DeprecatedAction` 接收但会被标记为弃用，保持向后兼容。  

- **性能影响**  
  - 旧实现根据 `hybrid_kvcache_ratio` 动态计算 SWA 与全层 KV 缓存的比例，可能在不同上下文长度下获得更细粒度的内存利用。  
  - 新实现固定使用 `swa_full_tokens_ratio`（默认 0.8），并在 `model_runner_kv_cache_mixin.py` 中针对 `MiMoV2MTP` 保持原有行为，针对 Llama4 等模型删除了复杂的比例计算，改为直接使用默认比例。  
  - 这会导致 **SWA KV 缓存占用略有固定化**，在极端场景（非常长 context 或非常小 page_size）下可能出现轻微的内存使用波动或 token 分配不够最优，但整体影响有限。  

- **安全考虑**  
  - 该改动不涉及网络、权限或加密等安全面向。  
  - 唯一需关注的是 **CLI 参数弃用**：如果用户在生产脚本中仍使用 `--hybrid-kvcache-ratio`，可能因新版解析仅发出警告而导致配置被误认为已生效，进而产生非预期的内存行为。  

**⚠️ 潜在风险**  

1. **向后兼容性**：  
   - 虽然保留了 `--hybrid-kvcache-ratio` 的解析入口，但已改为 `DeprecatedAction`，若该实现仅打印警告而不抛异常，旧脚本仍能运行；若未来彻底删除，使用旧参数的用户会直接报错。  
2. **功能回退**：  
   - 之前可以通过调节 `hybrid_kvcache_ratio` 实现细粒度的 KV 缓存分配（例如在 Llama4 中让 SWA 层占比更大），现在只能通过 `swa_full_tokens_ratio` 调整整体 SWA 层占比，失去了对 **局部注意力层** 与 **全局注意力层** 的独立控制。  
3. **文档/示例同步**：  
   - 文档已更新，但若还有未同步的 README、脚本或 CI 配置，用户可能仍会看到旧参数导致混淆。  

**💡 关注建议**  

- **升级指南**：在发布说明中明确告知用户：`--hybrid-kvcache-ratio` 已废弃，全部改为 `--swa-full-tokens-ratio`（默认 0.8）。若业务依赖自定义比例，请直接使用后者。  
- **测试覆盖**：  
  - 增加针对 `Llama4`、`MiMoV2MTP` 等模型的 **Hybrid‑SWA** 单元测试，验证在不同 `swa_full_tokens_ratio` 下 KV 缓存分配是否符合预期。  
  - 添加一次性 **CLI 参数回退测试**：使用 `--hybrid-kvcache-ratio` 启动服务器，确保系统打印废弃警告并使用默认 `swa_full_tokens_ratio`。  
- **监控/评估**：在生产环境开启内存/KV 缓存使用监控，留意因比例固定导致的潜在内存增长或 token 生成速率变化。  
- **代码审查**：确保 `DeprecatedAction` 的实现不会误将旧参数的值当作有效配置传递给后续逻辑，避免出现“参数被忽略却未提示”的情况。  

通过上述措施可以平滑完成参数迁移，最小化对已有部署的冲击，同时保持新特性的可维护性和可预测的行为。

### 7be1a8c70cdf2a4e878eca5f6f24b845ba181ef0
https://github.com/sgl-project/sglang/commit/7be1a8c70cdf2a4e878eca5f6f24b845ba181ef0
[diffusion] feat: support diffusers backend - run any model supported by diffusers (#14112)
**🎯 变更类型**：功能增强（feat）  
**⚡ 重要程度**：🔴 高  

**📋 变更摘要**  
- 新增 **diffusers** 后端支持：实现 `DiffusersPipeline`，可以直接跑任意 HuggingFace Diffusers 模型，无需 SGLang 原生实现。  
- 新增通用管线配置 `DiffusersGenericPipelineConfig` 与采样参数 `DiffusersGenericSamplingParams`，并在注册体系中自动发现。  
- 扩展 CLI、OpenAI 接口、ServerArgs 等，使用户可以通过 `--backend diffusers` 或自动回退方式使用该后端，同时加入 `diffusers_kwargs` 让用户自定义 Diffusers 参数。  

**🎯 影响范围**  
- `sglang/multimodal_gen/configs/pipeline_configs/*`（新增/修改）  
- `sglang/multimodal_gen/configs/sample/*`（新增）  
- `sglang/multimodal_gen/runtime/registry.py`、`runtime/pipelines_core/*`（后端选择逻辑）  
- `runtime/pipelines/diffusers_pipeline.py`（核心实现）  
- CLI、OpenAI Image/Video API、utils、GPU worker 代码路径均有改动。  

**🔍 技术洞察**  

- **架构影响**  
  - **模块划分**：新增 `DiffusersPipeline` 作为 `ComposedPipelineBase` 子类，遵循现有 **Stage‑Executor‑Pipeline** 框架，保持与原生 SGLang pipeline 的接口一致。  
  - **后端抽象**：`Backend` 枚举与 `get_model_info(model_path, backend=…)` 让模型加载在 **AUTO → SGLang → Diffusers** 三层自动回退，提升鲁棒性。  
  - **配置统一**：`DiffusersGenericPipelineConfig` 与 `DiffusersGenericSamplingParams` 通过 `__all__` 注入，保证 `import *` 时可直接使用。  
  - **请求对象扩展**：`Req` 增加 `true_cfg_scale`，`extra.diffusers_kwargs` 用于透传 Diffusers 特有参数，保持向后兼容。  

- **性能影响**  
  - **加载阶段**：利用 `device_map="cuda"`、`torch_dtype` 自动选取 BF16/FP16，配合 **accelerate** 并行分片，可显著降低初始化时的 CPU→GPU 拷贝开销。  
  - **运行时**：`DiffusersExecutionStage` 在调用前过滤不支持的 kwargs，避免因参数错误导致的异常；`_postprocess_output` 对 NaN/Inf 做修复，防止后续算子崩溃。  
  - **内存优化**：通过 `vae_slicing`、`vae_tiling`、`diffusers_attention_backend`（flash、xformers 等）可在保持相同输出质量的前提下降低显存峰值。  
  - **潜在开销**：若 `diffusers_kwargs` 包含大量大张量（如 `input_ids`），会直接进入 Diffusers 的内部实现，可能导致额外显存占用，需要用户自行衡量。  

- **安全考虑**  
  - **远程模型下载**：使用 `maybe_download_model`（与原有实现相同），但在 `DiffusersPipeline._load_diffusers_pipeline` 中对 `trust_remote_code` 默认仍受 `ServerArgs.trust_remote_code` 控制，未新增风险。  
  - **参数注入**：`diffusers_kwargs` 直接通过 `json.loads` 解析并在运行时 `update`，若上层对 JSON 输入未做校验，可能导致恶意代码在自定义 Diffusers pipeline 中执行（如自定义 `custom_pipeline`）。建议在生产环境限制 `--backend diffusers` 并限制 `diffusers_kwargs` 的可接受键。  
  - **日志**：对 `diffusers_kwargs` 只做 `logger.info` 打印，未写入敏感信息，安全性保持。  

**⚠️ 潜在风险**  
1. **兼容性回退**：`Backend.AUTO` 在某些模型的 `_class_name` 未注册时会自动切换到 Diffusers。若该模型在 Diffusers 上也不兼容（例如需要自定义 pipeline 且 `trust_remote_code=False`），会抛出运行时异常。  
2. **参数冲突**：用户通过 `--diffusers-kwargs` 传入的键可能覆盖 SGLang 已处理的参数（如 `height`、`width`、`guidance_scale`），导致意料之外的行为。  
3. **显存峰值**：开启 VAE‑tiling、‑slicing 与 Diffusers 自身的 `torch_dtype` 不匹配时，可能出现 **float16 → bf16** 转换导致额外拷贝，增大显存占用。  
4. **多视频流**：`DiffusersPipeline.is_video_pipeline` 通过简单关键词判断，若出现新模型名称未包含关键字，可能误判为图像 pipeline，导致 `num_frames` 参数被忽略。  
5. **线程安全**：`DiffusersExecutionStage.forward` 在多进程/多 GPU 场景下复用同一个 `DiffusionPipeline` 对象，若 Diffusers 实现内部不支持并发（如某些自定义 pipeline），可能出现竞态错误。  

**💡 关注建议**  
- **回归测试**：在 CI 增加对几类主流 Diffusers 模型（StableDiffusion‑XL, Flux, AnimateDiff, Diffusers‑custom）使用 `--backend diffusers` 的端到端生成测试，验证 `diffusers_kwargs` 透传与输出正确性。  
- **参数白名单**：在 `DiffusersExecutionStage._filter_pipeline_kwargs` 增加可接受键的白名单（如 `image`, `prompt`, `num_inference_steps` 等），对未知键仅记录警告而不 silently 丢弃，降低用户调参的猜测成本。  
- **文档**：在官方 README 与 CLI 帮助中说明 `--backend` 的三种模式、何时适用以及 `diffusers_kwargs` 的使用示例。  
- **安全**：在生产部署（尤其公开 API）中禁用 `--diffusers-kwargs` 或仅允许安全子集；对 `trust_remote_code` 默认保持 `False`。  
- **显存监控**：在 `DiffusersPipeline._apply_vae_optimizations` 与 `DiffusersExecutionStage._postprocess_output` 中加入显存日志（`torch.cuda.max_memory_allocated`），帮助用户评估开启 `vae_tiling`/`vae_slicing` 的实际收益。  
- **后续拓展**：考虑将 `Backend` 扩展为插件机制，允许社区自定义第三方后端（如 `onnxruntime`），并统一 `ModelInfo` 注册入口。  

---  

*该提交为 SGLang 项目引入了对 HuggingFace Diffusers 后端的全面支持，显著提升了模型兼容性与可用性，同时在实现上保持了与现有框架的一致性。开发者在使用新后端时请注意 `diffusers_kwargs` 的来源安全，以及显存/并发特性的潜在限制。*

### 84d13c54bbbdabe00c3fca1d404949d20532db54
https://github.com/sgl-project/sglang/commit/84d13c54bbbdabe00c3fca1d404949d20532db54
feat: only add input vision tokens in `bench_serving` result if vision dataset is used (#15492)

Signed-off-by: Raayan Dhar raayan.dhar@gmail.com <raayan.dhar@gmail.com>
**🎯 变更类型**：功能增强  
**⚡ 重要程度**：🟢低  
**📋 变更摘要**：在 `bench_serving.py` 中新增对输入视觉 token 统计的条件打印，仅当使用图像相关数据集（`image`、`mmmu`）时才展示该指标，避免在纯文本任务中出现误导性的统计信息。  

**🎯 影响范围**：  
- `python/sglang/bench_serving.py`（基准服务脚本）  

**🔍 技术洞察**：  
- **架构影响**：无；仅修改了呈现层的打印逻辑，不影响核心业务流程或模块耦合。  
- **性能影响**：极小。条件判断在每次打印时执行，时间复杂度 O(1)，对整体执行时间和内存占用基本没有影响。  
- **安全考虑**：无。改动不涉及数据处理、网络交互或权限控制，未引入安全风险。  

**⚠️ 潜在风险**：  
- 若未来新增其他视觉或多模态数据集，但未同步更新 `args.dataset_name` 检查列表，可能导致相应的视觉 token 统计未被打印，产生统计盲点。  
- 条件判断依赖字符串匹配，若 `args.dataset_name` 的取值方式或命名规范变化，可能导致判断失效。  

**💡 关注建议**：  
- **测试**：在包含视觉数据的基准任务（如 `image`、`mmmu`）以及纯文本任务上分别运行，确认视觉 token 统计在前者出现、后者隐藏，且不会影响其他指标的正确性。  
- **文档**：更新使用说明，明确哪些 `dataset_name` 会触发视觉 token 的统计展示，帮助使用者了解输出差异。  
- **可扩展性**：如果后续加入更多多模态数据集，建议将视觉数据集列表抽象为常量或配置项，以免遗漏。  
- **回归**：在持续集成中加入对 `bench_serving` 输出的快照测试，防止条件判断被意外修改导致统计信息异常。

### c80c0e0fc0d33e5e680e4dd0e32a6f3a17267471
https://github.com/sgl-project/sglang/commit/c80c0e0fc0d33e5e680e4dd0e32a6f3a17267471
fix: adding multi-threading for kimi weights loading in pr test (#16538)
**🎯 变更类型**：功能增强 / 测试  

**⚡ 重要程度**：🟡中  

**📋 变更摘要**：在 `test/srt/models/test_kimi_k2_models.py` 中为模型启动命令添加了 `--model-loader-extra-config` 参数，开启权重加载多线程并设定线程数为 64。此改动验证了模型加载器对多线程配置的支持，预计可显著缩短大模型权重的加载时间。  

**🎯 影响范围**：  
- `srt/models`（模型加载器）  
- 测试套件 `test/srt/models/test_kimi_k2_models.py`  
- 可能影响所有使用相同 `--model-loader-extra-config` 参数的启动脚本  

**🔍 技术洞察**：  
- **架构影响**：新增了 `model-loader-extra-config` 结构化配置入口，内部预计会读取 `enable_multithread_load` 与 `num_threads`，可能会在模型加载层引入线程池或并行 I/O 调度。对现有单线程加载路径保持兼容，属于向后兼容的可选特性。  
- **性能影响**：在 I/O 密集型的权重读取阶段，多线程（64 threads）可大幅提升磁盘/网络带宽利用率，加载时间预计下降 30%‑70%。但若 CPU 核心数不足或磁盘 IO 已达瓶颈，过多线程可能导致上下文切换开销，出现性能回退。  
- **安全考虑**：无直接安全风险，但需要确保多线程代码在异常路径下能够正确回滚、释放资源，防止资源泄露或死锁。  

**⚠️ 潜在风险**：  
1. **线程安全**：模型加载的内部数据结构若未做好并发保护，可能出现竞争条件、数据损坏或崩溃。  
2. **资源消耗**：`num_threads=64` 在资源受限的 CI 环境或低配机器上可能导致 CPU、内存、文件描述符耗尽，引起其他测试失败。  
3. **配置泄露**：如果该额外配置未在生产启动脚本中显式屏蔽，误将多线程加载打开，可能在生产环境引发不可预料的行为。  
4. **兼容性**：旧版模型加载器（未实现该配置）在接收到该参数时可能报错或忽略，导致测试结果不一致。  

**💡 关注建议**：  
- **代码审查**：确认模型加载器实现了对 `enable_multithread_load` 与 `num_threads` 的完整并发控制（锁、原子操作或线程安全的 I/O 库）。  
- **单元/集成测试**：新增多线程加载的专属测试，用不同线程数（如 1、8、16、64）对比加载时间及资源占用，验证在低配机器上的可接受性。  
- **资源限制**：在 CI 环境中为测试设置 `ulimit` 或容器资源配额，防止线程数过多导致资源争用。  
- **文档说明**：在模型加载器的配置文档中明确该选项的作用、适用场景、默认值及安全使用建议。  
- **回滚路径**：确保在未显式开启时仍保持单线程加载，且启动脚本默认不带该配置，以免意外引入。  

---  

*本次改动虽仅涉及测试文件，但暴露了模型加载器的新并发入口。建议在正式发布前完成并发安全性验证与性能基准，确保该特性在生产环境可平稳使用。*

### c105a3124b9d840742c6101fd8216a3c119018d4
https://github.com/sgl-project/sglang/commit/c105a3124b9d840742c6101fd8216a3c119018d4
Support multi-round conversations in bench_serving (#6135)
**🎯 变更类型**：功能增强 / 测试  
**⚡ 重要程度**：🔴 高  
**📋 变更摘要**  
- 为 `bench_serving.py` 引入 **多轮对话 (multi‑turn)** 支持：CLI 新增 `--gsp-num-turns` 参数，数据生成逻辑能够生成同一系统提示下的多轮问题；请求函数被包装成能够在同一会话中循环发送多轮消息，并在最后一轮返回整体结果。  
- 相应地扩展了 `RequestFuncInput.prompt` 类型，调整了指标计算、缓存、日志及并发控制的实现。  
- 为测试框架增加默认 `backend` 参数及多轮相关的 `gsp_*` 参数，并新增 **端到端功能测试**，验证多轮请求的正确性与日志前缀关系。  

**🎯 影响范围**  
- `python/sglang/bench_serving.py`（核心基准执行、数据生成、CLI 参数、请求包装、指标计算）  
- `python/sglang/test/test_utils.py`（默认参数、CLI 参数转发）  
- 新增测试文件 `test/registered/bench_fn/test_bench_serving_functionality.py`（CI）  
- 依赖的后端实现（`sglang-oai-chat`, `vllm-chat`, `lmdeploy-chat`）在多轮模式下被调用  

**🔍 技术洞察**  

| 维度 | 影响分析 |
|------|----------|
| **架构影响** | - 引入 **`wrap_multi_turn_request_func`** 高阶函数，实现“请求 → 多轮循环 → 汇总”模式，保持原有单轮 `request_func` 不变，仅在入口处进行包装。<br>- 新增 `MULTI_TURN_BACKENDS` 集合，限制仅在已实现聊天接口的后端上使用多轮，防止不兼容后端误用。<br>- 数据生成从 `num_groups × prompts_per_group` 扩展为 `num_groups × prompts_per_group × num_turns` 的三维结构，保持向后兼容（`num_turns=1` 时行为不变）。 |
| **性能影响** | - 多轮对话会把一次“conversation”拆成 `num_turns` 次 HTTP 请求，整体请求数线性增长，可能导致并发瓶颈。<br>- 为避免在中间轮次统计指标，`benchmark` 中通过 `is_multi_turn` 将 `input_requests` 设为 `None`，只在最后一轮统计，降低了统计开销。<br>- 使用 `copy.deepcopy` 与 `replace` 复制 `RequestFuncInput`，对单次请求的时间开销可忽略（仅几百字节的结构）。 |
| **安全考虑** | - 无新外部依赖或权限提升，仅在内部包装请求对象。<br>- `copy.deepcopy` 与 `replace` 处理的数据均来自用户传入的 `prompt`，未引入额外的代码执行路径，安全风险极低。 |
| **可维护性** | - 新增类型 `Union[str, List[str], List[Dict[str, str]]]` 需要在所有调用处检查兼容性，已在 `bench_serving.py` 完全覆盖。<br>- 多轮包装逻辑独立在 `wrap_multi_turn_request_func`，易于单元测试和后期扩展。 |

**⚠️ 潜在风险**  
1. **向后兼容性**：`RequestFuncInput.prompt` 类型扩展为列表，已有代码如果对 `prompt` 做 `isinstance(..., str)` 之外的检查可能出现意外分支。  
2. **非聊天后端误用**：如果用户在 `backend` 参数中手动指定非聊天模型（如 `sglang-oai-completions`），`wrap_multi_turn_request_func` 会被错误地包装，导致运行时断言错误。  
3. **指标统计偏差**：在多轮模式下 `calculate_metrics` 接收 `input_requests=None`，若后续改动依赖 `input_requests` 做更细粒度的分析（如 per‑turn latency），可能出现 `NoneType` 错误。  
4. **并发资源耗尽**：`num_turns` 较大时，单会话的并发请求数会乘以 `num_turns`，在高负载测试下可能触发 `Semaphore` 限制或服务器端并发上限。  
5. **日志前缀验证**：测试仅检查文本前缀关系，未验证 `routing_key`、`request_id` 等元信息在多轮间是否保持一致，若后端依赖这些字段进行会话关联，可能出错。  

**💡 关注建议**  
- **回归测试**：在所有已支持的聊天后端（`sglang-oai-chat`, `vllm-chat`, `lmdeploy-chat`）跑完整的单轮 & 多轮基准，确保 `is_multi_turn` 分支不影响单轮表现。  
- **文档更新**：在 CLI 使用手册中明确 `--gsp-num-turns` 的默认值、适用后端以及资源消耗的线性关系。  
- **参数校验**：在 `bench_serving.py` 入口处加入对 `backend` 与 `gsp_num_turns` 的提前校验，给出友好错误提示而非断言。  
- **指标扩展**：考虑在多轮模式下保留每轮的 `latency`、`ttft`，以便后续分析对话流畅度（如 per‑turn latency）。  
- **资源限制**：建议在文档或 CLI 中提供 `--max-concurrency-per-turn` 之类的参数，帮助用户在多轮场景下避免并发爆炸。  
- **安全审计**：虽然风险低，但仍建议在 CI 中加入对 `copy.deepcopy` 与 `replace` 使用的安全代码审查，防止未来引入可执行对象。  

总体而言，此次改动为 **多轮对话基准** 功能提供了完整实现和自动化验证，提升了 SGLang 在聊天场景下的评测能力，只要按照上述建议进行兼容性与资源管理的把控，即可安全发布。

### 4cf2bbd084300c0e7fa9715a04f08e0db9858e46
https://github.com/sgl-project/sglang/commit/4cf2bbd084300c0e7fa9715a04f08e0db9858e46
[router] Remove deadcode and add note for unused API completeness methods (#16528)
**🎯 变更类型**：重构 / 代码清理  

**⚡ 重要程度**：🟢 低  

**📋 变更摘要**：  
- 移除了若干已不再使用的结构体字段、方法以及 `#[allow(dead_code)]` 标记，统一在代码上添加 “API 完整性保留” 的注释。  
- 同时去除了 `WorkerRegistry` 在 `ResponsesContext` 中的持有以及相应的导入，精简了上下文结构体。  

**🎯 影响范围**：  
- `sgl-model-gateway/src/routers/grpc/common/stages/dispatch_metadata.rs`  
- `sgl-model-gateway/src/routers/grpc/context.rs`（`DispatchMetadata`、`WorkerSelection`、`ClientSelection`）  
- `sgl-model-gateway/src/routers/grpc/harmony/types.rs`（`HarmonyChannelDelta`）  
- `sgl-model-gateway/src/routers/grpc/regular/responses/context.rs`（`ResponsesContext`）  
- `sgl-model-gateway/src/routers/grpc/router.rs`（创建 `ResponsesContext` 时的参数）  

**🔍 技术洞察**  

- **架构影响**：  
  - 代码层面仅是对内部未使用的成员进行裁剪，未改动模块之间的交互接口。  
  - 移除 `DispatchMetadata.is_streaming` 以及 `ResponsesContext.worker_registry` 后，若有外部模块（如自定义插件或测试代码）直接访问这些字段，将会产生编译错误。  
  - 新增的 “Some methods are kept for API completeness even if currently unused.” 注释，表明保留的空实现仍然是公开 API 的一部分，避免因完全删除而导致向后兼容性问题。  

- **性能影响**：  
  - 删除无用字段和 `#[allow(dead_code)]` 标记，略微降低编译时间和生成的二进制体积。  
  - 运行时性能基本不受影响，因为这些成员在运行期间从未被访问。  

- **安全考虑**：  
  - 无新增安全风险。移除未使用的字段反而可以降低误用的可能性。  

**⚠️ 潜在风险**：  
1. **兼容性破坏**：如果项目的其它 crate（或内部工具）曾经在代码层面访问 `DispatchMetadata.is_streaming`、`ResponsesContext.worker_registry` 或者使用被 `#[allow(dead_code)]` 隐藏的成员，将在升级后出现编译错误。  
2. **文档/示例不匹配**：项目文档或示例若仍然展示这些已删除的字段/方法，可能导致用户困惑。  

**💡 关注建议**：  
- **升级前检查**：在升级到包含此提交的版本前，使用 IDE 或 `cargo check` 搜索项目代码库中对 `is_streaming`、`worker_registry` 的引用并进行相应移除或替代。  
- **文档同步**：更新相关的开发文档、README、示例代码，去除已删除成员的说明。  
- **测试覆盖**：虽然功能未改变，仍建议运行完整的单元测试、集成测试以及性能基准，确保没有因结构体布局变化导致的潜在回归（尤其是序列化/反序列化相关代码）。  
- **保持注释**：保留 “API 完整性” 注释是一个好的做法，若未来真正需要实现这些方法，直接补全即可；同时可以考虑在 `Cargo.toml` 中开启 `deny(warnings)` 来避免意外留下的 `#[allow(dead_code)]`。  

总体来看，此次提交属于安全的代码清理改动，风险可控，只需注意对外部依赖的兼容性检查即可。

### d7b706be945bea1c55ce86ba9c6c6558c41c915d
https://github.com/sgl-project/sglang/commit/d7b706be945bea1c55ce86ba9c6c6558c41c915d
ci: migrate HiCache 1-GPU tests to test/registered/hicache/ (#16416)
**🎯 变更类型**：配置 / CI 流程改动  
**⚡ 重要程度**：🟢低  
**📋 变更摘要**：  
- 将 HiCache 相关的 1‑GPU 测试文件迁移至 `test/registered/hicache/` 目录，并在文件头部加入 `register_cuda_ci` 注册调用，以便在 CI 中自动按预估时长和套件标签进行调度。  
- 同步更新 `test/srt/run_suite.py`，移除对这两个测试的显式引用，交由注册机制统一管理。  

**🎯 影响范围**：  
- `test/registered/hicache/` 目录下的 `test_hicache_storage.py`、`test_hicache_variants.py`  
- CI 入口 `test/srt/run_suite.py`（suite 配置）  
- CI 注册模块 `sglang.test.ci.ci_register`（使用 `register_cuda_ci`）  

**🔍 技术洞察**：  
- **架构影响**：无业务代码改动，仅涉及测试框架的组织方式。通过 `register_cuda_ci` 实现“声明式”注册，遵循 **插件式**（Plugin）设计，降低 `run_suite` 对测试文件的硬编码耦合。  
- **性能影响**：不影响运行时性能。对 CI 调度有正面影响：CI 能依据 `est_time` 更精准地分配资源，避免因手动配置错误导致的 GPU 资源浪费。  
- **安全考虑**：无安全相关改动。唯一需关注的是 CI 注册代码本身的异常处理（如注册函数异常抛出），若未捕获可能导致 CI 任务提前失败。  

**⚠️ 潜在风险**：  
1. **注册失效**：如果 `register_cuda_ci` 实现或导入路径出现问题（路径拼写错误、模块未安装），这些测试将不再被 CI 调度，导致回归覆盖缺失。  
2. **重复注册**：同一测试文件若被误加入 `run_suite` 与注册机制双重列出，可能导致重复执行，浪费 CI 资源。  
3. **估算时间不准**：`est_time` 参数是手工填写，若显著偏离实际运行时长，CI 调度依然可能出现资源争抢或空闲。

**💡 关注建议**：  
- **验证注册路径**：在本地或 CI 环境执行一次 `python -c "from sglang.test.ci.ci_register import register_cuda_ci; print('ok')"`，确保模块可导入。  
- **加入回归检测**：在 CI 流水线中加入步骤，列出已注册的测试并与 `run_suite` 的列表做对比，防止遗漏或重复。  
- **监控执行时长**：首次正式运行后收集实际耗时，调整 `est_time` 使其更贴近真实值，提升调度效率。  
- **文档同步**：在项目的 CI 配置文档（如 CONTRIBUTING.md）中注明新迁移的目录与注册方式，帮助新贡献者了解测试加入的正确流程。  

### 4a9537a495fd6425a3c3c10ce917b960b17d54e4
https://github.com/sgl-project/sglang/commit/4a9537a495fd6425a3c3c10ce917b960b17d54e4
ci: migrate Mamba/Layers tests to test/registered/layers/mamba/ (#16419)
**🎯 变更类型**：重构 / CI 配置  
**⚡ 重要程度**：🟢 低  
**📋 变更摘要**：将原本位于 `layers/attention/mamba/` 的四个 Mamba 相关单元测试迁移至 `test/registered/layers/mamba/`，并在每个文件开头加入 `register_cuda_ci` 进行 CI 注册，声明估算运行时长与所属套件。相应地，在 `test/srt/run_suite.py` 中删除了对旧路径的硬编码引用。  

**🎯 影响范围**：  
- 测试子系统（`test/registered/...`、`test/srt/run_suite.py`）  
- CI 流水线的测试调度与资源分配  

**🔍 技术洞察**：  
- **架构影响**：仅涉及测试组织结构的调整，未触及业务代码或模型实现。通过统一的 `register_cuda_ci` 接口，使 CI 调度更具可配置性，提升测试注册的可维护性。  
- **性能影响**：无业务代码变动，性能不受影响。CI 注册的 `est_time` 参数帮助调度器更好地分配 GPU 资源，可能间接提升整体测试执行效率。  
- **安全考虑**：变更仅在测试目录，未引入新的依赖或代码执行路径，安全风险基本为零。  

**⚠️ 潜在风险**：  
1. **路径依赖破坏**：如果项目中已有脚本、文档或第三方工具硬编码了旧的测试路径（如 `layers/attention/mamba/...`），迁移后可能导致找不到测试文件。  
2. **CI 注册漏失**：`register_cuda_ci` 调用若写错参数名或忘记导入，会导致该测试在 CI 中不被执行，影响覆盖率。  
3. **同步遗漏**：`run_suite.py` 已删除旧条目，但若还有其他入口（如自定义 CI 脚本）仍引用旧路径，可能出现 “文件不存在” 错误。  

**💡 关注建议**：  
- **回归测试**：在本地和 CI 环境运行一次完整的 `stage-b-test` 套件，确认新路径下的四个测试均被成功发现并执行。  
- **文档更新**：搜索项目中的 `layers/attention/mamba/` 字符串，确保所有相关文档或脚本同步更新为新路径。  
- **CI 配置检查**：确认 `sglang.test.ci.ci_register.register_cuda_ci` 的实现能够正确解析 `est_time` 与 `suite`，并在 CI 系统中注册相应的测试。  
- **监控运行时**：首轮 CI 运行后，观察实际耗时是否与 `est_time` 接近，必要时微调以优化调度。  

总体而言，此次提交是一次低风险的测试组织和 CI 注册改动，主要提升了测试可维护性和 CI 调度的可预测性。只需确保所有旧路径引用已彻底迁移，即可安全合并。

### ca922d4b05adbcba4f2181cf49290c482078f540
https://github.com/sgl-project/sglang/commit/ca922d4b05adbcba4f2181cf49290c482078f540
[diffusion] feat: support warmup with resolutions (#16434)
**🎯 变更类型**：功能增强  
**⚡ 重要程度**：🟡中  
**📋 变更摘要**：  
- 新增 `--warmup` 与 `--warmup-resolutions` 参数，支持在服务器启动后或首个请求前进行多分辨率的预热（warm‑up）请求。  
- 实现预热请求的自动生成、调度、日志与计时控制，确保预热只跑 1 步推理并不影响正常请求的计时统计。  

**🎯 影响范围**：  
- `python/sglang/multimodal_gen/runtime/entrypoints/diffusion_generator.py`  
- `python/sglang/multimodal_gen/runtime/managers/scheduler.py`  
- `python/sglang/multimodal_gen/runtime/pipelines_core/*`（包括 `composed_pipeline_base.py`, `executors/*`, `stages/*`）  
- `python/sglang/multimodal_gen/runtime/server_args.py`  
- `python/sglang/multimodal_gen/runtime/utils/perf_logger.py`  
- `python/sglang/multimodal_gen/runtime/pipelines_core/schedule_batch.py`  

**🔍 技术洞察**  

- **架构影响**：  
  - 在 `Scheduler` 初始化阶段即生成一批预热 `Req`（根据 `warmup_resolutions`），而不再依赖第一次真实请求触发的 **req‑based warmup**。  
  - 引入 `self.warmed_up` 标记，防止重复预热；调度路径中加入 `process_received_reqs_with_req_based_warmup` 兼容旧行为。  
  - 多处 `StageProfiler`（`Timer`）新增 `log_stage_start_end` 参数，使得预热请求可以关闭每阶段的开始/结束日志，降低噪声。  

- **性能影响**：  
  - **正面**：预热可以提前激活 CUDA kernels、缓存模型权重、触发 `torch.compile`（如开启），从而显著降低第一次真实推理的延迟。  
  - **负面**：服务器启动时会额外执行 `len(warmup_resolutions)` 次 1‑step 推理，导致启动时间线性增长（每个分辨率一次）。  
  - 通过 `Req.num_inference_steps = 1` 限制预热成本；对 `timesteps` 做 NaN 兜底，避免异常。  

- **安全考虑**：  
  - 变更仅涉及内部调度与日志，不引入外部输入的安全风险。  
  - 唯一注意点是 `warmup_resolutions` 解析函数 `_parse_size` 若未做好异常处理，可能导致服务器因非法分辨率字符串崩溃。  

**⚠️ 潜在风险**  

1. **默认 Seed 变更**：`ScheduleBatch.Req.seed` 从 `None` 改为 `42`，若调用方未显式指定 `seed`，所有非预热请求将默认使用 42，可能影响实验可重复性。  
2. **解析错误**：`_parse_size` 的实现未在本次提交中展示，若解析不严格（例如 `"256x"`）会抛异常，导致服务启动失败。  
3. **兼容性**：老版本脚本仍使用 `--enable-warmup` 参数，已被移除；未同步文档或 CI 脚本会导致启动失败。  
4. **日志抑制**：预热请求的阶段日志被默认关闭，若调试阶段出现异常，日志信息可能不足。  

**💡 关注建议**  

- **测试**  
  - 按不同分辨率组合（单分辨率、多分辨率、非法格式）启动服务器，验证预热请求是否成功插入并在日志中体现。  
  - 验证 `seed` 的默认值改动对非预热请求的影响，必要时在 `ServerArgs.__post_init__` 中恢复 `None` 并在预热路径单独设 `seed=42`。  
  - 对开启 `--warmup` 而不提供 `--warmup-resolutions` 的情形，确认会走 “req‑based warmup” 分支且不会导致两次预热。  

- **升级注意**  
  - 替换旧的 `--enable-warmup` 为 `--warmup`，并根据需求添加 `--warmup-resolutions`。  
  - 如使用自定义脚本解析命令行，确保兼容新参数签名。  

- **代码审查**  
  - 为 `_parse_size` 添加异常捕获与友好错误提示，防止启动因用户输入错误而崩溃。  
  - 如需保持原始 `seed=None` 行为，可在 `Req.__post_init__` 中仅在 `self.is_warmup` 为真时设置 `self.seed = 42`，避免影响常规请求。  

- **运营**  
  - 在部署说明中明确 warm‑up 将延长启动时间，并提供推荐的分辨率列表，以避免因分辨率过大导致显著启动延迟。  

---  

*总体而言，此次改动为 SGLang Diffusion 引入了更灵活、可配置的预热机制，对首次推理延迟的降低有明显正向效果。但需要注意默认种子改动、参数兼容性以及分辨率解析的鲁棒性，建议在正式生产环境启用前完成上述回归与边界测试。*

### 402a0bd6dcbc1fde405a5e257d63421ac07ce739
https://github.com/sgl-project/sglang/commit/402a0bd6dcbc1fde405a5e257d63421ac07ce739
[model-gateway] Add model scope support and LRU eviction for GPU-constrained environments (#16525)
**🎯 变更类型**：功能增强、性能优化、重构、测试、文档、依赖更新  

**⚡ 重要程度**：🟡中  

**📋 变更摘要**  
1. 为模型池引入 **model scope（session / class）** 并在 GPU 受限的环境下实现 **LRU（最近最少使用）驱逐**，让大模型可以按需在测试类级别启动/淘汰。  
2. 新增 **Gateway** 类，统一管理 sgl‑model‑gateway 路由进程（regular、PD、IGW 三种模式），替代原先散落在 `conftest.py` 中的 `launch_local_router`/`launch_pd_router` 函数。  
3. 扩展 pytest Marker 与 fixture：`@pytest.mark.model(name, scope="session|class")`、`@pytest.mark.workers(count=…, prefill=…, decode=…)`、`@pytest.mark.gateway(policy=…, timeout=…, extra_args=…)`。  
4. 新增针对 Gateway **Worker API** 的端到端测试以及 IGW（空网关）模式的测试。  
5. 细节改动：GPUAllocator 增加 `release_slot`、`available_gpus`；ModelPool 增加 LRU 驱逐、类作用域模型注册、健康检查优化；`conftest.py`、`setup_backend`、`backend_router` 等 fixture 均改为返回 `gateway` 实例；若干文档、日志、异常信息的补充。

---

### 🎯 影响范围
- **sgl-model-gateway/e2e_test/**  
  - `conftest.py`、`infra/`（`gateway.py`、`model_pool.py`、`gpu_allocator.py`、`__init__.py`）  
  - 所有基于 `setup_backend` / `backend_router` 的 E2E 测试  
  - 新增 `router/test_worker_api.py`、IGW 相关测试  
- **模型池与路由层**：所有依赖 `ModelPool.get()`、`ModelPool.startup()` 的内部或外部代码。  
- **CI / 测试运行环境**：GPU 资源分配逻辑被重新定义，尤其在 GPU 数量少于模型需求时会触发 LRU 驱逐。

---

### 🔍 技术洞察

| 维度 | 影响 |
|------|------|
| **架构影响** | <ul><li>新增 `Gateway` 抽象，统一封装 router 启动、健康检查、Worker 管理等职责，降低 `conftest.py` 中的重复代码。</li><li>模型作用域（session / class）引入模型生命周期管理，新概念在 `ModelPool` 中实现。</li><li>LRU 驱逐使模型池从“一次性预加载全部”转向“按需调度 + 资源回收”，提升在 GPU‑受限机器上的可用性。</li></ul> |
| **性能影响** | <ul><li>启动时仅预加载 `session` 模型，能显著缩短测试初始化时间（尤其模型数量多、GPU 少时）。</li><li>驱逐/重新加载模型会产生额外的模型加载开销，测试中若频繁切换 `class` 模型可能导致 **额外的数十秒延迟**。</li><li>`_wait_all_healthy` 只对未标记健康的实例检查，避免重复健康轮询，略微提升启动速度。</li></ul> |
| **安全考虑** | <ul><li>新增 API（/workers、/add_worker、/remove_worker）通过 HTTP 调用，若在生产环境误用可能导致未授权的 worker 增删。当前实现仅在测试环境使用，未加入鉴权，建议在正式部署时加入访问控制。</li><li>`Gateway.start()` 对参数做了模式互斥校验，防止错误组合导致未定义行为。</li></ul> |
| **可维护性** | <ul><li>`Gateway` 将路由进程管理集中到单文件，代码结构更清晰，利于后续功能扩展（如动态 scaling、metrics 导出）。</li><li>`ModelPool` 新增了大量状态字段（`scope`、`last_used`、`_healthy`），增加了类的复杂度，需要保持字段同步（如在 `terminate()`、`release_slot` 中）。</li></ul> |

---

### ⚠️ 潜在风险

1. **GPU 资源竞争**  
   - 当多个 `class` 模型并发请求时，LRU 驱逐可能频繁触发，导致模型反复加载/卸载，增加测试不确定性。  
   - 如果 `self._queued_models` 与实际 GPU 使用不一致（如释放槽位失败），可能出现 **“找不到可用 GPU”** 的 RuntimeError。

2. **模型健康状态**  
   - `_healthy` 标记只在第一次健康检查成功后置位，若 worker 在后续运行中崩溃（例如 OOM），`ModelPool.get()` 仍会返回实例并报 **RuntimeError**，但之前的 `last_used` 未更新，可能导致错误的 LRU 排序。

3. **API 兼容性**  
   - 原有 `launch_local_router` / `launch_pd_router` 被删除，外部脚本或自定义测试如果仍引用这些函数会报 ImportError。  
   - 新的 marker 参数（`scope`、`workers(count=…)`、`gateway(...)`）如果未在测试中显式指定，默认行为仍兼容，但误写会导致不期望的模型调度。

4. **循环依赖风险**  
   - `infra/__init__.py` 现在导入 `Gateway`，而 `gateway.py` 通过相对导入 `..process_utils` 等。若其他子模块再导入 `infra`，可能出现 **间接循环依赖**（目前未显现，但未来新增模块需注意）。

5. **CI 环境差异**  
   - 需要确认 CI runner 的 GPU 配置（数量、显存）足以支撑 `session` 模型的预加载；若 CI 只提供 1‑2 块 GPU，所有模型都会进入 `class` 范畴，导致大量 LRU 驱逐，测试时长可能显著上升。

---

### 💡 关注建议

| 目标 | 建议 |
|------|------|
| **测试可靠性** | <ul><li>在 CI 中显式设置 `MODEL_GATHERED="session"`（或通过 `pytest.mark.model(..., scope="session")`）对关键模型进行预加载，避免频繁驱逐。</li><li>为 `class` 模型的加载/驱逐路径增加 **日志级别 INFO**，便于定位因资源不足导致的延迟。</li></ul> |
| **GPU 资源监控** | <ul><li>利用 `GPUAllocator.available_gpus()` 在测试前后打印 GPU 分配状态，帮助检测泄漏或未释放的槽位。</li><li>考虑在 `ModelPool._evict_instance` 中加入 **延迟回收**（如 30 s）避免同一模型被频繁驱逐后立即重新加载。</li></ul> |
| **安全/生产化** | <ul><li>在正式部署时为 `Gateway` 的管理 API 加入鉴权（Bearer Token、OAuth）或仅在 `--dev` 模式下开启。</li><li>限制 `Gateway.add_worker` 的来源 IP，防止恶意注入不受信任的 worker。</li></ul> |
| **文档/使用指南** | <ul><li>在 `README` 或 `docs` 中补充 **model scope 与 LRU 驱逐** 的概念解释与最佳实践（如 “默认使用 session”，大型模型建议使用 class”。</li><li>示例代码中展示如何在 `

### 76c71d1d34f956ce5a673f5e72f6919d8cc8783d
https://github.com/sgl-project/sglang/commit/76c71d1d34f956ce5a673f5e72f6919d8cc8783d
fix: unimplemented methods in BaseIndexerMetadata (#16520)
**🎯 变更类型**：Bug修复 / 功能增强  
**⚡ 重要程度**：🟡 中  
**📋 变更摘要**：  
- 为 `BaseIndexerMetadata` 补全了之前未实现的 `get_indexer_kvcache_range`、`get_indexer_seq_len_cpu` 与 `get_token_to_batch_idx` 三个方法，实现了 kv‑cache 范围、CPU 上的序列长度及 token‑to‑batch 映射的返回逻辑。  
- 同时在 `topk_transform` 接口中加入了 `cu_seqlens_q`、`ke_offset`、`batch_idx_list`、`topk_indices_offset_override` 四个可选参数，为后续的 Top‑K 计算提供更多上下文信息。  

**🎯 影响范围**：  
- `test/registered/kernels/test_nsa_indexer.py`（新增测试/使用这些方法）  
- 任何依赖 `BaseIndexerMetadata` 的索引器实现或调度器（如 `nsa_indexer`、`triton`、`cuda` 实现等）  

**🔍 技术洞察**：  
- **架构影响**：  
  - 为 `BaseIndexerMetadata` 注入了完整的索引元信息查询能力，使其能够独立提供 kv‑cache 边界、序列长度与 batch‑token 映射，提升了模块的自洽性，降低了上层代码对外部协助的依赖。  
  - `topk_transform` 参数扩展保持向后兼容（默认 `None`），但为后续实现更高效的 Top‑K 逻辑（如基于 cu‑seq‑lens、偏移量的算子）奠定了接口基础。  

- **性能影响**：  
  - 新增方法均为一次性 `torch` 张量构造与拼接，时间复杂度 O(total_tokens)，空间复杂度同样 O(total_tokens)。对常规批次大小影响可忽略。  
  - `topk_transform` 参数本身不引入额外计算，仅在需要时由调用方自行利用；因此对现有路径的性能无负面影响。  

- **安全考虑**：  
  - 无直接安全风险。所有张量操作均在受控的设备（CPU/GPU）上完成，未涉及外部输入的解析或权限检查。  

**⚠️ 潜在风险**：  
- **接口兼容性**：虽然新参数设为可选，但若内部实现后来假设这些参数必定非空，未在所有调用点做好 Guard，可能导致运行时 `NoneType` 错误。  
- **行为变更**：`get_indexer_kvcache_range` 的实现方式（每个 token 的 `k_start` 固定为当前序列的起始偏移）与旧的未实现状态不同，若有自定义实现依赖旧的“未实现”异常，可能产生逻辑差异。  
- **测试覆盖**：目前只在单元测试文件中新增了使用示例，若项目中其他模块未覆盖这些方法，潜在的逻辑错误可能未被捕获。  

**💡 关注建议**：  
1. **回归测试**：在完整的 CI 流程中加入对 `BaseIndexerMetadata` 所有新方法的单元测试，尤其是多批次、不同序列长度的组合情况。  
2. **调用方审查**：检查项目中所有调用 `topk_transform` 的位置，确认未对新增参数做强制假设；必要时在调用处添加显式的 `None` 检查或默认值。  
3. **性能基准**：对大批量（如数万 token）进行基准测试，确保新增张量拼接不会导致显著的 GPU/CPU 内存峰值。  
4. **文档更新**：在 `BaseIndexerMetadata` 的接口文档中说明新方法的语义、返回形状以及 `topk_transform` 的新增参数用途，防止未来误用。  

通过上述检查与验证，可在保持现有功能稳定的前提下，安全地将这些实现投入生产环境。

### 2d02c150dc6632d188e395963620e44aea5b555e
https://github.com/sgl-project/sglang/commit/2d02c150dc6632d188e395963620e44aea5b555e
[3/N][Sparse With Hicache]: Init sparse coordinator (#16086)

Co-authored-by: 晟海 <huangtingwei.htw@antgroup.com>
Co-authored-by: Zhiqiang Xie <xiezhq@stanford.edu>
**🎯 变更类型**：功能增强、重构、配置、依赖更新  
**⚡ 重要程度**：🟡 中  

**📋 变更摘要**  
1. 新增 **hierarchical sparse attention**（层级稀疏注意力）框架：包括 `SparseCoordinator`、算法工厂、后端适配器（FlashAttention、NSA）以及统一的 `__init__` 接口。  
2. 在 `ServerArgs` 中加入 `hierarchical_sparse_attention_extra_config` 参数，并完成 CLI 参数解析。  
3. 调整已有稀疏算法实现以使用 `sparsity_ratio` 而非旧的 `compression_ratio`，并对 `BaseSparseAlgorithmImpl` 相关逻辑进行适配。  

**🎯 影响范围**  
- `python/sglang/srt/mem_cache/sparsity/`（全新子模块）  
- `python/sglang/srt/server_args.py`（配置结构与 CLI）  
- `python/sglang/srt/mem_cache/sparsity/algorithms/base_algorithm.py`（算法参数）  
- 相关的注意力层（`RadixAttention`）在运行时将通过 `SparseCoordinator` 调用新接口（间接影响）。  

**🔍 技术洞察**  

- **架构影响**  
  - 引入 **Coordinator‑Factory‑Adaptor** 三层架构：  
    - `SparseCoordinator` 负责生命周期管理（请求注册、稀疏检索、元数据适配、KVCache offloading 等）。  
    - `factory.py` 实现统一的创建入口，支持多种稀疏算法（Quest、DeepSeekNSA）和后端适配器（FlashAttention、NSA）。  
    - `backend_adaptor` 抽象不同注意力实现的元数据修改方式，保持上层算法与底层实现解耦。  
  - 通过全局单例 (`_global_sparse_coordinator`) 供运行时查询，使得其他模块无需显式传递对象。  
  - 配置统一为 `SparseConfig`，支持 **层级化、可扩展** 的额外字段（algorithm‑specific）。  

- **性能影响**  
  - 目标是 **解码阶段 KVCache 压缩**，理论上可显著降低显存占用，提升长序列推理吞吐。  
  - 实际性能取决于算法实现（Quest/DeepSeekNSA）以及后端适配器的实现效率；当前 `FlashAttentionAdaptor` 仅实现了元数据拷贝与简单的页面映射，仍有 **TODO: Optimize performance**。  
  - 引入稀疏比例 `sparsity_ratio`（默认 0.7），影响 Top‑k 选取的规模，直接关联时间复杂度 O(N·k)。  

- **安全考虑**  
  - 新增的 JSON 配置字段（`hierarchical_sparse_attention_extra_config`）若被恶意构造，可能导致 **异常参数注入**（例如极端的 `sparsity_ratio` > 1 或负数），进而触发运行时错误或资源耗尽。  
  - 当前代码对 JSON 解析异常仅记录警告，未做严格校验，建议在生产环境加入 schema 校验。  

**⚠️ 潜在风险**  

| 风险点 | 说明 | 严重度 |
|--------|------|--------|
| 兼容性 | 新增的 `SparseCoordinator` 需要在模型执行路径中显式调用；如果未在所有注意力层挂钩，可能导致稀疏功能在部分模型上失效。 | 中 |
| 性能回归 | `FlashAttentionAdaptor` 的实现仍是初版，额外的 `copy_` 与 `where` 操作在大 batch 中可能引入额外的显存拷贝，导致性能下降。 | 中 |
| 配置错误 | `hierarchical_sparse_attention_extra_config` 解析失败时 `algorithm`、`backend`、`min_sparse_prompt_len` 可能未定义，导致运行时 `NameError`。 | 中 |
| 代码路径未覆盖 | `NSABackendAdaptor` 仍是 `TODO`，若选择 `deepseek_nsa` 后端会触发 `NotImplementedError`。 | 高 |
| 资源泄露 | `RequestTrackers` 中的状态未在 `forward_end`、`forward_begin` 完全实现，可能导致长期请求的 KVCache 页面未及时 offload。 | 低‑中 |

**💡 关注建议**  

1. **完善后端适配器实现**：  
   - 首先实现 `NSABackendAdaptor.adapt_for_attn_metadata`，或在默认配置中隐藏 `deepseek_nsa` 选项。  
   - 对 `FlashAttentionAdaptor` 进行性能 profiling，降低不必要的拷贝，考虑在 `torch.cuda.Stream` 上异步执行。  

2. **增加配置校验**：  
   - 使用 `jsonschema` 或手写校验函数，对必填字段（`algorithm`、`backend`）以及数值范围（`0 < sparsity_ratio <= 1`）进行检查。  
   - 在解析失败时抛出明确异常，而非默默使用未定义的局部变量。  

3. **单元/集成测试**：  
   - 为 `SparseCoordinator`、`Factory`、各 `BackendAdaptor` 编写覆盖率 ≥ 80% 的测试，覆盖 **注册 → 检索 → 元数据适配 → 释放** 全流程。  
   - 在不同模型（GPT‑NeoX、LLaMA）和不同层数范围（start_layer、end_layer）上跑端到端基准，验证显存占用与吞吐提升。  

4. **监控与回滚**：  
   - 在服务启动时打印 `SparseConfig` 完整内容，方便排查配置错误。  
   - 若稀疏功能导致显著的 latency 回升，提供 `--disable-hierarchical-sparse-attention`（可在 `ServerArgs` 中加入）快速回滚。  

5. **文档**：  
   - 在官方 README/使用手册中补充 **hierarchical sparse attention** 的概念、配置示例以及已知限制（如仅支持 FlashAttention）。  

通过上述措施，可在保证功能可用性的前提下，降低新特性引入的风险，并最大化其在长上下文推理中的性能收益。

### b98bd9a5fb5f8fde4014c9f054d71c312c2c929a
https://github.com/sgl-project/sglang/commit/b98bd9a5fb5f8fde4014c9f054d71c312c2c929a
[model-gateway] Tighten visibility in modules and remove unused re-exports (#16524)
**🎯 变更类型**：功能增强 / 重构 / 可见性收敛  
**⚡ 重要程度**：🟡 中  
**📋 变更摘要**：本次提交主要收紧了 `sgl-model-gateway` 各模块的可见性，将大量 `pub` 项目改为 `pub(crate)`，删除或隐藏了未被使用的重新导出（re‑exports）以及废弃的内部工具函数。相应地更新了引用路径、测试代码和内部实现，以保持库内部能够正常编译。目标是降低库的公共 API 表面，防止误用并简化未来的内部演进。

**🎯 影响范围**  
- `sgl-model-gateway` 核心模块：`app_context`, `auth`, `config`, `core`, `mcp`, `observability`, `tokenizer`, `tool_parser`  
- 直接使用这些模块的外部项目（尤其是依赖 `smg`/`sgl-model-gateway` 的二方库）  

---

### 🔍 技术洞察

| 维度 | 影响分析 |
|------|----------|
| **架构影响** | - 将原本向外公开的类型（如 `JwtProvider`, `StandardClaims`, `Audience`, `JwksProvider`, `ConfigValidator`, 多数 `core` 的 re‑export）收敛为 `pub(crate)`，从而**封装**了内部实现。<br>- 移除 `worker::WorkerFactory`、`urls_to_workers` / `workers_to_urls` 等工厂函数，使得创建 Worker 的唯一入口变为 `BasicWorkerBuilder` / `DPAwareWorkerBuilder`。<br>- 通过重新组织 `core/mod.rs` 的导出列表，降低模块间耦合度；外部只能通过 `core::worker`、`core::model_card` 等受控入口访问。 |
| **性能影响** | - 纯粹的可见性修改，对运行时性能几乎没有直接影响。<br>- 移除未使用的 `try_reduce`（从 `pub` 变为私有）以及内部 `intern_string`、`interner_size` 的可见性收紧，**不影响**已有调用路径。 |
| **安全考虑** | - 收紧 `validate_url`、`JwksProvider`、`JwtValidator` 等安全关键组件的可见性，防止外部直接调用未经过内部统一检查的 API，间接提升安全性。<br>- 代码本身未引入新的安全风险。 |
| **可维护性** | - 通过隐藏实现细节，后续内部改动可以不破坏公共合约，提升库的演进空间。<br>- 删除冗余模块（`tool_parser/state.rs`、`partial_json` 中的工具函数）降低维护负担。<br>- 重新导出路径的整理使得 IDE 自动补全更清晰，减少误用。 |

---

### ⚠️ 潜在风险

1. **向后兼容性**  
   - 任何直接引用已改为 `pub(crate)` 的类型或函数的外部项目（包括内部测试工具、二方插件）将在编译时出现 **未找到符号** 错误。  
   - 公开的 `pub` 常量、结构体字段以及 `pub fn`（如 `JwtValidator::new`、`JwksProvider::new`、`ConfigValidator::validate`）已被限制，可导致升级破坏。  

2. **内部测试泄露**  
   - 部分单元测试仍使用已删除的函数（如 `WorkerFactory::create_dp_aware`、`urls_to_workers`），如果这些测试被外部 CI 引入，会出现编译错误。  

3. **模块路径变更**  
   - 例如 `core::worker_service` 中的 `worker_to_info` 现在通过 `core::worker::worker_to_info` 引入，若外部代码使用旧路径，需要同步改动。  

4. **文档/示例同步**  
   - 任何文档、README 或示例代码中仍然展示已收敛的公共 API，将导致用户在升级后遇到示例编译失败。  

---

### 💡 关注建议

| 项目 | 建议 |
|------|------|
| **升级指引** | - 在发布日志中明确列出 **破坏性 API**（如 `JwtValidator::new`、`ConfigValidator::validate`、`WorkerFactory` 等）已改为 `pub(crate)`。<br>- 提供迁移指南：使用 `BasicWorkerBuilder`/`DPAwareWorkerBuilder` 直接创建 `Worker`；通过 `RouterConfig::validate()` 替代 `ConfigValidator::validate(&config)`。 |
| **兼容层** | - 若需要保持向后兼容（例如已有客户使用这些 API），可在 `src/compat.rs` 中添加 *桥接* `pub` 包装函数，内部调用相同实现，并在下一次 major 版本中去除。 |
| **测试** | - 更新所有内部单元测试，移除对已删除/收敛 API 的调用。<br>- 增加 **可见性回归测试**：确保 `pub(crate)` 项目不意外泄漏为 `pub`（可以使用 `cargo udeps` 或 `cargo-public-api` 检查）。 |
| **文档** | - 检查并同步所有公开文档、示例、README，删除或改写涉及已收敛 API 的章节。 |
| **持续集成** | - 在 CI 中加入 `cargo-public-api` 检查，防止误将内部实现再次误标记为 `pub`。 |
| **安全审计** | - 复审 `validate_url`、`JwtValidator`、`JwksProvider` 的使用链，确保所有入口均经过内部统一的 URL/HTTPS 检查。 |
| **代码风格** | - 对于大量 `#[allow(dead_code)]` 标记的函数（如 `try_reduce`、`interner_size`），若未来确认不再使用，可考虑直接删除，进一步降低维护成本。 |

---

**结论**  
此次提交通过**收紧可见性**、**删除未使用的重新导出**以及 **去除废弃工具函数**，显著提升了库的内部封装度，为后续的架构演进提供了更安全的基础。唯一需要重点关注的是 **破坏性 API 的向后兼容**——外部项目在升级时必须同步代码路径和构造函数的使用方式。只要按照上述迁移建议进行适配，风险可控，长期可维护性将得到明显改善。

### ce694b2b9e0ab07aaffdd777d3370e096ed8b0f3
https://github.com/sgl-project/sglang/commit/ce694b2b9e0ab07aaffdd777d3370e096ed8b0f3
Fix the problem where Qwen3VL raises an "object has no attribute 'mod… (#15677)
**🎯 变更类型**：Bug修复  

**⚡ 重要程度**：🟡 中  

**📋 变更摘要**：  
在 `python/sglang/srt/models/qwen3_vl.py` 的 `load_weights` 方法中新增了 `hasattr(self, "model")` 检查，用于避免在 `self` 未创建 `model` 属性时直接访问 `self.model.start_layer` 导致的 `AttributeError`。此改动解决了 Qwen3VL 在特定路径下抛出 “object has no attribute 'mod…​” 的异常，提升了模型加载的鲁棒性。

**🎯 影响范围**：  
- `sglang/srt/models/qwen3_vl.py`（Qwen3VL 模型加载逻辑）  
- 依赖此模型的上层调用（如推理入口、模型管理器）  

**🔍 技术洞察**：  
- **架构影响**：无结构性改动，仅在权重加载流程中加入防御式检查，保持原有模块划分不变。  
- **性能影响**：额外的 `hasattr` 检查成本极低（O(1)），对整体加载时延几乎可以忽略不计。  
- **安全考虑**：未涉及安全功能或外部输入，新增检查只会防止异常崩溃，降低了潜在的拒绝服务风险。  

**⚠️ 潜在风险**：  
- 若在某些场景下 `self.model` 本应始终存在，但由于其他 bug 失效，新增的防护会导致对应层的权重被静默跳过，可能导致模型功能缺失或精度下降。  
- 代码路径中仍然使用 `self.model.start_layer`，若后续对 `self.model` 的属性检查不完整，可能再次触发属性错误。  

**💡 关注建议**：  
1. **回归测试**：在包含 `self.model` 与不包含 `self.model` 两种情况的环境下，分别验证权重加载是否完整，确保模型功能不受影响。  
2. **日志/警告**：建议在条件不满足时添加调试日志或警告（如 `logger.warning("self.model missing, skipping start_layer check")`），便于后续排查是否出现异常的模型实例化。  
3. **文档更新**：在模型加载说明中补充 “在模型实例化前调用 `load_weights` 可能导致部分权重被跳过” 的提示。  
4. **持续监控**：观察上线后是否出现因权重未加载导致的推理异常或性能下降的报告。  

---

### 6c0fb189f845707f1c7799c6ae48da437580b16b
https://github.com/sgl-project/sglang/commit/6c0fb189f845707f1c7799c6ae48da437580b16b
[Auto Sync] Update tokenizer_manager.py (20260105) (#16477)

Co-authored-by: github-actions[bot] <github-actions[bot]@users.noreply.github.com>
Co-authored-by: Wangfan Fu <wangfan@x.ai>
**🎯 变更类型**：Bug修复 / 轻量重构  
**⚡ 重要程度**：🟡 中  

**📋 变更摘要**  
在 `tokenizer_manager.py` 的 `convert_logprob_style` 方法中，为 `input_token_logprobs_val` 的扩展操作加入了空值检查。此前仅判断列表非空，但在某些索引处可能为 `None`，导致在 `extend` 时抛出异常。此改动通过在扩展前确认 `recv_obj.input_token_logprobs_val[recv_obj_index]` 不为 `None`，提升了代码的健壮性。

**🎯 影响范围**  
- `python/sglang/srt/managers/tokenizer_manager.py`（Tokenizer 管理器）  
- 依赖该管理器的推理路径及日志概率统计功能（如 SRT 推理服务、日志概率转换等）  

**🔍 技术洞察**  
- **架构影响**：无架构层面的改变，仅在同一模块内部加入防护逻辑，保持了原有模块划分和接口不变。  
- **性能影响**：新增的 `and recv_obj.input_token_logprobs_val[recv_obj_index] is not None` 检查是 O(1) 的常量时间，几乎不影响整体性能。  
- **安全考虑**：不涉及安全功能，但通过避免因异常导致的服务崩溃，间接提升了系统的可用性和稳健性。  

**⚠️ 潜在风险**  
- 若上层逻辑本意是即使某些位置为 `None` 也应保留空列表，当前改动会直接跳过扩展，可能导致后续统计结果与预期不符（例如缺失某些 token 的概率信息）。  
- 代码路径未覆盖 `recv_obj.input_token_logprobs_val` 为 `None` 的整体情况，需确保外层已有相应的空值保护。  

**💡 关注建议**  
1. **回归测试**：针对包含 `None` 元素的 `input_token_logprobs_val` 列表执行单元/集成测试，确认结果仍符合业务预期。  
2. **日志记录**：若业务需要追踪被跳过的 `None` 条目，考虑在条件分支内添加调试日志，以便后续分析数据缺失根因。  
3. **文档更新**：在相关 API 文档中注明 `input_token_logprobs_val` 中的 `None` 将被安全跳过，避免开发者误以为全部会被处理。  
4. **持续监控**：在生产环境监控异常率及日志概率相关指标，确保此改动未引入意外的统计偏差。  

### 9a9f996f8de7bc51a007ad3d79dc4b0a03b9a9d4
https://github.com/sgl-project/sglang/commit/9a9f996f8de7bc51a007ad3d79dc4b0a03b9a9d4
[FP8] Fix weight_scale shape to match with x_scale shape for per-tensor quant under torch.compile (#16356)
**🎯 变更类型**：Bug修复  

**⚡ 重要程度**：🟡 中  

**📋 变更摘要**：  
- 修正了在 `torch.compile` 环境下，`_scaled_mm` 对 `weight_scale` 与 `x_scale` 形状的要求不匹配的问题。  
- 当权重量化尺度为标量 (`ndim == 0`) 而激活尺度为向量 (`ndim == 1`) 时，自动在权重尺度前维度上 `unsqueeze(0)`，确保两者维度一致。  
- 该改动仅影响 FP8 线性层的融合 GEMM+Dequant 实现，提升了在 TorchScript 编译模式下的正确性。  

**🎯 影响范围**：  
- `python/sglang/srt/layers/quantization/fp8_utils.py` 中的 `apply_fp8_linear`  
- 依赖该函数的所有 FP8 量化模型（尤其在使用 `torch.compile` 的推理路径）  

**🔍 技术洞察**：  
- **架构影响**：  
  - 只在量化工具层进行局部修正，不影响整体模块划分或接口。  
  - 通过在运行时动态调整 `weight_scale` 形状，保持了与已有 API（标量或向量）兼容。  

- **性能影响**：  
  - `unsqueeze` 为常数时间操作，开销可以忽略不计。  
  - 解决了因形状不匹配导致的编译错误，间接提升了使用 `torch.compile` 时的启动与执行成功率。  

- **安全考虑**：  
  - 无涉及安全敏感的逻辑或外部输入处理，风险极低。  
  - 只改变内部张量形状，不会泄露或篡改数据。  

**⚠️ 潜在风险**：  
- 该兼容性处理假设仅在 **per‑tensor weight** 与 **per‑tensor activation** 同时开启时出现。如果未来出现 `weight_scale` 为标量而 `x_scale` 为标量（两者均 0‑维），该分支不会触发，仍保持原始行为，理论上无影响。  
- 可能对已有依赖 `weight_scale` 为标量且期望保持标量属性的外部代码产生细微行为差异（如 `weight_scale.shape` 检查），需确认无此类检查。  

**💡 关注建议**：  
1. **新增单元测试**：覆盖以下组合  
   - `per_tensor_weights=True`, `per_tensor_activations=True` 且 `weight_scale` 为标量、`x_scale` 为向量。  
   - 使用 `torch.compile` 编译模型，确保不再抛出 shape mismatch 异常。  
2. **回归验证**：在未使用 `torch.compile` 的路径下运行已有 FP8 量化模型，确认功能保持不变。  
3. **文档说明**：在 `fp8_utils.py` 或相应 API 文档中注明 `torch.compile` 对 `weight_scale`/`x_scale` 维度的要求，以及本实现的自动维度对齐行为。  
4. **兼容性检查**：如果项目中有手动检查 `weight_scale.ndim` 的代码，建议同步更新或通过 `torch.squeeze` 恢复原始标量形状，以防出现意外的维度泄露。  

### 4221b7c573904486290fc3bc3b4268838cc1f859
https://github.com/sgl-project/sglang/commit/4221b7c573904486290fc3bc3b4268838cc1f859
[model-gateway] refactor e2e test infrastructure and add router CI (#16513)
**🎯 变更类型**：重构 / 功能增强 / 配置 / 依赖更新  

**⚡ 重要程度**：🔴高  

**📋 变更摘要**  
- 在 GitHub Actions 中新增 `router-e2e-tests` job，统一在 GPU‑A10 实例上运行完整的 Router 端到端（e2e）测试并在 PR 中自动触发。  
- 大幅重构 **sgl‑model‑gateway/e2e_test** 目录：  
  - 替换原有的本地 Mock‑Worker、证书生成脚本以及冗余的后端实现，统一使用 **ModelPool** 与 **GPUAllocator** 管理真实模型进程。  
  - 引入 **infra/constants.py**、**infra/process_utils.py**、**infra/run_eval.py** 等模块，提供统一的枚举、环境变量、进程控制及评估工具。  
  - 将后端启动抽象为 **launch_cloud_router** / **launch_local_router** / **launch_pd_workers**，实现 OpenAI、xAI、本地 HTTP/GRPC 与 PD（Prefill‑Decode）三种路由方式。  
  - 改进 **GPUAllocator**，记录已使用 GPU、支持多次调用的增量分配并提供释放接口。  
  - 新增 **router/test_mmlu.py** 与 **router/test_pd_mmlu.py** 两套基准评估，用 MMLU 数据集验证路由业务的正确性与性能（阈值 0.65）。  
- 更新 `pyproject.toml` 与 CI 脚本以使用新的依赖并关闭 pytest 的 live‑log 打印。  

**🎯 影响范围**  
- **CI/CD 流水线**：`.github/workflows/pr-test-rust.yml`（新增 job）。  
- **E2E 测试代码**：`sgl-model-gateway/e2e_test/*`（全部重构）。  
- **模型启动与资源管理**：`infra/gpu_allocator.py`、`infra/model_pool.py`、`infra/constants.py`、`infra/process_utils.py`。  
- **评估工具**：`infra/run_eval.py`、`infra/simple_eval_*`（新增）。  
- **项目依赖**：新增 `grpcio-health-checking`、`openai`、`httpx`、`pytest-rerunfailures`、`ruff`（可选）。  

**🔍 技术洞察**  

- **架构影响**  
  - 将原有的 “mock_worker + 手写后端配置” 替换为 **真正的模型进程 + 动态路由**，使测试环境更贴近生产部署。  
  - 引入 **ConnectionMode**、**WorkerType**、**Runtime** 枚举，统一后端标识，降低字符串拼写错误风险。  
  - **ModelPool** 现在除了管理模型进程，还承担 **PD disaggregation**（prefill/ decode） worker 的启动与资源分配，新增 `launch_pd_workers` 方法。  
  - **GPUAllocator** 现在持久化已使用 GPU 集合 (`_used_gpus`) 并提供 `release_gpus`，防止同一 GPU 被多次分配导致冲突。  
  - **router‑e2e‑tests** job 通过 `scripts/ci/ci_install_dependency.sh` 与 `ci_install_rust.sh` 保证依赖一致性，统一使用 `sccache` 加速 Rust 编译。  

- **性能影响**  
  - 启动真实模型进程（30‑60 s）仍是最长路径，但 **ModelPool** 会在会话级别复用进程，单个测试只需 **1‑2 s** 启动 Router，显著提升 CI 并发度。  
  - `launch_pd_workers` 利用 InfiniBand（若可用）并行预填/解码，理论上提升吞吐。CPU‑GPU 亲和性通过 `GPUAllocator` 控制，避免同 GPU 上出现过度竞争。  

- **安全考虑**  
  - 原先的自签证书生成脚本已删除，当前测试不再使用 mTLS，降低了证书管理的复杂度与潜在泄露风险。  
  - 对外暴露的 Router 与模型服务端口均限定在 `127.0.0.1`，且仅在 CI GPU 节点内部可达，安全风险仍低。  
  - 新增的 `process_utils.kill_process_tree` 在缺少 `psutil` 时回退到 `os.kill`，如运行环境未安装 `psutil`，仍能安全结束子进程。  

**⚠️ 潜在风险**  

| 风险点 | 说明 | 严重度 |
|--------|------|--------|
| **GPU 资源耗尽** | `GPUAllocator` 现在在多次 `startup` 调用时会累计已使用 GPU，若 CI 流水线未正确释放（如异常退出），后续作业可能找不到可用 GPU。 | 🟡中 |
| **PD 依赖缺失** | `launch_pd_workers` 依赖 `sgl_kernel`、`torch`、InfiniBand (`ibv_devinfo`)。缺少任意一项将导致 PD 测试被 `skip`，但也可能误报为通过。 | 🟡中 |
| **环境变量不一致** | 新增的环境变量（`E2E_BACKENDS`, `E2E_MODELS`, `SKIP_MODEL_POOL` 等）若在本地开发者机器未设置，可能导致与 CI 行为不一致。 | 🟡中 |
| **网络端口冲突** | 多个 Router 实例使用 `get_open_port()` 分配端口，理论上安全，但在极端并发时仍可能冲突导致启动失败。 | 🟡中 |
| **依赖升级冲突** | 新增 `grpcio-health-checking` 与 `openai` 可能与项目已有的旧版库产生冲突，尤其在本地环境中使用不同 `pip` 镜像时。 | 🟡中 |
| **测试超时** | `router-e2e-tests` 设定 `timeout-minutes: 45`，但部分模型（大模型）加载可能超过此时间，导致 CI 直接 kill。 | 🟡中 |

**💡 关注建议**  

1. **GPU 资源回收**  
   - 在 CI `finish` job 中确保所有子进程已 `kill_process_tree`，必要时在 `model_pool.shutdown()` 前调用 `gpu_allocator.release_gpus([...])`。  
   - 本地调试时使用 `SKIP_MODEL_POOL=1` 避免不必要的 GPU 分配。  

2. **PD 环境检查**  
   - 在本地或 CI 前置步骤中显式安装 `sgl_kernel`、`torch`（对应 CUDA 版本），并检查 `ibv_devinfo` 是否可用。  
   - 若 InfiniBand 不可用，PD 测试仍可以在 CPU‑GPU 直接通信，确认 `detect_ib_device()` 正确返回 `None`。  

3. **环境变量统一**  
   - 在项目根目录提供 `.env.example`，列出所有 `E2E_*` 变量的默认值，建议 CI 与本地统一使用 `dotenv` 加载。  
   - 添加 CI 步骤打印当前环境变量（除敏感 key 之外）帮助定位因缺失变量导致的跳过。  

4. **端口冲突防护**  
   - `get_open_port()` 已足够，但在极度并发（>100）时可以预留一定端口范围或使用 `socket.SO_REUSEADDR` 进行复用。  

5. **依赖锁定**  
   - 将新加入的库（`grpcio-health-checking`, `openai`, `httpx`）版本在 `requirements.txt` 中锁定，以防上游不兼容的突发更新。  

6. **CI 超时调整**  
   - 对于特别大的模型（如 `Meta-Llama‑3.1‑70B`) 可在 CI 中通过 `E2E_MODELS` 只跑轻量模型，或在 `.github/workflows/pr-test-rust.yml` 为 `router-e2e-tests` 添加 `continue-on-error: false` 并适当延长 `timeout-minutes`。  

7. **日志可观测性**  
   - 由于 `log_cli` 已关闭，建议在 `conftest.py` 中的 `_setup_logging()` 保持 `INFO` 级别，必要时在 CI 步骤中捕获 `stdout` 并上传为 artefact，方便定位 flaky 测试。  

8. **回归测试**  
   - 在本地运行 `pytest -m e2e -vv

### c371df2f25d9c9e8e6d54f57e21b661574cf1283
https://github.com/sgl-project/sglang/commit/c371df2f25d9c9e8e6d54f57e21b661574cf1283
[AMD] Fix CI and add retry logic for git clone timeout (#15663)

Co-authored-by: Bingxu Chen <bingxche@amd.com>
**🎯 变更类型**：CI/测试、配置  
**⚡ 重要程度**：🟡 中  
**📋 变更摘要**：  
1. 将 GitHub Actions 工作流中直接使用 `docker exec` 运行测试的方式改为通过统一的 `amd_ci_exec.sh` 脚本执行，提升可维护性。  
2. 在 `scripts/ci/amd_ci_install_dependency.sh` 中新增 `git_clone_with_retry` 函数，为克隆 `human-eval` 仓库增加最多 3 次重试及低速检测，解决 CI 因网络波动导致的超时失败。  

**🎯 影响范围**：  
- `.github/workflows/pr-test-amd.yml`（CI 工作流）  
- `scripts/ci/amd_ci_exec.sh`（间接受影响）  
- `scripts/ci/amd_ci_install_dependency.sh`（新增重试逻辑）  
- 依赖拉取阶段的 Docker 镜像与容器（`ci_sglang`）  

**🔍 技术洞察**：  
- **架构影响**：  
  - 将测试执行抽象为 `amd_ci_exec.sh`，统一入口，降低工作流脚本的重复代码，便于后续增删参数或统一环境变量。  
  - `git_clone_with_retry` 将克隆操作从容器内部迁移到宿主机后再 `docker cp`，改变了依赖获取的执行位置，但仍保持同一容器可访问。  

- **性能影响**：  
  - 正常情况下增加的函数调用和一次 `docker cp` 开销极小（毫秒级），但在网络不佳时通过重试避免了整个 CI 任务的提前失败，整体耗时可能略增（最多 2 次 5 s 重试 + 重克隆时间）。  
  - 使用 `http.lowSpeedLimit=1000` 与 `http.lowSpeedTime=30` 能提前结束慢速克隆，配合重试可提升成功率。  

- **安全考虑**：  
  - 仅使用公开仓库的 `https` 克隆，无新增凭证泄露风险。  
  - `rm -rf "$dest_dir"` 在目标目录不存在或被误指定时可能误删本地文件，建议确保路径仅限于 CI 临时目录。  
  - `docker cp` 将本地文件复制进容器，默认保持文件所有者为 root，若后续步骤对权限有要求需额外处理。  

**⚠️ 潜在风险**：  
1. **误删风险**：`git_clone_with_retry` 会在每次尝试前强制 `rm -rf` 目标目录，若调用时传入了错误路径可能导致本地重要文件被删除。  
2. **权限问题**：`docker cp` 复制文件后默认属于 root，后续 `pip install -e .` 可能因权限不足导致安装失败。  
3. **隐藏根本网络问题**：重试成功掩盖了网络不稳定的根本原因，长远来看可能影响其他依赖的拉取。  
4. **CI 时长增长**：在网络极差的情况下，最多会多消耗约 10 s + 重新克隆耗时，导致 CI 总时长略增。  

**💡 关注建议**：  
- **测试本地脚本**：在本地或干跑环境中多次执行 `git_clone_with_retry`，验证在网络超时、目标目录已存在等场景下的行为。  
- **路径校验**：在函数开头加入对 `dest_dir` 是否为预期的临时目录的检查，防止误删。  
- **权限处理**：若后续需要非 root 用户执行，添加 `docker exec ... chown` 或在 `docker cp` 时使用 `--chmod`（Docker 20.10+ 支持）确保文件权限可用。  
- **监控重试次数**：在 CI 报表中记录实际的克隆尝试次数，以便后续评估网络质量趋势。  
- **回滚方案**：如果新增脚本导致意外错误，保留原来的 `docker exec -w / ci_sglang git clone …` 命令注释行，以便快速回滚。  

整体来看，此次改动提升了 CI 对网络波动的容错能力，并通过统一执行脚本提升了工作流的可维护性，风险可通过上述建议进一步降低。

### 1751c75b5dd4839fbe7d17bc9e4f0ac1bb7ebd35
https://github.com/sgl-project/sglang/commit/1751c75b5dd4839fbe7d17bc9e4f0ac1bb7ebd35
[model-gateway] Tighten visibility across `data_connector` and `grpc` module (#16516)
**🎯 变更类型**：重构 / 可见性收紧  

**⚡ 重要程度**：🟡 中  

**📋 变更摘要**  
本次提交将 `sgl-model-gateway` 中大量 `pub` API 调整为 `pub(super)` 或 `pub(crate)`，并使用 `#[allow(dead_code)]` 标记未使用的结构体/字段。涉及 `data_connector`、`grpc`（包括 `common`、`responses`、`stages`、`harmony`、`regular`）等多个子模块，同时删除了部分对外暴露的辅助函数（如 `ProtoRequest::as_generate`/`as_embed`、`RequestContext::request` 等），以收紧模块内部可见性。

**🎯 影响范围**  
- `sgl-model-gateway/src/data_connector/*`  
- `sgl-model-gateway/src/routers/grpc/*`（包括 `common`、`harmony/*`、`regular/*`、`utils.rs`、`pipeline.rs`、`proto_wrapper.rs` 等）  
- 可能受影响的外部依赖：任何直接引用这些已降级为 `pub(crate)`/`pub(super)` 的结构体或函数的项目（如自定义插件、测试代码、文档生成脚本）。

---

### 🔍 技术洞察

| 维度 | 影响分析 |
|------|----------|
| **架构影响** | - 通过收紧可见性，明确了模块边界，防止跨模块直接依赖实现细节。<br>- `RequestContext`、`ProcessingState` 及其内部子结构从 `pub` 变为 `pub(crate)`，使得只有同一 crate 内的路由/管线实现可以直接访问，外部调用必须经过统一的入口（如 `RequestPipeline::execute`）。<br>- `ProtoRequest` 的辅助访问函数被移除，外部只能通过公共 `request_id` 方法获取 ID，提升抽象层次。 |
| **性能影响** | - 纯粹的可见性修改不改变运行时逻辑，性能基本不受影响。<br>- 添加的 `#[allow(dead_code)]` 防止编译器在 release 模式下进行未使用代码的优化警告，亦不影响执行速度。 |
| **安全考虑** | - 收紧可见性降低了意外或恶意代码直接访问内部存储结构（如 `MemoryStoreStats`、`NoOp*Storage`）的风险。<br>- 移除对外暴露的 `as_generate`/`as_embed` 减少了对内部 protobuf 结构的直接依赖，降低潜在的协议层误用。 |
| **兼容性** | - **向后兼容破坏**：所有在 crate 外部（包括其他内部子 Crate、插件、测试或文档）使用的已降级为 `pub(crate)`/`pub(super)` 的 API 将编译失败。<br>- 这属于 **重大版本（MAJOR）** 变更，建议在发布时提升版本号。 |

---

### ⚠️ 潜在风险

1. **编译错误**  
   - 外部 crate、内部示例或 CI 测试仍然引用被降级的符号（如 `parse_tool_calls`、`NoOpConversationStorage`、`RequestContext::request` 等），会导致直接编译失败。  
2. **运行时行为差异**  
   - 虽然逻辑保持不变，但某些调试/监控代码可能依赖已隐藏的字段（如 `ProcessingState.streaming`）进行统计，若未同步改动会导致运行时 `panic!`（访问不存在的字段）。  
3. **文档/发布错误**  
   - 自动生成的 API 文档（rustdoc）将不再展示这些内部项，若文档中仍引用，将产生链接失效。  
4. **插件/扩展点失效**  
   - 第三方插件如果实现了自定义 `ToolParser`/`ReasoningParser` 并直接使用 `RequestContext` 的内部结构进行控制，可能失去兼容性。  

---

### 💡 关注建议

| 目标 | 建议 |
|------|------|
| **代码迁移** | - 在本仓库内部运行 `cargo test --all`，定位所有因可见性收紧而产生的编译错误并修正为使用公开的入口（如通过 `RequestPipeline`、`ResponseContext` 的公共方法）。<br>- 对外提供一个兼容层（可选）：在 `src/api.rs` 中保留少量 `pub` wrapper 函数，内部调用对应的 `pub(crate)` 实现，以平滑升级。 |
| **版本管理** | - 将此提交划分为 **MAJOR** 版本（如 `v2.0.0`），在 `CHANGELOG` 中注明 “收紧模块可见性，破坏性 API 更改”。 |
| **文档同步** | - 更新 `README`、开发者手册以及自动化文档生成脚本，删除已不再公开的 API 列表。 |
| **测试覆盖** | - 增加针对 `RequestPipeline`、`GrpcRouter` 的集成测试，确保即使内部结构不可达，外部调用路径仍然完整。<br>- 对 `grpc/utils.rs` 中的 `resolve_tokenizer`、`get_grpc_client_from_worker` 等关键函数保持 `pub(crate)`，确保内部单元测试覆盖。 |
| **兼容性检查** | - 在 CI 中添加跨 crate 依赖检查，比如使用 `cargo semver-checks` 检测是否出现意外的破坏性更改；如果有下游仓库，需要提前通知并提供迁移指南。 |
| **性能验证** | - 虽然改动对性能影响微乎其微，但仍建议在关键路径（如 `RequestPipeline::execute_generate`）跑一次基准测试，以确认没有因编译优化差异引入回归。 |

**总体结论**  
此次提交通过收紧可见性显著提升了代码库的封装性和内部一致性，是一次健康的架构清理。但由于涉及大量 `pub` → `pub(crate)`/`pub(super)` 的降级，破坏性兼容性较高。务必在升级前完成全链路编译与测试，并在发布说明中明确迁移步骤。

### 23849eba7b964df6b2d8597b477e134307108bd0
https://github.com/sgl-project/sglang/commit/23849eba7b964df6b2d8597b477e134307108bd0
[model-gateway] fix tokenizer encode in golang bindings (#16482)
**🎯 变更类型**：Bug修复 / API兼容性调整  
**⚡ 重要程度**：🟡 中  
**📋 变更摘要**：  
1. 为 `sgl_tokenizer_encode` C 接口新增 `add_special_tokens` 布尔参数，以匹配底层 Rust `tokenizer.encode(text, add_special_tokens)` 的签名。  
2. 在 Go 绑定层的调用处统一传入 `false`，修正了之前因缺少该参数导致的错误行为。  
3. 新增 `libc` 依赖并在 macOS 与其它平台间使用不同的 C 类型 (`boolean_t` / `c_int`) 表示布尔值。  

**🎯 影响范围**：  
- `sgl-model-gateway/bindings/golang`（CFFI、Rust‑Golang 交互层）  
- `sgl-model-gateway/bindings/golang/src/client.rs`、`preprocessor.rs`、`tokenizer.rs`  
- 任何使用 Go 绑定的上层项目以及直接调用 C 接口的用户代码  

**🔍 技术洞察**  

- **架构影响**：  
  - 将原本隐式 `add_special_tokens = true` 的行为显式化，提升 API 的可预测性。  
  - 引入跨平台布尔类型抽象，使代码在 macOS 与 Linux/Windows 上编译一致，保持了现有模块划分（`TokenizerHandle` 仍保持不变）。  

- **性能影响**：  
  - 仅在函数入口多做一次布尔转换 (`add_special_tokens != 0`)；时间/空间复杂度保持不变，性能影响可忽略。  

- **安全考虑**：  
  - 新增布尔参数后，需要确保传入的值严格为 0/1，防止因未初始化的内存导致未定义行为。  
  - 使用 `libc` 提供的原始 C 类型可以避免跨平台整数宽度差异，引入的风险很小。  

**⚠️ 潜在风险**  

1. **API 向后不兼容**：原先的 C/Go 调用不再满足签名，编译将报错，需要使用者显式传入 `add_special_tokens` 参数。  
2. **平台差异**：macOS 使用 `libc::boolean_t`（signed char），其它平台使用 `c_int`；若调用方自行构造参数且未使用 `libc` 定义，可能出现类型不匹配。  
3. **绑定代码同步**：如果项目中还有未更新的内部调用（例如自定义 C 包装或第三方语言绑定），仍会因缺少参数而编译失败或运行错误。  

**💡 关注建议**  

- **升级指南**：在升级到新版本前，检查所有调用 `sgl_tokenizer_encode` 的地方，补齐 `add_special_tokens` 参数（如需保留原行为请传 `true`，Go 绑定内部已默认 `false`）。  
- **跨平台测试**：在 macOS、Linux、Windows 上运行完整的单元/集成测试，确保 `BooleanT` 参数正确传递，尤其是 `0/1` 与非零值的行为。  
- **文档更新**：同步更新对应的 C API 文档和 Go 绑定说明，明确参数含义及默认值。  
- **CI 检查**：在 CI 中加入编译检查，确保任何未提供 `add_special_tokens` 参数的调用都会被捕获。  
- **兼容层（可选）**：为降低升级阻力，可在未来版本提供一个兼容包装函数 `sgl_tokenizer_encode_default`，内部固定 `add_special_tokens = true`，以平滑迁移。  

### 51541404f84b3f344f1c80dcee0afaf82e0c10e6
https://github.com/sgl-project/sglang/commit/51541404f84b3f344f1c80dcee0afaf82e0c10e6
[grpc] Refactor openai module (#16511)
**🎯 变更类型**：重构  

**⚡ 重要程度**：🟡 中  

**📋 变更摘要**  
- 将 OpenAI 响应相关的代码拆分抽象为 `responses` 子模块，并新增 `common.rs` 统一管理 SSE 解析、块处理等通用工具。  
- 调整模块可见性（`pub(super)` / `pub(crate)`）并删除多余的 `mod accumulator`、`mod streaming` 等声明，精简 `mod.rs`。  
- 为 `ProviderRegistry` 添加 `#[allow(dead_code)]` 标记以抑制未使用的 getter，避免编译警告。  
- 将原先在 `router.rs` 中实现的非流式响应处理抽离到 `responses/non_streaming.rs`，并统一入口 `handle_non_streaming_response`。  

**🎯 影响范围**  
- `sgl-model-gateway/src/routers/openai/` 及其所有子目录（`mod.rs、router.rs、provider.rs、responses/*`）  
- 关联的 `openai` 路由入口 (`OpenAIRouter`)  
- 依赖 `ProviderRegistry` 的外部代码（若有直接引用 `get`/`default_provider`）  

**🔍 技术洞察**  

- **架构影响**  
  - **模块化程度提升**：将 SSE 解析、块处理、公共工具统一放在 `responses/common.rs`，降低 `streaming.rs` 与 `accumulator.rs` 的耦合，实现 “单一职责”。  
  - **可见性收敛**：使用 `pub(super)` 把内部结构限制在 `responses` 子模块，防止误用，提升封装性。  
  - **路由层简化**：`router.rs` 只保留路由调度逻辑，实际业务实现迁移至 `responses`，符合 “控制器‑业务分离” 的设计模式。  

- **性能影响**  
  - **ChunkProcessor** 采用 `Cow` 与字符迭代进行 CRLF 归一化，避免额外的 `String` 分配，理论上在高并发 SSE 场景下略有提升。  
  - **parse_sse_block** 通过直接返回 `Cow<'_, str>`，在单行 `data:` 场景下可避免一次 `String` 拼接，提升热点路径的 CPU 效率。  
  - 其他业务逻辑未变，更改主要是代码组织，对整体吞吐量影响微乎其微。  

- **安全考虑**  
  - 本次改动不涉及身份验证、加密或外部输入过滤，未引入新的安全风险。  
  - 仍旧沿用原有的 `apply_provider_headers`、`extract_auth_header` 机制，安全姿态保持不变。  

**⚠️ 潜在风险**  

1. **可见性变更导致编译错误**  
   - 如果项目的其他 crate（或内部测试）直接引用了之前 `pub(crate)`/`pub` 的结构（如 `ToolLoopState`、`FunctionCallInProgress`），在升级后会因可见性收窄而编译失败。  

2. **未更新的 import 路径**  
   - `streaming.rs`、`tool_handler.rs` 等文件已改为使用 `common::{...}`，若仍有遗漏的旧路径引用，会导致运行时 panic 或编译错误。  

3. **行为回归**  
   - `ChunkProcessor` 与 `parse_sse_block` 的实现细节（尤其是对 CRLF 处理的顺序）若与旧实现不完全一致，可能导致 SSE 流分块在极端网络环境下出现微妙的解析差异，影响流式返回的顺序或内容完整性。  

**💡 关注建议**  

- **编译验证**：在所有工作区（包括示例、集成测试）执行 `cargo test --all-features`，确保没有因可见性收敛而出现未解析的引用。  
- **回归测试**：重点跑 OpenAI **streaming** 与 **non‑streaming** 两类 API 的端到端测试，验证 SSE 解析后事件顺序、`output_index` 映射以及工具调用（MCP）是否保持原有行为。  
- **性能基准**：在高并发 SSE 场景下跑一次 `wrk`/`hey` 基准，比较改动前后的 latency 与 throughput，确认没有意外的回退。  
- **文档更新**：如果库对外暴露了 `ProviderRegistry::get`、`default_provider` 等方法，需在 README/CHANGELOG 中注明这些已被标记为 dead‑code，后续可能会在大版本中移除。  
- **监控告警**：部署后关注在 `streaming` 路径下的错误率和响应时间（尤其是 `parse_sse_block` 报错），以捕获潜在的块解析异常。  

### 45ef8344128da4cb2f88b00afadf8bdc1f51092e
https://github.com/sgl-project/sglang/commit/45ef8344128da4cb2f88b00afadf8bdc1f51092e
Add MoE Integration Tests For CUTLASS Coverage (#16280)
**🎯 变更类型**：测试 / 代码覆盖提升  
**⚡ 重要程度**：🟡 中  
**📋 变更摘要**：  
- 为 MoE（Mixture‑of‑Experts）在 CUTLASS 后端的实现新增了 1‑GPU 与 4‑GPU 两套集成测试，覆盖 FP8、W4A8、DeepEP 等不同配置。  
- 调整了原有 1‑GPU 测试的超时时间、环境变量以及新增了 `moe_runner_cutlass_fp8` 配置，以确保 JIT DeepGEMM 能在测试中被激活。  

**🎯 影响范围**：  
- `test/manual/layers/moe/test_moe_runners_1gpu.py`（原有测试文件）  
- 新增 `test/manual/layers/moe/test_moe_runners_4gpu.py`  
- 相关测试工具：`sglang.test.run_eval`、`sglang.srt.utils.kill_process_tree`、`sglang.test.test_utils.popen_launch_server`  

**🔍 技术洞察**：  
- **架构影响**：无直接代码路径改动，仅在测试层面扩展了 MoE‑CUTLASS 的使用场景（单卡、四卡、不同后端组合），提升了对 MoE 调度器、A2A（All‑to‑All）以及 DeepEP 模式的覆盖。  
- **性能影响**：新增测试会在 CI/本地运行时占用显著的 GPU 资源和时长（单卡 6000 s，四卡 6000 s，部分配置 3600 s），可能导致 CI 运行时间增长。  
- **安全考虑**：测试中使用了 `--trust-remote-code` 参数加载远程模型，若 CI 环境未对模型来源做限制，可能引入供应链风险。其它新增的环境变量均为内部调试开关，无明显安全隐患。  

**⚠️ 潜在风险**：  
1. **资源竞争**：4‑GPU 测试要求 4 张显卡且占用时间长，若 CI 并发执行可能导致 GPU 不足或长时间排队。  
2. **易碎性**：使用远程模型、JIT 编译以及多进程启动，若网络波动或模型下载慢可能导致超时或间歇性失败。  
3. **测试污染**：`env.update(config.get("env_overrides", {}))` 直接修改子进程环境，若后续测试依赖全局环境变量，可能产生不一致。  
4. **误报**：`self.assertGreaterEqual(metrics["score"], 0.48)` 硬编码阈值，若模型或评测数据轻微变化导致分数波动，可能触发不必要的回归报警。  

**💡 关注建议**：  
- **CI 配置**：为这套 MoE‑CUTLASS 测试单独配置标签（如 `slow`、`gpu4`），并在 CI 中分配专用 GPU 节点或使用矩阵方式并行但限制并发度。  
- **超时与重试**：考虑在 CI 脚本中加入自动重试机制，或将 `DEFAULT_TIMEOUT_FOR_SERVER_LAUNCH` 恢复为可配置的全局参数，以便在资源紧张时灵活调节。  
- **模型安全**：在 CI 环境中使用已缓存或内部镜像的模型，避免每次拉取远程模型造成网络不确定性。  
- **阈值弹性**：将评测阈值抽离为配置项，或使用统计容差（如 `>= 0.48 - 0.02`）防止因轻微波动导致回归失败。  
- **清理环境**：在测试结束后显式恢复或清除可能被修改的环境变量，确保后续测试的干净运行。  
- **监控日志**：开启 `SGLANG_ENABLE_JIT_DEEPGEMM=1` 的日志输出，以便在出现 JIT 编译错误时快速定位。  

通过上述措施可在保持测试覆盖率提升的同时，降低对 CI 稳定性和资源的冲击。

### 5a2b1ed407c105213854a6b7d62ef0f1cabfba3f
https://github.com/sgl-project/sglang/commit/5a2b1ed407c105213854a6b7d62ef0f1cabfba3f
[grpc] Refactor grpc/regular/responses (#16509)
**🎯 变更类型**：重构 / 功能增强  
**⚡ 重要程度**：🔴高  

**📋 变更摘要**  
- 将 `sgl-model-gateway/src/routers/grpc/regular/responses` 相关代码重构为更清晰的模块划分：`common`（共享工具与状态）、`non_streaming`（同步/非流式执行）、`streaming`（流式执行）以及 `handlers`（入口路由）。  
- 引入 `BackgroundTaskInfo`，在其中加入 gRPC 客户端句柄及 `grpc_request_id`，统一取消任务的实现。  
- 移除已废弃的 `background` 模式支持，所有 `background=true` 请求将直接返回 400。  
- 对工具循环（MCP）实现进行抽象：新增 `ToolLoopState`、工具准备/提取、MCP 元数据构造、对话历史加载等通用逻辑，供同步与流式路径共用。  
- 删除 `types.rs`（内部类型已被 `BackgroundTaskInfo` 替代），并相应更新 `mod.rs` 的导出结构。  

**🎯 影响范围**  
- `sgl-model-gateway/src/routers/grpc/regular/responses/*`（所有响应处理相关文件）  
- `sgl-model-gateway/src/routers/grpc/regular/responses/context.rs`（Context 结构体）  
- 依赖这些路径的单元测试、集成测试以及上层 `gateway` 代码。  

**🔍 技术洞察**  

| 维度 | 影响说明 |
|------|----------|
| **架构影响** | - 把原本单一的 `handlers.rs` 拆分为 **入口**、**同步实现**、**流式实现**、**共享工具** 四层，提升了职责单一性，降低了文件体积（`handlers.rs` 删除了 700 行冗余代码）。<br>- 新增 `BackgroundTaskInfo`，统一了任务取消的抽象，后续可以在 `grpc_client` 与 Rust 任务之间实现可靠的双向撤销。<br>- `mod.rs` 只暴露 `ResponsesContext`、`route_responses` 与 `BackgroundTaskInfo`，对外 API 更清晰。 |
| **性能影响** | - 基础执行路径（非流式）仍然调用 `pipeline.execute_chat_for_responses`，核心性能 unchanged。<br>- 流式路径中，原来的 SSE 转换逻辑被抽象为 `convert_chat_stream_to_responses_stream`，内部仍然使用 `Body::into_data_stream` 并在单独任务中处理，仅多了一层 `mpsc` 通道，开销极小（< 1 ms 级别），不应成为瓶颈。 |
| **安全考虑** | - 新增的 `BackgroundTaskInfo.client: Arc<RwLock<Option<SglangSchedulerClient>>>` 需要确保在使用前已经完成 `lazy` 初始化，否则可能产生 `None` panic。<br>- 取消任务时若未同步撤销 gRPC 调用，可能出现 **“悬挂的 Python 侧任务”**，但目前代码在 `abort` 时会先发送取消请求，已在 `ensure_mcp_connection` 中检查连接可用性。<br>- 移除了 `background=true` 支持，防止用户误用导致未经过审计的后台执行。 |
| **可维护性** | - 将工具循环的复用代码集中到 `common.rs`，后续如果需要增加新工具或修改循环逻辑，只需改动一个文件。<br>- 通过 `prepare_chat_tools_and_choice`、`extract_all_tool_calls_from_chat` 等小函数，业务逻辑更易阅读与单元测试。 |
| **兼容性** | - `BackgroundTaskInfo` 从 `types.rs` 移动到 `context.rs`，内部使用未变，外部已无直接依赖；若有外部 crate 直接引用 `sgl_model_gateway::routers::grpc::regular::responses::types::BackgroundTaskInfo`，将出现编译错误，需要迁移到 `...::context::BackgroundTaskInfo`。<br>- 之前的 `route_responses()` 仍保持同名入口，签名未变，除非调用者显式依赖已删除的 `get_response_impl`/`cancel_response_impl`（这些已在注释中移除），兼容性影响极小。 |

**⚠️ 潜在风险**  

1. **编译兼容性**：如果项目或第三方插件在代码中直接 `use ...::responses::types::BackgroundTaskInfo`，会因文件删除导致编译失败。  
2. **懒加载的 gRPC 客户端**：`BackgroundTaskInfo.client` 初始化由 `pipeline` 的执行阶段完成，若异常路径（如提前返回错误）未触发初始化，后续尝试 `abort` 可能导致 `None` 解锁 panic。  
3. **工具循环的迭代上限**：`DEFAULT_MAX_ITERATIONS`（安全上限）仍硬编码在 `mcp_utils`，若业务希望自定义更大上限，需要额外配置。  
4. **流式 SSE 转换异常**：在 `process_and_transform_sse_stream` 中，如果客户端提前关闭连接，`tx.send(...)` 可能返回错误并导致 `tokio::spawn` 结束；虽然已捕获并记录，但仍可能出现 **“流提前终止”** 的用户可见错误。  
5. **删除 `background` 模式**：已有客户端可能仍旧发送 `background=true`，现在会返回 400。若未同步文档或客户端 SDK，可能导致用户使用受阻。  

**💡 关注建议**  

- **回归测试**：覆盖以下场景：<br>  • 同步（非流式）普通请求<br>  • 同步请求含 MCP 工具（单调、并行、多轮）<br>  • 流式请求不含 MCP、含 MCP（单调、并行）<br>  • `previous_response_id`、`conversation` 两种历史加载路径<br>  • `background=true` 错误路径<br>  • 任务取消（`abort`）路径，验证 `client` 已成功初始化且取消请求被发送。  
- **文档同步**：在 API 文档与 SDK 中明确标记 `background` 已不再支持，指明返回 400 的错误码与信息。  
- **兼容迁移**：若有外部依赖直接引用旧 `types::BackgroundTaskInfo`，提供迁移指南或在 `pub mod types` 中保留一个 *兼容 shim*（仅 re‑export），防止突发编译错误。  
- **监控 & 警报**：在 `Metrics` 中已经记录 `mcp_tool_iteration`、`mcp_tool_duration`，建议新增 `background_request_rejected` 计数，以监测旧客户端的误用情况。  
- **异常路径审查**：确保所有 `Result<...>` 在 `await` 前后都被 `?` 传播或映射为 `error::...`，防止出现未捕获的 `panic!` 导致服务崩溃。  

---  

整体来看，此次重构提升了代码结构的可读性与可维护性，未对核心业务逻辑做功能性改动，风险主要集中在 **向后兼容** 与 **懒初始化的 gRPC 客户端** 两块。只要在生产环境部署前完成上述测试与文档同步，即可安全发布。祝发布顺利！

### 454dc9e242be2ba474485e9c683a891122a24b27
https://github.com/sgl-project/sglang/commit/454dc9e242be2ba474485e9c683a891122a24b27
[model-gateway][grpc] Refactor harmony/responses.rs (#16508)
**🎯 变更类型**：重构 / 功能增强  
**⚡ 重要程度**：🟡 中  

**📋 变更摘要**  
- 将原本 1657 行的单一 `responses.rs`（包含 Harmony Responses API 的全部实现）拆分为 **5 个独立模块**（`common`, `context`, `execution`, `non_streaming`, `streaming`）并在 `mod.rs` 中统一导出。  
- 新增了公有的 `HarmonyResponsesContext`、工具执行、MCP 元数据注入、历史加载、请求构建等辅助函数，原有实现保持行为一致，仅在代码组织上做了显著改动。  

**🎯 影响范围**  
- `sgl-model-gateway/src/routers/grpc/harmony/responses/` 目录下全部文件（包括新建的 5 个模块）。  
- 直接或间接调用 Harmony Responses（同步/流式）入口的业务代码：`serve_harmony_responses`、`serve_harmony_responses_stream`。  
- 任何依赖旧文件路径（如 `use ...responses.rs`）的内部模块需要更新为新的模块路径。  

**🔍 技术洞察**  

| 维度 | 影响描述 |
|------|----------|
| **架构影响** | - **模块化**：把原本的“大块”代码拆分，形成 **职责单一** 的子模块（上下文、执行、公共工具、非流式、流式）。<br>- **可维护性提升**：每个文件职责清晰，后续增删功能时冲突概率降低，编译增量更快。<br>- **对外接口未变**：`mod.rs` 重新导出 `serve_harmony_responses`、`serve_harmony_responses_stream`、`HarmonyResponsesContext` 等，外部调用保持不变。 |
| **性能影响** | - 代码层面无新算法或 I/O 变更，运行时性能基本保持不变。<br>- 编译时间可能略有下降，因为增量编译粒度更细。 |
| **安全考虑** | - 没有新增外部依赖或权限检查，安全面保持原有水平。<br>- 需要确保 `pub(super)`/`pub(crate)` 可见性未误泄露内部实现细节；目前仅公开必要的 API，安全无倒退。 |
| **可维护性** | - **代码可读性大幅提升**（每个文件几百行以内），更易进行单元测试和审计。<br>- 通过 `pub(super)` 限制范围，防止误用内部函数。<br>- 统一错误处理（`error::internal_error`）仍在各子模块中复用。 |
| **兼容性** | - 只要项目内部的 `use` 路径已更新，外部调用（如部署的服务）不受影响。<br>- 若有第三方插件直接引用旧文件路径，会编译失败，需要同步迁移。 |

**⚠️ 潜在风险**  
1. **导入路径遗漏**：拆分后旧的 `use ...responses.rs` 语句若未全部替换，会导致编译错误或运行时 panic（尤其在宏或动态加载情境）。  
2. **可见性泄露或收缩**：部分函数从原来的 `pub` 改为 `pub(super)`，若其他 crate（如插件）曾经直接调用这些函数，将出现链接错误。  
3. **模块初始化顺序**：`mod.rs` 重新导出顺序如果出现循环依赖，可能导致编译器报错，需要检查 `use` 的相互引用。  
4. **测试覆盖不足**：虽然业务逻辑未变，但拆分后部分细节（如 `build_next_request_with_tools` 错误返回 `Box<Response>`）需要确保对应单元测试覆盖。  

**💡 关注建议**  
- **全量编译 & 测试**：在 CI 中执行 `cargo test --all`，确保所有单元、集成、e2e 测试均通过，尤其是 Harmony Responses 的同步/流式路径。  
- **搜索旧路径**：使用全局搜索确认项目内没有残留 `use ...responses.rs` 或直接调用已删文件中的函数。  
- **文档更新**：在项目文档或开放 API 说明中标记该模块已迁移至 `harmony::responses::` 子模块，避免外部开发者使用被删除的路径。  
- **审计可见性**：如果有第三方插件需要访问内部工具执行函数，考虑在 `mod.rs` 中提供更高层的包装函数，而非直接把 `pub(super)` 改为 `pub`。  
- **回滚计划**：若在生产环境出现因路径错误导致的服务不可用，准备好回滚到单文件版本（保留旧文件的分支）以快速恢复。  

总体而言，此次提交是一次 **代码结构层面的重大重构**，对功能没有行为变化，但显著提升了可维护性和代码组织。只要确保路径迁移完整、测试覆盖充分，即可安全上线。

### 1e41069ad1f582f29b44667b3131545378bccce8
https://github.com/sgl-project/sglang/commit/1e41069ad1f582f29b44667b3131545378bccce8
Fix age bucket rendering issue (#16492)
**🎯 变更类型**：Bug修复  
**⚡ 重要程度**：🟡中  
**📋 变更摘要**：修复了 HTTP 请求年龄直方图在 Prometheus 中渲染错误的问题。通过引入 `NumericalBuckets` 与 `LazyLock` 实现静态、非累计的 bucket 标签；`compute_bucket_counts` 改为返回非累计计数，并相应调整 `Metrics::set_inflight_request_age_count` 的签名与实现。测试也同步更新以验证新行为。  

**🎯 影响范围**：  
- `sgl-model-gateway/src/observability/inflight_tracker.rs`（核心逻辑）  
- `sgl-model-gateway/src/observability/metrics.rs`（指标导出）  
- 单元/集成测试 `sgl-model-gateway/tests/inflight_tracker_test.rs`  

**🔍 技术洞察**：  
- **架构影响**：  
  - 新增 `NumericalBuckets` 结构体，用于一次性生成 `le` 与 `gt` 两套标签，避免重复硬编码。  
  - 采用 `LazyLock`（std::sync::LazyLock）实现全局单例，确保仅在首次使用时分配并保持 `'static` 生命周期。  
  - `compute_bucket_counts` 接口从固定长度数组 `[usize; N]` 改为 `Vec<usize>`，提升灵活性（可随 bucket 数量变化而不需重新编译）。  
- **性能影响**：  
  - `LazyLock` 的惰性初始化仅在首次调用时产生一次锁竞争，后续访问几乎为零开销。  
  - `Vec` 动态分配一次（长度等于 bucket 数量），相比之前的数组没有显著的时间或空间劣化。  
  - `leak_str` 使用 `Box::leak` 将字符串转为 `'static`，会永久占用少量内存（仅限 bucket 数量的字符串），可接受。  
- **安全考虑**：  
  - 代码未引入外部输入或网络交互，仅使用内部常量，安全风险基本为 **无**。  
  - `Box::leak` 本质上是内存泄漏，但在此场景（少量常量）对系统安全无负面影响。  

**⚠️ 潜在风险**：  
1. **兼容性**：  
   - 之前的实现向 Prometheus 暴露的是累计直方图（`le` 标签），现在改为非累计 (`gt`/`le` 双标签)。若已有 Grafana/Prometheus 查询仍基于累计模型，可能出现查询结果不符或报警误报。  
2. **API 变更**：  
   - `Metrics::set_inflight_request_age_count` 现在接受 `(gt, le, count)`，任何直接调用旧签名的代码将编译失败。  
3. **内存泄漏**：  
   - `leak_str` 会导致每个 bucket 的字符串在程序生命周期内不可回收。虽然数量极少（<20），但在极端长时间运行的极端环境下仍算是永久泄漏。  

**💡 关注建议**：  
- **监控迁移**：更新所有 Prometheus 查询、Grafana 仪表盘、告警规则，使其使用 `gt` 与 `le` 两标签的非累计计数（如 `sum by (gt, le) (smg_http_inflight_request_age_count)`），或在查询层自行累积得到累计直方图。  
- **回归测试**：在 CI 中加入基于 Prometheus 的集成测试，验证新指标的导出和查询行为符合预期。  
- **文档同步**：在项目文档或 README 中说明 `smg_http_inflight_request_age_count` 的标签语义已从累计改为区间 (`gt < age <= le`)。  
- **审计其他调用点**：全局搜索 `set_inflight_request_age_count(`，确保所有调用已经适配新签名。  
- **内存泄漏评估**：如果对极端内存使用敏感，可考虑改用 `lazy_static!` 或 `once_cell::sync::Lazy` 与 `&'static str` 常量组合，避免 `Box::leak`。  
- **版本发布**：建议在发布说明中标记此为“破坏性变更”，提示使用者更新监控查询及代码兼容性。  

### 2b4d6d813b5f3e5abcda63cb1e994410d6e5b22c
https://github.com/sgl-project/sglang/commit/2b4d6d813b5f3e5abcda63cb1e994410d6e5b22c
[model-gateway][e2e_test]: Create directory structure and backends config (#16469)
**🎯 变更类型**：功能增强（为 E2E 测试引入多后端启动与管理框架）

**⚡ 重要程度**：🔴高  
- 该改动涉及测试运行时的进程管理、网络端口分配、环境变量以及对外部 API（OpenAI、xAI）的调用，若配置不当会导致 CI/CD 流水线卡死或泄露密钥。

**📋 变更摘要**  
- 新增 `backends.py`，统一描述并实现 **grpc、grpc_harmony、openai、xai、oracle_store** 等后端的启动、健康检查、资源回收等逻辑。  
- 在 `conftest.py` 中加入 **backend** 标记以及 **class‑scoped / function‑scoped** 夹具 `setup_backend`、`backend_cluster`，支持基于标记的多后端参数化。  
- 为模型规格 `infra/model_specs.py` 衍生出一系列默认模型路径常量（`DEFAULT_*_MODEL_PATH`），并在 `infra/__init__.py` 中导出。  
- 新增通用工具模块 `utils.py`，提供 tokenzier 加载、重试装饰器、CI 检测、GPU 检测、进程清理等辅助函数。  
- 新增空的 `__init__` 包目录以及若干占位文件。

**🎯 影响范围**  
- `sgl-model-gateway/e2e_test/` 目录下的所有 E2E 测试代码。  
- CI 流水线（GitHub Actions / 其他 CI）因新增依赖（`psutil`、`transformers`、`openai`）及环境变量检查而可能受影响。  
- 开发者本地调试时的端口占用与进程管理行为。  

**🔍 技术洞察**  

- **架构影响**  
  - 引入 **后端注册表 (`BACKENDS`)** 与统一的 **`launch_backend`** 接口，解耦测试代码与底层启动实现。  
  - 通过 **fixture + 参数化** 方式实现 **后端可组合**，对现有测试用例的改动最小（仅需添加 `@pytest.mark.backend("<name>")` 或 `@pytest.mark.parametrize(..., indirect=True)`）。  
  - 新增的 **`ClusterInfo`** 对象封装 router 与 worker 进程，提供统一的 `shutdown` 方法，提升资源回收的可控性。

- **性能影响**  
  - 启动本地 gRPC workers 需要 `time.sleep(20)` 的等待，整体测试套件的执行时间将显著增加（尤其在多后端并行时）。  
  - 端口分配通过 `socket.bind(0)` 动态获取，避免冲突但会产生额外的系统调用。  
  - 对 OpenAI/xAI 后端的调用仍依赖网络，受外网延迟影响，可能导致测试不稳定。

- **安全考虑**  
  - 对 OpenAI / xAI 后端强制读取环境变量 `OPENAI_API_KEY`、`XAI_API_KEY`，若 CI 环境未妥善隐藏，密钥可能泄漏。  
  - `kill_process_tree` 使用 `psutil`（如果可用）或 `os.kill`，在非 Linux 环境上可能出现权限问题。  
  - `launch_openai_router` 将 API 密钥写入子进程的 `env`，若子进程日志未过滤，可能暴露密钥。  

**⚠️ 潜在风险**  
1. **CI 失效**：缺失必需的环境变量或未安装 `psutil`、`transformers`，会导致测试阶段报错或卡死。  
2. **端口冲突**：在高并发 CI runner 中，动态分配端口仍可能与其它进程冲突，导致启动失败。  
3. **资源泄漏**：异常情况下（如 `wait_for_workers_ready` 超时）未能彻底杀掉子进程，可能残留 GPU 占用，影响后续任务。  
4. **测试不确定性**：外部 API（OpenAI/xAI）受网络波动影响，可能出现间歇性超时或速率限制错误。  
5. **跨平台兼容**：`psutil` 与 `subprocess.start_new_session=True` 在 Windows 上行为不同，可能导致进程清理失败。  

**💡 关注建议**  

| 建议 | 说明 |
|------|------|
| **CI 环境变量准备** | 在 CI 配置中显式声明 `OPENAI_API_KEY`、`XAI_API_KEY`（使用 secret），并在日志中遮蔽 `Authorization` 头。 |
| **依赖锁定** | 在 `requirements.txt`/`pyproject.toml` 中添加 `psutil>=5.9`、`transformers>=4.30`（或标记为可选），防止导入错误。 |
| **端口冲突防护** | 在 `launch_*` 中捕获 `OSError`（端口已占用），重试获取新端口。可考虑在 CI 中预留端口范围（例如 30000‑31000）并限制并行数。 |
| **超时与重试** | 对 `wait_for_health` 与 `wait_for_workers_ready` 增加指数回退重试，以提升在高负载机器上的鲁棒性。 |
| **进程清理强化** | 在 `ClusterInfo.shutdown` 中添加 `finally` 块记录被杀进程的 PID，必要时使用 `psutil` 的 `kill()` 强制清理。 |
| **平台兼容** | 为 Windows 环境提供 `kill_process_tree` 的实现分支（使用 `subprocess.CREATE_NEW_PROCESS_GROUP`），或在文档中注明仅在 Linux/macOS 上保证完整清理。 |
| **测试标记规范** | 在项目文档中列出所有后端名称及对应的必备环境变量，建议使用 `@pytest.mark.backend("<name>")` 而非硬编码字符串。 |
| **Mock 外部 API** | 在 CI 中对 OpenAI/xAI 后端提供可选的 mock server（如 `httpx.MockTransport`），以避免真实调用导致费用或速率限制。 |
| **日志审计** | 确保 `show_output` 默认关闭，防止在 CI 日志中泄露模型路径或敏感信息。 |

> **总结**：此次提交大幅提升了 E2E 测试的可配置性与可扩展性，使得同一套测试可以在本地 GPU、远程 OpenAI、xAI 等多种后端上运行。但它也引入了对外部资源、环境变量和进程管理的依赖，建议在 CI 与本地开发环境中做好相应的准备与防护，以免因缺失依赖或资源泄漏导致不必要的测试失败或安全风险。

