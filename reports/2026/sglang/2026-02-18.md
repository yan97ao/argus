# 每日更新报告（2026-02-18）

## sgl-project/sglang

| 提交时间 | 作者 | 提交信息 |
|----------|------|----------|
| 2026-02-18 23:03:07 | Yuhao Yang | Add DP ViT support for Kimi K2.5 (#18689) |
| 2026-02-18 20:57:42 | zijiexia | [diffusion] fix: refactor task resolution logic in benchmark function for multimodal generation (#18948) |
| 2026-02-18 18:21:39 | HAI | [AMD] ROCm7.2: Add /sgl-workspace/aiter to PYTHONPATH (#18972) |
| 2026-02-18 17:12:05 | Qiaolin Yu | Enable fa3 PDL by compiling it with corresponding flags (#18756) |
| 2026-02-18 16:18:43 | Xiaoyu Zhang | [Tiny fix] Super tiny fix mul_add naive forward bug (#18964) |
| 2026-02-18 15:51:07 | Xiaoyu Zhang | Remove unused fast-hadamard-transform PyTorch extension sources (#18927) |
| 2026-02-18 15:05:55 | HAI | Reasoning models fix docs (#18963) |
| 2026-02-18 14:56:58 | Mick | [diffusion] refactor: unify SamplingParams construction and improve DiffGenerator return types (#18928) |
| 2026-02-18 14:37:46 | DarkSharpness | [Refactor] Fix test and clean up hicache code (#18555) |
| 2026-02-18 14:11:19 | William Arnold | [feat] Add return_routed_experts param to async_generate for parity with generate (#18508) |
| 2026-02-18 13:13:26 | Neal Vaidya | feat: add nsa and swa disagg support with nixl (#18939) |
| 2026-02-18 12:43:55 | Liangsheng Yin | Revert "Fix generated-shared-prefix bench_serving" (#18956) |
| 2026-02-18 11:44:25 | Zheng Li | feat: [Qwen3.5] Support block-wise FP8 quantization and model adaptation (#18926) |
| 2026-02-18 11:14:22 | Yan Ru Pei | Expose priority parameter in Engine.generate() and Engine.async_generate() (#18944) |
| 2026-02-18 07:59:03 | Alison Shao | Fix eval tests not capturing server launch failures (#18886) |
| 2026-02-18 07:41:23 | Lianmin Zheng | Refactor sampler: Use a better hash function for deterministic sampling and clear dispatch for probs/logprobs/logits sampling paths (#18915) |
| 2026-02-18 06:49:26 | Liangsheng Yin | feat: add cuda core dump CI warpper (#18909) |
| 2026-02-18 06:35:35 | Ratish P | cleanup prefill metrics logging to fix dp-attn metrics (#18778) |
| 2026-02-18 06:25:37 | satyamk7054 | Fix benchmark_sglang_fused_moe_triton.py (#18940) |
| 2026-02-18 06:00:22 | Qiaolin Yu | Fix generated-shared-prefix bench_serving (#18769) |
| 2026-02-18 05:04:32 | Nickcp39 | fix(glm-image): single-GPU T5 config + SP support for 4D latents (#18… (#18739) |
| 2026-02-18 02:38:27 | Tamir Baydasov | [3/N] Quantization Refactor: ModelSlim MoE schemes (#17993) |
| 2026-02-18 01:36:06 | ronnie_zheng | [diffusion] update code owner (#18495) |
| 2026-02-18 00:52:11 | Simo Lin | [gRPC] Fix scheduler startup broken by context parallel refactor (#18933) |
| 2026-02-18 00:47:38 | triple-mu | [diffusion] improve: improve torch.compile for MOVA (#18914) |

### 📊 统计摘要
> 本日共 25 个提交 | 🔴高 6 | 🟡中 7 | 🟢低 12
## 📋 目录

- [sgl-project/sglang](#sgl-project-sglang)
  - [📊 统计摘要](#-统计摘要)
  - [🔴 高重要度变更 (6)](#-🔴-高重要度变更-6)
    - [[diffusion] refactor: unify SamplingParams construction a...](#420a611)
    - [feat: add nsa and swa disagg support with nixl (#18939)](#ac0e493)
    - [feat: [Qwen3.5] Support block-wise FP8 quantization and m...](#fa5698d)
    - [feat: add cuda core dump CI warpper (#18909)](#83a475e)
    - [fix(glm-image): single-GPU T5 config + SP support for 4D ...](#48fcd62)
    - [[3/N] Quantization Refactor: ModelSlim MoE schemes (#17993)](#aeca7d3)
  - [🟡 中重要度变更 (7)](#-🟡-中重要度变更-7)
    - [[diffusion] fix: refactor task resolution logic in benchm...](#eb6ff4a)
    - [Remove unused fast-hadamard-transform PyTorch extension s...](#513c12d)
    - [[Refactor] Fix test and clean up hicache code (#18555)](#9d13868)
    - [Expose priority parameter in Engine.generate() and Engine...](#83e24e2)
    - [Fix eval tests not capturing server launch failures (#18886)](#34d975b)
    - [Refactor sampler: Use a better hash function for determin...](#e02a9be)
    - [cleanup prefill metrics logging to fix dp-attn metrics (#...](#9a7d6be)
  - [🟢 低重要度变更 (12)](#-🟢-低重要度变更-12)
    - [Add DP ViT support for Kimi K2.5 (#18689)](#5a7ae05)
    - [[AMD] ROCm7.2: Add /sgl-workspace/aiter to PYTHONPATH (#1...](#0215d47)
    - [Enable fa3 PDL by compiling it with corresponding flags (...](#90d5e27)
    - [[Tiny fix] Super tiny fix mul_add naive forward bug (#18964)](#390c154)
    - [Reasoning models fix docs (#18963)](#934b366)
    - [[feat] Add return_routed_experts param to async_generate ...](#95c44ce)
    - [Revert "Fix generated-shared-prefix bench_serving" (#18956)](#2d85f01)
    - [Fix benchmark_sglang_fused_moe_triton.py (#18940)](#355127c)
    - [Fix generated-shared-prefix bench_serving (#18769)](#3c601db)
    - [[diffusion] update code owner (#18495)](#10569d0)
    - [[gRPC] Fix scheduler startup broken by context parallel r...](#bf08d3f)
    - [[diffusion] improve: improve torch.compile for MOVA (#18914)](#504b2c5)
#### 🔴 高重要度变更 (6)

### [diffusion] refactor: unify SamplingParams construction and improve DiffGenerator return types (#18928)
**SHA**: `420a611` | 🔗 [查看提交](https://github.com/sgl-project/sglang/commit/420a6112754076716ee1fd7d2dbc6bf02d70551f)

**🎯 变更类型**：重构  

**⚡ 重要程度**：🔴高  

**📋 变更摘要**  
1. 将所有入口（CLI、HTTP、OpenAI、Diffusion）统一使用 `SamplingParams.from_user_sampling_params_args` 构建方式，抽取出 `build_sampling_params` 与 `_resolve_prompts` 等公共函数，消除重复逻辑。  
2. 为 Diffusion 生成器引入 `GenerationResult` 数据类，并改写返回值为统一的对象或对象列表，简化后续数据访问与日志记录。  
3. 精简了性能日志、日志输出以及文件路径管理（如 `outputs/uploads → inputs/uploads`），并删除了不再使用的 `MemorySnapshot` 反序列化代码。

**🎯 影响范围**  
- `python/sglang/multimodal_gen/configs/pipeline_configs/base.py`  
- `python/sglang/multimodal_gen/runtime/entrypoints/cli/generate.py`  
- `python/sglang/multimodal_gen/runtime/entrypoints/diffusion_generator.py`  
- `python/sglang/multimodal_gen/runtime/entrypoints/http_server.py`  
- `python/sglang/multimodal_gen/runtime/entrypoints/openai/*`（image、video、common_api）  
- `python/sglang/multimodal_gen/runtime/entrypoints/utils.py`（新增 `GenerationResult`、`build_sampling_params`、大小解析等）  
- `python/sglang/multimodal_gen/runtime/managers/scheduler.py`（导入路径调整）  
- `python/sglang/multimodal_gen/runtime/pipelines_core/*`（日志细节、条件图像调试信息）  
- 相关的测试、示例脚本及文档（若有）均需同步更新。

**🔍 技术洞察**  

- **架构影响**  
  - 统一了 `SamplingParams` 的构造入口，所有高层入口都通过 `build_sampling_params` 生成统一的配置对象，降低了各子系统之间的耦合度。  
  - 引入 `GenerationResult`，把原本散落在字典中的字段（`samples`、`frames`、`audio`、`timings`、`peak_memory_mb` 等）集中到一个强类型的数据结构，提升代码可读性和 IDE 自动补全能力。  
  - `DiffusionGenerator.generate` 现在返回 `GenerationResult`（单个或列表），对外 API 更加明确；同时内部 `_log_summary`、`_log_summary` 复用统一的日志格式。  
  - `http_server` 与 OpenAI 接口通过 `build_sampling_params` 共享同一套参数解析与默认值处理，避免了先前在 `image_api` 与 `video_api` 中的重复实现。  
  - Scheduler 交互仍保持“一次请求一个 batch”，但 `process_generation_batch` 的返回值由单路径改为路径列表，配合 `save_outputs` 的统一文件命名逻辑，简化了后续文件管理。  

- **性能影响**  
  - 删除了对 `MemorySnapshot` 的反序列化（曾在 `cli/generate.py` 中恢复），可略微降低 CPU 与内存占用，且避免了不必要的对象构造。  
  - 在 `base.py` 中对潜在的 SP（tensor parallel）填充进行调试日志提示，帮助运维快速定位因填充导致的性能下降。  
  - `save_outputs` 现在统一使用 `batch.output_file_path(num_outputs, idx)` 计算文件名，避免了在循环中多次拼接字符串带来的微小开销。  
  - 其它改动主要是代码整洁与日志改进，对核心推理吞吐量的直接影响有限。  

- **安全考虑**  
  - 将所有 `print` 替换为结构化 `logger`，并在异常捕获时使用 `exc_info=True`，提升了错误可追溯性，符合生产级日志规范。  
  - 对 Base64 解码做了更严格的校验；错误信息统一为 “Failed to decode base64 image …”，避免泄露异常堆栈。  
  - 重新组织文件路径（如统一使用 `inputs/uploads`），防止路径注入或意外覆盖 `outputs` 目录下的敏感文件。  
  - 未引入新的网络交互或权限检查，现有的安全模型保持不变。  

**⚠️ 潜在风险**  
1. **API 兼容性**：原先依赖 `generate` 返回 `dict`/`list[np.ndarray]` 的外部脚本或 SDK 将因改为 `GenerationResult` 报错，需要添加适配层或更新文档。  
2. **性能日志回退**：移除 `MemorySnapshot` 可能导致已有的基准报告缺少内存快照字段，若用户依赖该信息做监控，需要在上层自行恢复或使用 `timings` 中的 `memory_snapshots`（已被删除）。  
3. **文件路径改动**：从 `outputs/uploads` 迁移到 `inputs/uploads`，可能破坏已有的 CI/脚本或磁盘清理策略。  
4. **默认值细微差异**：`build_sampling_params` 现在会在没有显式 `output_compression` 时根据 `output_quality` 自动填充，若下游对 `output_compression` 有精细控制，可能出现意外的压缩率变化。  
5. **并发批处理**：目前仍是“一次一个 batch”发送到 Scheduler，若后续计划开启批量调度，需重新审视 `GenerationResult` 聚合逻辑。  

**💡 关注建议**  
- **迁移指南**：在 SDK、示例代码以及测试套件中加入 `GenerationResult` 的兼容包装（如 `result.to_dict()`），确保老用户平滑升级。  
- **回归测试**：重点验证 CLI、HTTP、OpenAI（image、video）三个入口的返回结构、文件路径、以及 `warmup` 日志是否保持一致。  
- **监控与基准**：在 CI 中加入对 `MemorySnapshot` 被移除后的基准对比，确认整体吞吐与显存占用未出现回退。  
- **文档更新**：明确 `SamplingParams` 的统一构造入口、`output_quality` 与 `output_compression` 互斥规则、以及 `GenerationResult` 各字段的含义。  
- **安全审计**：再次审查上传路径的写权限，确保 `inputs/uploads` 目录仅对可信进程可写，防止恶意文件写入。  

通过以上改动，项目在代码可维护性、统一性以及调试便利性上获得显著提升，若按建议完成兼容层与测试覆盖，可安全上线。

---

### feat: add nsa and swa disagg support with nixl (#18939)
**SHA**: `ac0e493` | 🔗 [查看提交](https://github.com/sgl-project/sglang/commit/ac0e493329d017723fc1a3a097504a816d002612)

**🎯 变更类型**：功能增强（feat）  
**⚡ 重要程度**：🔴高  
**📋 变更摘要**：  
- 在 `python/sglang/srt/disaggregation/nixl/conn.py` 中引入通用 KV‑cache 传输实现 `_send_kvcache_generic`，并以此实现 `send_kvcache` 与新增的 `maybe_send_extra`。  
- 新增对 NSA（Non‑Self‑Attention） 与 SWA（Sliding‑Window Attention） 混合模型的 disaggregation 支持，能够在 NIXL 后端统一处理 MHA、MLA、Mamba、NSA、SWA 等多种注意力/状态类型。  
- 引入一系列参数校验（TP‑size、state_type、索引长度），提升运行时安全性。

**🎯 影响范围**：  
- `python/sglang/srt/disaggregation/nixl/conn.py`（核心实现）  
- 依赖 KV‑cache 传输的调度层、解码器以及混合模型的 disaggregation 逻辑（间接受影响）  
- 可能影响的测试套件与示例脚本（涉及 NSA/SWA 的使用场景）

**🔍 技术洞察**  

- **架构影响**  
  1. **统一抽象层**：通过 `_send_kvcache_generic` 把 MHA 与 MLA 两条分支合并为同一套数据路径，降低代码重复度。  
  2. **扩展状态处理**：新增 `maybe_send_extra`，在 `add_transfer_request` 中统一调用，使得 PD（Prefill‑Disaggregation）能够在同一框架下处理 Mamba、NSA、SWA 三类额外状态，提升体系结构的 **可组合性** 与 **可扩展性**。  
  3. **后端兼容**：保持对原有 `is_mla_backend` 标志的判定，仅在需要时切换到对应的指针获取函数，保证兼容已有的 MLA / MHA 实现。  

- **性能影响**  
  1. **一次性分组**：`group_concurrent_contiguous` 仍然在索引层面执行聚合，未引入额外的遍历开销。  
  2. **函数调用层级**：新增的包装层（`_send_kvcache_generic`、`maybe_send_extra`）会产生极少的函数调用开销，几乎可以忽略。  
  3. **额外状态传输**：针对 NSA/SWA，若模型存在额外的 state（`state_data_ptrs`），会触发一次额外的 PCIe / NVLink 传输，可能导致 **prefill‑decode** 阶段的带宽占用提升，需要在实际部署中进行基准测试。  

- **安全考虑**  
  1. **参数校验**：加入对 `decode_tp_size` 与 `attn_tp_size` 不匹配的显式异常，防止跨 TP‑size 的错误内存拷贝。  
  2. **state_type 限制**：仅允许 `mamba、nsa、swa` 三类已实现的状态类型，其余类型直接抛异常，避免未知指针传输。  
  3. **指针安全**：仍然使用原始整数指针列表进行低层拷贝，若上层传入错误指针仍可能导致 **内存访问违规**，建议在调用方加入完整性检查（长度、对齐等）。  

**⚠️ 潜在风险**  

| 风险点 | 可能后果 | 触发条件 |
|--------|----------|----------|
| 指针列表长度不匹配 | 越界访问 / 段错误 | `src_data_ptrs`、`dst_data_ptrs` 或 `item_lens` 长度与实际层数不一致 |
| 索引数组长度不一致 | 传输目标错位，导致缓存不一致 | `prefill_data_indices` 与 `dst_data_indices` 长度不匹配 |
| 非法 `state_type` 进入 `maybe_send_extra` | 运行时异常，导致调度中断 | 第三方插件或旧版代码仍旧传递未受支持的 state_type |
| TP‑size 不一致的分支逻辑缺失 | 数据同步错误、模型推理错误 | 混合模型的 PD 与 Decode 使用不同的 TP‑size，且未触发显式异常（代码路径遗漏） |
| 新增异常路径未被捕获 | 进程退出或调度器卡死 | `add_transfer_request` 中 `maybe_send_extra` 抛异常后未被上层捕获 |
| 额外状态传输导致带宽瓶颈 | 推理延迟显著上升 | 大模型使用 NSA/SWA，state 数据量大且 GPU‑GPU 互联带宽受限 |

**💡 关注建议**  

1. **测试覆盖**  
   - 为 NSA、SWA 两类模型分别编写 **单元测试** 与 **集成测试**，验证 `maybe_send_extra` 的正确路径、异常路径以及性能基准。  
   - 在 CI 中加入对 `state_type` 未实现情况的回归检测，防止未来误加入不兼容的模型。  

2. **参数校验强化**  
   - 在 `_send_kvcache_generic` 前加入断言，确保 `len(src_data_ptrs) == len(dst_data_ptrs) == len(item_lens)` 与 `layers_current_pp_stage` 一致。  
   - 对 `prefill_data_indices`、`dst_data_indices` 进行 **有序性** 与 **重复性** 检查，以免 `group_concurrent_contiguous` 产生不可预期的块划分。  

3. **性能监控**  
   - 在关键路径（如 `make_req_array` 前后）加入计时日志，帮助运营团队定位额外状态传输是否成为瓶颈。  
   - 提供可选的 **批量合并** 开关，允许在带宽受限的环境下一次性发送多段 state。  

4. **文档与迁移指引**  
   - 更新 README / API 文档，说明 `send_kvcache` 仍保持兼容，而新功能应通过 `maybe_send_extra` 与 `state_type` 参数使用。  
   - 对已有插件/自定义 Agent 明确标注：如果需要支持 NSA/SWA，请实现对应的 `state_data_ptrs` 与 `state_item_lens` 字段。  

5. **安全审计**  
   - 由于仍然直接操作低层指针，建议在后续迭代中考虑 **CFFI / PyCapsule** 包装，以强制类型检查，降低非法指针注入的风险。  

通过上述措施，可在充分利用新功能提升混合模型 disaggregation 能力的同时，控制风险并保持系统的稳健性。

---

### feat: [Qwen3.5] Support block-wise FP8 quantization and model adaptation (#18926)
**SHA**: `fa5698d` | 🔗 [查看提交](https://github.com/sgl-project/sglang/commit/fa5698d7916497288af8fe5a5b57bc4ee7e6fb37)

**🎯 变更类型**：功能增强  

**⚡ 重要程度**：🔴高  

**📋 变更摘要**  
1. 为 `MergedColumnParallelLinear` 引入块级 FP8 量化的尺度加载逻辑，实现跨 TP（Tensor Parallel）分片的块级权重恢复。  
2. 在 FP8 配置读取中加入对 Mistral‑3 系列模型的特殊前缀处理，提升兼容性。  
3. 调整 Qwen‑3.5‑MTP 与 Qwen‑3‑VL 两套模型的前缀映射与量化配置，统一权重加载路径并规避不兼容的量化方式。  

**🎯 影响范围**  
- `python/sglang/srt/layers/linear.py`（块级尺度加载）  
- `python/sglang/srt/layers/quantization/fp8.py`（配置解析）  
- `python/sglang/srt/models/qwen3_5_mtp.py`（MTP 前缀适配）  
- `python/sglang/srt/models/qwen3_vl.py`（视觉子模型前缀与量化）  

**🔍 技术洞察**  

- **架构影响**  
  - 新增 `_load_merged_block_scale` 方法，使 `MergedColumnParallelLinear` 在加载 checkpoint 时能够按 **weight_block_size** 划分块，并在 TP 环境下正确对齐每个分片。  
  - 参数类 `BlockQuantScaleParameter` 被纳入 `weight_loader_v2` 分支，实现与原有 `RowvLLMParameter`、`BasevLLMParameter` 的统一加载路径。  
  - 前缀改动（`add_prefix("mtp", …)`、`add_prefix("model.visual", …)`）让模型在多阶段（pipeline、tensor parallel）部署时的权重命名更具一致性，降低了因命名差异导致的加载错误。  

- **性能影响**  
  - **内存**：块级 FP8 量化将权重压缩至 8bit，配合块尺度（scale）分块存储，可显著降低显存占用，尤其在大模型（>30B）上可节约 30%‑40% 显存。  
  - **推理速度**：FP8 运算在支持的硬件（如 Nvidia Hopper、AMD CDNA3）上可触发 Tensor Core 加速，理论上提升 1.2‑1.5 倍吞吐。实际收益取决于 block 大小与硬件的向量化支持。  
  - **加载时延**：块级拆分与 TP‑aware 偏移计算略微增加权重切分成本，但相较于整体权重拷贝的显著节省仍为正向收益。  

- **安全考虑**  
  - 该改动仅涉及权重读取与数值格式转换，无外部网络交互或权限变更，不引入新的攻击面。  
  - 唯一安全关注点在于 **checkpoint 可信度**：错误的块尺度或恶意篡改的块尺度表（scale）可能导致数值溢出或模型失效，建议在生产环境加校验和或签名验证。  

**⚠️ 潜在风险**  

1. **块尺寸不匹配**：若 `weight_block_size` 与实际 checkpoint 中的块划分不一致，会导致 `narrow` 取片越界或尺度错位，进而出现 NaN/Inf 或推理精度大幅下降。  
2. **TP 迁移错误**：`rank_shard_offset = shard_block_offset // self.tp_size` 假设每个块在所有 TP 进程间均匀划分，若模型在某些分片采用非均匀划分（如残余层），可能出现偏移错误。  
3. **向后兼容性**：老的 checkpoint 未携带块尺度信息或使用不同前缀（如 `model.language_model.mtp`），在未进入新分支前可能仍触发旧加载路径，导致权重未被正确量化。  
4. **视觉子模型量化被禁用**：对 Qwen‑3‑VL，`quant_config` 被强制置 `None`，若用户误以为已开启 FP8 量化，可能产生预期不符的显存占用。  

**💡 关注建议**  

- **单元测试/集成测试**：  
  - 为每种 `tp_size`（1、2、4、8）跑一次完整的 checkpoint 加载，校验 `param.scale` 与原始权重的数值误差在可接受范围内。  
  - 增加针对 `BlockQuantScaleParameter` 的专属测试，确保块尺度在不同前缀下均能正确映射。  

- **配置校验**：在 `Fp8Config.from_config` 中加入对 `weight_block_size` 合法性的断言（必须能被 `output_dim` 整除），并在出现不匹配时给出明确错误提示。  

- **日志与可观测性**：在 `_load_merged_block_scale` 完成后打印 `shard_id、shard_offset、shard_size` 等信息，方便用户排查 TP/PP 环境下的加载异常。  

- **文档更新**：  
  - 明确说明 Qwen‑3.5‑MTP 与 Qwen‑3‑VL 在多阶段部署时的前缀约定以及对 FP8 量化的支持范围。  
  - 对 “ministral” hack 进行注释，解释为何仅在 `model_type` 包含 `mistral3` 时进行前缀裁剪，防止后续误删。  

- **安全措施**：在生产系统中加入 checkpoint 哈希校验或签名验证步骤，防止因恶意/损坏的块尺度文件导致模型行为异常。  

通过上述措施，可最大化新块级 FP8 量化功能的收益，同时将潜在的兼容性与可靠性风险降到最低。

---

### feat: add cuda core dump CI warpper (#18909)
**SHA**: `83a475e` | 🔗 [查看提交](https://github.com/sgl-project/sglang/commit/83a475e8d7de58c032d3e13551208cc1d5549ea2)

**🎯 变更类型**：功能增强  
**⚡ 重要程度**：🔴高  
**📋 变更摘要**：在 CI 中新增 CUDA 核心转储（coredump）收集机制。通过环境变量 `SGLANG_CUDA_COREDUMP` 启用后，会在进程启动时自动注入 CUDA 相关的 `CUDA_*` 环境变量，使 GPU 异常产生轻量级 coredump；CI workflow 末尾调用新的 composite action 将生成的转储文件上传为 artifacts 并清理临时目录。新增的 smoke test 用于验证整套流水线的可用性。

**🎯 影响范围**：  
- `python/sglang/srt/environ.py`（新增 env 变量）  
- `python/sglang/srt/debug_utils/cuda_coredump.py`（核心实现）  
- CI workflow 文件 `.github/workflows/nightly-test-nvidia.yml`、`.github/workflows/pr-test.yml`（多个 job 增加上传步骤）  
- 新增 GitHub Action `.github/actions/upload-cuda-coredumps`  
- 单元测试目录 `test/registered/debug_utils/test_cuda_coredump_smoke.py`

---

### 🔍 技术洞察

| 维度 | 影响描述 |
|------|----------|
| **架构影响** | - **模块化**：将 CUDA coredump 相关逻辑抽离到 `debug_utils.cuda_coredump`，保持业务代码的干净；<br>- **全局注入**：在 `environ._convert_SGL_to_SGLANG()` 中强制 import，使只要 `SGLANG_CUDA_COREDUMP=1`，所有进程都会自动开启转储，影响范围覆盖整个项目的 Python 入口。<br>- **CI 集成**：新增 composite Action，统一负责上传与清理，减少各 job 的重复配置。 |
| **性能影响** | - **启动开销**：创建 dump 目录、注入 4 条环境变量，几乎可以忽略。<br>- **异常时成本**：生成 coredump 需要复制 GPU 内存映射，会导致一次崩溃后的测试耗时显著增加（取决于 GPU 容量和 `CUDA_COREDUMP_GENERATION_FLAGS`），在大模型/大显存场景可能产生数百 MB‑GB 的文件。<br>- **CI 资源**：上传、存储和下载这些大文件会消耗网络带宽和存储配额。 |
| **安全考虑** | - **敏感信息泄露**：coredump 可能包含模型权重、显存中的输入数据等。当前直接作为 GitHub Artifacts 保存 7 天（可自定义），如果项目公开仓库，所有有权限下载 CI artifacts 的人员都能获取。<br>- **权限**：Workflow 使用默认 `permissions:`，未做额外限制；建议在 `upload-artifact` 步骤中限定 `permissions: read` 或仅对内部组织成员可见。 |
| **可维护性** | - **代码路径简洁**：核心逻辑仅 100 行，易于单独测试。<br>- **环境变量冲突**：若用户在本地或 CI 前已手动设置 `CUDA_*`，模块会跳过注入并记录警告，避免意外覆盖。<br>- **文档缺失**：目前未在 README 或 CI 文档中说明如何开启/关闭该功能，后续需要补充说明。 |

---

### ⚠️ 潜在风险

1. **磁盘/带宽耗尽**  
   - 大显存 GPU（如 H100 80GB）在崩溃时会生成巨大的转储文件，可能导致 runner 磁盘空间耗尽或 CI 上传超时。  
2. **泄露模型/数据**  
   - 转储中可能包含未加密的模型权重或用户数据，在公开仓库或共享 CI 环境下有泄密风险。  
3. **并发目录冲突**  
   - 虽然每个 job 都在独立的 runner 上执行，但如果同一 runner 被复用且 `SGLANG_CUDA_COREDUMP_DIR` 使用默认路径，旧的残余文件可能被误上传。  
4. **误触发导致误报**  
   - 在非 GPU 环境运行（CPU-only）时仍会导入模块，但 `is_enabled()` 为 `False`，不会产生影响；但若误将 `SGLANG_CUDA_COREDUMP=1` 设置在 CPU-only runner，可能导致不必要的目录创建和日志噪声。  
5. **CI 时长增加**  
   - 生成并上传 coredump 会延长每个失败 job 的执行时间，影响整体 pipeline 的吞吐。

---

### 💡 关注建议

| 建议 | 说明 |
|------|------|
| **限制启用范围** | 仅在需要调试的分支或特定 CI 任务中显式设置 `SGLANG_CUDA_COREDUMP=1`，避免在所有 nightly / PR 测试中默认开启。 |
| **压缩/分片上传** | 在 Action 中加入 `gzip` 或 `zstd` 对 `cuda_coredump_*` 文件进行压缩后再上传，显著降低存储和网络开销。 |
| **敏感信息脱敏** | 如有必要，可在生成 coredump 前通过 `CUDA_COREDUMP_GENERATION_FLAGS` 过滤掉 `global_memory`，只保留堆栈信息，以降低泄露风险。 |
| **存储策略** | 将 `retention-days` 默认调低（如 2 天），并在成功的 CI run 中通过 `if: failure()` 条件限制上传，仅在测试失败时才收集转储。 |
| **文档与警示** | 在项目 README、CONTRIBUTING 和 CI 文档中加入 “CUDA core dump” 功能的使用说明、风险提示以及如何手动清理本地目录的步骤。 |
| **监控磁盘使用** | 在 CI 前增加一步检查 `/tmp`（或自定义目录）剩余空间，如果低于阈值（如 5 GB）则直接跳过 coredump 步骤，防止 runner 失效。 |
| **安全权限** | 在 `upload-artifact` 步骤显式设置 `permissions: write-all`（或更细粒度）并在仓库的 **Settings → Actions → Artifact retention** 中限制可见范围，仅对内部成员可访问。 |
| **单元测试覆盖** | 为 `cuda_coredump.py` 添加更多单元测试，验证：<br>• 环境变量已正确注入<br>• 已存在的 `CUDA_*` 变量不会被覆盖<br>• `cleanup_dump_dir` 与 `report` 正常工作 |

--- 

**总结**：此次改动为 SGLang 引入了在 GPU 异常时自动生成并收集 CUDA core dump 的能力，极大提升了定位 GPU 相关崩溃的效率。技术实现简洁、可扩展，但因涉及大文件生成和潜在数据泄露，需要在 CI 中谨慎控制启用范围、存储时长以及权限。依据上述建议进行细化配置，可在保证调试价值的同时将风险降到最低。

---

### fix(glm-image): single-GPU T5 config + SP support for 4D latents (#18… (#18739)
**SHA**: `48fcd62` | 🔗 [查看提交](https://github.com/sgl-project/sglang/commit/48fcd62d1f60110a4656805468dbd38e20c12bef)

**🎯 变更类型**：功能增强 / Bug 修复  

**⚡ 重要程度**：🔴高  

**📋 变更摘要**  
1. 新增 `SpatialImagePipelineConfig`，使基于 4 维 latent（B, C, H′, W′）的图像管线在模型并行（SP）下能够沿高度维度切分/聚合，从而兼容单 GPU T5 编码器配置。  
2. 将 GLM‑Image 管线改为继承 `SpatialImagePipelineConfig`，并为其补充默认的 T5 文本编码器配置，解决因缺失 `parallel_folding` 参数导致的 `AttributeError`。  
3. 在 `glm_image.py` 的 forward 实现中加入对 prior hidden‑states 的高度切片，以保持在 SP 场景下与 sharded latent patches 的序列长度一致。  

**🎯 影响范围**  
- `python/sglang/multimodal_gen/configs/pipeline_configs/base.py`（新增 `SpatialImagePipelineConfig`）  
- `python/sglang/multimodal_gen/configs/pipeline_configs/glm_image.py`（管线改基类、默认 T5 配置）  
- `python/sglang/multimodal_gen/runtime/models/dits/glm_image.py`（forward 中 prior hidden‑states 切分）  

**🔍 技术洞察**  

- **架构影响**  
  - 引入了针对 **Spatial Parallelism (SP)** 的专属切分/汇聚逻辑，避免了原来基于 token‑style (B, S, C) 的切分路径不适用于 4D latent 场景。  
  - `SpatialImagePipelineConfig` 通过 `shard_latents_for_sp` 与 `gather_latents_for_sp` 把 sharding 维度从序列维度切换到空间维度（H′），从而在多 GPU 环境下实现 **height‑wise model parallelism**。  
  - `GlmImagePipelineConfig` 现在默认使用 `T5Config`（带 `parallel_folding`），保证在单 GPU 上也能正常实例化，不再回落到原生 T5 丢失权重的情况。  

- **性能影响**  
  - **正向**：在 SP 场景下，latent 按高度切分能够更均匀分配显存和计算负载，降低了每张卡的内存占用，提升了大分辨率图像的吞吐。  
  - **负向**：增加了额外的 **padding**（当 H′ 不能被 world size 整除时）以及 `torch.cat`、`contiguous` 操作，会产生一次小的拷贝开销；但相较于整体显存瓶颈，这一成本可忽略。  
  - 对 **单 GPU** 场景几乎无性能影响，因为 `sp_world_size <= 1` 时直接返回原始 latents。  

- **安全考虑**  
  - 代码仅涉及张量切分与聚合，未引入外部依赖或网络交互，安全风险极低。  
  - 需要确保 `sp_world_size` 与实际进程数保持一致，防止因配置错误导致的 **IndexError** 或 **隐式数据泄漏**（如部分数据未被聚合）。  

**⚠️ 潜在风险**  

1. **维度不匹配**：若在 SP 环境下 `prior_hidden_states` 未按相同的切分规则处理（例如模型层内部自行改变序列长度），会触发运行时报错或生成错误的图像。  
2. **Padding 引入的噪声**：在高度切分后进行 `torch.cat` 的 zero‑padding 可能在后续的卷积或注意力层中产生额外的虚假特征，需要在 `gather_latents_for_sp` 前确保 downstream 层能够安全忽略这些 padding（当前实现依赖 `contiguous`，但未显式 mask）。  
3. **多进程同步**：`sequence_model_parallel_all_gather` 必须在所有 SP 进程上同步调用，否则会导致死锁或不完整的聚合结果。  
4. **兼容性**：老版本的配置文件仍可能引用旧的 `ImagePipelineConfig`，在升级后如果未显式改为 `SpatialImagePipelineConfig`，可能仍走基于 token 的切分路径，导致潜在的显存溢出。  

**💡 关注建议**  

- **测试覆盖**：在 CI 中加入 **SP‑enabled** 的单元测试，验证 `shard_latents_for_sp`、`gather_latents_for_sp` 与 `forward` 中 prior 切分的正确性（包括不同 `sp_world_size`、不可整除的 H′ 场景）。  
- **Mask Padding**：在 latent 进入下游层前，加入可选的 `latent_mask`，在需要时屏蔽 zero‑padding 区域，防止其对注意力计算产生影响。  
- **配置校验**：在 pipeline 初始化时检测 `sp_world_size` 是否与实际进程数匹配，并在不匹配时抛出明确的错误提示。  
- **文档更新**：补充使用 SP 的最佳实践文档，说明何时需要切换到 `SpatialImagePipelineConfig`，以及在单 GPU 与多 GPU 环境下的行为差异。  
- **回滚路径**：保留旧的 `ImagePipelineConfig` 作为 fallback，确保在不需要 SP 或者出现异常时能够安全回退，不影响已有模型的部署。

---

### [3/N] Quantization Refactor: ModelSlim MoE schemes (#17993)
**SHA**: `aeca7d3` | 🔗 [查看提交](https://github.com/sgl-project/sglang/commit/aeca7d348c6bce7af5ae8eb198f07be495f49295)

**🎯 变更类型**：重构 / 功能增强  
**⚡ 重要程度**：🔴高  

**📋 变更摘要**  
本次提交对 ModelSlim 量化框架进行大幅重构，拆分了线性层与 MoE（Mixture‑of‑Experts）层的抽象基类，新增 `ModelSlimLinearScheme` 与 `ModelSlimMoEScheme`，并实现了对应的 W4A8/W8A8 Int8 MoE 方案。`ModelSlimFusedMoEMethod` 取代此前的 `ModelSlimMoEMethod`，统一通过 scheme 完成权重创建、后处理及前向计算，使量化路径更加模块化、可扩展。

**🎯 影响范围**  
- `python/sglang/srt/layers/quantization/modelslim/`（核心量化实现）  
- `modelslim/modelslim.py`（QuantizationConfig 与 get_quant_method）  
- `modelslim/schemes/`（新增/调整的 scheme 抽象与实现）  
- 依赖 `sglang.srt.layers.moe` 的 FusedMoE 相关代码  
- 相关的 `base_config`, `hardware_backend` 以及 `utils` 模块  

**🔍 技术洞察**  

- **架构影响**  
  - 将原有的单一 `ModelSlimScheme` 拆分为线性与 MoE 两套抽象，符合单一职责原则，提升了代码可维护性和未来扩展空间。  
  - `ModelSlimFusedMoEMethod` 通过 `layer.scheme` 完成所有操作，消除之前在 `ModelSlimMoEMethod` 中的硬编码分支，层次更加清晰。  
  - 引入 `TYPE_CHECKING` 导入，降低运行时循环依赖风险。  

- **性能影响**  
  - 新增的 MoE scheme 直接复用了底层 NPU 实现 (`NPUW4A8Int8DynamicMoEMethod` / `NPUW8A8Int8DynamicMoEMethod`)，不引入额外的 Python 计算开销。  
  - 通过显式的 `process_weights_after_loading`、`create_weights` 与 `apply_weights` 调用顺序，避免在 forward 时重复进行权重转换，理论上可保持或略微提升量化模型的推理吞吐。  
  - 代码路径的分离有助于后续对不同 scheme 做细粒度的性能基准。  

- **安全考虑**  
  - 新增的抽象层没有暴露新的外部接口，仅在内部使用 `layer.scheme`，不影响已有的 API 边界。  
  - 仍旧依赖底层 NPU kernel，若 kernel 存在安全漏洞则影响相同；本次改动未引入新的安全风险。  

**⚠️ 潜在风险**  

1. **兼容性回退**：旧的 `ModelSlimMoEMethod` 被删除，若外部代码仍直接引用（例如自定义量化插件），会触发 `ImportError`。  
2. **Scheme 选择逻辑**：`get_moe_scheme` 只判断 `W4A8_DYNAMIC` 与 `W8A8_DYNAMIC`，未覆盖 `STATIC` 或其它自定义量化类型，可能导致 `None` 被返回并在后续抛出异常。  
3. **类型检查遗漏**：`ModelSlimFusedMoEMethod.apply` 中未对 `dispatch_output` 做显式校验，若上层传入不符合 `StandardDispatchOutput` 结构的对象，可能导致运行时错误。  
4. **权重后处理**：`process_weights_after_loading` 现在由 scheme 负责，若某些旧模型的权重元数据与新 scheme 不匹配（比如缺少 scale/offset），可能出现未初始化的参数。  

**💡 关注建议**  

- **回归测试**：在支持的硬件（NPU）上运行完整的量化模型推理基准，覆盖线性层、FusedMoE（W4A8/W8A8）以及未量化的路径，确保功能等价。  
- **向后兼容**：提供一个兼容层（例如在 `modelslim.py` 中保留 `ModelSlimMoEMethod` 的别名）或在发布说明中明确迁移指南。  
- **配置校验**：在 `get_moe_scheme` 中加入对未知量化类型的显式异常或回退至默认方案，避免 `None` 导致的难以定位的错误。  
- **文档更新**：更新 quantization config 文档，说明支持的 MoE scheme 名称以及对应的 `quant_description` 键格式。  
- **持续监控**：在 CI 中加入对 `ModelSlimFusedMoEMethod` 的单元测试，确保 `layer.scheme` 在每种路径下均被正确初始化。  

通过以上措施，可最大化本次重构带来的可维护性和可扩展性收益，同时降低因接口变更导致的生产风险。

---

#### 🟡 中重要度变更 (7)

### [diffusion] fix: refactor task resolution logic in benchmark function for multimodal generation (#18948)
**SHA**: `eb6ff4a` | 🔗 [查看提交](https://github.com/sgl-project/sglang/commit/eb6ff4a94004ccb9d55d8d5c10ffb8b5f94e8e57)

**🎯 变更类型**：重构 / Bug 修复  
**⚡ 重要程度**：🟡 中  
**📋 变更摘要**：在 `bench_serving.py` 中重构了基准测试的任务解析逻辑。现在先按 `--task` 参数、再本地 `config.json`、最后 HuggingFace `pipeline_tag` 的顺序确定任务，并加入合法任务校验与详细日志。  
**🎯 影响范围**：`python/sglang/multimodal_gen/benchmarks/bench_serving.py`（多模态生成基准），以及依赖该入口的 CLI 脚本和 CI 测试。  

**💡 关注建议**  
1. **缺少 `json` 导入**：重构后 `json` 只在局部块使用，却未显式 `import json`，会抛出 `NameError`。请在文件顶部或相应代码块加入 `import json`。  
2. **兼容性**：原实现会在 `args.task` 与模型标记不一致时给出警告并使用模型默认；新版直接采用 `args.task`（若提供）并不再提示，可能导致用户误以为已生效。建议保留警告或在日志中提醒。  
3. **任务列表**：`valid_tasks` 仅列出五种任务，若未来模型新增其它 multimodal pipeline（如 `audio-to-video`），当前实现会直接报 `ValueError`。可考虑将合法任务抽取为配置项或从 HF 元数据动态获取。  
4. **文档/帮助信息**：CLI `--task` 的可选值应同步更新，避免用户因参数错误而中断。  
5. **测试覆盖**：新增单元测试，验证三种任务来源（参数、本地 config、HF tag）以及非法任务错误路径。  

总体而言，改动提升了任务解析的明确性与可调试性，但需修复 `json` 导入并注意向后兼容性。

---

### Remove unused fast-hadamard-transform PyTorch extension sources (#18927)
**SHA**: `513c12d` | 🔗 [查看提交](https://github.com/sgl-project/sglang/commit/513c12d23f349f62afa02c7b57ebe6f07052e1c5)

**变更概览**  
本次提交删除了 `python/sglang/jit_kernel/csrc/fast-hadamard-transform/` 目录下的全部 C++/CUDA 源文件（`fast_hadamard_transform.cpp` 与 `fast_hadamard_transform_cuda.cu`），共计 773 行代码。对应的 PyTorch‑extension 编译入口已不再存在，属于 **功能清理**（去除未被使用的 Fast‑Hadamard‑Transform 实现）。

**影响范围**  
- **构建系统**：`setup.py`/`CMakeLists.txt` 中若仍列出该目录的源文件，会导致编译错误。  
- **Python 接口**：`python/sglang/jit_kernel/__init__.py` 或其他模块若仍 `import fast_hadamard_transform`，将抛出 `ImportError`。  
- **模型/脚本**：搜索全库发现只有 `fast_hadamard_transform` 的调用被注释或已迁移到其它实现（如 `torch.nn.functional`），因此对运行时影响有限。  
- **测试套件**：任何依赖该扩展的单元测试或基准将失效，需要删除或改为使用替代实现。  

**建议**  
1. **检查构建脚本**：确认 `setup.py`、`CMakeLists.txt`、`pyproject.toml` 中已移除对应的 `src` 条目，防止“找不到文件”编译失败。  
2. **清理 Python 包装层**：在 `sglang/jit_kernel` 或相关目录中删除对 `fast_hadamard_transform` 的 `pybind11` 导出及 `import` 语句。若有文档示例，请同步更新。  
3. **全局搜索**：使用 `grep -R "fast_hadamard_transform"` 确认没有残留调用；若有业务逻辑依赖，需要提供替代实现或在 README 中标注已不再支持。  
4. **运行完整 CI**：包括 CPU 与 CUDA 测试，确保删除的代码未被间接引用（例如在自定义 ops 注册表中）。  
5. **更新发布说明**：注明 “移除未使用的 Fast‑Hadamard‑Transform 扩展，减小编译体积”，并提醒用户在自定义扩展上自行实现时需另行添加。  

通过上述检查，项目在编译、运行和文档层面都能平滑过渡到没有该扩展的状态。

---

### [Refactor] Fix test and clean up hicache code (#18555)
**SHA**: `9d13868` | 🔗 [查看提交](https://github.com/sgl-project/sglang/commit/9d138685c1c083321638f5594a4600631c56594a)

**🎯 变更类型**：功能增强 / 重构  
**⚡ 重要程度**：🟡 中  

**📋 变更摘要**  
1. **benchmark/bench_hicache.py**  
   - 新增 `HiCacheCache`、`gen_indices` 并在全局预分配一次性大 cache，避免每轮 `torch.randn` 带来的波动。  
   - 引入可调超参数（`PAGE_SIZE`、`ENABLE_SORT`、`GPU/HOST_CACHE_SIZE`、`NUM_LAYERS`）以及 `DISABLE_TORCH` 环境开关；删除了慢速的 `torch_streams` 基线。  
   - 对所有层的传输通过循环调用单层 kernel，实现“一次性”基准并统一计时；对索引做排序以提升 Host 访问命中率。  

2. **csrc/hicache.cuh**  
   - 将原 `device::warp` 实现简化为 `device` 命名空间，使用 `SGL_DEVICE`、`SGL_HICACHE_KERNEL` 宏统一标记。  
   - 采用 `AlignedStorage` 与 `load_vec/store_vec` 的新模板，实现 128‑byte 对齐、线程数/块大小可调的向量化加载/存储，移除不必要的 `concepts`、`cstddef` 依赖。  
   - 参数结构体 `HicacheKernelParams` 中 `length`、`kv_cache_*_stride` 改为 `uint32_t / int64_t`，并调整字段顺序，以匹配新版 kernel 调用。  
   - `HiCacheKernel` 中 `run_one/run_all` 统一使用 `kernel_one/kernel_all`，去掉了 `occupancy` 参数，默认 `num_threads = 1024`，并在 `can_use_hicache_jit_kernel` 中加入对 `element_size % 128 == 0` 的检查。  

**🎯 影响范围**  
- **benchmark**：`bench_hicache.py`、`jit_kernel/benchmark/utils.py`（使用了新 env 变量）。  
- **kernel**：`jit_kernel/csrc/hicache.cuh`、`jit_kernel/hicache.py`（API 变更）。  
- 可能波及 **tests**、**benchmark scripts** 以及任何直接调用 `transfer_hicache_one_layer`/`transfer_hicache_all_layer` 的上层代码。  

**💡 关注建议**  
1. **兼容性**：`HicacheKernelParams` 参数类型从 `size_t` 改为 `uint32_t/int64_t`，调用方需同步更新（尤其是 Python‑C++ 边界的 `tvm::ffi::TensorView` 包装）。  
2. **元素大小限制**：JIT kernel 现在仅在 `element_size` 能被 128 整除时生效，确保上游代码在调用前检查或提供回退路径（如使用 AOT kernel）。  
3. **内存使用**：全局 `HiCacheCache` 按 `NUM_LAYERS * (GPU/HOST_CACHE_SIZE)` 预分配，约 256 K + 512 K tokens * `bfloat16`，请确认机器有足够显存和主机内存。  
4. **基准结果**：排序和预分配会显著降低噪声，若对比历史数据，请注意已去除 `torch_streams` 基线以及 `DISABLE_TORCH` 开关的默认行为。  
5. **文档/脚本**：在 README 或 benchmark 使用说明中加入 `DISABLE_TORCH`、`PAGE_SIZE`、`ENABLE_SORT` 的解释；确保 CI 环境设置了足够的 GPU 资源以跑完整的 8‑layer 基准。  

总体来看，此次重构提升了基准的可重复性和 JIT kernel 的实现简洁度，但引入了 API 更改和对 element‑size 的硬性约束，建议在合并前补全兼容层测试并更新相关文档。

---

### Expose priority parameter in Engine.generate() and Engine.async_generate() (#18944)
**SHA**: `83e24e2` | 🔗 [查看提交](https://github.com/sgl-project/sglang/commit/83e24e2eb434df20031c511230d849d4f27bafd3)

**变更类型**：功能增强  
**重要程度**：🟡 中  

**变更摘要**：在 `EngineBase.generate`、`engine.generate`、`engine.async_generate` 以及 HTTP 接口中新增 `priority` 参数，并在请求对象构造时向下传递，以便在调度层面支持优先级控制。  

**影响范围**：  
- `python/sglang/srt/entrypoints/EngineBase.py`（抽象基类）  
- `python/sglang/srt/entrypoints/engine.py`（具体实现）  
- `python/sglang/srt/entrypoints/http_server_engine.py`（HTTP 调用入口）  

**关注建议**  

1. **兼容性**：新增参数默认 `None`，保持现有调用不受影响。但若后端调度器未实现 `priority` 处理，传递此字段可能导致未知错误。建议在调用前校验 `priority` 是否为正整数，或在文档中明确未实现时会被忽略。  

2. **输入校验**：当前仅在签名中加入 `priority`，未对其进行类型或范围检查。建议在 `engine.generate`/`async_generate` 入口做 `isinstance(priority, int) and priority >= 0` 的断言，并在非法时抛出易懂的 `ValueError`。  

3. **下游传播**：`priority` 已加入 `GenerateReqInput` 的构造参数，但需确认 `sglang/srt/managers/io_struct.py` 中对应字段是否已定义，否则会出现 `TypeError`。若尚未加入，需要同步修改该结构体并在调度器中使用。  

4. **文档与示例**：更新 README、API 文档及示例代码，说明 `priority` 的取值意义、默认行为以及对吞吐/延迟的潜在影响。  

5. **测试覆盖**：新增单元测试，覆盖以下场景：  
   - `priority=None`（保持原行为）  
   - 合法整数优先级（验证字段被正确传递）  
   - 非法类型/负数（抛出异常）  
   - HTTP 接口 `POST /generate` 带 `priority` 时的请求体过滤。  

6. **日志与监控**：如果调度器使用优先级做排队，建议在日志中记录每个请求的 `priority`，便于后续性能分析。  

7. **并发安全**：若调度器内部依据 `priority` 进行队列重排，确认该操作在多线程/多进程环境下是线程安全的，避免出现竞态。  

**总体评价**：本次改动合理地对外暴露了优先级控制入口，为后续调度策略提供了扩展点。只要补齐输入校验、结构体同步以及文档/测试，即可安全合并。

---

### Fix eval tests not capturing server launch failures (#18886)
**SHA**: `34d975b` | 🔗 [查看提交](https://github.com/sgl-project/sglang/commit/34d975b18fa5a01b0950735faac85b79dc57507b)

**🎯 变更类型**：功能增强 / Bug 修复  
**⚡ 重要程度**：🟡 中  

**📋 变更摘要**  
1. `ci_weight_validation.py` 将下载锁机制从 `fcntl.flock` 改为 `filelock.FileLock`，并加入 `cache_dir` 参数，使锁文件能够放在共享的 HF 缓存目录（NFS）上，从而在多容器 CI 环境下避免 `.incomplete` 冲突。  
2. 增加对已有缓存的二次检查、预清理 stale `.incomplete` 文件、加大重试间隔（10 s、20 s、40 s），提升下载可靠性。  
3. 测试层面统一使用 `process = None` 防止空指针，提升异常安全；为 Nightly‑Eval 加长服务器启动超时至 1800 s，避免因大模型下载慢导致测试失败。  

**🎯 影响范围**  
- `python/sglang/srt/model_loader/ci_weight_validation.py`（模型权重下载 & CI 相关逻辑）  
- `python/sglang/test/nightly_utils.py`、`test/registered/eval/test_text_models_gsm8k_eval.py`、`test/registered/eval/test_vlms_mmmu_eval.py`（CI 测试脚本）  

**💡 关注建议**  
- 确认 `filelock` 已列入 `requirements.txt`，否则 CI 环境会因缺失依赖报错。  
- 检查所有调用 `ci_download_with_validation_and_retry` 的位置是否需要显式传入 `cache_dir`（默认使用 `HF_HUB_CACHE`），避免出现 “None” 导致锁文件仍落在 `/dev/shm`。  
- 注意 NFS 上的目录权限，`.sglang_locks` 需要可写；若在只读缓存场景，回退到 `/dev/shm`/`/tmp` 仍能正常工作。  
- 评估新增的 1800 s 超时对 Nightly‑Eval 总时长的影响，必要时在 CI 配置中适当上调整体超时限制。  

总体来说，此次改动显著提升了 CI 环境下模型下载的鲁棒性，兼容多容器共享缓存，同时对测试用例做了安全性加强，风险主要集中在新依赖和锁文件目录的可写性上。

---

### Refactor sampler: Use a better hash function for deterministic sampling and clear dispatch for probs/logprobs/logits sampling paths (#18915)
**SHA**: `e02a9be` | 🔗 [查看提交](https://github.com/sgl-project/sglang/commit/e02a9bec8d9cc02ffd867b58a8edb33fe4ae880a)

**🎯 变更类型**：功能增强 / 重构  
**⚡ 重要程度**：🟡 中  

**📋 变更摘要**  
1. 为 `Sampler` 引入更可靠的哈希函数 `murmur_hash32`，用于 deterministic sampling（通过 Gumbel‑trick 实现）并统一采样路径。  
2. 重构采样逻辑：  
   - 新增 `use_log_softmax_logprob`、`enable_deterministic`、`use_ascend_backend` 等开关，明确 RL‑on‑policy、Ascend NPU、原始 logprob 等模式。  
   - 将概率‑、logprob‑、logits‑采样分别抽象为 `_sample_from_probs`、`_sample_from_logprobs`、`_sample_from_logits`，并在 Ascend 后端走专用 `_forward_ascend_backend`。  
   - 统一 `return_logprob` 的处理，加入 `SGLANG_RETURN_ORIGINAL_LOGPROB` 支持，避免不必要的 `log`/`softmax`。  
3. 新增 `sglang/srt/layers/utils/hash.py`，实现基于 Triton 的 MurmurHash 32 位，以提升跨设备（GPU/Ascend/NPU） deterministic seed 的散列质量。  
4. `send_one.py` CLI 支持 `--seed`，可把种子直接传给后端的 `sampling_seed` 参数。  

**🎯 影响范围**  
- `sglang/srt/layers/sampler.py`（核心采样路径）  
- `sglang/srt/layers/utils/hash.py`（全新哈希实现）  
- 采样相关测试/benchmark 脚本 `test/send_one.py`  
- 相关配置 `server_args`（新增 `rl_on_policy_target`、`sampling_backend`、`enable_deterministic_inference`）  

**💡 关注建议**  
1. **确定性验证**：在多 GPU/TP（尤其是 XPU）环境下运行带种子的大批量推理，检查 `batch_next_token_ids` 在不同节点是否完全一致；若仍出现不一致，请确认 `SYNC_TOKEN_IDS_ACROSS_TP` 环境变量是否需要开启。  
2. **性能基准**：对比原始 `sampling_from_probs_torch`、`top_k_top_p_min_p_sampling_from_probs_ascend` 与新的路径（尤其是 Ascend 后端），确认额外的 `log_softmax`、`torch.log` 计算没有显著拖慢吞吐。  
3. **数值稳健**：`multinomial_with_seed` 中使用 `float64` 进行 Gumbel 采样，建议在高吞吐场景下评估 GPU memory/带宽占用；若出现 OOM，可考虑在 `logprobs` 已是 `float32` 时直接使用 `float32`（保持误差在可接受范围）。  
4. **接口兼容**：`Sampler.__init__` 新增属性在旧版本配置文件中缺失时会使用默认 `None`，但外部代码若直接访问 `self.use_ascend_backend` 需确保已导入新版 `server_args`。  
5. **测试覆盖**：补充单元测试，覆盖以下组合：  
   - `simple_sampling_case` + `return_logprob`（原始 vs. 经过 softmax）  
   - `rl_on_policy_target` + `enable_deterministic` + `sampling_backend=ascend`  
   - `SYNC_TOKEN_IDS_ACROSS_TP` 打开/关闭的多 TP 场景  
6. **文档更新**：在 README / Sampler 参数说明中补充 `sampling_seed`、`rl_on_policy_target`、`sampling_backend` 的作用与取值范围，避免用户误以为 `temperature=0` 已足够确定性。  

总体而言，改动显著提升了确定性抽样的可控性和后端兼容性，但需要通过多平台回归测试确保新哈希与 Gumbel‑trick 在极端并行环境下不产生随机漂移。

---

### cleanup prefill metrics logging to fix dp-attn metrics (#18778)
**SHA**: `9a7d6be` | 🔗 [查看提交](https://github.com/sgl-project/sglang/commit/9a7d6be56775307bada7cadc5513cea733feccf7)

**🎯 变更类型**：功能增强 / 代码清理  
**⚡ 重要程度**：🟡 中  
**📋 变更摘要**：本次 PR 将原先分散在 `maybe_prepare_mlp_sync_batch_and_log_stats` 中的预填充（prefill）统计记录逻辑统一到 `log_prefill_stats`，去除 `log_prefill_stats_late` 辅助函数；同时在 `SchedulerMetricsMixin` 与 `MetricsCollector` 中引入 `DPCooperationInfo`，把 DP‑Attention 合作信息（多少 rank 正在做 extend）计入实时 token 统计。相关调用处统一改为 `maybe_prepare_mlp_sync_batch`，并在 `process_batch_result_*` 流程中把 `batch.dp_cooperation_info` 透传给统计接口。

**🎯 影响范围**  
- `sglang/srt/disaggregation/*`（decode、prefill）  
- `sglang/srt/managers/*`（scheduler、dp_attn_mixin、pp_mixin、output_processor_mixin、scheduler_metrics_mixin）  
- `sglang/srt/metrics/collector.py`（DP 合作信息、实时 token 计数）  

**💡 关注建议**  

1. **日志/监控兼容性**：去掉 `log_prefill_stats_late` 后，原来依赖该函数的外部监控脚本需检查是否仍然能获取 `prefill_compute_tokens`、`prefill_cache_tokens`。建议在发布说明中明确迁移步骤。  
2. **DP‑Attention 统计准确性**：`DPCooperationInfo.create` 现在通过 `ForwardMode.is_extend()` 判断 “extend” 工作，确保所有自定义 `ForwardMode` 实现了该属性，否则会出现统计缺失。建议添加单元测试覆盖不同 `forward_modes` 场景。  
3. **性能影响**：`increment_realtime_tokens` 过滤了 `delta == 0`，可略微降低指标上报开销；但因为 `maybe_prepare_mlp_sync_batch` 调用频率提升，需关注是否引入额外的同步成本。建议在高并发 DP‑Attention 场景下跑基准，确认延迟未回退。  
4. **回退路径**：若业务方仍需要旧的 “late” 统计，可考虑在 `SchedulerMetricsMixin` 中保留兼容入口（如 `log_prefill_stats_late` 只做一次转发），避免突发行为变更。  
5. **文档/注释**：`maybe_prepare_mlp_sync_batch` 参数 `need_sync` 语义未变，仍需在代码注释中说明它同时负责“统计”与“同步”两件事，防止后续开发者误删或误改。  

总体来看，此次改动将预填充统计与 DP‑Attention 合作度合并，代码更简洁、指标更完整，只要注意上述兼容性与测试覆盖，即可安全上线。

---

#### 🟢 低重要度变更 (12)

### Add DP ViT support for Kimi K2.5 (#18689)
**SHA**: `5a7ae05` | 🔗 [查看提交](https://github.com/sgl-project/sglang/commit/5a7ae059e37f2c481462a2ad965467264718c461)

**🎯 变更类型**：代码重构  
**⚡ 重要程度**：🟢 低  
**📋 摘要**：为 Kimi K2.5 引入分布式数据并行（DP）ViT 支持，新增 `use_data_parallel` 参数并通过全局服务器配置开启，使用 `run_dp_sharded_mrope_vision_model` 进行并行视觉特征抽取。

---

### [AMD] ROCm7.2: Add /sgl-workspace/aiter to PYTHONPATH (#18972)
**SHA**: `0215d47` | 🔗 [查看提交](https://github.com/sgl-project/sglang/commit/0215d470070621cddf32483cbede5a8b5bab2742)

**🎯 变更类型**：其他（代码改动）  
**⚡ 重要程度**：🟢 低  
**📋 摘要**：在 `docker/rocm720.Dockerfile` 中，构建完成后添加一行将 `/sgl-workspace/aiter` 写入 `PYTHONPATH`，以便在容器内部自动加载该路径下的 Python 包。

---

### Enable fa3 PDL by compiling it with corresponding flags (#18756)
**SHA**: `90d5e27` | 🔗 [查看提交](https://github.com/sgl-project/sglang/commit/90d5e27f795de9fe86704ff7335ec93c6a9fc0d9)

**🎯 变更类型**：配置调整  
**⚡ 重要程度**：🟢低  
**📋 摘要**：在 `sgl-kernel/CMakeLists.txt` 为 FA3 PDL 添加 `-DCUTLASS_ENABLE_GDC_FOR_SM90` 与 `-DCUTE_SM90_EXTENDED_MMA_SHAPES_ENABLED` 编译标志，启用 SM90 的 WGMMA 形状支持。

---

### [Tiny fix] Super tiny fix mul_add naive forward bug (#18964)
**SHA**: `390c154` | 🔗 [查看提交](https://github.com/sgl-project/sglang/commit/390c154306162b20ab9d98c4268bbecac83bb690)

**🎯 变更类型**：代码重构  
**⚡ 重要程度**：🟢低  
**📋 摘要**：在 `elementwise.py` 的 `forward_native` 中，将原本的 `a * b` 修正为 `a * (k + b)`，纠正了 mul_add naive 前向计算的错误。

---

### Reasoning models fix docs (#18963)
**SHA**: `934b366` | 🔗 [查看提交](https://github.com/sgl-project/sglang/commit/934b36693c03ba6ecdce55ae115de132ff50b4bb)

**🎯 变更类型**：文档更新  
**⚡ 重要程度**：🟢低  
**📋 摘要**：在 `evaluating_new_models.md` 中的提示文字去掉了 `deepseek‑r1` 示例，仅保留 `deepseek‑v3`，更新说明更准确。

---

### [feat] Add return_routed_experts param to async_generate for parity with generate (#18508)
**SHA**: `95c44ce` | 🔗 [查看提交](https://github.com/sgl-project/sglang/commit/95c44cea2945ee80f1b174fdbb88205b1556c14f)

**🎯 变更类型**：代码重构  
**⚡ 重要程度**：🟢低  
**📋 摘要**：在 `async_generate` 中新增 `return_routed_experts` 参数，并将其向内部调用传递，实现与同步 `generate` 接口的功能对齐。

---

### Revert "Fix generated-shared-prefix bench_serving" (#18956)
**SHA**: `2d85f01` | 🔗 [查看提交](https://github.com/sgl-project/sglang/commit/2d85f01d43aeaee0d6b6bb9254c001506b59148e)

**🎯 变更类型**：代码重构  
**⚡ 重要程度**：🟢 低  
**📋 摘要**：将 `compute_random_lens` 的返回类型从 `np.ndarray` 改为 `List[int]`，并在生成随机整数后使用 `.tolist()` 转换为 Python 列表。函数签名相应更新为 `List[int]`。

---

### Fix benchmark_sglang_fused_moe_triton.py (#18940)
**SHA**: `355127c` | 🔗 [查看提交](https://github.com/sgl-project/sglang/commit/355127c2e98e5bf62d22f4d814796891b47e86ab)

**🎯 变更类型**：代码重构  
**⚡ 重要程度**：🟢低  
**📋 摘要**：在 benchmark 脚本中引入 `TopKOutputFormat` 与全局服务器参数初始化，调整 MoE 调度配置以兼容 Triton kernel。

---

### Fix generated-shared-prefix bench_serving (#18769)
**SHA**: `3c601db` | 🔗 [查看提交](https://github.com/sgl-project/sglang/commit/3c601db0312abf824c3aa8523183c138a32b3f53)

**🎯 变更类型**：代码重构  
**⚡ 重要程度**：🟢低  
**📋 摘要**：将 `compute_random_lens` 的返回类型从 `List[int]` 改为 `np.ndarray`，去除 `.tolist()`，简化实现。

---

### [diffusion] update code owner (#18495)
**SHA**: `10569d0` | 🔗 [查看提交](https://github.com/sgl-project/sglang/commit/10569d04bb2028f74ef453011ec66487b940ec4a)

**🎯 变更类型**：配置调整  
**⚡ 重要程度**：🟢低  
**📋 摘要**：更新 `.github/CODEOWNERS`，为 `multimodal_gen` 及其子目录新增 `@ping1jing2` 代码所有者。简化代码所有权管理。

---

### [gRPC] Fix scheduler startup broken by context parallel refactor (#18933)
**SHA**: `bf08d3f` | 🔗 [查看提交](https://github.com/sgl-project/sglang/commit/bf08d3f43c3d8a62dd1c9f8f4044b19e6a2afb2c)

**🎯 变更类型**：代码重构  
**⚡ 重要程度**：🟢低  
**📋 摘要**：在 `scheduler_launcher.py` 中新增注意力 CP、MoE DP、MoE EP 等并行度计算，并将相应参数传递给调度器进程，修复因上下文并行重构导致的启动问题。

---

### [diffusion] improve: improve torch.compile for MOVA (#18914)
**SHA**: `504b2c5` | 🔗 [查看提交](https://github.com/sgl-project/sglang/commit/504b2c58cf94db16813745383dc71750a4a816aa)

**🎯 变更类型**：代码重构  
**⚡ 重要程度**：🟢低  
**📋 摘要**：在 `mova.py` 中引入 `torch.nn.Module` 类型注解，并将原先的 `compile_module_with_torch_compile` 重构为 `_maybe_enable_torch_compile`，统一使用 `module.compile()`，加入对 `torch.compile` 开关和模块类型的检查，同时对设备管理函数的类型标注做了微调。整体提升编译逻辑的可读性与安全性。

---

