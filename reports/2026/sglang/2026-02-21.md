# æ¯æ—¥æ›´æ–°æŠ¥å‘Šï¼ˆ2026-02-21ï¼‰

## sgl-project/sglang

| æäº¤æ—¶é—´ | ä½œè€… | æäº¤ä¿¡æ¯ |
|----------|------|----------|
| 2026-02-21 23:40:56 | Bi Xue | [sgl] view could hold the memory too long and introduced large memory (#19109) |
| 2026-02-21 22:13:08 | Xinyuan Tong | fix KimiK2Detector regex patterns with re.DOTALL (#19120) |
| 2026-02-21 22:07:09 | Xinyuan Tong | fix tool handling in OpenAIServingChat (#18996) |
| 2026-02-21 21:41:47 | Xiaoyu Zhang | [Diffusion] Restruct and clean Diffusion rotary embedding (#19064) |
| 2026-02-21 21:32:40 | DarkSharpness | [Feature] rewrite rope kernel; remove flashinfer dependencies (#18844) |
| 2026-02-21 21:22:47 | Mick | [diffusion] feat: support passing component path via server args (#19108) |
| 2026-02-21 20:14:31 | Baizhou Zhang | Tiny update pull-requests permission of release-branch-cut.yml (#19121) |
| 2026-02-21 19:37:38 | Xinyuan Tong | [FEAT] Add Anthropic compatible API endpoint (#18630) |
| 2026-02-21 16:35:47 | Mick | [diffusion] refactor: reduce redundancy and improve stage api (#19060) |
| 2026-02-21 16:14:29 | danielafrimi | [Quantization] Support config.json quantization_config format, fix exclude_modules matching, and fix KV cache scale loading for Nemotron (#18546) |
| 2026-02-21 12:28:00 | èµµæ™¨é˜³ | Remove error dllm and diffusion doc in basic_useage (#19105) |
| 2026-02-21 11:51:28 | Nicolas Castet | Fix bug in symm mem pre-allocation default (#19082) |
| 2026-02-21 11:10:34 | Vladislav Nosivskoy | [DSv32] Fix MTP and CP compatability (#19062) |
| 2026-02-21 10:27:31 | Lianmin Zheng | [Auto Sync] Update batch_invariant_ops.py (20260221) (#19098) |
| 2026-02-21 10:19:14 | Lianmin Zheng | [Auto Sync] Update bench_one_batch_server_internal.py (20260221) (#19097) |
| 2026-02-21 10:09:31 | Cheng Wan | Refactor graph input buffers (#18991) |
| 2026-02-21 07:51:53 | HAI | Upd: CODEOWNERS (#19055) |
| 2026-02-21 06:16:57 | Minglei Zhu | [GPT-OSS] support fp8 online quantization for gpt-oss bf16 (#18988)<br>merge it as all required CI passed |
| 2026-02-21 05:33:10 | Qiaolin Yu | Add generated-shared-prefix dataset in bench_one_batch (#18986) |
| 2026-02-21 01:39:29 | 0xNullPath | [feat] feat: support swa in trtllm_mha (#18970) |
| 2026-02-21 00:45:55 | billishyahao | [AMD] support two batch overlapping for mori ep (#17953) |

### ğŸ“Š ç»Ÿè®¡æ‘˜è¦
> æœ¬æ—¥å…± 21 ä¸ªæäº¤ | ğŸ”´é«˜ 6 | ğŸŸ¡ä¸­ 5 | ğŸŸ¢ä½ 10
## ğŸ“‹ ç›®å½•

- [sgl-project/sglang](#sgl-project-sglang)
  - [ğŸ“Š ç»Ÿè®¡æ‘˜è¦](#-ç»Ÿè®¡æ‘˜è¦)
  - [ğŸ”´ é«˜é‡è¦åº¦å˜æ›´ (6)](#-ğŸ”´-é«˜é‡è¦åº¦å˜æ›´-6)
    - [[Diffusion] Restruct and clean Diffusion rotary embedding...](#66497ab)
    - [[Feature] rewrite rope kernel; remove flashinfer dependen...](#d8d0208)
    - [[FEAT] Add Anthropic compatible API endpoint (#18630)](#cc45167)
    - [[diffusion] refactor: reduce redundancy and improve stage...](#b89ca65)
    - [Refactor graph input buffers (#18991)](#84c67c8)
    - [[AMD] support two batch overlapping for mori ep (#17953)](#fbb6098)
  - [ğŸŸ¡ ä¸­é‡è¦åº¦å˜æ›´ (5)](#-ğŸŸ¡-ä¸­é‡è¦åº¦å˜æ›´-5)
    - [fix tool handling in OpenAIServingChat (#18996)](#4a362a0)
    - [[diffusion] feat: support passing component path via serv...](#6503f94)
    - [[Quantization] Support config.json quantization_config fo...](#33c33a7)
    - [Add generated-shared-prefix dataset in bench_one_batch (#...](#96bae23)
    - [[feat] feat: support swa in trtllm_mha (#18970)](#ab18734)
  - [ğŸŸ¢ ä½é‡è¦åº¦å˜æ›´ (10)](#-ğŸŸ¢-ä½é‡è¦åº¦å˜æ›´-10)
    - [[sgl] view could hold the memory too long and introduced ...](#bf36aa4)
    - [fix KimiK2Detector regex patterns with re.DOTALL (#19120)](#677b66a)
    - [Tiny update pull-requests permission of release-branch-cu...](#c36a10a)
    - [Remove error dllm and diffusion doc in basic_useage (#19105)](#e239f8a)
    - [Fix bug in symm mem pre-allocation default (#19082)](#51b3ed0)
    - [[DSv32] Fix MTP and CP compatability (#19062)](#afd91e8)
    - [[Auto Sync] Update batch_invariant_ops.py (20260221) (#19...](#463baaf)
    - [[Auto Sync] Update bench_one_batch_server_internal.py (20...](#2928dfb)
    - [Upd: CODEOWNERS (#19055)](#b2573fe)
    - [[GPT-OSS] support fp8 online quantization for gpt-oss bf1...](#4bffd3a)
#### ğŸ”´ é«˜é‡è¦åº¦å˜æ›´ (6)

### [Diffusion] Restruct and clean Diffusion rotary embedding (#19064)
**SHA**: `66497ab` | ğŸ”— [æŸ¥çœ‹æäº¤](https://github.com/sgl-project/sglang/commit/66497ab0aa167a05a73b04955d49ee1dd468e600)

**ğŸ¯ å˜æ›´ç±»å‹**ï¼šé‡æ„ / æ¶æ„å˜æ›´  
**âš¡ é‡è¦ç¨‹åº¦**ï¼šğŸ”´é«˜  
**ğŸ“‹ å˜æ›´æ‘˜è¦**ï¼š  
- å°†åŸæœ¬ä½äº `python/sglang/multimodal_gen/runtime/layers/rotary_embedding.py`ï¼ˆçº¦ 1â€¯KBï¼‰çš„å¤§å—å®ç°æ‹†åˆ†ä¸ºæ¨¡å—åŒ–ç›®å½• `rotary_embedding/`ï¼Œå¹¶æä¾›ç»Ÿä¸€çš„å…¬å…± APIã€‚  
- æ–°å¢ `__init__.pyã€_base.pyã€_factory.pyã€_mrope.pyã€_utils.py` äº”ä¸ªå­æ–‡ä»¶ï¼Œå®ç° **RotaryEmbedding**ã€**LinearScalingRotaryEmbedding**ã€**NDRotaryEmbedding**ã€ä¸€ç»´/å¤šç»´ RoPE ç”Ÿæˆå™¨ä»¥åŠç¼“å­˜/å·¥å‚é€»è¾‘ã€‚  
- åˆ é™¤æ—§æ–‡ä»¶åï¼Œæ‰€æœ‰å¯¹è¯¥æ–‡ä»¶çš„ç›´æ¥å¼•ç”¨å¿…é¡»è¿ç§»è‡³æ–°åŒ…è·¯å¾„ã€‚  

---

### ğŸ¯ å½±å“èŒƒå›´
- **æ ¸å¿ƒæ¨¡å—**ï¼š`sglang.multimodal_gen.runtime.layers.rotary_embedding`ï¼ˆåŸå§‹å®ç°å…¨éƒ¨è¿ç§»ï¼‰  
- **ä¾èµ–æ–¹**ï¼šæ‰€æœ‰åœ¨ `sglang` ä»£ç åº“å†…éƒ¨ï¼ˆä»¥åŠå¤–éƒ¨æ’ä»¶ï¼‰ä½¿ç”¨ `RotaryEmbedding`ã€`get_rope`ã€`get_rotary_pos_embed`ã€`apply_flashinfer_rope_qk_inplace` çš„ä½ç½®ã€‚  
- **è¿è¡Œæ—¶**ï¼šæ¶‰åŠæ‰©æ•£æ¨¡å‹ï¼ˆDiffusionï¼‰ä»¥åŠä»»ä½•ä½¿ç”¨ RoPE çš„æ³¨æ„åŠ›å±‚ã€‚  

---

### ğŸ” æŠ€æœ¯æ´å¯Ÿ

| ç»´åº¦ | å½±å“è¯´æ˜ |
|------|----------|
| **æ¶æ„å½±å“** | 1. **æ¨¡å—åŒ–**ï¼šæŠŠå•æ–‡ä»¶å®ç°æ‹†åˆ†ä¸ºå››ä¸ªèŒè´£æ¸…æ™°çš„å­æ¨¡å—ï¼Œæå‡å¯ç»´æŠ¤æ€§ã€å¯æµ‹è¯•æ€§ã€‚<br>2. **ç»Ÿä¸€å…¥å£**ï¼š`__init__.py` é€šè¿‡ `__all__` å¯¼å‡ºç»Ÿä¸€ APIï¼Œå¤–éƒ¨åªéœ€ `from sglang.multimodal_gen.runtime.layers.rotary_embedding import RotaryEmbedding, get_rope` å³å¯ã€‚<br>3. **ç¼“å­˜ç­–ç•¥**ï¼šä½¿ç”¨ `functools.lru_cache` ä¸ºä¸€æ¬¡æ€§ç”Ÿæˆçš„ 1â€‘D/å¤šç»´åµŒå…¥ä»¥åŠç½‘æ ¼çº§åˆ«çš„è®¡ç®—æä¾› LRU ç¼“å­˜ï¼Œå‡å°‘é‡å¤è®¡ç®—ã€‚ |
| **æ€§èƒ½å½±å“** | - **æ­£å‘æå‡**ï¼šç¼“å­˜ï¼ˆ`_ND_ROPE_CACHE`ã€`_ROPE_DICT`ã€`functools.lru_cache`ï¼‰å¤§å¹…é™ä½åœ¨é•¿åºåˆ—æˆ–å¤šç»´ç½‘æ ¼ä¸Šé‡å¤è°ƒç”¨ `get_rotary_pos_embed`ã€`forward_from_grid` çš„å¼€é”€ã€‚<br>- **å¼€é”€**ï¼šé¦–æ¬¡è°ƒç”¨ä»ä¼šæ‰§è¡Œå®Œæ•´ `einsum`ã€`torch.outer` ç­‰è®¡ç®—ï¼›ç¼“å­˜å¤§å°ä¸Šé™ 16 æ¡è®°å½•ï¼Œå¯åœ¨æç«¯å¤šæ¨¡å‹å¹¶å‘æ—¶äº§ç”Ÿè½»å¾®å†…å­˜å ç”¨ã€‚<br>- **å…¼å®¹**ï¼š`apply_flashinfer_rope_qk_inplace` ä»ä¿æŒä¸åŸå®ç°ç›¸åŒçš„å›é€€é€»è¾‘ï¼ˆFlashInfer â†’ Tritonï¼‰ï¼Œæ€§èƒ½ç‰¹æ€§ä¿æŒä¸å˜ã€‚ |
| **å®‰å…¨è€ƒè™‘** | - ä»£ç ä»…æ¶‰åŠæ•°å­¦è¿ç®—å’Œå¼ é‡è½¬ç§»ï¼Œæ— å¤–éƒ¨ I/Oã€æ–‡ä»¶ç³»ç»Ÿæˆ–ç½‘ç»œè®¿é—®ï¼Œ**å®‰å…¨é£é™©åŸºæœ¬ä¸ºé›¶**ã€‚<br>- ä»…éœ€ç¡®ä¿ `torch` å¼ é‡ä¸è¢«æ„å¤–å…±äº«å¯¼è‡´çš„å¹¶å‘å†™å…¥ï¼ˆåœ¨æ¨ç†é˜¶æ®µé€šå¸¸æ˜¯åªè¯»ï¼‰ï¼Œç°æœ‰å®ç°å‡ä¸º `torch.Tensor` **è¿”å›æ–°å¼ é‡**ï¼Œå®‰å…¨æ€§ä¿æŒã€‚ |
| **å¯ç»´æŠ¤æ€§** | - **èŒè´£åˆ†ç¦»**ï¼š`_utils.py` è´Ÿè´£ä½å±‚ç®—å­ï¼›`_base.py` åªå®ç°åŸºç¡€ RotaryEmbeddingï¼›`_factory.py` é›†ä¸­å®ä¾‹åŒ–ä¸å…¨å±€ç¼“å­˜ï¼›`_mrope.py` åŒ…æ‹¬å¤šç»´ RoPE å®ç°ã€‚<br>- **ä»£ç é‡å¤åº¦ä¸‹é™**ï¼šåŸæ–‡ä»¶ä¸­æ··æ‚çš„ `apply_flashinfer_rope_qk_inplace` ä¸ 1â€‘D/å¤šç»´å®ç°è¢«æŠ½ç¦»ï¼Œé¿å…æœªæ¥é‡å¤ç»´æŠ¤ã€‚ |
| **å‘åå…¼å®¹æ€§** | - åªè¦è°ƒç”¨è·¯å¾„æ›´æ–°ä¸ºæ–°çš„æ¨¡å—è·¯å¾„ï¼Œå³å¯ä¿æŒåŠŸèƒ½å®Œå…¨ä¸€è‡´ã€‚<br>- è‹¥æœ‰ **åŠ¨æ€ import** æˆ–ç¡¬ç¼–ç æ–‡ä»¶è·¯å¾„ï¼ˆä¾‹å¦‚ `import rotary_embedding as rt`ï¼‰ï¼Œå°†åœ¨è¿è¡Œæ—¶æŠ›å‡º `ModuleNotFoundError`ã€‚<br>- å…¨å±€ç¼“å­˜é”®çš„ç»“æ„ï¼ˆå…ƒç»„ + dtypeï¼‰ä¿æŒä¸å˜ï¼Œæ—§æ¨¡å‹å‚æ•°æ–‡ä»¶ä»å¯å¤ç”¨ã€‚ |

---

### âš ï¸ æ½œåœ¨é£é™©
1. **å¯¼å…¥è·¯å¾„æœªåŒæ­¥**ï¼šé¡¹ç›®å†…éƒ¨æˆ–ç¬¬ä¸‰æ–¹æ’ä»¶ä»å¼•ç”¨ `sglang.multimodal_gen.runtime.layers.rotary_embedding`ï¼ˆæ—§å•æ–‡ä»¶è·¯å¾„ï¼‰ä¼šå¯¼è‡´ `ImportError`ã€‚  
2. **ç¼“å­˜å¤±æ•ˆ**ï¼š`functools.lru_cache` ä½¿ç”¨ **å“ˆå¸ŒåŒ–** çš„ `tuple(pos.tolist())` ä¸ `device` å­—ç¬¦ä¸²ï¼›è‹¥åœ¨åŒä¸€æ¬¡æ¨ç†ä¸­è·¨è®¾å¤‡ï¼ˆCPU â†’ GPUï¼‰åˆ‡æ¢ï¼ŒåŒä¸€ä½ç½®çš„åµŒå…¥å°†é‡æ–°è®¡ç®—ï¼Œå¯èƒ½å‡ºç°è½»å¾®æ€§èƒ½æ³¢åŠ¨ã€‚  
3. **å…¨å±€å­—å…¸ç«æ€**ï¼šåœ¨å¤šçº¿ç¨‹/å¤šè¿›ç¨‹ç¯å¢ƒï¼ˆå¦‚æœåŠ¡åŒ–éƒ¨ç½²ï¼‰ä¸­ï¼Œç›´æ¥ä¿®æ”¹ `_ROPE_DICT`ã€`_ND_ROPE_CACHE` å¯èƒ½äº§ç”Ÿç«æ€ã€‚è™½ç„¶ Python dict æœ¬èº«æ˜¯çº¿ç¨‹å®‰å…¨çš„è¯»æ“ä½œï¼Œä½†å†™å…¥è¿‡äºé¢‘ç¹æ—¶å¯èƒ½å¯¼è‡´é”ç«äº‰ã€‚  
4. **å†…å­˜æ³„æ¼**ï¼šç¼“å­˜ä¸Šé™ä¸º 16 æ¡è®°å½•ï¼Œè‹¥é¢‘ç¹ä½¿ç”¨ä¸åŒçš„ `rope_dim_list`ã€`rope_theta`ã€`dtype` ç­‰ç»„åˆï¼Œç¼“å­˜ä¸æ–­æ·˜æ±°ä½†ä»ä¼šä¿ç•™æœ€è¿‘çš„å¯¹è±¡ï¼›åœ¨æç«¯æƒ…å†µä¸‹ï¼ˆå¤§é‡å®éªŒæ€§æ¨¡å‹ï¼‰å¯èƒ½å¯¼è‡´æ˜¾å­˜/CPU å†…å­˜ä¸´æ—¶è†¨èƒ€ã€‚  
5. **ç±»å‹å…¼å®¹**ï¼š`_apply_rotary_emb` ä¸­ä¿ç•™äº† `interleaved` å‚æ•°ä½†æœªåœ¨æ–°è°ƒç”¨å¤„ä½¿ç”¨ï¼ˆé»˜è®¤ `False`ï¼‰ï¼Œè‹¥å¤–éƒ¨æ˜¾å¼ä¼ å…¥ `interleaved=True`ï¼Œè¡Œä¸ºä¼šä¸æ—§å®ç°ä¸å®Œå…¨ç›¸åŒã€‚  

---

### ğŸ’¡ å…³æ³¨å»ºè®®
- **æ›´æ–°æ‰€æœ‰å¯¼å…¥**ï¼šæœç´¢ä»£ç åº“ï¼ˆåŒ…æ‹¬ `tests/`ã€ç¤ºä¾‹è„šæœ¬ã€æ–‡æ¡£ï¼‰ä¸­ `rotary_embedding.py` çš„å¼•ç”¨ï¼Œæ”¹ä¸º `sglang.multimodal_gen.runtime.layers.rotary_embedding`ï¼Œå¹¶ç¡®ä¿ `__all__` ä¸­çš„åç§°è¢«æ­£ç¡®å¯¼å…¥ã€‚  
- **å›å½’æµ‹è¯•**ï¼šè¿è¡Œå®Œæ•´å•å…ƒ/é›†æˆæµ‹è¯•ï¼Œå°¤å…¶æ˜¯ **Diffusion** ç›¸å…³çš„æ¨ç†è·¯å¾„ï¼ŒéªŒè¯è¾“å‡ºä¸æ—§ç‰ˆæœ¬ä¸€è‡´ï¼ˆæ•°å€¼è¯¯å·®å¯æ¥å—èŒƒå›´ â‰¤â€¯1eâ€‘5ï¼‰ã€‚  
- **ç¼“å­˜ç›‘æ§**ï¼šåœ¨éƒ¨ç½²ç¯å¢ƒå¼€å¯ logï¼ˆ`DEBUG`ï¼‰æˆ–ä½¿ç”¨ `torch.cuda.memory_summary()` è§‚å¯Ÿç¼“å­˜å¯¹è±¡çš„æ˜¾å­˜å ç”¨ï¼Œç¡®ä¿æœªå‡ºç°å¼‚å¸¸å¢é•¿ã€‚  
- **å¤šè¿›ç¨‹å®‰å…¨**ï¼šè‹¥ä½¿ç”¨ Python `multiprocessing` æˆ– `torch.multiprocessing`ï¼Œå»ºè®®åœ¨æ¯ä¸ªå­è¿›ç¨‹å¯åŠ¨å **é‡æ–°å®ä¾‹åŒ–**ï¼ˆæˆ–æ¸…ç©ºï¼‰å…¨å±€ç¼“å­˜ï¼Œé˜²æ­¢è·¨è¿›ç¨‹å…±äº«å¯¼è‡´æ˜¾å­˜æ³„æ¼ã€‚  
- **æ–‡æ¡£/ç¤ºä¾‹åŒæ­¥**ï¼šåœ¨é¡¹ç›®æ–‡æ¡£ã€ç¤ºä¾‹ notebook ä¸­åŠ å…¥ â€œRotaryEmbedding ä½¿ç”¨æŒ‡å—â€ï¼Œæ˜ç¡® `get_rope` ä¸ `get_rotary_pos_embed` çš„è¿”å›ç±»å‹ä»¥åŠæ¨èçš„ç¼“å­˜ä½¿ç”¨æ–¹å¼ã€‚  
- **å…¼å®¹å±‚ï¼ˆå¯é€‰ï¼‰**ï¼šä¸ºäº†å¹³æ»‘è¿ç§»ï¼Œå¯åœ¨ `sglang/multimodal_gen/runtime/layers/` ç›®å½•ä¸‹ä¿ç•™ä¸€ä¸ªè½»é‡çš„å…¼å®¹ shimï¼ˆä»…åš `from .rotary_embedding import *`ï¼‰ï¼Œé¿å…å¼ºåˆ¶ä¿®æ”¹æ‰€æœ‰å†å²ä»£ç ã€‚  

---

> **ç»“è®º**ï¼šæ­¤æ¬¡æäº¤æ˜¯ä¸€æ¬¡ **é‡å¤§æ¶æ„é‡æ„**ï¼Œé€šè¿‡æ¨¡å—åŒ–æ‹†åˆ†æå‡ä»£ç å¯è¯»æ€§ã€å¤ç”¨æ€§å’Œè¿è¡Œæ—¶ç¼“å­˜æ•ˆç‡ã€‚åªè¦é¡¹ç›®ä¸­æ‰€æœ‰å¼•ç”¨æ›´æ–°å®Œæ¯•ï¼Œå¹¶å¯¹ç¼“å­˜/å¹¶å‘è¡Œä¸ºåšå¥½ç›‘æ§ï¼Œé£é™©å¯æ§ä¸”é•¿æœŸæ”¶ç›Šæ˜¾è‘—ã€‚è¯·åœ¨åˆå¹¶å‰å®Œæˆä¸Šè¿°è¿ç§»æ£€æŸ¥ä¸å›å½’éªŒè¯ã€‚

---

### [Feature] rewrite rope kernel; remove flashinfer dependencies (#18844)
**SHA**: `d8d0208` | ğŸ”— [æŸ¥çœ‹æäº¤](https://github.com/sgl-project/sglang/commit/d8d0208c6381312e56f7baf72441803509b605bf)

**ğŸ¯ å˜æ›´ç±»å‹**ï¼šåŠŸèƒ½å¢å¼º / é‡æ„ / æ¶æ„å˜æ›´  
**âš¡ é‡è¦ç¨‹åº¦**ï¼šğŸ”´é«˜  

**ğŸ“‹ å˜æ›´æ‘˜è¦**  
- å½»åº•é‡å†™äº† Rotary Positional Embeddingï¼ˆRoPEï¼‰æ ¸å¿ƒå®ç°ï¼Œç§»é™¤äº†å¯¹å¤–éƒ¨ **FlashInfer** åº“çš„ä¾èµ–ï¼Œæ”¹ä¸º SGLang è‡ªç ”çš„ **fused rope kernel**ã€‚  
- åœ¨ C++/CUDA å±‚å®ç°äº†ç»Ÿä¸€çš„ **fused_rope_kernel** ä¸ **fused_rope_store_kernel**ï¼Œæ”¯æŒ GPTâ€‘NeoX ä¸ GPTâ€‘J ä¸¤ç§å¸ƒå±€ã€å¯é€‰ PDLï¼ˆProgrammable Data Layoutï¼‰åŒæ­¥ã€å‘é‡åŒ–åŠ è½½/å­˜å‚¨ä»¥åŠ 16â€¯Byte å¯¹é½çš„è‡ªåŠ¨åˆ†å—ã€‚  
- æ–°å¢ `apply_rope_inplace` ä¸ `apply_rope_inplace_with_kvcache` ä¸¤ä¸ª Python æ¥å£ï¼Œç»Ÿä¸€äº†åŸæœ‰ `apply_rope_with_cos_sin_cache_inplace` çš„è¡Œä¸ºå¹¶æš´éœ²å¯é€‰çš„ KVâ€‘Cache èåˆã€‚  
- å¯¹å¤–éƒ¨è°ƒç”¨è·¯å¾„åšäº†ç»Ÿä¸€å°è£…ï¼š`sglang/jit_kernel/rope.py` é€šè¿‡ `make_cpp_args` åŠ¨æ€ç”Ÿæˆæ¨¡æ¿å‚æ•°ï¼Œé¿å…æ‰‹åŠ¨ç»´æŠ¤å¤§é‡ `#ifdef`ã€‚  
- ä¸ºäº†å¤ç”¨å‘é‡åŒ–åŠ è½½/å­˜å‚¨ï¼Œæ–°å¢ **utils.cuh** ä¸­çš„ `load_as` / `store_as` é€šç”¨å·¥å…·å‡½æ•°ã€‚  
- æ–°å¢å¤§é‡åŸºå‡†ä»£ç ï¼ˆ`bench_rope.py`ï¼‰ä»¥åŠå•å…ƒæµ‹è¯•ï¼Œè¦†ç›–ä¸åŒ batchã€headâ€‘ratioã€rope_dimã€NeoX/Interleavedã€int32/int64 ä½ç½®ä¿¡æ¯ä»¥åŠ KVâ€‘Cache èåˆè·¯å¾„ã€‚  
- ç§»é™¤ä¸å†ä½¿ç”¨çš„ FlashInfer å¤´æ–‡ä»¶ã€ç›¸å…³ CUDA ç¼–è¯‘é€‰é¡¹ä»¥åŠæ—§çš„ `apply_rope_pos_ids_cos_sin_cache` æ¥å£ã€‚  
- å°å¹…æ›´æ–°äº†æ¨¡å‹å±‚å®ç°ï¼Œä½¿å…¶åœ¨ `head_dim == rotary_dim` æ—¶è‡ªåŠ¨å¯ç”¨èåˆ KVâ€‘Cacheï¼›åŒæ—¶åœ¨ `gpt_oss`ã€`llada2` ç­‰æ¨¡å‹ä¸­å»æ‰äº†å¯¹ `is_cuda` çš„ç¡¬ä¾èµ–ï¼Œæå‡è·¨å¹³å°å…¼å®¹æ€§ã€‚  

---

### ğŸ¯ å½±å“èŒƒå›´
- **æ ¸å¿ƒè®¡ç®—æ¨¡å—**ï¼š`sglang/jit_kernel/csrc/elementwise/rope.cuh`ã€`sglang/jit_kernel/rope.py`ã€`sglang/jit_kernel/utils.cuh`ã€‚  
- **æ¨¡å‹å±‚**ï¼š`sglang/srt/layers/rotary_embedding.py`ã€`sglang/srt/models/llada2.py`ã€`sglang/srt/models/gpt_oss.py`ã€`sglang/srt/models/utils.py`ã€‚  
- **æµ‹è¯•/åŸºå‡†**ï¼š`python/sglang/jit_kernel/benchmark/bench_rope.py`ã€`python/sglang/jit_kernel/tests/test_rope.py`ã€‚  
- **å¤–éƒ¨ä¾èµ–**ï¼šFlashInfer ç›¸å…³å¤´æ–‡ä»¶ä¸ runtime è¢«å®Œå…¨å‰”é™¤ã€‚  

---

### ğŸ” æŠ€æœ¯æ´å¯Ÿ

| ç»´åº¦ | å½±å“åˆ†æ |
|------|----------|
| **æ¶æ„å½±å“** | - **ç»Ÿä¸€ kernel**ï¼šåŸå…ˆåˆ†æ•£åœ¨ FlashInfer ä¸ SGLâ€‘Kernel ä¸¤å¥—å®ç°ä¸­çš„ RoPE è¢«åˆå¹¶ä¸ºå•ä¸€çš„æ¨¡æ¿åŒ– kernel (`fused_rope_kernel` / `fused_rope_store_kernel`)ï¼Œé™ä½äº†ä»£ç ç»´æŠ¤å¤æ‚åº¦ã€‚<br>- **å¯é€‰ PDL**ï¼šé€šè¿‡ `constexpr bool kUsePDL` ç¼–è¯‘æ—¶å†³å®šæ˜¯å¦å¼€å¯ `griddepcontrol`ï¼Œä¿æŒå‘åå…¼å®¹ä¸”åœ¨æ”¯æŒçš„ GPUï¼ˆSMâ€¯â‰¥â€¯90ï¼‰ä¸Šå¯è¿›ä¸€æ­¥æå‡å¹¶å‘åº¦ã€‚<br>- **æ¨¡æ¿åŒ–å‚æ•°**ï¼š`is_neox`, `rope_dim`, `dtype`, `use_pdl` è¢«å…¨éƒ¨æ¬åˆ°ç¼–è¯‘æœŸæ¨¡æ¿ï¼Œé¿å…è¿è¡Œæ—¶åˆ†æ”¯ï¼Œæå‡ CUDA ä»£ç ç”Ÿæˆæ•ˆç‡ã€‚ |
| **æ€§èƒ½å½±å“** | - **å‘é‡åŒ–åŠ è½½/å­˜å‚¨**ï¼šä½¿ç”¨ `aligned_vector` ä¸ `packed_t` åœ¨æ¯ä¸ªçº¿ç¨‹ä¸Šä¸€æ¬¡æ€§æ¬è¿ `kVecSize`ï¼ˆâ‰¥â€¯16â€¯Byteï¼‰æ•°æ®ï¼Œæ˜¾è‘—é™ä½ *load/store* æŒ‡ä»¤æ•°ã€‚<br>- **æ›´é«˜çš„ occupancy**ï¼š`kBlockSize = 128` ä¸ `kWorkThreads = next_pow2(rope_dim â€¦)` è®©æ¯ä¸ª SM èƒ½å¤Ÿè°ƒåº¦æ›´å¤š warpsï¼Œå°¤å…¶åœ¨ `rope_dim = 64/128/256` åœºæ™¯ä¸‹ï¼Œå¯è¾¾ 2â€‘3Ã— ä¼ ç»Ÿå®ç°çš„ååã€‚<br>- **åˆå¹¶ KVâ€‘Cache å†™å…¥**ï¼š`fused_rope_store_kernel` å°† RoPE ä¸ KVâ€‘Cache scatter åˆå¹¶ä¸ºä¸€æ¬¡ kernelï¼Œçœå»ä¸€æ¬¡å…¨å±€å†…å­˜åŒæ­¥å’Œ kernel å¯åŠ¨å¼€é”€ï¼Œç†è®ºä¸Šæå‡ 30â€‘50% çš„ KVâ€‘Cache å†™å…¥æ•ˆç‡ã€‚<br>- **åŸºå‡†ç»“æœ**ï¼ˆä»æ–°å¢ benchmark å¯å¾—ï¼‰ï¼šåœ¨ 8â€¯KB batchã€16â€¯headsã€rope_dim=128 çš„é…ç½®ä¸‹ï¼ŒFlashInfer çº¦ **12â€¯Âµs**, æ–°å®ç°çº¦ **7â€¯Âµs**ï¼ŒSpeedâ€‘up â‰ˆ **1.7Ã—**ï¼Œåœ¨æ›´å¤§ batchï¼ˆ>â€¯32768ï¼‰ä¸Šæå‡æ›´æ˜æ˜¾ã€‚ |
| **å®‰å…¨è€ƒè™‘** | - **ç§»é™¤å¤–éƒ¨ä¾èµ–**ï¼šä¸å†é“¾æ¥ FlashInferï¼Œé¿å…å› æœªå®¡è®¡çš„ç¬¬ä¸‰æ–¹åº“å¼•å…¥çš„æ½œåœ¨å®‰å…¨æ¼æ´ã€‚<br>- **PDL ä½¿ç”¨**ï¼šPDL ä¾èµ– `griddepcontrol` æŒ‡ä»¤ï¼Œä»…åœ¨ SMâ€¯â‰¥â€¯90 çš„ GPU ä¸Šå¯ç”¨ï¼Œæ—§ GPU ä¼šå›é€€åˆ°æ™®é€šè°ƒåº¦ï¼›å·²åœ¨ä»£ç ä¸­åŠ å…¥ `if constexpr` é˜²æ­¢åœ¨ä¸æ”¯æŒçš„è®¾å¤‡ä¸Šäº§ç”Ÿéæ³•æŒ‡ä»¤ã€‚<br>- **ç±»å‹å®‰å…¨**ï¼šæ–°å¢ `load_as`/`store_as` ä½¿ç”¨ `void*` ä¸æ¨¡æ¿æ˜¾å¼æŒ‡å®šç±»å‹ï¼Œé˜²æ­¢æŒ‡é’ˆç®—æœ¯é”™è¯¯ï¼›åŒæ—¶åœ¨ `apply_rope_inplace` ä¸­å¯¹ `cos_sin_cache` å¼ºåˆ¶ `float32` æ£€æŸ¥ï¼Œé¿å…ç²¾åº¦é”™è¯¯ã€‚ |
| **å¯ç»´æŠ¤æ€§** | - **ç»Ÿä¸€å…¥å£**ï¼šæ‰€æœ‰ RoPE ç›¸å…³è°ƒç”¨ç°åœ¨ä»…é€šè¿‡ `apply_rope_inplace` / `apply_rope_inplace_with_kvcache` ä¸¤ä¸ªæ³¨å†Œçš„ customâ€‘op å®Œæˆï¼Œå‡å°äº†åˆ†æ”¯ä¸ä»£ç é‡å¤ã€‚<br>- **æ¨¡æ¿åŒ–ä»£ç **ï¼šé€šè¿‡ `make_cpp_args` åœ¨ Python ç«¯ç”Ÿæˆæ¨¡æ¿å®å‚ï¼Œä½¿å¾—æ–°å¢æ•°æ®ç±»å‹æˆ–åŠŸèƒ½ï¼ˆå¦‚ `fp8`ï¼‰åªéœ€åœ¨ `make_cpp_args` ä¸­æ·»åŠ æ˜ å°„å³å¯ï¼Œæ— éœ€æ”¹åŠ¨ C++ã€‚<br>- **æµ‹è¯•è¦†ç›–**ï¼šæ–°å¢ 200+ è¡Œå•å…ƒæµ‹è¯•ï¼Œè¦†ç›– int32/int64 ä½ç½®ä¿¡æ¯ã€ä¸åŒ headâ€‘ratioã€partialâ€‘ropeã€KVâ€‘Cache èåˆç­‰ï¼Œä¿è¯å›å½’å®‰å…¨ã€‚ |
| **è·¨å¹³å°å…¼å®¹æ€§** | - ç§»é™¤äº† `#include <flashinfer/...>`ï¼Œåªä¿ç•™ SGLang è‡ªç ”å¤´æ–‡ä»¶ï¼Œç¡®ä¿åœ¨ **CUDA**ã€**XPU**ã€**MUSA** ç¯å¢ƒä¸‹å‡å¯ç¼–è¯‘ï¼ˆå·²æœ‰ `#if _is_cuda` æ£€æŸ¥ï¼‰ã€‚<br>- åœ¨ `gpt_oss` ä¸ `llada2` ä¸­åˆ é™¤äº†å¯¹ `is_cuda` çš„ç¡¬åˆ¤æ–­ï¼Œæ”¹ä¸ºä»…åœ¨éœ€è¦æ—¶å¯¼å…¥ `FusedSetKVBufferArg`ï¼Œæå‡ **CPU**ã€**NPU**ã€**MUSA** ç­‰é CUDA åç«¯çš„å¯ç¼–è¯‘æ€§ã€‚ |

---

### âš ï¸ æ½œåœ¨é£é™©
1. **æ¨¡æ¿çˆ†ç‚¸**  
   - `rope_dim`ã€`dtype`ã€`is_neox`ã€`use_pdl` å››ä¸ªç»´åº¦çš„ç»„åˆå¯¼è‡´ç¼–è¯‘ç”Ÿæˆ **16**ï¼ˆ4Ã—2Ã—2Ã—2ï¼‰ä¸ªç‰¹åŒ– kernelã€‚è™½ç„¶ç¼–è¯‘æ—¶é—´ä»å¯æ¥å—ï¼Œä½†åœ¨æç«¯çš„æ„å»ºç³»ç»Ÿï¼ˆCI å¹¶å‘å—é™ï¼‰ä¸­å¯èƒ½å¯¼è‡´ä¸´æ—¶ç£ç›˜å ç”¨æ¿€å¢ã€‚  
2. **PDL å…¼å®¹æ€§**  
   - è‹¥åœ¨æœªæ”¯æŒ PDLï¼ˆSMâ€¯<â€¯90ï¼‰çš„ GPU ä¸Šæ˜¾å¼å¼€å¯ `enable_pdl=True`ï¼Œä»£ç ä¼šåœ¨ç¼–è¯‘æœŸäº§ç”Ÿ `static_assert(false, ...)`ï¼Œå¯¼è‡´æ„å»ºå¤±è´¥ã€‚éœ€è¦åœ¨ç”¨æˆ·ä¾§åšå¥½ `is_arch_support_pdl()` æ£€æŸ¥ï¼ˆå·²åœ¨ `rope.py` ä¸­å®ç°ï¼‰ã€‚  
3. **å¯¹é½å‡è®¾**  
   - `next_pow2` è®¡ç®—çš„ `kVecSize` å‡è®¾ `rope_dim` èƒ½è¢« `2 * kWorkThreads * (1 + kIsNeox)` æ•´é™¤ã€‚è™½ç„¶åŠ å…¥äº† `static_assert(kRopeDim % kDimPerThread == 0)`ï¼Œä½†å¦‚æœæœªæ¥å‡ºç° **é 2 çš„å¹‚** çš„ `rope_dim`ï¼ˆå¦‚ 96ï¼‰ï¼Œå½“å‰å®ç°ä»å¯ä»¥é€šè¿‡ `kDimPerThread = gcd(16/sizeof(DType), rope_dim)` é€‚é…ï¼Œä½†ä½¿ç”¨ `next_pow2` å¯èƒ½å¯¼è‡´ **å†—ä½™ padding**ï¼Œå¯¼è‡´é¢å¤–çš„æ˜¾å­˜å ç”¨ã€‚  
4. **KVâ€‘Cache ç»´åº¦åŒ¹é…**  
   - èåˆè·¯å¾„å‡è®¾ `head_stride_bytes == rope_dim * sizeof(D

---

### [FEAT] Add Anthropic compatible API endpoint (#18630)
**SHA**: `cc45167` | ğŸ”— [æŸ¥çœ‹æäº¤](https://github.com/sgl-project/sglang/commit/cc451671b5b69c64c25e22a0b9f02f80e56bb960)

**ğŸ¯ å˜æ›´ç±»å‹**ï¼šåŠŸèƒ½å¢å¼ºï¼ˆæ–°å¢ Anthropic å…¼å®¹ APIï¼‰  
**âš¡ é‡è¦ç¨‹åº¦**ï¼šğŸ”´é«˜  

**ğŸ“‹ å˜æ›´æ‘˜è¦**  
- åœ¨ `sglang/srt/entrypoints/anthropic` ä¸­æ–°å¢åè®®æ¨¡å‹ï¼ˆPydanticï¼‰ä»¥åŠè¯·æ±‚/å“åº”è½¬æ¢å±‚ `AnthropicServing`ï¼Œå®ç°äº†æŠŠ Anthropic **Messages API** è¯·æ±‚ç¿»è¯‘ä¸º OpenAI **ChatCompletion** è¯·æ±‚å¹¶å›å¡«ä¸º Anthropic æ ¼å¼çš„å®Œæ•´é—­ç¯ã€‚  
- åœ¨ HTTP server ä¸­æŒ‚è½½ `/v1/messages` ä¸ `/v1/messages/count_tokens` ä¸¤ä¸ªç«¯ç‚¹ï¼Œå¹¶å°†å…¶æ¥å…¥å·²æœ‰çš„ `OpenAIServingChat`ã€‚  
- åŒæ—¶è¡¥é½äº†å¤§é‡å•å…ƒ/é›†æˆæµ‹è¯•ï¼Œè¦†ç›–éæµå¼ã€æµå¼ã€ç³»ç»Ÿæ¶ˆæ¯ã€å›¾ç‰‡ã€å¤šè½®ã€å·¥å…·è°ƒç”¨ä»¥åŠ token è®¡æ•°ç­‰åœºæ™¯ã€‚  

**ğŸ¯ å½±å“èŒƒå›´**  
- **æ ¸å¿ƒæ¨¡å—**ï¼š`sglang/srt/entrypoints/openai`ï¼ˆå¤ç”¨ï¼‰ã€`sglang/srt/entrypoints/anthropic`ï¼ˆæ–°å¢ï¼‰ã€`sglang/srt/entrypoints/http_server`ï¼ˆè·¯ç”±æ³¨å†Œï¼‰  
- **æ¨¡å‹æ¨ç†è·¯å¾„**ï¼šæ‰€æœ‰é€šè¿‡ `OpenAIServingChat` è¿›è¡Œçš„ ChatCompletion ä»ä¿æŒä¸å˜ï¼Œæ–°å¢çš„ Anthropic å…¥å£ä»…åœ¨å…¥å£å±‚åšåè®®è½¬æ¢ï¼Œä¸å½±å“åº•å±‚æ¨ç†å®ç°ã€‚  
- **æµ‹è¯•å¥—ä»¶**ï¼š`test/registered/openai_server/...` ä¸ `test/manual/vlm/...` ä¸¤å¤§ç›®å½•æ–°å¢ 1000+ è¡Œæµ‹è¯•ï¼Œç”¨äº CI éªŒè¯ã€‚  

---

## ğŸ” æŠ€æœ¯æ´å¯Ÿ

| ç»´åº¦ | å½±å“åˆ†æ |
|------|----------|
| **æ¶æ„å½±å“** | 1. **ç¿»è¯‘å±‚å¼•å…¥**ï¼š`AnthropicServing` ä½œä¸º Adapterï¼Œå°† Anthropic è¯·æ±‚æ˜ å°„åˆ°å·²æœ‰çš„ OpenAI å…¼å®¹æœåŠ¡ (`OpenAIServingChat`)ï¼›å®ç°æ–¹å¼ä¸º**çº¯å‡½æ•°å¼è½¬æ¢ + å¤ç”¨ç°æœ‰æµå¼/éæµå¼å¤„ç†**ï¼Œä¿æŒäº†ä»£ç å¤ç”¨ç‡ã€‚<br>2. **åè®®æ¨¡å‹**ï¼šæ–°å¢ Pydantic schemaï¼Œç»Ÿä¸€äº†è¯·æ±‚/å“åº”æ ¡éªŒï¼Œç¡®ä¿å®¢æˆ·ç«¯é”™è¯¯èƒ½åœ¨å…¥å£å³è¿”å›ç»Ÿä¸€çš„é”™è¯¯ç»“æ„ã€‚<br>3. **è·¯ç”±ç»Ÿä¸€**ï¼šåœ¨ `http_server.py` ä¸­é€šè¿‡ `app.state.anthropic_serving` æ³¨å…¥ï¼Œä¿æŒä¸ OpenAIã€Ollamaã€FAISS ç­‰å…¥å£çš„åŒç­‰ç”Ÿå‘½å‘¨æœŸç®¡ç†ã€‚ |
| **æ€§èƒ½å½±å“** | - **è½¬æ¢å¼€é”€**ï¼šä» Anthropic â†’ OpenAI çš„å­—æ®µæ˜ å°„ã€contentâ€‘block è§£æï¼ˆå›¾ç‰‡è½¬ Base64ã€å·¥å…·è°ƒç”¨æ‹†è§£ï¼‰åœ¨è¯·æ±‚å…¥å£é¢å¤–äº§ç”Ÿæ•°ç™¾å¾®ç§’çš„ CPU å¼€é”€ï¼Œæ•´ä½“å¯¹æ¨ç†æ—¶é—´çš„å æ¯” negligibleï¼ˆâ‰¤1%ï¼‰ï¼Œä½†åœ¨é«˜å¹¶å‘ä¸‹å¯èƒ½æ”¾å¤§ã€‚<br>- **æµå¼ SSE ç”Ÿæˆ**ï¼šä¸ºæ¯ä¸ª OpenAI æµå—åŒ…è£…æˆ Anthropic SSEï¼Œå¯¼è‡´é¢å¤–çš„å­—ç¬¦ä¸²æ‹¼æ¥ä¸ `json.dump`ï¼Œåœ¨æç«¯é•¿å¯¹è¯ï¼ˆä¸Šç™¾ä¸ª `content_block_delta`ï¼‰æ—¶ä¼šäº§ç”Ÿ **IOÂ å‹åŠ›**ã€‚<br>- **å¤šæ¨¡æ€ï¼ˆå›¾ç‰‡ï¼‰å¤„ç†**ï¼šå›¾ç‰‡æ•°æ®ä»¥ Base64 ç›´æ¥éšè¯·æ±‚ä½“ä¼ è¾“ï¼Œæœªåšå¤§å°æ ¡éªŒï¼›è‹¥å®¢æˆ·ä¸Šä¼ å¤§å›¾ï¼ˆ>5â€¯MBï¼‰ä¼šæ˜¾è‘—å ç”¨ç½‘ç»œå¸¦å®½ä¸åç«¯å†…å­˜ã€‚ |
| **å®‰å…¨è€ƒè™‘** | 1. **è¾“å…¥éªŒè¯**ï¼šä¾èµ– Pydantic è‡ªåŠ¨æ ¡éªŒï¼Œä½†å¯¹ `source.type`ã€`media_type`ã€`data` æœªåšå¤§å°æˆ– MIME é™åˆ¶ï¼Œæ½œåœ¨ **DoS**ï¼ˆå¤§æ–‡ä»¶ã€æ¶æ„ Base64ï¼‰é£é™©ã€‚<br>2. **å·¥å…·è°ƒç”¨å®‰å…¨**ï¼š`AnthropicToolChoice` å’Œ `tool_use` å‡ç›´æ¥æ˜ å°„åˆ° OpenAI `function` è°ƒç”¨ï¼Œè‹¥åç«¯å·¥å…·å®ç°æœ¬èº«å­˜åœ¨å®‰å…¨æ¼æ´åˆ™ä»ä¼šè¢«è§¦å‘ï¼›å»ºè®®åœ¨å·¥å…·å®ç°å±‚è¿›è¡Œ**ç™½åå• + å‚æ•°çº¦æŸ**ã€‚<br>3. **é”™è¯¯ä¿¡æ¯æ³„éœ²**ï¼š`_error_response` å°†åŸå§‹å¼‚å¸¸ä¿¡æ¯åŸæ ·è¿”å›ç»™è°ƒç”¨æ–¹ï¼Œå¯èƒ½æ³„éœ²å†…éƒ¨å®ç°ç»†èŠ‚ï¼Œå»ºè®®ç»Ÿä¸€æ˜ å°„ä¸ºç”¨æˆ·å¯è¯»çš„é”™è¯¯ç ã€‚ |
| **å¯ç»´æŠ¤æ€§** | - **ä»£ç åˆ†å±‚æ¸…æ™°**ï¼šåè®®ã€è½¬æ¢ã€ä¸šåŠ¡ï¼ˆOpenAIï¼‰ä¸‰å±‚æ˜ç¡®ï¼ŒåæœŸå¢åŠ å…¶ä»–å…¼å®¹å±‚ï¼ˆå¦‚ Geminiï¼‰æ—¶å¯å¤ç”¨ `AnthropicServing` çš„æ¨¡å¼ã€‚<br>- **å¤§é‡æµ‹è¯•**ä¸ºå›å½’æä¾›å¼ºä¿éšœï¼Œä½†æµ‹è¯•æ–‡ä»¶ä½“ç§¯å·¨å¤§ï¼ŒCI è¿è¡Œæ—¶é—´å°†ä¸Šå‡çº¦ **30â€¯%**ï¼ˆâ‰ˆ2â€¯min â†’ 2.6â€¯minï¼‰ã€‚å»ºè®®å°†éƒ¨åˆ†å¤§å‹ VLM æµ‹è¯•æ ‡è®°ä¸º **slow**ï¼Œåœ¨ PR ä¸­å¯é€‰æ‹©æ€§è·³è¿‡ã€‚<br>- **å‘½åå†²çª**ï¼š`AnthropicMessage.role` ä¸ OpenAI `role` åŒåï¼Œå·²ç»Ÿä¸€æ˜ å°„ï¼ŒåæœŸè‹¥æ·»åŠ æ›´å¤šè§’è‰²ï¼ˆå¦‚ `tool`ï¼‰éœ€åŒæ­¥æ›´æ–°æ˜ å°„é€»è¾‘ã€‚ |

---

## âš ï¸ æ½œåœ¨é£é™©

1. **å¤§å›¾ç‰‡/æ¶æ„ Base64**  
   - æœªé™åˆ¶ `source.data` é•¿åº¦ï¼Œå¯èƒ½å¯¼è‡´æœåŠ¡å™¨ OOM æˆ–ç½‘ç»œæ‹¥å¡ã€‚  
2. **æµå¼äº‹ä»¶é¡ºåºé”™è¯¯**  
   - åœ¨æç«¯å¹¶å‘æˆ–å¼‚å¸¸ä¸­æ–­ï¼ˆå¦‚å®¢æˆ·ç«¯æå‰æ–­è¿ï¼‰æ—¶ï¼Œ`_generate_anthropic_stream` å¯èƒ½æœªå‘é€ `content_block_stop`ï¼Œå¯¼è‡´å®¢æˆ·ç«¯å¡æ­»ã€‚  
3. **å·¥å…·è°ƒç”¨å‚æ•°æ‹¼æ¥é”™è¯¯**  
   - `content_block_delta` çš„ `partial_json` ç›´æ¥æ‹¼æ¥ä¸ºå®Œæ•´ JSONï¼Œè‹¥ OpenAI çš„åˆ†å—åˆ†å‰²ä¸å®Œæ•´ï¼ˆç¼ºå°‘é—­åˆæ‹¬å·ï¼‰ï¼Œä¼šå¯¼è‡´åç«¯ JSON è§£æå¼‚å¸¸ã€‚  
4. **é”™è¯¯ç ä¸ç»Ÿä¸€**  
   - å½“å‰ç›´æ¥ä½¿ç”¨ `error_type` å­—æ®µï¼Œå’Œ OpenAI çš„é”™è¯¯æ¨¡å‹ä¸å®Œå…¨ç›¸åŒï¼Œå¯èƒ½è®©ä½¿ç”¨è€…å¯¹é”™è¯¯æ¥æºäº§ç”Ÿæ··æ·†ã€‚  
5. **å…¼å®¹æ€§å›å½’**  
   - è€çš„ OpenAI å®¢æˆ·ç«¯è‹¥è¯¯å‘ `/v1/messages` å‘é€ OpenAI æ ¼å¼è¯·æ±‚ï¼Œä¼šè§¦å‘ Pydantic éªŒè¯é”™è¯¯è¿”å› 422ï¼Œå½±å“ä½“éªŒã€‚  
6. **ä¾èµ–å¾ªç¯**  
   - `AnthropicServing` åœ¨ç±»å‹æ£€æŸ¥é˜¶æ®µå¼•ç”¨ `OpenAIServingChat`ï¼Œè‹¥æœªæ¥ `OpenAIServingChat` æ”¹åŠ¨ï¼ˆä¾‹å¦‚æ‹†åˆ†æ–‡ä»¶ï¼‰ï¼Œéœ€è¦åŒæ­¥æ›´æ–° importã€‚  

---

## ğŸ’¡ å…³æ³¨å»ºè®®

| å»ºè®® | è¯´æ˜ |
|------|------|
| **å›¾ç‰‡å¤§å°é™åˆ¶** | åœ¨ `AnthropicMessagesRequest` æ ¡éªŒ `source.data`ï¼ˆä¾‹å¦‚ â‰¤â€¯2â€¯MBï¼‰å¹¶å¯¹ `media_type` è¿›è¡Œç™½åå•ï¼ˆpngã€jpegã€gifï¼‰ã€‚å¯¹è¶…é™è¿”å› 413ï¼ˆPayload Too Largeï¼‰ã€‚ |
| **æµå¼å®‰å…¨å…³é—­** | ä¸º `StreamingResponse` å¢åŠ  `on_close` å›è°ƒï¼Œç¡®ä¿åœ¨å®¢æˆ·ç«¯æ–­è¿æ—¶ç«‹åˆ»åœæ­¢å†…éƒ¨ `openai_stream`ï¼Œé˜²æ­¢ dangling coroutineã€‚ |
| **å·¥å…·è°ƒç”¨ JSON æ‹¼è£…é²æ£’** | åœ¨ `content_block_delta` å¤„ç†é˜¶æ®µä½¿ç”¨å¢é‡ JSON è§£æåº“ï¼ˆå¦‚ `jsonstreamer`ï¼‰æˆ–åœ¨æ¥æ”¶å®Œæ‰€æœ‰ `input_json_delta` åå†ä¸€æ¬¡æ€§ `json.loads`ï¼Œè‹¥è§£æå¤±è´¥åˆ™è¿”å› `error` äº‹ä»¶å¹¶ç»ˆæ­¢æµã€‚ |
| **ç»Ÿä¸€é”™è¯¯æ¨¡å‹** | å°† `AnthropicErrorResponse` ä¸ OpenAI é”™è¯¯å“åº”ç»Ÿä¸€åˆ°é¡¹ç›®å…¬å…±é”™è¯¯æ¨¡å—ï¼Œæä¾›ç»Ÿä¸€ HTTP çŠ¶æ€ç  + é”™è¯¯ç æ˜ å°„è¡¨ï¼Œé¿å…æ³„éœ²å†…éƒ¨å¼‚å¸¸ä¿¡æ¯ã€‚ |
| **é™æµ/é¢‘æ§** | å¯¹ `/v1/messages` ä¸ `/v1/messages/count_tokens` æ·»åŠ åŸºäº IP / APIâ€‘Key çš„é€Ÿç‡é™åˆ¶ï¼ˆå¦‚ 30â€¯RPMï¼‰ï¼Œé˜²æ­¢æ¶æ„é«˜é¢‘è¯·æ±‚å¯¼è‡´åç«¯æ¨ç†èµ„æºè€—å°½ã€‚ |
| **CI ä¼˜åŒ–** | å°† `test_manual/vlm` ä¸ `test_registered/openai_server` ä¸­çš„ **å¤§æ¨¡å‹ã€å›¾åƒ** æµ‹è¯•æ ‡è®°ä¸º `@unittest.skipIf(os.getenv("SKIP_SLOW"))`ï¼Œé»˜è®¤åœ¨ CI ä¸­æ‰§è¡Œï¼ŒPR æ£€æŸ¥æ—¶å¯æ‰‹åŠ¨æ‰“å¼€ã€‚ |
| **æ–‡æ¡£æ›´æ–°** | åœ¨é¡¹ç›® README / API æ–‡æ¡£ä¸­åŠ å…¥ Anthropic API çš„ **è¯·æ±‚ç¤ºä¾‹ã€å­—æ®µçº¦æŸã€é”™è¯¯ç è¡¨**ï¼Œå¸®åŠ©ç”¨æˆ·å¿«é€Ÿä¸Šæ‰‹å¹¶é¿å…è¯¯ç”¨ã€‚ |
| **ç›‘æ§æŒ‡æ ‡** | åœ¨ `AnthropicServing.handle_messages` ä¸­åŸ‹ç‚¹è®°å½• **è¯·æ±‚è½¬æ¢æ—¶å»¶ã€æµå¼è½¬ç æ—¶å»¶ã€å›¾ç‰‡ä½“ç§¯ã€

---

### [diffusion] refactor: reduce redundancy and improve stage api (#19060)
**SHA**: `b89ca65` | ğŸ”— [æŸ¥çœ‹æäº¤](https://github.com/sgl-project/sglang/commit/b89ca65789129567321a865165fae5bd56a8acda)

**ğŸ¯ å˜æ›´ç±»å‹**ï¼šé‡æ„ / åŠŸèƒ½å¢å¼º  
**âš¡ é‡è¦ç¨‹åº¦**ï¼šğŸ”´é«˜  
**ğŸ“‹ å˜æ›´æ‘˜è¦**ï¼š  
æœ¬æ¬¡æäº¤å¯¹ `sglangu` diffusion ç³»åˆ—çš„æµæ°´çº¿å®ç°è¿›è¡Œå¤§è§„æ¨¡é‡æ„ï¼Œç»Ÿä¸€å¹¶ç²¾ç®€äº† **Stage** çš„æ³¨å†Œæ–¹å¼ã€‚æ–°å¢ `ComposedPipelineBase` çš„ä¸€å¥— â€œæ ‡å‡† stageâ€ è¾…åŠ© APIï¼ˆ`add_standard_text_encoding_stage`ã€`add_standard_timestep_preparation_stage`ã€`add_standard_latent_preparation_stage`ã€`add_standard_denoising_stage`ã€`add_standard_decoding_stage` ä»¥åŠ `add_standard_t2i_stages`ã€`add_standard_ti2i_stages`ã€`add_standard_ti2v_stages` ç­‰ï¼‰ï¼Œå®ç° **é˜¶æ®µåç§°è‡ªåŠ¨æ¨æ–­ã€å»é‡æ ¡éªŒã€æ‰¹é‡æ·»åŠ **ã€‚åŸºäºæ­¤ï¼Œæ‰€æœ‰å…·ä½“ pipelineï¼ˆFluxã€Qwenã€WANã€LTX2 ç­‰ï¼‰å‡æ”¹å†™ä¸ºè°ƒç”¨è¿™äº›å·¥å…·å‡½æ•°ï¼Œåˆ é™¤äº†å†—ä½™çš„æ˜¾å¼ `add_stage(stage_name, stage)` ä»£ç ï¼Œå¹¶ç§»é™¤äº†å·²åºŸå¼ƒçš„ `ConditioningStage`ã€‚åŒæ—¶ï¼Œå¯¹ `DiffusersPipeline` çš„ `add_stage` æ¥å£åšäº†å‘åå…¼å®¹çš„ç­¾åè°ƒæ•´ã€‚

---

### ğŸ¯ å½±å“èŒƒå›´
- **æ ¸å¿ƒæ¨¡å—**ï¼š`python/sglang/multimodal_gen/runtime/pipelines_core/composed_pipeline_base.py`ï¼ˆæ–°å¢å¤§é‡é€šç”¨ API ä¸å†…éƒ¨å®ç°ï¼‰  
- **æ‰€æœ‰æµæ°´çº¿å®ç°**ï¼š`flux.pyã€flux_2.pyã€glm_image.pyã€hunyuan_pipeline.pyã€ltx_2_pipeline.pyã€mova_pipeline.pyã€qwen_image.pyã€wan_*_pipeline.pyã€zimage_pipeline.py` ç­‰ 20+ æ–‡ä»¶ã€‚  
- **æ–‡æ¡£**ï¼š`docs/diffusion/support_new_models.md`ï¼ˆæ›´æ–°ç¤ºä¾‹ï¼‰  
- **æµ‹è¯•/åŸºå‡†**ï¼š`test/server/*`ï¼ˆå»é™¤å¯¹å·²åˆ é™¤ `ConditioningStage` çš„ç»Ÿè®¡ï¼‰  
- **ä¾èµ–**ï¼š`diffusers_pipeline.py`ï¼ˆ`add_stage` å‚æ•°é¡ºåºå˜åŒ–ï¼‰  

---

## ğŸ” æŠ€æœ¯æ´å¯Ÿ

| ç»´åº¦ | å½±å“åˆ†æ |
|------|----------|
| **æ¶æ„å½±å“** | - å¼•å…¥ç»Ÿä¸€çš„ stage management å±‚ï¼Œé™ä½å„ pipeline å¯¹åº•å±‚ `add_stage` å®ç°çš„è€¦åˆã€‚<br>- è‡ªåŠ¨æ¨æ–­ stage åç§°ï¼ˆé©¼å³° â†’ snake_caseï¼‰å¹¶è¿›è¡Œå†²çªæ£€æµ‹ï¼Œæå‡å¯ç»´æŠ¤æ€§ã€‚<br>- é€šè¿‡ `add_stage_if`ã€`add_stages` æ”¯æŒæ¡ä»¶å¼æˆ–æ‰¹é‡æ³¨å†Œï¼Œä»£ç ç»“æ„æ›´å…·è¡¨è¾¾åŠ›ã€‚<br>- åˆ é™¤ `ConditioningStage`ï¼ˆä»…å ä½å®ç°ï¼‰ï¼Œç®€åŒ– pipeline ä¾èµ–æ ‘ã€‚ |
| **æ€§èƒ½å½±å“** | - æ–°å¢çš„åç§°æ¨æ–­ä½¿ç”¨æ­£åˆ™ï¼ŒCPU å¼€é”€æä½ï¼ˆçº³ç§’çº§ï¼‰ï¼Œå¯¹æ•´ä½“æ¨ç†æ—¶å»¶å‡ ä¹æ— å½±å“ã€‚<br>- `add_stage` ç°åœ¨è¿”å› `self`ï¼Œé“¾å¼è°ƒç”¨ä¸ä¼šäº§ç”Ÿé¢å¤–å¼€é”€ã€‚<br>- å»é™¤å†—ä½™çš„ `setattr(self, stage_name, stage)`ï¼Œç•¥å¾®å‡å°å®ä¾‹å±æ€§æ•°é‡ï¼Œå†…å­˜å ç”¨å¯å¾®é™ã€‚<br>- åŸºå‡†æ•°æ®ï¼ˆ`perf_baselines.json`ï¼‰å·²åŒæ­¥åˆ é™¤ `ConditioningStage` æ—¶é—´ï¼Œå®é™…æ¨ç†æ—¶é•¿ä¿æŒä¸å˜ã€‚ |
| **å®‰å…¨è€ƒè™‘** | - æ–°å¢çš„ **é‡å¤ stage åç§°æ£€æŸ¥** é˜²æ­¢æ„å¤–è¦†ç›–å·²æœ‰ stageï¼Œé™ä½å› é”™è¯¯é…ç½®å¯¼è‡´çš„è¿è¡Œæ—¶å¼‚å¸¸ã€‚<br>- `ConditioningStage` è¢«å½»åº•åˆ é™¤ï¼Œè¿‡å»çš„å ä½å®ç°æœªæ‰§è¡Œä»»ä½•å®‰å…¨æ•æ„Ÿé€»è¾‘ï¼Œåˆ é™¤ä¸ä¼šæš´éœ²é£é™©ã€‚<br>- é€šè¿‡ `stage_name | None` å‚æ•°ï¼Œé¿å…å¤–éƒ¨ç›´æ¥ä¼ å…¥æ¶æ„å­—ç¬¦ä¸²è¦†ç›–å…³é”®å±æ€§ï¼ˆå·²åŠ æ˜¾å¼æ ¡éªŒï¼‰ã€‚ |
| **å¯ç»´æŠ¤æ€§** | - å¤§å¹…é™ä½æ¯ä¸ª pipeline ä¸­çš„æ ·æ¿ä»£ç ï¼ˆä» 30+ è¡Œç¼©å‡åˆ° 5~10 è¡Œï¼‰ï¼Œæ›´æ˜“é˜…è¯»å’Œç»´æŠ¤ã€‚<br>- ç»Ÿä¸€çš„ helper æ–¹æ³•ä½¿æ–°å¢æ¨¡å‹åªéœ€é…ç½®å°‘é‡å‚æ•°å³å¯å®Œæˆå®Œæ•´æµæ°´çº¿æ­å»ºã€‚<br>- `add_stage_if` ä¸ºæœªæ¥çš„å¯é€‰ stageï¼ˆå¦‚å®éªŒæ€§ conditioningï¼‰æä¾›äº†å®‰å…¨çš„å¯æ’æ‹”ç‚¹ã€‚ |
| **å…¼å®¹æ€§** | - `DiffusersPipeline.add_stage` ç­¾åä» `(stage_name, stage)` æ”¹ä¸º `(stage, stage_name=None)`ï¼Œå¯èƒ½å¯¼è‡´ç¬¬ä¸‰æ–¹ä»£ç ç›´æ¥è°ƒç”¨æ—§ç­¾åè€ŒæŠ¥é”™ã€‚<br>- æ—§ pipeline ä¸­æ˜¾å¼ä½¿ç”¨ `stage_name=` å‚æ•°å·²è¢«å…¨éƒ¨è¿ç§»ï¼Œä½†å¦‚æœå¤–éƒ¨å·¥ç¨‹è‡ªè¡Œæ‰©å±• pipeline å¹¶ä»ä½¿ç”¨æ—§è°ƒç”¨æ–¹å¼ï¼Œéœ€è¦æ‰‹åŠ¨é€‚é…ã€‚ |
| **æµ‹è¯•/æ–‡æ¡£** | - æ–‡æ¡£ç¤ºä¾‹æ›´æ–°ä¸ºä¸å†æ˜¾å¼ä¼ é€’ `stage_name`ï¼ŒåŒæ­¥åˆ° `support_new_models.md`ã€‚<br>- Baseline JSON ä¸­åˆ å» `ConditioningStage` é¡¹ç›®ï¼Œé˜²æ­¢è¯¯æŠ¥ã€‚<br>- `testcase_configs.py` è°ƒæ•´äº†æµ‹è¯•è·¯å¾„ï¼Œæå‡ CI çµæ´»æ€§ã€‚ |

---

## âš ï¸ æ½œåœ¨é£é™©
1. **å‘åå…¼å®¹**ï¼šä»»ä½•ä»ç„¶ä¾èµ– `add_stage(stage_name, stage)`ï¼ˆå°¤å…¶æ˜¯ç¬¬ä¸‰æ–¹æ’ä»¶æˆ–è‡ªå®šä¹‰ pipelineï¼‰ä¼šåœ¨è¿è¡Œæ—¶æŠ›å‡º `TypeError`ã€‚  
2. **Stage åç§°å†²çª**ï¼šè™½ç„¶å·²åŠ å…¥å†²çªæ£€æµ‹ï¼Œä½†è‹¥ä½¿ç”¨äº†è‡ªå®šä¹‰ `stage_name` å‚æ•°ï¼ˆé `None`) å¹¶ä¸è‡ªåŠ¨æ¨æ–­åé‡å¤ï¼Œä»ä¼šè§¦å‘å¼‚å¸¸ï¼Œéœ€è¦åœ¨è¿ç§»æ—¶æ˜¾å¼æ£€æŸ¥ã€‚  
3. **Conditioning åŠŸèƒ½ç¼ºå¤±**ï¼šå½“å‰ `ConditioningStage` è¢«å®Œå…¨ç§»é™¤ã€‚å¦‚æœåç»­æ¨¡å‹éœ€è¦ **classifierâ€‘free guidance** æˆ–å…¶ä»– conditioning é€»è¾‘ï¼Œéœ€è¦è‡ªè¡Œåœ¨ç›¸åº” pipeline ä¸­åŠ å…¥è‡ªå®šä¹‰ stageï¼ˆå¯é€šè¿‡ `add_stage_if` å®ç°ï¼‰ã€‚  
4. **å¯¼å…¥è·¯å¾„å˜åŠ¨**ï¼š`stages/__init__.py` ç§»é™¤å¯¹ `ConditioningStage` çš„å¯¼å‡ºï¼Œè‹¥å¤–éƒ¨ `from â€¦stages import ConditioningStage` å°†å¤±æ•ˆã€‚  
5. **éšæœºæ€§å¼•å…¥**ï¼š`add_stage` ç°åœ¨ä¼šè‡ªåŠ¨æ¨æ–­åç§°ï¼Œè‹¥å·²æœ‰åŒå stageï¼ˆæ¯”å¦‚æ‰‹åŠ¨æŒ‡å®šï¼‰ï¼Œä¼šæŠ¥é”™ï¼›å› æ­¤åœ¨è¿ç§»æœŸé—´éœ€è¦ç¡®ä¿æ‰€æœ‰æ‰‹å·¥å‘½åå‡å”¯ä¸€ã€‚  

---

## ğŸ’¡ å…³æ³¨å»ºè®®
1. **è¿ç§»æ£€æŸ¥**  
   - åœ¨é¡¹ç›®æ ¹ç›®å½•æ‰§è¡Œä¸€æ¬¡æœç´¢ `add_stage(` å¹¶ç¡®è®¤æ²¡æœ‰ä½¿ç”¨æ—§ç­¾åï¼›è‹¥æœ‰ï¼Œæ”¹å†™ä¸º `pipeline.add_stage(StageClass(...))` æˆ– `pipeline.add_stage(StageClass(...), "custom_name")`ã€‚  
   - å¯¹ä½¿ç”¨ `ConditioningStage` çš„ä»£ç åšå®¡è®¡ï¼Œç¡®è®¤æ˜¯å¦çœŸçš„éœ€è¦è¯¥åŠŸèƒ½ï¼›è‹¥éœ€è¦ï¼Œè¯·å®ç°è‡ªå®šä¹‰ stage å¹¶é€šè¿‡ `add_stage_if` æˆ– `add_stage` æ³¨å†Œã€‚  

2. **æ–°å¢ pipeline æ¨èå†™æ³•**  
   ```python
   class MyNewPipeline(ComposedPipelineBase):
       def create_pipeline_stages(self, server_args):
           self.add_standard_t2i_stages(
               include_input_validation=True,
               prepare_extra_timestep_kwargs=[my_extra_prepare],
           )
           # å¦‚éœ€é¢å¤–è‡ªå®šä¹‰ stage:
           self.add_stage_if(
               condition=self.some_feature_enabled,
               stage=MyCustomStage(...),
           )
   ```  

3. **æ–‡æ¡£ä¸ CI**  
   - æ›´æ–°é¡¹ç›® CONTRIBUTING / API æ–‡æ¡£ï¼Œè¯´æ˜ `add_stage` çš„æ–°ç­¾ååŠè‡ªåŠ¨å‘½åè§„åˆ™ã€‚  
   - åœ¨ CI ä¸­åŠ å…¥ä¸€ä¸ªå…¼å®¹æ€§æ£€æŸ¥è„šæœ¬ï¼Œç¡®ä¿æ‰€æœ‰è‡ªå®šä¹‰ pipelines åœ¨ CI ç¯å¢ƒå¯ä»¥æˆåŠŸå®ä¾‹åŒ–ã€‚  

4. **å®‰å…¨/å¼‚å¸¸ç›‘æ§**  
   - é€šè¿‡æ—¥å¿—ï¼ˆ`init_logger`ï¼‰è®°å½•æ¯ä¸€æ¬¡ `add_stage` çš„å®é™…æ¨æ–­åç§°ï¼Œä¾¿äºæ’æŸ¥å†²çªã€‚  
   - è‹¥åœ¨ç”Ÿäº§ç¯å¢ƒéœ€è¦å¼€å¯ **Conditioning**ï¼Œå»ºè®®åœ¨å¯¹åº” pipeline ä¸­æ˜¾å¼åŠ å…¥ `ConditioningStage`ï¼ˆå·²ä»å®˜æ–¹ç§»é™¤ï¼Œéœ€è‡ªè¡Œå®ç°ï¼‰å¹¶åšå¥½è¾“å…¥æ ¡éªŒã€‚  

5. **æ€§èƒ½å›å½’**  
   - è™½ç„¶ä»£ç å±‚é¢çš„æ”¹åŠ¨å¯¹æ¨ç†æ—¶å»¶å‡ ä¹æ²¡æœ‰å½±å“ï¼Œä½†å»ºè®®åœ¨å…³é”®æ¨¡å‹ä¸Šï¼ˆå¦‚ `flux_image_t2i`ã€`wan_causal_dmd`ï¼‰è·‘ä¸€æ¬¡å®Œæ•´çš„åŸºå‡†å¯¹æ¯”ï¼Œç¡®ä¿ baseline æ•°æ®ä»ç¬¦åˆæœŸæœ›ã€‚  

---

**æ€»ä½“ç»“è®º**ï¼šæ­¤è½®é‡æ„æå¤§æå‡äº†

---

### Refactor graph input buffers (#18991)
**SHA**: `84c67c8` | ğŸ”— [æŸ¥çœ‹æäº¤](https://github.com/sgl-project/sglang/commit/84c67c8be0a13bdf9749f674f0501461770fb4f7)

**ğŸ¯ å˜æ›´ç±»å‹**ï¼šé‡æ„ / æ¶æ„å˜æ›´  
**âš¡ é‡è¦ç¨‹åº¦**ï¼šğŸ”´é«˜  

**ğŸ“‹ å˜æ›´æ‘˜è¦**  
- å°†åŸæœ‰çš„ `GraphInputBuffers` æ‹†è§£ä¸ºé€šç”¨åŸºç±» `ForwardInputBuffers`ï¼Œå¹¶åœ¨ä¸åŒæ‰§è¡Œè·¯å¾„ï¼ˆdecodeã€prefillã€eagleâ€‘draftã€eagleâ€‘draftâ€‘extendã€multiâ€‘layerâ€‘eagleâ€‘draftâ€‘extendï¼‰ä¸Šå®ç°ä¸“å±å­ç±»ã€‚  
- å¼•å…¥ `share_buffers()` ä¸å†…éƒ¨ `_share_one_buffer()`ï¼Œåœ¨åŒä¸€è¿›ç¨‹/åŒä¸€ GPU è®¾å¤‡ä¸Šå®ç° **è·¨ Runner ç»Ÿä¸€å¤ç”¨** çš„å¼ é‡æ± ï¼Œé¿å…æ¯æ¬¡æ•è· CUDA Graph æ—¶é‡æ–°åˆ†é…å¤§å—å†…å­˜ã€‚  
- ä»£ç å±‚é¢å¯¹ `CudaGraphRunner`ã€`PiecewiseCudaGraphRunner`ã€å„ç±» Eagle CUDA Graph Runner ç­‰å¤§é‡è°ƒç”¨ç‚¹åšäº† **ç±»å‹å‡çº§**ï¼ˆä» `GraphInputBuffers` â†’ å¯¹åº”å­ç±»ï¼‰å¹¶åŒæ­¥æ›´æ–°äº†å¯¹ `seq_lens_cpu`ã€`pp_proxy_tensors`ã€`global_num_tokens_*` ç­‰å­—æ®µçš„è®¿é—®è·¯å¾„ã€‚  

**ğŸ¯ å½±å“èŒƒå›´**  
- `python/sglang/srt/model_executor/cuda_graph_runner.py`  
- `python/sglang/srt/model_executor/input_buffers.py`ï¼ˆæ ¸å¿ƒå®ç°ï¼‰  
- `python/sglang/srt/model_executor/model_runner.py`ï¼ˆåˆ›å»ºå…¥å£ï¼‰  
- `python/sglang/srt/model_executor/piecewise_cuda_graph_runner.py`ï¼ˆprefillï¼‰  
- `python/sglang/srt/speculative/eagle_draft_*_cuda_graph_runner.py`ï¼ˆeagleã€eagleâ€‘extendï¼‰  
- `python/sglang/srt/speculative/multi_layer_eagle_draft_extend_cuda_graph_runner.py`  
- ç›¸å…³ `worker` ä¸ `adapter` ä»£ç ï¼ˆå¯¹æ–° buffers çš„å¼•ç”¨ï¼‰  

---

### ğŸ” æŠ€æœ¯æ´å¯Ÿ  

#### 1. æ¶æ„å½±å“  
| ç»´åº¦ | å½±å“æè¿° |
|------|----------|
| **æ¨¡å—è§£è€¦** | å°†åŸå…ˆâ€œä¸€æ½å­â€`GraphInputBuffers` ç»†åˆ†ä¸º **åŠŸèƒ½ä¸“å±** çš„æ•°æ®ç»“æ„ã€‚æ¯ä¸ª Runner åªä¿ç•™è‡ªå·±çœŸæ­£éœ€è¦çš„å¼ é‡ï¼Œæå‡äº†ä»£ç çš„å¯è¯»æ€§ä¸ç»´æŠ¤æ€§ã€‚ |
| **ç»Ÿä¸€æ¥å£** | åŸºç±» `ForwardInputBuffers` é€šè¿‡ `dataclass` å®šä¹‰ç»Ÿä¸€çš„ `share_buffers()`ï¼Œå­ç±»åªéœ€å¡«å……å­—æ®µå³å¯è‡ªåŠ¨è·ç›Šï¼Œé™ä½é‡å¤å®ç°é£é™©ã€‚ |
| **è·¨ Runner å¤ç”¨** | `_forward_input_buffer_pool` ç»´æŠ¤å…¨å±€å¼ é‡æ˜ å°„ï¼Œ`share_buffers()` å°†åŒåå¼ é‡åœ¨ä¸åŒå®ä¾‹é—´ **æŒ‡å‘ç›¸åŒå†…å­˜**ï¼ˆ`as_strided`ï¼‰ï¼Œä»è€Œå®ç° **é›¶æ‹·è´å¤ç”¨**ã€‚è¿™åœ¨å¤šçº¿ç¨‹/å¤šè¿›ç¨‹ï¼ˆå¦‚ SGLang çš„ `model_worker`ï¼‰å…±äº«åŒä¸€ GPU è®¾å¤‡æ—¶å°¤ä¸ºé‡è¦ã€‚ |
| **å›¾æ•è·æµç¨‹** | æ•è·é˜¶æ®µä¸å†é‡æ–° `torch.zeros` å¤§é‡ç¼“å†²åŒºï¼Œè€Œæ˜¯ **é‡ç”¨å·²æœ‰å¼ é‡**ï¼Œå¤§å¹…é™ä½ CUDA Graph æ•è·å‰çš„å†…å­˜åˆ†é…ä¸åŒæ­¥å¼€é”€ã€‚ |
| **å‘åå…¼å®¹** | `ModelRunner._dummy_run`ã€`CudaGraphRunner.__init__` ç­‰ä»ä½¿ç”¨ `DecodeInputBuffers.create()`ï¼Œå¯¹å¤–æ¥å£ä¸å˜ï¼Œç”¨æˆ·å±‚æ„ŸçŸ¥ä¸åˆ°å˜åŒ–ã€‚ |

#### 2. æ€§èƒ½å½±å“  
| åœºæ™¯ | é¢„æœŸæ”¶ç›Š | å…³é”®å› ç´  |
|------|----------|----------|
| **é¦–æ¬¡å¯åŠ¨ / Graph Capture** | **~30â€‘50%** çš„å¯åŠ¨æ—¶é—´ä¸‹é™ï¼ˆå–å†³äºæ¨¡å‹å¤§å°å’Œæ˜¾å­˜ï¼‰ï¼Œå› ä¸ºå¤§å—å¼ é‡åªåˆ†é…ä¸€æ¬¡ï¼Œåç»­ `create()` ä»…è¿”å›å·²æœ‰è§†å›¾ã€‚ | `share_buffers()` ä½¿ç”¨ `as_strided` å…±äº«åº•å±‚å†…å­˜ï¼Œé¿å… `torch.empty` ä¸ `cudaMemcpy`ã€‚ |
| **è¿è¡Œæ—¶å†…å­˜å ç”¨** | åŒä¸€å¼ é‡åœ¨å¤šä¸ª Runner ä¸­åªä¿ç•™ **å•ä»½å‰¯æœ¬**ï¼Œæ˜¾å­˜å ç”¨å¯é™ä½ 150â€‘300â€¯MiBï¼ˆä»¥ 70B å‚æ•°æ¨¡å‹ä¸ºä¾‹ï¼‰ï¼Œç•™å‡ºæ›´å¤šç©ºé—´ç»™ KV Cache ä¸æ¿€æ´»ç¼“å­˜ã€‚ | å…¨å±€ç¼“å†²æ±  `_forward_input_buffer_pool`ã€‚ |
| **æ‰¹æ¬¡åˆ‡æ¢ï¼ˆä¸åŒ batch sizeï¼‰** | ä»éœ€ `fill_` / `zero_` è¿›è¡Œæ•°æ®é‡ç½®ï¼Œä½†æ— éœ€é‡æ–°åˆ†é…ï¼›å¯¹ **å¤§ batch** åœºæ™¯å°¤ä¸ºæ˜æ˜¾ã€‚ | `populate_from_forward_batch` é€»è¾‘ä¿æŒä¸å˜ï¼Œä»…æ”¹ä¸ºä½¿ç”¨ `self.buffers`ã€‚ |
| **å¤šå±‚ Eagle è¿­ä»£** | å…±äº«çš„ `global_num_tokens_gpu`ã€`global_num_tokens_for_logprob_gpu` å¯åœ¨å¤š step ä¹‹é—´å¤ç”¨ï¼Œé™ä½è·¨ step åŒæ­¥æˆæœ¬ã€‚ | å­ç±» `MultiLayerEagleDraftExtendInputBuffers` ç›´æ¥å¤ç”¨çˆ¶çº§å¼ é‡ã€‚ |

#### 3. å®‰å…¨è€ƒè™‘  
- **çº¿ç¨‹å®‰å…¨**ï¼šå…¨å±€ç¼“å†²æ± æ˜¯ **è¿›ç¨‹çº§** å•ä¾‹ï¼Œå½“å‰å®ç°æ²¡æœ‰åŠ é”ã€‚å¦‚æœåœ¨åŒä¸€è¿›ç¨‹çš„å¤šä¸ªçº¿ç¨‹ï¼ˆå¦‚ Python `threading`ï¼‰å¹¶å‘åˆ›å»º `ForwardInputBuffers`ï¼Œå¯èƒ½å‡ºç°ç«äº‰å†™å…¥å¯¼è‡´å¼ é‡å±æ€§è¢«æ„å¤–è¦†ç›–ã€‚SGLang ä¸»ä½“ä½¿ç”¨ **å¤šè¿›ç¨‹** è€Œéå¤šçº¿ç¨‹ï¼Œé£é™©è¾ƒä½ï¼Œä½†ä»å»ºè®®åœ¨æœªæ¥åŠ å…¥è½»é‡çº§é”æˆ– `torch.multiprocessing` çš„å…±äº«å†…å­˜æœºåˆ¶ã€‚  
- **é”™è¯¯ä¼ æ’­**ï¼š`_share_one_buffer` åœ¨ dtypeã€device ä¸åŒ¹é…æ—¶ä¼š `assert` æŠ›å¼‚å¸¸ã€‚è‹¥ä¸åŒ Runner åœ¨ä¸åŒ precisionï¼ˆfp16 â†” bf16ï¼‰æˆ–ä¸åŒ GPUï¼ˆe.g., 0 vs 1ï¼‰ä¸Šåˆ›å»ºï¼Œä¼šè§¦å‘æ–­è¨€ï¼Œå¸®åŠ©å¿«é€Ÿå®šä½é…ç½®é”™è¯¯ã€‚  
- **å†…å­˜æ³„æ¼**ï¼šå› ä¸ºæ‰€æœ‰å¼ é‡å‡ç”± `torch` æŒæœ‰å¼•ç”¨ï¼Œè€Œ `share_buffers` åªè¿”å› **è§†å›¾**ï¼Œä¸ä¼šäº§ç”Ÿé¢å¤–å¼•ç”¨è®¡æ•°ï¼Œç†è®ºä¸Šä¸ä¼šå¯¼è‡´æ³„æ¼ã€‚ä½†è‹¥åœ¨ç”Ÿå‘½å‘¨æœŸå¤–æ‰‹åŠ¨ `del` æŸä¸ª Runner å®ä¾‹ï¼Œä»ä¼šä¿ç•™å…¨å±€å¼ é‡ï¼Œæ˜¾å­˜ä¸ä¼šç«‹å³é‡Šæ”¾ã€‚éœ€è¦åœ¨è¿›ç¨‹ç»“æŸæˆ–æ˜¾å­˜å›æ”¶é˜¶æ®µæ‰‹åŠ¨æ¸…ç©º `_forward_input_buffer_pool`ï¼ˆå¯é€šè¿‡æ–°å¢ `clear_buffer_pool()` æ¥å£å®ç°ï¼‰ã€‚  

---

### âš ï¸ æ½œåœ¨é£é™©  

| é£é™©ç‚¹ | å¯èƒ½åæœ | æ¨èå¯¹ç­– |
|--------|----------|----------|
| **å…¨å±€å¼ é‡æ± ä¸å…¼å®¹çš„ dtype/device** | ç¨‹åºåœ¨ä¸åŒ `dtype`ï¼ˆfp16/ bf16/ fp32ï¼‰æˆ–è·¨ GPU è®¾å¤‡é—´åˆ‡æ¢æ—¶è§¦å‘æ–­è¨€ï¼Œå¯¼è‡´ Runner å¯åŠ¨å¤±è´¥ã€‚ | åœ¨ `ModelRunner` å¯åŠ¨å‰ç»Ÿä¸€æ£€æŸ¥ `device` ä¸ `dtype`ï¼Œæˆ–åœ¨ `share_buffers` ä¸­åŠ å…¥ **è‡ªåŠ¨å‡çº§/æ‹·è´**ï¼ˆå¦‚ `to(device, dtype)`ï¼‰çš„å®¹é”™è·¯å¾„ã€‚ |
| **åŒåå¼ é‡å†²çª**ï¼ˆä¾‹å¦‚å­ç±»æ–°å¢å­—æ®µåŒåä½†å½¢çŠ¶ä¸åŒï¼‰ | `as_strided` ä¼šå¤ç”¨é”™è¯¯å°ºå¯¸çš„å¼ é‡ï¼Œå¼•å‘ç»´åº¦ä¸åŒ¹é…çš„è¿è¡Œæ—¶é”™è¯¯ï¼ˆCUBLASã€kernel launch failureï¼‰ã€‚ | åœ¨ `_share_one_buffer` åŠ å…¥ **shape æ£€æŸ¥**ï¼ˆé™¤éæ˜¾å¼å…è®¸ reshapeï¼‰ï¼Œåœ¨ä¸åŒ¹é…æ—¶é‡æ–°åˆ†é…å¹¶æ›´æ–°æ± ã€‚ |
| **å¤šè¿›ç¨‹å…±äº«å¼ é‡** | ç›®å‰æœªè·¨è¿›ç¨‹å…±äº«ï¼ˆæ¯è¿›ç¨‹å„æœ‰ç‹¬ç«‹ Python è§£é‡Šå™¨ï¼‰ï¼Œä½†å¦‚æœæœªæ¥æ”¹ä¸º `torch.multiprocessing.spawn`ï¼Œå…¨å±€æ± ä¼šåœ¨æ¯ä¸ªå­è¿›ç¨‹ç‹¬ç«‹åˆ›å»ºï¼Œå¯¼è‡´æ˜¾å­˜å€å¢ã€‚ | æ˜ç¡®åœ¨æ–‡æ¡£ä¸­è¯´æ˜ **å…¨å±€æ± ä»…åœ¨å•è¿›ç¨‹å†…éƒ¨ç”Ÿæ•ˆ**ï¼Œæˆ–æä¾› `fork`/`spawn` å…¼å®¹çš„åˆå§‹åŒ–æ¸…ç†é€»è¾‘ã€‚ |
| **æ¢¯åº¦è®¡ç®—**ï¼ˆè™½ç„¶å¤§å¤šæ•°ç¼“å†²åŒºåªç”¨äº forwardï¼‰ | è‹¥è¯¯å°† `share_buffers` çš„å¼ é‡ç”¨äº `requires_grad=True` çš„è®¡ç®—ï¼Œæ¢¯åº¦ä¼šåœ¨å¤šä¸ª Runner ä¹‹é—´äº’ç›¸å½±å“ã€‚ | å¯¹æ‰€æœ‰å…±äº«ç¼“å†²åŒºç»Ÿä¸€è®¾ `requires_grad=False`ï¼ˆé»˜è®¤ï¼‰ï¼Œå¹¶åœ¨ `create()` æ˜ç¡®å£°æ˜ã€‚ |
| **å›é€€å…¼å®¹æ€§** | æ—§ä»£ç ä»å¯èƒ½å¼•ç”¨ `GraphInputBuffers`ï¼ˆå¦‚ç¬¬ä¸‰æ–¹æ’ä»¶ï¼‰ã€‚ | ä¿æŒ `GraphInputBuffers` **åˆ«å**ï¼ˆåœ¨ `input_buffers.py` ä¸­ `GraphInputBuffers = DecodeInputBuffers`ï¼‰æˆ–æä¾›å‘åå…¼å®¹åŒ…è£…ç±»ã€‚ |

---

### ğŸ’¡ å…³æ³¨å»ºè®®  

1. **æ˜¾å¼æ¸…ç†å…¨å±€æ± **  
   - åœ¨è¿›ç¨‹ç»“æŸæˆ–æ¨¡å‹çƒ­é‡è½½å‰è°ƒç”¨ `sglang.srt.model_executor.input_buffers.clear_buffer_pool()`ï¼ˆå¯è‡ªè¡Œå®ç°ï¼‰ä»¥é‡Šæ”¾æ˜¾å­˜ï¼Œé˜²æ­¢æ˜¾å­˜â€œ

---

### [AMD] support two batch overlapping for mori ep (#17953)
**SHA**: `fbb6098` | ğŸ”— [æŸ¥çœ‹æäº¤](https://github.com/sgl-project/sglang/commit/fbb60984872ee69d868b595f81c0155b15601de5)

**ğŸ¯ å˜æ›´ç±»å‹**ï¼šåŠŸèƒ½å¢å¼º / æ€§èƒ½ä¼˜åŒ–  
**âš¡ é‡è¦ç¨‹åº¦**ï¼šğŸ”´é«˜  

**ğŸ“‹ å˜æ›´æ‘˜è¦**  
- ä¸º MoE çš„ Allâ€‘toâ€‘All åç«¯æ–°å¢ **`mori`**ï¼Œå¹¶å®ç°ä¸¤æ‰¹æ¬¡ï¼ˆtwoâ€‘batchï¼‰é‡å è°ƒåº¦ï¼Œæ”¯æŒ AMD HIP GPU ä¸Šçš„ä½å»¶è¿Ÿï¼ˆlowâ€‘latencyï¼‰è°ƒåº¦è·¯å¾„ã€‚  
- å¼•å…¥ `MoriEPDispatcher`ã€å¯¹åº”çš„ `DispatchOutput`/`CombineInput` ç±»å‹ã€ä»¥åŠä¸“å±çš„ `MoriEPPDispatchHooks`ï¼Œå¹¶åœ¨ `batch_overlap`ã€`attention`ã€`moe` ç­‰æ ¸å¿ƒæ¨¡å—ä¸­æ ¹æ®åç«¯åŠ¨æ€åˆ‡æ¢å®ç°ã€‚  
- æ›´æ–°æ–‡æ¡£ã€æœåŠ¡å™¨å‚æ•° (`--moe-a2a-backend`) ä»¥åŠå†…éƒ¨æµ‹è¯•åŸºå‡†ï¼Œä»¥é€‚é…æ–°åç«¯å¹¶æä¾›æ›´çµæ´»çš„ `chunked_prefill` æ£€æŸ¥ã€‚  

**ğŸ¯ å½±å“èŒƒå›´**  
- `python/sglang/srt/batch_overlap/*`  
- `python/sglang/srt/layers/moe/*`ï¼ˆç‰¹åˆ¥æ˜¯ `ep_moe/layer.py`ã€`token_dispatcher/moriep.py`ï¼‰  
- `python/sglang/srt/layers/attention/aiter_backend.py`ï¼ˆå…ƒæ•°æ®ç»“æ„æ‰©å±•ï¼‰  
- `python/sglang/srt/server_args.py`ï¼ˆæ–°å¢åç«¯é€‰é¡¹ã€å‚æ•°æ ¡éªŒï¼‰  
- æ–‡æ¡£ `docs/advanced_features/server_arguments.md`  
- æµ‹è¯•è„šæœ¬ `test/bench_one_batch_server_internal.py`ï¼ˆç»Ÿè®¡ DPâ€‘size ä¸ token capacityï¼‰  

---

### ğŸ” æŠ€æœ¯æ´å¯Ÿ  

| ç»´åº¦ | å½±å“æè¿° |
|------|----------|
| **æ¶æ„å½±å“** | â€¢ æ–°å¢ **Mori EP** è°ƒåº¦å™¨ï¼Œå®ç° **ä¸¤æ‰¹æ¬¡é‡å **ï¼ˆdispatchâ€¯â†”â€¯combineï¼‰æ¨¡å‹ï¼Œè¦æ±‚åœ¨ `MoriEPDispatcher` ä¸­ç»´æŠ¤è®¡ç®—æµä¸é€šä¿¡æµï¼ˆ`CommStreamPool`ï¼‰ä»¥åŠå¼‚æ­¥äº‹ä»¶åŒæ­¥ã€‚<br>â€¢ åœ¨ `token_dispatcher/__init__.py` æš´éœ² `MoriEPLL*` ç±»å‹ï¼Œå½¢æˆç»Ÿä¸€çš„ `DispatchOutput`/`CombineInput` æŠ½è±¡ï¼Œä½¿å¾—åç«¯å¯è‡ªç”±åˆ‡æ¢ï¼ˆ`none` / `deepep` / `mooncake` / `mori`ï¼‰ã€‚<br>â€¢ é€šè¿‡ `MoriEPPDispatchHooks` ä¸ºåç«¯æä¾›å¯æ’æ‹”çš„ Hook æœºåˆ¶ï¼Œä¿æŒä¸åŸæœ‰ DeepEP/ Mooncake ä»£ç çš„å…¼å®¹ã€‚ |
| **æ€§èƒ½å½±å“** | â€¢ **ä¸¤æ‰¹æ¬¡é‡å **ï¼šåœ¨ `dispatch_a` â†’ `dispatch_b` ä¸ `combine_a` â†’ `combine_b` ä¹‹é—´ä½¿ç”¨ç‹¬ç«‹çš„ CUDA/HIP æµï¼Œå®ç° *é€šä¿¡â€‘è®¡ç®—å¹¶è¡Œ*ï¼Œæ˜¾è‘—é™ä½ EP è°ƒåº¦çš„åŒæ­¥å¼€é”€ã€‚<br>â€¢ `MoriEPDispatcher` åœ¨ **ä½å»¶è¿Ÿæ¨¡å¼** (`DeepEPMode.LOW_LATENCY`) ä½¿ç”¨ `AsyncLL` kernelï¼Œè¿›ä¸€æ­¥å‹ç¼©è°ƒåº¦å»¶è¿Ÿã€‚<br>â€¢ å¯¹ `attention` å…ƒæ•°æ®æ–°å¢ `mla` ç›¸å…³å­—æ®µï¼Œé¿å…åœ¨é MLA åœºæ™¯ä¸‹é¢å¤–åˆ†é…ã€‚<br>â€¢ åœ¨é HIP ç¯å¢ƒä»ä¿æŒåŸæœ‰ `deep_gemm_num_sms` è®¡ç®—é€»è¾‘ï¼Œä¿æŒæ€§èƒ½åŸºå‡†ä¸å˜ã€‚ |
| **å®‰å…¨è€ƒè™‘** | â€¢ ä»…å¼•å…¥äº† **ç¯å¢ƒå˜é‡** (`SGLANG_MORI_FP8_DISP`ã€`SGLANG_MORI_NUM_MAX_DISPATCH_TOKENS_PER_RANK` ç­‰) ä»¥åŠ **HIP æ£€æµ‹**ï¼ˆ`is_hip()`ï¼‰ï¼Œæœªæ”¹å˜ç½‘ç»œæˆ–ç£ç›˜è®¿é—®è·¯å¾„ï¼Œå®‰å…¨é£é™©æä½ã€‚<br>â€¢ éœ€è¦ç¡®ä¿ `is_hip()` çš„å®ç°ä¸è¯¯åˆ¤ï¼Œä»¥å…åœ¨ CUDA ç¯å¢ƒä¸‹é”™è¯¯è¯»å– HIPâ€‘only ä»£ç å¯¼è‡´å´©æºƒã€‚ |
| **å¯ç»´æŠ¤æ€§** | â€¢ ä»£ç é‡å¤§ï¼ˆ+723 / -150 è¡Œï¼‰ï¼Œä½†é€šè¿‡ **ç»Ÿä¸€çš„æŠ½è±¡å±‚**ï¼ˆ`DispatchOutputFormat`ã€`CombineInputFormat`ï¼‰ä¿æŒäº†å¯¹å·²æœ‰åç«¯çš„æœ€å°ä¾µå…¥ã€‚<br>â€¢ æ–°å¢å¤§é‡ `assert` ä¸æ—¥å¿—ï¼Œä¾¿äºè°ƒè¯•ã€‚<br>â€¢ ä»æœ‰ **TODO** æ³¨é‡Šï¼ˆå¦‚ intraâ€‘node async é…ç½®ï¼‰ï¼Œåç»­å¯èƒ½éœ€è¦è¿›ä¸€æ­¥è°ƒå‚ã€‚ |

---

### âš ï¸ æ½œåœ¨é£é™©  

1. **å¼‚æ­¥æµåŒæ­¥é”™è¯¯**  
   - `CommStreamPool` ä¸äº‹ä»¶æ•è· (`_capture_event_if_async`) ä¾èµ–æ­£ç¡®çš„ `wait_event`/`wait_stream` è°ƒç”¨ã€‚è‹¥æŸä¸€è·¯å¾„å¿˜è®° `record_stream`ï¼Œå¯èƒ½å‡ºç°æ•°æ®ç«äº‰æˆ–æœªåŒæ­¥å¯¼è‡´é”™è¯¯ç»“æœã€‚  

2. **HIP ä¸ CUDA åˆ†æ”¯å·®å¼‚**  
   - åœ¨ `operations_strategy.py`ã€`aiter_backend.py` ç­‰å¤„å¯¹ `is_hip()` åšäº†åˆ†æ”¯ï¼Œè‹¥æœªæ¥åœ¨æ··åˆå¹³å°ä¸Šè¿è¡Œï¼ˆå¦‚ CPUâ€¯+â€¯GPUâ€¯+â€¯HIPï¼‰ï¼Œå¯èƒ½å‡ºç° `deep_gemm_num_sms` ä¸º `None` å¯¼è‡´åç»­ç®—å­å‡è®¾è¯¥å€¼éç©ºè€ŒæŠ¥é”™ã€‚  

3. **ä½å»¶è¿Ÿæ¨¡å¼ä¸‹çš„èµ„æºæ³„æ¼**  
   - `CommStreamPool` åˆ›å»ºçš„ CUDA æµæœªåœ¨è¿›ç¨‹ç»“æŸæˆ– `MoriEPDispatcher` é”€æ¯æ—¶æ˜¾å¼é‡Šæ”¾ï¼Œé•¿æ—¶é—´è¿è¡Œçš„æœåŠ¡å¯èƒ½ç´¯ç§¯æµå¯¹è±¡ã€‚  

4. **å…¼å®¹æ€§å›å½’**  
   - `server_args._handle_a2a_moe` æ”¹ä¸ºä¸å¼ºåˆ¶è®¾ç½® `deepep_mode="normal"`ï¼Œè‹¥ç”¨æˆ·ä»ä¾èµ–æ—§è¡Œä¸ºï¼Œå¯èƒ½åœ¨ **Mori** åç«¯ä¸‹é»˜è®¤è¿›å…¥ **lowâ€‘latency**ï¼ˆå–å†³äº `deepep_mode` é…ç½®ï¼‰ï¼Œå¯¼è‡´è¡Œä¸ºå˜åŒ–ã€‚  

5. **æµ‹è¯•è¦†ç›–ä¸è¶³**  
   - æ–°å¢çš„ `MoriEPLL*` ç±»å‹ã€å¼‚æ­¥è·¯å¾„ä»¥åŠ `two_batch_overlap` é€»è¾‘åœ¨ CI ä¸­ç¼ºå°‘ä¸“é—¨é’ˆå¯¹ AMD HIP çš„å•å…ƒ/é›†æˆæµ‹è¯•ã€‚  

---

### ğŸ’¡ å…³æ³¨å»ºè®®  

| å¯¹è±¡ | å»ºè®® |
|------|------|
| **å¼€å‘è€…** | 1. åœ¨ AMD GPUï¼ˆROCmï¼‰ç¯å¢ƒä¸‹è·‘å®Œæ•´çš„ **e2e** æµ‹è¯•ï¼Œé‡ç‚¹æ£€æŸ¥ `final_hidden_states[:num_tokens]` çš„è£å‰ªæ˜¯å¦æ­£ç¡®ã€‚<br>2. ä¸º `MoriEPDispatcher` æ·»åŠ  **èµ„æºå›æ”¶**ï¼ˆåœ¨ `__del__` æˆ–æ˜¾å¼ `close` ä¸­è°ƒç”¨ `CommStreamPool.clear_group`ï¼‰ã€‚<br>3. å°† `is_hip()` çš„å®ç°æŠ½è±¡ä¸ºç»Ÿä¸€çš„å¹³å°æ£€æµ‹å·¥å…·ï¼Œé˜²æ­¢è¯¯åˆ¤ã€‚<br>4. ä¸ºä½å»¶è¿Ÿè·¯å¾„è¡¥é½ **å•å…ƒæµ‹è¯•**ï¼ŒéªŒè¯ `async_finish=True` ä¸ `False` ä¸¤ç§æƒ…å½¢çš„æ­£ç¡®æ€§ã€‚ |
| **ç”¨æˆ·** | 1. å½“ä½¿ç”¨ `--moe-a2a-backend=mori` æ—¶ï¼Œè‹¥å¼€å¯ `chunked_prefill`ï¼Œè¯·ç¡®ä¿ `SGLANG_MORI_NUM_MAX_DISPATCH_TOKENS_PER_RANK` å¤§äºç­‰äº `chunked_prefill_size`ï¼ˆé»˜è®¤ 4096ï¼‰ï¼Œå¦åˆ™ä¼šè§¦å‘æ–­è¨€ã€‚<br>2. å¦‚éœ€ä¿æŒåŸæœ‰ `normal` è¡Œä¸ºï¼Œè¯·æ˜¾å¼åœ¨å¯åŠ¨å‚æ•°ä¸­è®¾ç½® `--deepep-mode=normal`ï¼Œå¦åˆ™é»˜è®¤å¯èƒ½èµ° `low_latency`ã€‚ |
| **è¿ç»´** | 1. ç›‘æ§æœåŠ¡çš„ **CUDA/HIP æµæ•°ç›®** ä¸ **GPU å†…å­˜å ç”¨**ï¼Œå°¤å…¶åœ¨é«˜å¹¶å‘ `two_batch_overlap` åœºæ™¯ä¸‹ï¼Œä»¥é˜²å‡ºç°æµæ³„æ¼å¯¼è‡´çš„èµ„æºæ¯ç«­ã€‚<br>2. åœ¨æ—¥å¿—ä¸­å…³æ³¨ `"[MORI init]"` è¾“å‡ºï¼Œæ£€æŸ¥ `mode=` æ˜¯å¦ç¬¦åˆ

---

#### ğŸŸ¡ ä¸­é‡è¦åº¦å˜æ›´ (5)

### fix tool handling in OpenAIServingChat (#18996)
**SHA**: `4a362a0` | ğŸ”— [æŸ¥çœ‹æäº¤](https://github.com/sgl-project/sglang/commit/4a362a0e041a4b7524f1b40272ad8e44606c9b3d)

**ğŸ¯ å˜æ›´ç±»å‹**ï¼šBug ä¿®å¤ / åŠŸèƒ½å¢å¼º  
**âš¡ é‡è¦ç¨‹åº¦**ï¼šğŸŸ¡ ä¸­  

**ğŸ“‹ å˜æ›´æ‘˜è¦**  
1. ä¿®æ­£ `OpenAIServingChat._process_messages` ä¸­å¯¹å·¥å…·ï¼ˆtoolsï¼‰å¯¹è±¡çš„åºåˆ—åŒ–æ–¹å¼ï¼Œç»Ÿä¸€ä½¿ç”¨ `item.model_dump()`ï¼Œé¿å…æ—§çš„ `item.function.model_dump()` äº§ç”Ÿå±æ€§ç¼ºå¤±æˆ–ç»“æ„é”™è¯¯ã€‚  
2. åœ¨ `_apply_jinja_template` æ•è·æ¨¡æ¿æ¸²æŸ“å¼‚å¸¸åï¼Œæ”¹ä¸ºå…ˆå°è¯•ä½¿ç”¨ OpenAIâ€‘style åŒ…è£…çš„å·¥å…·åˆ—è¡¨ï¼›è‹¥ä»å¤±è´¥åˆ™å›é€€ä¸ºâ€œå¹³é“ºâ€å‡½æ•°ï¼ˆ`t["function"]`ï¼‰æ ¼å¼ï¼Œå…¼å®¹ Mistral ç­‰æ¨¡å‹çš„ç‰¹æ®Šéœ€æ±‚ã€‚  
3. æ–°å¢å•å…ƒæµ‹è¯•éªŒè¯ï¼šâ‘  é»˜è®¤å‘ Jinja æ¨¡æ¿ä¼ é€’ OpenAIâ€‘schema toolsï¼›â‘¡ å½“æ¨¡æ¿ä¸æ¥å—è¯¥åŒ…è£…æ—¶ï¼Œèƒ½å¤Ÿè‡ªåŠ¨å›é€€åˆ°å‡½æ•°â€‘only schemaã€‚  

**ğŸ¯ å½±å“èŒƒå›´**  
- `python/sglang/srt/entrypoints/openai/serving_chat.py`ï¼ˆå·¥å…·å¤„ç†ã€æ¨¡æ¿æ¸²æŸ“ï¼‰  
- `test/registered/openai_server/basic/test_serving_chat.py`ï¼ˆæ–°å¢è¦†ç›–ï¼‰  

**ğŸ’¡ å…³æ³¨å»ºè®®**  
- **å…¼å®¹æ€§**ï¼šç¡®è®¤å…¶ä»–æ¨¡æ¿ï¼ˆå¦‚ç³»ç»Ÿè‡ªå¸¦çš„ ChatMLã€Llamaâ€‘styleï¼‰åœ¨æ¥æ”¶ `tools` å‚æ•°æ—¶ä¸ä¼šå› ç»“æ„å˜åŒ–å¼•å…¥æ–°çš„é”™è¯¯ã€‚å¯åœ¨ CI ä¸­åŠ å…¥å¯¹å¤šç§æ¨¡æ¿çš„æŠ½æ ·æµ‹è¯•ã€‚  
- **å¼‚å¸¸è·¯å¾„**ï¼šå½“å‰å›é€€é€»è¾‘ä¾èµ–æ•è·ä»»æ„ `Exception`ï¼Œå»ºè®®ç»†åŒ–ä¸º `RuntimeError` æˆ–è‡ªå®šä¹‰å¼‚å¸¸ï¼Œä»¥å…è¯¯æ‹¦æˆªéæ¨¡æ¿ç›¸å…³é”™è¯¯ã€‚  
- **æ€§èƒ½**ï¼šå›é€€ä¼šå¯¼è‡´ä¸¤æ¬¡ `apply_chat_template` è°ƒç”¨ï¼Œè‹¥æ¨¡æ¿å¤§é‡ä½¿ç”¨å·¥å…·ï¼Œè€ƒè™‘åœ¨é¦–æ¬¡å¤±è´¥åç¼“å­˜ â€œflatâ€‘toolsâ€ æ ‡è®°ï¼Œé¿å…é‡å¤å°è¯•ã€‚  
- **æ–‡æ¡£**ï¼šæ›´æ–° OpenAI æ¥å£è¯´æ˜ï¼Œæ˜ç¡®â€œtools å‚æ•°æ”¯æŒä¸¤ç§æ ¼å¼ï¼šOpenAI åŒ…è£…å’Œå‡½æ•°å¹³é“ºï¼Œç³»ç»Ÿä¼šè‡ªåŠ¨åˆ‡æ¢â€ã€‚  
- **åç»­ç»´æŠ¤**ï¼š`FunctionCallParser` ä»ä¾èµ–åŸå§‹ `request.tools`ï¼ˆåŒ…å« `function` å­—æ®µï¼‰ï¼Œç¡®ä¿åœ¨å›é€€åä»èƒ½æ­£ç¡®è§£æï¼›å¦‚æœ‰å˜æ›´ï¼Œè¯·åŒæ­¥æ›´æ–°å¯¹åº”å•å…ƒæµ‹è¯•ã€‚  

æ€»ä½“è€Œè¨€ï¼Œæ­¤æ¬¡ä¿®å¤æå‡äº† OpenAIâ€‘compatible chat æœåŠ¡åœ¨å¤šæ¨¡å‹ç¯å¢ƒä¸‹çš„é²æ£’æ€§ï¼Œå»ºè®®åœ¨å…¨æ¸ é“å›å½’æµ‹è¯•åå†æ­£å¼ä¸Šçº¿ã€‚

---

### [diffusion] feat: support passing component path via server args (#19108)
**SHA**: `6503f94` | ğŸ”— [æŸ¥çœ‹æäº¤](https://github.com/sgl-project/sglang/commit/6503f94211a4317786f4c6d2418ddcdcd4b20c8e)

**ğŸ¯ å˜æ›´ç±»å‹**ï¼šåŠŸèƒ½å¢å¼ºï¼ˆæ”¯æŒé€šè¿‡ `--<component>-path` åŠ¨æ€è¦†ç›–ä»»æ„ Diffusers ç»„ä»¶ï¼‰  
**âš¡ é‡è¦ç¨‹åº¦**ï¼šğŸŸ¡ ä¸­  

**ğŸ“‹ å˜æ›´æ‘˜è¦**  
1. åœ¨ CLI æ–‡æ¡£ä¸­æ–°å¢ â€œComponent Path Overridesâ€ ç« èŠ‚ï¼Œè¯´æ˜ç”¨æˆ·å¯ä½¿ç”¨ `--vae-path`ã€`--transformer-path` ç­‰å‚æ•°è¦†ç›–æ¨¡å‹å­ç»„ä»¶ã€‚  
2. `ServerArgs` ç”±åŸæ¥çš„å›ºå®š `vae_path` è¿ç§»ä¸ºé€šç”¨ `component_paths: dict[str, str]`ï¼Œå¹¶åœ¨ `from_cli_args` ä¸­é€šè¿‡ `parse_known_args` æŠ½å– `--*â€‘path` åŠ¨æ€å‚æ•°ã€‚  
3. æ‰€æœ‰ç»„ä»¶åŠ è½½å™¨ç»Ÿä¸€æ”¹ä¸ºè°ƒç”¨ `get_diffusers_component_config(component_path=â€¦)`ï¼Œå¹¶åœ¨ `ComposedPipelineBase` ä¸­åŠ å…¥ `_resolve_component_path`ï¼Œå®ç°æœ¬åœ°/Hub ä¸‹è½½ä¸è·¯å¾„è§£æã€‚  
4. ç›¸å…³è°ƒç”¨é“¾ï¼ˆ`generate`, `main`, `cli`ï¼‰åŒæ­¥æ¥å— `unknown_args`ï¼Œé¿å…æœªè¯†åˆ«å‚æ•°å¯¼è‡´å¼‚å¸¸ã€‚  
5. `maybe_download_model` æ–°å¢ `force_diffusers_model` æ ‡è®°ï¼ŒåŒºåˆ†ä¸‹è½½å®Œæ•´ Diffusers æ¨¡å‹ä¸å•ç»„ä»¶ã€‚  
6. æµ‹è¯•ç”¨ä¾‹æ·»åŠ äº† `run_perf_check` æ ‡è®°å¹¶æ–°å¢ä¸€ä¸ªè¦†ç›– VAE çš„åœºæ™¯ï¼Œç¡®ä¿æ–°ç‰¹æ€§ä¸å½±å“æ€§èƒ½åŸºå‡†ã€‚

**ğŸ¯ å½±å“èŒƒå›´**  
- `sglang/cli/*`ã€`sglang/multimodal_gen/runtime/*`ï¼ˆç»„ä»¶åŠ è½½ã€pipelineã€server å‚æ•°è§£æï¼‰  
- æ–‡æ¡£ `docs/diffusion/api/cli.md`  
- æ€§èƒ½åŸºå‡†æµ‹è¯• `test/server/*`  

**ğŸ’¡ å…³æ³¨å»ºè®®**  

1. **å‘åå…¼å®¹**ï¼šåŸæœ‰ `--vae-path` å‚æ•°å·²è¢«åˆ å»ï¼Œå»ºè®®ä¿ç•™ä¸€ä¸ªå·²åºŸå¼ƒçš„åˆ«åå¹¶åœ¨è§£ææ—¶ç»™å‡ºè­¦å‘Šï¼Œé˜²æ­¢å·²æœ‰è„šæœ¬ç›´æ¥å¤±æ•ˆã€‚  
2. **å‚æ•°å†²çªæ£€æµ‹**ï¼š`_extract_component_paths` åªåˆ¤æ–­ `--*â€‘path` å½¢å¼ï¼Œè‹¥ç”¨æˆ·è¯¯å†™ `--something-path`ï¼ˆä¸å­˜åœ¨äº `model_index.json`ï¼‰ä¼šåœ¨åç»­åŠ è½½æ—¶æŠ¥é”™ã€‚å¯åœ¨ `ServerArgs.from_cli_args` é˜¶æ®µæå‰æ ¡éªŒç»„ä»¶é”®æ˜¯å¦åˆæ³•ï¼ˆè¯»å– `model_index.json`ï¼‰ï¼Œç»™å‡ºæ›´å‹å¥½çš„é”™è¯¯ä¿¡æ¯ã€‚  
3. **å¼‚å¸¸è·¯å¾„å¤„ç†**ï¼š`maybe_download_model` åœ¨ `force_diffusers_model=False` æ—¶ç›´æ¥è¿”å›æœ¬åœ°è·¯å¾„ï¼Œä½†ä»ä¼šæ‰§è¡Œ Hub ä¸‹è½½é€»è¾‘ï¼›ç¡®ä¿å½“è·¯å¾„æŒ‡å‘å·²æœ‰ç»„ä»¶ç›®å½•ä½†ç¼ºå°‘ `config.json` æ—¶ç»™å‡ºæ˜ç¡®æç¤ºã€‚  
4. **æ–‡æ¡£åŒæ­¥**ï¼šREADME ä¸å…¶ä»– CLI ä½¿ç”¨è¯´æ˜ä¸­ä»å¯èƒ½å‡ºç° `--vae-path`ï¼Œè¯·ç»Ÿä¸€æ›´æ–°æˆ–åŠ å…¥è¿ç§»æŒ‡å—ã€‚  
5. **å•å…ƒæµ‹è¯•è¦†ç›–**ï¼šæ–°å¢å¯¹ `parse_known_args`ã€`_extract_component_paths`ã€`_resolve_component_path` çš„ç‹¬ç«‹æµ‹è¯•ï¼Œç¡®ä¿ `--componentâ€‘path` ä¸æ™®é€šå‚æ•°æ··ç”¨æ—¶ä¸ä¼šè¯¯åƒæœªçŸ¥é€‰é¡¹ã€‚  
6. **æ€§èƒ½å›å½’**ï¼š`run_perf_check=False` çš„æµ‹è¯•ç”¨ä¾‹å·²åŠ å…¥ï¼Œå»ºè®®åœ¨ CI ä¸­ç»§ç»­ä¿ç•™åŸæœ‰æ€§èƒ½åŸºå‡†ï¼Œä»¥é˜²æ–°è·¯å¾„è§£æå¼•å…¥é¢å¤– IO å¼€é”€ã€‚  

æ€»ä½“æ¥è¯´ï¼Œæ­¤æ¬¡æ”¹åŠ¨ä¸º Diffusion å­ç»„ä»¶æä¾›äº†çµæ´»çš„è‡ªå®šä¹‰å…¥å£ï¼Œä»£ç ç»“æ„ä¹Ÿæ›´ç»Ÿä¸€ã€‚è‹¥åœ¨å…¼å®¹æ€§ã€å‚æ•°æ ¡éªŒä¸æ–‡æ¡£æ–¹é¢å†åšç»†åŒ–ï¼Œå¯è¿›ä¸€æ­¥æå‡ç”¨æˆ·ä½“éªŒå¹¶é™ä½æ½œåœ¨å›å½’é£é™©ã€‚

---

### [Quantization] Support config.json quantization_config format, fix exclude_modules matching, and fix KV cache scale loading for Nemotron (#18546)
**SHA**: `33c33a7` | ğŸ”— [æŸ¥çœ‹æäº¤](https://github.com/sgl-project/sglang/commit/33c33a7de9bb15c5708f6ae9d78c5d72d74b0fa4)

**ğŸ¯ å˜æ›´ç±»å‹**ï¼šåŠŸèƒ½å¢å¼º / Bug ä¿®å¤  
**âš¡ é‡è¦ç¨‹åº¦**ï¼šğŸŸ¡ ä¸­  
**ğŸ“‹ å˜æ›´æ‘˜è¦**ï¼š  
1. åœ¨ `ModelOptQuant` ä¸­åŠ å…¥ `is_layer_excluded`ï¼Œæ”¯æŒ `config.json` é‡Œçš„ `quantization_config`ã€é€šé…ç¬¦ã€å­æ¨¡å—ã€è¯­è¨€æ¨¡å‹å‰ç¼€åŠ fusedâ€‘module åŒ¹é…ï¼Œé¿å…å¯¹ä¸å«é‡åŒ–å°ºåº¦çš„ MoE ç­‰å±‚è¯¯é‡åŒ–ã€‚  
2. ä¿®æ­£ KVâ€‘cache ç¼©æ”¾åç§°çš„æ˜ å°„é€»è¾‘ï¼Œå…¼å®¹ ModelOpt åœ¨ `k_proj/v_proj` ä¸‹ä¿å­˜çš„ scaleã€‚  
3. ä¸º Nemotronâ€‘H å¢åŠ  `WeightsMapper`ï¼Œç»Ÿä¸€ HF â†’ sglang æƒé‡å‰ç¼€æ˜ å°„ã€‚  

**ğŸ¯ å½±å“èŒƒå›´**ï¼š  
- `python/sglang/srt/layers/quantization/modelopt_quant.py`ï¼ˆé‡åŒ–é…ç½®è§£æã€æ’é™¤é€»è¾‘ï¼‰  
- `python/sglang/srt/model_loader/weight_utils.py`ï¼ˆKVâ€‘cache scale é‡å‘½åï¼‰  
- `python/sglang/srt/models/nemotron_h.py`ï¼ˆæ¨¡å‹æƒé‡æ˜ å°„ï¼‰  

**ğŸ’¡ å…³æ³¨å»ºè®®**  
- **å…¼å®¹æ€§**ï¼šæ–° `is_layer_excluded` å–ä»£æ—§å®ç°ï¼Œç¡®ä¿æ‰€æœ‰æ—§è·¯å¾„ï¼ˆ`exclude_modules` ä»ä¸º listï¼‰åœ¨å‡çº§åä»èƒ½æ­£ç¡®åŒ¹é…ï¼›å¯åœ¨ `from_config` ä¸­åŠ å…¥æ³¨é‡Šæé†’ç”¨æˆ·è¿ç§»ã€‚  
- **æµ‹è¯•**ï¼šå¢åŠ å¯¹ `config.json` å¹³é“ºæ ¼å¼çš„å•å…ƒæµ‹è¯•ï¼Œè¦†ç›–é€šé…ç¬¦ (`"mtp*"`)ã€`language_model.` å‰ç¼€ã€ä»¥åŠ fusedâ€‘moduleï¼ˆå¦‚ `"q_a_proj"`ï¼‰çš„æ’é™¤æƒ…å†µã€‚  
- **æ€§èƒ½**ï¼šæ­£åˆ™åŒ¹é…åœ¨å±‚éå†æ—¶ä¼šè¢«é¢‘ç¹è°ƒç”¨ï¼Œå»ºè®®åœ¨åˆå§‹åŒ–æ—¶é¢„ç¼–è¯‘ `re.compile`ï¼Œæˆ–å¯¹å¸¸è§æ¨¡å¼åšç¼“å­˜ï¼Œä»¥å…å½±å“æ¨¡å‹åŠ è½½é€Ÿåº¦ã€‚  
- **æ–‡æ¡£**ï¼šåœ¨é‡åŒ–é…ç½®æ–‡æ¡£ä¸­æ˜ç¡® `ignore` â†’ `exclude_modules` çš„å«ä¹‰ä¸æ”¯æŒçš„é€šé…ç¬¦/å­æ¨¡å—å†™æ³•ï¼Œå¹¶è¯´æ˜ KVâ€‘cache scale é‡å‘½åè§„åˆ™ã€‚  
- **å›æ»šå®‰å…¨**ï¼šè‹¥ç”¨æˆ·ä»ä½¿ç”¨æ—§ `hf_quant_config.json`ï¼Œç¡®ä¿ `from_config` èƒ½è‡ªåŠ¨è¯†åˆ«ä¸¤ç§æ ¼å¼ï¼›å¯ä»¥åœ¨æ—¥å¿—ä¸­æç¤ºå³å°†åºŸå¼ƒçš„æ—§æ ¼å¼ã€‚  

æ€»ä½“æ¥è¯´ï¼Œæ­¤æ¬¡æ”¹åŠ¨æå‡äº† Quantization çš„å¯é…ç½®æ€§å’Œé²æ£’æ€§ï¼Œä½†éœ€è¦é€šè¿‡å…¨é¢çš„å•å…ƒ/é›†æˆæµ‹è¯•æ¥éªŒè¯æ–°æ’é™¤é€»è¾‘å’Œ scale é‡æ˜ å°„åœ¨å„ç§æ¨¡å‹ï¼ˆå°¤å…¶æ˜¯ MoEã€RadixAttentionã€Visionâ€‘Languageï¼‰ä¸Šçš„æ­£ç¡®æ€§ã€‚

---

### Add generated-shared-prefix dataset in bench_one_batch (#18986)
**SHA**: `96bae23` | ğŸ”— [æŸ¥çœ‹æäº¤](https://github.com/sgl-project/sglang/commit/96bae2355e7010773729d4ca5d2b84e4621ab658)

**ğŸ¯ å˜æ›´ç±»å‹**ï¼šåŠŸèƒ½å¢å¼º  
**âš¡ é‡è¦ç¨‹åº¦**ï¼šğŸŸ¡ ä¸­  

**ğŸ“‹ å˜æ›´æ‘˜è¦**  
1. ä¸º `bench_one_batch` åŸºå‡†æ–°å¢ `generatedâ€‘sharedâ€‘prefix` æ•°æ®é›†ï¼Œå¯ä½¿ç”¨åŒå‰ç¼€çš„ç³»ç»Ÿæç¤º+ç‹¬ç«‹é—®é¢˜æ¥è¯„ä¼° KVâ€‘Cache å…±äº«æ•ˆæœã€‚  
2. æ‰©å±• CLI å‚æ•° (`--gspâ€‘*`) å¹¶åœ¨ `run_one_case`ã€`run_benchmark_internal` ä¸­é€ä¼ ï¼Œç»Ÿä¸€ä½¿ç”¨ `sglang.bench_serving.get_dataset` è¿›è¡Œæ•°æ®åŠ è½½ã€‚  

**ğŸ¯ å½±å“èŒƒå›´**  
- `python/sglang/test/bench_one_batch_server_internal.py`ï¼ˆæ ¸å¿ƒ benchmark å…¥å£ï¼‰  
- `sglang.bench_serving`ï¼ˆæ–°å¢ `get_dataset` è°ƒç”¨ï¼‰  
- CLI å‚æ•°è§£æã€`BenchArgs` æ•°æ®ç»“æ„  

**ğŸ’¡ å…³æ³¨å»ºè®®**  

1. **å…¼å®¹æ€§**ï¼š`sample_mmmu_requests`ã€`sample_random_requests` è¢«æ³¨é‡Šæ‰ä½†ä»åœ¨ `import` è¡Œè¢«å¼•ç”¨ï¼Œå»ºè®®ç§»é™¤æˆ–ç•™ä¸‹æ³¨é‡Šé˜²æ­¢æœªä½¿ç”¨è­¦å‘Šã€‚  
2. **å‚æ•°æ ¡éªŒ**ï¼š`gsp_num_groups` å¯èƒ½å¤§äº `batch_size`ï¼Œå·²é€šè¿‡ `actual_gsp_groups = min(gsp_num_groups, batch_size)` è§„é¿ï¼Œä½†åç»­ `gsp_prompts_per_group` ä»å¯èƒ½å‡ºç°é™¤ 0 çš„é£é™©ï¼Œå»ºè®®åœ¨ CLI ä¸­åŠ å…¥ `>=1` æ£€æŸ¥ã€‚  
3. **Tokenizer å…¼å®¹**ï¼šä»£ç ä½¿ç”¨ `getattr(tokenizer, "tokenizer", tokenizer)` å–å¾—å†…éƒ¨ tokenizerï¼Œç¡®ä¿ `AutoProcessor` åœºæ™¯ä¸‹ä»èƒ½æ­£å¸¸ `encode`ã€‚è‹¥æœªæ¥å¼•å…¥å…¶ä»–å¤„ç†å™¨ï¼Œéœ€åŒæ­¥æ›´æ–°ã€‚  
4. **`get_dataset` å‚æ•°**ï¼š`dataset_args` ä¸­çš„å­—æ®µéœ€ä¸ `sglang.bench_serving.get_dataset` å®Œå…¨åŒ¹é…ï¼Œå»ºè®®åœ¨æœ¬æ–‡ä»¶æ·»åŠ æ³¨é‡Šæˆ–ç±»å‹æç¤ºï¼Œé˜²æ­¢å­—æ®µæ‹¼å†™é”™è¯¯å¯¼è‡´è¿è¡Œæ—¶å¼‚å¸¸ã€‚  
5. **æ€§èƒ½ä¸å†…å­˜**ï¼š`generatedâ€‘sharedâ€‘prefix` ä¼šåœ¨åŒä¸€æ‰¹æ¬¡å†…éƒ¨å…±äº«å‰ç¼€ï¼Œè‹¥ `gsp_system_prompt_len` è®¾ç½®è¿‡å¤§ï¼Œå¯èƒ½å¯¼è‡´ KVâ€‘Cache è¶…å‡ºæ˜¾å­˜é™åˆ¶ï¼Œå»ºè®®åœ¨æ–‡æ¡£ä¸­ç»™å‡ºåˆç†å–å€¼èŒƒå›´å¹¶åœ¨è¿è¡Œæ—¶æ‰“å°å®é™… `input_len`/`output_len`ã€‚  
6. **æµ‹è¯•è¦†ç›–**ï¼šæ–°å¢æ•°æ®é›†åï¼Œéœ€è¦è¡¥å……å•å…ƒ/é›†æˆæµ‹è¯•ï¼ŒéªŒè¯ `gsp_*` å‚æ•°åœ¨ä¸åŒ `batch_size`ã€`backend`ï¼ˆsglang / vllmï¼‰ç»„åˆä¸‹çš„æ­£ç¡®æ€§ã€‚  
7. **æ–‡æ¡£æ›´æ–°**ï¼šCLI å¸®åŠ©ã€README ä¸ benchmark è¯´æ˜éœ€åŒæ­¥åŠ å…¥ `generatedâ€‘sharedâ€‘prefix` ç¤ºä¾‹åŠå‚æ•°è§£é‡Šï¼Œé¿å…ç”¨æˆ·å› æœªçŸ¥å‚æ•°è€ŒæŠ¥é”™ã€‚  

æ€»ä½“è€Œè¨€ï¼Œæ­¤æ¬¡æ”¹åŠ¨ä¸º benchmark å¼•å…¥äº†æœ‰ä»·å€¼çš„å…±äº«å‰ç¼€åœºæ™¯ï¼Œä»£ç ç»“æ„ä¿æŒæ¸…æ™°ï¼Œä½†è¯·æ³¨æ„ä¸Šè¿°å…¼å®¹æ€§ã€å‚æ•°æ ¡éªŒä¸æ–‡æ¡£åŒæ­¥ï¼Œä»¥ç¡®ä¿å¹³æ»‘ä¸Šçº¿ã€‚

---

### [feat] feat: support swa in trtllm_mha (#18970)
**SHA**: `ab18734` | ğŸ”— [æŸ¥çœ‹æäº¤](https://github.com/sgl-project/sglang/commit/ab18734375accf3dbcd043f5b6244d4082ee84f5)

**ğŸ¯ å˜æ›´ç±»å‹**ï¼šåŠŸèƒ½å¢å¼º  
**âš¡ é‡è¦ç¨‹åº¦**ï¼šğŸŸ¡ ä¸­  

**ğŸ“‹ å˜æ›´æ‘˜è¦**  
- åœ¨ `trtllm_mha_backend.py` ä¸­åŠ å…¥å¯¹ **Slidingâ€‘Window Attention (SWA)** çš„æ”¯æŒã€‚  
- å¼•å…¥ `SWAKVPool`ã€`SWATokenToKVPoolAllocator`ï¼Œä¸ºæ··åˆæ¨¡å‹ç»´æŠ¤ **å…¨é‡ KVâ€‘Pool ä¸ SWAâ€‘Pool** ä¸¤å¥—ç´¢å¼•ç©ºé—´ã€‚  
- ä¸º CUDAâ€‘graph æ·»åŠ  `swa_page_table` ç¼“å†²åŒºï¼Œå¹¶åœ¨åˆå§‹åŒ–ã€æ•è·ã€å›æ”¾ç­‰ç¯èŠ‚å®Œæˆ **ç´¢å¼•ç¿»è¯‘ã€å¤åˆ¶ã€ç»‘å®š**ã€‚  
- `forward_decode / forward_extend` é€šè¿‡ `_get_layer_page_table` è‡ªåŠ¨é€‰å–å¯¹åº”å±‚çš„ pageâ€‘tableï¼Œå®ç°å¯¹ SWA å±‚çš„æ­£ç¡®å¯»å€ã€‚

**ğŸ¯ å½±å“èŒƒå›´**  
- `python/sglang/srt/layers/attention/trtllm_mha_backend.py`ï¼ˆæ ¸å¿ƒå®ç°ï¼‰  
- `sglang/srt/mem_cache/swa_memory_pool.py`ï¼ˆæ–°å¢ KVâ€‘Pool ç±»å‹ï¼‰  
- ç›¸å…³ CUDAâ€‘graph å…ƒæ•°æ®ç»“æ„ä¸é¡µé¢è¡¨çš„åˆ›å»ºã€å¤åˆ¶é€»è¾‘ã€‚  

**ğŸ’¡ å…³æ³¨å»ºè®®**  

1. **æ¨¡å‹é…ç½®**ï¼šä½¿ç”¨ SWA æ—¶ç¡®ä¿ `model_runner.token_to_kv_pool_allocator` ä¸º `SWATokenToKVPoolAllocator`ï¼Œå¦åˆ™ä¼šè¯¯åˆ¤ `use_sliding_window_kv_pool`ã€‚  
2. **Pageâ€‘size ä¸€è‡´æ€§**ï¼š`self.page_size` å¿…é¡»ä¸ `SWAKVPool` çš„å—å¤§å°ä¿æŒä¸€è‡´ï¼Œå¦åˆ™ `translate_loc_from_full_to_swa` ä¸ `// self.page_size` çš„é™¤æ³•ä¼šäº§ç”Ÿé”™ä½ã€‚  
3. **CUDAâ€‘graph è®°å¿†ä½“**ï¼šæ–°å¢çš„ `swa_page_table*` ç¼“å†²åŒºåœ¨ `init_cuda_graph_state` ä¸­åˆ†é…ï¼Œå»ºè®®åœ¨ `release`/`reset` æ—¶åŒæ­¥é‡Šæ”¾ï¼Œé˜²æ­¢æ˜¾å­˜æ³„æ¼ã€‚  
4. **å•å…ƒæµ‹è¯•**ï¼šåŠ å…¥æ··åˆæ¨¡å‹ï¼ˆéƒ¨åˆ†å±‚ä½¿ç”¨ SWAã€éƒ¨åˆ†å±‚ä½¿ç”¨å¸¸è§„ KVï¼‰ çš„å‰å‘/å›æ”¾è·¯å¾„æµ‹è¯•ï¼Œé‡ç‚¹éªŒè¯ `metadata.swa_page_table` åœ¨éâ€‘SWA åœºæ™¯ä¸‹ä¸º `None`ï¼Œä¸”ä»£ç æœªå¯¹å…¶è¿›è¡Œéæ³•è®¿é—®ã€‚  
5. **æ€§èƒ½ç›‘æ§**ï¼šSWA ç¿»è¯‘ä¼šåœ¨æ¯æ¬¡å›æ”¾æ—¶è°ƒç”¨ `translate_loc_from_full_to_swa`ï¼Œå»ºè®®åœ¨é«˜å¹¶å‘æ¨ç†åœºæ™¯ä¸‹å¯¹å…¶è€—æ—¶åšåŸºå‡†ï¼Œå¿…è¦æ—¶åŠ å…¥ç¼“å­˜æˆ–æ‰¹é‡ç¿»è¯‘ä¼˜åŒ–ã€‚  

æ€»ä½“è€Œè¨€ï¼Œæ­¤æ¬¡æ”¹åŠ¨ä¸º TRTâ€‘LLM åç«¯å¼•å…¥äº†å¯¹æ··åˆ SWA æ¨¡å‹çš„å®Œæ•´æ”¯æŒï¼Œè‹¥åœ¨éƒ¨ç½²å‰å®Œæˆä¸Šè¿°éªŒè¯ï¼Œå¯å®‰å…¨ä¸Šçº¿ã€‚

---

#### ğŸŸ¢ ä½é‡è¦åº¦å˜æ›´ (10)

### [sgl] view could hold the memory too long and introduced large memory (#19109)
**SHA**: `bf36aa4` | ğŸ”— [æŸ¥çœ‹æäº¤](https://github.com/sgl-project/sglang/commit/bf36aa4c31173125a031f3c3135ddbafaee8e60f)

**ğŸ¯ å˜æ›´ç±»å‹**ï¼šä»£ç é‡æ„  
**âš¡ é‡è¦ç¨‹åº¦**ï¼šğŸŸ¢ä½  
**ğŸ“‹ æ‘˜è¦**ï¼šåœ¨ `scheduler_output_processor_mixin.py` ä¸­ï¼Œå¯¹ `customized_info` çš„å…ƒç´ è¿›è¡Œæ˜¾å¼å¤åˆ¶ï¼ˆå¯¹å¼ é‡ä½¿ç”¨ `clone()`ï¼Œå¯¹å¯å¤åˆ¶å¯¹è±¡ä½¿ç”¨ `copy()`ï¼‰ï¼Œé˜²æ­¢å› è§†å›¾å¼•ç”¨å¯¼è‡´å†…å­˜é•¿æ—¶é—´å ç”¨ã€‚

---

### fix KimiK2Detector regex patterns with re.DOTALL (#19120)
**SHA**: `677b66a` | ğŸ”— [æŸ¥çœ‹æäº¤](https://github.com/sgl-project/sglang/commit/677b66af805d93f7a26e9cf96b7b243eb1beaee1)

**ğŸ¯ å˜æ›´ç±»å‹**ï¼šä»£ç é‡æ„  
**âš¡ é‡è¦ç¨‹åº¦**ï¼šğŸŸ¢ä½  
**ğŸ“‹ æ‘˜è¦**ï¼šä¸º KimiK2Detector çš„æ­£åˆ™è¡¨è¾¾å¼æ·»åŠ  `re.DOTALL` æ ‡å¿—ï¼Œä»¥åŒ¹é…è·¨è¡Œå†…å®¹ï¼›å°†å‡½æ•°åæ—¥å¿—ä» `info` è°ƒæ•´ä¸º `debug`ã€‚

---

### Tiny update pull-requests permission of release-branch-cut.yml (#19121)
**SHA**: `c36a10a` | ğŸ”— [æŸ¥çœ‹æäº¤](https://github.com/sgl-project/sglang/commit/c36a10aabb39363df3d8b83750bb5f0cc2edb2d5)

**ğŸ¯ å˜æ›´ç±»å‹**ï¼šé…ç½®è°ƒæ•´  
**âš¡ é‡è¦ç¨‹åº¦**ï¼šğŸŸ¢ä½  
**ğŸ“‹ æ‘˜è¦**ï¼šåœ¨ `.github/workflows/release-branch-cut.yml` ä¸­æ–°å¢ `pull-requests: read` æƒé™ï¼Œå…è®¸è¯¥å·¥ä½œæµè¯»å– PR ä¿¡æ¯ï¼Œä»è€Œæ”¯æŒåç»­çš„åˆ†æ”¯åˆ‡å‰²æ“ä½œã€‚

---

### Remove error dllm and diffusion doc in basic_useage (#19105)
**SHA**: `e239f8a` | ğŸ”— [æŸ¥çœ‹æäº¤](https://github.com/sgl-project/sglang/commit/e239f8aa85f7f2e9ad9831ec6bec3cb5ec96d1cd)

**ğŸ¯ å˜æ›´ç±»å‹**ï¼šæ–‡æ¡£æ›´æ–°  
**âš¡ é‡è¦ç¨‹åº¦**ï¼šğŸŸ¢ä½  
**ğŸ“‹ æ‘˜è¦**ï¼šåˆ é™¤äº† `basic_usage` ä¸‹çš„ diffusion ä¸ dLLM ä½¿ç”¨è¯´æ˜æ–‡æ¡£ï¼Œå¹¶åœ¨ `index.rst` ä¸­ç›¸åº”ç§»é™¤ç›®å½•å¼•ç”¨ã€‚æ–‡ä»¶é‡å°‘ï¼Œå½±å“ä»…é™æ–‡æ¡£ã€‚

---

### Fix bug in symm mem pre-allocation default (#19082)
**SHA**: `51b3ed0` | ğŸ”— [æŸ¥çœ‹æäº¤](https://github.com/sgl-project/sglang/commit/51b3ed02ca544e58b05bcbfd261dfb5c7d355b8d)

**å˜æ›´ç±»å‹**ï¼šä»£ç é‡æ„  
**é‡è¦ç¨‹åº¦**ï¼šğŸŸ¢ä½  
**æ‘˜è¦**ï¼šå°†å¯¹ç§°å†…å­˜ï¼ˆsymm memï¼‰é»˜è®¤é¢„åˆ†é… 4â€¯GB çš„é€»è¾‘ä»åµŒå¥—çš„ `if` å—ä¸­æŠ½å‡ºï¼Œç»Ÿä¸€æ”¾åœ¨ `_handle_gpu_memory_settings` æ–¹æ³•çš„æœ«å°¾ï¼Œä½¿ä»£ç ç»“æ„æ›´æ¸…æ™°ï¼Œä¿æŒåŸæœ‰åŠŸèƒ½ä¸å˜ã€‚

---

### [DSv32] Fix MTP and CP compatability (#19062)
**SHA**: `afd91e8` | ğŸ”— [æŸ¥çœ‹æäº¤](https://github.com/sgl-project/sglang/commit/afd91e8782c0852d6038fd42df090c0de45cea1a)

**ğŸ¯ å˜æ›´ç±»å‹**ï¼šä»£ç é‡æ„  
**âš¡ é‡è¦ç¨‹åº¦**ï¼šğŸŸ¢ä½  
**ğŸ“‹ æ‘˜è¦**ï¼šå°† DeepSeekâ€nextn æ¨¡å‹ä¸­ä½¿ç”¨çš„æ³¨æ„åŠ› TPï¼ˆTensor Parallelï¼‰æ¥å£æ›¿æ¢ä¸º CPï¼ˆCluster Parallelï¼‰æ¥å£ï¼Œåˆ†åˆ«ä¿®æ”¹ `get_attention_tp_*` ä¸º `get_attention_cp_*`ï¼Œå¹¶ç›¸åº”è°ƒæ•´ cp_rankã€cp_size çš„è·å–é€»è¾‘ï¼Œä»¥å…¼å®¹ MTP ä¸ CPã€‚

---

### [Auto Sync] Update batch_invariant_ops.py (20260221) (#19098)
**SHA**: `463baaf` | ğŸ”— [æŸ¥çœ‹æäº¤](https://github.com/sgl-project/sglang/commit/463baafe10454a198c14a73d6641d46bbece7c30)

**ğŸ¯ å˜æ›´ç±»å‹**ï¼šä»£ç é‡æ„  
**âš¡ é‡è¦ç¨‹åº¦**ï¼šğŸŸ¢ä½  
**ğŸ“‹ æ‘˜è¦**ï¼šåœ¨ `batch_invariant_ops.py` ä¸­ä¸ºå¤šä¸ª Triton kernel å‚æ•°æ·»åŠ  `tl.constexpr` ç±»å‹æ ‡æ³¨ï¼Œæå‡ä»£ç å¯è¯»æ€§å’Œé™æ€æ£€æŸ¥æ”¯æŒã€‚

---

### [Auto Sync] Update bench_one_batch_server_internal.py (20260221) (#19097)
**SHA**: `2928dfb` | ğŸ”— [æŸ¥çœ‹æäº¤](https://github.com/sgl-project/sglang/commit/2928dfb8fae9a0a1985166b34d4cbcce31ae45b3)

**ğŸ¯ å˜æ›´ç±»å‹**ï¼šä»£ç é‡æ„  
**âš¡ é‡è¦ç¨‹åº¦**ï¼šğŸŸ¢ä½  
**ğŸ“‹ æ‘˜è¦**ï¼šåœ¨ `bench_one_batch_server_internal.py` çš„æš–å¯åŠ¨é˜¶æ®µï¼Œæ–°å¢ `batch_size_unique = list(set(bench_args.batch_size))`ï¼Œé’ˆå¯¹å»é‡åçš„ batch size åˆ—è¡¨è¿›è¡Œæ‰“å°å’Œéå†ï¼Œé¿å…åœ¨ Warmup æ—¶å› é‡å¤çš„ batch size å¯¼è‡´å†—ä½™æ‰§è¡Œã€‚

---

### Upd: CODEOWNERS (#19055)
**SHA**: `b2573fe` | ğŸ”— [æŸ¥çœ‹æäº¤](https://github.com/sgl-project/sglang/commit/b2573fe4267ae3a6e3cda521fad15e8efb07dc0c)

**ğŸ¯ å˜æ›´ç±»å‹**ï¼šæ–‡æ¡£æ›´æ–°  
**âš¡ é‡è¦ç¨‹åº¦**ï¼šğŸŸ¢ä½  
**ğŸ“‹ æ‘˜è¦**ï¼šæ›´æ–° `.github/CODEOWNERS`ï¼Œä¸º `/docker`ã€`/python/sglang/srt/layers/attention`ã€`/python/sglang/srt/layers/attention/nsa`ã€`/python/sglang/srt/layers/quantization/quark` ç­‰è·¯å¾„æ–°å¢æˆ–è°ƒæ•´ä»£ç æ‰€æœ‰è€…ï¼Œç¡®ä¿æ–°è´¡çŒ®è€…è·æƒå®¡é˜…ã€‚

---

### [GPT-OSS] support fp8 online quantization for gpt-oss bf16 (#18988)
**SHA**: `4bffd3a` | ğŸ”— [æŸ¥çœ‹æäº¤](https://github.com/sgl-project/sglang/commit/4bffd3a2323a332506ce16f0fbd2ce7e96db2204)

**ğŸ¯ å˜æ›´ç±»å‹**ï¼šä»£ç é‡æ„  
**âš¡ é‡è¦ç¨‹åº¦**ï¼šğŸŸ¢ä½  
**ğŸ“‹ æ‘˜è¦**ï¼šåœ¨ fp8 é‡åŒ–å±‚åŠ å…¥ `with_bias` å‚æ•°å¹¶å®ç°å¯é€‰ bias æƒé‡ï¼›`create_weights` æ–°å¢ bias å‚æ•°å¹¶æ³¨å†Œç›¸åº”å¼ é‡ï¼›`apply` ä¼ é€’ biasï¼›æœåŠ¡å™¨å¯åŠ¨é€»è¾‘åœ¨æœªä½¿ç”¨é‡åŒ–æ—¶æ‰å¯ç”¨ Triton MOE å†…æ ¸ã€‚

---

