# æ¯æ—¥æ›´æ–°æŠ¥å‘Šï¼ˆ2026-02-17ï¼‰

## sgl-project/sglang

| æäº¤æ—¶é—´ | ä½œè€… | æäº¤ä¿¡æ¯ |
|----------|------|----------|
| 2026-02-17 23:31:12 | Minglei Zhu | [PCG] support piecewise cuda graph for kimi-linear model (#18849) |
| 2026-02-17 22:56:04 | Mick | Revert "[diffusion] operator: unify rotary embedding impl" (#18929) |
| 2026-02-17 21:54:19 | Makcum888e | [Diffusion] [NPU] Fix CI run (#18921) |
| 2026-02-17 19:00:37 | HAI | ROCm use rotary_embedding from sgl-kernel (#18920) |
| 2026-02-17 18:19:54 | Makcum888e | [Diffusion] Fix get model name when model local path end with "/" (#18918) |
| 2026-02-17 18:17:46 | Ratish P | [diffusion]: fix sparse video gen 2 backend being applied to cross-attention (#18900) |
| 2026-02-17 17:07:50 | HAI | Revert "[AMD] Fix RotaryEmbedding crash on AMD/ROCm (regression from #17934)" (#18922) |
| 2026-02-17 15:12:20 | Makcum888e | [Diffusion] [NPU] [Doc] Add NPU documentation for sglang-diffusion (#18894) |
| 2026-02-17 14:18:57 | billishyahao | [TBO] fix cuda graph intermittently becomes disabled bug (#18320) |
| 2026-02-17 12:59:40 | Michael | [AMD] Fix RotaryEmbedding crash on AMD/ROCm (regression from #17934) (#18903) |
| 2026-02-17 12:54:30 | Mohammad Miadh Angkad | [Tiny] Fix assert syntax warning in compressed_tensors_w4a4_mxint4_moe.py (#18899) |
| 2026-02-17 12:50:55 | Alison Shao | Skip flaky test_tool_choice_required_non_streaming for Mistral (#18889) |
| 2026-02-17 12:14:15 | Yilong Zhao | [misc] adding metadata field in UpdateWeightFromDiskReqInput (#18821) |
| 2026-02-17 12:02:48 | triple-mu | [diffusion] operator: unify rotary embedding impl (#18164) |
| 2026-02-17 10:20:41 | pansicheng | Adapt the Qwen2Model._update_causal_mask for transformers==4.57.1 (#18774) |
| 2026-02-17 09:45:05 | Ratish P | [diffusion]: fix scheduler crash on ZMQ messages with unexpected frame counts (#17890) |
| 2026-02-17 05:50:10 | Alison Shao | Fix CI: add flashinfer --download-cubin to install dependencies (#18887) |
| 2026-02-17 03:50:39 | Frank Minors | Fix GLM-5 fused shared expert (#18804) |
| 2026-02-17 00:59:50 | danielafrimi | Fix modelopt FP8 create weights (#18447) |

### ğŸ“Š ç»Ÿè®¡æ‘˜è¦
> æœ¬æ—¥å…± 19 ä¸ªæäº¤ | ğŸ”´é«˜ 2 | ğŸŸ¡ä¸­ 2 | ğŸŸ¢ä½ 15
## ğŸ“‹ ç›®å½•

- [sgl-project/sglang](#sgl-project-sglang)
  - [ğŸ“Š ç»Ÿè®¡æ‘˜è¦](#-ç»Ÿè®¡æ‘˜è¦)
  - [ğŸ”´ é«˜é‡è¦åº¦å˜æ›´ (2)](#-ğŸ”´-é«˜é‡è¦åº¦å˜æ›´-2)
    - [Revert "[diffusion] operator: unify rotary embedding impl...](#bfe34c9)
    - [[diffusion] operator: unify rotary embedding impl (#18164)](#26b2c63)
  - [ğŸŸ¡ ä¸­é‡è¦åº¦å˜æ›´ (2)](#-ğŸŸ¡-ä¸­é‡è¦åº¦å˜æ›´-2)
    - [[PCG] support piecewise cuda graph for kimi-linear model ...](#bf52388)
    - [[Diffusion] [NPU] Fix CI run (#18921)](#2aa0db7)
  - [ğŸŸ¢ ä½é‡è¦åº¦å˜æ›´ (15)](#-ğŸŸ¢-ä½é‡è¦åº¦å˜æ›´-15)
    - [ROCm use rotary_embedding from sgl-kernel (#18920)](#8bb1037)
    - [[Diffusion] Fix get model name when model local path end ...](#5f81ec1)
    - [[diffusion]: fix sparse video gen 2 backend being applied...](#f6cc024)
    - [Revert "[AMD] Fix RotaryEmbedding crash on AMD/ROCm (regr...](#b158f5d)
    - [[Diffusion] [NPU] [Doc] Add NPU documentation for sglang-...](#14c95d2)
    - [[TBO] fix cuda graph intermittently becomes disabled bug ...](#899e2be)
    - [[AMD] Fix RotaryEmbedding crash on AMD/ROCm (regression f...](#5e3103a)
    - [[Tiny] Fix assert syntax warning in compressed_tensors_w4...](#90a0d66)
    - [Skip flaky test_tool_choice_required_non_streaming for Mi...](#7e41ac6)
    - [[misc] adding metadata field in UpdateWeightFromDiskReqIn...](#d5307ce)
    - [Adapt the Qwen2Model._update_causal_mask for transformers...](#b21390f)
    - [[diffusion]: fix scheduler crash on ZMQ messages with une...](#50ca24a)
    - [Fix CI: add flashinfer --download-cubin to install depend...](#f9c3def)
    - [Fix GLM-5 fused shared expert (#18804)](#1b659bc)
    - [Fix modelopt FP8 create weights (#18447)](#0ff2415)
#### ğŸ”´ é«˜é‡è¦åº¦å˜æ›´ (2)

### Revert "[diffusion] operator: unify rotary embedding impl" (#18929)
**SHA**: `bfe34c9` | ğŸ”— [æŸ¥çœ‹æäº¤](https://github.com/sgl-project/sglang/commit/bfe34c90ffe57a78b5c2556c504292026e388a61)

**ğŸ¯ å˜æ›´ç±»å‹**ï¼šé‡æ„ / æ¶æ„å˜æ›´ã€æ€§èƒ½ä¼˜åŒ–  
**âš¡ é‡è¦ç¨‹åº¦**ï¼šğŸ”´ é«˜  

**ğŸ“‹ å˜æ›´æ‘˜è¦**  
æœ¬æ¬¡æäº¤æ’¤å›äº†å…ˆå‰ç»Ÿä¸€å®ç° RoPEï¼ˆRotary Positional Embeddingï¼‰çš„æ”¹åŠ¨ï¼Œé‡æ–°å¼•å…¥äº†é’ˆå¯¹ FlashInfer çš„ä¸“å±å®ç° `apply_flashinfer_rope_qk_inplace`ï¼Œå¹¶åœ¨æ‰€æœ‰æ¶‰åŠ RoPE çš„æ¨¡å‹å±‚ä¸­åˆ‡æ¢ä¸ºè¯¥å®ç°ï¼ˆåœ¨ CUDA ç¯å¢ƒä¸” FlashInfer å¯ç”¨æ—¶ä½¿ç”¨ FlashInferï¼Œå¦åˆ™å›é€€è‡³ Triton å®ç°ï¼‰ã€‚åŒæ—¶å¯¹ `compute_rope_cos_sin`ã€`rotary_embedding`ã€`triton_ops` ç­‰æ ¸å¿ƒæ–‡ä»¶ä½œäº† API è°ƒæ•´å’Œå…¼å®¹æ€§å¤„ç†ã€‚

**ğŸ¯ å½±å“èŒƒå›´**  
- `python/sglang/multimodal_gen/runtime/layers/rotary_embedding.py`ï¼ˆæ ¸å¿ƒ RoPE å®ç°ï¼‰  
- `python/sglang/multimodal_gen/runtime/layers/triton_ops.py`ï¼ˆTriton fallbackï¼‰  
- å¤šä¸ª DiTã€MOVAã€Fluxã€WanVideoã€Qwenâ€‘Image ç­‰æ¨¡å‹å®ç°æ–‡ä»¶ï¼Œå‡ ä¹è¦†ç›–é¡¹ç›®ä¸­å…¨éƒ¨ä½¿ç”¨ RoPE çš„ attention ç»„ä»¶ã€‚  
- `pipelines_core/stages/model_specific_stages/mova.py`ï¼ˆé¢‘ç‡å¼ é‡å½¢çŠ¶è°ƒæ•´ï¼‰  

**ğŸ” æŠ€æœ¯æ´å¯Ÿ**  

| ç»´åº¦ | å½±å“ |
|------|------|
| **æ¶æ„å½±å“** | 1. æ–°å¢ `apply_flashinfer_rope_qk_inplace` ä½œä¸ºç»Ÿä¸€å…¥å£ï¼Œå–ä»£æ—§çš„ `_apply_rotary_emb_qk`ã€‚<br>2. é‡æ„ `compute_rope_cos_sin`ï¼Œæ”¯æŒæ‰¹æ¬¡ç»´åº¦ `[B, L]`ï¼Œè¿”å› `[B, L, head_dim]` çš„ cosine/sineï¼Œç»Ÿä¸€äº†ä¸åŒæ¨¡å‹å¯¹ RoPE çš„è°ƒç”¨æ–¹å¼ã€‚<br>3. åœ¨ CUDA ç¯å¢ƒä¸‹å¼•å…¥ FlashInfer å¯é€‰ä¾èµ–ï¼Œå¢åŠ äº†è¿è¡Œæ—¶åˆ†æ”¯ï¼šFlashInfer â†’ Triton â†’ çº¯ Python NaÃ¯veï¼Œå®ç°æ›´åŠ æ¨¡å—åŒ–ï¼Œæå‡ä»£ç å¯ç»´æŠ¤æ€§ã€‚ |
| **æ€§èƒ½å½±å“** | - **æ­£å‘**ï¼šFlashInfer åœ¨ 2â€‘4 å€å·¦å³çš„ååæå‡ï¼ˆç‰¹åˆ«æ˜¯å¤§ batchã€é•¿åºåˆ—çš„ DiT/Fluxï¼‰ï¼Œæ˜¾è‘—å‡å° RoPE è®¡ç®—å æ¯”ã€‚<br>- **è´Ÿå‘**ï¼šè‹¥ FlashInfer ä¸å¯ç”¨ï¼Œå°†é€€å› Triton å®ç°ï¼›åœ¨ä¸æ”¯æŒ CUDAï¼ˆå¦‚ AMD/ROCmï¼‰æ—¶ä»ä¿æŒåŸæœ‰ Triton å®ç°ï¼Œæ€§èƒ½ç•¥æœ‰å›é€€ä½†ä¸ä¼šå› ç¼ºå¤±å®ç°å¯¼è‡´å´©æºƒã€‚ |
| **å®‰å…¨è€ƒè™‘** | - å¼•å…¥å¤–éƒ¨åº“ `flashinfer`ï¼Œå¢åŠ äº†æ½œåœ¨çš„ä¾èµ–å®‰å…¨é£é™©ï¼ˆéœ€å®¡è®¡å‘å¸ƒçš„ wheelï¼‰ã€‚<br>- ä½¿ç”¨ `warnings.warn` åœ¨ç¼ºå°‘ FlashInfer æ—¶æç¤ºç”¨æˆ·ï¼Œé¿å…å›  ImportError å¯¼è‡´æœåŠ¡ä¸å¯ç”¨ã€‚<br>- å‚æ•°æ£€æŸ¥ï¼ˆshapeã€dtypeã€ç»´åº¦ï¼‰åœ¨æ–°å®ç°ä¸­æ›´ä¸ºä¸¥æ ¼ï¼Œé™ä½äº†å› é”™è¯¯è¾“å…¥å¯¼è‡´çš„æœªå®šä¹‰è¡Œä¸ºã€‚ |
| **å…¼å®¹æ€§** | - å¯¹å¤– API ä»ä¿æŒ `_apply_rotary_emb`ï¼ˆä»…ç”¨äºå•å¼ é‡ï¼‰ä¸å˜ï¼Œä¿æŒå‘åå…¼å®¹ã€‚<br>- æ–°å¢çš„ `apply_flashinfer_rope_qk_inplace` å‚æ•°æ”¹å˜ï¼ˆéœ€ä¼ å…¥ `cos_sin_cache`ï¼‰ï¼Œæ—§ä»£ç å·²å…¨éƒ¨è¿ç§»ï¼Œè‹¥ç”¨æˆ·è‡ªè¡Œè°ƒç”¨æ—§å®ç°éœ€æ³¨æ„å…¼å®¹ã€‚ |

**âš ï¸ æ½œåœ¨é£é™©**  
1. **ä¾èµ–ç¼ºå¤±**ï¼šåœ¨éƒ¨åˆ†éƒ¨ç½²ç¯å¢ƒï¼ˆå¦‚ä»…å®‰è£… CPU ç‰ˆæˆ– AMD GPUï¼‰æœªå®‰è£… FlashInferï¼Œå¯èƒ½è§¦å‘å¤§é‡ `warnings`ï¼Œå¹¶ä¸”å›é€€åˆ° Triton å®ç°åå‡ºç°æ˜¾è‘—æ€§èƒ½ä¸‹é™ã€‚  
2. **å½¢çŠ¶/ç±»å‹ä¸åŒ¹é…**ï¼š`apply_flashinfer_rope_qk_inplace` å¯¹ `cos_sin_cache` è¦æ±‚ 2D `[seq_len, head_dim]`ï¼Œè€Œ `compute_rope_cos_sin` ç°åœ¨è¿”å› `[B, L, head_dim]`ã€‚è‹¥è°ƒç”¨æ–¹æœª `squeeze(0)`ï¼Œä¼šå¯¼è‡´è¿è¡Œæ—¶ `ValueError`ï¼ˆå·²åœ¨æ¨¡å‹å±‚è‡ªè¡Œ `squeeze`ï¼Œä½†è‡ªå®šä¹‰è°ƒç”¨ä»æœ‰é£é™©ï¼‰ã€‚  
3. **CUDA/FlashInfer ç‰ˆæœ¬å…¼å®¹**ï¼šFlashInfer ä¸ç‰¹å®š CUDA ç‰ˆæœ¬ã€æ˜¾å¡é©±åŠ¨å¼ºå…³è”ï¼Œå‡çº§æˆ–é™çº§ CUDA å¯èƒ½å¯¼è‡´ `ImportError` æˆ–å†…éƒ¨æ–­è¨€é”™è¯¯ã€‚  
4. **æ•°å€¼å·®å¼‚**ï¼šFlashInfer ä½¿ç”¨ `float32` ä¸­é—´è®¡ç®—å†è½¬å›åŸ dtypeï¼Œå¯èƒ½åœ¨ `bfloat16` åœºæ™¯ä¸‹å‡ºç°ç»†å¾®æ•°å€¼å·®å¼‚ï¼Œå½±å“æ¨¡å‹è¾“å‡ºçš„ç¡®å®šæ€§ã€‚  
5. **å¹¶è¡Œ/åˆ†å¸ƒå¼**ï¼šåœ¨å¤šæœºåˆ†å¸ƒå¼è®¾ç½®ä¸‹ï¼Œ`apply_flashinfer_rope_qk_inplace` éœ€è¦ `positions` å‚æ•°æ¥ä¿è¯è·¨æ‰¹æ¬¡ä½ç½®å¯¹é½ï¼Œè‹¥æœªæ˜¾å¼ä¼ é€’ï¼Œå¯èƒ½å¯¼è‡´ä½ç½®é”™ä½ã€‚  

**ğŸ’¡ å…³æ³¨å»ºè®®**  

| å»ºè®® | è¯´æ˜ |
|------|------|
| **1. ç¯å¢ƒæ£€æµ‹ä¸ä¾èµ–ç®¡ç†** | åœ¨éƒ¨ç½²è„šæœ¬ä¸­æ˜¾å¼æ£€æŸ¥ `flashinfer` æ˜¯å¦å¯ç”¨ï¼›è‹¥ä¸å¯ç”¨ï¼Œå»ºè®®è‡ªåŠ¨åˆ‡æ¢è‡³ Triton å¹¶è®°å½•æ—¥å¿—ï¼Œä»¥å…åœ¨ç”Ÿäº§ç¯å¢ƒå‡ºç°å¤§é‡è­¦å‘Šã€‚ |
| **2. å‚æ•°æ ¡éªŒå•å…ƒæµ‹è¯•** | ä¸º `apply_flashinfer_rope_qk_inplace` æ·»åŠ å•å…ƒæµ‹è¯•ï¼š<br>â€¢ 4D è¾“å…¥ã€ä¸åŒ `head_dim`ã€`is_neox`/é `is_neox` ä¸¤ç§æ¨¡å¼<br>â€¢ `positions` å‚æ•°çš„æœ‰æ— åˆ†æ”¯<br>ç¡®ä¿é”™è¯¯ä¿¡æ¯å‹å¥½ä¸”ä¸æŠ›å‡ºæœªæ•è·å¼‚å¸¸ã€‚ |
| **3. æ€§èƒ½åŸºå‡†** | åœ¨ä¸»è¦æ¨¡å‹ï¼ˆMOVAã€Fluxã€WanVideoï¼‰ä¸Šåˆ†åˆ«è·‘ `torch.cuda.synchronize` å‰åçš„è®¡æ—¶ï¼Œæ¯”è¾ƒ FlashInfer ä¸ Triton ä¸¤ç§è·¯å¾„çš„å®é™…åŠ é€Ÿæ¯”ä¾‹ï¼Œå†™å…¥ CI åŸºå‡†ï¼Œä»¥é˜²å›é€€å¯¼è‡´æ€§èƒ½å€’é€€ã€‚ |
| **4. æ•°å€¼ä¸€è‡´æ€§éªŒè¯** | å¯¹æ¯”ä½¿ç”¨ FlashInfer ä¸ä½¿ç”¨åŸ NaÃ¯ve/Trition å®ç°çš„å‰å‘è¾“å‡ºï¼ˆFP16/BF16ï¼‰ï¼Œç¡®ä¿ç›¸å¯¹è¯¯å·®åœ¨å¯æ¥å—é˜ˆå€¼ï¼ˆå¦‚ `<1e-4`ï¼‰ã€‚è‹¥å‡ºç°åå·®ï¼Œéœ€è¦åœ¨ `apply_flashinfer_rope_qk_inplace` ä¸­åŠ å…¥ `torch.float64` ä¸­é—´æ€æˆ–æ˜¾å¼ roundingã€‚ |
| **5. æ–‡æ¡£ä¸ç¤ºä¾‹æ›´æ–°** | åœ¨é¡¹ç›®æ–‡æ¡£ä¸­æ ‡æ˜ï¼š<br>â€¢ `apply_flashinfer_rope_qk_inplace` ä»…åœ¨ CUDA + FlashInfer ç¯å¢ƒä¸‹æ¿€æ´»ï¼›<br>â€¢ å¦‚ä½•æ‰‹åŠ¨å…³é—­ FlashInferï¼ˆè®¾ç½®ç¯å¢ƒå˜é‡æˆ–åœ¨ä»£ç ä¸­å¼ºåˆ¶ `use_flashinfer=False`ï¼‰ã€‚ |
| **6. å›æ»šè·¯å¾„** | ç”±äºæœ¬æ¬¡æ˜¯ **æ’¤é”€** ç»Ÿä¸€å®ç°çš„æäº¤ï¼Œè‹¥åç»­å‘ç°å…¼å®¹æ€§é—®é¢˜ï¼Œå¯å¿«é€Ÿå›é€€åˆ°åŸ `_apply_rotary_emb_qk` å®ç°ï¼›å»ºè®®åœ¨ `CustomOp` æ³¨å†Œè¡¨ä¸­ä¿ç•™æ—§å®ç°çš„åˆ«åï¼Œä»¥ä¾¿å¿«é€Ÿåˆ‡æ¢ã€‚ |
| **7. åˆ†å¸ƒå¼ä¸€è‡´æ€§** | åœ¨ä½¿ç”¨ `apply_flashinfer_rope_qk_inplace` çš„æ¨¡å‹ï¼ˆå°¤å…¶æ˜¯ `MOVA` åŒå¡”ï¼‰ä¸­ï¼Œç¡®ä¿ `positions` åœ¨æ‰€æœ‰ rank ä¸Šä¿æŒä¸€è‡´ï¼Œå¿…è¦æ—¶åœ¨ `forward_dual_tower_dit` å‰ç»Ÿä¸€å¹¿æ’­ã€‚ |

> **ç»“è®º**ï¼šæ­¤æ¬¡æ”¹åŠ¨é€šè¿‡å¼•å…¥ FlashInfer åŠ é€Ÿ RoPE è®¡ç®—ï¼Œæ•´ä½“æ¶æ„æ›´æ¸…æ™°ã€æ€§èƒ½æœ‰æ˜¾è‘—æå‡ã€‚ä½†åŒæ—¶å¼•å…¥äº†å¤–éƒ¨ä¾èµ–å’Œæ›´ä¸¥æ ¼çš„è¾“å…¥æ ¡éªŒï¼Œéƒ¨ç½²å‰åŠ¡å¿…å®Œæˆå…¼å®¹æ€§ä¸æ€§èƒ½å›å½’æµ‹è¯•ï¼Œä»¥è§„é¿å› ä¾èµ–ç¼ºå¤±æˆ–å½¢çŠ¶

---

### [diffusion] operator: unify rotary embedding impl (#18164)
**SHA**: `26b2c63` | ğŸ”— [æŸ¥çœ‹æäº¤](https://github.com/sgl-project/sglang/commit/26b2c63d03665ab70524599c2e146b37f589f1a7)

**ğŸ¯ å˜æ›´ç±»å‹**ï¼šé‡æ„ / æ€§èƒ½ä¼˜åŒ–  
**âš¡ é‡è¦ç¨‹åº¦**ï¼šğŸ”´é«˜  
**ğŸ“‹ å˜æ›´æ‘˜è¦**ï¼šç»Ÿä¸€å¹¶å‡çº§äº† Rotaryâ€¯Embedding çš„å®ç°ã€‚æ–°å¢ `_apply_rotary_emb`ï¼ˆå•å‘ï¼‰å’Œ `_apply_rotary_emb_qk`ï¼ˆQâ€¯&â€¯K åŒæ—¶ï¼‰ä¸¤ä¸ªé«˜å±‚æ¥å£ï¼Œå†…éƒ¨æ ¹æ®è¿è¡Œæ—¶ç¯å¢ƒè‡ªåŠ¨é€‰æ‹© **FlashInfer**ï¼ˆCUDAâ€¯fp16/bf16ï¼‰ã€**Triton** æˆ– **naÃ¯ve PyTorch** å®ç°ã€‚åŒæ­¥æ›´æ–°äº†å¤šå¤„æ¨¡å‹ã€å±‚ã€pipeline ä»£ç ä»¥ä½¿ç”¨æ–°æ¥å£ï¼Œå¹¶å¯¹ `compute_rope_cos_sin` çš„è¾“å‡ºå½¢çŠ¶åšäº†ç®€åŒ–ï¼Œä½¿å…¶æ›´æ˜“äºåœ¨ FSDP/TP/SP åœºæ™¯ä¸‹ä½¿ç”¨ã€‚

---

### ğŸ¯ å½±å“èŒƒå›´
- **æ ¸å¿ƒå±‚**ï¼š`rotary_embedding.py`ã€`triton_ops.py`ï¼ˆæ–°å¢ `apply_rotary_embedding_qk` kernelï¼‰ã€‚  
- **æ¨¡å‹å®ç°**ï¼š`mova_dual_tower.py`, `causal_wanvideo.py`, `flux.py`, `flux_2.py`, `glm_image.py`, `hunyuanvideo.py`, `mova_audio_dit.py`, `mova_video_dit.py`, `qwen_image.py`, `wanvideo.py`, `zimage.py` ç­‰å…¨éƒ¨ DiT ç³»åˆ—æ¨¡å‹ã€‚  
- **Pipeline**ï¼š`stages/mova.py`ï¼ˆé¢‘ç‡å‘é‡åŒ…è£…ä¸º `(cos, sin)` å…ƒç»„ï¼‰ã€‚  
- **ä¾èµ–**ï¼šæ–°å¢å¯¹ `flashinfer`ï¼ˆå¯é€‰ï¼‰å’Œ `current_platform.is_cuda()` çš„æ£€æµ‹ï¼›å¯¹ `triton` çš„ kernel å‚æ•°åšäº†æ‰©å±•ã€‚

---

### ğŸ” æŠ€æœ¯æ´å¯Ÿ  

| ç»´åº¦ | å½±å“åˆ†æ |
|------|----------|
| **æ¶æ„å½±å“** | - å°†åŸå…ˆæ•£è½åœ¨å„æ¨¡å‹é‡Œçš„ FlashInfer/Trition è°ƒç”¨ç»Ÿä¸€æŠ½è±¡ä¸ºä¸¤å¥—é«˜å±‚å‡½æ•°ï¼Œé™ä½è€¦åˆåº¦ã€‚<br>- æ–°å¢ `current_platform` åˆ¤å®šï¼Œç»Ÿä¸€åœ¨ CUDA ç¯å¢ƒä¸‹å¯ç”¨ FlashInferï¼Œå®ç° â€œå¹³å°æ„ŸçŸ¥â€ æ¶æ„ã€‚<br>- `compute_rope_cos_sin` è¾“å‡ºä» `[B, L, head_dim]` â†’ `[L, head_dim]`ï¼Œç®€åŒ–äº†è·¨è¿›ç¨‹/åˆ†å¸ƒå¼å¼ é‡åˆå§‹åŒ–ï¼ˆå¯¹ FSDP/TP æ›´å‹å¥½ï¼‰ã€‚ |
| **æ€§èƒ½å½±å“** | - **FlashInfer**ï¼ˆè‹¥å¯ç”¨ï¼‰åœ¨ FP16/BF16 ä¸‹æä¾›åŸä½ã€SIMDâ€‘çº§åˆ«çš„ RoPE åŠ é€Ÿï¼Œæ˜¾è‘—é™ä½ Q/K è®¡ç®—çš„ GPU æ—¶é—´ã€‚<br>- **Triton** æ–°å¢ `apply_rotary_embedding_qk` kernelï¼Œç»Ÿä¸€ Qã€K çš„å¹¶è¡Œè®¡ç®—ï¼Œå‡å°‘ kernel å¯åŠ¨æ¬¡æ•°ï¼›å¹¶ä½¿ç”¨ `BLOCK_HS_HALF` è‡ªåŠ¨è°ƒä¼˜ï¼Œæé«˜å¤§ headâ€‘size åœºæ™¯çš„ååã€‚<br>- åœ¨æ²¡æœ‰ FlashInfer çš„ç¯å¢ƒä»ä¿æŒå…¼å®¹ï¼ˆfallback to Triton â†’ NaÃ¯veï¼‰ï¼Œä»…åœ¨æç«¯å¤§åºåˆ—æ—¶å¯èƒ½å‡ºç°è½»å¾®å›é€€ã€‚ |
| **å®‰å…¨è€ƒè™‘** | - ä»…æ˜¯å¯é€‰çš„ç¬¬ä¸‰æ–¹åº“å¯¼å…¥ (`flashinfer`)ï¼›è‹¥ç¼ºå¤±ä¼šå›é€€ï¼Œä¸ä¼šå¼•å…¥æœªå®¡è®¡çš„ä»£ç æ‰§è¡Œè·¯å¾„ã€‚<br>- æ–°å¢çš„ `apply_rotary_embedding_qk` é€šè¿‡ `torch.empty_like` åˆ›å»ºè¾“å‡ºï¼Œæ— é¢å¤–å†…å­˜æ‹·è´ï¼Œæœªå¼•å…¥æ˜¾å¼å†…å­˜æ³„æ¼é£é™©ã€‚ |
| **å¯ç»´æŠ¤æ€§** | - ç»Ÿä¸€çš„æ¥å£å‡å°‘äº†å„æ¨¡å‹æ–‡ä»¶ä¸­çš„é‡å¤å®ç°ï¼Œåç»­ç»´æŠ¤/Bug ä¿®å¤é›†ä¸­åœ¨ `rotary_embedding.py` ä¸ `triton_ops.py`ã€‚<br>- é€šè¿‡ `try/except` åŒ…è£… `flashinfer`ï¼Œé¿å…ç¡¬ä¾èµ–ï¼Œæå‡è·¨å¹³å°å¯æ„å»ºæ€§ã€‚<br>- ä»£ç ä¸­å¯¹ `dtype`ã€`device` çš„æ˜¾å¼è½¬æ¢æ›´åŠ æ˜ç¡®ï¼Œé™ä½äº†éšå¼å¹¿æ’­å¯¼è‡´çš„é”™è¯¯ã€‚ |

---

### âš ï¸ æ½œåœ¨é£é™©  
1. **API å…¼å®¹æ€§**ï¼šåŸæœ‰ `apply_flashinfer_rope_qk_inplace` å·²è¢«åˆ é™¤ï¼Œè‹¥å¤–éƒ¨é¡¹ç›®ç›´æ¥å¼•ç”¨ä¼šæŠ¥ `ImportError`ã€‚  
2. **Shape å˜åŒ–**ï¼š`compute_rope_cos_sin` ç°åœ¨è¿”å› `[L, head_dim]`ï¼ˆå»æ‰ batchç»´ï¼‰ï¼Œä»»ä½•ä»æŒ‰æ—§å½¢çŠ¶ `[..., L, head_dim]` è®¿é—®çš„ä»£ç ä¼šè§¦å‘ç»´åº¦ä¸åŒ¹é…é”™è¯¯ã€‚  
3. **å¹³å°æ£€æµ‹é”™è¯¯**ï¼š`_is_flashinfer_available` ä»…åœ¨ CUDA ç¯å¢ƒä¸”æˆåŠŸå¯¼å…¥ `flashinfer` æ—¶ä¸º Trueï¼Œè‹¥ç”¨æˆ·åœ¨ CUDA ç¯å¢ƒä½†æœªå®‰è£… `flashinfer`ï¼Œä»ä¼šå›é€€åˆ° Tritonï¼›è‹¥ Triton ä¸å…¼å®¹ï¼ˆå¦‚ AMD/ROCmï¼‰ï¼Œä¼šèµ° NaÃ¯ve è·¯å¾„ï¼Œæ€§èƒ½å¯èƒ½ä¸‹é™ã€‚  
4. **dtype å¼ºåˆ¶è½¬æ¢**ï¼šåœ¨ FlashInfer è·¯å¾„ä¸­å¼ºåˆ¶ `float32` ç¼“å­˜ï¼Œè€Œåœ¨ Triton/NaÃ¯ve è·¯å¾„ä¸­ä¿æŒåŸ dtypeï¼›åœ¨æç«¯æ··åˆ dtype åœºæ™¯ä¸‹ï¼ˆå¦‚ BF16 â†’ FP16ï¼‰å¯èƒ½å‡ºç°å¾®å°æ•°å€¼å·®å¼‚ã€‚  
5. **å¹¶è¡Œåˆ†å¸ƒå¼**ï¼š`apply_rotary_embedding_qk` ä¸­å¯¹ `stride` çš„ä½¿ç”¨å‡è®¾è¿ç»­å¸ƒå±€ï¼Œè‹¥ upstream å¯¹å¼ é‡åšäº†éæ ‡å‡†è½¬ç½®/åˆ‡ç‰‡ï¼ˆå¯¼è‡´ stride ä¸è¿ç»­ï¼‰ï¼Œå¯èƒ½å¯¼è‡´é”™è¯¯æˆ–æ€§èƒ½ä¸‹é™ã€‚  

---

### ğŸ’¡ å…³æ³¨å»ºè®®  
- **å›å½’æµ‹è¯•**ï¼šåœ¨ CPUã€CUDAï¼ˆæœ‰/æ—  flashinferï¼‰ã€ROCm ç¯å¢ƒè·‘å®Œæ•´æ¨¡å‹æ¨ç†ï¼Œå¯¹æ¯”è¾“å‡ºæ•°å€¼å·®å¼‚ï¼Œç¡®ä¿æ•°å€¼è¯¯å·®åœ¨å¯æ¥å—èŒƒå›´ã€‚  
- **æ–‡æ¡£/è¿ç§»æŒ‡å—**ï¼šåœ¨é¡¹ç›® RELEASE NOTES ä¸­æ˜ç¡®è¯´æ˜ `apply_flashinfer_rope_qk_inplace` å·²è¢«åºŸå¼ƒï¼Œæ¨èä½¿ç”¨ `_apply_rotary_emb_qk`ï¼›å¹¶æä¾›ç¤ºä¾‹ä»£ç ã€‚  
- **ç¯å¢ƒæ£€æµ‹**ï¼šåœ¨å¯åŠ¨æ—¥å¿—ä¸­æ‰“å° `FlashInfer`/`Triton`/`NaÃ¯ve` é€‰æ‹©ç»“æœï¼Œå¸®åŠ©ç”¨æˆ·å¿«é€Ÿå®šä½æ€§èƒ½ç“¶é¢ˆã€‚  
- **å¼‚å¸¸å¤„ç†**ï¼šåœ¨ Triton è°ƒç”¨å¤±è´¥æ—¶æ•è·å¼‚å¸¸åå›é€€è‡³ NaÃ¯veï¼Œå®ç°â€œä¿å®ˆâ€å…¼å®¹è€Œä¸æ˜¯ç›´æ¥æŠ¥é”™ã€‚  
- **dtype ä¸ device ç»Ÿä¸€**ï¼šåœ¨è°ƒç”¨ `_apply_rotary_emb*_qk` å‰ç¡®ä¿ `cos/sin` å·²ç»è¢« `.to(q.dtype).to(q.device)`ï¼Œé¿å…ä¸å¿…è¦çš„è·¨è®¾å¤‡æ‹·è´ã€‚  
- **æŒç»­ç›‘æ§**ï¼šå¯¹ä½¿ç”¨ FlashInfer çš„æ¨¡å‹è¿›è¡ŒåŸºå‡†ç›‘æ§ï¼ˆGPUâ€‘Utilã€Kernelâ€‘Timeï¼‰ï¼Œåœ¨ flashinfer ç‰ˆæœ¬å‡çº§åé‡æ–°è¯„ä¼°å…¼å®¹æ€§ã€‚  

> **ç»“è®º**ï¼šæ­¤æ¬¡æ”¹åŠ¨é€šè¿‡ç»Ÿä¸€å®ç°ã€å¹³å°æ„ŸçŸ¥åŠ é€Ÿä»¥åŠæ›´ç®€æ´çš„é¢‘ç‡è®¡ç®—ï¼Œæ˜¾è‘—æå‡äº†æ¨¡å‹çš„æ‰§è¡Œæ•ˆç‡å¹¶é™ä½äº†ä»£ç ç»´æŠ¤æˆæœ¬ã€‚ä½†å› ä¸ºæ¶‰åŠæ ¸å¿ƒç®—å­æ¥å£çš„ç­¾åå˜æ›´å’Œå¼ é‡å½¢çŠ¶è°ƒæ•´ï¼ŒåŠ¡å¿…åœ¨å‘å¸ƒå‰å®Œæˆè·¨å¹³å°ã€è·¨æ¨¡å‹çš„å›å½’éªŒè¯ï¼Œå¹¶åœ¨æ–‡æ¡£ä¸­æ˜ç¡®è¿ç§»æ­¥éª¤ï¼Œä»¥é˜²æ­¢ç”¨æˆ·åœ¨å‡çº§åé­é‡éšè—çš„ç»´åº¦æˆ–ä¾èµ–é—®é¢˜ã€‚

---

#### ğŸŸ¡ ä¸­é‡è¦åº¦å˜æ›´ (2)

### [PCG] support piecewise cuda graph for kimi-linear model (#18849)
**SHA**: `bf52388` | ğŸ”— [æŸ¥çœ‹æäº¤](https://github.com/sgl-project/sglang/commit/bf523883545917d225cd5839d0ac8b0d715c5515)

**æ ¸å¿ƒå˜æ›´æ¦‚è§ˆ**  
1. **æ³¨æ„åŠ›åç«¯ç»Ÿä¸€æ¥å£**ï¼š`HybridLinearAttnBackend.forward_*` ç³»åˆ—çš„ `mixed_qkv` å‚æ•°ä» `Tuple[Tensor,â€¦] | Tensor` æ”¹ä¸ºåªèƒ½æ¥å— `torch.Tensor`ï¼Œå¹¶åœ¨å†…éƒ¨é€šè¿‡ `torch.split` æŠŠ `q/k/v` æŒ‰ `layer.q_dimã€k_dimã€v_dim` æ‹†åˆ†ã€‚  
2. **RadixLinearAttention** åŒæ­¥ç­¾åä¿®æ”¹ï¼Œæ‰€æœ‰è°ƒç”¨ç‚¹å‡æ”¹ä¸ºä¼ å…¥å•ä¸€ `Tensor`ã€‚  
3. **Kimiâ€‘Linear æ¨¡å‹**ï¼š  
   - å¼•å…¥ `QKVParallelLinear`ï¼ˆä½¿ç”¨ `get_attention_tp_rank/size`ï¼‰å–ä»£åŸæ¥çš„ç‹¬ç«‹ `ColumnParallelLinear` Q/K/Vï¼Œå®ç°ä¸€æ¬¡æ€§æŠ•å°„ã€‚  
   - èåˆè·¯å¾„çš„æŠ•å°„åç§°ä» `fused_qkvbfg_proj` æ”¹ä¸º `fused_qkvbfg_a_proj`ï¼Œå¹¶ç›¸åº”æ›´æ–°æƒé‡åŠ è½½æ˜ å°„ã€‚  
   - å¯¹éèåˆè·¯å¾„ï¼ˆ`do_fuse_qkvbfg=False`ï¼‰åŠ å…¥ `QKVParallelLinear`ï¼Œå¹¶åœ¨ `forward_qkvbfg`/`forward_qkvbfg_fused` ä¸­ç»Ÿä¸€è¿”å› `qkv`ã€‚  
   - `load_weights` ä¸­æ–°å¢å¯¹ `qkv_proj`ï¼ˆæœªèåˆæ—¶ï¼‰ä»¥åŠå¯¹ fused æŠ•å°„çš„æ¡ä»¶æ£€æŸ¥ï¼Œç¡®ä¿ä»…åœ¨ KDA å±‚ä¸”å¼€å¯èåˆæ—¶åŠ è½½ã€‚  
4. **æ–°å¢æµ‹è¯•** `test_kimi_linear_models_pcg.py`ï¼šåœ¨ä¸¤å¡ TP ç¯å¢ƒä¸‹å¯åŠ¨æœåŠ¡å™¨å¹¶å¼€å¯ `--enable-piecewise-cuda-graph`ï¼Œè·‘ GSM8K è¯„ä¼°éªŒè¯æ­£ç¡®æ€§ã€‚

**å½±å“èŒƒå›´**  
- **æ³¨æ„åŠ›å±‚**ï¼šæ‰€æœ‰ä½¿ç”¨ `HybridLinearAttnBackend`ï¼ˆåŒ…æ‹¬ `RadixLinearAttention`ï¼‰çš„æ¨¡å‹å¿…é¡»ä¼ å…¥åˆå¹¶åçš„ QKV Tensorï¼›æ—§çš„ tuple å‚æ•°å°†è§¦å‘æ–­è¨€æˆ–å½¢çŠ¶é”™è¯¯ã€‚  
- **æ¨¡å‹æƒé‡åŠ è½½**ï¼šæƒé‡æ˜ å°„è¡¨è¢«é‡æ–°ç»„ç»‡ï¼Œå¯èƒ½å½±å“è‡ªå®šä¹‰ checkpoint æˆ–é€šè¿‡ `torch.save`/`load_state_dict` æ¢å¤çš„æ¨¡å‹ã€‚  
- **å¹¶è¡Œè®¾ç½®**ï¼šæ–°å¢ `get_attention_tp_rank`ï¼Œåœ¨å¤šå¡ TP åœºæ™¯ä¸‹è‹¥ `--tp` ä¸æ¨¡å‹å†…éƒ¨çš„ TP å¤§å°ä¸ä¸€è‡´ï¼Œä¼šå¯¼è‡´æŠ•å°„ç»´åº¦é”™ä½ã€‚  
- **æ€§èƒ½/åŠŸèƒ½**ï¼šå¼€å¯ `--enable-piecewise-cuda-graph` æ—¶ï¼ŒKimiâ€‘Linear å°†ä½¿ç”¨åˆ†æ®µ CUDA Graphï¼Œå®ç°æ›´ä½çš„æ¨ç†å»¶è¿Ÿï¼›ä½†ä»…åœ¨ `do_fuse_qkvbfg=True`ï¼ˆé»˜è®¤ï¼‰ä¸”æ¨¡å‹æ ‡è®°ä¸º KDA å±‚æ—¶ç”Ÿæ•ˆã€‚

**å…³æ³¨å»ºè®®**  

*å¼€å‘è€…*  
- ç¡®è®¤æ‰€æœ‰è‡ªå®šä¹‰è°ƒç”¨ç‚¹ï¼ˆå°¤å…¶æ˜¯æ’ä»¶æˆ–å¤–éƒ¨è§£ç å™¨ï¼‰å·²æ”¹ä¸ºä¼ å…¥å•ä¸€ `Tensor`ï¼›å¦‚ä»ä½¿ç”¨ tupleï¼Œéœ€åœ¨è°ƒç”¨å‰æ‰‹åŠ¨ `torch.cat`ã€‚  
- æ£€æŸ¥æƒé‡åŠ è½½è·¯å¾„ï¼šè‹¥åœ¨é KDA å±‚ä½¿ç”¨ `QKVParallelLinear`ï¼Œåº”æ˜¾å¼å…³é—­èåˆ (`do_fuse_qkvbfg=False`) æˆ–è¡¥å……å¯¹åº”æ˜ å°„ã€‚  
- å¯¹ TP ç¯å¢ƒåšä¸€æ¬¡å®Œæ•´çš„ `torchrun --nproc_per_node=TP` æµ‹è¯•ï¼Œç¡®ä¿ `get_attention_tp_rank/size` ä¸ `--tp` å‚æ•°ä¿æŒä¸€è‡´ã€‚  
- è¿è¡Œæ–°å¢å•å…ƒæµ‹è¯•ï¼Œç¡®è®¤ CUDA Graph èƒ½åœ¨ä¸¤å¡ï¼ˆæˆ–æ›´å¤šï¼‰ç¯å¢ƒä¸‹æˆåŠŸåˆ›å»ºä¸”ç»“æœä¸ä¸ä½¿ç”¨ Graph çš„åŸºå‡†ç›¸ç¬¦ã€‚

*ç”¨æˆ·*  
- åœ¨ä½¿ç”¨ Kimiâ€‘Linear ç³»åˆ—æ¨¡å‹æ—¶ï¼Œè‹¥æƒ³åˆ©ç”¨åˆ†æ®µ CUDA Graphï¼Œè¯·åŠ ä¸Š `--enable-piecewise-cuda-graph` å¹¶ç¡®ä¿æ¨¡å‹çš„ `is_kda_layer` ä¸º Trueï¼ˆé»˜è®¤åœ¨ 48Bâ€‘A3Bâ€‘Instruct ä¸­ï¼‰ã€‚  
- å¯¹å·²æœ‰ checkpointï¼Œä½¿ç”¨ `sglang.load_weights` æ—¶ä¸éœ€è¦é¢å¤–æ”¹åŠ¨ï¼Œåªè¦æ¨¡å‹é…ç½®ä¸­ `do_fuse_qkvbfg` ä¸å®é™…æ¨¡å‹ä¿æŒä¸€è‡´å³å¯ã€‚  
- è‹¥åœ¨å•å¡æˆ–é TP ç¯å¢ƒè¿è¡Œï¼Œä»å¯æ­£å¸¸ä½¿ç”¨ï¼Œåªæ˜¯ `QKVParallelLinear` ä¼šé€€åŒ–ä¸ºæ™®é€šçº¿æ€§å±‚ï¼Œä¸ä¼šè§¦å‘ CUDA Graphã€‚  

æ€»ä½“è€Œè¨€ï¼Œæ­¤æ¬¡æ”¹åŠ¨ä¸º Kimiâ€‘Linear å¼•å…¥äº†æ›´é«˜æ•ˆçš„ QKV åˆå¹¶æŠ•å°„ä¸å¯é€‰çš„ Piecewise CUDA Graphï¼Œæå‡å¤§æ¨¡å‹æ¨ç†æ€§èƒ½ï¼›ä½†ä¹Ÿå¯¹æ¥å£å’Œæƒé‡æ˜ å°„æå‡ºäº†å…¼å®¹è¦æ±‚ï¼Œéœ€åœ¨å‡çº§å‰å®Œæˆç›¸åº”ä»£ç æ£€æŸ¥å’Œç¯å¢ƒéªŒè¯ã€‚

---

### [Diffusion] [NPU] Fix CI run (#18921)
**SHA**: `2aa0db7` | ğŸ”— [æŸ¥çœ‹æäº¤](https://github.com/sgl-project/sglang/commit/2aa0db7d9cfadc5f0a596328a641a6f09d5887e3)

**ğŸ¯ å˜æ›´ç±»å‹**ï¼šå…¶ä»–ï¼ˆCI ä¸ NPU å…¼å®¹æ€§ä¿®å¤ï¼‰  
**âš¡ é‡è¦ç¨‹åº¦**ï¼šğŸŸ¡ ä¸­  

**ğŸ“‹ å˜æ›´æ‘˜è¦**  
1. ä¿®æ­£ `.github/workflows/pr-test-npu.yml` ä¸­å¯¹ `steps.filter` è¾“å‡ºçš„å¸ƒå°”åˆ¤æ–­ï¼Œé˜²æ­¢ç©ºå­—ç¬¦ä¸²å¯¼è‡´æ¡ä»¶å§‹ç»ˆä¸ºçœŸã€‚  
2. åœ¨ `gpu_worker.py` å°†åŸå§‹çš„ `torch.cuda.*` æ¥å£æ¢æˆ `torch.get_device_module().*`ï¼Œä½¿å†…å­˜å³°å€¼ç»Ÿè®¡åœ¨ NPU ç¯å¢ƒä¸‹ä¹Ÿèƒ½å·¥ä½œã€‚  
3. æ›´æ–° NPU æ€§èƒ½åŸºçº¿ `perf_baselines_npu.json` ä¸­çš„ `denoise_step_ms` æ•°æ®ã€‚  
4. å°† NPU æµ‹è¯•ç”¨ä¾‹ `warmup` å‚æ•°ç”± `0` æ”¹ä¸º `True`ï¼ŒåŒ¹é… `DiffusionServerArgs` çš„æ–°å¸ƒå°”è¯­ä¹‰ã€‚  

**ğŸ¯ å½±å“èŒƒå›´**  
- CI æµç¨‹ï¼ˆprâ€‘testâ€‘npu å·¥ä½œæµï¼‰  
- å¤šæ¨¡æ€ç”Ÿæˆè¿è¡Œæ—¶ï¼ˆ`sglang/multimodal_gen/runtime/managers/gpu_worker.py`ï¼‰  
- NPU æ€§èƒ½åŸºå‡†ä¸å›å½’æµ‹è¯•ï¼ˆ`perf_baselines_npu.json`ã€`testcase_configs_npu.py`ï¼‰  

**ğŸ’¡ å…³æ³¨å»ºè®®**  
1. **CI æ¡ä»¶**ï¼šç¡®è®¤ `steps.filter.outputs.*` åœ¨æœªåŒ¹é…ä»»ä½•æ–‡ä»¶æ—¶è¿”å›çš„å€¼å§‹ç»ˆä¸º `'false'`ï¼ˆæˆ–ç©ºï¼‰ï¼Œæ–°å†™æ³•ä½¿ç”¨æ˜¾å¼æ¯”è¾ƒï¼Œå¯é¿å… `||` éšå¼è½¬ä¸ºéç©ºå­—ç¬¦ä¸²çš„è¯¯åˆ¤ã€‚å»ºè®®åœ¨å·¥ä½œæµæ–‡æ¡£ä¸­æ³¨æ˜æ­¤è§„åˆ™ã€‚  
2. **torch æ¥å£å…¼å®¹**ï¼š`torch.get_device_module()` åªåœ¨æ–°ç‰ˆ PyTorch ä¸­æä¾›ï¼Œè‹¥é¡¹ç›®ä»éœ€æ”¯æŒæ—§ç‰ˆæˆ–ä»… CUDA ç¯å¢ƒï¼Œæœ€å¥½åŠ å…¥å›é€€é€»è¾‘ï¼Œä¾‹å¦‚ `getattr(torch, "cuda", torch)`ï¼Œé˜²æ­¢ `AttributeError`ã€‚  
3. **æ€§èƒ½åŸºçº¿**ï¼šæ›´æ–°çš„ `denoise_step_ms` åªæ¶‰åŠå‰ 3 æ­¥çš„å€¼ï¼Œéœ€åœ¨ CI ä¸­åŒæ­¥æ›´æ–°å¯¹æ¯”é˜ˆå€¼ï¼Œå¦åˆ™å¯èƒ½å‡ºç°è¯¯æŠ¥ã€‚å»ºè®®åœ¨æäº¤è¯´æ˜ä¸­è®°å½•åŸºå‡†æ›´æ–°åŸå› ï¼ˆå¦‚ NPU é©±åŠ¨æ”¹è¿›ï¼‰ã€‚  
4. **warmup å‚æ•°**ï¼š`DiffusionServerArgs.warmup` ç°æ¥å—å¸ƒå°”å€¼ï¼Œç¡®è®¤æ‰€æœ‰è°ƒç”¨æ–¹å·²æ”¹ä¸ºå¸ƒå°”è€Œéæ•°å€¼ï¼Œé¿å…ç±»å‹ä¸åŒ¹é…å¯¼è‡´çš„è¿è¡Œæ—¶å¼‚å¸¸ã€‚  
5. **å›å½’æµ‹è¯•**ï¼šè¿è¡Œå®Œæ•´çš„ NPU æµ‹è¯•å¥—ä»¶ï¼Œç¡®ä¿æ–°åŸºå‡†ä¸ `warmup=True` é…ç½®ä¸‹çš„ååã€å»¶è¿Ÿç¬¦åˆé¢„æœŸï¼›åŒæ—¶æ£€æŸ¥ GPU ç¯å¢ƒä¸‹ä»èƒ½ä½¿ç”¨æ—§çš„ `torch.cuda.*` è·¯å¾„ã€‚  

æ€»ä½“æ¥çœ‹ï¼Œæ­¤æ¬¡æ”¹åŠ¨æå‡äº† NPU CI çš„å¯é æ€§å’Œè¿è¡Œæ—¶çš„è·¨è®¾å¤‡å…¼å®¹æ€§ï¼Œåªè¦åšå¥½å‘åå…¼å®¹ä¸åŸºå‡†åŒæ­¥ï¼Œå³å¯å®‰å…¨åˆå¹¶ã€‚

---

#### ğŸŸ¢ ä½é‡è¦åº¦å˜æ›´ (15)

### ROCm use rotary_embedding from sgl-kernel (#18920)
**SHA**: `8bb1037` | ğŸ”— [æŸ¥çœ‹æäº¤](https://github.com/sgl-project/sglang/commit/8bb103779624bb899dfe02d6ee9eab4b5ad8b4de)

**å˜æ›´ç±»å‹**ï¼šä»£ç é‡æ„  
**é‡è¦ç¨‹åº¦**ï¼šğŸŸ¢ä½  
**æ‘˜è¦**ï¼šåœ¨ `rotary_embedding.py` ä¸­ä¸º ROCmï¼ˆHIPï¼‰è®¾å¤‡æ–°å¢åˆ†æ”¯ï¼Œæ”¹ä¸ºåœ¨ `_is_hip` ä¸ºçœŸæ—¶ä» `sgl_kernel` å¯¼å…¥ `rotary_embedding`ï¼Œå¹¶å°†åŸå…ˆçš„ `_is_cuda or _is_hip` æ¡ä»¶æ‹†åˆ†ã€‚

---

### [Diffusion] Fix get model name when model local path end with "/" (#18918)
**SHA**: `5f81ec1` | ğŸ”— [æŸ¥çœ‹æäº¤](https://github.com/sgl-project/sglang/commit/5f81ec1ad5212be474c41b8140f0580891679227)

**ğŸ¯ å˜æ›´ç±»å‹**ï¼šä»£ç é‡æ„  
**âš¡ é‡è¦ç¨‹åº¦**ï¼šğŸŸ¢ä½  
**ğŸ“‹ æ‘˜è¦**ï¼šåœ¨ `get_model_short_name` ä¸­åŠ å…¥ `rstrip("/")`ï¼Œä¿®å¤æ¨¡å‹æœ¬åœ°è·¯å¾„ä»¥æ–œæ ç»“å°¾æ—¶è·å–ä¸åˆ°æ­£ç¡®çŸ­åçš„é—®é¢˜ã€‚

---

### [diffusion]: fix sparse video gen 2 backend being applied to cross-attention (#18900)
**SHA**: `f6cc024` | ğŸ”— [æŸ¥çœ‹æäº¤](https://github.com/sgl-project/sglang/commit/f6cc02489fb26af8eb6704170821359b6edb91c7)

**ğŸ¯ å˜æ›´ç±»å‹**ï¼šä»£ç é‡æ„  
**âš¡ é‡è¦ç¨‹åº¦**ï¼šğŸŸ¢ ä½  
**ğŸ“‹ æ‘˜è¦**ï¼šåœ¨ `wanvideo.py` ä¸­ç§»é™¤ç¨€ç–è§†é¢‘ Genâ€‘2 æ³¨æ„åŠ›åç«¯åœ¨äº¤å‰æ³¨æ„åŠ›ä¸­çš„ä½¿ç”¨ï¼Œå¹¶åœ¨ `interface.py` å°†å…¶æ ‡è®°ä¸ºç¨€ç–åç«¯ã€‚è¿™æ ·é˜²æ­¢ä¸å…¼å®¹çš„åç«¯è¢«é”™è¯¯åº”ç”¨ã€‚

---

### Revert "[AMD] Fix RotaryEmbedding crash on AMD/ROCm (regression from #17934)" (#18922)
**SHA**: `b158f5d` | ğŸ”— [æŸ¥çœ‹æäº¤](https://github.com/sgl-project/sglang/commit/b158f5d4a2b57512e5e75a5d7aa1a2c15a4c3e90)

**ğŸ¯ å˜æ›´ç±»å‹**ï¼šä»£ç é‡æ„  
**âš¡ é‡è¦ç¨‹åº¦**ï¼šğŸŸ¢ä½  
**ğŸ“‹ æ‘˜è¦**ï¼šåˆ é™¤äº† `forward_hip` æ–¹æ³•ï¼Œæ’¤å›å¯¹ AMD/ROCm çš„ç‰¹åŒ–å®ç°ï¼Œä»…ä¿ç•™åŸæœ‰ CUDA å®ç°ï¼Œæ¢å¤ä¹‹å‰å› è¯¥å®ç°å¯¼è‡´çš„å´©æºƒã€‚

---

### [Diffusion] [NPU] [Doc] Add NPU documentation for sglang-diffusion (#18894)
**SHA**: `14c95d2` | ğŸ”— [æŸ¥çœ‹æäº¤](https://github.com/sgl-project/sglang/commit/14c95d255c1d0f43fe96f592339cf00eb197e2ec)

**ğŸ¯ å˜æ›´ç±»å‹**ï¼šæ–‡æ¡£æ›´æ–°  
**âš¡ é‡è¦ç¨‹åº¦**ï¼šğŸŸ¢ä½  
**ğŸ“‹ æ‘˜è¦**ï¼šæ–°å¢å¯¹ Ascend NPU çš„æ”¯æŒè¯´æ˜ï¼Œæ›´æ–°å¤šå¹³å°åˆ—è¡¨å¹¶åœ¨å®‰è£…ã€æ³¨æ„åŠ›åç«¯æ–‡æ¡£ä¸­åŠ å…¥ NPU ç›¸å…³å†…å®¹ã€‚

---

### [TBO] fix cuda graph intermittently becomes disabled bug (#18320)
**SHA**: `899e2be` | ğŸ”— [æŸ¥çœ‹æäº¤](https://github.com/sgl-project/sglang/commit/899e2be7d06047aa95b16abf06e553148c1418f5)

**ğŸ¯ å˜æ›´ç±»å‹**ï¼šä»£ç é‡æ„  
**âš¡ é‡è¦ç¨‹åº¦**ï¼šğŸŸ¢ä½  
**ğŸ“‹ æ‘˜è¦**ï¼šåœ¨ `two_batch_overlap.py` ä¸­å®Œå–„å…¨å±€å‰å‘æ¨¡å¼è®¡ç®—ï¼Œè¿‡æ»¤æ‰ `IDLE` ä¸ `PREBUILT` ä¸¤ç±»ï¼Œé¿å…åœ¨è¿™äº›çŠ¶æ€ä¸‹è¯¯åˆ¤ä¸ºå…¨å±€å‰å‘æ¨¡å¼ï¼Œä»è€Œä¿®å¤ CUDA Graph é—´æ­‡å¤±æ•ˆçš„é—®é¢˜ã€‚

---

### [AMD] Fix RotaryEmbedding crash on AMD/ROCm (regression from #17934) (#18903)
**SHA**: `5e3103a` | ğŸ”— [æŸ¥çœ‹æäº¤](https://github.com/sgl-project/sglang/commit/5e3103a7872c645012ce316bc87da41a7cbaae52)

**ğŸ¯ å˜æ›´ç±»å‹**ï¼šä»£ç é‡æ„  
**âš¡ é‡è¦ç¨‹åº¦**ï¼šğŸŸ¢ä½  
**ğŸ“‹ æ‘˜è¦**ï¼šåœ¨ `rotary_embedding.py` ä¸­æ–°å¢ `forward_hip` æ–¹æ³•ï¼Œä½¿ç”¨çº¯ PyTorch å®ç°ç»•è¿‡ CUDA JITï¼Œè§£å†³ AMD/ROCm ç¯å¢ƒä¸‹çš„å´©æºƒé—®é¢˜ã€‚

---

### [Tiny] Fix assert syntax warning in compressed_tensors_w4a4_mxint4_moe.py (#18899)
**SHA**: `90a0d66` | ğŸ”— [æŸ¥çœ‹æäº¤](https://github.com/sgl-project/sglang/commit/90a0d66e1e46f67ceba1c1c5061180e6af1cc748)

**ğŸ¯ å˜æ›´ç±»å‹**ï¼šä»£ç é‡æ„  
**âš¡ é‡è¦ç¨‹åº¦**ï¼šğŸŸ¢ä½  
**ğŸ“‹ æ‘˜è¦**ï¼šä¿®æ”¹ `compressed_tensors_w4a4_mxint4_moe.py` ä¸­çš„ `assert` è¯­å¥å†™æ³•ï¼Œæ”¹ä¸ºç¬¦åˆ Python è¯­æ³•çš„å½¢å¼ï¼Œæ¶ˆé™¤è¯­æ³•è­¦å‘Šã€‚

---

### Skip flaky test_tool_choice_required_non_streaming for Mistral (#18889)
**SHA**: `7e41ac6` | ğŸ”— [æŸ¥çœ‹æäº¤](https://github.com/sgl-project/sglang/commit/7e41ac6c8db6496820f8c9f404db67f1973fd121)

**ğŸ¯ å˜æ›´ç±»å‹**ï¼šæµ‹è¯•ä¿®æ”¹  
**âš¡ é‡è¦ç¨‹åº¦**ï¼šğŸŸ¢ä½  
**ğŸ“‹ æ‘˜è¦**ï¼šåœ¨ `test_tool_choice.py` ä¸­ä¸º Mistral ç›¸å…³çš„ `test_tool_choice_required_non_streaming` æ·»åŠ  `unittest.skip`ï¼Œè·³è¿‡å› ç©ºç™½å­—ç¬¦é—®é¢˜å¯¼è‡´çš„ flaky æµ‹è¯•ã€‚

---

### [misc] adding metadata field in UpdateWeightFromDiskReqInput (#18821)
**SHA**: `d5307ce` | ğŸ”— [æŸ¥çœ‹æäº¤](https://github.com/sgl-project/sglang/commit/d5307ce022d0af0790b06af48a77465db0458d6f)

**ğŸ¯ å˜æ›´ç±»å‹**ï¼šä»£ç é‡æ„  
**âš¡ é‡è¦ç¨‹åº¦**ï¼šğŸŸ¢ä½  
**ğŸ“‹ æ‘˜è¦**ï¼šåœ¨ `UpdateWeightFromDiskReqInput` ä¸­æ–°å¢å¯é€‰å­—æ®µ `manifest`ï¼ˆå­—å…¸ç±»å‹ï¼‰ï¼Œç”¨äºæºå¸¦å¼ é‡å…ƒæ•°æ®ã€‚

---

### Adapt the Qwen2Model._update_causal_mask for transformers==4.57.1 (#18774)
**SHA**: `b21390f` | ğŸ”— [æŸ¥çœ‹æäº¤](https://github.com/sgl-project/sglang/commit/b21390f8f396f734a0d516009fa2c87f2b5e645b)

**ğŸ¯ å˜æ›´ç±»å‹**ï¼šä»£ç é‡æ„  
**âš¡ é‡è¦ç¨‹åº¦**ï¼šğŸŸ¢ä½  
**ğŸ“‹ æ‘˜è¦**ï¼šå°† Qwen2Model._update_causal_mask é€‚é… transformers==4.57.1ï¼Œæ”¹ä¸ºé€šè¿‡å› æœæ©ç æ˜ å°„ä¼ é€’ï¼Œæ›´æ–° deepseek_ocr ä¸­çš„ forward è°ƒç”¨ã€‚

---

### [diffusion]: fix scheduler crash on ZMQ messages with unexpected frame counts (#17890)
**SHA**: `50ca24a` | ğŸ”— [æŸ¥çœ‹æäº¤](https://github.com/sgl-project/sglang/commit/50ca24aebb7d2dfcd63f2759d43819845ed597c6)

**ğŸ¯ å˜æ›´ç±»å‹**ï¼šä»£ç é‡æ„  
**âš¡ é‡è¦ç¨‹åº¦**ï¼šğŸŸ¢ä½  
**ğŸ“‹ æ‘˜è¦**ï¼šåœ¨ `scheduler.py` ä¸­æ”¹è¿› ZMQ æ¶ˆæ¯æ¥æ”¶é€»è¾‘ï¼Œæ•è·å¼‚å¸¸å¹¶å¯¹éæ ‡å‡†å¸§æˆ–ååºåˆ—åŒ–é”™è¯¯åšå®¹é”™å¤„ç†ï¼Œé˜²æ­¢å› æ„å¤–å¸§æ•°å¯¼è‡´çš„å´©æºƒã€‚

---

### Fix CI: add flashinfer --download-cubin to install dependencies (#18887)
**SHA**: `f9c3def` | ğŸ”— [æŸ¥çœ‹æäº¤](https://github.com/sgl-project/sglang/commit/f9c3def7fe464a19d8321474a4e149a3a8d3dcc4)

**ğŸ¯ å˜æ›´ç±»å‹**ï¼šé…ç½®è°ƒæ•´  
**âš¡ é‡è¦ç¨‹åº¦**ï¼šğŸŸ¢ä½  
**ğŸ“‹ æ‘˜è¦**ï¼šæ–°å¢è„šæœ¬ `ci_download_flashinfer_cubin.sh`ï¼Œåœ¨ CI å®‰è£…ä¾èµ–åæ£€æŸ¥å¹¶è¡¥å…¨ flashinfer çš„ cubin æ–‡ä»¶ï¼›åœ¨ `ci_install_dependency.sh` ä¸­è°ƒç”¨è¯¥è„šæœ¬ï¼Œç¡®ä¿ CI ç¯å¢ƒå®Œæ•´ã€‚

---

### Fix GLM-5 fused shared expert (#18804)
**SHA**: `1b659bc` | ğŸ”— [æŸ¥çœ‹æäº¤](https://github.com/sgl-project/sglang/commit/1b659bcb088fd303ee472c0720eeb1a3797cffa1)

**ğŸ¯ å˜æ›´ç±»å‹**ï¼šä»£ç é‡æ„  
**âš¡ é‡è¦ç¨‹åº¦**ï¼šğŸŸ¢ ä½  
**ğŸ“‹ æ‘˜è¦**ï¼šåœ¨ `GlmMoeDsaForCausalLM` ç±»ä¸­å®ç° `determine_num_fused_shared_experts` æ–¹æ³•ï¼Œè°ƒç”¨çˆ¶ç±»é€»è¾‘å¹¶ä¼ å…¥ç±»åï¼Œä»¥ä¿®å¤ GLMâ€‘5 èåˆå…±äº«ä¸“å®¶è®¡æ•°çš„é—®é¢˜ã€‚

---

### Fix modelopt FP8 create weights (#18447)
**SHA**: `0ff2415` | ğŸ”— [æŸ¥çœ‹æäº¤](https://github.com/sgl-project/sglang/commit/0ff24159a5bcd0872a65135b0b1eeb3350273949)

**å˜æ›´ç±»å‹**ï¼šä»£ç é‡æ„  
**é‡è¦ç¨‹åº¦**ï¼šğŸŸ¢ä½  
**æ‘˜è¦**ï¼šåœ¨ `modelopt_quant.create_weights` æ–°å¢ `input_size`ã€`output_size` å‚æ•°ï¼›`NemotronHForCausalLM` å¼•å…¥ `quant_config`ï¼Œæ‰©å±• `remap_substr` æ˜ å°„å¹¶ä¿®æ­£ KV ç¼©æ”¾åçš„åŠ è½½é€»è¾‘ï¼Œè§£å†³ FP8 æƒé‡åˆ›å»ºé—®é¢˜ã€‚

---

