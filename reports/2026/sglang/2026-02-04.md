# æ¯æ—¥æ›´æ–°æŠ¥å‘Šï¼ˆ2026-02-04ï¼‰

## sgl-project/sglang

| æäº¤æ—¶é—´ | ä½œè€… | æäº¤ä¿¡æ¯ |
|----------|------|----------|
| 2026-02-04 22:18:36 | RunningLeon | entrypoint: support passing spaces_between_special_tokens per request (#17939) |
| 2026-02-04 21:25:23 | wxy | [diffusion] fix: fix the bug of redundant memory usage on GPU-0 (#18221) |
| 2026-02-04 21:23:41 | Zhang Yiyang (SII) | [diffusion] chore: clean MOVA codes (#18107) |
| 2026-02-04 19:59:41 | BingjiaWang | optimize get_topk_ragged by fusing get k and k_scale triton kernel (#16043) |
| 2026-02-04 19:58:28 | Nicolas Castet | Make sure we always disable symm memory without dp padding (#18129) |
| 2026-02-04 19:58:04 | Jincong Chen | Tiny fix for fp8 moe backend flashinfer_trtllm naming (#18243) |
| 2026-02-04 19:19:02 | Evrard-Nil | [diffusion] logging: downgrade default prompt log from info to debug (#17813) |
| 2026-02-04 19:12:32 | Xiaoyu Zhang | [diffusion] update code owner (#18247) |
| 2026-02-04 18:09:55 | Cheng Wan | Moving _alloc_extend_naive out of npu allocator (#18200) |
| 2026-02-04 17:10:46 | zhangheng | [RadixTree][5/N Refactor]: Introduce pre and post-processing methods for key matching (#18147) |
| 2026-02-04 14:12:13 | Baizhou Zhang | [DeepGemm] Add a flag for fast warmup (#18111) |
| 2026-02-04 13:46:20 | Jianying | [diffusion] kernel: gated residual layernorm scale shift and layernorm scale shift kernel fusion for Qwen-Image, WAN and HunyuanVideo (#14717) |
| 2026-02-04 12:53:17 | Kun Lin | Support Markdown/Notebook-Friendly Documentation Export for Downstream Integration (copy all markdown and rst files) (#18223) |
| 2026-02-04 12:43:38 | Douglas Yang | fix: bumping nightly whl version (#18212) |
| 2026-02-04 11:41:26 | strgrb | fuse qkvbfg linear into one gemm and f_b g_b into batched gemm. (#17801) |
| 2026-02-04 10:33:27 | Aurick Qiao | Fix Session for multimodal and expose it through Engine (#18152) |
| 2026-02-04 09:37:28 | Qi Jia | [Docs] fix readme typo (#18207) |
| 2026-02-04 09:03:37 | wxy | [diffusion] fix: fix server cache-dit bug under continuous dynamic requests (#17140) |
| 2026-02-04 07:54:41 | Douglas Yang | fix: ensuring nightly whls are tagged with latest commit (#18204) |
| 2026-02-04 05:55:11 | satyamk7054 | Update weight rename check for Qwen3 Embeddings (#17535) |
| 2026-02-04 04:46:01 | Hudson Xing | add streaming parallel tool call test case (#18097) |
| 2026-02-04 04:44:57 | R0CKSTAR | [diffusion] hardware: support diffusion models on MTGPU (doc, 6/N) (#17346) |
| 2026-02-04 04:44:22 | R0CKSTAR | [diffusion] hardware: support diffusion models on MTGPU (multi-GPU, 5/N) (#17318) |
| 2026-02-04 04:42:58 | R0CKSTAR | [Diffusion] Only import sgl_kernel in custom op cuda path (SiluAndMul and RMSNorm) (#15592) |
| 2026-02-04 03:45:35 | Vladislav Nosivskoy | [HiCache] feat: Add detailed cache hit breakdown for HiCache in `sglext` and Prometheus metrics (#17648) |
| 2026-02-04 03:39:38 | Even Zhou | [CI][NPU] Bugfix import sgl-kernel error (#18173) |
| 2026-02-04 03:15:14 | DiweiSun | enable ut test for xpu devices (#11712) |
| 2026-02-04 03:09:38 | ishandhanani | ci: improve docker for cu13 builds (#18194) |
| 2026-02-04 02:56:44 | Kangyan-Zhou | Revert broken sgl_kernel exclusion patterns in paths-filter (#18193) |
| 2026-02-04 02:42:05 | ishandhanani | fix: add cu13 dev container to our release (#18192) |

### ğŸ“Š ç»Ÿè®¡æ‘˜è¦
> æœ¬æ—¥å…± 30 ä¸ªæäº¤ | ğŸ”´é«˜ 2 | ğŸŸ¡ä¸­ 14 | ğŸŸ¢ä½ 14
## ğŸ“‹ ç›®å½•

- [sgl-project/sglang](#sgl-project-sglang)
  - [ğŸ“Š ç»Ÿè®¡æ‘˜è¦](#-ç»Ÿè®¡æ‘˜è¦)
  - [ğŸ”´ é«˜é‡è¦åº¦å˜æ›´ (2)](#-ğŸ”´-é«˜é‡è¦åº¦å˜æ›´-2)
    - [[diffusion] kernel: gated residual layernorm scale shift ...](#4739f2e)
    - [fix: add cu13 dev container to our release (#18192)](#820df54)
  - [ğŸŸ¡ ä¸­é‡è¦åº¦å˜æ›´ (14)](#-ğŸŸ¡-ä¸­é‡è¦åº¦å˜æ›´-14)
    - [[diffusion] chore: clean MOVA codes (#18107)](#0c9a0ad)
    - [optimize get_topk_ragged by fusing get k and k_scale trit...](#760ae93)
    - [Make sure we always disable symm memory without dp paddin...](#315306d)
    - [Moving _alloc_extend_naive out of npu allocator (#18200)](#84c0991)
    - [[RadixTree][5/N Refactor]: Introduce pre and post-process...](#be557cb)
    - [[DeepGemm] Add a flag for fast warmup (#18111)](#d279520)
    - [fix: bumping nightly whl version (#18212)](#b7c1dfc)
    - [fuse qkvbfg linear into one gemm and f_b g_b into batched...](#37c33cc)
    - [Fix Session for multimodal and expose it through Engine (...](#c1d529c)
    - [[diffusion] fix: fix server cache-dit bug under continuou...](#da758ed)
    - [fix: ensuring nightly whls are tagged with latest commit ...](#ae004e1)
    - [[diffusion] hardware: support diffusion models on MTGPU (...](#ec2461b)
    - [[HiCache] feat: Add detailed cache hit breakdown for HiCa...](#e166ca8)
    - [enable ut test for xpu devices (#11712)](#495290a)
  - [ğŸŸ¢ ä½é‡è¦åº¦å˜æ›´ (14)](#-ğŸŸ¢-ä½é‡è¦åº¦å˜æ›´-14)
    - [entrypoint: support passing spaces_between_special_tokens...](#a6f53cc)
    - [[diffusion] fix: fix the bug of redundant memory usage on...](#4c40304)
    - [Tiny fix for fp8 moe backend flashinfer_trtllm naming (#1...](#a72f4f8)
    - [[diffusion] logging: downgrade default prompt log from in...](#ce02df8)
    - [[diffusion] update code owner (#18247)](#2e9d044)
    - [Support Markdown/Notebook-Friendly Documentation Export f...](#669a9bd)
    - [[Docs] fix readme typo (#18207)](#1f72f66)
    - [Update weight rename check for Qwen3 Embeddings (#17535)](#793bf9f)
    - [add streaming parallel tool call test case (#18097)](#e867040)
    - [[diffusion] hardware: support diffusion models on MTGPU (...](#7de650c)
    - [[Diffusion] Only import sgl_kernel in custom op cuda path...](#acf724b)
    - [[CI][NPU] Bugfix import sgl-kernel error (#18173)](#d48bbe3)
    - [ci: improve docker for cu13 builds (#18194)](#0a69256)
    - [Revert broken sgl_kernel exclusion patterns in paths-filt...](#0db6fd4)
#### ğŸ”´ é«˜é‡è¦åº¦å˜æ›´ (2)

### [diffusion] kernel: gated residual layernorm scale shift and layernorm scale shift kernel fusion for Qwen-Image, WAN and HunyuanVideo (#14717)
**SHA**: `4739f2e` | ğŸ”— [æŸ¥çœ‹æäº¤](https://github.com/sgl-project/sglang/commit/4739f2e8d5732f7464d1af75d31b4d44c61783b6)

**ğŸ¯ å˜æ›´ç±»å‹**ï¼šåŠŸèƒ½å¢å¼º / æ€§èƒ½ä¼˜åŒ– / é‡æ„  

**âš¡ é‡è¦ç¨‹åº¦**ï¼šğŸ”´é«˜  

**ğŸ“‹ å˜æ›´æ‘˜è¦**  
æœ¬æ¬¡æäº¤ä¸º SGLang æ·»åŠ ä¸€ç³»åˆ—åŸºäº CuTeDSL / CUTLASS çš„ **normâ€‘scaleâ€‘shift** ä¸ **scaleâ€‘residualâ€‘normâ€‘scaleâ€‘shift** èåˆç®—å­ï¼Œå¹¶åœ¨ `layernorm.py`ã€è‹¥å¹²æ¨¡å‹å®ç°ä»¥åŠå¯¹åº”çš„ benchmark ä¸å•å…ƒæµ‹è¯•ä¸­å®Œæˆè¿ç§»ã€‚æ ¸å¿ƒæ€è·¯æ˜¯æŠŠ â€œLayerNorm/RMSNorm â†’ (1+scale) â†’ shiftâ€ ä»¥åŠ â€œresidual + gate * x â†’ norm â†’ (1+scale) â†’ shiftâ€ ä¸‰æ­¥åˆå¹¶ä¸ºå•ä¸ª CUDA kernelï¼Œå®ç° **å‘é‡åŒ– 128â€‘bit è¯»å–ã€CTA/warp å½’çº¦**ï¼Œæ˜¾è‘—é™ä½å†…å­˜å¸¦å®½å‹åŠ›å’Œ kernel launch å¼€é”€ã€‚

---

### ğŸ¯ å½±å“èŒƒå›´
| å—å½±å“æ¨¡å— | å…·ä½“ä½ç½® |
|-----------|----------|
| å½’ä¸€åŒ–å±‚å®ç° | `python/sglang/multimodal_gen/runtime/layers/layernorm.py`ï¼ˆæ–°å¢ `LayerNormScaleShift`ã€`ScaleResidualLayerNormScaleShift`ã€`ScaleResidualRMSNormScaleShift`ï¼‰ |
| Diffusionâ€¯JITâ€¯Kernel | `sglang/jit_kernel/diffusion/cutedsl/*`ï¼ˆå®ç°æ ¸èåˆã€å…¬å…±å·¥å…·ã€reduceã€broadcastï¼‰ |
| Model ä»£ç  | `wanvideo.pyã€qwen_image.pyã€hunyuanvideo.pyã€dit...` ç­‰å¤šå¤„æ”¹ä¸ºä½¿ç”¨æ–° fused å±‚ | 
| åŸºå‡†æµ‹è¯• | `benchmark/bench_fused_norm_scale_shift.py` |
| å•å…ƒæµ‹è¯• | `tests/test_fused_norm_scale_shift.py`ï¼ˆè¦†ç›–å¤šç§å¼ é‡å½¢çŠ¶ã€dtypeã€ç´¢å¼•æ¨¡å¼ï¼‰ |
| å…¬å…±å·¥å…· | `jit_kernel/diffusion/cutedsl/utils.py`ï¼ˆdtypeã€warp size å¸¸é‡ï¼‰ |

---

### ğŸ” æŠ€æœ¯æ´å¯Ÿ

| ç»´åº¦ | å½±å“è¯¦æƒ… |
|------|----------|
| **æ¶æ„å½±å“** | - å°†åŸæœ¬åˆ†æ•£åœ¨ Python / PyTorch å®ç°çš„ **LayerNorm/RMSNorm + ScaleShift** ä¸ **Residualâ€‘Gateâ€‘Normâ€‘ScaleShift** åˆå¹¶ä¸º **å•ä¸ª CuTeDSL kernel**ã€‚<br>- é€šè¿‡ `ScaleResidualNormScaleShift` æŠŠ **æ®‹å·® + gating**ã€**å½’ä¸€åŒ–**ã€**scaleâ€‘shift** ä¸‰é˜¶æ®µåœ¨åŒä¸€ CTA ä¸­å®Œæˆï¼Œé¿å…å¤šæ¬¡å…¨å±€å†…å­˜è®¿é—®ã€‚<br>- ä¸ºäº†ä¿æŒçµæ´»æ€§ï¼Œä¿ç•™äº† **fallbackï¼ˆnativeï¼‰å®ç°**ï¼Œåœ¨ä¸æ»¡è¶³ `D%256==0 && D<=8192` æˆ–åœ¨ ROCm ç¯å¢ƒä¸‹ä¼šè‡ªåŠ¨å›é€€ã€‚ |
| **æ€§èƒ½å½±å“** | - **å‘é‡åŒ–åŠ è½½**ï¼šä½¿ç”¨ `LDG.128`ï¼ˆ8â€¯Ã—â€¯float16/bfloat16ï¼‰ä¸€æ¬¡è¯»å– 8 å…ƒç´ ï¼Œé™ä½è®¿å­˜æ¬¡æ•°ã€‚<br>- **CTA/warp å½’çº¦**ï¼š`warp_reduce_sum` + `cta_reduce_sum` å®ç°é«˜æ•ˆçš„å‡å€¼/æ–¹å·®èšåˆï¼Œé¿å…åŒæ­¥å…¨ç½‘æ ¼ã€‚<br>- **ç¼–è¯‘ç¼“å­˜**ï¼š`_COMPILE_CACHE` é€šè¿‡ **hash key**ï¼ˆå½¢çŠ¶ã€dtypeã€norm ç±»å‹ï¼‰å¤ç”¨å·²ç¼–è¯‘ kernelï¼Œæ˜¾è‘—é™ä½é¦–æ¬¡è°ƒç”¨çš„ JIT ç¼–è¯‘æ—¶é—´ã€‚<br>- **åŸºå‡†**ï¼šæ–°å¢ `bench_fused_norm_scale_shift.py` å¯¹æ¯”åŸç”Ÿå®ç°ï¼Œé¢„è®¡åœ¨ 3072/4096 ç»´åº¦ä¸‹æå‡ **30%â€“60%**ï¼ˆå®é™…æ•°æ®è¯· CI æŠ¥å‘Šï¼‰ã€‚ |
| **å®‰å…¨/ç¨³å¥æ€§** | - ä»£ç ä¸å¼•å…¥å¤–éƒ¨ä¾èµ–ï¼Œä»…ä½¿ç”¨å†…éƒ¨çš„ CUTLASS / CuTeDSLï¼Œæ”»å‡»é¢ä¿æŒä¸å˜ã€‚<br>- ä»ç„¶æœ‰ **å‚æ•°æ ¡éªŒ**ï¼ˆ`validate_x`ã€`validate_scale_shift` ç­‰ï¼‰ï¼Œä½†å¯¹ **D å¿…é¡»æ˜¯ 256 çš„å€æ•°ä¸” â‰¤â€¯8192** åšäº†æ˜¾å¼æ£€æŸ¥ï¼Œè‹¥ä¸æ»¡è¶³å°†æŠ›å¼‚å¸¸ï¼Œé˜²æ­¢éšå¼æ•°å€¼é”™è¯¯ã€‚<br>- ä½¿ç”¨ `torch._dynamo.disable` é¿å… Dynamo æŠŠ kernel å½“ä½œæ™®é€š Python å‡½æ•°æ•è·ã€‚ |
| **å¯ç»´æŠ¤æ€§** | - å°†åŸæ¥æ•£è½åœ¨å¤šä¸ªæ–‡ä»¶çš„ `fuse_scale_shift_kernel`ã€`fuse_scale_shift_gate_select01_kernel` é‡æ„ä¸ºç»Ÿä¸€çš„ `fused_*` APIï¼Œè°ƒç”¨æ–¹æ›´ç®€æ´ã€‚<br>- å¼•å…¥ `CustomOp` åŸºç±»ï¼ˆè™½ç„¶ç›®å‰æœªå®Œæ•´å®ç°ï¼‰ï¼Œä¸ºä»¥ååœ¨ä¸åŒåç«¯ï¼ˆCUDA / ROCm / CPUï¼‰æä¾›ç»Ÿä¸€æ¥å£å¥ å®šåŸºç¡€ã€‚<br>- æµ‹è¯•è¦†ç›– **7 ç§ dtypeã€5 ç§ normã€9 ç§ç´¢å¼•æ¨¡å¼**ï¼Œæå¤§æå‡å›å½’å®‰å…¨æ€§ã€‚ |
| **å…¼å®¹æ€§** | - **CUDA**ï¼šä»…åœ¨ `D%256==0 && D<=8192` æ—¶å¯ç”¨ï¼Œå…¶ä»–åœºæ™¯è‡ªåŠ¨å›é€€åˆ°åŸç”Ÿå®ç°ï¼Œä¿è¯ç°æœ‰æ¨¡å‹ä¸å—å½±å“ã€‚<br>- **ROCm**ï¼š`forward_hip` ç›´æ¥è°ƒç”¨ native fallbackï¼Œä¿æŒè·¨å¹³å°å…¼å®¹ã€‚<br>- **æ¨¡å‹ä»£ç **ï¼šå¤šæ•°æ¨¡å‹ï¼ˆWanVideoã€Qwenâ€‘Imageã€HunyuanVideo ç­‰ï¼‰å·²æ”¹ä¸ºä½¿ç”¨æ–°çš„ fused ç±»ï¼›è‹¥ç”¨æˆ·è‡ªè¡Œå®ä¾‹åŒ–æ—§çš„ `LayerNorm`/`RMSNorm`ï¼Œä¸å—å½±å“ã€‚ |

---

### âš ï¸ æ½œåœ¨é£é™©

1. **ç¼–è¯‘ç¼“å­˜é”®å†²çª**  
   - `make_hash_key` åªè€ƒè™‘ `dtypeã€ndimã€hidden_dim` ä»¥åŠéƒ¨åˆ†è¾“å…¥å¼ é‡çš„ **shape[-1]**ã€‚å¦‚æœç”¨æˆ·åœ¨åŒä¸€è¿›ç¨‹ä¸­å¤šæ¬¡ä½¿ç”¨ç›¸åŒ `D` ä½†ä¸åŒ `B`ã€`S`ï¼Œä¼šå¤ç”¨åŒä¸€ä¸ªå·²ç¼–è¯‘ kernelï¼Œè¿™æœ¬æ˜¯æœŸæœ›çš„è¡Œä¸ºï¼Œä½†è‹¥åç»­ kernel å®ç°å¯¹ `B/S` æœ‰æ˜¾å¼ä¾èµ–ï¼ˆå¦‚åœ¨ kernel ä¸­ç¡¬ç¼–ç äº† `S` ç”¨äºå¸§åˆ’åˆ†ï¼‰ï¼Œå¯èƒ½å¯¼è‡´é”™è¯¯ã€‚  
2. **ç»´åº¦çº¦æŸ**  
   - å½“æ¨¡å‹çš„ hidden size ä¸æ˜¯ 256 çš„æ•´æ•°å€ï¼ˆå¦‚ 1024/2048 æ­£å¸¸ï¼Œä½† 384ã€512 ç­‰ï¼‰ï¼Œä¼šå¼ºåˆ¶å›é€€åˆ° native å®ç°ï¼Œå¯¼è‡´ **æ€§èƒ½çªå˜**ã€‚å¦‚æœåç»­æœ‰äººåœ¨è‡ªå®šä¹‰æ¨¡å‹ä¸­ä½¿ç”¨è¯¥ fused å±‚ä½†å¿˜è®°æ£€æŸ¥ç»´åº¦ï¼Œå¯èƒ½å‡ºç°æ„å¤–çš„æ€§èƒ½å›é€€ã€‚  
3. **CUDA / CUTLASS ç‰ˆæœ¬ä¾èµ–**  
   - CuTeDSL éœ€è¦ä¸€å®šçš„ `cutlass` ç‰ˆæœ¬ï¼ˆ>=3.0ï¼‰ä»¥åŠå¯¹åº”çš„ **NVCC/CUDA** ç¼–è¯‘å™¨æ”¯æŒ `--enable-tvm-ffi`ã€‚åœ¨ CI ç¯å¢ƒæˆ–ç”¨æˆ·æœºå™¨ä¸Šè‹¥ CUDA ç‰ˆæœ¬è¿‡ä½æˆ–ç¼ºå°‘ TVMâ€¯FFIï¼Œkernel ç¼–è¯‘ä¼šå¤±è´¥å¹¶æŠ›å¼‚å¸¸ã€‚  
4. **å¼‚å¸¸å›é€€è·¯å¾„**  
   - fallback ä½¿ç”¨ `self.forward_native`ï¼Œä½†åœ¨æŸäº›è·¯å¾„ï¼ˆå¦‚ `gate` ä¸º int æ—¶ï¼‰ä»ä¼šæ‰§è¡Œ `gate = 1 if gate is None else gate`ï¼Œè‹¥ `gate` ä¸º `torch.Tensor` ä½† shape ä¸å…¼å®¹ï¼Œå¯èƒ½è§¦å‘ **å¹¿æ’­é”™è¯¯**ï¼Œè€Œä¸æ˜¯æ˜ç¡®çš„å°ºå¯¸æ£€æŸ¥ã€‚  
5. **ROCm æ”¯æŒç¼ºå¤±**  
   - ä»…å®ç°äº† `forward_hip` çš„ç®€å• fallbackï¼Œè‹¥ç”¨æˆ·åœ¨ ROCm ä¸ŠæœŸå¾…åŒç­‰æ€§èƒ½ï¼Œå°†ä¼šè¢«è¿«ä½¿ç”¨æ…¢é€Ÿ PyTorch å®ç°ã€‚  
6. **æµ‹è¯•ç›²åŒº**  
   - å•å…ƒæµ‹è¯•è¦†ç›–äº†å¤§é‡å¼ é‡å½¢çŠ¶ï¼Œä½† **æç«¯å¸§æ•°**ï¼ˆå¦‚ `F=1` æ—¶çš„é™¤æ³• `S // F` ä¸ºé›¶ï¼‰ä»¥åŠ **å¤§ batch**ï¼ˆB>8ï¼‰æœªæ˜¾å¼æµ‹è¯•ï¼Œå¯èƒ½åœ¨ `tensor_slice_for_bsfd` ä¸­äº§ç”Ÿæ•´æ•°é™¤æ³•é”™è¯¯ã€‚  

---

### ğŸ’¡ å…³æ³¨å»ºè®®

| å»ºè®® | å…·ä½“æªæ–½ |
|------|----------|
| **å®Œå–„æ–‡æ¡£** | - åœ¨ `README` / API æ–‡æ¡£ä¸­æ˜ç¡®æ ‡æ³¨ **hiddenâ€‘size å¿…é¡»ä¸º 256 çš„æ•´æ•°å€ä¸” â‰¤â€¯8192**ï¼Œä»¥åŠ **fallback è¡Œä¸º**ã€‚<br>- ç»™å‡º **æ€§èƒ½å¯¹æ¯”è¡¨**ï¼ˆä¸åŒ Dã€Bã€Sï¼‰å¸®åŠ©ç”¨æˆ·å†³å®šæ˜¯å¦ä½¿ç”¨ fused ç‰ˆæœ¬ã€‚ |
| **å¼ºåŒ–è¾“å…¥æ ¡éªŒ** | - åœ¨ `fused_norm_scale_shift` / `fused_scale_residual_norm_scale_shift` ä¸­åŠ å…¥å¯¹ **Bã€Sã€F** çš„åˆæ³•æ€§æ£€æŸ¥ï¼ˆå¦‚ `S % F == 0`ï¼‰ï¼Œåœ¨ä¸æ»¡è¶³æ—¶æå‰æŠ›å‡ºå¼‚å¸¸ã€‚ |
| **ç¼“å­˜é”®ç»†åŒ–** | - å°† `B`ã€`

---

### fix: add cu13 dev container to our release (#18192)
**SHA**: `820df54` | ğŸ”— [æŸ¥çœ‹æäº¤](https://github.com/sgl-project/sglang/commit/820df545f2c48ea92911e2078389cc1a447bde3f)

**ğŸ¯ å˜æ›´ç±»å‹**ï¼šBugä¿®å¤ / åŠŸèƒ½å¢å¼ºï¼ˆä¸º CUDAâ€¯13 æ·»åŠ ä¸“ç”¨å‘å¸ƒå·¥ä½œæµï¼‰  
**âš¡ é‡è¦ç¨‹åº¦**ï¼šğŸ”´é«˜  
**ğŸ“‹ å˜æ›´æ‘˜è¦**ï¼š  
- æ–°å¢ `.github/workflows/release-docker-cu13-framework.yml`ï¼Œä¸“é—¨ç”¨äºåœ¨ CI ä¸­æ„å»ºå¹¶æ¨é€åŸºäº CUDAâ€¯13 çš„ **framework** é•œåƒï¼ˆamd64â€¯+â€¯arm64ï¼‰ä»¥åŠç”Ÿæˆå¤šæ¶æ„ manifestã€‚  
- åœ¨ä¸»å‘å¸ƒå·¥ä½œæµ `release-docker.yml` ä¸­åŒæ­¥åŠ å…¥ CUDAâ€¯13 çš„ framework ä¸ runtime é•œåƒæ„å»ºæ­¥éª¤ã€å¯¹åº”çš„ manifest åˆ›å»ºé€»è¾‘ï¼Œå¹¶å¯¹è¾“å…¥æè¿°åšäº†è½»å¾®çš„å­—ç¬¦ä¸²ç»Ÿä¸€ã€‚  
- è¿™äº›æ”¹åŠ¨ä½¿å¾—é¡¹ç›®å¯ä»¥åœ¨åŒä¸€ CI ä¸­åŒæ—¶ç»´æŠ¤ CUDAâ€¯12ã€CUDAâ€¯13 ä»¥åŠæœªæ¥ç‰ˆæœ¬çš„é•œåƒå‘å¸ƒæµç¨‹ã€‚

**ğŸ¯ å½±å“èŒƒå›´**ï¼š  
- GitHub Actions CI/CD æµç¨‹ï¼ˆDocker æ„å»ºã€ç™»å½•ã€é•œåƒæ¨é€ï¼‰  
- `docker/Dockerfile` çš„æ„å»ºå‚æ•°ï¼ˆ`CUDA_VERSION=13.0.1`ã€`GRACE_BLACKWELL` å¼€å…³ç­‰ï¼‰  
- Docker Hub ä¸Šçš„é•œåƒæ ‡ç­¾ä½“ç³»ï¼ˆ`-cu130-amd64/arm64`ã€`vX.Y.Z-cu130`ã€`latest-cu130`ï¼‰  
- é¡¹ç›®æ–‡æ¡£/ä½¿ç”¨æŒ‡å—ï¼ˆéœ€è¦åŒæ­¥è¯´æ˜ CUDAâ€¯13 é•œåƒçš„å¯ç”¨æ€§ï¼‰  

**ğŸ” æŠ€æœ¯æ´å¯Ÿ**  

- **æ¶æ„å½±å“**ï¼š  
  - åœ¨ CI å±‚é¢å¼•å…¥äº† **åŒå¹³å°ï¼ˆamd64 & arm64ï¼‰+ åŒ CUDA ç‰ˆæœ¬** çš„å¤šç»´åº¦æ„å»ºçŸ©é˜µï¼Œæå‡äº†å‘å¸ƒæ¶æ„çš„å¯æ‰©å±•æ€§ã€‚  
  - é€šè¿‡ `docker buildx imagetools create` ç”Ÿæˆçš„å¤šæ¶æ„ manifestï¼Œä½¿ç”¨æˆ·åœ¨ `docker pull lmsysorg/sglang:latest-cu130` æ—¶å¯é€æ˜è·å–å¯¹åº”å¹³å°é•œåƒï¼Œä¿æŒäº†ç°æœ‰ `latest`ã€`vX.Y.Z` æ ‡ç­¾çš„ä¸€è‡´æ€§ã€‚  

- **æ€§èƒ½å½±å“**ï¼š  
  - æ–°å¢çš„å·¥ä½œæµä½¿ç”¨ `--no-cache`ï¼Œä¼šå¯¼è‡´æ¯æ¬¡æ„å»ºéƒ½é‡æ–°æ‹‰å–åŸºç¡€é•œåƒå’Œé‡æ–°ç¼–è¯‘ä¾èµ–ï¼Œæ˜¾è‘—å¢åŠ  CI è€—æ—¶ä¸èµ„æºæ¶ˆè€—ï¼ˆå°¤å…¶åœ¨ arm64 èŠ‚ç‚¹ï¼‰ã€‚  
  - å¯¹è¿è¡Œæ—¶æ€§èƒ½æ²¡æœ‰ç›´æ¥å½±å“ï¼Œå› ä¸ºåªæ˜¯æ„å»ºé˜¶æ®µçš„æ”¹åŠ¨ï¼›ä½†ç”Ÿæˆçš„ CUDAâ€¯13 é•œåƒä½“ç§¯ä¼šæ¯” CUDAâ€¯12 ç•¥å¤§ï¼Œä¸‹è½½æˆæœ¬ç•¥å‡ã€‚  

- **å®‰å…¨è€ƒè™‘**ï¼š  
  - ä»ç„¶é€šè¿‡ GitHub Secrets (`DOCKERHUB_USERNAME`, `DOCKERHUB_TOKEN`) å®Œæˆ Docker Hub ç™»å½•ï¼Œæœªæ³„éœ²å‡­è¯ã€‚  
  - æ–°å¢çš„ workflow åªåœ¨å®˜æ–¹ä»“åº“ (`sgl-project/sglang`) æ¡ä»¶ä¸‹æ‰§è¡Œï¼Œé¿å…å¤–éƒ¨ fork è¢«è¯¯ç”¨ã€‚  
  - `free-disk-space` æ­¥éª¤åˆ é™¤äº†å¤§é‡æœ¬åœ°ç¼“å­˜ï¼Œé™ä½äº†ç£ç›˜æ³„æ¼é£é™©ã€‚  

**âš ï¸ æ½œåœ¨é£é™©**ï¼š  
1. **CI è´¹ç”¨æ¿€å¢**ï¼š`--no-cache` + åŒå¹³å°å¹¶è¡Œæ„å»ºä¼šæ˜¾è‘—æå‡ GitHub Actions çš„è¿è¡Œæ—¶é—´ï¼Œå¯¼è‡´æœˆåº¦ CI è´¹ç”¨ä¸Šå‡ã€‚  
2. **æ ‡ç­¾å†²çª**ï¼šè‹¥æ‰‹åŠ¨è¾“å…¥çš„ `version` ä¸å·²æœ‰çš„ `vX.Y.Z` tag ä¸åŒ¹é…ï¼Œå¯èƒ½äº§ç”Ÿæœªè¢«æ¨é€çš„é•œåƒæˆ–é‡å¤çš„ manifestã€‚  
3. **æ„å»ºä¸ç¡®å®šæ€§**ï¼šCUDAâ€¯13 ç¯å¢ƒåœ¨ arm64 èŠ‚ç‚¹ä¸Šä¾èµ–çš„åº•å±‚åº“ï¼ˆå¦‚ `libcudart`ï¼‰å¯èƒ½å°šæœªåœ¨å®˜æ–¹é•œåƒä¸­å®Œå…¨å…¼å®¹ï¼Œå¯¼è‡´æ„å»ºå¤±è´¥ã€‚  
4. **é•œåƒä½“ç§¯å¢é•¿**ï¼šåŒ…å« CUDAâ€¯13 + FlashInfer JIT Cache çš„ framework é•œåƒä½“ç§¯å¯èƒ½è¶…è¿‡ 10â€¯GBï¼Œæ‹‰å–é€Ÿåº¦å’Œå­˜å‚¨æˆæœ¬æå‡ã€‚  

**ğŸ’¡ å…³æ³¨å»ºè®®**ï¼š  
- **CI è´¹ç”¨ç›‘æ§**ï¼šåœ¨å·¥ä½œæµä¸­åŠ å…¥ `actions/cache`ï¼ˆé’ˆå¯¹ä¾èµ–å±‚ï¼‰æˆ–åœ¨éæœ¬æ¬¡å‘å¸ƒçš„åˆ†æ”¯ä¸Šå…³é—­ `--no-cache`ï¼ŒèŠ‚çº¦æ„å»ºæ—¶é—´ã€‚  
- **ç‰ˆæœ¬æ ¡éªŒ**ï¼šåœ¨ `Validate version` æ­¥éª¤ååŠ å…¥é¢å¤–æ£€æŸ¥ï¼Œç¡®ä¿è¾“å…¥çš„ç‰ˆæœ¬å·å·²å¯¹åº”ä»“åº“çš„ Git tagï¼Œé¿å…è¯¯æ¨ã€‚  
- **é•œåƒä½“ç§¯ä¼˜åŒ–**ï¼šè€ƒè™‘åœ¨ `Dockerfile` ä¸­ä½¿ç”¨ `--build-arg INSTALL_FLASHINFER_JIT_CACHE=0` ä½œä¸ºå¯é€‰ç‰¹æ€§ï¼Œè®©ç”¨æˆ·è‡ªè¡Œå†³å®šæ˜¯å¦éœ€è¦è¯¥åŠŸèƒ½ï¼Œä»¥æ§åˆ¶é•œåƒå¤§å°ã€‚  
- **æ–‡æ¡£åŒæ­¥**ï¼šåœ¨é¡¹ç›® README / Docker usage æ–‡æ¡£ä¸­æ ‡æ˜ `-cu130` ç³»åˆ—é•œåƒçš„ CUDA ç‰ˆæœ¬ã€å…¼å®¹çš„ç¡¬ä»¶è¦æ±‚åŠä½¿ç”¨æ–¹å¼ã€‚  
- **å›æ»šé¢„æ¡ˆ**ï¼šè‹¥ CUDAâ€¯13 é•œåƒå‡ºç°æ„å»ºå¤±è´¥æˆ–å…¼å®¹æ€§é—®é¢˜ï¼Œå¯ä¸´æ—¶åœ¨ CI ä¸­æ³¨é‡Šæ‰å¯¹åº”æ­¥éª¤ï¼Œå…ˆä¿è¯ CUDAâ€¯12 å‘å¸ƒæµç¨‹ä¸å—å½±å“ã€‚  

--- 

*ä»¥ä¸Šåˆ†æä¾§é‡äºå¯¹é¡¹ç›®å‘å¸ƒä½“ç³»çš„ç»“æ„æ€§å½±å“ï¼Œå®é™…è¿è¡Œæ—¶çš„ä¸šåŠ¡é€»è¾‘ä»£ç æœªå—æ”¹åŠ¨ã€‚*

---

#### ğŸŸ¡ ä¸­é‡è¦åº¦å˜æ›´ (14)

### [diffusion] chore: clean MOVA codes (#18107)
**SHA**: `0c9a0ad` | ğŸ”— [æŸ¥çœ‹æäº¤](https://github.com/sgl-project/sglang/commit/0c9a0adc5329d393435097337fa113174363299e)

**ğŸ¯ å˜æ›´ç±»å‹**ï¼šä»£ç æ¸…ç† / åŠŸèƒ½å‰Šå‡  
**âš¡ é‡è¦ç¨‹åº¦**ï¼šğŸŸ¡ ä¸­  

**ğŸ“‹ å˜æ›´æ‘˜è¦**  
1. åœ¨ `mova_audio_dit.py`ã€`mova_video_dit.py` ä¸­åˆ é™¤äº† *controlâ€‘adapter* ç›¸å…³å®ç°ï¼Œä»¥åŠæ¢¯åº¦æ£€æŸ¥ç‚¹ï¼ˆgradientâ€‘checkpointingï¼‰çš„åŒ…è£…é€»è¾‘ï¼ŒForward ç›´æ¥è°ƒç”¨å—ã€‚  
2. `flow_match_pair.py` å»é™¤äº† `diffusers` çš„ `SchedulerMixin/ConfigMixin` ä¾èµ–ï¼Œæ”¹ä¸ºçº¯å†…éƒ¨ `BaseScheduler` å®ç°ï¼›å¯¹é…å¯¹åå¤„ç†å‡½æ•°çš„æ¥å£ã€é”™è¯¯ä¿¡æ¯ã€æ–‡æ¡£åšäº†å…¨é¢è‹±æ–‡åŒ–å’Œå¼‚å¸¸ç»†åŒ–ã€‚

**ğŸ¯ å½±å“èŒƒå›´**  
- `sglang/multimodal_gen/runtime/models/dits/`ï¼ˆMOVA éŸ³é¢‘/è§†é¢‘ DITï¼‰  
- `sglang/multimodal_gen/runtime/models/schedulers/flow_match_pair.py`  
- ä»»ä½•åœ¨é…ç½®ä¸­å¯ç”¨ `add_control_adapter`ã€ä½¿ç”¨ `use_gradient_checkpointing`ã€æˆ–ä¾èµ– `SchedulerMixin` çš„ä¸Šå±‚ä»£ç ã€‚

**ğŸ’¡ å…³æ³¨å»ºè®®**  
1. **é…ç½®åŒæ­¥**ï¼š`MOVAAudioConfig` / `MOVAVideoConfig` ä¸­çš„ `add_control_adapter` ä¸ `in_dim_control_adapter` å·²ä¸å†ç”Ÿæ•ˆï¼Œéœ€åœ¨æ¨¡å‹åˆå§‹åŒ–å‰æ¸…é™¤æˆ–è¿ç§»ç›¸å…³å­—æ®µã€‚  
2. **è°ƒç”¨æ–¹é€‚é…**ï¼š`forward` å‚æ•°åˆ—è¡¨å·²åˆ å» `encoder_hidden_states_image`ã€`guidance`ã€`use_gradient_checkpointing*`ï¼Œè¯·æ£€æŸ¥æ‰€æœ‰æ¨¡å‹è°ƒç”¨å¤„ï¼Œåˆ é™¤å¤šä½™å®å‚æˆ–æ”¹ä¸ºæ–°ç­¾åã€‚  
3. **å†…å­˜ä¸æ€§èƒ½**ï¼šå»é™¤ checkpoint å¯èƒ½å¯¼è‡´æ˜¾å­˜æ¿€å¢ï¼Œå»ºè®®åœ¨èµ„æºå—é™çš„æœºå™¨ä¸Šè¿›è¡Œè¯„ä¼°å¹¶é…Œæƒ…æ‰‹åŠ¨åŠ å…¥ `torch.utils.checkpoint`ã€‚  
4. **è°ƒåº¦å™¨å…¼å®¹**ï¼š`FlowMatchPairScheduler` ç°åœ¨ä¸å†ç»§æ‰¿ `diffusers` åŸºç±»ï¼Œè‹¥é¡¹ç›®å…¶ä»–æ¨¡å—ä»ä½¿ç”¨ `SchedulerMixin` çš„å±æ€§ï¼ˆå¦‚ `config`ï¼‰ï¼Œéœ€æ”¹ä¸ºç›´æ¥ä½¿ç”¨è¯¥ç±»æä¾›çš„æ¥å£ã€‚  
5. **å•å…ƒæµ‹è¯•**ï¼šé‡ç‚¹è·‘å« controlâ€‘adapterã€gradientâ€‘checkpointingã€ä»¥åŠ scheduler åå¤„ç†åç§°ï¼ˆå¦‚ `quadratic_perp_bulge_swap`ï¼‰çš„æµ‹è¯•ï¼Œç¡®ä¿åŠŸèƒ½æœªå› åˆ é™¤ä»£ç è€Œå¤±æ•ˆã€‚  

é€šè¿‡ä¸Šè¿°æ£€æŸ¥å¹¶æ›´æ–°é…ç½®/è°ƒç”¨ï¼Œèƒ½å¤Ÿå¹³ç¨³è¿ç§»åˆ°æœ¬æ¬¡â€œæ¸…ç†â€åçš„å®ç°ã€‚

---

### optimize get_topk_ragged by fusing get k and k_scale triton kernel (#16043)
**SHA**: `760ae93` | ğŸ”— [æŸ¥çœ‹æäº¤](https://github.com/sgl-project/sglang/commit/760ae933bb3878a6897e7e552a746929c29e9d90)

**ğŸ”§ å˜æ›´æ¦‚å†µ**  
- å°†åŸå…ˆçš„åˆ†ä¸¤æ­¥ï¼ˆå…ˆå– K å†å– Scaleï¼‰çš„ Triton å®ç°åˆå¹¶ä¸º **ä¸€æ¬¡æ€§ fused kernel**ï¼Œé€šè¿‡ `GetKAndS.triton` åŒæ—¶è¿”å› `k_fp8` ä¸ `k_scale`ã€‚  
- æ–°å¢/ä¿®æ”¹æ¥å£ï¼š`NSATokenToKVPool.get_index_k_scale_buffer`ã€`_get_k_and_s_triton`ã€`_get_k_and_s_triton_kernel`ï¼ŒåŠ å…¥ `seq_len_tensor/seq_len_sum/max_seq_len` å‚æ•°ï¼Œä»¥æ”¯æŒæ‰¹é‡ï¼ˆraggedï¼‰åºåˆ—ã€‚  
- `nsa_indexer._get_topk_ragged` è°ƒæ•´ä¸ºä¸€æ¬¡æ€§è·å– Kã€Scaleï¼Œå»æ‰åŸå…ˆçš„å¾ªç¯æ‹¼æ¥ã€‚  
- ç›¸åº”çš„å•å…ƒæµ‹è¯•å’Œæ‰‹å·¥æ€§èƒ½æµ‹è¯•ä¹ŸåŒæ­¥æ”¹å†™ï¼ŒéªŒè¯åŠŸèƒ½ä¸åŠ é€Ÿæ•ˆæœã€‚  

**ğŸ“¦ å½±å“èŒƒå›´**  
- `python/sglang/srt/layers/attention/nsa/*`ï¼ˆå°¤å…¶æ˜¯ `index_buf_accessor.py`ã€`nsa_indexer.py`ï¼‰  
- `python/sglang/srt/mem_cache/memory_pool.py`ï¼ˆæ¥å£ç­¾åå˜åŒ–ï¼‰  
- ä¾èµ– `get_index_k_scale_buffer` çš„æ‰€æœ‰ä¸Šå±‚è°ƒç”¨ï¼ˆå¦‚å…¶ä»–æ³¨æ„åŠ›å®ç°ï¼‰éœ€è¦åŒæ­¥æ›´æ–°å‚æ•°ã€‚  

**âš ï¸ å…³é”®é£é™©**  
1. **å‘åå…¼å®¹æ€§**ï¼šæ–°ç­¾åå¼ºåˆ¶ä¼ å…¥ `seq_len_tensorã€seq_len_sumã€max_seq_len`ï¼Œè‹¥è¿˜æœ‰æ—§ä»£ç æœªåŒæ­¥ï¼Œä¼šå¯¼è‡´è¿è¡Œæ—¶ `TypeError`ã€‚å»ºè®®æä¾›é»˜è®¤å€¼æˆ–é‡è½½åŒ…è£…å‡½æ•°ï¼Œä»¥å…ç ´åå·²æœ‰åˆ†æ”¯ã€‚  
2. **æ‰¹é‡ç»´åº¦å®ç°**ï¼škernel ä½¿ç”¨ `grid = (batch, max_seq_len)`ï¼Œå¹¶åœ¨å†…éƒ¨é€šè¿‡ `seq_len_num_pow` è®¡ç®—å‰ç¼€å’Œã€‚è‹¥ `batch` é 2â€‘å¹‚ï¼Œ`seq_len_num_pow` ä»ä¼šå‘ä¸Šå–æœ€è¿‘ 2 çš„å¹‚ï¼Œå¯èƒ½å¯¼è‡´é¢å¤–çš„ç©ºçº¿ç¨‹å¹¶è®¿é—®è¶Šç•Œã€‚å½“å‰å·²åŠ  `if token_id >= seq_len: return`ï¼Œä½†ä»éœ€ç¡®è®¤ `prev_seq_lens` è¯»å–çš„æ©ç æ­£ç¡®ï¼Œå¦åˆ™ä¼šäº§ç”Ÿæœªå®šä¹‰çš„ç´¯è®¡åç§»ã€‚  
3. **HIP æ”¯æŒ**ï¼šåŸä»£ç åœ¨ HIP ç¯å¢ƒèµ° `_is_hip` åˆ†æ”¯ï¼Œæ–°çš„ fused kernel åªå®ç°äº† CUDA ç‰ˆæœ¬ã€‚éœ€è¦ç¡®ä¿ HIP ç¯å¢ƒä»èƒ½å›é€€åˆ°åŸæœ‰çš„ä¸¤æ­¥å®ç°ï¼Œæˆ–æä¾›å¯¹åº”çš„ HIP kernelã€‚  
4. **å†…å­˜å¸ƒå±€**ï¼š`k_out`ã€`s_out` æŒ‰ `seq_len_sum` é¢„åˆ†é…ï¼Œè‹¥ `seq_len_sum` è®¡ç®—é”™è¯¯ä¼šå¯¼è‡´å†™è¶Šç•Œæˆ–ç©ºæ´ã€‚å»ºè®®åœ¨è°ƒç”¨å‰åŠ å…¥æ–­è¨€ `seq_len_sum == seq_len_tensor.sum()`ã€‚  

**ğŸ’¡ æ”¹è¿›å»ºè®®**  
- åœ¨ `memory_pool.get_index_k_scale_buffer` æ·»åŠ  **å…¼å®¹å±‚**ï¼ˆå¦‚æ¥å— `int seq_len` å¹¶å†…éƒ¨åŒ…è£…ä¸º tensorï¼‰ï¼Œä¿æŒæ—§ API å¯ç”¨ã€‚  
- ä¸º `seq_len_num_pow` åŠ ä¸Š *assert*ï¼Œç¡®è®¤ `seq_len_num_pow >= batch`ï¼Œå¹¶åœ¨æ–‡æ¡£ä¸­è¯´æ˜è¯¥å‚æ•°çš„æ„ä¹‰ã€‚  
- ä¸º HIP ç¯å¢ƒå®ç°ä¸€ä¸ª `fallback_get_k_and_s_triton`ï¼Œæˆ–åœ¨ `index_buf_accessor.triton` ä¸­æ£€æµ‹ `torch.cuda.is_available()` å¹¶è‡ªåŠ¨åˆ‡æ¢ã€‚  
- å¢åŠ  **æ€§èƒ½åŸºå‡†**ï¼ˆå¦‚å¯¹æ¯” 2â€‘step vs fused åœ¨ä¸åŒ batch/seq_len åœºæ™¯ä¸‹çš„ååï¼‰ï¼Œæ”¾å…¥ CIã€‚  
- æ›´æ–° README/æ³¨é‡Šï¼Œè¯´æ˜æ–° kernel çš„è°ƒç”¨æ–¹å¼ã€è¾“å…¥å¼ é‡çš„ shape ä¸ dtype è¦æ±‚ï¼ˆ`int64`ã€`uint8`ï¼‰ï¼Œå¹¶æä¾›ç¤ºä¾‹ä»£ç ã€‚  

**ç»“è®º**  
æ­¤æ”¹åŠ¨é€šè¿‡ä¸€æ¬¡æ€§ Triton kernel æ˜¾è‘—é™ä½äº†æ˜¾å­˜è®¿é—®æ¬¡æ•°ä¸ kernel å¯åŠ¨å¼€é”€ï¼Œç†è®ºä¸Šå¯æå‡ 15%â€‘30% çš„æ¨ç†é€Ÿåº¦ã€‚ä½†éœ€æ³¨æ„å…¼å®¹æ€§ã€batch è¾¹ç•Œä»¥åŠ HIP å›é€€çš„å®Œæ•´æ€§ã€‚å®Œæˆä¸Šè¿°æ£€æŸ¥å¹¶åŠ å…¥å…¼å®¹åŒ…è£…åï¼Œå»ºè®®åˆå¹¶ã€‚

---

### Make sure we always disable symm memory without dp padding (#18129)
**SHA**: `315306d` | ğŸ”— [æŸ¥çœ‹æäº¤](https://github.com/sgl-project/sglang/commit/315306d8a9f93ed24e3a6d532b3c1da41e83ca9d)

**ğŸ¯ å˜æ›´ç±»å‹**ï¼šåŠŸèƒ½å¢å¼ºï¼ˆå¯¹å¯¹ç§°å†…å­˜ä½¿ç”¨é€»è¾‘çš„ç»†åŒ–ï¼‰  
**âš¡ é‡è¦ç¨‹åº¦**ï¼šğŸŸ¡ ä¸­  

**ğŸ“‹ å˜æ›´æ‘˜è¦**  
åœ¨åˆ†å¸ƒå¼å¹¶è¡ŒçŠ¶æ€ (`parallel_state.py`) ä¸­æ–°å¢ `is_allocation_symmetric` æ ‡è¯†ï¼Œå¹¶åœ¨ `all_gather`ã€DPâ€‘Attention ç¼“å†²åŒºåˆ›å»º (`dp_attention.py`) ä¸è¯è¡¨å¹¶è¡ŒåµŒå…¥ (`vocab_parallel_embedding.py`) çš„å¯¹ç§°å†…å­˜ä¸Šä¸‹æ–‡ä¸­åŠ å…¥ `disabled=not â€¦` åˆ¤æ–­ï¼Œç¡®ä¿åœ¨å¯ç”¨ DPâ€‘padding æ—¶æ‰å¼€å¯å¯¹ç§°å†…å­˜ï¼Œä»è€Œé¿å…åœ¨ä¸éœ€è¦æ—¶ä»å¼ºåˆ¶ä½¿ç”¨å¯¹ç§°åˆ†é…å¯¼è‡´çš„é¢å¤–é€šä¿¡æˆ–å†…å­˜å¼€é”€ã€‚

**ğŸ¯ å½±å“èŒƒå›´**  
- `sglang.srt.distributed.parallel_state` â€“ å¯¹ `use_symmetric_memory` çš„åŒ…è£…æ–¹å¼æ›´æ”¹ã€‚  
- `sglang.srt.layers.dp_attention` â€“ DP ç¼“å†²åŒºçš„åˆ›å»ºå— `cls._dp_max_padding` æ§åˆ¶ã€‚  
- `sglang.srt.layers.vocab_parallel_embedding` â€“ åµŒå…¥å±‚çš„å¯¹ç§°å†…å­˜å¼€å¯ä¾æ® `is_allocation_symmetric()`ã€‚  

**ğŸ’¡ å…³æ³¨å»ºè®®**  
1. **åŠŸèƒ½éªŒè¯**ï¼šåœ¨ä¸åŒæ¨¡å‹å¹¶è¡Œè§„æ¨¡ï¼ˆTP/DPï¼‰ä»¥åŠæœ‰/æ—  DPâ€‘padding åœºæ™¯ä¸‹è·‘ä¸€æ¬¡å®Œæ•´æ¨ç†/è®­ç»ƒï¼Œç¡®è®¤ `all_gather` è¾“å‡ºä¸€è‡´ä¸”æ— é¢å¤–åŒæ­¥é”™è¯¯ã€‚  
2. **æ€§èƒ½å›å½’**ï¼šæµ‹é‡å¯ç”¨/ç¦ç”¨å¯¹ç§°å†…å­˜å‰åçš„æ˜¾å­˜å ç”¨å’Œé€šä¿¡æ—¶é—´ï¼Œç¡®ä¿åœ¨ç¦ç”¨å¯¹ç§°å†…å­˜æ—¶æ˜¾å­˜å›æ”¶ä¸”ååæå‡ã€‚  
3. **å…¼å®¹æ€§æ£€æŸ¥**ï¼š`is_allocation_symmetric` ä»ä¾èµ– `dp_attention.is_allocation_symmetric`ï¼Œç¡®ä¿è¯¥å‡½æ•°åœ¨æ‰€æœ‰çƒ­æ›´æ–°è·¯å¾„å‡å·²å®ç°ä¸”è¿”å›å¸ƒå°”å€¼ã€‚  
4. **æ–‡æ¡£/é…ç½®**ï¼šè‹¥é¡¹ç›®æä¾›å¯¹ç§°å†…å­˜å¼€å…³çš„ç”¨æˆ·å¯é…ç½®é¡¹ï¼Œéœ€åœ¨æ–‡æ¡£ä¸­æ³¨æ˜å…¶å— DPâ€‘padding æ§åˆ¶ï¼Œé˜²æ­¢è¯¯è§£ã€‚  

æ€»ä½“è€Œè¨€ï¼Œæ­¤æ”¹åŠ¨é€šè¿‡ç»†ç²’åº¦æ§åˆ¶å¯¹ç§°å†…å­˜ä½¿ç”¨ï¼Œé™ä½ä¸å¿…è¦çš„å†…å­˜å¤åˆ¶ï¼Œæå‡å¤§è§„æ¨¡å¹¶è¡Œè®­ç»ƒçš„èµ„æºåˆ©ç”¨ç‡ã€‚å»ºè®®åœ¨ CI ä¸­åŠ å…¥é’ˆå¯¹ `is_allocation_symmetric` ä¸º `False` çš„å¿«é€Ÿå•å…ƒæµ‹è¯•ï¼Œä»¥é˜²åç»­æ”¹åŠ¨æ„å¤–æ¢å¤æ—§è¡Œä¸ºã€‚

---

### Moving _alloc_extend_naive out of npu allocator (#18200)
**SHA**: `84c0991` | ğŸ”— [æŸ¥çœ‹æäº¤](https://github.com/sgl-project/sglang/commit/84c09913eb1458278f62f9dc393007141d3b67c3)

**ğŸ¯ å˜æ›´ç±»å‹**ï¼šé‡æ„ / åŠŸèƒ½å¢å¼º  
**âš¡ é‡è¦ç¨‹åº¦**ï¼šğŸŸ¡ ä¸­  

**ğŸ“‹ å˜æ›´æ‘˜è¦**  
1. å°†åŸæœ¬ä»…åœ¨ `allocator_npu.py` æ–‡ä»¶ä¸­å®ç°çš„å†…éƒ¨å‡½æ•° `_alloc_extend_naive` æå–åˆ°å…¬å…±æ¨¡å— `allocator.py`ï¼Œå¹¶æ”¹åä¸º `alloc_extend_naive`ã€‚  
2. `NPUPagedTokenToKVPoolAllocator` ç°åœ¨ç›´æ¥è°ƒç”¨è¯¥å…¬å…±å®ç°ï¼Œä»£ç è¡Œæ•°å¤§å¹…å‹ç¼©ã€‚  
3. åœ¨æ–°å®ç°ä¸­åŠ å…¥äº†ä¸¤å¤„æå‰ `continue` åˆ¤å®šï¼Œé¿å…åœ¨åºåˆ—å·²å®Œæ•´åˆ†é…åç»§ç»­è®¡ç®— `num2`/`num3`ï¼Œæå‡äº†é€»è¾‘æ¸…æ™°åº¦ã€‚

**ğŸ¯ å½±å“èŒƒå›´**  
- `python/sglang/srt/hardware_backend/npu/allocator_npu.py`ï¼ˆNPU KVâ€‘Cache åˆ†é…é€»è¾‘ï¼‰  
- `python/sglang/srt/mem_cache/allocator.py`ï¼ˆé€šç”¨å†…å­˜åˆ†é…å®ç°ï¼‰  
- å¯èƒ½è¢«å…¶ä»–ç¡¬ä»¶åç«¯ï¼ˆå¦‚ GPUï¼‰æˆ–æµ‹è¯•ç”¨ä¾‹é—´æ¥å¼•ç”¨çš„ `alloc_extend_naive`ã€‚

**ğŸ’¡ å…³æ³¨å»ºè®®**  
1. **è¡Œä¸ºç­‰ä»·æ€§**ï¼šæ–°å‡½æ•°åœ¨ `num1`ã€`num2`ã€`num3` è®¡ç®—ååŠ å…¥çš„ `continue` è¯­å¥æ”¹å˜äº†åŸå…ˆçš„æ‰§è¡Œæµï¼ŒåŠ¡å¿…ç¡®è®¤åœ¨æ‰€æœ‰è¾¹ç•Œæ¡ä»¶ï¼ˆå¦‚ `seq_len == prefix_len`ã€æ°å¥½è·¨é¡µã€å…¨é¡µå¡«æ»¡ç­‰ï¼‰ä¸‹ä»äº§ç”Ÿç›¸åŒçš„ `out_indices`ã€‚å»ºè®®è¡¥å……å•å…ƒæµ‹è¯•ï¼Œè¦†ç›– `0ã€1ã€page_sizeâ€‘1ã€page_sizeã€page_size+1` ç­‰å…¸å‹é•¿åº¦ç»„åˆã€‚  
2. **å…¼å®¹æ€§**ï¼šåŸç§æœ‰å‡½æ•°å `_alloc_extend_naive` å·²è¢«åˆ é™¤ï¼Œè‹¥å¤–éƒ¨ä»£ç ï¼ˆæˆ–æ—§çš„å®éªŒè„šæœ¬ï¼‰ä»é€šè¿‡ `from â€¦allocator_npu import _alloc_extend_naive` è®¿é—®ï¼Œå°†å¯¼è‡´ ImportErrorã€‚æ¨èåœ¨ `allocator_npu.py` ä¸­ä¿ç•™ä¸€ä¸ªè–„å°è£…åˆ«åï¼ˆ`_alloc_extend_naive = alloc_extend_naive`ï¼‰æˆ–åœ¨å‘å¸ƒè¯´æ˜ä¸­æ³¨æ˜å·²åºŸå¼ƒã€‚  
3. **æ€§èƒ½è¯„ä¼°**ï¼šè™½ç„¶å‡½æ•°ä»åœ¨ Python å¾ªç¯å†…éå† batchï¼Œæ€§èƒ½ä¸åŸå®ç°å¤§è‡´ç›¸åŒï¼›ä½† `continue` å¯èƒ½ç•¥å¾®æå‡å°‘é‡åˆ†æ”¯å¯†é›†åœºæ™¯çš„æ•ˆç‡ã€‚å»ºè®®åœ¨ CI ä¸­åŠ å…¥åŸºå‡†æµ‹è¯•ï¼Œç¡®è®¤åœ¨å¤§æ‰¹é‡æ¨ç†æ—¶æ— å›é€€ã€‚  
4. **ä»£ç å¯è¯»æ€§**ï¼šå°†å®ç°é›†ä¸­åˆ° `allocator.py` åï¼ŒNPU åç«¯æ–‡ä»¶ä»…ä¿ç•™è°ƒåº¦é€»è¾‘ï¼Œæ˜“äºç»´æŠ¤ã€‚åç»­è‹¥æœ‰å…¶ä»–ç¡¬ä»¶åç«¯éœ€è¦ç›¸åŒæ‰©å±•ç­–ç•¥ï¼Œå¯ç›´æ¥å¤ç”¨ `alloc_extend_naive`ï¼Œé™ä½ä»£ç é‡å¤ã€‚  

æ€»ä½“æ¥çœ‹ï¼Œæ­¤æ¬¡é‡æ„æå‡äº†æ¨¡å—åŒ–ä¸å¯ç»´æŠ¤æ€§ï¼Œä½†åŠ¡å¿…é€šè¿‡å®Œæ•´çš„å•å…ƒ/é›†æˆæµ‹è¯•éªŒè¯åŠŸèƒ½ç­‰ä»·ï¼Œå¹¶åšå¥½å‘åå…¼å®¹çš„è¿‡æ¸¡æç¤ºã€‚

---

### [RadixTree][5/N Refactor]: Introduce pre and post-processing methods for key matching (#18147)
**SHA**: `be557cb` | ğŸ”— [æŸ¥çœ‹æäº¤](https://github.com/sgl-project/sglang/commit/be557cbc5f8d7aad5fffa5e771b9a00b6ea092a6)

**ğŸ¯ å˜æ›´ç±»å‹**ï¼šé‡æ„ï¼ˆå¼•å…¥å‰ç½®/åç½®å¤„ç†æŠ½è±¡ï¼‰  
**âš¡ é‡è¦ç¨‹åº¦**ï¼šğŸŸ¡ ä¸­  
**ğŸ“‹ å˜æ›´æ‘˜è¦**ï¼šåœ¨ `mamba_radix_cache.py` ä¸ `swa_radix_cache.py` ä¸­ï¼Œå°† `match_prefix` çš„é”®å‰ç½®æ£€æŸ¥ã€é¡µå¯¹é½ã€Mamba çŠ¶æ€æ‹·è´ä»¥åŠç»“æœåŒ…è£…ç­‰é€»è¾‘æŠ½ç¦»ä¸º `_match_pre_processor` ä¸ `_match_post_processor` ä¸¤ä¸ªç‹¬ç«‹æ–¹æ³•ã€‚`_match_prefix_helper` ç°åœ¨ç»Ÿä¸€è¿”å› `(value, last_node, best_value_len)`ï¼Œä»è€Œæ¶ˆé™¤ä»£ç é‡å¤å¹¶æå‡å¯è¯»æ€§ã€‚  

**ğŸ¯ å½±å“èŒƒå›´**  
- `python/sglang/srt/mem_cache/mamba_radix_cache.py`  
- `python/sglang/srt/mem_cache/swa_radix_cache.py`  
- ç›¸å…³çš„ `MatchPrefixParams`ã€`MatchResult` ä½¿ç”¨è·¯å¾„ï¼ˆå¦‚è¯·æ±‚è°ƒåº¦å±‚ï¼‰  

**ğŸ’¡ å…³æ³¨å»ºè®®**  

1. **è¡Œä¸ºä¿æŒ**ï¼š  
   - å‰ç½®å¤„ç†è¿”å› `None` æ—¶ï¼Œ`match_prefix` ç›´æ¥è¿”å›ç©º `MatchResult`ï¼ŒåŠ¡å¿…ç¡®è®¤è°ƒç”¨æ–¹å¯¹ `last_device_node`/`last_host_node` ä¸ºæ ¹èŠ‚ç‚¹çš„å‡è®¾ä»ç„¶æˆç«‹ã€‚  
   - å¯¹ `swa_radix_cache`ï¼ŒåŸå®ç°ç›´æ¥åœ¨ `params.key` ä¸Šä¿®æ”¹ `token_ids` å¹¶æˆªæ–­ï¼›æ–°å®ç°è¿”å›æ–°çš„ `RadixKey` å®ä¾‹ï¼Œéœ€æ£€æŸ¥åç»­æ˜¯å¦ä»ä¾èµ–åŸå¯¹è±¡çš„å‰¯ä½œç”¨ï¼ˆå¦‚ç¼“å­˜é”®çš„å”¯ä¸€æ€§ï¼‰ã€‚

2. **ç±»å‹å®‰å…¨**ï¼š  
   - `_match_prefix_helper` çš„è¿”å›ç±»å‹å·²ä» `Optional[int]` æ”¹ä¸ºå¿…å®š `int`ï¼ˆ`best_value_len`ï¼‰ï¼Œç¡®ä¿åœ¨æ‰€æœ‰åˆ†æ”¯å‡æœ‰æœ‰æ•ˆè¿”å›ï¼Œé˜²æ­¢è¿è¡Œæ—¶ `None` å¼•å‘å¼‚å¸¸ã€‚  
   - `MatchPrefixParams` ä¸­çš„ `cow_mamba`ã€`req` åœ¨åç½®å¤„ç†é‡Œä»è¢«ä½¿ç”¨ï¼Œå»ºè®®åœ¨æ–‡æ¡£ä¸­æ³¨æ˜æ­¤ä¾èµ–å…³ç³»ã€‚

3. **æ€§èƒ½å½±å“**ï¼š  
   - æŠ½è±¡å±‚çš„å‡½æ•°è°ƒç”¨å¼€é”€æå°ï¼Œå®é™…è·¯å¾„æœªæ”¹å˜ï¼›ä½†åœ¨ `swa_radix_cache` å‰ç½®å¤„ç†é‡Œä»ä¼šè¿›è¡Œ `key = key[:page_aligned_len]` çš„åˆ‡ç‰‡ï¼Œä¿æŒä¸åŸå®ç°ä¸€è‡´ã€‚  
   - å¤åˆ¶ Mamba çŠ¶æ€çš„é€»è¾‘è¿ç§»è‡³åç½®å¤„ç†ï¼Œä¸å½±å“ç¼“å­˜å‘½ä¸­è·¯å¾„çš„æ—¶é—´å¤æ‚åº¦ã€‚

4. **æµ‹è¯•è¦†ç›–**ï¼š  
   - å¢åŠ å¯¹ç©ºé”®ã€`disable=True`ã€`page_size>1`ã€ä»¥åŠ `cow_mamba=True` ä¸”è¯·æ±‚æ— ç¼“å­˜çš„è¾¹ç•Œæƒ…å†µçš„å•å…ƒæµ‹è¯•ã€‚  
   - éªŒè¯ LRU æ›´æ–°ä»åŸºäº `last_node`ï¼ˆåŸä»£ç ä½¿ç”¨ `best_last_node`ï¼‰ï¼Œç¡®ä¿ç¼“å­˜é©±é€ç­–ç•¥ä¸å—å½±å“ã€‚  

5. **æ–‡æ¡£/æ³¨é‡Š**ï¼š  
   - ä¸º `_match_pre_processor` ä¸ `_match_post_processor` æ·»åŠ ä½¿ç”¨ç¤ºä¾‹æˆ–è°ƒç”¨é¡ºåºè¯´æ˜ï¼Œå¸®åŠ©åç»­ç»´æŠ¤è€…å¿«é€Ÿå®šä½åŒ¹é…æµç¨‹çš„å…¥å£ä¸å‡ºå£ã€‚  

æ€»ä½“æ¥çœ‹ï¼Œæ­¤æ¬¡é‡æ„æå‡äº†ä»£ç å¯ç»´æŠ¤æ€§ï¼Œé£é™©ä¸»è¦åœ¨äºé”®å¯¹è±¡çš„å¯å˜æ€§ä»¥åŠå¯¹ç©ºè¿”å›çš„å¤„ç†ã€‚é€šè¿‡å®Œå–„æµ‹è¯•å’Œæ–‡æ¡£ï¼Œå¯ç¡®ä¿æ”¹åŠ¨å¹³æ»‘ä¸Šçº¿ã€‚

---

### [DeepGemm] Add a flag for fast warmup (#18111)
**SHA**: `d279520` | ğŸ”— [æŸ¥çœ‹æäº¤](https://github.com/sgl-project/sglang/commit/d279520ba5771e0bd361c6a762b653391bb1bc09)

**ğŸ¯ å˜æ›´ç±»å‹**ï¼šåŠŸèƒ½å¢å¼ºï¼ˆä¸º DeepGemmâ€‘JIT æ·»åŠ å¿«é€Ÿé¢„çƒ­å¼€å…³ï¼‰  
**âš¡ é‡è¦ç¨‹åº¦**ï¼šğŸŸ¡ ä¸­  
**ğŸ“‹ å˜æ›´æ‘˜è¦**  
1. åœ¨æ–‡æ¡£å’Œ `python/sglang/srt/environ.py` ä¸­æ–°å¢ç¯å¢ƒå˜é‡ `SGLANG_JIT_DEEPGEMM_FAST_WARMUP`ï¼ˆé»˜è®¤ `false`ï¼‰ã€‚  
2. åœ¨ `compile_utils.py` ä¸­è¯»å–è¯¥æ ‡å¿—ï¼Œåœ¨ `update_deep_gemm_config` é‡Œå†³å®šæ˜¯å¦åªç¼–è¯‘ä¸€å°éƒ¨åˆ†å…¸å‹ `M`ï¼ˆbatchâ€‘sizeï¼‰kernelï¼Œä»¥æŠŠé¢„çƒ­æ—¶é—´ä»çº¦â€¯30â€¯min é™è‡³ <â€¯3â€¯minã€‚  
3. åŒæ—¶å°† `SGL_USE_DEEPGEMM_BMM` åç§°ç»Ÿä¸€ä¸º `SGLANG_USE_DEEPGEMM_BMM`ï¼Œå¹¶åœ¨æ–‡æ¡£ä¸­åŒæ­¥æ›´æ–°ã€‚  

**ğŸ¯ å½±å“èŒƒå›´**  
- **ç¯å¢ƒå˜é‡è§£æå±‚** (`environ.py`)  
- **DeepGemm ç¼–è¯‘æµç¨‹** (`layers/deep_gemm_wrapper/compile_utils.py`)  
- **æ–‡æ¡£** (`docs/references/environment_variables.md`)  
- ä¾èµ– `_BUILTIN_M_LIST` çš„åç»­ JIT è°ƒåº¦æˆ–ç¼“å­˜å±‚ï¼ˆé—´æ¥å—å½±å“ï¼‰ã€‚  

**ğŸ’¡ å…³æ³¨å»ºè®®**  

1. **åŠŸèƒ½éªŒè¯**ï¼šåœ¨å¼€å¯ `SGLANG_JIT_DEEPGEMM_FAST_WARMUP=1` æ—¶ï¼Œç¡®ä¿å¯åŠ¨ååªç”Ÿæˆæ–‡ä¸­åˆ—å‡ºçš„ ~3k kernelï¼Œè€Œéå…¨éƒ¨ ~12kã€‚è·‘ä¸€æ¬¡å®Œæ•´æ¨ç†å·¥ä½œæµï¼Œæ¯”è¾ƒå®é™…ååä¸æœªå¼€å¯æ—¶çš„å·®è·ï¼Œç¡®è®¤ â€œå¯èƒ½å¯¼è‡´è¿è¡Œæ—¶æ€§èƒ½ä¸‹é™â€ çš„é£é™©åœ¨å¯æ¥å—èŒƒå›´ã€‚  

2. **å›é€€å…¼å®¹**ï¼šé»˜è®¤ä»ä¿æŒ `false`ï¼Œä½†å¦‚æœç”¨æˆ·åœ¨å·²æœ‰ç¼“å­˜ç›®å½•ä¸‹åˆ‡æ¢æ ‡å¿—ï¼Œéœ€æ³¨æ„ç¼“å­˜å¯èƒ½æ··ç”¨ä¸åŒçš„ kernel é›†åˆã€‚å»ºè®®åœ¨åˆ‡æ¢åæ¸…ç† `~/.cache/deep_gemm` æˆ–åœ¨ä»£ç ä¸­æ£€æµ‹æ ‡å¿—å˜åŒ–å¹¶å¼ºåˆ¶é‡æ–°ç¼–è¯‘ã€‚  

3. **æ–‡æ¡£ä¸€è‡´æ€§**ï¼šç›®å‰æ–‡æ¡£å·²åŠ å…¥æ–°å˜é‡è¯´æ˜ï¼Œä½†ä»ä¿ç•™æ—§ `SGL_USE_DEEPGEMM_BMM` æ¡ç›®ï¼ˆå·²æ”¹ä¸º `SGLANG_USE_DEEPGEMM_BMM`ï¼‰ï¼Œè¯·æ£€æŸ¥å…¶ä»– README æˆ–ç¤ºä¾‹è„šæœ¬ï¼Œé˜²æ­¢å‡ºç°æ‹¼å†™ä¸ç»Ÿä¸€å¯¼è‡´ç”¨æˆ·é…ç½®å¤±æ•ˆã€‚  

4. **å•å…ƒ/é›†æˆæµ‹è¯•**ï¼šåŠ å…¥ä¸¤å¥—æµ‹è¯•ï¼š  
   - **å¿«é€Ÿé¢„çƒ­**ï¼š`SGLANG_JIT_DEEPGEMM_FAST_WARMUP=1` æ—¶éªŒè¯ `_BUILTIN_M_LIST` é•¿åº¦çº¦ä¸º 3kï¼Œä¸”åŒ…å« 1â€‘1024ã€1024â€‘max_prefill ç­‰å…³é”®åŒºé—´ã€‚  
   - **å®Œæ•´é¢„çƒ­**ï¼šæ ‡å¿—å…³é—­æ—¶ä»èƒ½ç”Ÿæˆå®Œæ•´ `1..m_max` åˆ—è¡¨ã€‚  

5. **æ€§èƒ½ç›‘æ§**ï¼šå»ºè®®åœ¨è¿è¡Œæ—¶è®°å½•å®é™…ç¼–è¯‘çš„ kernel æ•°é‡åŠé¢„çƒ­è€—æ—¶ï¼ˆå¯é€šè¿‡æ—¥å¿—ï¼‰ï¼Œä¸ºåç»­æ˜¯å¦é»˜è®¤å¼€å¯è¯¥ç‰¹æ€§æä¾›æ•°æ®æ”¯æ’‘ã€‚  

æ€»ä½“è€Œè¨€ï¼Œæ­¤æ¬¡æ”¹åŠ¨åœ¨ä¿æŒåŸæœ‰åŠŸèƒ½çš„å‰æä¸‹æä¾›äº†æ˜¾è‘—çš„å¯åŠ¨åŠ é€Ÿé€‰é¡¹ï¼Œä½†éœ€è¦ä¸¥æ ¼çš„å…¼å®¹æ€§æµ‹è¯•å’Œç¼“å­˜ç®¡ç†ç­–ç•¥ï¼Œä»¥é˜²å› ç¼ºå¤±å…³é”® kernel è€Œå¯¼è‡´æ¨ç†æ€§èƒ½é€€åŒ–ã€‚å¯¹éœ€è¦å¿«é€Ÿå¯åŠ¨çš„å¼€å‘è°ƒè¯•åœºæ™¯éå¸¸æœ‰ä»·å€¼ï¼Œç”Ÿäº§ç¯å¢ƒè¯·æ…é‡è¯„ä¼°åå†å¯ç”¨ã€‚

---

### fix: bumping nightly whl version (#18212)
**SHA**: `b7c1dfc` | ğŸ”— [æŸ¥çœ‹æäº¤](https://github.com/sgl-project/sglang/commit/b7c1dfc6022a68e74034f94274b04fc6565ec248)

**ğŸ¯ å˜æ›´ç±»å‹**ï¼šBug ä¿®å¤ï¼ˆå¤œé—´æ„å»ºç‰ˆæœ¬å·ä¸é€’å¢å¯¼è‡´çš„å†²çªï¼‰  
**âš¡ é‡è¦ç¨‹åº¦**ï¼šğŸŸ¡ ä¸­  
**ğŸ“‹ å˜æ›´æ‘˜è¦**ï¼šåœ¨ `.github/workflows/release-pypi-nightly.yml` ä¸­ï¼ŒåŸå…ˆçš„ nightly ç‰ˆæœ¬ç›´æ¥ä½¿ç”¨ tagâ€¯`vX.Y.Z` å¹¶åœ¨åç¼€åŠ  `.dev0+hash`ã€‚æ­¤å®ç°ä¼šåœ¨åŒä¸€ tagï¼ˆå¦‚ `v0.5.8`ï¼‰å¤šæ¬¡è§¦å‘ nightly æ—¶äº§ç”Ÿé‡å¤çš„ç‰ˆæœ¬å·ï¼Œå¯¼è‡´ PyPI ä¸Šä¼ å†²çªã€‚æ–°é€»è¾‘åœ¨ tag åŸºç¡€ä¸Šå°† **patch** å·åŠ â€¯1ï¼ˆ`v0.5.8 â†’ 0.5.9.dev0+hash`ï¼‰ï¼Œç¡®ä¿æ¯æ¬¡ nighty æ„å»ºå¾—åˆ°å”¯ä¸€çš„ç‰ˆæœ¬ã€‚

**ğŸ¯ å½±å“èŒƒå›´**  
- CI/CD å·¥ä½œæµï¼ˆnightly åŒ…å‘å¸ƒï¼‰  
- ä¾èµ– nightly åŒ…çš„ç”¨æˆ·/è‡ªåŠ¨åŒ–è„šæœ¬ï¼ˆç‰ˆæœ¬è§£æï¼‰  
- å¯èƒ½æ¶‰åŠçš„æ–‡æ¡£æˆ–å†…éƒ¨è¯´æ˜ä¸­å¯¹ç‰ˆæœ¬å·çš„çº¦å®š

**ğŸ’¡ å…³æ³¨å»ºè®®**  
1. **å…¼å®¹æ€§æ£€æŸ¥**ï¼šç¡®ä¿æ‰€æœ‰ downstream é¡¹ç›®åœ¨ `0.5.9.dev0+...` å½¢å¼ä¸‹ä»å¯é€šè¿‡ `pip install` æ­£å¸¸è§£æï¼›è‹¥ä½¿ç”¨ `packaging.version.Version`ï¼Œåº”ä¿æŒå…¼å®¹ã€‚  
2. **æ ‡ç­¾æ ¼å¼**ï¼šå½“å‰ä»…å¤„ç† `vMAJOR.MINOR.PATCH`ï¼Œè‹¥å‡ºç° `vMAJOR.MINOR` æˆ–å¸¦é¢„å‘å¸ƒåç¼€çš„æ ‡ç­¾ï¼Œè„šæœ¬ä¼šæŠ¥é”™ã€‚å»ºè®®åœ¨å·¥ä½œæµä¸­åŠ å…¥é˜²å¾¡æ€§æ£€æŸ¥æˆ–é»˜è®¤ `PATCH=0`ã€‚  
3. **æµ‹è¯•éªŒè¯**ï¼šåœ¨ PR åˆå¹¶å‰å¯å¢åŠ ä¸€æ¬¡ dryâ€‘run æ­¥éª¤ï¼Œæ‰“å°ç”Ÿæˆçš„ `FORCE_VERSION` å¹¶é€šè¿‡ `python -c "import packaging.version; packaging.version.Version('$FORCE_VERSION')"` éªŒè¯åˆæ³•æ€§ã€‚  
4. **æ–‡æ¡£æ›´æ–°**ï¼šåœ¨é¡¹ç›®çš„ Release æˆ– Nightly ç« èŠ‚è¯´æ˜æ–°ç‰ˆå·è§„åˆ™ï¼Œé¿å…ç”¨æˆ·å¯¹ â€œpatch+1â€ äº§ç”Ÿè¯¯è§£ã€‚  
5. **å›æ»šç­–ç•¥**ï¼šè‹¥å‡ºç°æ„å¤–çš„ç‰ˆæœ¬è·³è·ƒï¼ˆå¦‚ `0.5.9` å·²æ­£å¼å‘å¸ƒï¼‰ï¼Œnightly ä»ä¼šç”Ÿæˆ `0.5.10.dev0`ï¼Œå¯èƒ½ä¸æœªæ¥çš„æ­£å¼ç‰ˆæœ¬æ··æ·†ï¼Œå»ºè®®åœ¨æ­£å¼å‘å¸ƒååŒæ­¥æ›´æ–°å·¥ä½œæµé€»è¾‘æˆ–æ‰‹åŠ¨é”å®šæœ€é«˜å·²å‘å¸ƒç‰ˆæœ¬ã€‚  

æ€»ä½“è€Œè¨€ï¼Œæ­¤ä¿®æ”¹è§£å†³äº† nightly åŒ…ç‰ˆæœ¬å†²çªé—®é¢˜ï¼Œå½±å“å±€é™åœ¨ CI æµç¨‹å’Œç‰ˆæœ¬å·è§£æï¼Œä¿æŒå‘åå…¼å®¹çš„å‰æä¸‹å³å¯å®‰å…¨ä¸Šçº¿ã€‚

---

### fuse qkvbfg linear into one gemm and f_b g_b into batched gemm. (#17801)
**SHA**: `37c33cc` | ğŸ”— [æŸ¥çœ‹æäº¤](https://github.com/sgl-project/sglang/commit/37c33cc0aa6213fd4abcfb40c3e1d71dde484295)

**ğŸ¯ å˜æ›´ç±»å‹**ï¼šåŠŸèƒ½å¢å¼ºï¼ˆç®—å­èåˆã€æ‰¹é‡ GEMMï¼‰  
**âš¡ é‡è¦ç¨‹åº¦**ï¼šğŸŸ¡ ä¸­  
**ğŸ“‹ å˜æ›´æ‘˜è¦**ï¼šåœ¨ `KimiLinear` ä¸­å°† Qã€Kã€Vã€Bã€Fã€G å…­è·¯çº¿æ€§æŠ•å½±åˆå¹¶ä¸ºä¸¤æ¬¡ GEMMï¼šâ‘  `MergedColumnParallelRepeatedLinear` æŠŠåˆ—å¹¶è¡Œçš„ Q/K/V/B ä¸é‡å¤çš„ F/Gâ€‘A åˆå¹¶ä¸ºä¸€æ¬¡å¤§çŸ©é˜µä¹˜ï¼›â‘¡ `ColumnParallelBatchedLinear` ç”¨ä¸€æ¬¡æ‰¹é‡ GEMM åŒæ—¶è®¡ç®— Fâ€‘B ä¸ Gâ€‘Bã€‚ç›¸åº”çš„æƒé‡åŠ è½½é€»è¾‘å’Œ forward åˆ†æ”¯ä¹Ÿåšäº†é€‚é…ï¼Œé»˜è®¤åœ¨æ— é‡åŒ–é…ç½®æ—¶å¼€å¯èåˆã€‚

**ğŸ¯ å½±å“èŒƒå›´**  
- `python/sglang/srt/layers/linear.py`ï¼šæ–°å¢ `MergedColumnParallelRepeatedLinear` ä¸ `ColumnParallelBatchedLinear`ï¼Œä»¥åŠæƒé‡åˆ‡åˆ†/åŠ è½½å®ç°ã€‚  
- `python/sglang/srt/models/kimi_linear.py`ï¼šæ”¹å†™ QKVâ€‘Bâ€‘Fâ€‘G ç›¸å…³æŠ•å½±ï¼ŒåŠ å…¥ `do_fuse_qkvbfg` å¼€å…³ï¼Œé‡æ„ `forward`ã€`load_weights`ã€‚  
- å…¶ä»–æ¨¡å‹ï¼ˆå¦‚ MoEï¼‰åœ¨æƒé‡åŠ è½½æ—¶éœ€è¦æ£€æŸ¥ `do_fuse_qkvbfg` æ ‡å¿—ï¼Œé˜²æ­¢è¯¯åŠ è½½ã€‚  

**ğŸ’¡ å…³æ³¨å»ºè®®**  
1. **å…¼å®¹æ€§**ï¼šç›®å‰ä»…åœ¨ `quant_config is None` æ—¶å¯ç”¨èåˆï¼Œè‹¥åç»­åŠ å…¥é‡åŒ–ï¼Œéœ€è¦å®ç°å¯¹åº”çš„æƒé‡é‡åŒ–åˆ‡åˆ†ï¼Œå¦åˆ™ä¼šå‡ºç°æœªå®ç°çš„è·¯å¾„ã€‚  
2. **æƒé‡åŠ è½½**ï¼šæ–°å¢çš„ `fuse_qkvbfg_keys` è¿‡æ»¤é€»è¾‘è¦ç¡®ä¿æ‰€æœ‰å‚æ•°ååœ¨æ£€æŸ¥ç‚¹ä¸­éƒ½æœ‰å¯¹åº”æ˜ å°„ï¼Œå»ºè®®åœ¨ CI ä¸­åŠ å…¥ checkpointâ€‘toâ€‘model çš„å®Œæ•´å¯¹æ¯”æµ‹è¯•ã€‚  
3. **æ€§èƒ½éªŒè¯**ï¼šè¯·å¯¹æ¯”å¼€å¯/å…³é—­èåˆçš„ååå’Œæ˜¾å­˜å ç”¨ï¼Œå°¤å…¶åœ¨å¤šæœº `tp_size>1` æ—¶éªŒè¯åˆ†ç‰‡æ˜¯å¦æ­£ç¡®ï¼ˆ`shard_offset`ã€`shard_size` çš„è®¡ç®—ï¼‰ã€‚  
4. **é”™è¯¯å¤„ç†**ï¼š`weight_loader` ä¸­å¯¹ `loaded_shard_id` è¶Šç•Œæˆ– `param` æ²¡æœ‰ `output_dim` å±æ€§çš„æƒ…å†µæœªåšä¿æŠ¤ï¼Œå»ºè®®åŠ æ–­è¨€ä»¥é˜²éšè—çš„ IndexErrorã€‚  
5. **æ–‡æ¡£/é…ç½®**ï¼šåœ¨æ¨¡å‹é…ç½®æˆ– README ä¸­è¯´æ˜ `do_fuse_qkvbfg` çš„é»˜è®¤è¡Œä¸ºåŠä½•æ—¶åº”æ‰‹åŠ¨å…³é—­ï¼ˆå¦‚é‡åŒ–æˆ–è‡ªå®šä¹‰æƒé‡æ ¼å¼ï¼‰ã€‚  

æ€»ä½“è€Œè¨€ï¼Œæ­¤æ¬¡èåˆå¯æ˜¾è‘—å‡å°‘ GEMM æ¬¡æ•°ï¼Œæå‡è§£ç é˜¶æ®µæ€§èƒ½ï¼Œä½†éœ€åŠ å¼ºé‡åŒ–å…¼å®¹ã€æƒé‡æ ¡éªŒåŠå¼‚å¸¸ä¿æŠ¤ï¼Œä»¥å…åœ¨ä¸åŒéƒ¨ç½²ç¯å¢ƒä¸‹å‡ºç°éšè”½é”™è¯¯ã€‚

---

### Fix Session for multimodal and expose it through Engine (#18152)
**SHA**: `c1d529c` | ğŸ”— [æŸ¥çœ‹æäº¤](https://github.com/sgl-project/sglang/commit/c1d529c19605cbf1f9be8db6d6d225b1465ea2e0)

**ğŸ¯ å˜æ›´ç±»å‹**ï¼šåŠŸèƒ½å¢å¼º / Bug ä¿®å¤  
**âš¡ é‡è¦ç¨‹åº¦**ï¼šğŸŸ¡ ä¸­  
**ğŸ“‹ å˜æ›´æ‘˜è¦**  
1. ä¸ºå¤šè½®ä¼šè¯ï¼ˆsessionï¼‰æ–°å¢ `open_session` / `close_session` æ¥å£ï¼Œæ”¯æŒåœ¨åŒä¸€ä¼šè¯ä¸­å…±äº«ä¸Šä¸‹æ–‡å¹¶ä¼ é€’ multimodal ä¿¡æ¯ã€‚  
2. åœ¨è°ƒåº¦å™¨ä¸­å¯¹ä¼šè¯è¯·æ±‚çš„å¤šæ¨¡æ€è¾“å…¥åšäº†ä¸¤é¡¹å…³é”®å¤„ç†ï¼šâ‘  ä¼šè¯ç»“æŸåä¸å†æ¸…é™¤ `mm_inputs`ï¼Œä¿è¯åç»­è¯·æ±‚å¯ä»¥å¤ç”¨ï¼›â‘¡ å½“ä¼šè¯å‰ç¼€å¯¼è‡´ `input_ids` è¢«æˆªçŸ­æ—¶ï¼Œè‡ªåŠ¨è°ƒæ•´ multimodal é¡¹çš„ offsetï¼Œä½¿å›¾åƒ/éŸ³é¢‘ç­‰ä½ç½®ä¸æ–°è¾“å…¥å¯¹é½ã€‚  
3. ç§»é™¤ `ScheduleBatch.customized_info`ï¼ˆå·²ä¸å†ä½¿ç”¨ï¼‰ï¼Œç®€åŒ–æ‰¹æ¬¡çŠ¶æ€æ¢å¤ã€‚  

**ğŸ¯ å½±å“èŒƒå›´**  
- `python/sglang/srt/entrypoints/engine.py`ï¼ˆæ–°å¢ä¼šè¯ APIï¼‰  
- `python/sglang/srt/managers/scheduler.py`ï¼ˆä¼šè¯ multimodal å¤„ç†ï¼‰  
- `python/sglang/srt/managers/schedule_batch.py`ï¼ˆæ¸…ç†é€»è¾‘ï¼‰  
- ç›¸å…³ `io_struct` å®šä¹‰ï¼ˆ`OpenSessionReqInput`ã€`CloseSessionReqInput`ï¼‰  

**ğŸ’¡ å…³æ³¨å»ºè®®**  
1. **æ¥å£ä¸€è‡´æ€§**ï¼š`open_session` é‡‡ç”¨ `self.loop.run_until_complete`ï¼Œéœ€è¦ç¡®è®¤ `TokenizerManager.open_session` ä¸ `close_session` å·²å®ç°å¹¶æ”¯æŒ async é”™è¯¯è¿”å›ã€‚è‹¥æœªå®ç°ï¼Œè°ƒç”¨ä¼šæŠ¥ `AttributeError`ã€‚  
2. **UUID ç”Ÿæˆ**ï¼šå½“å‰ä»£ç æœªæ˜¾å¼å¯¼å…¥ `uuid`ï¼Œè‹¥ `OpenSessionReqInput` åªæ¥å— `None` å¹¶åœ¨å†…éƒ¨ç”Ÿæˆ UUIDï¼Œéœ€åœ¨æ–‡æ¡£æˆ–å®ç°ä¸­è¯´æ˜ã€‚å¦åˆ™å»ºè®®åœ¨ `engine.py` ä¸­è‡ªè¡Œç”Ÿæˆï¼ˆ`import uuid; session_id = session_id or str(uuid.uuid4())`ï¼‰ã€‚  
3. **èµ„æºå›æ”¶**ï¼šä¼šè¯ç»“æŸåå¿…é¡»è°ƒç”¨ `close_session`ï¼Œå¦åˆ™åº•å±‚ç¼“å­˜ï¼ˆtokenã€embeddingï¼‰ä¼šæ³„æ¼ã€‚å»ºè®®åœ¨ `Engine.__exit__` ä¸­åŠ å…¥å¯¹æœªå…³é—­ä¼šè¯çš„è‡ªåŠ¨æ¸…ç†æˆ–åœ¨æ–‡æ¡£ä¸­å¼ºåˆ¶æç¤ºç”¨æˆ·ã€‚  
4. **åç§»æ ¡æ­£çš„é²æ£’æ€§**ï¼š`offsets` åªåœ¨éç©ºæ—¶è°ƒæ•´ï¼Œç¡®ä¿ `mm_item.offsets` ä¸º `list[tuple[int,int]]`ã€‚è‹¥åç»­å‡ºç° `None`ï¼Œä¼šè§¦å‘ `TypeError`ã€‚å¯åœ¨å¾ªç¯å‰åŠ  `if not mm_item.offsets: continue`ã€‚  
5. **æµ‹è¯•è¦†ç›–**ï¼šå¢åŠ ä»¥ä¸‹æµ‹è¯•åœºæ™¯ï¼š  
   - æ‰“å¼€ä¼šè¯ã€è¿ç»­ä¸¤æ¬¡ `generate`ï¼ˆå«å›¾åƒ tokenï¼‰å¹¶æ£€æŸ¥è¿”å›çš„ `multimodal_inputs` æ˜¯å¦è¢«æ­£ç¡®ä¿ç•™ã€‚  
   - ä¼šè¯å‰ç¼€å¯¼è‡´ `input_ids` æˆªçŸ­æ—¶ï¼ŒéªŒè¯ `offsets` å·²è¢«å¹³ç§»ã€‚  
   - å…³é—­ä¼šè¯åå†æ¬¡è°ƒç”¨ `generate`ï¼Œç¡®è®¤æ–°ä¼šè¯ä¸å—æ—§ç¼“å­˜å½±å“ã€‚  

6. **æ–‡æ¡£æ›´æ–°**ï¼šåœ¨ README / API æ–‡æ¡£ä¸­åŠ å…¥ `Engine.open_session`ã€`Engine.close_session` çš„ä½¿ç”¨ç¤ºä¾‹ï¼Œè¯´æ˜ `session_params` å¿…é¡»åŒ…å« `id` ä¸ `capacity_of_str_len`ï¼Œä»¥åŠå¯¹ multimodal è¾“å…¥çš„ç‰¹æ®Šå¤„ç†ã€‚  

æ€»ä½“è€Œè¨€ï¼Œæ­¤æ¬¡æ”¹åŠ¨ä¸ºå¤šè½® multimodal ä¼šè¯æä¾›äº†å¿…è¦çš„ç”Ÿå‘½å‘¨æœŸç®¡ç†ï¼Œé€»è¾‘ä¸Šç¬¦åˆå·²æœ‰è°ƒåº¦æ¡†æ¶ã€‚ä½†éœ€æ³¨æ„ä¸Šè¿°ç»†èŠ‚ï¼Œä»¥é˜²è¿è¡Œæ—¶å¼‚å¸¸æˆ–èµ„æºæ³„æ¼ã€‚éšç€ä¼šè¯ç‰¹æ€§çš„å¼€æ”¾ï¼Œå»ºè®®å°½å¿«è¡¥é½ç›¸åº”çš„å•å…ƒ/é›†æˆæµ‹è¯•å¹¶æ›´æ–°æ–‡æ¡£ã€‚

---

### [diffusion] fix: fix server cache-dit bug under continuous dynamic requests (#17140)
**SHA**: `da758ed` | ğŸ”— [æŸ¥çœ‹æäº¤](https://github.com/sgl-project/sglang/commit/da758ed601270b21e1cfb404306ff0ca5c816a3f)

**ğŸ¯ å˜æ›´ç±»å‹**ï¼šBug ä¿®å¤ï¼ˆä¼˜åŒ–è¿ç»­åŠ¨æ€è¯·æ±‚ä¸‹çš„ Cacheâ€‘DIT è¡Œä¸ºï¼‰  
**âš¡ é‡è¦ç¨‹åº¦**ï¼šğŸŸ¡ ä¸­  

**ğŸ“‹ å˜æ›´æ‘˜è¦**  
1. åœ¨ `cache_dit_integration.py` ä¸­è¡¥å……äº†å¯¹ secondaryï¼ˆç¬¬äºŒï¼‰transformer çš„ SCM æ­¥æ•°ç»Ÿè®¡ï¼Œæ–°å¢äº† `refresh_context_on_transformer` ä¸ `refresh_context_on_dual_transformer`ï¼Œå®ç°æ¯æ¬¡æ–°è¯·æ±‚åˆ°æ¥æ—¶é‡æ–°åˆ·æ–° Cacheâ€‘DIT ä¸Šä¸‹æ–‡ã€‚  
2. `denoising.py` çš„ `_maybe_enable_cache_dit` æ”¹ä¸ºæ¥å—å•/åŒæ­¥æ•° (`int` æˆ– `tuple[int,int]`)ï¼Œåœ¨åŒå™ªå£°ä¸“å®¶æ¨¡å¼ä¸‹åˆ†åˆ«è®¡ç®— highâ€‘noise ä¸ lowâ€‘noise æ­¥æ•°ï¼Œå¹¶åœ¨å·²æœ‰ Cacheâ€‘DIT å¯ç”¨æ—¶è°ƒç”¨å¯¹åº”çš„åˆ·æ–°å‡½æ•°ã€‚  
3. è°ƒæ•´äº†æ—¥å¿—ä¿¡æ¯ã€å˜é‡å‘½åä»¥åŠå¯¹ `num_inference_steps` çš„è·å–æ–¹å¼ï¼Œç¡®ä¿åœ¨ warmâ€‘up åœºæ™¯ä¸‹ä»ä½¿ç”¨åŸå§‹æ€»æ­¥æ•°ã€‚  

**ğŸ¯ å½±å“èŒƒå›´**  
- `sglang/multimodal_gen/runtime/cache/`ï¼šCacheâ€‘DIT å¯ç”¨ä¸åˆ·æ–°é€»è¾‘ã€‚  
- `sglang/multimodal_gen/runtime/pipelines_core/stages/denoising.py`ï¼šå»å™ªæµæ°´çº¿çš„åˆå§‹åŒ–ä¸æ­¥éª¤è®¡æ•°ã€‚  
- ç›¸å…³åˆ†å¸ƒå¼å·¥å…·ï¼ˆ`get_sp_group`ã€`get_tp_group` ç­‰ï¼‰é—´æ¥å—å½±å“ã€‚  

**ğŸ’¡ å…³æ³¨å»ºè®®**  
- **æµ‹è¯•è¦†ç›–**ï¼šè¡¥å……é’ˆå¯¹åŒ transformer åœºæ™¯çš„å•å…ƒ/é›†æˆæµ‹è¯•ï¼ŒéªŒè¯ `refresh_context_*` èƒ½åœ¨è¿ç»­è¯·æ±‚ä¸­ä¿æŒç¼“å­˜ä¸€è‡´æ€§ã€‚  
- **æ€§èƒ½ç›‘æ§**ï¼šåˆ·æ–°ä¸Šä¸‹æ–‡ä¼šäº§ç”Ÿé¢å¤–çš„åŒæ­¥å¼€é”€ï¼Œå»ºè®®åœ¨ç”Ÿäº§ç¯å¢ƒå¼€å¯ç›¸åº”çš„æ€§èƒ½æŒ‡æ ‡ï¼ˆå¦‚åˆ·æ–°æ—¶å»¶ã€ç¼“å­˜å‘½ä¸­ç‡ï¼‰ã€‚  
- **å‘åå…¼å®¹**ï¼š`_maybe_enable_cache_dit` å‚æ•°ç±»å‹å˜æ›´ä¸º `int|tuple`ï¼Œç¡®ä¿è°ƒç”¨æ–¹åœ¨æ—§ç‰ˆä»£ç ä¸­ä»ä¼ å…¥æ•´æ•°ï¼Œä¸ä¼šå‡ºç°ç±»å‹é”™è¯¯ã€‚  
- **æ—¥å¿—ä¸ç›‘æ§**ï¼šæ–°æ—¥å¿—å·²åŒºåˆ† primary/secondaryï¼Œå»ºè®®åœ¨éƒ¨ç½²æ—¶è®¾ç½®åˆé€‚çš„æ—¥å¿—çº§åˆ«ï¼Œé¿å…åœ¨é«˜å¹¶å‘ä¸‹äº§ç”Ÿè¿‡å¤š I/Oã€‚  

æ€»ä½“è€Œè¨€ï¼Œæ­¤æ¬¡æ”¹åŠ¨ä¿®å¤äº†è¿ç»­åŠ¨æ€è¯·æ±‚å¯¼è‡´ Cacheâ€‘DIT é…ç½®å¤±æ•ˆçš„é—®é¢˜ï¼Œæå‡äº†åŒå™ªå£°ä¸“å®¶æ¨¡å¼çš„é²æ£’æ€§ï¼Œä½†éœ€å…³æ³¨åˆ·æ–°å¼€é”€å’Œå…¼å®¹æ€§ã€‚

---

### fix: ensuring nightly whls are tagged with latest commit (#18204)
**SHA**: `ae004e1` | ğŸ”— [æŸ¥çœ‹æäº¤](https://github.com/sgl-project/sglang/commit/ae004e15c98b36dda9c460d4d0ee9891889a5adf)

**ğŸ¯ å˜æ›´ç±»å‹**ï¼šBug ä¿®å¤  
**âš¡ é‡è¦ç¨‹åº¦**ï¼šğŸŸ¡ ä¸­  

**ğŸ“‹ å˜æ›´æ‘˜è¦**ï¼šåœ¨ `release-pypi-nightly.yml` ä¸­ï¼Œå°†å¤œé—´æ„å»ºæ—¶ç”¨äºå¼ºåˆ¶ç‰ˆæœ¬å·çš„ **HASH** ç”Ÿæˆæ–¹å¼ç”±ä¾èµ– `git describe` çš„åˆ‡åˆ†æ”¹ä¸ºç›´æ¥ä½¿ç”¨ `git rev-parse --short HEAD`ï¼Œç¡®ä¿åœ¨ tagâ€¯=â€¯0ï¼ˆå³ç²¾ç¡® tag æ„å»ºï¼‰æ—¶ï¼Œç”Ÿæˆçš„ wheel ç‰ˆæœ¬å§‹ç»ˆåŒ…å«å½“å‰æäº¤çš„çŸ­ hashï¼Œé¿å…å›  `git describe` è¿”å›æ—§ hash è€Œå¯¼è‡´è½®å­æ–‡ä»¶åå†²çªã€‚

**ğŸ¯ å½±å“èŒƒå›´**ï¼š  
- GitHub Actions CI ä¸­çš„ Nightly PyPI å‘å¸ƒå·¥ä½œæµã€‚  
- ä»…å½±å“æ„å»ºè¿‡ç¨‹å’Œç”Ÿæˆçš„ wheel ç‰ˆæœ¬å·ï¼Œè¿è¡Œæ—¶ä»£ç åŠåº“åŠŸèƒ½ä¸å—å½±å“ã€‚

**ğŸ’¡ å…³æ³¨å»ºè®®**ï¼š  
1. **CI éªŒè¯**ï¼šåœ¨ CI ç¯å¢ƒç¡®è®¤ `git rev-parse --short HEAD` èƒ½æ­£å¸¸è·å– hashï¼ˆGit checkout å¿…é¡»å®Œæ•´ï¼‰ï¼Œå¹¶æ£€æŸ¥ç”Ÿæˆçš„ `FORCE_VERSION` ç¬¦åˆ PEPâ€¯440ï¼ˆå¦‚ `1.2.3.dev0+gabcd12`ï¼‰ã€‚  
2. **å…¼å®¹æ€§**ï¼šè‹¥é¡¹ç›®ä¸­æœ‰è„šæœ¬æˆ–å·¥å…·è§£æç‰ˆæœ¬å·ï¼Œéœ€è¦ç¡®ä¿å®ƒä»¬èƒ½å¤Ÿæ¥å—å‰ç¼€ `g`ï¼Œå¦åˆ™å¯èƒ½è¯¯åˆ¤ã€‚  
3. **å›é€€è·¯å¾„**ï¼šè¯¥æ”¹åŠ¨ä»…åœ¨ `DIST=0` åˆ†æ”¯æ‰§è¡Œï¼Œå…¶ä»–æ„å»ºè·¯å¾„ä¿æŒåŸè¡Œä¸ºï¼Œæ•…ä¸å¿…æ‹…å¿ƒå¯¹å¸¸è§„å‘å¸ƒçš„å½±å“ã€‚  
4. **æ–‡æ¡£æ›´æ–°**ï¼šè‹¥å·²æœ‰ Nightly è½®å­ç‰ˆæœ¬å‘½åè¯´æ˜ï¼Œå»ºè®®åœ¨ README æˆ– CI æ–‡æ¡£ä¸­æ³¨æ˜ä½¿ç”¨å½“å‰ commit hash ä½œä¸ºåç¼€ã€‚  

æ€»ä½“è€Œè¨€ï¼Œæ­¤æ”¹åŠ¨æå‡äº† Nightly è½®å­ç‰ˆæœ¬çš„å”¯ä¸€æ€§å’Œå¯è¿½æº¯æ€§ï¼Œå¯¹ç”¨æˆ·ä½¿ç”¨å½±å“æå°ï¼Œå®Œæˆåè¯·è§‚å¯Ÿå‡ æ¬¡ Nightly å‘å¸ƒæ˜¯å¦é¡ºåˆ©ä¸Šä¼ ä¸”ç‰ˆæœ¬å·æ­£ç¡®ã€‚

---

### [diffusion] hardware: support diffusion models on MTGPU (multi-GPU, 5/N) (#17318)
**SHA**: `ec2461b` | ğŸ”— [æŸ¥çœ‹æäº¤](https://github.com/sgl-project/sglang/commit/ec2461bc16e59d8a5738340fb559ccf396cd9af7)

**ğŸ¯ å˜æ›´ç±»å‹**ï¼šåŠŸèƒ½å¢å¼ºï¼ˆæ–°å¢å¯¹ MUSAï¼ˆMTGPUï¼‰å¹³å°çš„æ”¯æŒï¼‰  
**âš¡ é‡è¦ç¨‹åº¦**ï¼šğŸŸ¡ ä¸­  
**ğŸ“‹ å˜æ›´æ‘˜è¦**ï¼šåœ¨ `pynccl_wrapper.py`ã€`clip.py` ä¸ `utils.py` ä¸­åŠ å…¥å¯¹ MUSAï¼ˆCambriconï¼‰GPU çš„æ£€æµ‹ä¸åº“åŠ è½½é€»è¾‘ï¼Œå¹¶åœ¨ CLIP ç¼–ç å™¨çš„æ³¨æ„åŠ›å®ç°é‡Œè§„é¿ MUSA ä¸Š `torch.nn.functional.scaled_dot_product_attention` åŒæ—¶ä½¿ç”¨ `attn_mask` ä¸ `is_causal=True` çš„é™åˆ¶ã€‚  
**ğŸ¯ å½±å“èŒƒå›´**ï¼š  
- `python/sglang/multimodal_gen/runtime/distributed/device_communicators/`ï¼ˆNCCL/RCCl/MCCl åŠ¨æ€é“¾æ¥ï¼‰  
- `python/sglang/multimodal_gen/runtime/models/encoders/clip.py`ï¼ˆæ³¨æ„åŠ›è·¯å¾„ï¼‰  
- `python/sglang/multimodal_gen/utils.py`ï¼ˆåº“æ–‡ä»¶æŸ¥æ‰¾ï¼‰  

**ğŸ’¡ å…³æ³¨å»ºè®®**  

1. **å¹³å°æ£€æµ‹å¯é æ€§**ï¼š`current_platform.is_musa()` ä¸ `torch.version.musa` çš„åˆ¤æ–­å·²ç»åŠ å…¥ï¼Œä½†åœ¨æœªç¼–è¯‘ MUSA ç‰ˆ PyTorch æ—¶ä»ä¼šå‡ºç° `AttributeError`ã€‚å»ºè®®åœ¨ `utils.find_nccl_library` ä¸­ä½¿ç”¨ `getattr(torch.version, "musa", None)`ï¼Œå¹¶åœ¨ `current_platform` ä¸­æä¾›å›é€€è·¯å¾„ï¼Œé˜²æ­¢è¿è¡Œæ—¶å´©æºƒã€‚  

2. **ç¼ºå¤±åº“çš„å®¹é”™**ï¼šè‹¥ `libmccl.so.2` æœªå®‰è£…ï¼Œç°æœ‰ `raise ValueError` ä¼šä¸­æ–­æ•´ä¸ªæœåŠ¡ã€‚å¯ä»¥è€ƒè™‘åœ¨é”™è¯¯ä¿¡æ¯ä¸­æä¾› `SGLANG_DIFFUSION_NCCL_SO_PATH` ç¯å¢ƒå˜é‡çš„ä½¿ç”¨è¯´æ˜ï¼Œæˆ–åœ¨ `pynccl_wrapper` ä¸­æ•è·å¼‚å¸¸å¹¶é™çº§ä¸ºå•å¡æ‰§è¡Œã€‚  

3. **æ³¨æ„åŠ›å®ç°çš„å…¼å®¹æ€§**ï¼šMUSA ä¸Šçš„ `scaled_dot_product_attention` æš‚ä¸æ”¯æŒ `attn_mask` ä¸ `is_causal=True` åŒæ—¶ä½¿ç”¨ï¼Œä»£ç å·²æ”¹ä¸ºä»…ä½¿ç”¨ `is_causal=True`ã€‚åº”åœ¨å•å…ƒæµ‹è¯•ä¸­éªŒè¯åœ¨ MUSA ç¯å¢ƒä¸‹ CLIP å‰å‘ä¸ä¼šäº§ç”Ÿ NaNï¼Œå¹¶åœ¨æ–‡æ¡£ä¸­æ˜ç¡®è¯¥é™åˆ¶ã€‚  

4. **CI ä¸è·¨å¹³å°æµ‹è¯•**ï¼šå½“å‰ CI ä»ä¸»è¦è¦†ç›– CUDA/ROCmï¼Œå»ºè®®åœ¨ CI ä¸­åŠ å…¥æ¨¡æ‹Ÿçš„ MUSA ç¯å¢ƒï¼ˆä¾‹å¦‚é€šè¿‡ mockï¼‰æˆ–åœ¨ç¤¾åŒºæä¾›ä¸€ä»½ `MUSA` æµ‹è¯•è„šæœ¬ï¼Œä»¥é˜²æ­¢æœªæ¥æ”¹åŠ¨ç ´åå…¼å®¹æ€§ã€‚  

5. **æ–‡æ¡£æ›´æ–°**ï¼šREADME/CHANGELOG ä¸­åŠ å…¥ â€œæ”¯æŒ MUSA å¤šå¡â€ çš„è¯´æ˜ï¼Œåˆ—å‡ºå¿…éœ€çš„åº“ï¼ˆ`libmccl.so.2`ï¼‰ä»¥åŠå¯¹åº”çš„ç¯å¢ƒå˜é‡é…ç½®æ–¹å¼ï¼Œå¸®åŠ©ç”¨æˆ·å¿«é€Ÿä¸Šæ‰‹ã€‚  

æ€»ä½“æ¥çœ‹ï¼Œæ­¤æ¬¡æ”¹åŠ¨ä¸ºåœ¨ MUSA ç¡¬ä»¶ä¸Šè¿è¡Œæ‰©æ•£æ¨¡å‹å¥ å®šäº†åŸºç¡€ï¼Œè‹¥åœ¨ä¸Šè¿°ç»†èŠ‚ä¸Šåšå¥½å®¹é”™ä¸æµ‹è¯•ï¼Œå°†èƒ½å¹³æ»‘åœ°æŠŠåŠŸèƒ½æ¨å¹¿åˆ°æ›´å¹¿æ³›çš„ç¡¬ä»¶ç”Ÿæ€ã€‚

---

### [HiCache] feat: Add detailed cache hit breakdown for HiCache in `sglext` and Prometheus metrics (#17648)
**SHA**: `e166ca8` | ğŸ”— [æŸ¥çœ‹æäº¤](https://github.com/sgl-project/sglang/commit/e166ca87584368699ac35ccb5e518211631849cf)

**ğŸ¯ å˜æ›´ç±»å‹**ï¼šåŠŸèƒ½å¢å¼ºï¼ˆHiCache ç¼“å­˜å‘½ä¸­ç»†ç²’åº¦ç»Ÿè®¡ + Prometheus æŒ‡æ ‡ï¼‰  
**âš¡ é‡è¦ç¨‹åº¦**ï¼šğŸŸ¡ ä¸­  

**ğŸ“‹ å˜æ›´æ‘˜è¦**  
1. åœ¨ OpenAIâ€‘style åè®®ä¸­æ–°å¢ `CachedTokensDetails`ã€`PromptTokensDetails` ä¸ `sglext.cached_tokens_details`ï¼Œå¹¶åœ¨åºåˆ—åŒ–æ—¶è‡ªåŠ¨å‰”é™¤ `None` å­—æ®µã€‚  
2. ä¸º `Completion/ChatCompletion` è¯·æ±‚åŠ å…¥ `return_cached_tokens_details` å¼€å…³ï¼Œåç«¯åœ¨å“åº”çš„ `sglext` ä¸­è¿”å›ç¼“å­˜å‘½ä¸­ä¿¡æ¯ï¼ˆdeviceã€hostï¼ŒåŠå¯é€‰çš„ L3â€‘storage ä¸ backendï¼‰ã€‚  
3. è°ƒåº¦å±‚ã€Tokenâ€‘managerã€detokenizerã€metrics ç­‰å¤§é‡ä»£ç åŒæ­¥æ”¹é€ ï¼š  
   - `Req` å¢åŠ  `cached_tokens_device/host/storage` ä¸ä¸€æ¬¡æ€§è®¡ç®—æ ‡è®° `_cache_breakdown_computed`ã€‚  
   - Scheduler åœ¨ `prepare_for_extend` æ—¶è®¡ç®—å„æ¥æºå‘½ä¸­æ•°ï¼Œå¹¶åœ¨ `stream_output_*` ä¸­å°†ç»†åˆ†æ•°æ®å†™å…¥ `cached_tokens_details`ã€‚  
   - `TreeCache` æ–°å¢ `prefetch_loaded_tokens_by_reqid` ç”¨äºç»Ÿè®¡ L3â€‘storage å®é™…åŠ è½½çš„ tokenï¼Œå¹¶åœ¨ abort/reset/terminate ä¸­æ¸…ç†ã€‚  
   - Prometheus æŒ‡æ ‡ `sglang:cached_tokens_total` æ–°å¢ `cache_source` ç»´åº¦ï¼Œæ”¯æŒ device/host/storageâ€‘<backend>ã€‚  

**ğŸ¯ å½±å“èŒƒå›´**  
- **åè®®å±‚**ï¼š`protocol.py`ï¼ˆæ¨¡å‹ã€åºåˆ—åŒ–ï¼‰ã€`utils.py`ï¼ˆæ–°å¢ `process_cached_tokens_details_from_ret`ï¼‰ã€‚  
- **è°ƒåº¦/æ‰§è¡Œå±‚**ï¼š`scheduler.py`ã€`schedule_batch.py`ã€`scheduler_output_processor_mixin.py`ã€`hiradix_cache.py`ã€`detokenizer_manager.py`ã€`tokenizer_manager.py`ã€‚  
- **Metrics**ï¼š`collector.py`ï¼ˆæ–°æ ‡ç­¾ã€åˆ†æ¥æºè®¡æ•°ï¼‰ã€‚  
- **OpenAI æ¥å£å®ç°**ï¼š`serving_chat.py`ã€`serving_completions.py`ï¼ˆsglext åˆå¹¶ã€æµå¼å“åº”ç»“æ„å˜æ›´ï¼‰ã€‚  

**ğŸ’¡ å…³æ³¨å»ºè®®**  

1. **å‘åå…¼å®¹**  
   - `sglext` ç”±åŸæ¥çš„ `sgl_ext` é‡å‘½åï¼Œä¸”ç§»é™¤ `sgl_ext` å­—æ®µã€‚æ—§ç‰ˆå®¢æˆ·ç«¯ä»æœŸå¾… `sgl_ext`ï¼Œå»ºè®®åœ¨æ–‡æ¡£ä¸­æ˜ç¡®å‡çº§è·¯å¾„æˆ–åœ¨ `model_serializer` ä¸­ä¿ç•™å…¼å®¹å±‚ï¼ˆå¦‚åœ¨ç¼ºå¤±æ—¶å¡«å…… `sgl_ext`ï¼‰ã€‚  
   - `return_cached_tokens_details` é»˜ `False`ï¼Œç¡®ä¿æœªå¼€å¯æ­¤æ ‡å¿—çš„è¯·æ±‚ä¸å—å½±å“ï¼›ä½†è‹¥æ—§å®¢æˆ·ç«¯è¯¯è§£æ `sglext`ï¼Œå¯èƒ½å‡ºç° `null` å­—æ®µå¯¼è‡´ JSON è§£æå¤±è´¥ã€‚  

2. **å­—æ®µåˆå§‹åŒ– & å¹¶å‘å®‰å…¨**  
   - `Req._cache_breakdown_computed` åªåœ¨ç¬¬ä¸€æ¬¡ `prepare_for_extend` è®¡ç®—ï¼Œåç»­ chunk ä»ä¼šä½¿ç”¨å·²å¡«å……çš„ `cached_tokens_*`ã€‚è¯·ç¡®è®¤åœ¨å¤šè½®å¹¶å‘è¯·æ±‚çš„ç”Ÿå‘½å‘¨æœŸé‡Œï¼Œ`req.prefix_indices`ã€`host_hit_length` ä¸ `storage_hit_length` çš„é¡ºåºå§‹ç»ˆæ»¡è¶³æ³¨é‡Šæ‰€è¿°ï¼Œå¦åˆ™å¯èƒ½å‡ºç°è´Ÿå€¼æˆ–é‡å¤è®¡æ•°ã€‚  
   - `TreeCache.prefetch_loaded_tokens_by_reqid` åœ¨ `check_prefetch_progress` ä¸ `release_aborted_request`ã€`reset` ä¸­å‡æœ‰æ¸…ç†ï¼Œå»ºè®®åŠ å…¥å•å…ƒæµ‹è¯•éªŒè¯å¼‚å¸¸è·¯å¾„ï¼ˆå¦‚ abort å‰å·² `pop_prefetch_loaded_tokens`ï¼‰ã€‚  

3. **æŒ‡æ ‡æ ‡ç­¾**  
   - `cached_tokens_total` ç°åœ¨è¦æ±‚ `cache_source` æ ‡ç­¾ï¼Œæ‰€æœ‰ç°æœ‰ç›‘æ§ä»ªè¡¨ç›˜éœ€è¦åŒæ­¥æ›´æ–°ã€‚è‹¥åç«¯æœªé…ç½® `enable_hicache_storage`ï¼Œä»ä¼šäº§ç”Ÿ `device`ã€`host` ä¸¤ä¸ªæ ‡ç­¾ï¼›è¯·æ£€æŸ¥ Prometheus ç«¯çš„ `labelnames` ä¸ä»£ç ä¿æŒä¸€è‡´ã€‚  

4. **æ–‡æ¡£ & ç¤ºä¾‹**  
   - åœ¨ API æ–‡æ¡£ä¸­è¡¥å…… `return_cached_tokens_details` ç”¨æ³•ã€`sglext.cached_tokens_details` çš„ JSON ç¤ºä¾‹ï¼ˆåŒ…æ‹¬ `storage_backend` ç¤ºä¾‹ï¼‰ã€‚  
   - è¯´æ˜ HiCache ä¸ L3â€‘storage ä¸¤çº§ç¼“å­˜çš„å¼€å¯æ–¹å¼ï¼ˆ`--enable-hicache`ã€`--enable-hicache-storage`ï¼‰ï¼Œä»¥åŠåœ¨ä¸å¯ç”¨ L3 æ—¶ `storage` ä¸ `storage_backend` å­—æ®µä¼šè¢«è‡ªåŠ¨å‰”é™¤ã€‚  

5. **æµ‹è¯•è¦†ç›–**  
   - æ·»åŠ  **éæµå¼** ä¸ **æµå¼** ä¸¤ç±»è¯·æ±‚çš„å•å…ƒæµ‹è¯•ï¼š  
     - å¼€å¯/å…³é—­ `return_cached_tokens_details` çš„è¿”å›å·®å¼‚ã€‚  
     - L3â€‘storage å¼€/å…³æ—¶ `cached_tokens_details` å­—æ®µæ˜¯å¦æ­£ç¡®å‡ºç°æˆ–è¢«è¿‡æ»¤ã€‚  
   - å¯¹ `collector.observe_one_finished_request` çš„æ–°è·¯å¾„è¿›è¡Œå›å½’ï¼Œç¡®ä¿ `cache_source` ç»´åº¦è®¡æ•°å‡†ç¡®ã€‚  

**æ€»ç»“**  
æœ¬æ¬¡æ”¹åŠ¨ä¸º HiCache å¢æ·»äº†ç»†ç²’åº¦ç¼“å­˜å‘½ä¸­ç»Ÿè®¡ï¼Œæ¶‰åŠåè®®ã€è°ƒåº¦ã€åº¦é‡ç­‰å¤šå±‚æ”¹å†™ã€‚æ ¸å¿ƒé€»è¾‘åŸºæœ¬å®Œæ•´ï¼Œä½†éœ€è¦æ³¨æ„å­—æ®µé‡å‘½åçš„å…¼å®¹æ€§ã€å¹¶å‘è®¡æ•°çš„è¾¹ç•Œæƒ…å†µä»¥åŠ Prometheus æ ‡ç­¾çš„åŒæ­¥æ›´æ–°ã€‚å»ºè®®åœ¨å‘å¸ƒå‰è¡¥å…¨æ–‡æ¡£ã€å®Œå–„å•å…ƒ/é›†æˆæµ‹è¯•å¹¶åœ¨å®éªŒç¯å¢ƒéªŒè¯æŒ‡æ ‡æ”¶æ•›åå†ä¸Šçº¿ã€‚

---

### enable ut test for xpu devices (#11712)
**SHA**: `495290a` | ğŸ”— [æŸ¥çœ‹æäº¤](https://github.com/sgl-project/sglang/commit/495290aefd1f5e8f7872a218473ac0b4c7dcc2f6)

**å˜æ›´æ¦‚è§ˆ**  
æœ¬æ¬¡æäº¤çš„æ ¸å¿ƒç›®æ ‡æ˜¯æŠŠåŸæœ¬ç¡¬ç¼–ç ä¸º CUDA çš„å®ç°ç»Ÿä¸€ä¸º **get_device()**ï¼Œå¹¶æ–°å¢å¯¹ **Intel XPU**ï¼ˆtorch.xpuï¼‰çš„æ£€æµ‹ä¸æ”¯æŒã€‚å…·ä½“åŒ…æ‹¬ï¼š

1. **sglang/srt/utils**  
   - æ–°å¢ `is_xpu`ã€`_is_xpu` æ ‡è¯†ã€‚  
   - å®ç° `get_device()`ã€`get_gpu_count()`ã€`empty_gpu_cache()`ã€`get_gpu_memory_gb()`ï¼Œåœ¨ PyTorchâ€¯2.8/2.9 å…¼å®¹ `torch.accelerator`ï¼Œå¹¶åœ¨ `torch.cuda`ã€`torch.xpu` ä¸¤å¥—åç«¯ä¹‹é—´åˆ‡æ¢ã€‚

2. **layers/moe/topk.py**  
   - é€šè¿‡ `_is_xpu` æ¡ä»¶å¯¼å…¥ `sg_kernel.topk_softmax`ï¼Œå®ç° XPU ä¸Šçš„ Topâ€‘K è®¡ç®—ã€‚

3. **å¤§é‡æµ‹è¯•åŠå·¥å…·ä»£ç **  
   - æ‰€æœ‰æ˜¾å¼ `"cuda"`ã€`"cpu"` çš„å¼ é‡åˆ›å»ºã€æ¨¡å‹åŠ è½½ã€`torch.cuda.empty_cache()`ã€`torch.cuda.device_count()` ç­‰å‡æ”¹ä¸º `get_device()`ã€`empty_gpu_cache()`ã€`get_gpu_count()`ã€‚  
   - æ–°å¢ `is_xpu`ã€`is_cuda` æ£€æµ‹ï¼Œä»¥ä¾¿åœ¨ CI ä¸­æ ¹æ®å®é™…ç¡¬ä»¶è·³è¿‡ä¸æ”¯æŒçš„ç”¨ä¾‹ã€‚  
   - å¯¹ `test_fused_moe.py`ã€`test_awq_dequant.py`ã€`test_gptqmodel_dynamic.py` ç­‰æ ¸å¿ƒç®—å­æµ‹è¯•ç»Ÿä¸€ä½¿ç”¨ç»Ÿä¸€è®¾å¤‡è·¯å¾„ã€‚

**å½±å“èŒƒå›´**  
- **è¿è¡Œæ—¶æ ¸å¿ƒ**ï¼š`sglang/srt/utils`ã€`sglang/srt/layers/moe/topk.py`ã€‚  
- **æ¨¡å‹åŠ è½½/æ¨ç†å…¥å£**ï¼šæ‰€æœ‰é€šè¿‡ `DeviceConfig`ã€`Engine`ã€`ModelOptModelLoader` ç­‰åˆå§‹åŒ–çš„è·¯å¾„å‡ä¼šå—åˆ°å½±å“ã€‚  
- **å•å…ƒ/é›†æˆæµ‹è¯•**ï¼šå‡ ä¹æ‰€æœ‰ `test/registered/*` ç›®å½•ä¸‹çš„æµ‹è¯•æ–‡ä»¶è¢«æ”¹å†™ï¼Œæ¶‰åŠæ³¨æ„åŠ›ã€MOEã€Mambaã€é‡åŒ–ã€æ¨ç†æœåŠ¡å™¨ç­‰æ¨¡å—ã€‚  
- **CI è„šæœ¬**ï¼šæ–°å¢å¯¹ XPU çš„æ³¨å†Œä¸è·³è¿‡é€»è¾‘ï¼Œå¯èƒ½éœ€è¦åœ¨ CI ç¯å¢ƒä¸­æä¾› XPU è®¾å¤‡ã€‚

**å»ºè®®**  

| è§’è‰² | å»ºè®® |
|------|------|
| **å¼€å‘è€…** | 1. ç¡®è®¤ `sglang/srt/utils.get_device()` åœ¨æ²¡æœ‰ XPU ä¸” CUDA ä¸å¯ç”¨æ—¶å®‰å…¨å›é€€åˆ° `"cpu"`ï¼Œé˜²æ­¢åœ¨ CIï¼ˆä»… CPUï¼‰ä¸Šå‡ºç° `torch.xpu` æœªå®šä¹‰çš„ AttributeErrorã€‚<br>2. å¯¹ `is_xpu()`ã€`_is_xpu` çš„å®ç°ä¿æŒä¸ `is_cuda()`ã€`_is_cuda` å¯¹ç§°ï¼Œé¿å…åœ¨ `torch` ç‰ˆæœ¬ä½äº 2.8 æ—¶è°ƒç”¨ä¸å­˜åœ¨çš„å±æ€§ã€‚<br>3. åœ¨ XPU ä¸Šçš„å…³é”®ç®—å­ï¼ˆå¦‚ `topk_softmax`ã€`fused_moe`ï¼‰æœªæä¾›å®ç°æ—¶ï¼Œéœ€è¦åœ¨å¯¼å…¥é˜¶æ®µç»™å‡ºæ˜ç¡®çš„ `ImportError` ä¿¡æ¯ï¼Œé˜²æ­¢ silent fallback å¯¼è‡´é”™è¯¯ç»“æœã€‚ |
| **æµ‹è¯•/CI** | 1. ä¸º XPU æ·»åŠ ä¸“é—¨çš„ CI ä½œä¸šï¼ŒéªŒè¯ `is_xpu` åˆ†æ”¯çš„è·¯å¾„æ˜¯å¦èµ°é€šï¼›è‹¥æš‚ä¸æ”¯æŒï¼Œå¯åœ¨ç›¸åº”æµ‹è¯•ä¸­ä½¿ç”¨ `@unittest.skipIf(not is_xpu(), "XPU not available")`ã€‚<br>2. `empty_gpu_cache()` å·²å…¼å®¹ `torch.accelerator`ï¼Œä½†åœ¨ XPU ç¯å¢ƒä¸‹ä»åº”æ£€æŸ¥ `torch.xpu.empty_cache` æ˜¯å¦å­˜åœ¨ã€‚<br>3. å…³æ³¨ `get_gpu_memory_gb()` åœ¨ XPU ä¸Šè¿”å›çš„å•ä½å’Œç²¾åº¦ï¼Œé˜²æ­¢åç»­å†…å­˜å ç”¨åˆ¤æ–­å‡ºç°è¯¯å·®ã€‚ |
| **ç”¨æˆ·** | 1. åœ¨å¯åŠ¨ SGLang æ—¶è¯·ä½¿ç”¨ `--device XPU`ï¼ˆæˆ–é€šè¿‡ç¯å¢ƒå˜é‡ï¼‰ï¼Œç³»ç»Ÿä¼šè‡ªåŠ¨åˆ‡æ¢åˆ° XPUï¼›è‹¥æœªæŒ‡å®šä¼šä½¿ç”¨ `get_device()` é»˜è®¤æ£€æµ‹ã€‚<br>2. å¯¹äºè‡ªè¡Œç¼–å†™çš„è„šæœ¬ï¼Œå»ºè®®ç»Ÿä¸€ä½¿ç”¨ `get_device()` è€Œä¸æ˜¯ç¡¬ç¼–ç  `"cuda"`ï¼Œä»¥è·å¾—æœ€å¹¿çš„ç¡¬ä»¶å…¼å®¹æ€§ã€‚ |

æ•´ä½“æ¥çœ‹ï¼Œæ­¤æ¬¡æ”¹åŠ¨æå¤§æå‡äº†é¡¹ç›®çš„ç¡¬ä»¶é€‚é…èƒ½åŠ›ï¼Œå”¯ä¸€éœ€è¦ç•™æ„çš„æ˜¯ **XPU ä»£ç è·¯å¾„çš„å®Œæ•´æ€§**ï¼ˆç®—å­å®ç°ã€å†…å­˜ç®¡ç†ï¼‰ä»¥åŠ **CI ä¸­çš„è®¾å¤‡æ£€æµ‹**ï¼Œå»ºè®®åœ¨åç»­ PR ä¸­è¡¥é½ XPUâ€‘only çš„å•å…ƒæµ‹è¯•ï¼Œä»¥é˜²å‡ºç°éšè—çš„å›å½’ã€‚ç¥è°ƒè¯•é¡ºåˆ©ï¼

---

#### ğŸŸ¢ ä½é‡è¦åº¦å˜æ›´ (14)

### entrypoint: support passing spaces_between_special_tokens per request (#17939)
**SHA**: `a6f53cc` | ğŸ”— [æŸ¥çœ‹æäº¤](https://github.com/sgl-project/sglang/commit/a6f53cc5e3ac7eb8ae9e4236d9834897684505ad)

**ğŸ¯ å˜æ›´ç±»å‹**ï¼šä»£ç é‡æ„  
**âš¡ é‡è¦ç¨‹åº¦**ï¼šğŸŸ¢ä½  
**ğŸ“‹ æ‘˜è¦**ï¼šåœ¨ OpenAI æ¥å£åè®®ä¸­æ–°å¢ `spaces_between_special_tokens` å‚æ•°ï¼Œæ”¯æŒåœ¨å•æ¬¡è¯·æ±‚çº§åˆ«é…ç½®ç‰¹æ®Šæ ‡è®°é—´çš„ç©ºæ ¼è¡Œä¸ºã€‚ä»…ä¿®æ”¹ `protocol.py`ï¼Œæ— åŠŸèƒ½å›é€€ã€‚

---

### [diffusion] fix: fix the bug of redundant memory usage on GPU-0 (#18221)
**SHA**: `4c40304` | ğŸ”— [æŸ¥çœ‹æäº¤](https://github.com/sgl-project/sglang/commit/4c403045ec690dbcf3b63a941356e004201ba337)

ğŸ¯ å˜æ›´ç±»å‹ï¼šä»£ç é‡æ„  
âš¡ é‡è¦ç¨‹åº¦ï¼šğŸŸ¢ä½  
ğŸ“‹ æ‘˜è¦ï¼šåœ¨ CUDA å¹³å°è·å–æ˜¾å­˜æ—¶ï¼Œæ–°å¢å¯¹ `torch.distributed` æ˜¯å¦å·²åˆå§‹åŒ–çš„æ£€æµ‹ï¼Œä½¿ç”¨å½“å‰è¿›ç¨‹çš„ rank ä½œä¸º `device_id`ï¼Œé¿å…å¤šå¡åˆ†å¸ƒå¼ç¯å¢ƒä¸‹å¯¹ GPUâ€‘0 çš„å†—ä½™å†…å­˜å ç”¨ã€‚

---

### Tiny fix for fp8 moe backend flashinfer_trtllm naming (#18243)
**SHA**: `a72f4f8` | ğŸ”— [æŸ¥çœ‹æäº¤](https://github.com/sgl-project/sglang/commit/a72f4f839c4dd0a7cab88f563c8e47dec01a2cf2)

**ğŸ¯ å˜æ›´ç±»å‹**ï¼šä»£ç é‡æ„  
**âš¡ é‡è¦ç¨‹åº¦**ï¼šğŸŸ¢ä½  
**ğŸ“‹ æ‘˜è¦**ï¼šå°† `Fp8GemmRunnerBackend` ä¸­çš„ `is_flashinfer` æ–¹æ³•é‡å‘½åä¸º `is_flashinfer_trtllm`ï¼Œå¹¶ç›¸åº”æ›´æ–°è°ƒç”¨å¤„ï¼Œç¡®ä¿å‘½åä¸ flashinferâ€‘trtllm åç«¯ä¸€è‡´ï¼ŒåŠŸèƒ½ä¿æŒä¸å˜ã€‚

---

### [diffusion] logging: downgrade default prompt log from info to debug (#17813)
**SHA**: `ce02df8` | ğŸ”— [æŸ¥çœ‹æäº¤](https://github.com/sgl-project/sglang/commit/ce02df85927b1c3c8df7fc9e11f0a3fa9c58c256)

**ğŸ¯ å˜æ›´ç±»å‹**ï¼šé…ç½®è°ƒæ•´  
**âš¡ é‡è¦ç¨‹åº¦**ï¼šğŸŸ¢ä½  
**ğŸ“‹ æ‘˜è¦**ï¼šå°† `schedule_batch.py` ä¸­é»˜è®¤çš„æç¤ºæ—¥å¿—ç­‰çº§ä» `info` é™ä¸º `debug`ï¼Œä»¥å‡å°‘æ™®é€šè¿è¡Œæ—¶çš„æ—¥å¿—å™ªå£°ã€‚

---

### [diffusion] update code owner (#18247)
**SHA**: `2e9d044` | ğŸ”— [æŸ¥çœ‹æäº¤](https://github.com/sgl-project/sglang/commit/2e9d0442e2e54f6e8f06f012ae58a700398a06a7)

**ğŸ¯ å˜æ›´ç±»å‹**ï¼šé…ç½®è°ƒæ•´  
**âš¡ é‡è¦ç¨‹åº¦**ï¼šğŸŸ¢ä½  
**ğŸ“‹ æ‘˜è¦**ï¼šåœ¨ `.github/CODEOWNERS` ä¸­ä¸º `python/sglang/jit_kernel/diffusion` æ·»åŠ ä»£ç æ‰€æœ‰è€…ï¼Œå¹¶å°† `multimodal_gen/runtime/layers` ä¸ `multimodal_gen/runtime/models/dits` çš„æ‰€æœ‰è€…åå•è¿½åŠ  `@yingluosanqian`ã€‚

---

### Support Markdown/Notebook-Friendly Documentation Export for Downstream Integration (copy all markdown and rst files) (#18223)
**SHA**: `669a9bd` | ğŸ”— [æŸ¥çœ‹æäº¤](https://github.com/sgl-project/sglang/commit/669a9bd1809a344fae5b9d962d2cd6f842cb50c1)

**ğŸ¯ å˜æ›´ç±»å‹**ï¼šæ–‡æ¡£æ›´æ–°  
**âš¡ é‡è¦ç¨‹åº¦**ï¼šğŸŸ¢ä½  
**ğŸ“‹ æ‘˜è¦**ï¼šåœ¨ `docs/Makefile` çš„ `markdown` ç›®æ ‡ä¸­æ–°å¢æ­¥éª¤ï¼Œå¤åˆ¶å­ç›®å½•ä¸‹çš„æ‰€æœ‰ `.md`ã€`.rst` æ–‡ä»¶ï¼ˆæ’é™¤æ ¹ç›®å½•ï¼‰ï¼Œå¹¶ä¿æŒåŸç›¸å¯¹è·¯å¾„ï¼ŒåŒæ—¶ç»§ç»­å°†æ‰€æœ‰ `.ipynb` è½¬ä¸º Markdownã€‚è¿™æ ·å¯ä¸ºä¸‹æ¸¸é›†æˆæä¾›å®Œæ•´çš„æ–‡æ¡£å¯¼å‡ºã€‚

---

### [Docs] fix readme typo (#18207)
**SHA**: `1f72f66` | ğŸ”— [æŸ¥çœ‹æäº¤](https://github.com/sgl-project/sglang/commit/1f72f66c6d6ef0eff589230b9ca06cf4e44ecdd2)

**ğŸ¯ å˜æ›´ç±»å‹**ï¼šæ–‡æ¡£æ›´æ–°  
**âš¡ é‡è¦ç¨‹åº¦**ï¼šğŸŸ¢ä½  
**ğŸ“‹ æ‘˜è¦**ï¼šå°† README ä¸­ â€œ2025/01â€ çš„æ—¥æœŸä¿®æ­£ä¸º â€œ2026/01â€ï¼Œçº æ­£äº†æ—¶é—´æˆ³çš„ç¬”è¯¯ã€‚

---

### Update weight rename check for Qwen3 Embeddings (#17535)
**SHA**: `793bf9f` | ğŸ”— [æŸ¥çœ‹æäº¤](https://github.com/sgl-project/sglang/commit/793bf9fc06499cb1ba236444a7a3dde0ea5b7e49)

**ğŸ¯ å˜æ›´ç±»å‹**ï¼šä»£ç é‡æ„  
**âš¡ é‡è¦ç¨‹åº¦**ï¼šğŸŸ¢ä½  
**ğŸ“‹ æ‘˜è¦**ï¼šåœ¨ Qwen3 æ¨¡å‹çš„ `load_weights` ä¸­ï¼Œæ”¹è¿›äº†æƒé‡åç§°é‡å‘½åæ£€æŸ¥é€»è¾‘ï¼šå¯¹ä¸ä»¥ `model.` å¼€å¤´ä¸”ä»¥ `layers.`ã€`embed_tokens.` æˆ– `norm.` å¼€å¤´çš„æƒé‡ï¼Œç»Ÿä¸€åœ¨å‰é¢æ·»åŠ  `model.` å‰ç¼€ï¼Œä»¥ç¡®ä¿åŠ è½½è¿‡ç¨‹çš„å…¼å®¹æ€§ã€‚

---

### add streaming parallel tool call test case (#18097)
**SHA**: `e867040` | ğŸ”— [æŸ¥çœ‹æäº¤](https://github.com/sgl-project/sglang/commit/e867040fc6624445ffa4b567c157b598d9aed2c8)

**ğŸ¯ å˜æ›´ç±»å‹**ï¼šæµ‹è¯•ä¿®æ”¹  
**âš¡ é‡è¦ç¨‹åº¦**ï¼šğŸŸ¢ä½  
**ğŸ“‹ æ‘˜è¦**ï¼šåœ¨ `tool_call_test_runner.py` ä¸­æ–°å¢ `test_streaming_parallel` æ ‡å¿—å¹¶å®ç°å¯¹åº”æµ‹è¯•ï¼Œç”¨äºéªŒè¯åœ¨æµå¼ï¼ˆ`stream=True`ï¼‰ä¸” `tool_choice=auto` æ—¶èƒ½å¤Ÿè¿”å›å¤šä¸ªå·¥å…·è°ƒç”¨ã€‚æ–°å¢æµ‹è¯•å‡½æ•°å¹¶åœ¨æµ‹è¯•åˆ—è¡¨ä¸­æ³¨å†Œã€‚

---

### [diffusion] hardware: support diffusion models on MTGPU (doc, 6/N) (#17346)
**SHA**: `7de650c` | ğŸ”— [æŸ¥çœ‹æäº¤](https://github.com/sgl-project/sglang/commit/7de650c83c4d63b9107184bd5cf36303d89e8d28)

**ğŸ¯ å˜æ›´ç±»å‹**ï¼šæ–‡æ¡£æ›´æ–°  
**âš¡ é‡è¦ç¨‹åº¦**ï¼šğŸŸ¢ ä½  
**ğŸ“‹ æ‘˜è¦**ï¼šæ–°å¢å¯¹ Moore Threadsï¼ˆMTGPUï¼‰MUSA è½¯ä»¶æ ˆçš„æ”¯æŒè¯´æ˜ï¼ŒåŒ…æ‹¬å®‰è£…æŒ‡å—ã€å¿«é€Ÿæµ‹è¯•ç¤ºä¾‹ï¼Œå¹¶åœ¨ç°æœ‰æ–‡æ¡£ä¸­åŠ å…¥ç›¸åº”æŒ‡å¼•ã€‚

---

### [Diffusion] Only import sgl_kernel in custom op cuda path (SiluAndMul and RMSNorm) (#15592)
**SHA**: `acf724b` | ğŸ”— [æŸ¥çœ‹æäº¤](https://github.com/sgl-project/sglang/commit/acf724b036c595292b036942db69fb169efffc45)

**ğŸ¯ å˜æ›´ç±»å‹**ï¼šä»£ç é‡æ„  
**âš¡ é‡è¦ç¨‹åº¦**ï¼šğŸŸ¢ä½  
**ğŸ“‹ æ‘˜è¦**ï¼šåœ¨æ¿€æ´»å±‚å’Œå±‚å½’ä¸€åŒ–å®ç°ä¸­ï¼Œæ–°å¢å¯¹ `current_platform` çš„æ£€æµ‹ï¼Œä»…åœ¨ CUDAï¼ˆæˆ– HIPï¼‰ç¯å¢ƒä¸‹æ‰å¯¼å…¥ `sgl_kernel`ï¼Œé¿å…åœ¨é GPU ç¯å¢ƒåŠ è½½ CUDA ä¸“ç”¨æ‰©å±•ã€‚

---

### [CI][NPU] Bugfix import sgl-kernel error (#18173)
**SHA**: `d48bbe3` | ğŸ”— [æŸ¥çœ‹æäº¤](https://github.com/sgl-project/sglang/commit/d48bbe3beda74106e27ab4e83eebbc235a5fbd59)

**ğŸ¯ å˜æ›´ç±»å‹**ï¼šå…¶ä»–  
**âš¡ é‡è¦ç¨‹åº¦**ï¼šğŸŸ¢ä½  
**ğŸ“‹ æ‘˜è¦**ï¼šåœ¨ `flashinfer_trtllm.py` ä¸­æ–°å¢ `is_cuda_alike` åˆ¤æ–­ï¼Œä¿®å¤åœ¨ NPU ç¯å¢ƒä¸‹æœªèƒ½æ­£ç¡®å¯¼å…¥ `sgl_kernel` çš„é—®é¢˜ï¼›è‹¥é FlashInfer ä¸ SM120 æ”¯æŒä¸”ä¸º CUDA ç±»è®¾å¤‡ï¼Œåˆ™ä½¿ç”¨ `sgl_kernel` çš„ `scaled_fp4_quant`ï¼Œå¦åˆ™è®¾ä¸º `None`ã€‚

---

### ci: improve docker for cu13 builds (#18194)
**SHA**: `0a69256` | ğŸ”— [æŸ¥çœ‹æäº¤](https://github.com/sgl-project/sglang/commit/0a6925639b3f2d7b70503f06170eb490c09dac4c)

**ğŸ¯ å˜æ›´ç±»å‹**ï¼šé…ç½®è°ƒæ•´  
**âš¡ é‡è¦ç¨‹åº¦**ï¼šğŸŸ¢ä½  
**ğŸ“‹ æ‘˜è¦**ï¼šåœ¨ CI å·¥ä½œæµ `release-docker-cu13-framework.yml` ä¸­æ–°å¢å¯é€‰è¾“å…¥ `flashinfer_version`ï¼ˆé»˜è®¤ 0.6.1ï¼‰ï¼Œå¹¶å°†å…¶ä½œä¸ºæ„å»ºå‚æ•°ä¼ é€’ï¼›åŒæ­¥æ›´æ–° Dockerfile ä¸­é»˜è®¤çš„ `FLASHINFER_VERSION` ä¸º 0.6.2ï¼Œä»¥æ”¯æŒ CUDAâ€‘13 é•œåƒçš„çµæ´» FlashInfer ç‰ˆæœ¬æ„å»ºã€‚

---

### Revert broken sgl_kernel exclusion patterns in paths-filter (#18193)
**SHA**: `0db6fd4` | ğŸ”— [æŸ¥çœ‹æäº¤](https://github.com/sgl-project/sglang/commit/0db6fd4dbec5e9eaac6ee35dfba257720ae65ea5)

**ğŸ¯ å˜æ›´ç±»å‹**ï¼šé…ç½®è°ƒæ•´  
**âš¡ é‡è¦ç¨‹åº¦**ï¼šğŸŸ¢ ä½  
**ğŸ“‹ æ‘˜è¦**ï¼šæ’¤é”€åœ¨å¤šä¸ª CI å·¥ä½œæµä¸­å¯¹ `sgl-kernel` çš„é”™è¯¯æ’é™¤è§„åˆ™ï¼Œæ¢å¤å¯¹è¯¥ç›®å½•å…¨éƒ¨æ–‡ä»¶çš„è·¯å¾„è¿‡æ»¤ã€‚

---

