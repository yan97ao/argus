# æ¯æ—¥æ›´æ–°æŠ¥å‘Šï¼ˆ2026-01-31ï¼‰

## sgl-project/sglang

| æäº¤æ—¶é—´ | ä½œè€… | æäº¤ä¿¡æ¯ |
|----------|------|----------|
| 2026-01-31 23:01:29 | b8zhong | [Fix] Revert back to using CUTLASS `mm_fp4` backend (#17369) |
| 2026-01-31 20:22:31 | Mick | [diffusion] refactor: split component_loader into component-wise files (#17820) |
| 2026-01-31 17:01:55 | Lianmin Zheng | [Auto Sync] Update linear.py to assert shapes (20260130) (#17966) |
| 2026-01-31 17:00:40 | Lianmin Zheng | Add launch_command assignment in crash dump (#17967) |
| 2026-01-31 15:56:26 | b8zhong | [Fix] Triton TP MoE Dpsk V3/Qwen3 Coder with SwapAB (#17965) |
| 2026-01-31 14:30:11 | Zheng Wengang | [EPD][Perf] parallelize ZMQ send for encode server (#16487) |
| 2026-01-31 13:59:00 | jeff | Fix OOM in DeepSeek weight loading by deferring dict(weights) materialization (#17744) |
| 2026-01-31 13:42:21 | Yifan Cui | Reduce topk kernel shared memory from 128KB to 32KB for better occupancy (#17747) |
| 2026-01-31 13:09:23 | Hudson Xing | add reasoning_tokens usage test for tool call (#18022) |
| 2026-01-31 12:42:11 | husf | ã€docsã€‘ã€NPUã€‘Update Expert Parallelism docs for Ascend NPU (#17940) |
| 2026-01-31 12:33:32 | R0CKSTAR | Fix .gitignore may ignore files like core_attention.py (#18021) |
| 2026-01-31 12:01:52 | Mohammad Miadh Angkad | Fix cuBLAS >=12.9 detection for cu12/cu13 package naming (#17766) |
| 2026-01-31 11:47:27 | Xiaoyu Zhang | [Diffusion] Fix FLUX.1-schnell time embedding argument mismatch (#17988) |
| 2026-01-31 11:12:07 | kk | Add ROCm + Mori docker build instructions in rocm.Dockerfile (#18018) |
| 2026-01-31 11:06:58 | 22dimensions | [NPU] fix sgl-kernel-npu package url error in npu.Dockerfile (#18017) |
| 2026-01-31 10:10:23 | Tiance Wang | doc update for CANN version (#18014) |
| 2026-01-31 09:09:13 | Bi Xue | [sglang] fix mm token padded value overlap with text token id (#17781) |
| 2026-01-31 08:49:38 | JiaruiChang5268 | [NPU] support llama-3.2-11B-vision-instruct mode for NPU (#17492) |
| 2026-01-31 03:57:42 | Siyuan Chen | [BugFix] Fix server crashes when req.grammar and ngram spec are enabled (#17585) |
| 2026-01-31 01:02:12 | Sam (Kesen Li) | Optimize GDN decode for Qwen3 Next (#17094) |

### ğŸ“Š ç»Ÿè®¡æ‘˜è¦
> æœ¬æ—¥å…± 20 ä¸ªæäº¤ | ğŸ”´é«˜ 1 | ğŸŸ¡ä¸­ 3 | ğŸŸ¢ä½ 16
## ğŸ“‹ ç›®å½•

- [sgl-project/sglang](#sgl-project-sglang)
  - [ğŸ“Š ç»Ÿè®¡æ‘˜è¦](#-ç»Ÿè®¡æ‘˜è¦)
  - [ğŸ”´ é«˜é‡è¦åº¦å˜æ›´ (1)](#-ğŸ”´-é«˜é‡è¦åº¦å˜æ›´-1)
    - [[diffusion] refactor: split component_loader into compone...](#1a006c2)
  - [ğŸŸ¡ ä¸­é‡è¦åº¦å˜æ›´ (3)](#-ğŸŸ¡-ä¸­é‡è¦åº¦å˜æ›´-3)
    - [[Fix] Triton TP MoE Dpsk V3/Qwen3 Coder with SwapAB (#17965)](#22498e1)
    - [[NPU] support llama-3.2-11B-vision-instruct mode for NPU ...](#e86476a)
    - [[BugFix] Fix server crashes when req.grammar and ngram sp...](#578b119)
  - [ğŸŸ¢ ä½é‡è¦åº¦å˜æ›´ (16)](#-ğŸŸ¢-ä½é‡è¦åº¦å˜æ›´-16)
    - [[Fix] Revert back to using CUTLASS `mm_fp4` backend (#17369)](#ef134d4)
    - [[Auto Sync] Update linear.py to assert shapes (20260130) ...](#7412ceb)
    - [Add launch_command assignment in crash dump (#17967)](#0e18460)
    - [[EPD][Perf] parallelize ZMQ send for encode server (#16487)](#a4df95c)
    - [Fix OOM in DeepSeek weight loading by deferring dict(weig...](#04efd03)
    - [Reduce topk kernel shared memory from 128KB to 32KB for b...](#45fe51a)
    - [add reasoning_tokens usage test for tool call (#18022)](#c72bf50)
    - [ã€docsã€‘ã€NPUã€‘Update Expert Parallelism docs for Ascend NPU ...](#c52578c)
    - [Fix .gitignore may ignore files like core_attention.py (#...](#dc77def)
    - [Fix cuBLAS >=12.9 detection for cu12/cu13 package naming ...](#d0d9cec)
    - [[Diffusion] Fix FLUX.1-schnell time embedding argument mi...](#22aad4e)
    - [Add ROCm + Mori docker build instructions in rocm.Dockerf...](#ec76c39)
    - [[NPU] fix sgl-kernel-npu package url error in npu.Dockerf...](#ee3058c)
    - [doc update for CANN version (#18014)](#f6a4ff7)
    - [[sglang] fix mm token padded value overlap with text toke...](#5d00150)
    - [Optimize GDN decode for Qwen3 Next (#17094)](#81449b4)
#### ğŸ”´ é«˜é‡è¦åº¦å˜æ›´ (1)

### [diffusion] refactor: split component_loader into component-wise files (#17820)
**SHA**: `1a006c2` | ğŸ”— [æŸ¥çœ‹æäº¤](https://github.com/sgl-project/sglang/commit/1a006c2a0dea4856cdbc907cc96fade370f33b35)

**ğŸ¯ å˜æ›´ç±»å‹**ï¼šé‡æ„ / æ¶æ„å˜æ›´  
**âš¡ é‡è¦ç¨‹åº¦**ï¼šğŸ”´é«˜  

**ğŸ“‹ å˜æ›´æ‘˜è¦**  
- å°†åŸæœ¬è‡ƒè‚¿çš„ `component_loader.py` æ‹†åˆ†ä¸ºå¤šä¸ªä¸“èŒæ–‡ä»¶ï¼ˆadapterã€bridgeã€vaeã€schedulerã€transformerã€text_encoderã€image_encoderã€vl_encoder ç­‰ï¼‰ï¼Œæ¯ä¸ªæ–‡ä»¶å®ç°å¯¹åº”ç»„ä»¶çš„åŠ è½½é€»è¾‘ã€‚  
- å¼•å…¥ç»Ÿä¸€çš„ **ComponentLoader** åŸºç±»ï¼Œå¹¶é€šè¿‡ `ComponentLoader.for_component_type()` åŠ¨æ€å‘ç°ã€æ³¨å†Œã€å®ä¾‹åŒ–å¯¹åº”çš„å­ç±»ã€‚  
- æ–°å¢ `loader/utils.py`ï¼Œæä¾›é€šç”¨å·¥å…·ï¼ˆ`skip_init_modules`, `_list_safetensors_files`, `_clean_hf_config_inplace`, `component_name_to_loader_cls` ç­‰ï¼‰ï¼Œå¹¶å®ç° **lazyâ€‘registration**ï¼ˆ`_ensure_loaders_registered`ï¼‰ä»¥è‡ªåŠ¨å¯¼å…¥åŒç›®å½•ä¸‹çš„ loader å­æ¨¡å—ã€‚  
- æ›´æ–° `PipelineComponentLoader` æ¥å£ä¸º `load_component`ï¼Œå¹¶ç›¸åº”ä¿®æ”¹ `ComposedPipelineBase.load_modules` ä¸­çš„å˜é‡åä¸è°ƒç”¨æ–¹å¼ã€‚  
- æ‰€æœ‰å·²æœ‰çš„åŠ è½½è·¯å¾„ï¼ˆVAEã€Transformerã€Adapterã€Bridgeã€Schedulerã€Visionâ€‘Language Encoderï¼‰è¿ç§»åˆ°ç‹¬ç«‹æ–‡ä»¶ï¼Œä¿æŒåŸæœ‰åŠŸèƒ½ä¸å˜ã€‚  

**ğŸ¯ å½±å“èŒƒå›´**  
- **åŠ è½½å­ç³»ç»Ÿ**ï¼š`sglang.multimodal_gen.runtime.loader` åŒ…ä¸‹çš„å…¨éƒ¨ç»„ä»¶ã€‚  
- **ç®¡çº¿åˆå§‹åŒ–**ï¼š`sglang.multimodal_gen.runtime.pipelines_core.composed_pipeline_base`ï¼ˆæ¨¡å—åŠ è½½ï¼‰ã€‚  
- **è‹¥å¹² stage å®ç°**ï¼š`decoding.py`ï¼ˆVAEï¼‰ä¸ `denoising.py`ï¼ˆTransformerï¼‰ä¾èµ–æ–°æ–‡ä»¶è·¯å¾„ã€‚  
- **å·¥å…·å‡½æ•°**ï¼š`utils.py` ä¸­çš„ `skip_init_modules`ã€`_list_safetensors_files`ã€`get_memory_usage_of_component` è¢«å¤šä¸ª loader å¤ç”¨ã€‚  

---

## ğŸ” æŠ€æœ¯æ´å¯Ÿ  

### 1. æ¶æ„å½±å“
| ç»´åº¦ | æ­£é¢å½±å“ | è´Ÿé¢/æ³¨æ„äº‹é¡¹ |
|------|----------|----------------|
| **æ¨¡å—åŒ–** | æ¯ç§æ¨¡å‹ç»„ä»¶çš„åŠ è½½é€»è¾‘ç‹¬ç«‹ï¼Œä»£ç è¡Œæ•°ä¸‹é™ï¼ˆå•æ–‡ä»¶ 70â€‘120 è¡Œï¼‰ï¼Œæ˜“äºç»´æŠ¤ã€æ·»åŠ æ–°ç»„ä»¶ï¼ˆåªéœ€æ–°å¢æ–‡ä»¶å¹¶å£°æ˜ `component_names`ï¼‰ã€‚ | éœ€è¦ä¿è¯ **æ‰€æœ‰å­ç±»åœ¨é¦–æ¬¡ä½¿ç”¨å‰å·²è¢«å¯¼å…¥**ï¼Œå¦åˆ™ `component_name_to_loader_cls` ä¸ºç©ºå¯¼è‡´å›é€€åˆ° `GenericComponentLoader`ï¼ˆæ€§èƒ½/åŠŸèƒ½å›é€€ï¼‰ã€‚ |
| **æ³¨å†Œæœºåˆ¶** | `ComponentLoader.__init_subclass__` è‡ªåŠ¨æŠŠ `component_names` â†’ loader class æ³¨å†Œåˆ°å…¨å±€å­—å…¸ï¼Œé¿å…æ‰‹åŠ¨ç»´æŠ¤æ˜ å°„è¡¨ã€‚ | å…¨å±€å­—å…¸æ˜¯ **mutableçš„å•ä¾‹**ï¼Œåœ¨å¤šè¿›ç¨‹/å¤šçº¿ç¨‹ç¯å¢ƒä¸‹é¦–æ¬¡å¹¶å‘è°ƒç”¨å¯èƒ½å‡ºç° race conditionï¼ˆä¸¤ä¸ªè¿›ç¨‹åŒæ—¶å°è¯•æ³¨å†Œï¼‰ï¼Œè™½ç„¶æ¦‚ç‡ä½ï¼Œä½†åœ¨åˆ†å¸ƒå¼å¯åŠ¨æ—¶åº”æ³¨æ„ã€‚ |
| **å‘åå…¼å®¹** | ä¿ç•™äº† `ComponentLoader.for_component_type` çš„ç­¾åï¼Œåªæ˜¯æ”¹åä¸º â€œcomponentâ€ã€‚ | æ—§ä»£ç ä»å¯èƒ½è°ƒç”¨å·²åˆ é™¤çš„ `ComponentLoader.for_module_type`ï¼Œæˆ–ç›´æ¥ import æ—§ç±»è·¯å¾„ï¼ˆå¦‚ `from .component_loader import VAELoader`ï¼‰ï¼Œä¼šè§¦å‘ `ImportError`ã€‚éœ€è¦åœ¨å…¨é¡¹ç›®æœç´¢å¹¶æ›´æ–°ã€‚ |
| **åŠ è½½è·¯å¾„ç»Ÿä¸€** | `PipelineComponentLoader.load_component` ç»Ÿä¸€æ—¥å¿—ä¸é”™è¯¯å¤„ç†ï¼Œè¿”å› `(module, memory_usage)` ä¸åŸå®ç°ä¿æŒä¸€è‡´ã€‚ | `load_modules` ä¸­çš„å˜é‡åæ”¹ä¸º `loaded_components`ï¼Œè‹¥å…¶å®ƒä»£ç ä»ä½¿ç”¨æ—§ `components` å˜é‡ä¼šå‡ºç°æœªå®šä¹‰é”™è¯¯ã€‚ |

### 2. æ€§èƒ½å½±å“
- **åŠ è½½æ—¶é—´**ï¼šæ–°å¢çš„ **lazy import** (`_ensure_loaders_registered`) åœ¨ç¬¬ä¸€æ¬¡è°ƒç”¨ `for_component_type` æ—¶éå†ç›®å½•å¹¶ `importlib.import_module`ï¼Œç›¸å½“äºä¸€æ¬¡é¢å¤–çš„ **æ•°åæ¯«ç§’** I/O+ç¼–è¯‘ï¼Œä¹‹åç¼“å­˜ç”Ÿæ•ˆï¼Œå¯¹å®é™…æ¨ç†æ€§èƒ½æ— å½±å“ã€‚  
- **å†…å­˜å ç”¨**ï¼šæ‹†åˆ†æ–‡ä»¶æœ¬èº«ä¸æ”¹å˜æ¨¡å‹æƒé‡åŠ è½½æ–¹å¼ï¼›`skip_init_modules` ä»åœ¨ `utils.py` ä¸­å®ç°ï¼Œè¡Œä¸ºä¿æŒä¸å˜ã€‚  
- **å¹¶è¡Œ/åˆ†å¸ƒå¼**ï¼šFSDPã€HSâ€‘DP ç­‰åŠ è½½è·¯å¾„ä¿æŒåŸæœ‰å®ç°ï¼Œæœªè¢«æ”¹åŠ¨ã€‚  

### 3. å®‰å…¨è€ƒè™‘
| é£é™© | æè¿° | ç¼“è§£ |
|------|------|------|
| **åŠ¨æ€å¯¼å…¥è‡ªå®šä¹‰æ¨¡å‹ä»£ç ** (`importlib.util.spec_from_file_location`) | å¯¹ VAEã€Bridgeã€Vocoder ç­‰æ”¯æŒ `auto_map` çš„è‡ªå®šä¹‰ç±»æ—¶ï¼Œä¼šç›´æ¥æ‰§è¡Œæ¨¡å‹ä»“åº“ä¸­çš„ Python è„šæœ¬ã€‚è‹¥æ¨¡å‹æ¥æºä¸å¯ä¿¡ï¼Œå¯èƒ½æ‰§è¡Œæ¶æ„ä»£ç ã€‚ | ä¸åŸå®ç°ç›¸åŒï¼›å»ºè®®åœ¨éƒ¨ç½²ç¯å¢ƒä»…å…è®¸å—ä¿¡ä»»çš„æ¨¡å‹ç›®å½•ï¼Œæˆ–åœ¨å®¹å™¨ä¸­ä½¿ç”¨åªè¯»æŒ‚è½½ + `PYTHONPATH` é™åˆ¶ã€‚ |
| **è·¯å¾„éå†** (`_list_safetensors_files`) | ä½¿ç”¨ `glob(os.path.join(model_path, "*.safetensors"))`ï¼Œè‹¥ `model_path` è¢«æ³¨å…¥æ¶æ„è·¯å¾„ï¼ˆå¦‚ `../../etc/passwd`ï¼‰å¯èƒ½è¯»å–éæ¨¡å‹æ–‡ä»¶ã€‚ | `ServerArgs` ä¸­çš„ `model_path` é€šå¸¸æ¥æºäºé…ç½®æ–‡ä»¶æˆ– CLIï¼Œéœ€å¯¹å…¶åšç»å¯¹è·¯å¾„æ ¡éªŒæˆ–é™åˆ¶åœ¨é¢„è®¾æ ¹ç›®å½•ã€‚ |
| **å…¨å±€æ³¨å†Œè¡¨æ³„éœ²** (`component_name_to_loader_cls`) | ä»»ä½•ä»£ç éƒ½å¯ä¿®æ”¹è¯¥å­—å…¸ï¼Œæ½œåœ¨çš„ **ä¾›åº”é“¾æ”»å‡»**ï¼ˆæ¶æ„æ’ä»¶æ³¨å…¥æ–°çš„ loaderï¼‰ã€‚ | åœ¨ç”Ÿäº§ç¯å¢ƒå¯å°†å­—å…¸è®¾ä¸º `MappingProxyType` é˜²æ­¢è¿è¡Œæ—¶ä¿®æ”¹ï¼Œæˆ–åœ¨åˆå§‹åŒ–ååˆ é™¤ `__setitem__`ã€‚ |

### 4. å¯ç»´æŠ¤æ€§ä¸å¯æ‰©å±•æ€§
- **æ–°å¢ç»„ä»¶**ï¼šåªéœ€å®ç°å­ç±»ã€å£°æ˜ `component_names = ["my_component"]`ã€`expected_library = "diffusers"`ï¼Œå¹¶æ”¾åœ¨ `loader/` ç›®å½•ã€‚æ— éœ€æ”¹åŠ¨ä¸­å¿ƒæ˜ å°„è¡¨ã€‚  
- **æ–‡æ¡£/IDE æ”¯æŒ**ï¼š`ComponentLoader.for_component_type` é€šè¿‡ **type hints**ï¼ˆè¿”å› `ComponentLoader`ï¼‰ä½¿ IDE èƒ½æç¤ºå¯ç”¨å­ç±»ã€‚  
- **æµ‹è¯•**ï¼šåŸæœ‰çš„ `loader.*` å•å…ƒæµ‹è¯•éœ€è¦æ›´æ–°å¯¼å…¥è·¯å¾„ï¼›æ¨èä¸ºæ¯ä¸ªå­ç±»æ–°å¢ **smoke test**ï¼ˆä»…å®ä¾‹åŒ–å¹¶è°ƒç”¨ `load_customized` çš„å¼‚å¸¸åˆ†æ”¯ï¼‰ï¼Œç¡®ä¿æ³¨å†Œè¡¨æ­£ç¡®ã€‚  

---

## âš ï¸ æ½œåœ¨é£é™©  

| é£é™©ç‚¹ | å¯èƒ½åæœ | è§¦å‘æ¡ä»¶ | å»ºè®®çš„é˜²å¾¡æªæ–½ |
|--------|----------|----------|----------------|
| **æœªèƒ½è‡ªåŠ¨æ³¨å†Œå­ç±»** | `ComponentLoader.for_component_type` å›é€€åˆ° `GenericComponentLoader`ï¼Œå¯¼è‡´åŠ è½½çš„æ¨¡å‹ä½¿ç”¨ **åŸå§‹ Diffusers/Transformers** å®ç°ï¼Œæ€§èƒ½ä¸‹é™æˆ–ä¸å…¼å®¹è‡ªå®šä¹‰æƒé‡ã€‚ | é¦–æ¬¡è°ƒç”¨å‘ç”Ÿåœ¨å­è¿›ç¨‹æœªæ‰§è¡Œ `ComponentLoader._ensure_loaders_registered()`ï¼ˆå¦‚åœ¨ `fork` åç›´æ¥è°ƒç”¨ï¼‰ã€‚ | åœ¨æ¯ä¸ªè¿›ç¨‹å¯åŠ¨å…¥å£ï¼ˆå¦‚ `main.py`ï¼‰æ˜¾å¼è°ƒç”¨ `ComponentLoader._ensure_loaders_registered()`ï¼›æˆ–å°†æ³¨å†Œè¿‡ç¨‹æ”¾å…¥ `__init__` æ¨¡å—çº§æ‰§è¡Œã€‚ |
| **å¾ªç¯å¯¼å…¥ / å¯¼å…¥é¡ºåºé”™è¯¯** | `ImportError` æˆ–å±æ€§æœªå®šä¹‰ï¼ˆå¦‚ `ComponentLoader` æœªå®šä¹‰çš„ `target_device`ï¼‰ã€‚ | æŸå­åŠ è½½å™¨åœ¨å¯¼å…¥æ—¶ä¾èµ–å¦ä¸€ä¸ªå­åŠ è½½å™¨ä¸”ä¸¤è€…ç›¸äº’ importã€‚ | ä¿æŒæ¯ä¸ªå­åŠ è½½å™¨ä»…ä¾èµ–å…¬å…±æ¨¡å— (`component_loader

---

#### ğŸŸ¡ ä¸­é‡è¦åº¦å˜æ›´ (3)

### [Fix] Triton TP MoE Dpsk V3/Qwen3 Coder with SwapAB (#17965)
**SHA**: `22498e1` | ğŸ”— [æŸ¥çœ‹æäº¤](https://github.com/sgl-project/sglang/commit/22498e10c06a281a46e707fcb0cf3a843757363d)

**ğŸ¯ å˜æ›´ç±»å‹**ï¼šåŠŸèƒ½å¢å¼º / Bug ä¿®å¤  
**âš¡ é‡è¦ç¨‹åº¦**ï¼šğŸŸ¡ ä¸­  

**ğŸ“‹ å˜æ›´æ‘˜è¦**  
1. ä¸º Tritonâ€‘TP MoE çš„åŸºå‡†è„šæœ¬ `benchmark/kernels/fused_moe_triton/tuning_fused_moe_triton_sep.py` æ–°å¢ `ep_size` å‚æ•°ï¼Œå¹¶åœ¨ `prepare` é˜¶æ®µå¯¹ `topk_ids` è¿›è¡Œ **å…¨å±€â€‘>å±€éƒ¨** æ˜ å°„ï¼Œå®ç°å¯¹ Expert Parallelï¼ˆEPï¼‰çš„æ”¯æŒã€‚  
2. å°† `ep_size` å‚æ•°å‘ä¸Šä¼ é€’è‡³ `benchmark`ã€`tune`ã€`cmp_configs`ã€`main` ç­‰å…¥å£å‡½æ•°ï¼Œç¡®ä¿ CLI å¯æ§åˆ¶ã€‚  
3. æ–°å¢å¤šå¥—é’ˆå¯¹ NVIDIA H200ï¼ˆfp8_w8a8ï¼‰åœ¨ä¸åŒ (E,N) ç»„åˆå’Œ blockâ€‘shape ä¸‹çš„è°ƒä¼˜é…ç½® JSONï¼ˆæ­£å‘ä¸ downâ€‘sampling ç‰ˆï¼‰ï¼Œä¸°å¯Œç¡¬ä»¶â€‘æ¨¡å‹åŒ¹é…åº“ã€‚  
4. åœ¨ `fused_moe_triton_kernels.py` ä¸­ï¼š  
   - ç§»é™¤ `get_device_name` ä¾èµ–ï¼Œæ”¹ä¸ºç›´æ¥æ£€æµ‹ **SM90** æ”¯æŒï¼›  
   - å¼•å…¥ `is_batch_invariant_mode_enabled()`ï¼Œåœ¨ Batchâ€‘Invariant æ¨¡å¼ä¸‹å…³é—­ `swap_ab`ï¼›  
   - ç®€åŒ– `should_enable_swap_ab` çš„åˆ¤å®šé€»è¾‘ã€‚  

**ğŸ¯ å½±å“èŒƒå›´**  
- **benchmark / tuning**ï¼šæ‰€æœ‰è°ƒç”¨ `tuning_fused_moe_triton_sep.py` çš„å®éªŒè„šæœ¬å’Œ CI åŸºå‡†ã€‚  
- **MoE Triton kernel**ï¼š`swap_ab` çš„å¼€å¯/å…³é—­ç­–ç•¥ï¼Œå½±å“ SM90 ç³»åˆ— GPUï¼ˆH20ã€H100ã€H200 ç­‰ï¼‰çš„æ‰§è¡Œè·¯å¾„ã€‚  
- **é…ç½®åº“**ï¼š`sglang/srt/layers/moe/fused_moe_triton/configs/...` æ–°å¢çº¦ 540 æ¡é…ç½®æ¡ç›®ï¼Œä¾› `fused_moe_triton` è‡ªåŠ¨è°ƒä¼˜ä½¿ç”¨ã€‚  
- **è¿è¡Œæ—¶**ï¼šåœ¨å¼€å¯ EPï¼ˆ`ep_size>1`ï¼‰æ—¶ï¼Œéœ€è¦ä¿è¯ `topk_ids` çš„æ•´æ•°é™¤æ³•ä¸äº§ç”Ÿç²¾åº¦è¯¯å·®ï¼›é»˜è®¤è¡Œä¸ºä¿æŒå‘åå…¼å®¹ã€‚  

**ğŸ’¡ å…³æ³¨å»ºè®®**  

1. **åŠŸèƒ½éªŒè¯**  
   - ä¸º `ep_size` æ·»åŠ å•å…ƒæµ‹è¯•ï¼šåœ¨ `ep_size=2,4` æ—¶æ£€æŸ¥ `topk_ids` æ˜¯å¦è¢«æ­£ç¡®æ˜ å°„ä¸”ä¸ä¼šè¶Šç•Œã€‚  
   - åœ¨ä¸åŒ GPUï¼ˆSM90 ä¸é SM90ï¼‰ä¸Šè·‘ä¸€æ¬¡åŸºå‡†ï¼Œç¡®è®¤ `swap_ab` åœ¨ Batchâ€‘Invariant æ¨¡å¼ä¸‹è¢«ç¦ç”¨ï¼Œé˜²æ­¢æ„å¤–æ€§èƒ½å›é€€ã€‚  

2. **æ–‡æ¡£ä¸ CLI**  
   - æ›´æ–° `benchmark`/`tune` è„šæœ¬çš„ `argparse`ï¼Œæš´éœ² `--ep-size` å‚æ•°å¹¶åœ¨ README ä¸­è¯´æ˜ä½•æ—¶éœ€è¦ä½¿ç”¨ã€‚  
   - åœ¨é…ç½®æ–‡ä»¶ç›®å½•çš„ `README` ä¸­æ ‡æ³¨æ–°åŠ å…¥çš„ H200â€‘fp8 é…ç½®çš„é€‚ç”¨åœºæ™¯ï¼ˆå¦‚ Qwen3â€‘Coderã€DPSKâ€‘V3ï¼‰ã€‚  

3. **å…¼å®¹æ€§ & å›æ»š**  
   - `should_enable_swap_ab` ç°åœ¨ä»…æ£€æŸ¥ `is_sm90_supported()` ä¸å—å°ºå¯¸ï¼Œè‹¥åç»­å‡ºç°ç‰¹ä¾‹ï¼ˆå¦‚æŸäº› SM90 GPU å¯¹ `swap_ab` æœ‰å‰¯ä½œç”¨ï¼‰ï¼Œè¯·ä¿ç•™ `--disable-swap-ab` ä¹‹ç±»çš„ç¯å¢ƒå¼€å…³ã€‚  
   - ç¡®è®¤ `is_batch_invariant_mode_enabled()` çš„é»˜è®¤å€¼ä¸º `False`ï¼Œé¿å…åœ¨æœªæ˜¾å¼å¼€å¯æ—¶è¯¯å…³é—­ `swap_ab`ã€‚  

4. **æ€§èƒ½å›å½’ç›‘æµ‹**  
   - å°†æ–°å¢çš„ JSON é…ç½®åŠ å…¥è‡ªåŠ¨è°ƒä¼˜æµ‹è¯•çŸ©é˜µï¼Œç¡®ä¿åœ¨ H200 ä¸Šçš„ fp8â€‘w8a8 èƒ½å¤Ÿè¾¾åˆ°é¢„æœŸçš„ååæå‡ã€‚  
   - å¯¹æ¯”å¼€å¯/å…³é—­ `swap_ab` çš„æ ¸æ—¶å»¶ï¼Œç¡®ä¿æ–°åˆ¤å®šé€»è¾‘æœªå¼•å…¥ä¸å¿…è¦çš„å»¶è¿Ÿã€‚  

æ€»ä½“æ¥çœ‹ï¼Œæœ¬æ¬¡æ”¹åŠ¨ä¸º Tritonâ€‘TP MoE å¼•å…¥ EP æ”¯æŒå¹¶ä¼˜åŒ–äº† SM90 GPU çš„ kernel é€‰æ‹©ï¼Œæå‡äº†è·¨ç¡¬ä»¶çš„é€‚é…èƒ½åŠ›ã€‚åªè¦åœ¨ EP ä¸é EP åœºæ™¯ä¸‹åšå……åˆ†çš„å›å½’æµ‹è¯•ï¼Œå³å¯å®‰å…¨åˆå…¥ä¸»çº¿ã€‚

---

### [NPU] support llama-3.2-11B-vision-instruct mode for NPU (#17492)
**SHA**: `e86476a` | ğŸ”— [æŸ¥çœ‹æäº¤](https://github.com/sgl-project/sglang/commit/e86476acfc525d7c378efbeab2321d5bc65b7899)

**ğŸ¯ å˜æ›´ç±»å‹**ï¼šåŠŸèƒ½å¢å¼º  
**âš¡ é‡è¦ç¨‹åº¦**ï¼šğŸŸ¡ ä¸­  
**ğŸ“‹ å˜æ›´æ‘˜è¦**ï¼šä¸º NPUï¼ˆAscendï¼‰åç«¯æ–°å¢å¯¹ Llamaâ€‘3.2â€‘11Bâ€‘Visionâ€‘Instruct çš„è·¨æ¨¡æ€ï¼ˆvisionâ€‘crossâ€‘attentionï¼‰æ”¯æŒã€‚å®ç°äº† `AscendTorchNativeAttnBackend`ï¼Œåœ¨ `ascend_backend.py` ä¸­æ”¹ç”¨è¯¥å®ç°å¹¶å®Œå–„ kvâ€‘cacheã€è·¨æ³¨æ„åŠ›ä»¥åŠ encoderâ€‘lens çš„å¤„ç†ï¼›åŒæ—¶ä¿®æ­£äº†çº¿æ€§å±‚ bias çš„åˆå§‹åŒ–æ–¹å¼å¹¶åŠ å…¥å¯¹åº”çš„ CI æµ‹è¯•ã€‚

**ğŸ¯ å½±å“èŒƒå›´**  
- `python/sglang/srt/hardware_backend/npu/attention/ascend_backend.py`ï¼ˆæ³¨æ„åŠ›è°ƒåº¦é€»è¾‘ï¼‰  
- æ–°å¢ `ascend_torch_native_backend.py`ï¼ˆåŸºäº PyTorch åŸç”Ÿ SDPAï¼‰  
- `python/sglang/srt/layers/linear.py`ï¼ˆbias åˆå§‹åŒ–ï¼‰  
- NPU CI æµ‹è¯•ç›®å½• `test/registered/ascend/vlm_models/`  

**ğŸ’¡ å…³æ³¨å»ºè®®**  
1. **æ€§èƒ½éªŒè¯**ï¼šæ–°å®ç°åœ¨å¾ªç¯ä¸­é€æ¡è¯·æ±‚ä»æœ‰æ½œåœ¨æ…¢ç‚¹ï¼Œå»ºè®®åœ¨ CI ä¸­åŠ å…¥ `torch.compile`/æ‰¹é‡åŒ–çš„åŸºå‡†ï¼Œç¡®è®¤ç›¸è¾ƒäºåŸå…ˆ NPU flash attention çš„ååæå‡æˆ–ä¸é™ã€‚  
2. **è·¨æ³¨æ„åŠ›æ­£ç¡®æ€§**ï¼šæ–°å¢ `encoder_lens` ä¸ `is_cross_attention` å‚æ•°åï¼Œéœ€è¦åœ¨å¤šæ¨¡æ€æ¨ç†è·¯å¾„ï¼ˆVisionâ€‘Languageï¼‰è·‘å®Œæ•´çš„å›å½’ï¼Œå°¤å…¶è¦æ£€æŸ¥ KVâ€‘cache å¯¹é½å’Œ padding æ˜¯å¦ä¸€è‡´ã€‚  
3. **Bias åˆå§‹åŒ–**ï¼šå°† bias ä» `empty` æ”¹ä¸º `zeros`ï¼Œç¡®ä¿æ¨¡å‹åŠ è½½åè¡Œä¸ºä¸€è‡´ï¼Œè‹¥æœ‰æ¨¡å‹è¿ç§»æˆ– checkpoint å…¼å®¹æ€§éœ€æ±‚ï¼Œç¡®è®¤ä¸ä¼šå¯¼è‡´æ•°å€¼åå·®ã€‚  
4. **æµ‹è¯•è¦†ç›–**ï¼šCI æ–°å¢çš„ VLM æµ‹è¯•ä»…è·‘ MMMU 0.2 çš„é˜ˆå€¼ï¼Œå»ºè®®å†åŠ å…¥å¯¹æ¯” CPU/CUDA ç»“æœçš„ç²¾åº¦å›å½’ï¼Œä»¥é˜²å‡ºç° subtle çš„æ•°å€¼å·®å¼‚ã€‚  
5. **æ–‡æ¡£ä¸ä½¿ç”¨è¯´æ˜**ï¼šåœ¨ `README`/æ¨¡å‹é…ç½®ä¸­æ ‡æ˜ `attention-backend=ascend` ç°åœ¨æ”¯æŒ visionâ€‘instructï¼Œå¹¶æç¤ºç”¨æˆ·å¼€å¯ `--disable-cuda-graph` ä¸ `--disable-radix-cache`ï¼ˆå·²åœ¨æµ‹è¯•ä¸­ä½¿ç”¨ï¼‰ã€‚  

æ€»ä½“è€Œè¨€ï¼Œæ­¤æ¬¡æ”¹åŠ¨ä¸º NPU åç«¯æ‰“å¼€äº†è·¨æ¨¡æ€å¤§æ¨¡å‹çš„å¯ç”¨æ€§ï¼Œä½†ä»éœ€å…³æ³¨å®ç°çš„æ‰¹å¤„ç†æ•ˆç‡ä¸è·¨æ³¨æ„åŠ›çš„æ•°å€¼ä¸€è‡´æ€§ã€‚

---

### [BugFix] Fix server crashes when req.grammar and ngram spec are enabled (#17585)
**SHA**: `578b119` | ğŸ”— [æŸ¥çœ‹æäº¤](https://github.com/sgl-project/sglang/commit/578b119bc66746d096a14917245af93c503674a1)

**ğŸ¯ å˜æ›´ç±»å‹**ï¼šBug ä¿®å¤ / åŠŸèƒ½å¢å¼º  
**âš¡ é‡è¦ç¨‹åº¦**ï¼šğŸŸ¡ ä¸­ï¼ˆé˜²æ­¢ server åœ¨åŒæ—¶å¼€å¯ `req.grammar` ä¸ nâ€‘gram æ—¶å´©æºƒï¼‰  

**ğŸ“‹ å˜æ›´æ‘˜è¦**  
1. åœ¨ `NgramVerifyInput` ä¸­æ–°å¢ `grammar` æˆå‘˜ï¼Œå¹¶åœ¨æ„é€ å‡½æ•°ä¸­æ¥å— `BaseGrammarObject`ï¼ˆé»˜è®¤ `None`ï¼‰ã€‚  
2. `NgramWorker.forward_batch_generation` å¢åŠ å¯¹ `batch.has_grammar` çš„åˆ†æ”¯ï¼šåœ¨ç›®æ ‡éªŒè¯é˜¶æ®µå…ˆæŠŠ CPUâ€‘side çš„ `retrive_next_*`ã€`draft_token` æ‹‰å› CPUï¼Œè°ƒç”¨æ–°å·¥å…· `generate_token_bitmask` ç”Ÿæˆç»“æ„åŒ–è¾“å‡ºçš„ vocab maskï¼Œå¹¶åœ¨ `verify` æ—¶æŠŠ mask ä¼ è¿›å»ã€‚  
3. `spec_utils.generate_token_bitmask` ä¸å†…éƒ¨ `traverse_tree`ã€`dfs` é€»è¾‘åŠ å…¥ `vocab_size` æ£€æŸ¥ï¼Œé˜²æ­¢è¶Šç•Œè®¿é—®ï¼›å¹¶å°† `vocab_size` é€šè¿‡å‚æ•°å‘ä¸‹ä¼ é€’ã€‚  

**ğŸ¯ å½±å“èŒƒå›´**  
- `python/sglang/srt/speculative/ngram_info.py`ã€`ngram_worker.py`ã€`spec_utils.py`ï¼ˆæ ¸å¿ƒæ¨ç†è·¯å¾„ï¼‰  
- `sglang.srt.constrained.base_grammar_backend.BaseGrammarObject`ï¼ˆæ–°å¢ä¾èµ–ï¼‰  
- å¯èƒ½å½±å“ `ScheduleBatch`ã€`SpeculativeAlgorithm` çš„è°ƒç”¨æ–¹ï¼Œéœ€è¦ç¡®ä¿ `spec_info.grammar` æ­£ç¡®å¡«å……ã€‚  

**ğŸ’¡ å…³æ³¨å»ºè®®**  
1. **å…¼å®¹æ€§**ï¼šæ–°å¢ `grammar` å‚æ•°é»˜è®¤ `None`ï¼Œä½† `verify` ä»ä¼šåœ¨ `batch.has_grammar` ä¸ºçœŸæ—¶å¼ºåˆ¶ä½¿ç”¨å®ƒã€‚è°ƒç”¨æ–¹åœ¨æœªå¼€å¯ grammar æ—¶åŠ¡å¿…ä¿æŒ `batch.has_grammar=False`ï¼Œå¦åˆ™å¯èƒ½å‡ºç° `None` è¢«è§£åŒ…çš„å¼‚å¸¸ã€‚  
2. **åŒæ­¥å¼€é”€**ï¼š`retrive_next_token` ç­‰å¼ é‡ä» GPU æ‹‰å› CPU å¯èƒ½å¯¼è‡´é¢å¤–çš„åŒæ­¥å»¶è¿Ÿï¼Œå»ºè®®åœ¨æ€§èƒ½åŸºå‡†ä¸­å¯¹æ¯”å¼€å¯/å…³é—­ grammar çš„ååä¸ latencyï¼Œè¯„ä¼°æ˜¯å¦éœ€è¦ç¼“å­˜æˆ–å¼‚æ­¥æ‹·è´ã€‚  
3. **å†…å­˜/ä½å›¾å¤§å°**ï¼š`allocate_token_bitmask` ä»æŒ‰ 32â€‘bit æ‰“åŒ…ï¼Œæ–°å¢ `vocab_size` æ£€æŸ¥é˜²æ­¢è¶Šç•Œï¼Œä½†è‹¥ vocab è¶…è¿‡ 2^31â€‘1ï¼Œä½å›¾å¤§å°å¯èƒ½ä¸å¤Ÿï¼Œéœ€åœ¨æ¨¡å‹é…ç½®å±‚é¢é™åˆ¶ vocab èŒƒå›´æˆ–æ”¹å†™ä½å›¾å®ç°ã€‚  
4. **æµ‹è¯•**ï¼šç¡®è®¤æ–°å¢åˆ†æ”¯åœ¨æ—  grammarã€ä»… nâ€‘gramã€ä»… grammarã€ä¸¤è€…å‡å¼€å¯å››ç§ç»„åˆä¸‹éƒ½èƒ½é€šè¿‡ç°æœ‰å•å…ƒ/é›†æˆæµ‹è¯•ï¼›ç‰¹åˆ«æ£€æŸ¥ `batch.sampling_info.vocab_mask` åœ¨æ¯æ¬¡ verify å‰è¢«æ¸…ç©ºçš„é€»è¾‘æ˜¯å¦ä¿æŒå¹‚ç­‰ã€‚  
5. **æ–‡æ¡£**ï¼šæ›´æ–° `speculative` ä½¿ç”¨è¯´æ˜ï¼Œæ˜ç¡®åœ¨ `req.grammar` ä¸ `ngram` åŒæ—¶å¼€å¯æ—¶å¿…é¡»ä½¿ç”¨æœ€æ–°çš„æœåŠ¡å™¨äºŒè¿›åˆ¶ï¼Œå¦åˆ™ä»ä¼šå‡ºç°æ—§ç‰ˆå´©æºƒã€‚  

æ•´ä½“è€Œè¨€ï¼Œæ­¤æ¬¡ä¿®æ”¹ä¿®å¤äº†è‡´å‘½çš„ server crashï¼Œé€»è¾‘æ¸…æ™°ä¸”å¯¹å¤–ä¿æŒå‘åå…¼å®¹ã€‚ä½†å»ºè®®åœ¨é«˜åååœºæ™¯ä¸‹è¯„ä¼° CPUâ€‘GPU æ•°æ®æ¬è¿å¸¦æ¥çš„æ€§èƒ½å½±å“ï¼Œå¹¶è¡¥å……ç›¸åº”çš„å›å½’æµ‹è¯•ä¸ä½¿ç”¨æ–‡æ¡£ã€‚

---

#### ğŸŸ¢ ä½é‡è¦åº¦å˜æ›´ (16)

### [Fix] Revert back to using CUTLASS `mm_fp4` backend (#17369)
**SHA**: `ef134d4` | ğŸ”— [æŸ¥çœ‹æäº¤](https://github.com/sgl-project/sglang/commit/ef134d407d6965c3e0ac3c35d3323a9a8ca20033)

**ğŸ¯ å˜æ›´ç±»å‹**ï¼šä»£ç é‡æ„  
**âš¡ é‡è¦ç¨‹åº¦**ï¼šğŸŸ¢ä½  
**ğŸ“‹ æ‘˜è¦**ï¼šåœ¨ `modelopt_quant.py` ä¸­ï¼Œä¿®å¤ FP4 GEMM åç«¯çš„é€‰æ‹©é€»è¾‘ï¼Œè‹¥åç«¯ä¸ºè‡ªåŠ¨æ¨¡å¼åˆ™å¼ºåˆ¶ä½¿ç”¨ `cutlass`ï¼Œé˜²æ­¢è¯¯ç”¨ FlashInferã€‚

---

### [Auto Sync] Update linear.py to assert shapes (20260130) (#17966)
**SHA**: `7412ceb` | ğŸ”— [æŸ¥çœ‹æäº¤](https://github.com/sgl-project/sglang/commit/7412ceb4eb159c92841491075bde63735bac7c8d)

**ğŸ¯ å˜æ›´ç±»å‹**ï¼šä»£ç é‡æ„  
**âš¡ é‡è¦ç¨‹åº¦**ï¼šğŸŸ¢ä½  
**ğŸ“‹ æ‘˜è¦**ï¼šåœ¨ `linear.py` ä¸­ä¸ºæƒé‡åŠ è½½å‡½æ•°æ·»åŠ  shape æ ¡éªŒæ–­è¨€ï¼Œå¹¶æä¾›é”™è¯¯ä¿¡æ¯ï¼Œæå‡è°ƒè¯•å¯è¯»æ€§ã€‚

---

### Add launch_command assignment in crash dump (#17967)
**SHA**: `0e18460` | ğŸ”— [æŸ¥çœ‹æäº¤](https://github.com/sgl-project/sglang/commit/0e184609d329ecbb1fdda816cd164fd363fd4557)

**ğŸ¯ å˜æ›´ç±»å‹**ï¼šä»£ç é‡æ„  
**âš¡ é‡è¦ç¨‹åº¦**ï¼šğŸŸ¢ä½  
**ğŸ“‹ æ‘˜è¦**ï¼šåœ¨ `tokenizer_manager.py` çš„å´©æºƒè½¬å‚¨ä¸­æ–°å¢ `launch_command` å­—æ®µï¼Œè®°å½•å¯åŠ¨æ—¶çš„å®Œæ•´å‘½ä»¤è¡Œå‚æ•°ï¼Œä»¥ä¾¿è°ƒè¯•ã€‚å¯¹åŠŸèƒ½æ— å½±å“ï¼Œä»…æå‡å¯è¿½æº¯æ€§ã€‚

---

### [EPD][Perf] parallelize ZMQ send for encode server (#16487)
**SHA**: `a4df95c` | ğŸ”— [æŸ¥çœ‹æäº¤](https://github.com/sgl-project/sglang/commit/a4df95c15f0f7fdfe170b78f601a30fa41d05f90)

**ğŸ¯ å˜æ›´ç±»å‹**ï¼šä»£ç é‡æ„  
**âš¡ é‡è¦ç¨‹åº¦**ï¼šğŸŸ¢ä½  
**ğŸ“‹ æ‘˜è¦**ï¼šåœ¨ `encode_server.py` ä¸­å¼•å…¥åŒæ­¥ ZMQ ä¸Šä¸‹æ–‡å’Œçº¿ç¨‹æ± ï¼Œå®ç°å¹¶è¡Œå‘é€ï¼Œä½¿ç”¨ `run_in_executor` å°†å‘é€æ“ä½œç¦»çº¿æ‰§è¡Œï¼Œæå‡ç¼–ç æœåŠ¡çš„ååæ€§èƒ½ã€‚

---

### Fix OOM in DeepSeek weight loading by deferring dict(weights) materialization (#17744)
**SHA**: `04efd03` | ğŸ”— [æŸ¥çœ‹æäº¤](https://github.com/sgl-project/sglang/commit/04efd03dbf0f40c2c847e2dcaba84faa8dfcb128)

**ğŸ¯ å˜æ›´ç±»å‹**ï¼šä»£ç é‡æ„  
**âš¡ é‡è¦ç¨‹åº¦**ï¼šğŸŸ¢ä½  
**ğŸ“‹ æ‘˜è¦**ï¼šåœ¨ `deepseek_weight_loader.py` ä¸­å»¶è¿Ÿ `dict(weights)` çš„åˆ›å»ºï¼Œä»…åœ¨éœ€è¦é‡åŒ–æ—¶æ‰ materializeï¼Œé¿å…ä¸å¿…è¦çš„å†…å­˜å ç”¨ï¼Œé˜²æ­¢ OOMã€‚

---

### Reduce topk kernel shared memory from 128KB to 32KB for better occupancy (#17747)
**SHA**: `45fe51a` | ğŸ”— [æŸ¥çœ‹æäº¤](https://github.com/sgl-project/sglang/commit/45fe51a28e43c02a8aa7060a0b4ff06379926540)

**ğŸ¯ å˜æ›´ç±»å‹**ï¼šä»£ç é‡æ„  
**âš¡ é‡è¦ç¨‹åº¦**ï¼šğŸŸ¢ä½  
**ğŸ“‹ æ‘˜è¦**ï¼šæŠŠ `topk` GPU kernel çš„å…±äº«å†…å­˜ä¸Šé™ä» 128â€¯KB é™è‡³ 32â€¯KBï¼Œå¹¶æ·»åŠ è¯´æ˜æ³¨é‡Šï¼Œä»¥æå‡å ç”¨ç‡å’Œæ•´ä½“æ€§èƒ½ã€‚

---

### add reasoning_tokens usage test for tool call (#18022)
**SHA**: `c72bf50` | ğŸ”— [æŸ¥çœ‹æäº¤](https://github.com/sgl-project/sglang/commit/c72bf50706b351590c4c8b2a3d1e6ab710e76c06)

**ğŸ¯ å˜æ›´ç±»å‹**ï¼šæµ‹è¯•ä¿®æ”¹  
**âš¡ é‡è¦ç¨‹åº¦**ï¼šğŸŸ¢ä½  
**ğŸ“‹ æ‘˜è¦**ï¼šä¸ºå·¥å…·è°ƒç”¨æµ‹è¯•æ–°å¢ `test_reasoning_usage`ï¼ŒéªŒè¯åœ¨å¼€å¯ thinking æ—¶è¿”å›çš„ `usage.reasoning_tokens` å¤§äº 0ï¼Œå¹¶åœ¨ DeepSeek æ¨¡å‹æµ‹è¯•ä¸­å¯ç”¨è¯¥é¡¹ã€‚

---

### ã€docsã€‘ã€NPUã€‘Update Expert Parallelism docs for Ascend NPU (#17940)
**SHA**: `c52578c` | ğŸ”— [æŸ¥çœ‹æäº¤](https://github.com/sgl-project/sglang/commit/c52578c7fd19f64353513006b604b5050132901e)

**ğŸ¯ å˜æ›´ç±»å‹**ï¼šæ–‡æ¡£æ›´æ–°  
**âš¡ é‡è¦ç¨‹åº¦**ï¼šğŸŸ¢ä½  
**ğŸ“‹ æ‘˜è¦**ï¼šåœ¨ `docs/advanced_features/attention_backend.md` ä¸ `docs/advanced_features/expert_parallelism.md` ä¸­æ–°å¢å¹¶å®Œå–„ Ascend NPUï¼ˆåä¸ºæ˜‡è…¾ï¼‰ç›¸å…³è¯´æ˜ï¼Œæ›´æ–°æ”¯æŒçŸ©é˜µã€åŠ å…¥ EP/TP ä¸ Ascend FuseEP çš„å…¼å®¹æ€§æè¿°ï¼Œä»¥åŠæä¾› Ascend NPU é…ç½®ã€DeepEP å‚æ•°å’Œç¼“å†²åŒºå¤§å°çš„ä½¿ç”¨æŒ‡å—ã€‚

---

### Fix .gitignore may ignore files like core_attention.py (#18021)
**SHA**: `dc77def` | ğŸ”— [æŸ¥çœ‹æäº¤](https://github.com/sgl-project/sglang/commit/dc77defdd0d4a1b94caaf8ffdd3c19080b3d751e)

**ğŸ¯ å˜æ›´ç±»å‹**ï¼šé…ç½®è°ƒæ•´  
**âš¡ é‡è¦ç¨‹åº¦**ï¼šğŸŸ¢ä½  
**ğŸ“‹ æ‘˜è¦**ï¼šå°† `.gitignore` ä¸­çš„ `core_*` æ”¹ä¸º `*.mudmp`ï¼Œé˜²æ­¢è¯¯å¿½ç•¥ç±»ä¼¼ `core_attention.py` çš„æ–‡ä»¶ï¼Œä»…é’ˆå¯¹ MUSA æ ¸å¿ƒè½¬å‚¨æ–‡ä»¶çš„å¿½ç•¥è§„åˆ™è¿›è¡Œä¿®æ­£ã€‚

---

### Fix cuBLAS >=12.9 detection for cu12/cu13 package naming (#17766)
**SHA**: `d0d9cec` | ğŸ”— [æŸ¥çœ‹æäº¤](https://github.com/sgl-project/sglang/commit/d0d9cecd1b34ead4caf506e0481011603ac87bcc)

**ğŸ¯ å˜æ›´ç±»å‹**ï¼šä»£ç é‡æ„  
**âš¡ é‡è¦ç¨‹åº¦**ï¼šğŸŸ¢ä½  
**ğŸ“‹ æ‘˜è¦**ï¼šå°† cuBLAS ç‰ˆæœ¬æ£€æµ‹å‡½æ•°é‡å‘½åå¹¶æ”¹ä¸ºåŒæ—¶æ£€æŸ¥ `nvidia-cublas` ä¸ `nvidia-cublas-cu12`ï¼Œåœ¨ç›¸å…³æ¨¡å—ä¸­æ›´æ–°è°ƒç”¨ï¼Œä¿®å¤ Cu12/Cu13 åŒ…å‘½åå¯¼è‡´çš„æ£€æµ‹å¤±æ•ˆã€‚

---

### [Diffusion] Fix FLUX.1-schnell time embedding argument mismatch (#17988)
**SHA**: `22aad4e` | ğŸ”— [æŸ¥çœ‹æäº¤](https://github.com/sgl-project/sglang/commit/22aad4e2c4741b92a37d02e64502c710119cd098)

**ğŸ¯ å˜æ›´ç±»å‹**ï¼šä»£ç é‡æ„  
**âš¡ é‡è¦ç¨‹åº¦**ï¼šğŸŸ¢ä½  
**ğŸ“‹ æ‘˜è¦**ï¼šä¿®å¤ FLUX.1â€‘schnell æ¨¡å‹åœ¨æ—¶é—´åµŒå…¥çš„å‚æ•°ä¼ é€’é”™è¯¯ï¼›ä»…åœ¨é…ç½®æ”¯æŒä¸”æä¾› guidance æ—¶æ‰å‘ `time_text_embed` ä¼ å…¥ guidance å‚æ•°ï¼Œé¿å…å‚æ•°ä¸åŒ¹é…å¯¼è‡´è¿è¡Œæ—¶é”™è¯¯ã€‚

---

### Add ROCm + Mori docker build instructions in rocm.Dockerfile (#18018)
**SHA**: `ec76c39` | ğŸ”— [æŸ¥çœ‹æäº¤](https://github.com/sgl-project/sglang/commit/ec76c390c95bbba7ad657e6c458772eda040425a)

**ğŸ¯ å˜æ›´ç±»å‹**ï¼šæ–‡æ¡£æ›´æ–°  
**âš¡ é‡è¦ç¨‹åº¦**ï¼šğŸŸ¢ä½  
**ğŸ“‹ æ‘˜è¦**ï¼šåœ¨ `docker/rocm.Dockerfile` ä¸­æ–°å¢ ROCmâ€¯+â€¯Mori æ„å»ºç¤ºä¾‹åŠä½¿ç”¨è¯´æ˜ï¼Œæœªæ”¹åŠ¨å®é™…æ„å»ºé€»è¾‘ã€‚

---

### [NPU] fix sgl-kernel-npu package url error in npu.Dockerfile (#18017)
**SHA**: `ee3058c` | ğŸ”— [æŸ¥çœ‹æäº¤](https://github.com/sgl-project/sglang/commit/ee3058c6e867e6cc0cfc6ff10bf318d476257180)

**ğŸ¯ å˜æ›´ç±»å‹**ï¼šé…ç½®è°ƒæ•´  
**âš¡ é‡è¦ç¨‹åº¦**ï¼šğŸŸ¢ä½  
**ğŸ“‹ æ‘˜è¦**ï¼šä¿®æ­£ `docker/npu.Dockerfile` ä¸­ sglâ€‘kernelâ€‘npu åŒ…çš„ä¸‹è½½ URLï¼Œæ”¹ä¸ºä½¿ç”¨ `-` åˆ†éš”å¹¶åŠ å…¥ `$(arch)`ï¼Œé¿å…åŸé“¾æ¥é”™è¯¯å¯¼è‡´æ„å»ºå¤±è´¥ã€‚

---

### doc update for CANN version (#18014)
**SHA**: `f6a4ff7` | ğŸ”— [æŸ¥çœ‹æäº¤](https://github.com/sgl-project/sglang/commit/f6a4ff718f917d0c4076cc3787736ea9db1f4270)

**ğŸ¯ å˜æ›´ç±»å‹**ï¼šæ–‡æ¡£æ›´æ–°  
**âš¡ é‡è¦ç¨‹åº¦**ï¼šğŸŸ¢ ä½  
**ğŸ“‹ æ‘˜è¦**ï¼šå°† MindSpore æ”¯æŒçš„ Ascend CANN ç‰ˆæœ¬ä» â€œ8.3.RC2â€ æ›´æ–°ä¸º â€œ8.5â€ï¼Œç›¸åº”ä¿®æ”¹äº†ä¸‹è½½è¯´æ˜æ–‡å­—ã€‚

---

### [sglang] fix mm token padded value overlap with text token id (#17781)
**SHA**: `5d00150` | ğŸ”— [æŸ¥çœ‹æäº¤](https://github.com/sgl-project/sglang/commit/5d00150e9965f467399236ebf7819bbff5e385bb)

**ğŸ¯ å˜æ›´ç±»å‹**ï¼šä»£ç é‡æ„  
**âš¡ é‡è¦ç¨‹åº¦**ï¼šğŸŸ¢ä½  
**ğŸ“‹ æ‘˜è¦**ï¼šå¼•å…¥ `MM_PAD_SHIFT_VALUE` å¹¶é€šè¿‡ `_compute_pad_value` ä¸ºå¤šæ¨¡æ€ padâ€‘value åŠ åç§»ï¼Œä½¿ç”¨ `lru_cache` çš„ `sanity_check_mm_pad_shift_value` åœ¨æ¨¡å‹åˆå§‹åŒ–æ—¶æ ¡éªŒ vocab_sizeï¼Œé˜²æ­¢ padâ€‘value ä¸æ–‡æœ¬ token ID å†²çªã€‚

---

### Optimize GDN decode for Qwen3 Next (#17094)
**SHA**: `81449b4` | ğŸ”— [æŸ¥çœ‹æäº¤](https://github.com/sgl-project/sglang/commit/81449b4beebf761eab1ad67ad19e3cab4c0109d4)

**ğŸ¯ å˜æ›´ç±»å‹**ï¼šä»£ç é‡æ„  
**âš¡ é‡è¦ç¨‹åº¦**ï¼šğŸŸ¢ä½  
**ğŸ“‹ æ‘˜è¦**ï¼šå°† `fused_recurrent_gated_delta_rule_fwd` ä¸­ BV çš„ä¸Šé™ç”± 8 æå‡è‡³ 32ï¼Œä»¥æå‡ Qwen3 Next çš„ GDN è§£ç æ€§èƒ½ã€‚

---

