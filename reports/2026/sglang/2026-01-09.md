# 每日更新报告（2026-01-09）

## sgl-project/sglang

| 提交时间 | 作者 | 提交信息 |
|----------|------|----------|
| 2026-01-09 23:22:21 | Hanming Lu | [nemetron/mtp] fix nemotron mtp (#16275) |
| 2026-01-09 23:07:18 | fzyzcjy | Support token low usage watermark in prefill delayer (#16814) |
| 2026-01-09 22:58:38 | fzyzcjy | Tiny add and enhance tests for prefill delayer (#16813) |
| 2026-01-09 22:51:16 | fzyzcjy | Tiny enhance prefill delayer observability (#16812) |
| 2026-01-09 22:46:41 | fzyzcjy | Refactor prefill delayer for clarity and extensibility (#16811) |
| 2026-01-09 22:38:51 | siyu | add doc for #14386 (#14655) |
| 2026-01-09 20:16:58 | sunxxuns | [diffusion] amd: fix SGLANG_DIFFUSION_ATTENTION_BACKEND env var for diffusion attention backend selection (#16325) |
| 2026-01-09 19:20:17 | ybyang | fix spec qwen3 pd error (#16708) |
| 2026-01-09 19:07:13 | Lianmin Zheng | [Docs] Improve docs for install on gb200 (#16760) |
| 2026-01-09 18:42:27 | Shangming Cai | chore: bump mooncake version to 0.3.8.post1 (#16792) |
| 2026-01-09 16:24:04 | Hubert Lu | [AMD] Clean up vllm dependencies in moe_runner/triton.py (#11349) |
| 2026-01-09 15:43:49 | Alison Shao | Fix external_models import path and migrate model loading tests (#16458) |
| 2026-01-09 15:08:25 | Xiaoyu Zhang | [Diffusion] Tiny rename parallel_groups (#16743) |
| 2026-01-09 13:28:37 | Hanming Lu | support page size large than 64 for mamba radix cache with fix (#16768) |
| 2026-01-09 13:17:20 | YC Tseng | [AMD] Change AITER package name  (#16721) |
| 2026-01-09 13:16:23 | Liangsheng Yin | Tiny remove auto-triggering for list-active-pr-runs. (#16778) |
| 2026-01-09 13:02:12 | Liangsheng Yin | List ci workflows status. (#16774) |
| 2026-01-09 12:06:31 | Sirut Buasai | add AWS SGLang DLC to docs (#16686) |
| 2026-01-09 11:31:38 | Fenglin Yu | [diffusion] docs: add LoRA support (#16378) |
| 2026-01-09 11:29:15 | Michael | [AMD] Add MI35x nightly CI tests (#16588) |
| 2026-01-09 11:20:29 | Liangsheng Yin | Tiny simplify draft worker init. (#16446) |
| 2026-01-09 11:08:17 | Liangsheng Yin | Tiny fix wording about CI preemption. (#16773) |
| 2026-01-09 11:01:49 | Yongfei Xu | [DeepSeek 3.2] Support and optimize pipeline parallelis when context pipeline enabled (#16380) |
| 2026-01-09 09:49:37 | Simo Lin | [model-gateway] release 0.3.1 (#16254) |
| 2026-01-09 09:40:31 | triple-mu | [diffusion] model: wan tp+usp optimize (#16720) |
| 2026-01-09 08:39:53 | fzyzcjy | [smg] cleanup router RAII guards (#16560) |
| 2026-01-09 08:33:09 | Simo Lin | [smg] update gRPC proto to match upstream changes (#16764) |
| 2026-01-09 08:29:24 | Simo Lin | [smg] Add Nemotron Nano V3 reasoning parser support (#16763) |
| 2026-01-09 08:08:21 | Douglas Yang | fix: extend cpu only install dependency timeout to 20 mins (#16759) |
| 2026-01-09 07:13:13 | Alison Shao | Skip causal_conv1d test with padded batches due to Triton kernel bug (#16715) |
| 2026-01-09 06:41:03 | Simo Lin | [smg] Work around sglang's notorious orphan process problem (#16756) |
| 2026-01-09 05:09:01 | Simo Lin | [grpc] Fix protobuf compilation in isolated build environments (#16754) |
| 2026-01-09 04:35:56 | Simo Lin | fix(e2e): prevent potential hangs in model pool subprocess handling (#16752) |
| 2026-01-09 03:31:54 | Simo Lin | [smg][ci] delete old chat completion integration tests and workflow step (#16751) |
| 2026-01-09 03:25:41 | Liangsheng Yin | Adjust the cancel PR workflows for better preemption. (#16749) |
| 2026-01-09 03:08:01 | Simo Lin | [smg][ci] migrate function calling tests to new infrastructure (#16748) |
| 2026-01-09 02:16:27 | YC Tseng | [AMD] Fix CI - unit-test-backend-1-gpu-amd-mi35x and unit-test-backend-2-gpu-amd, stage-b-test-small-1-gpu-amd (#16675) |
| 2026-01-09 01:26:31 | Simo Lin | [smg][ci] migrate validation tests to new infrastructure (#16746) |
| 2026-01-09 01:09:54 | Chang Su | [grpc] Auto-generate protobuf files during wheel build (#16409) |
| 2026-01-09 01:01:35 | Yi Zhong | [perf] Add two stream norm for `Olmo3` speedup 5% (#13681) |
| 2026-01-09 00:55:18 | Simo Lin | [smg][ci] fix model pool GPU cleanup and add startup reliability improvements (#16745) |
| 2026-01-09 00:25:39 | Simo Lin | [smg][ci] migrate reasoning_content tests to new infrastructure (#16741) |

### 📊 统计摘要
> 本日共 42 个提交 | 🔴高 3 | 🟡中 24 | 🟢低 15
## 📋 目录

- [sgl-project/sglang](#sgl-project-sglang)
  - [📊 统计摘要](#-统计摘要)
  - [🔴 高重要度变更 (3)](#-🔴-高重要度变更-3)
    - [[AMD] Add MI35x nightly CI tests (#16588)](#fcec35d)
    - [[smg][ci] delete old chat completion integration tests an...](#9d03af9)
    - [[grpc] Auto-generate protobuf files during wheel build (#...](#1688023)
  - [🟡 中重要度变更 (24)](#-🟡-中重要度变更-24)
    - [[nemetron/mtp] fix nemotron mtp (#16275)](#5dcff94)
    - [Support token low usage watermark in prefill delayer (#16...](#8eeffbe)
    - [Tiny add and enhance tests for prefill delayer (#16813)](#71e9c31)
    - [Tiny enhance prefill delayer observability (#16812)](#7656d26)
    - [Refactor prefill delayer for clarity and extensibility (#...](#dd24ba9)
    - [[diffusion] amd: fix SGLANG_DIFFUSION_ATTENTION_BACKEND e...](#64a31d4)
    - [Fix external_models import path and migrate model loading...](#e46f794)
    - [support page size large than 64 for mamba radix cache wit...](#41609b5)
    - [List ci workflows status. (#16774)](#f7c1d24)
    - [Tiny simplify draft worker init. (#16446)](#75da784)
    - [[DeepSeek 3.2] Support and optimize pipeline parallelis w...](#05dfef9)
    - [[diffusion] model: wan tp+usp optimize (#16720)](#f7f5c38)
    - [[smg] cleanup router RAII guards (#16560)](#9e3a032)
    - [[smg] update gRPC proto to match upstream changes (#16764)](#1bc7aa5)
    - [fix: extend cpu only install dependency timeout to 20 min...](#a1b243d)
    - [[grpc] Fix protobuf compilation in isolated build environ...](#55a8dd0)
    - [fix(e2e): prevent potential hangs in model pool subproces...](#cf24232)
    - [Adjust the cancel PR workflows for better preemption. (#1...](#064ae34)
    - [[smg][ci] migrate function calling tests to new infrastru...](#49305fa)
    - [[AMD] Fix CI - unit-test-backend-1-gpu-amd-mi35x and unit...](#4e99940)
    - [[smg][ci] migrate validation tests to new infrastructure ...](#fbc2488)
    - [[perf] Add two stream norm for `Olmo3` speedup 5% (#13681)](#cda3561)
    - [[smg][ci] fix model pool GPU cleanup and add startup reli...](#8a45a9c)
    - [[smg][ci] migrate reasoning_content tests to new infrastr...](#aecd5f5)
  - [🟢 低重要度变更 (15)](#-🟢-低重要度变更-15)
    - [add doc for #14386 (#14655)](#068abe7)
    - [fix spec qwen3 pd error (#16708)](#2babf88)
    - [[Docs] Improve docs for install on gb200 (#16760)](#d56d14e)
    - [chore: bump mooncake version to 0.3.8.post1 (#16792)](#0c4e155)
    - [[AMD] Clean up vllm dependencies in moe_runner/triton.py ...](#d6d5c3f)
    - [[Diffusion] Tiny rename parallel_groups (#16743)](#9d4d57d)
    - [[AMD] Change AITER package name  (#16721)](#ccd0fb3)
    - [Tiny remove auto-triggering for list-active-pr-runs. (#16...](#87ee6b5)
    - [add AWS SGLang DLC to docs (#16686)](#cceb5e6)
    - [[diffusion] docs: add LoRA support (#16378)](#c1c13c8)
    - [Tiny fix wording about CI preemption. (#16773)](#77d3566)
    - [[model-gateway] release 0.3.1 (#16254)](#7460240)
    - [[smg] Add Nemotron Nano V3 reasoning parser support (#16763)](#8726d30)
    - [Skip causal_conv1d test with padded batches due to Triton...](#a979927)
    - [[smg] Work around sglang's notorious orphan process probl...](#ee71e77)
#### 🔴 高重要度变更 (3)

### [AMD] Add MI35x nightly CI tests (#16588)
**SHA**: `fcec35d` | 🔗 [查看提交](https://github.com/sgl-project/sglang/commit/fcec35dc4a0f54b0a74bd84aba9e4a4cffcad81a)

**🎯 变更类型**：功能增强 / 架构变更（为 AMD MI35x GPU 新增 Nightly CI 测试套件，重构已有 AMD nightly 测试注册机制）  

**⚡ 重要程度**：🔴 高  

**📋 变更摘要**  
- 在 `.github/workflows/nightly-test-amd.yml` 中加入 **MI35x 2‑GPU / 8‑GPU** 任务（GPT‑OSS、GROK、DeepSeek‑R1 等模型），并统一使用 `run_suite.py` 的注册机制。  
- 新增 **MI35x 专用测试代码**：  
  - `test/registered/amd/nightly/test_gsm8k_completion_eval_mi35x.py`、`test/registered/amd/nightly/test_gsm8k_completion_eval_amd.py`（迁移并改写），  
  - `test/registered/amd/nightly/test_deepseek_r1_mxfp4_perf.py`（MXFP4 量化模型性能基准）。  
- 为所有 AMD Nightly 测试统一 **CI 注册**（`register_amd_ci`），并在 `run_suite.py` 中删除旧硬编码的 `nightly-amd*` 列表，改为由注册表决定。  
- 调整模型组定义，去除 **DeepSeek‑V3** 准确度模型，仅保留其 **性能基准**；为 DeepSeek‑R1 引入 “basic / MTP / DP / TC” 四种变体并在 MI35x 中统一管理。  
- 在 CI 启动容器时为 MI35x 环境补装 `tabulate`，并对模型本地缓存/线上下载路径做了更细致的检查与日志。  

**🎯 影响范围**  
- CI/CD 子系统（GitHub Actions workflow、Docker 启动脚本）  
- AMD 相关测试代码（`test/registered/amd/...`）  
- 模型调度与配置代码（`registered/amd/nightly/*`、模型组常量）  
- 项目根目录下的 `test/run_suite.py` 与 `test/srt/run_suite.py`（注册表/矩阵）  

---

## 🔍 技术洞察

| 维度 | 影响/说明 |
|------|-----------|
| **架构影响** | 1. **CI 工作流扩展**：新增 7 条 MI35x job（2‑GPU、8‑GPU）以及对应的 `if` 条件，导致 workflow YAML 行数 +221。<br>2. **注册表化**：`register_amd_ci` 把测试文件与 **suite 名称**、**估算时长**解耦，`run_suite.py` 通过注册表动态生成测试矩阵，旧的硬编码列表被删除，提升可维护性。<br>3. **模型抽象**：`BaseModelConfig` 增加 `variant`、`local_path`、`get_effective_model_path` 方法，统一本地/HF 路径解析，避免不同平台硬编码。<br>4. **容器执行路径**：`amd_ci_exec.sh` 统一使用 `-w /sglang-checkout/test` 工作目录，防止不同 job 共享同一目录导致并发冲突。 |
| **性能影响** | - **CI 时长显著增长**：MI35x 8‑GPU 任务每个约 2 h（`est_time=7200`），全部 7 项约 **14 h**（受并行 runner 限制，实际 CI 时长 ~ 2–3 h 取决并发）。<br>- **模型加载**：新增对本地缓存的检测 (`check_local_cache`) 与 HF 下载路径（`/data2/models/huggingface`），在 MI35x 环境首次运行会触发大规模模型下载（数 TB），对网络带宽和磁盘 I/O 有较大冲击。<br>- **额外依赖**：在 MI35x 容器中安装 `tabulate`，几乎不产生额外运行时开销。 |
| **安全考虑** | - 所有新变量均通过 **环境变量** 传递（`AMD_TEST_MODEL_GROUP`、`DEEPSEEK_R1_MXFP4_MODEL_PATH` 等），未泄露任何凭证。<br>- **HF 访问检查** 通过 `huggingface_hub` 捕获 401/404 错误并在日志中提示，需要在 CI 中配置 `HF_TOKEN`（若访问 gated repo），否则跑失败但不影响安全。<br>- 新增的 **GitHub Actions step** `Setup docker`、`Install dependencies` 将工作目录映射到容器内部，保持与之前相同的隔离层级。 |
| **可维护性** | - **代码复用度提升**：模型组统一在 `get_models_for_group` 中返回列表，新增/删除模型只需修改常量块。<br>- **日志/报表**：`log_model_status` 统一打印本地缓存、HF 访问、下载路径，便于 CI 失败排查。<br>- **测试注册**：通过 `register_amd_ci` 将 CI 预估时长写入 GitHub step summary，帮助项目维护者监控 CI 成本。 |
| **兼容性** | - 原有 `nightly-amd`、`nightly-amd-vlm`、`nightly-amd-8-gpu` 仍通过注册表驱动，**不再直接在 `test/srt/run_suite.py` 中列出**，确保向后兼容且不影响已有 GitHub Actions。<br>- 对老平台（MI300X）保持原有测试不变，新增的 MI35x 只在 `nightly-test-*-mi35x` job 中被触发。 |
| **成本** | - **计算资源**：新增的 MI35x 8‑GPU runner 使用 `linux-mi35x-gpu-8`，若公开在 GitHub Self‑Hosted，需要准备相应硬件；若使用云服务，每次跑完约 2 h，成本约 **$15–$30**（取决提供商）。<br>- **存储**：模型缓存目录 `/data2/models/huggingface` 需预留至少 **2 TB**（DeepSeek‑R1‑MXFP4‑Preview 约 400 GB，GPT‑OSS‑120B 约 1.5 TB）。 |

---

## ⚠️ 潜在风险

| 风险点 | 说明 | 严重度 | 缓解措施 |
|--------|------|--------|-----------|
| **CI 运行超时 / 资源耗尽** | MI35x 8‑GPU 作业每个约 2 h，若模型下载慢或容器启动失败，会导致 `job timeout`（默认 6 h）。 | 高 | - 为每个 job 设置 `timeout-minutes`（已在部分 job 中显式声明）。<br>- 在 `run_suite.py` 中使用 `est_time` 注册，CI 主页面可预警。 |
| **模型不可达** | 某些模型为 gated repo（DeepSeek‑R1‑MXFP4‑Preview 需要 HF token）。 | 中 | - 在 CI 环境中配置 `HF_TOKEN`，并在 `log_model_status` 中给出明确提示。<br>- 若缺失，测试会被标记为 “SKIP”。 |
| **磁盘空间不足** | 全部 MI35x 模型累计 > 2 TB，CI 运行时若未清理旧缓存会导致磁盘满。 | 中 | - 在 CI 启动前添加磁盘检查脚本，或使用 `rm -rf /data2/models/huggingface/*` 进行周期性清理（仅在安全的 CI 环境中）。 |
| **Flaky 性能基准** | 性能基准受 GPU 温度、并发 IO、网络下载影响，可能出现不稳定的 `latency` / `throughput`。 | 中 | - 在 benchmark 脚本中加入重试机制（已实现 `for attempt in range(3)`），并在报告中记录 `invalid` 与 `latency`

---

### [smg][ci] delete old chat completion integration tests and workflow step (#16751)
**SHA**: `9d03af9` | 🔗 [查看提交](https://github.com/sgl-project/sglang/commit/9d03af916a0b9654cff9fcc393ebafc32de8b42a)

**🎯 变更类型**：重构 / 测试清理  
**⚡ 重要程度**：🔴高  

**📋 变更摘要**  
本次提交在 `sgl-project/sglang` 中删除了 **全部旧的 gRPC 端到端（e2e）集成测试**（包括 `test_enable_thinking.py`、`test_reasoning_content.py`、`test_openai_function_calling.py`、`test_tool_choice.py`、`test_large_max_new_tokens.py`、`test_openai_server_ignore_eos.py` 等共 6 + 1 个 `util.py`、`pytest.ini`）以及相应的 GitHub Actions workflow 步骤 (`.github/workflows/pr-test-rust.yml` 中的 `grpc` job)。这些文件共计约 **3000 行代码**被移除，CI 中对 gRPC 路由器的完整功能覆盖被彻底剔除。

---

## 🔍 技术洞察

| 维度 | 影响分析 |
|------|----------|
| **架构影响** | - 代码库层面未更改核心业务实现，仅删除了 **测试层**（`sgl-model-gateway/e2e_test/e2e_grpc/`）以及 CI 中对应的执行步骤。<br>- `popen_launch_workers_and_router` 等启动逻辑仍保留在其他测试中，未受影响。<br>- 失去的测试文件本身并未被其它生产代码引用，删除不会导致运行时错误。 |
| **性能影响** | - **CI 运行时间显著下降**：原本的 `grpc` job 包含多组长时间运行的 e2e 场景（函数调用、思考推理、工具选择、大 token、EOS 处理等），每个场景常常需要数十秒至几分钟的模型启动与推理。移除后 PR 检查时间预计缩短 **30 %–50 %**。<br>- 对用户实际推理性能无直接影响。 |
| **安全考虑** | - 删除的测试均属于功能验证，不涉及安全敏感代码或权限检查。<br>- 唯一潜在风险是 **安全回归检测缺失**：例如 `test_openai_server_ignore_eos.py` 用来确认 `ignore_eos` 参数不会导致未预期的无限生成，若后续出现相关漏洞将失去自动检测。 |
| **可维护性** | - **正面**：大幅削减了冗余、过时的测试，降低了维护成本（测试 flaky、依赖模型版本等问题）。<br>- **负面**：如果这些测试是唯一覆盖的场景，后续对功能的改动将缺乏回归保障；也可能导致新贡献者误以为对应功能已不再受支持。 |
| **CI 可靠性** | - 移除了 **`grpc`** 这一并行执行的 job，减少了 flaky 测试导致的 CI 失败率。<br>- 同时也意味着 **CI 覆盖率下降**：对 gRPC 路由器的 **function calling、tool‑choice、reasoning、streaming、多选项、ignore_eos** 等关键特性的自动验证全失效。 |
| **依赖影响** | - `util.py`、`pytest.ini` 被删除，若项目中其他测试（非 `e2e_grpc`）仍显式引用这些文件，CI 将报错。当前代码库搜索显示这些文件仅在 `e2e_grpc` 相关测试中使用，故影响范围局限。 |
| **回归风险** | - **功能回归**：后续对 gRPC 路由器、工具调用解析器（`--tool-call-parser`）或推理相关 flag 的改动，缺少端到端验证，容易在模型升级或配置变更时引入隐藏错误。<br>- **文档/示例不匹配**：若 README、示例或 CI badge 仍声称 “gRPC e2e tests are run on PR”, 可能导致用户困惑。 |
| **资产回收** | - 删除的文件体积约 **300 KB**，对仓库大小影响可忽略。<br>- 因为这些测试依赖较大的模型文件（如 `Llama‑3.2‑1B‑Instruct`、`Qwen2.5‑7B‑Instruct`），删除后 CI 资源消耗（模型下载、磁盘占用）大幅降低。 |

---

## ⚠️ 潜在风险

1. **回归缺失**  
   - 关键功能（function calling、tool choice、reasoning、ignore_eos）不再受到自动化端到端验证。任何对 `sglang_router`、`sglang_worker` 或模型推理路径的改动，若出现细微错误，CI 将不易捕获，可能导致发布版本出现 **功能异常**。

2. **文档/用户期望不一致**  
   - 项目文档、示例或 CI badge 若仍提及 “gRPC e2e tests”，用户在本地或 CI 中找不到相应测试，会产生误解。

3. **间接依赖冲突**  
   - 其他测试目录（比如 `core`、`srt`）可能在未来引用 `util.py`、`pytest.ini` 中的配置或常量。如果后续新增测试直接复制旧代码而未同步更新，可能出现 ImportError。

4. **安全/稳定性验证缺失**  
   - `ignore_eos` 参数的安全性（防止无限生成）以及大 token 处理的资源防护（防 OOM、超时）现在没有监管，可能在高并发或大请求情形下导致 **资源泄露** 或 **服务失效**。

---

## 💡 关注建议

| 建议 | 说明 | 操作方式 |
|------|------|----------|
| **保留或迁移关键测试** | 将 **function calling、tool‑choice、reasoning、ignore_eos** 等核心场景迁移到 **非 gRPC**（如 HTTP/REST）或 **单独的独立测试套件**，确保仍有回归检测。 | 1. 建立 `tests/e2e_http/` 或 `tests/functional/`，复制并适配相应测试；2. 在 CI 中增加对应 job。 |
| **在 CI 中标记已废弃** | 在 `README.md`、文档和 CI badge中明确声明 **gRPC e2e tests 已被移除**，避免用户误解。 | 更新文档，添加 `⚠️ gRPC e2e tests 已不再执行` 注释。 |
| **增加轻量化 smoke test** | 为关键 gRPC 功能设计 **快速 smoke test**（例如只跑一次 `chat/completions`，不进行复杂工具调用），以在 CI 中保留最基本的端到端检查，防止大幅回归。 | 在 `.github/workflows/pr-test-rust.yml` 中新增 `grpc-smoke` 步骤，使用极小模型或 mock server。 |
| **监控模型下载/资源占用** | 由于删除了大模型的长时间下载，CI 资源使用下降；但如果未来重新加入测试，需要 **缓存模型** 或使用 **artifact**，防止再次出现资源瓶颈。 | 使用 GitHub Actions `actions/cache` 缓存 `~/.cache/huggingface` 目录。 |
| **审计残余引用** | 使用全局搜索确认代码库不再出现对已删除 `util.py`、`pytest.ini` 常量的引用，防止潜在的 ImportError。 | `git grep "util.py"`、`git grep "STDOUT_FILENAME"` 等。 |
| **增强单元测试覆盖** | 在核心库层面（如 `sglang.router`, `sglang.worker`）补充单元测试，覆盖刚才删除的 e2e 场景的关键业务逻辑，以弥补端到端覆盖的缺失。 | 编写 `tests/unit/test_router_toolcall.py`，使用 mock 对象验证 `tool_call_parser` 的输出。 |
| **定期回顾测试策略** | 建议项目维护者定期（如每 3

---

### [grpc] Auto-generate protobuf files during wheel build (#16409)
**SHA**: `1688023` | 🔗 [查看提交](https://github.com/sgl-project/sglang/commit/16880235d17a8fe8f93e5e650cf368334779abda)

**🎯 变更类型**：功能增强 / 架构变更  
**⚡ 重要程度**：🔴 高  

**📋 变更摘要**  
- 在 `python/setup.py` 中新增自定义构建指令，在 wheel 打包、editable 安装或生成 egg‑info 时自动编译 `sglang_scheduler.proto`，生成 `*_pb2.py`、`*_pb2_grpc.py` 与对应的 `.pyi` 类型存根。  
- `pyproject.toml` 增加 `grpcio-tools==1.75.1` 作为构建时依赖，并在 `.gitignore` 中将生成的 protobuf 文件标记为可再生成的产物。  
- 同时删除仓库中已经生成好的 `sglang_scheduler_pb2*`、`sglang_scheduler_pb2_grpc*` 文件（共计约 1200 行），改为由构建流程实时生成。  

**🎯 影响范围**  
- `python/sglang/srt/grpc/` 包下的所有 gRPC 接口代码。  
- 项目打包与发布流程（wheel、editable install、CI 打包）。  
- 依赖管理（新增 `grpcio-tools` 版本锁定）。  

**🔍 技术洞察**  

| 维度 | 影响 |
|------|------|
| **架构影响** | - 将 protobuf 编译从源码库迁移到构建阶段，构建产物更具一致性；减少了因手动编辑/同步错误导致的运行时异常。<br>- 通过 `_fix_imports` 将生成的 `*_pb2_grpc.py` 中的绝对导入改为相对导入，确保在包内部使用时的相对路径正确，提升模块化兼容性。 |
| **性能影响** | - 编译 protobuf 只在构建时执行，对运行时性能无直接影响。<br>- 生成的代码大小与原先提交的文件相同，加载速度保持不变。 |
| **安全考虑** | - 引入 `grpcio-tools` 作为构建依赖，若使用不受信任的 `*.proto` 文件，可能触发代码生成攻击（如恶意的 `proto` 导入）。<br>- 构建时通过 `subprocess.run(..., check=True)` 捕获 `protoc` 错误，防止生成损坏的代码进入发行包。 |
| **可维护性** | - 移除大量手动维护的生成文件，降低因代码生成器升级或 .proto 变更后忘记同步的风险。<br>- CI/CD 中只需要确保 `grpcio-tools` 可用，即可自动保持最新的 gRPC 接口实现。 |
| **兼容性** | - 需要 `grpcio-tools==1.75.1`（与项目当前使用的 `grpcio` 兼容），可能导致在旧版 Python 环境或不允许安装 C‑extensions 的平台上构建失败。<br>- 对于直接使用源码（不走 `pip install .`）的开发者，仍需在本地执行 `python setup.py develop` 或 `pip install -e .`，否则缺失 `*_pb2*` 文件会导致 `ImportError`。 |

**⚠️ 潜在风险**  
1. **构建环境依赖缺失**：在一些轻量化 CI（如本地 CI、GitHub Actions 自带的 `python` 镜像）未预装 `grpcio-tools`，构建会中止。  
2. **版本不匹配**：`grpcio-tools` 与实际运行时的 `grpcio` 版本不匹配（例如用户自行装的旧版 `grpcio`），可能出现运行时 “generated code requires grpcio>=X.Y.Z”。  
3. **网络访问**：`grpcio-tools` 需要从 PyPI 下载，网络受限的环境（如国内镜像不完整）会导致构建卡死。  
4. **错误的 .proto**：如果 `sglang_scheduler.proto` 本身出现语法错误或不兼容当前 `protoc`，构建会失败，影响所有依赖方。  
5. **相对导入 bug**：`_fix_imports` 只处理单一模式的 import（`import xxx_pb2`），若 `protoc` 生成其他 import 形式（如 `from xxx_pb2 import ...`），可能仍保持绝对路径，导致运行时 `ModuleNotFoundError`。  

**💡 关注建议**  
- **CI 防护**：在 CI 中添加显式步骤 `python -m pip install "grpcio-tools==1.75.1"` 并检测 `grpc_tools.protoc --version`，确保构建前已准备好。  
- **错误提示**：在 `compile_proto()` 中捕获 `FileNotFoundError`（缺少 `protoc`）或 `ImportError`（缺少 `grpcio-tools`），并给出友好的提示，引导用户先执行 `pip install -r requirements-build.txt`。  
- **可选降级路径**：提供 `compile_proto.py` 脚本（已有），在开发者手动运行时可跳过 `setup.py`，并在 `README` 中说明 “如果构建失败，请先运行 `python compile_proto.py`”。  
- **版本锁定**：考虑在 `requirements-build.txt` 中固定 `grpcio-tools` 与 `grpcio` 的兼容范围，防止未来升级导致不匹配。  
- **文档更新**：在发布说明中明确说明 “生成的 protobuf 文件不再提交，构建时会自动生成”。并在 *Installation* 部分加入构建依赖说明。  
- **回滚兼容**：保留一个 `generated/` 目录的历史文件（可通过 git tag）以便紧急回滚到不依赖构建生成的版本。  

通过上述改动，项目的构建过程更加自动化、源码库更干净，同时也需要做好构建环境的依赖保障，以避免因为生成步骤失败导致的发布阻断。

---

#### 🟡 中重要度变更 (24)

### [nemetron/mtp] fix nemotron mtp (#16275)
**SHA**: `5dcff94` | 🔗 [查看提交](https://github.com/sgl-project/sglang/commit/5dcff94791749efb74d13fb09c99c45c02dbab00)

**🎯 变更类型**：功能增强（为 Nemotron‑H 系列加入 speculative 解码的中间状态索引）  
**⚡ 重要程度**：🟡 中（影响解码路径但仅在开启 speculative 时生效）  

**📋 变更摘要**  
1. 在 `Mamba` 前向中为 draft‑token 解码新增 `intermediate_state_indices`，用于在多轮草稿阶段定位缓存中的中间状态。  
2. Triton kernel `selective_state_update` 增加 `HAS_INTERMEDIATE_STATE_INDICES` 启发式以及相应指针参数，改写缓存索引的读取逻辑，使其优先使用提供的索引而非 `state_batch_indices`。  
3. `server_args` 中加入检测：当 `speculative_algorithm` 不为空且未手动关闭 radix 缓存时，自动关闭 radix 缓存并给出警告。  

**🎯 影响范围**  
- `python/sglang/srt/layers/attention/mamba/mamba.py`（前向路径）  
- `python/sglang/srt/layers/attention/mamba/ops/mamba_ssm.py`（底层 Triton kernel）  
- `python/sglang/srt/server_args.py`（启动参数与缓存策略）  

**💡 关注建议**  
1. **兼容性**：`intermediate_state_indices` 默认在 `num_decodes` 为 0 时仍会生成张量，若后续有其他分支未传入该参数，需确保 `None` 检查不导致非法访问。  
2. **正确性**：在开启 speculative 时，验证 `intermediate_state_indices` 与实际缓存 stride（`cache_steps * nheads * dim * dstate`）对应；尤其注意 `torch.int32`→`tl.int64` 转换是否在所有 GPU 上一致。  
3. **性能**：新增张量在每轮解码都会 allocate，建议在 `forward` 开头缓存复用或在 `speculative` 环境下提前创建，以免产生不必要的显存碎片。  
4. **测试**：添加针对 Nemotron‑H 的 speculative 解码单元测试，覆盖：① 有/无 `intermediate_state_indices`；② 关闭 radix cache 的路径；③ 旧版（非 speculative）模型确保行为不受影响。  
5. **文档**：更新模型说明，明确 “Nemotron‑H speculative decoding 目前不兼容 radix cache” 的限制，并给出 `--disable-radix-cache` 的使用示例。  

总体来说，本次改动为 Nemotron‑H 引入了关键的草稿解码支持，但需要在显存管理、参数检查和文档上做进一步完善，以防在生产环境中出现意外的缓存冲突或性能回退。

---

### Support token low usage watermark in prefill delayer (#16814)
**SHA**: `8eeffbe` | 🔗 [查看提交](https://github.com/sgl-project/sglang/commit/8eeffbe9aa0fcab23f2567ad4d3aadfaba7ce29c)

**🎯 变更类型**：功能增强  
**⚡ 重要程度**：🟡 中  

**📋 变更摘要**  
1. 在 `Envs` 中新增环境变量 `SGLANG_PREFILL_DELAYER_TOKEN_USAGE_LOW_WATERMARK`（Float），用于控制 “低 token 使用率” 的强制预填充阈值。  
2. `PrefillDelayer` 增加 `token_usage_low_watermark` 参数，并在 `_negotiate_should_allow_prefill_*` 流程中加入对该阈值的判断：当本地可预填且全局 token 使用率低于阈值时，即使出现 “mixed” 状态也会强制允许预填（输出 reason 为 `token_watermark`）。  
3. 相关调用链同步更新：`Scheduler.init_schedule_policy`、`Scheduler.get_new_batch_prefill`、`PrefillDelayerSinglePassExecutor` 均传递 token 使用率。  
4. 指标采集改为布尔字符串（`true/false`），并新增 `token_watermark` 计数。  
5. 大量单元/集成测试扩展以覆盖 watermark 场景，包括开启/关闭阈值的行为验证与实际吞吐测试。  

**🎯 影响范围**  
- `python/sglang/srt/environ.py`（环境变量）  
- `python/sglang/srt/managers/prefill_delayer.py`（调度核心）  
- `python/sglang/srt/managers/scheduler.py`（调度入口）  
- `python/sglang/srt/metrics/collector.py`（Prometheus 指标）  
- 测试套件 `test/srt/*`（新增和改动的用例）  

**💡 关注建议**  
1. **向后兼容**：`token_usage_low_watermark` 允许 `None`，务必在部署脚本或 CI 中保持默认不生效，防止意外强制预填。  
2. **参数获取**：确保在 `Scheduler._get_token_info()` 中返回的 `token_usage` 正确反映真实 KV‑cache 使用率，避免因统计不准导致误判。  
3. **监控**：部署后关注 `prefill_delayer_outcomes_total` 中的 `output_reason="token_watermark"` 与 `token_watermark` 计数，验证阈值触发频率符合预期。  
4. **性能验证**：在不同硬件（如 H200 vs B200）上跑 `TestPrefillDelayerTokenUsageLowWatermark`，必要时调节 `max_delay_passes` 与阈值，以防出现过度延迟或误触。  
5. **文档更新**：在使用说明中加入 `SGLANG_PREFILL_DELAYER_TOKEN_USAGE_LOW_WATERMARK` 环境变量的作用、取值范围及推荐配置。  

总体来看，此次改动为 PrefillDelayer 引入了基于 token 使用率的自适应放行机制，可在缓存紧张时提升吞吐，但需在生产环境中谨慎调参并监控新指标。

---

### Tiny add and enhance tests for prefill delayer (#16813)
**SHA**: `71e9c31` | 🔗 [查看提交](https://github.com/sgl-project/sglang/commit/71e9c31cb800cf98daf73cf8a7c4866b1ecce18f)

**变更类型**：功能增强（测试覆盖）  
**重要程度**：🟡 中  

**变更概述**  
- 为 `PrefillDelayer` 新增单元测试，验证其在多卡协商过程中的 `should_allow_prefill` 行为，并加入基于 `torch.distributed` 的 4‑GPU并行模拟。  
- 重构吞吐量基准测试，抽取 `_run_throughput_comparison`、`_assert_throughput_improvement` 等工具函数，明确要求 `SGLANG_TEST_WORLD_SIZE=8` 并检查整体吞吐提升阈值。  
- 拓展启动服务函数 ` _launch_server`，新增 `max_delay_passes` 参数并使用统一的 `WORLD_SIZE` 环境变量。  
- 更新 Prometheus 指标校验，改为检查 `sglang:prefill_delayer_outcomes_total`，并提供 `_sum_prometheus_metric_values` 辅助。

**影响范围**  
- `test/srt/test_prefill_delayer.py`（新增大量测试代码）  
- `sglang/srt/managers/prefill_delayer.py`（间接被测试）  
- `sglang/srt/utils.py`（启动服务相关参数）  

**关注建议**  
1. **CI 环境**：该套测试强依赖 8 张 GPU（或至少 4 张用于协商），CI 如未配置相应资源会直接失败。建议在 CI 中加入 `skipif` 或 `pytest.mark.timeout`，或提供 `--world-size` 参数的回退方案。  
2. **进程清理**：`torch.multiprocessing.spawn` 创建的子进程在异常情况下可能残留，确保 `p.terminate()`/`p.join()` 在测试异常时也能执行。  
3. **环境变量**：`WORLD_SIZE` 为字符串比较，后续若改为 int 需同步更新断言 `test_case.assertEqual(WORLD_SIZE, "8")`。  
4. **指标解析**：新增的 `_sum_prometheus_metric_values` 目前未被调用，若后续需要统计特定标签的计数，请在相应断言中使用。  
5. **代码可维护性**：将 `_run_throughput_test` 中 `prefill_delayer` 参数位置统一放在 `other_args` 前后，避免因顺序导致的启动失败。  

总体而言，此次提交提升了 `PrefillDelayer` 的可靠性验证，但对硬件依赖和进程管理提出了更高要求，建议在非 GPU 环境下提供跳过或模拟路径。

---

### Tiny enhance prefill delayer observability (#16812)
**SHA**: `7656d26` | 🔗 [查看提交](https://github.com/sgl-project/sglang/commit/7656d26737a2bc61a301b90d28658160c01649bb)

**🎯 变更类型**：功能增强（可观测性）  
**⚡ 重要程度**：🟡 中  

**📋 变更摘要**  
1. 将 `PrefillDelayer` 的观测接口从 `observe_prefill_delayer_wait` 改为 `observe_prefill_delayer_outcome`，新增 **input_estimation、output_allow、output_reason、actual_execution** 四个维度。  
2. 为等待次数、等待时长的直方图添加 “≤0” bucket，以记录零延迟情况。  
3. 新增 `prefill_delayer_outcomes_total` Counter，用于统计不同结果组合的次数。  

**🎯 影响范围**  
- `python/sglang/srt/managers/prefill_delayer.py`（调用新的观测函数）  
- `python/sglang/srt/metrics/collector.py`（新增/修改指标定义、实现）  

**💡 关注建议**  
- **兼容性**：`MetricsCollector.observe_prefill_delayer_wait` 已被删除，外部或测试代码若仍旧调用会报错，请统一迁移到 `observe_prefill_delayer_outcome`。  
- **标签基数**：`input_estimation` 与 `output_reason` 可能产生高基数，建议在文档中约定其取值范围或使用枚举，以防 Prometheus 爆表。  
- **监控查询**：新增的 “0” bucket 可能导致直方图的 `sum` 与 `count` 与旧版本不兼容，相关告警规则需同步更新。  
- **单元测试**：请补充对新 Counter 的统计验证以及零延迟分支的 histogram 记录，确保指标正确上报。  
- **文档**：在 README/监控说明中加入新指标 `sglang:prefill_delayer_outcomes_total` 的含义和标签解释。  

整体上，此次改动提升了 Prefill Delayer 的可观测性，但需要注意标签基数和向后兼容性，及时更新相关监控、文档和测试。

---

### Refactor prefill delayer for clarity and extensibility (#16811)
**SHA**: `dd24ba9` | 🔗 [查看提交](https://github.com/sgl-project/sglang/commit/dd24ba9084bdb739f0195b2d1bfa486b7c8a0e9a)

**变更概述**  
本次提交对 `PrefillDelayer` 进行了结构性重构：引入不可变 `_State` 与 `_NegotiateOutput`，将延迟计数、超时判断、日志与指标统一封装；新增 `max_delay_passes` 参数以外部化阈值；改写单次调度入口为 `PrefillDelayerSinglePassExecutor`，通过 `finalize` 在调度结束后统一记录指标。`Scheduler` 相应删掉 `nullcontext`，改为手动创建/最终化 executor。

**影响范围**  
- `python/sglang/srt/managers/prefill_delayer.py`（核心调度逻辑、状态管理、指标收集）  
- `python/sglang/srt/managers/scheduler.py`（批调度入口、PrefillDelayer 实例化）  

**重点审查**  
1. **不可变状态**：`_State` 使用 `dataclasses.replace`，确保并发安全，但 `bump_delayed_count` 每次返回新实例，需确认外部保持引用（已在 `_negotiate_should_allow_prefill_pure` 中使用）。  
2. **返回结构**：`_NegotiateOutput` 包含 `next_state`、`output_allow`、`output_reason` 等，调度器需依据 `output_allow` 决策，当前实现已返回 `bool`，兼容性良好。  
3. **指标记录**：`_record_single_pass_result` 计算等待时间仅在 `next_state` 非空时，确保 `start_time` 正确；若 `max_delay_passes` 为 0，`next_state` 仍会为 `None`，需确认未产生除零错误。  
4. **Scheduler 改动**：去除 `nullcontext`，手动调用 `finalize`，确保即使 `prefill_delayer` 为 `None` 也不抛异常。`finalize` 传入 `actual_prefill`，但若 `_get_new_batch_prefill_raw` 抛异常，`finalize` 未被调用，建议在异常捕获后仍调用以避免漏记指标。  
5. **初始化参数**：`PrefillDelayer` 新增 `max_delay_passes`，Scheduler 通过 `envs.SGLANG_PREFILL_DELAYER_MAX_DELAY_PASSES` 注入，确保 env 配置兼容旧版本（默认仍可得到原行为）。  

**建议**  
- 为 `PrefillDelayerSinglePassExecutor.finalize` 加上异常安全包装，确保指标必写。  
- 在单元测试中覆盖 “mixed+delay达到上限”“全可预填”“全不可预填” 三种分支，以及 `max_delay_passes=0` 场景。  
- 文档或 README 中说明 `max_delay_passes` 新配置项的含义及默认值，防止用户误设导致过度延迟。  

整体改动提升了代码可读性、可扩展性和度量一致性，风险主要在异常路径的指标漏记和 `max_delay_passes` 配置的边界值，建议相应添加测试与容错处理。

---

### [diffusion] amd: fix SGLANG_DIFFUSION_ATTENTION_BACKEND env var for diffusion attention backend selection (#16325)
**SHA**: `64a31d4` | 🔗 [查看提交](https://github.com/sgl-project/sglang/commit/64a31d4b75fac33840156479b1c9e9a62c0e5ae8)

**🎯 变更类型**：功能增强 / 稳定性改进  
**⚡ 重要程度**：🟡 中  
**📋 变更摘要**  
1. 删除了 `SGLANG_DIFFUSION_ATTENTION_BACKEND=AITER` 的强制设定，使注意力后端只受 `global_force_attn_backend()` 或 CLI 参数控制，防止环境变量意外覆盖。  
2. Scheduler 在接收请求时加入了连续错误计数与阈值（3 次），超限后抛异常终止 event‑loop，提升服务失效可检测性。  
3. LoRA 加载在多机（rank）环境下实现 0 号进程先下载、其余进程等待 barrier 再各自读取缓存，避免并发写冲突。  
4. ROCm 平台移除对 `SGLANG_DIFFUSION_ATTENTION_BACKEND` 的日志输出，统一后端选择逻辑；对 AITer dtype 警告文字略作调整。

**🎯 影响范围**  
- `python/sglang/multimodal_gen/runtime/layers/attention/selector.py`（注意力后端选择）  
- `python/sglang/multimodal_gen/runtime/managers/scheduler.py`（调度器错误容忍）  
- `python/sglang/multimodal_gen/runtime/pipelines_core/lora_pipeline.py`（LoRA 分布式下载）  
- `python/sglang/multimodal_gen/runtime/platforms/rocm.py`（ROCm 后端日志与警告）  
- CI 工作流 `.github/workflows/pr-test-amd.yml`（去除旧 env var）

**💡 关注建议**  
1. **环境变量兼容**：`selector.py` 已不再读取 `SGLANG_DIFFUSION_ATTENTION_BACKEND`，如仍有用户在外部脚本中依赖该变量，需要在文档中说明已废弃并提供迁移方式。  
2. **Scheduler 错误处理**：确认在生产部署中 `max_consecutive_errors` 是否合适，避免因一次短暂网络抖动就导致服务全停；必要时把阈值设为可配置。  
3. **分布式屏障**：`lora_pipeline.py` 使用 `dist.is_initialized()` 与 `dist.barrier()`，但在单机未启用 torch.distributed 时仍会走 `else` 分支，需确保 `maybe_download_lora` 在所有进程都能安全调用（即使缓存已存在）。  
4. **日志一致性**：ROCm 端去除 env var 日志后，调试时若需查看实际选用的后端，建议在 `get_attn_backend_cls_str` 统一打印 `selected_backend`。  
5. **测试覆盖**：新增单元/集成测试验证：① env var 被忽略的注意力选择路径；② Scheduler 连续错误触发异常；③ 多 rank LoRA 下载的 barrier 行为。  

总体来看，此次改动提升了注意力后端的可控性、Scheduler 的容错能力以及 LoRA 分布式加载的可靠性，影响范围主要限于注意力层、调度器和 LoRA 管线，风险相对可控。若按上面建议完善文档与配置，可进一步降低用户升级成本。

---

### Fix external_models import path and migrate model loading tests (#16458)
**SHA**: `e46f794` | 🔗 [查看提交](https://github.com/sgl-project/sglang/commit/e46f79431b809aca979f105cb6034684f9ff9b53)

**🎯 变更类型**：Bug 修复 / 功能增强  
**⚡ 重要程度**：🟡 中  
**📋 变更摘要**：  
1. 修正 `external_models` 的导入路径，使其在测试环境下能够正确加载。  
2. 为模型加载相关测试统一在 CI 中注册（`register_cuda_ci` / `register_amd_ci`），并调整 `run_suite.py` 中的测试分配，使这些测试不再随默认的 per‑commit 套件运行。  
3. 将 CI 分区从 11 改为 14，保证所有分区都有对应的测试。  
4. 在 `deep_gemm.py` 中为 `torch.compile` 添加 `disable=_is_hip or _is_npu`，防止在非 CUDA 环境下触发编译错误。

**🎯 影响范围**：  
- `sglang/test/external_models` 与 `test/registered/model_loading` 目录下的测试文件。  
- GitHub Actions 工作流 `pr-test.yml`（分区与并行数）。  
- `sglang/srt/layers/moe/moe_runner/deep_gemm.py`（编译路径）。  
- `test/srt/run_suite.py`（默认套件配置）。

**💡 关注建议**  
1. **路径兼容**：确认 `sglang.test.external_models` 包在生产环境仍保持可用，或在文档中标明仅供 CI/测试使用。  
2. **CI 注册**：`register_cuda_ci` / `register_amd_ci` 的调用顺序和参数需与 CI 脚本保持一致，避免出现 “est_time” 与实际执行时间不符导致分区调度失衡。  
3. **分区改动**：增加的分区（11‑13）是否已有对应的测试文件？若无，应在 CI 中加入占位或注释，以免出现空分区导致跑批不均。  
4. **torch.compile 过滤**：`_is_hip`、`_is_npu` 的定义位置需要确保在导入时已可用，防止在不支持的硬件上仍尝试编译。  
5. **run_suite 更新**：被移除的测试（`test_external_models.py`、`test_modelopt_loader.py`、`test_utils_update_weights.py`、`test_modelopt_export.py`）已在新分区跑完，最好在 CI 文档或注释中说明原因，便于后续维护。  

总体来看，此次改动主要是提升测试的可靠性与可维护性，只要检查上述兼容性细节即可安全合并。

---

### support page size large than 64 for mamba radix cache with fix (#16768)
**SHA**: `41609b5` | 🔗 [查看提交](https://github.com/sgl-project/sglang/commit/41609b52fe78b1d72b6d67caeb5c526bb47ea6f2)

**🎯 变更类型**：功能增强  
**⚡ 重要程度**：🟡 中  
**📋 变更摘要**：  
1. 新增 `ServerArgs.mamba_cache_chunk_size` 参数，统一使用 `max(FLA_CHUNK_SIZE, page_size)` 作为 Mamba 缓存块大小，解决 page size 大于 64 时的对齐问题。  
2. 在 `hybrid_linear_attn_backend.py`、`schedule_batch.py`、`mamba_radix_cache.py` 中改用该参数，并在分支‑track 计算中加入 `_force_track_h` 以在非对齐情形下强制向后取 1，确保从 `h` 中取到正确的 Mamba 状态。  
3. 更新 `server_args.py` 的检查信息以及相关注释。  
4. 调整测试基准，使 MTP（多进程）模型的阈值更宽松，防止因新缓存行为导致的回归。

**🎯 影响范围**：  
- **内存缓存层**：`sglang.srt.mem_cache.mamba_radix_cache`、`sglang.srt.managers.schedule_batch`  
- **注意力实现**：`sglang.srt.layers.attention.hybrid_linear_attn_backend`  
- **服务器配置**：`sglang.srt.server_args`（新增属性）  
- **测试套件**：`test.srt.models.test_qwen3_next_models`

**💡 关注建议**：  
1. **兼容性检查**：新参数默认取 `max(FLA_CHUNK_SIZE, page_size)`，但若用户自行在运行时修改 `page_size`，需要确认所有旧代码（尤其是自定义插件）仍使用 `self.page_size` 而非新属性，避免出现两套不一致的对齐计算。建议在文档中注明迁移步骤。  
2. **边界条件**：`_force_track_h` 通过 `i + 1` 强制向后取 1，若 `i` 已是序列末尾（如 `extend_input_len` 正好等于块大小），会产生越界访问。请在调用前添加断言或改为 `min(i+1, max_len)` 以防止潜在的 `IndexError`。  
3. **性能评估**：块大小增大后，缓存命中率可能提升，但对齐计算次数也会增多，建议在不同 `page_size`（如 128、256）下跑一次基准，确认延迟和显存占用未出现异常。  
4. **测试覆盖**：当前仅调整了 MTP 的阈值，建议补充针对 `mamba_cache_chunk_size` 不等于 `FLA_CHUNK_SIZE`（例如 `page_size=128`）的单元测试，验证 `branching_seqlen_aligned_mask`、`mamba_last_track_seqlen` 等关键路径的正确性。  

总体来看，本次改动解决了 “page size > 64” 的缓存对齐 bug，改动范围集中在缓存与调度代码，风险可控。完成上述检查后即可合并。

---

### List ci workflows status. (#16774)
**SHA**: `f7c1d24` | 🔗 [查看提交](https://github.com/sgl-project/sglang/commit/f7c1d24b18ee791cf2c9caad23930ad322569815)

**变更类型**：功能增强（CI 辅助工具）  
**重要程度**：🟡 中  

### 变更概述  
本次提交在 `.github/workflows/` 下新增 `list-active-pr-runs.yml.yml`，实现一个可手动或在 PR 同步时触发的工作流，用 GitHub CLI + jq 列出当前所有 **pull_request** 事件的排队或运行中的 workflow，按 “high priority” 标签排序并输出详细的跑批、排队时长、使用的 runner 等信息。

### 影响范围  
- **CI 环境**：每次 PR 同步或手动触发都会安装 `gh`、`jq`，并调用 GitHub API，可能略微延长 CI 时长。  
- **仓库权限**：工作流读取 `pull-requests`、`actions`、`contents` 权限，不涉及写操作，安全风险较低。  
- **工作流文件名**：使用了双后缀 `.yml.yml`，GitHub Actions 只识别 `.yml`/`.yaml`，当前文件可能 **不会被自动识别**，只能通过手动 `workflow_dispatch` 调用。  

### 关注建议  
1. **文件命名**：建议改为 `list-active-pr-runs.yml`，确保 GitHub 能在 PR 打开/同步时自动触发。  
2. **触发频率**：`pull_request: synchronize` 会在每次推送新 commit 时执行，若 PR 较活跃可能导致频繁调用 API，建议加上 `if: github.event.pull_request.draft == false` 或使用 `workflow_run` 限流。  
3. **依赖与缓存**：`apt-get install gh jq` 每次都重新安装，耗时可通过 `actions/setup-gh` 或缓存 `apt` 包来优化。  
4. **安全审计**：虽然只读权限，但仍会使用 `GITHUB_TOKEN` 调用 `gh api`，确认仓库未开启敏感信息泄露的风险（如打印 `head_sha`）。  
5. **标签硬编码**：当前硬编码 “high priority”。若后续标签变更，需同步更新脚本；可考虑把标签名设为 workflow 输入参数。  

总体而言，此工作流为维护者提供了快速定位卡住 PR 的可视化报告，对 CI 运营有帮助，但需修正文件后缀并考虑执行成本与触发频率，以免产生不必要的负担。

---

### Tiny simplify draft worker init. (#16446)
**SHA**: `75da784` | 🔗 [查看提交](https://github.com/sgl-project/sglang/commit/75da784d48c8868d0be92c55429cd56ac4ef453c)

**🎯 变更类型**：功能增强 / 重构  
**⚡ 重要程度**：🟡 中  

**📋 变更摘要**  
1. 将 `init_draft_worker` 改名为 `maybe_init_draft_worker`，在投机算法为 NONE 时直接跳过并将 `draft_worker` 设为 `None`。  
2. `SpecInfo.create_worker` 的签名由 `enable_overlap` → `server_args`，内部统一根据 `server_args.disable_overlap_schedule`、`enable_multi_layer_eagle` 选择相应的 DraftWorker 类。  
3. 移除了原来的多层 Eagle 条件分支，改由 `create_worker` 完全负责类的返回，`Scheduler` 只负责实例化。

**🎯 影响范围**  
- `python/sglang/srt/managers/scheduler.py`（调度器初始化）  
- `python/sglang/srt/speculative/spec_info.py`（投机算法工厂）  
- 相关的多层 Eagle、EAGLE、NGRAM Worker 实现（类返回路径）  

**💡 关注建议**  
- **兼容性**：`create_worker` 参数更改会影响所有直接调用该方法的地方，确认除 `Scheduler` 外没有遗漏的调用。  
- **错误处理**：当前假设 `create_worker` 必返回合法类，若返回 `None` 将导致实例化错误，建议在 `maybe_init_draft_worker` 中加 `if DraftWorkerClass is None: self.draft_worker=None` 的防御代码。  
- **配置验证**：`disable_overlap_schedule`、`enable_multi_layer_eagle` 等 flag 的默认值与文档保持一致，防止出现意外的 `None` worker。  
- **单元测试**：补充 NONE、EAGLE（单层/多层）以及 NGRAM 三种情形的初始化测试，确保 `draft_worker` 正确为 `None` 或相应实例。  
- **文档/注释**：为 `maybe_init_draft_worker` 与 `SpecInfo.create_worker` 添加简要说明，帮助后续维护。  

整体来说，此次重构简化了投机 worker 的初始化路径，降低了调度器的分支复杂度，但需确保新签名的传播与异常安全性。

---

### [DeepSeek 3.2] Support and optimize pipeline parallelis when context pipeline enabled (#16380)
**SHA**: `05dfef9` | 🔗 [查看提交](https://github.com/sgl-project/sglang/commit/05dfef92a1f03cf4f308b9bd529bfb149d737e67)

**🎯 变更类型**：功能增强 / 性能优化  
**⚡ 重要程度**：🟡 中  

**📋 变更摘要**  
1. 为 DeepSeek‑3.2 模型在开启 **context‑pipeline**（即 Prefill‑Context Parallel）时加入对 **pipeline parallelism (PP)** 的适配。  
2. 在 `nsa_indexer` 中通过 `self.logits_with_pp_recv` 判断当前 PP 级别是否需要额外的 recv SM，使用 `deep_gemm_wrapper.configure_deep_gemm_num_sms` 动态把可用 SM 数减 1，从而避免 SM 资源争用。  
3. 在 `Scheduler`（`scheduler_pp_mixin.py`）加入 `require_attn_tp_allgather` 标志，CP 模式下不再进行 Attention TP 的 All‑Gather，进而省去不必要的通信。  
4. 将上述标志在发送/接收 Tensor 时作为 `all_gather_group` 参数的开关，实现条件性 All‑Gather。

**🎯 影响范围**  
- **核心模块**：`sglang.srt.layers.attention.nsa`（NSA Indexer）、`sglang.srt.managers.scheduler_pp_mixin`、`sglang.srt.distributed.parallel_state`（`get_pp_group`）以及相关的硬件抽象层（deep_gemm、deep_gemm_wrapper）。  
- **运行时路径**：Prefill 阶段的 `context_pipeline`、解码阶段的 PP 循环、以及多卡 TP All‑Gather。  

**💡 关注建议**  

1. **功能验证**  
   - 在单机单卡、单机多卡（TP + PP）以及多机多卡配置下跑完整的 Prefill + Decode 流程，确保 **logits 与 logits_with_pp_recv** 分支在所有 PP rank 上均得到正确结果。  
   - 对比开启/关闭 `enable_nsa_prefill_context_parallel` 前后的输出一致性（相同随机种子），防止因 SM 计数偏差导致数值误差。  

2. **性能基准**  
   - 分别测量 **SM 使用率**（`nvidia-smi` 或 torch.profiler）以及 **通信时延**，确认在 CP 模式下 All‑Gather 被成功关闭，且 PP Recv 只占用 1 SM。  
   - 对比 `pp_size=1` 与 `pp_size>1` 的吞吐率，确认优化是否带来预期的 5%~10% 提升。  

3. **容错与回滚**  
   - `self.logits_with_pp_recv` 只在 CUDA 环境下生效，CPU/模拟环境仍使用原路径；确保 CI 中的 CPU 测试不因 `get_pp_group` 未初始化而崩溃。  
   - `deep_gemm_wrapper.configure_deep_gemm_num_sms` 的上下文管理器在异常抛出时必须恢复原配置，建议在异常路径加上 `finally` 进行显式恢复（目前依赖 contextmanager 自动恢复）。  

4. **配置兼容性**  
   - `server_args.enable_nsa_prefill_context_parallel` 为新开关，文档和 CLI 参数需同步更新；默认保持关闭，以免在已有部署上产生意外行为。  
   - `pp_loop_size` 计算已加入 `pp_async_batch_depth`，验证该值在极端大 batch 深度时不会导致数组越界。  

5. **代码可维护性**  
   - `contextlib.contextmanager` 的实现可抽成通用工具函数，以便未来对其他算子也进行 SM 资源裁剪。  
   - 在 `scheduler_pp_mixin.py` 中对 `require_attn_tp_allgather` 的注释建议标记为 **CP‑mode flag**，防止后续误删。  

总体来看，此次改动为 DeepSeek 3.2 在 **Prefill‑Context Parallel** 场景下的 PP 支持提供了必要的资源调度与通信优化，若通过上述验证，能够在保持功能正确性的前提下提升多卡吞吐。请在正式发布前完成上述回归与基准测试。

---

### [diffusion] model: wan tp+usp optimize (#16720)
**SHA**: `f7f5c38` | 🔗 [查看提交](https://github.com/sgl-project/sglang/commit/f7f5c3896d3fdb54fae3146879365000b916f0a1)

**🎯 变更类型**：功能增强（Tensor‑Parallel 支持）  
**⚡ 重要程度**：🟡 中  

**📋 变更摘要**  
1. 在 `layernorm.py` 新增 `tensor_parallel_rms_norm`，在模型并行时对 RMS‑Norm 进行跨卡均值归约并使用切分的 `weight`。  
2. `wanvideo` 模型改为使用 `ColumnParallelLinear`（不收集输出）和 `RowParallelLinear`（收集并求平均），并把注意力头数按张量并行度 `divide(..., tp_world_size)` 分配。  
3. 在前向路径中加入 `tp_rmsnorm` 判断，必要时调用新实现的并行 RMS‑Norm；同时统一 `unflatten` 维度为 `(-1, dim_head)`，避免硬编码 `num_attention_heads`。  

**🎯 影响范围**  
- `sglang/multimodal_gen/runtime/layers/layernorm.py`（并行 RMS‑Norm）  
- `sglang/multimodal_gen/runtime/models/dits/wanvideo.py`（WAN‑Video Transformer）  
- 相关的并行调度 (`parallel_state`, `divide`) 以及线性层实现 (`ColumnParallelLinear`, `RowParallelLinear`)  

**💡 关注建议**  
- **兼容性**：在单卡（tp=1）情况下 `tensor_parallel_rms_norm` 仍会进行一次 `all_reduce`，确认不会引入额外同步开销或改变数值。  
- **权重切分**：`norm.weight.tensor_split(tp_size)[tp_rank]` 假设 `weight` 能均匀切分，需在模型初始化时检查 `dim_head % tp_size == 0`。  
- **梯度同步**：`RowParallelLinear(..., reduce_results=True)` 会在 forward 端做 `all_reduce`，确保对应的 backward 也使用相同的通信图。  
- **测试**：新增单元测试覆盖 tp=1、2、4 的前向/反向路径，特别是 `norm_q/k` 与 `tensor_parallel_rms_norm` 的数值一致性。  
- **文档**：在模型配置说明里标注 “tensor_model_parallel_size 必须整除 num_attention_heads”，并给出 `tp_world_size` > 1 时的性能收益预期。  

整体来看，此次改动为 WAN‑Video 引入了张量并行加速，关键在于确保切分、通信与原始 FP32‑LayerNorm 行为保持一致，建议在多卡环境进行充分回归验证后再上线。

---

### [smg] cleanup router RAII guards (#16560)
**SHA**: `9e3a032` | 🔗 [查看提交](https://github.com/sgl-project/sglang/commit/9e3a032ad6ba3ffa2e3827ae9d2d36d2be1326e9)

**🎯 变更类型**：重构  
**⚡ 重要程度**：🟡 中  

**📋 变更摘要**  
将原本的 `attach_guards_to_response` 与 `GuardedBody/MultiGuardedBody` 实现改为通用的 `AttachedBody<T>`，用一个持有附加值的包装体来实现 RAII，统一了对 `WorkerLoadGuard`（以及未来可能的其他资源）生命周期的管理。相应地删除旧函数、简化 `WorkerLoadGuard::attach_to_response`，并在所有路由、HTTP/GRPC 处理链以及测试中改用 `AttachedBody::wrap_response`。

**🎯 影响范围**  
- `sgl-model-gateway/src/core/mod.rs`、`worker.rs`（核心包装体实现）  
- 所有使用 `attach_guards_to_response` 的路由模块：`routers/grpc/*`、`routers/http/*`  
- 单元测试 `tests/load_guard_raii_test.rs`  

**💡 关注建议**  
1. **兼容性**：`AttachedBody<T>` 要求 `T: Send + Unpin + 'static`，检查已有代码（尤其是自定义 guard）是否满足。  
2. **行为验证**：确认包装体在错误路径、客户端中断、空 Body 等场景仍能正确触发 `Drop`，建议运行完整的 CI 表和实际负载测试。  
3. **性能**：包装层仅添增一次结构体包装，理论上无额外拷贝，仍需关注在高并发流式请求下的 memory‑layout 与 GC（Arc）计数的影响。  
4. **文档**：更新 `core::worker`、路由模块的使用示例，说明新 API `AttachedBody::wrap_response` 替代旧 `attach_guards_to_response`。  
5. **后续扩展**：此通用实现为未来在响应体中附加日志、监控句柄等提供统一入口，建议在设计时保持 `AttachedBody` 的 minimal interface，避免在内部泄露实现细节。  

开发者在合并后应重点跑 `load_guard_raii_test` 与全链路压测，确保 guard 的释放时机未改变；用户侧调用无感知，只需使用新的 `wrap_response` 接口即可。

---

### [smg] update gRPC proto to match upstream changes (#16764)
**SHA**: `1bc7aa5` | 🔗 [查看提交](https://github.com/sgl-project/sglang/commit/1bc7aa5801666d8503a4f3d5160354e25c85a99d)

**🎯 变更类型**：功能增强 / 兼容上游  
**⚡ 重要程度**：🟡 中  

**📋 变更摘要**  
1. 更新 `vllm_engine.proto` 以匹配上游 vLLM 的最新协议：  
   - 将多数标量字段改为 **optional**（`float temperature`、`uint32 max_tokens` 等），并把 `int32` 改为 `uint32`。  
   - 将 `AbortRequest` 从单个 `request_id`/`reason` 改为 `repeated string request_ids`。  
   - `GenerateRequest` 中原来的 `tokenized` 字段改为 `oneof input`，支持普通文本 `text`。  
   - 移除 `GenerateError`、`EmbedError` 等错误子消息，错误将通过 gRPC 状态返回。  
2. 相应地在 Rust 客户端 `vllm_engine.rs`、包装层 `proto_wrapper.rs` 做了大量适配：  
   - 使用 `proto::generate_request::Input::Tokenized` 组装请求。  
   - 统一 `AbortRequest` 的构造，忽略已废弃的 `reason` 参数。  
   - 所有 `int32` 字段改为 `u32`，并在代码中添加 `as i32` 的转换，以保持外部统一的 `i32` 接口。  
   - `SamplingParams` 中可选字段改为 `Option<T>`（如 `temperature: Option<f32>`），并相应更新默认构造与字段映射宏。  
   - `ProtoGenerateResponse` 以及 `ProtoGenerateError` 的枚举实现作出调整，vLLM 端不再返回 `Error` 消息。  
   - 为避免所有权冲突，`ProtoGenerateResponse::Sglang` 包装为 `Box<>`。  

**🎯 影响范围**  
- **sgl-model-gateway/src/grpc_client/vllm_engine.rs**：请求构造、参数映射、abort 接口。  
- **sgl-model-gateway/src/proto/vllm_engine.proto**：协议本身的结构与字段类型。  
- **sgl-model-gateway/src/routers/grpc/proto_wrapper.rs**：统一响应包装、统计字段转换、错误处理。  
- 可能波及 **sgl-model-gateway/src/routers/**、**sgl-model-gateway/src/server/** 中对 `GenerateRequest` / `AbortRequest` 的直接使用。  

**💡 关注建议**  

| 关注点 | 建议 |
|--------|------|
| **向后兼容** | ① 现有调用仍期望 `request_id: String`（单值）和 `reason: String`，但现在被忽略。建议在网关层保留兼容包装：如果上层仍传单个 `request_id`，自动封装成 `vec![id]`。<br>② 对 `temperature`、`max_tokens` 等可选字段的默认行为保持不变（`None` → 使用后端默认），防止意外的 `0` 或 `None` 导致生成异常。 |
| **类型安全** | 代码中大量 `as i32`/`as u32` 转换，确保在溢出前做检查或使用 `try_from`，否则可能在极端情况下出现负数或截断。 |
| **错误处理** | 现在 vLLM 的错误通过 gRPC **status** 返回，`ProtoGenerateError` 只保留 Sglang 实现。请确认上层错误捕获路径能够处理 `tonic::Status` 并将其转化为统一的 `ProtoGenerateError`，避免出现 `panic!`。 |
| **测试覆盖** | 已新增单元测试验证新 proto 字段，但应补充：<br>① `AbortRequest` 多 ID 场景的集成测试。<br>② `GenerateRequest` 使用 `text` 输入（oneof）时的路径。 |
| **文档与示例** | 更新 README / API 文档，说明 `temperature`、`max_tokens` 已为 optional，`AbortRequest` 参数已变更，以及 `GenerateRequest` 现在支持原始文本。 |
| **跨语言兼容** | 如果项目提供 Python/Go 客户端，请确认对应的 proto 生成代码同步更新，防止不同语言的客户端出现字段缺失或类型不匹配。 |
| **性能影响** | 更改为 `optional` 并不会增加运行时开销，唯一的额外开销是 `Box` 包装 `Sglang` 响应，影响极小。 |

**总体评价**  
此次提交是一次必要的协议同步，代码已基本完成对应适配。唯一需要重点关注的是 **向后兼容**（单 ID abort、旧字段的默认处理）以及 **错误传播**（gRPC status → 统一错误类型）的实现细节。完成上述检查后，系统应能够平滑切换到上游 vLLM 最新协议。

---

### fix: extend cpu only install dependency timeout to 20 mins (#16759)
**SHA**: `a1b243d` | 🔗 [查看提交](https://github.com/sgl-project/sglang/commit/a1b243d76f1cb38e6845d9ec2a3b0df81732f3ac)

**🎯 变更类型**：Bug修复  
**⚡ 重要程度**：🟡 中  
**📋 变更摘要**：在 GitHub Actions 的 `pr-test.yml` 工作流中，将 CPU‑only 环境的 “Install dependencies” 步骤超时时间从 10 分钟提升至 20 分钟，防止因依赖编译或网络波动导致的超时失败。  

**🎯 影响范围**：  
- CI/CD 流程（`.github/workflows/pr-test.yml`）  
- 仅在 CPU‑only 测试 job 中生效，不影响 GPU、CUDA 或其他平台的构建。  

**💡 关注建议**：  
1. **监控 CI 时长**：延长超时后，单次 PR 的总耗时可能增加，建议在 CI 面板观察实际安装耗时，防止出现异常卡顿。  
2. **依赖锁定**：若依赖升级导致安装时间进一步增长，可考虑使用 `requirements.txt` 锁定版本或预构建的 wheel 包，以缩短安装过程。  
3. **网络可靠性**：CI 运行在公共网络环境，若仍出现超时，建议在步骤前加入缓存（`actions/cache`）或使用国内镜像源加速 `pip install`。  
4. **回滚策略**：如后续发现 20 分钟仍不足，或导致流水线资源占用过高，可再调高超时或拆分依赖安装为多个子步骤。  

此修改对普通用户影响极小，仅提升了 PR 检测的稳定性；开发者在本地运行时仍使用原始 `pip install -e "python/[dev]"`，无需额外调整。

---

### [grpc] Fix protobuf compilation in isolated build environments (#16754)
**SHA**: `55a8dd0` | 🔗 [查看提交](https://github.com/sgl-project/sglang/commit/55a8dd00959f95242f1d461e0f9809e8f8fecd08)

**🎯 变更类型**：Bug 修复 / 构建改进  
**⚡ 重要程度**：🟡 中  

**📋 变更摘要**  
- 为多平台 `pyproject_*.toml` 的 `build-system.requires` 添加了固定版本的 `grpcio-tools==1.75.1`，确保在隔离的 PEP 517 构建环境中能够找到 `grpc_tools.protoc`。  
- `setup.py` 将原先通过 `subprocess` 调用外部 `protoc` 的方式改为直接导入 `grpc_tools.protoc` 并在 Python 进程内部执行，同时加入了对 `grpcio-tools` 包内自带的 `_proto` 目录的搜索路径，解决了在纯粹的 wheel‑build 环境下找不到标准 proto 文件的问题。  

**🎯 影响范围**  
- **构建系统**：所有使用 `python -m pip wheel`、`pip install .` 或 `editable install` 的平台（CPU、XPU、Other）。  
- **源码**：`python/setup.py`、`python/pyproject_*.toml`。  

**💡 关注建议**  
1. **兼容性测试**：在没有全局 `grpcio-tools` 安装的干净 CI 环境（如 manylinux、musl）跑一遍完整的 wheel 打包，确保 `grpc_tools.protoc` 能被成功导入且生成的 `.py`、`.pyi` 正确。  
2. **版本锁定**：当前硬编码 `grpcio-tools==1.75.1`，后续若升级 `grpcio-tools`，需同步更新 `pyproject.toml` 并验证 `protoc.main` 参数兼容性。  
3. **错误信息**：`SetupError` 已经提示缺少依赖，建议在文档或 `README` 中明确说明 “构建前请确保使用的 Python 环境满足 `grpcio-tools==1.75.1`”。  
4. **路径恢复**：`original_cwd` 已保存并在 `finally` 中恢复，确保即使 `protoc.main` 改变工作目录也不会影响后续步骤，保持此实现即可。  

总体来看，此次改动解决了在隔离构建环境下 protobuf 编译失败的根本原因，风险主要集中在对 `grpcio-tools` 版本的强制锁定和对 `setup.py` 的运行时导入，建议在多平台 CI 中充分验证后再上线。

---

### fix(e2e): prevent potential hangs in model pool subprocess handling (#16752)
**SHA**: `cf24232` | 🔗 [查看提交](https://github.com/sgl-project/sglang/commit/cf24232100d0dc610660fded682de1cd088cb807)

**🎯 变更类型**：Bug 修复  
**⚡ 重要程度**：🟡 中  

**📋 变更摘要**  
- 在 `ModelInstance.terminate` 中，对 `process.kill()` 后新增 `wait(timeout=5)`，并在仍未退出时记录错误，防止子进程残留导致资源泄露。  
- 在模型池的健康检查 `_wait_all_healthy` 中，改为对子进程 `stderr` 使用 `select` + `os.read` 的非阻塞读取，并加上异常捕获，以避免因管道未关闭而产生的无限阻塞。  
- 同步更新了两处对 `stderr` 的读取逻辑，加入超时、大小限制以及 `errors="replace"` 解码，提升调试信息的可得性并防止程序挂起。

**🎯 影响范围**  
- `sgl-model-gateway/e2e_test/infra/model_pool.py`（模型池管理、子进程生命周期）  
- 相关的 e2e 测试脚本以及任何依赖该模型池的上层服务。

**💡 关注建议**  
1. **回归测试**：重点运行包含模型池启动/终止的 e2e 场景，确认在异常模型或超时情况下不再出现进程卡死。  
2. **资源监控**：在 CI 环境或本地调试时观察子进程的 PID 与句柄是否能在 `terminate` 调用后被系统回收，防止僵尸进程残留。  
3. **日志审查**：新加入的 `logger.error` 与 `logger.warning` 信息会在极端情况下出现，建议在生产环境中适当设置日志级别或采集，以帮助定位仍未被 `SIGKILL` 结束的进程。  
4. **兼容性检查**：`select` 与 `os.read` 依赖 POSIX 行为，在 Windows 上可能表现不同，若项目需跨平台运行，请确认测试覆盖 Windows 环境或提供替代实现。  

整体来看，此次改动通过非阻塞读取和安全的进程终止流程，有效消除了模型池在异常情况下的潜在死锁风险，对系统鲁棒性提升明显。只要通过上述回归验证，即可安全合并。

---

### Adjust the cancel PR workflows for better preemption. (#16749)
**SHA**: `064ae34` | 🔗 [查看提交](https://github.com/sgl-project/sglang/commit/064ae3419eed58558e7f46eb7fef180d86fc92ed)

**🎯 变更类型**：功能增强 / 重构  
**⚡ 重要程度**：🟡 中  
**📋 变更摘要**：删除了 `cancel-all-pending-pr-test-runs.yml` 与 `cancel-all-pr-test-runs.yml` 两个通用的 PR 运行取消工作流，新增 `cancel-unfinished-pr-tests.yml`。新工作流在取消 “queued / waiting / in_progress” PR 运行时，会先获取对应 PR 信息，跳过标记了 **high priority** 的 PR，并对 fork/branch 的来源做了兼容处理，提供更细致的日志与统计。  

**🎯 影响范围**  
- `.github/workflows/`：CI 取消逻辑全部迁移到新文件。  
- CI 触发方式：仍依赖 `workflow_dispatch` 手动触发，但输入参数默认仍是 `pr-test.yml`。  
- 需要的权限新增 `pull-requests: read`（用于读取 PR 标签）。  
- 依赖的 GitHub CLI、jq、Rate‑limit（最多 1000 条 run 列表）以及 `gh api` 调用。  

**💡 关注建议**  
1. **权限检查**：确保仓库的 `GITHUB_TOKEN` 包含 `pull-requests: read`，否则标签判断会失效。  
2. **高优先级标签**：确认团队约定的标签名称（当前硬编码为 `high priority`），必要时改为变量或在文档中说明。  
3. **速率限制**：新增 `gh api` 调用会增加对 GitHub API 的消耗，建议在高频触发场景下监控 Rate‑limit，或增加分页处理（`--limit 1000` 可能漏掉更多运行）。  
4. **兼容性**：如果仍有旧工作流被外部自动化引用，建议保留兼容入口或在 README 中明确迁移路径。  
5. **测试验证**：在自己仓库或测试分支手动触发几次，验证：① 能正确跳过带 “high priority” 的 PR，② 能处理 fork PR（正确获取 `head_owner:head_branch`），③ 取消失败时不会导致工作流异常退出。  

总体来看，此次重构提升了预占资源的粒度控制，降低了高优先级 PR 被误取消的风险，但也引入了更多 API 调用和权限依赖，需在实际运行前做好相应的验证和监控。

---

### [smg][ci] migrate function calling tests to new infrastructure (#16748)
**SHA**: `49305fa` | 🔗 [查看提交](https://github.com/sgl-project/sglang/commit/49305fa1c15c2b901a13b6951dbdf52a6e1d8601)

**🎯 变更类型**：功能增强（新增大量 Function‑Calling E2E 测例）  
**⚡ 重要程度**：🟡 中  
**📋 变更摘要**：本次提交在 `sgl-model-gateway/e2e_test/chat_completions/` 目录下新增 **1529 行**的 `test_function_calling.py`，覆盖 OpenAI‑compatible 函数调用、工具选择、流式返回、多选项、strict/required/auto 等模式的行为，包括 Llama‑1B（llama 解析器）和 Llama‑8B（pythonic 解析器）的完整端到端验证。  

**🎯 影响范围**  
1. **测试套件**：CI 将执行新增的 1+k 条测试，显著增加运行时长。  
2. **gateway 启动参数**：`--tool-call-parser`, `--history-backend` 等新标记在 `@pytest.mark.gateway` 中使用，需确保相应 CLI 参数已实现并在 CI 中可用。  
3. **模型/后端 fixtures**：`@pytest.mark.model`、`setup_backend`、`grpc` 参数化均被引用，涉及 `tests/conftest.py` 对模型/后端的注册逻辑。  
4. **依赖**：新增对 `openai` 客户端的直接调用，需在测试环境中安装对应版本（兼容 OpenAI SDK）。  

**💡 关注建议**  
- **CI 稳定性**：部分测试标记为可能 flaky（`FLAKY_TESTS`），建议在 CI 中加入重试或单独标记，以防偶发失败导致 CI 卡死。  
- **执行时间**：1529 行测试会显著拉长 CI，用 `pytest -m "not flaky"` 或分批运行的方式控制耗时。  
- **参数兼容性**：确认 `gateway` 启动脚本已接受 `--tool-call-parser`、`--history-backend` 等新参数；若尚未实现，需要同步更新入口脚本或相应配置。  
- **依赖锁定**：在 `requirements.txt` 或 `pyproject.toml` 中固定 `openai` 版本，以免未来升级导致接口不兼容。  
- **代码审查**：虽然大部分为测试，但请检查是否有硬编码的模型名称（`llama-1b`, `llama-8b`）与仓库实际可用模型保持一致，防止因模型缺失导致测试报错。  

总体来说，此次提交为函数调用特性提供了完整的端到端验证，提升了产品质量；但需关注 CI 稳定性、运行时长以及新 CLI 参数的实现情况。

---

### [AMD] Fix CI - unit-test-backend-1-gpu-amd-mi35x and unit-test-backend-2-gpu-amd, stage-b-test-small-1-gpu-amd (#16675)
**SHA**: `4e99940` | 🔗 [查看提交](https://github.com/sgl-project/sglang/commit/4e999404c3361a64a2147988380270cfb4fd394c)

**🎯 变更类型**：功能增强（AMD GPU CI 扩展）  
**⚡ 重要程度**：🟡 中  
**📋 变更摘要**：  
- 在 GitHub Actions 中新增 `stage-b-test-small-1-gpu-amd-mi35x` 以及对应的 AMD‑MI35X GPU runner。  
- 将原有的 `stage-b-test-small-1-gpu` 套件全部改名为 `stage-b-test-small-1-gpu-amd`，并在 `run_suite.py` 中加入新套件映射。  
- 相应地在 `scripts/ci/slash_command_handler.py` 与全部 `test/registered/*` 的 CI 注册文件中同步更新套件名称。  
- 移除原先的 `unit-test-backend-1/2-gpu-amd` 任务，改为让后续的 `unit-test-backend-8-gpu-amd` 直接依赖 `stage-a-test-1-amd`。

**🎯 影响范围**  
- **CI 工作流**：`.github/workflows/pr-test-amd.yml`（CI 阶段、runner 选择、依赖关系）。  
- **测试注册**：`test/registered/**` 中约 70 处 `register_amd_ci(..., suite="stage-b-test-small-1-gpu")` 被改为 `stage-b-test-small-1-gpu-amd`，少数改为 `...-amd-mi35x`（如 `test_gpt_oss_1gpu.py`）。  
- **命令处理**：`scripts/ci/slash_command_handler.py` 增加新 stage 关键词。  
- **运行套件映射**：`test/run_suite.py` 新增 `stage-b-test-small-1-gpu-amd-mi35x`。  
- **可能受影响的文档/脚本**：任何硬编码 `stage-b-test-small-1-gpu` 字符串的地方（如 README、benchmark 脚本）需同步更新。

**💡 关注建议**  

1. **CI 稳定性检查**  
   - 确认新 runner `linux-mi35x-gpu-1` 已在组织的 self‑hosted pool 中可用，且 `ensure_vram_clear.sh`、`amd_ci_start_container.sh` 在该硬件上能正常执行。  
   - 运行一次完整的 PR 检测，确保 `stage-b-test-small-1-gpu-amd-mi35x` 能正确触发并完成所有已注册的测试（尤其 `test_gpt_oss_1gpu.py` 的新套件）。  

2. **依赖关系与并行度**  
   - 由于 `unit-test-backend-1/2-gpu-amd` 被删除，原本依赖它们的后续作业（如 `performance-test-2-gpu-amd`）已改为依赖 `stage-a-test-1-amd`。请检查是否会导致资源竞争或覆盖率下降。  
   - 如有需要，考虑在 `stage-b-test-small-1-gpu-amd-mi35x` 中加入 `needs: [stage-a-test-1-amd]`，保持与其他 AMD 作业的一致性。  

3. **测试注册的一致性**  
   - 目前仅 `test_gpt_oss_1gpu.py` 改为 `...-amd-mi35x`，其余 70+ 测试仍使用 `-amd`。确认这符合预期（即只有该测试在 MI35X 硬件上跑），避免误把其他测试排除在 MI35X 之外。  

4. **文档与工具链同步**  
   - 在 CI 文档、贡献指南以及 `sglang/ci` 相关脚本中把旧套件名 `stage-b-test-small-1-gpu` 替换为 `stage-b-test-small-1-gpu-amd`。  
   - 检查是否还有脚本（如 `run_ci.py`、本地测试脚本）使用硬编码套件名，需要同步更新。  

5. **回滚与监控**  
   - 由于改动涉及 CI 关键路径，建议在 PR 合并后打开一个短期监控窗口，关注 AMD CI 失败率。若出现异常，可快速回滚到原 `stage-b-test-small-1-gpu`（保留分支）或在 `pr-test-amd.yml` 中加入 `continue-on-error` 临时兜底。  

6. **代码质量**  
   - 此次改动主要是字符串替换，未涉及业务逻辑。建议在后续 PR 中加入单元测试或 lint 检查，确保所有 `register_amd_ci` 调用的 `suite` 参数与 `run_suite.py` 中的映射保持一致，防止遗漏导致 CI “suite not found”。  

总体来看，此次提交为 AMD 生态链的 CI 拓展奠定了基础，只要确认新 runner 与新套件的可用性，整体风险可控。请在合并前完成上述验证步骤。

---

### [smg][ci] migrate validation tests to new infrastructure (#16746)
**SHA**: `fbc2488` | 🔗 [查看提交](https://github.com/sgl-project/sglang/commit/fbc24886ddab3a04ebd5052fbdaff432e7fb0d2f)

**🎯 变更类型**：功能增强（新增 E2E 验证测试）  
**⚡ 重要程度**：🟡 中  

**📋 变更摘要**  
- 在 `sgl-model-gateway/e2e_test/chat_completions/` 新增 `test_validation.py`，迁移并简化原有的 `ignore_eos` 与 `large_max_new_tokens` 验证逻辑。  
- 引入 **懒加载 + 缓存** 的 tokenizer（仅在需要时导入 `transformers`），并使用 `ThreadPoolExecutor` 对并发长文本生成进行压力测试。  

**🎯 影响范围**  
- **测试套件**：新增约 167 条测试代码，会显著增加 CI 时长。  
- **依赖**：`transformers` 成为可选运行时依赖，若未安装会在 `get_tokenizer` 中报错。  
- **网关/模型启动**：使用 `--history-backend memory` 以及 `extra_body={"ignore_eos": …}` 参数，依赖当前网关对这些字段的实现。  

**💡 关注建议**  
1. **依赖安全**：在 `setup.cfg/requirements` 中明确标记 `transformers` 为 `extras`，并在测试入口使用 `pytest.importorskip("transformers")` 防止无该库时 CI 直接失败。  
2. **并发稳定性**：虽然使用全局锁保证 tokenizer 单例，但在高并发 CI 环境下仍可能出现阻塞。建议在 `get_tokenizer` 里加入 `functools.lru_cache` 并确保返回的对象是线程安全的（如仅读取）。  
3. **模型路径匹配**：`AutoTokenizer.from_pretrained(model_path)` 需要模型目录中包含 tokenizer 配置，若模型仓库更新或删减，测试会报 `OSError`。可在测试前加入 `skipif` 判断模型是否具有对应 tokenizer。  
4. **资源限制**：并发请求数固定为 4，`max_tokens=256`，在资源受限的机器上可能触发 OOM。建议在 CI 配置中提供足够的 GPU/CPU 内存，或在测试中使用 `@pytest.mark.timeout` 防止卡死。  
5. **结果判定**：`ignore_eos` 测试仅检查 token 数量和 `finish_reason`，但未校验实际内容连贯性。若后端实现细节变更（如返回 `stop` 而非 `length`），可能导致误报。可考虑增加对出现 EOS 标记的显式检测。  

总体来看，此次提交通过独立的 E2E 测试提升了对 **ignore_eos** 与 **大规模并发生成** 功能的覆盖，但需注意依赖、资源和并发安全性，以免在 CI 或用户侧引入不必要的失败。

---

### [perf] Add two stream norm for `Olmo3` speedup 5% (#13681)
**SHA**: `cda3561` | 🔗 [查看提交](https://github.com/sgl-project/sglang/commit/cda35611d41c7c450aab47a6d6cdfd850c75fc80)

**🎯 变更类型**：性能优化  
**⚡ 重要程度**：🟡 中  

**📋 变更摘要**  
为 `Olmo2`（即 Olmo3）模型的 Q‑K 归一化引入了可选的 **alt_stream**，在 CUDA graph capture 模式下将 `q_norm` 与 `k_norm` 分别放在两个 CUDA 流上并行执行，理论上提升约 5% 的吞吐。新增 `is_cuda` 与 `get_is_capture_mode` 检查，默认在 CUDA 环境下创建独立的 `torch.cuda.Stream` 并在模型、层、注意力模块中向下传递。

**🎯 影响范围**  
- `python/sglang/srt/models/olmo2.py`（模型、层、注意力实现）  
- 相关导入：`sglang.srt.model_executor.cuda_graph_runner.get_is_capture_mode`、`sglang.srt.utils.is_cuda`  

**💡 关注建议**  

1. **流同步安全**：`alt_stream` 在模型实例上是共享的，若同一模型在多线程/多进程并发推理，可能出现同一流被多次使用导致竞争。建议在 `forward` 时局部创建 `torch.cuda.Stream`（或使用 `torch.cuda.Stream` 池）或明确文档说明模型实例不可并发使用。  
2. **捕获模式兼容性**：`get_is_capture_mode()` 为 True 时才开启双流路径，确保该函数在图捕获期间返回正确值，否则会引入不可捕获的异步操作。可在单元测试中加入捕获模式下的前向跑通验证。  
3. **CPU 与非‑CUDA 兼容**：`alt_stream` 仅在 `_is_cuda` 为 True 时创建，其他环境保持 `None`，但在 `Olmo2Attention._apply_qk_norm` 中仍会调用 `torch.cuda.current_stream()`。最好在代码块前加 `if self.alt_stream is not None:` 的 guard，以防在 CPU 环境误调用 CUDA API。  
4. **梯度传播与视图**：对 `q`、`k` 进行 `reshape(-1, dim)` 再 `view`，确保 `requires_grad` 与 autograd 正常。建议在 CI 中加入梯度检查（`torch.autograd.gradcheck`）以防因视图变化引入隐式复制。  
5. **资源释放**：`torch.cuda.Stream` 本身无需显式释放，但若模型在长生命周期内频繁创建/销毁实例，最好在 `__del__` 中 `self.alt_stream = None`，防止潜在的 CUDA 上下文泄漏。  

总体来看，此次改动在保持原有功能的前提下通过流并行提升了归一化阶段的算子利用率，收益可观。若能在文档中明确使用约束（单实例单推理）并补充捕获模式下的回归测试，将进一步降低风险。

---

### [smg][ci] fix model pool GPU cleanup and add startup reliability improvements (#16745)
**SHA**: `8a45a9c` | 🔗 [查看提交](https://github.com/sgl-project/sglang/commit/8a45a9c6a92203247c3202c08dd0371ec5b047b4)

**变更类型**：功能增强 / 稳定性改进  
**重要程度**：🟡 中  

**变更概览**  
1. **启动参数扩展**：在 `constants.py` 中新增 `INITIAL_GRACE_PERIOD`（首次健康检查前的等待）和 `LAUNCH_STAGGER_DELAY`（多 worker 启动间的间隔），并将健康检查间隔从 5 s 缩短至 2 s。  
2. **模型池启动逻辑**：`model_pool.py`  
   - 为每次 worker 启动计数 `launched_count`，在 `LAUNCH_STAGGER_DELAY` > 0 时进行睡眠，以降低模型加载时的资源争用。  
   - 在 `_wait_all_healthy` 前加入 `INITIAL_GRACE_PERIOD`，让模型有足够时间完成加载再进行健康检查。  
   - 当 worker 退出或报错时，改用 `self._evict_instance(key)` 统一回收 GPU 资源，同时在失败路径中加入非阻塞 `select` 读取 `stderr`，记录最近的错误日志。  
3. **代码清理**：删除了 `e2e_test/utils.py`（183 行），该文件原本提供 tokenizer、CI 检测等通用工具，改为直接从 `infra` 子模块导入，减少冗余。  

**影响范围**  
- `sgl-model-gateway/e2e_test/infra` 及其子模块（模型启动、健康检查、GPU 回收）。  
- 任何依赖 E2E 测试启动模型池的 CI/CD 流水线，将感受到更快的健康检查响应以及更可靠的 GPU 释放。  

**审查要点 & 建议**  
1. **并发启动测试**：验证在高并发（> 10 workers）时，`LAUNCH_STAGGER_DELAY` 的累加睡眠不会导致整体启动超时。可以在 CI 中加入极端并发场景的压力测试。  
2. **回退配置**：保持默认值可覆盖，防止用户在资源紧张的环境下因 `INITIAL_GRACE_PERIOD` 过长导致启动超时。建议在文档中说明如何通过环境变量或配置文件调节。  
3. **GPU 清理路径**：`_evict_instance` 已在其他位置实现，确保其在所有异常分支（如 `select` 读取异常、`stderr` 为空）仍能安全释放 CUDA/显存，否则可能残留僵尸进程。  
4. **日志噪声**：`logger.info` 与 `logger.error` 的频率提升，建议在默认日志级别下确认不会淹没关键业务日志，必要时提供 `--quiet` 开关。  
5. **utils.py 删除影响**：确认项目中没有其他模块直接 `import utils`（而非通过 `infra`），否则会出现 `ImportError`。可以在迁移分支运行一次全仓库搜索，确保引用已全部更新。  

综上，此次改动显著提升模型池的启动可靠性和 GPU 资源回收机制，风险主要集中在并发启动时的累计延迟以及对已删除 `utils.py` 的残留引用。建议在 CI 中加入并发压力和回归测试，以验证改动在各种硬件配置下的稳健性。

---

### [smg][ci] migrate reasoning_content tests to new infrastructure (#16741)
**SHA**: `aecd5f5` | 🔗 [查看提交](https://github.com/sgl-project/sglang/commit/aecd5f5f3e3264f448b5608fddd24aad49d39bb2)

**🎯 变更类型**：其他（新增 E2E 测试）

**⚡ 重要程度**：🟡 中  
**📋 变更摘要**：向 `sgl-model-gateway/e2e_test/chat_completions/` 添加了 `test_reasoning_content.py`，迁移自旧的 gRPC 测试，实现了对 DeepSeek‑7B 模型在不同 `separate_reasoning`、`stream_reasoning` 配置下的 streaming 与 non‑streaming 响应的完整验证。  

**🎯 影响范围**：  
- **gateway 启动参数**：`--reasoning-parser deepseek_r1 --history-backend memory`；新增 `extra_body` 参数的解析路径。  
- **模型返回结构**：在 `ChatCompletionChunk.delta` 与 `Message` 中加入 `reasoning_content` 字段的解析与校验。  
- **CI 流水线**：使用 `pytest.mark.model("deepseek-7b")` 与 `pytest.mark.gateway`，会在 CI 中触发对应模型/网关的启动，可能增加执行时间。  

**💡 关注建议**：

1. **兼容性检查**：确认 `reasoning_content` 字段在所有代码路径（包括非 DeepSeek 模型）都保持可选，避免在旧模型返回时出现 `AttributeError`。  
2. **异常处理**：测试里对 `chunk.choices[0].delta.reasoning_content` 直接访问，若后端在某些异常情况下返回 `None`，会导致属性错误。建议在生产代码中加入 `getattr(..., None)` 防护。  
3. **资源限制**：E2E 测试会启动 DeepSeek‑7B（约 7 B 参数），对 CI 机器的显存要求较高。若 CI 环境无法满足，可在 `pytest.mark.model` 中加入 `skipif` 条件或提供轻量化 mock。  
4. **日志可观测性**：测试只使用 `logger` 而未输出关键信息，建议在关键分支（如 `stream_reasoning=False`）加入调试日志，以便定位流式 vs 非流式的时序差异。  
5. **参数默认值一致性**：`extra_body` 中的 `separate_reasoning`、`stream_reasoning` 与网关启动参数的默认值保持同步，防止文档与实现不符导致用户困惑。  

总体而言，此次提交为功能验证层面的重要补充，未直接改动业务代码，风险主要在 CI 环境资源与 `reasoning_content` 可选性上。若上述建议落实，可确保该测试在不同部署环境下稳定运行。

---

#### 🟢 低重要度变更 (15)

### add doc for #14386 (#14655)
**SHA**: `068abe7` | 🔗 [查看提交](https://github.com/sgl-project/sglang/commit/068abe7e4039bff6e2ef20976fa6b9a97a266fb1)

**🎯 变更类型**：文档更新/代码重构  
**⚡ 重要程度**：🟢低  
**📋 摘要**：在环境变量文档中新增 `SGLANG_MM_BUFFER_SIZE_MB` 说明，并在 `schedule_batch.py` 中加入对该变量的读取与多模态特征哈希 GPU 加速的实现，默认关闭。

---

### fix spec qwen3 pd error (#16708)
**SHA**: `2babf88` | 🔗 [查看提交](https://github.com/sgl-project/sglang/commit/2babf88f245ddd93bc8d6ad14670a82c8ab5177b)

**变更类型**：代码重构  
**重要程度**：🟢低  
**摘要**：在 `memory_pool.py` 的 `get_contiguous_buf_infos` 中新增文档说明，并排除用于 speculative 解码的中间缓存 (`intermediate_ssm`, `intermediate_conv_window`) 以避免错误的 RDMA 注册。

---

### [Docs] Improve docs for install on gb200 (#16760)
**SHA**: `d56d14e` | 🔗 [查看提交](https://github.com/sgl-project/sglang/commit/d56d14e566adffab9248d9c857e32e2bd2934d45)

**🎯 变更类型**：文档更新  
**⚡ 重要程度**：🟢低  
**📋 摘要**：在安装文档中去掉 `--prerelease=allow` 参数，并新增针对不同 CUDA 版本（如 GB200）使用 `--extra-index-url` 指定 PyTorch wheel 的说明。

---

### chore: bump mooncake version to 0.3.8.post1 (#16792)
**SHA**: `0c4e155` | 🔗 [查看提交](https://github.com/sgl-project/sglang/commit/0c4e155a3c88f3a530c6ab31f205203d024ca453)

**🎯 变更类型**：配置调整  
**⚡ 重要程度**：🟢 低  
**📋 摘要**：将 mooncake‑transfer‑engine 版本从 0.3.8 升级至 0.3.8.post1，更新 Dockerfile、CI 安装脚本以及对应的警告提示文字。

---

### [AMD] Clean up vllm dependencies in moe_runner/triton.py (#11349)
**SHA**: `d6d5c3f` | 🔗 [查看提交](https://github.com/sgl-project/sglang/commit/d6d5c3fdea700706b16b9797e187e48b83c5a105)

**🎯 变更类型**：代码重构  
**⚡ 重要程度**：🟢低  
**📋 摘要**：将 MOE 相关环境变量名统一为 `SGLANG_USE_AITER`，并在 `triton.py` 中加入对 AMD HIP 的支持，调整导入路径和条件分支以兼容 CUDA 与 HIP。

---

### [Diffusion] Tiny rename parallel_groups (#16743)
**SHA**: `9d4d57d` | 🔗 [查看提交](https://github.com/sgl-project/sglang/commit/9d4d57dbfa485d4f51ea4a4027df3c9b28fd6fba)

**🎯 变更类型**：代码重构  
**⚡ 重要程度**：🟢低  
**📋 摘要**：将 `yunchang` 模块改名为 `parallel_groups`，相应更新 `parallel_state.py` 中的导入路径。文件结构保持不变，功能不受影响。

---

### [AMD] Change AITER package name  (#16721)
**SHA**: `ccd0fb3` | 🔗 [查看提交](https://github.com/sgl-project/sglang/commit/ccd0fb32911765dd05a5373c86e01a4736e700ac)

**🎯 变更类型**：配置调整  
**⚡ 重要程度**：🟢低  
**📋 摘要**：在 `scripts/ci/amd_ci_install_dependency.sh` 中，将容器内检查 AITER 包版本的命令由 `pip show aiter` 改为 `pip show amd-aiter`，同步已更名的包名。

---

### Tiny remove auto-triggering for list-active-pr-runs. (#16778)
**SHA**: `87ee6b5` | 🔗 [查看提交](https://github.com/sgl-project/sglang/commit/87ee6b5eaab0161d8c2db4d93ca573ae64290db5)

**🎯 变更类型**：配置调整  
**⚡ 重要程度**：🟢低  
**📋 摘要**：删除 list‑active‑pr‑runs 工作流的 pull_request 自动触发，仅保留手动触发；简化输入描述并改用 gh api 分页获取作业，去除不再使用的临时文件。

---

### add AWS SGLang DLC to docs (#16686)
**SHA**: `cceb5e6` | 🔗 [查看提交](https://github.com/sgl-project/sglang/commit/cceb5e6aa5cc541ef07bfda2853ec73703baea32)

**🎯 变更类型**：文档更新  
**⚡ 重要程度**：🟢低  
**📋 摘要**：在 `install.md` 中新增关于 AWS 提供的 SGLang 容器（DLC）的说明及链接，便于用户了解并获取 AWS SGLang 镜像。

---

### [diffusion] docs: add LoRA support (#16378)
**SHA**: `c1c13c8` | 🔗 [查看提交](https://github.com/sgl-project/sglang/commit/c1c13c841ae9b88e22bf76d775a3d06a900ef2aa)

**🎯 变更类型**：文档更新  
**⚡ 重要程度**：🟢低  
**📋 摘要**：在 `support_matrix.md` 中新增 LoRA 支持章节，列出各基模型已验证可用的 LoRA 示例。

---

### Tiny fix wording about CI preemption. (#16773)
**SHA**: `77d3566` | 🔗 [查看提交](https://github.com/sgl-project/sglang/commit/77d35665554be5f4de2346f51bb9c264428f7d4c)

**🎯 变更类型**：文档更新  
**⚡ 重要程度**：🟢低  
**📋 摘要**：在 PR 模板和贡献指南中澄清 CI 触发方式及说明 CI 受调度限制可能被高优先级 PR 抢占；同时将工作流名称由 “Cancel Unfinished PR Tests” 改为 “Cancel Unfinished PR Runs”。

---

### [model-gateway] release 0.3.1 (#16254)
**SHA**: `7460240` | 🔗 [查看提交](https://github.com/sgl-project/sglang/commit/7460240737f6e60a0f81209402d0aae568fe1ddf)

**🎯 变更类型**：配置调整  
**⚡ 重要程度**：🟢低  
**📋 摘要**：将 sgl-model-gateway 及其 Go、Python 绑定的版本号从 0.3.0 升级至 0.3.1，并同步更新 Python 包的 `pyproject.toml` 与 `version.py`。

---

### [smg] Add Nemotron Nano V3 reasoning parser support (#16763)
**SHA**: `8726d30` | 🔗 [查看提交](https://github.com/sgl-project/sglang/commit/8726d30cb2273bc4eaffd95317291e0f81e35b3b)

**🎯 变更类型**：其他  
**⚡ 重要程度**：🟢低  
**📋 摘要**：在 `factory.rs` 中为 Nemotron Nano V3 添加了解析器映射，复用 Qwen3 解析规则，支持显式 `<think>` 标记。

---

### Skip causal_conv1d test with padded batches due to Triton kernel bug (#16715)
**SHA**: `a979927` | 🔗 [查看提交](https://github.com/sgl-project/sglang/commit/a979927727c43337361df888f7fa6158a59f0b4f)

**🎯 变更类型**：测试修改  
**⚡ 重要程度**：🟢低  
**📋 摘要**：在 `test_causal_conv1d` 的两个用例中新增 `pytest.skip`，因 Triton kernel（#16714）导致的错误，暂时跳过带填充批次的测试。

---

### [smg] Work around sglang's notorious orphan process problem (#16756)
**SHA**: `ee71e77` | 🔗 [查看提交](https://github.com/sgl-project/sglang/commit/ee71e773e121a2314b85a0d463994f3fa5577cb2)

**🎯 变更类型**：代码重构  
**⚡ 重要程度**：🟢 低  
**📋 摘要**：将模型启动间隔从 5 s 调整为 10 s，降低 I/O 竞争；改进 `terminate` 方法，使用进程组信号（SIGTERM/SIGKILL）一次性终止主进程及其子进程，防止孤儿进程残留。

---

