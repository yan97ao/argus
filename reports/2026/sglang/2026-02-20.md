# 每日更新报告（2026-02-20）

## sgl-project/sglang

| 提交时间 | 作者 | 提交信息 |
|----------|------|----------|
| 2026-02-20 23:23:38 | Cheng Wan | Fix adjust_num_token_non_padded_for_attn_tp returning CPU tensor (#19051) |
| 2026-02-20 23:21:38 | Nicolas Castet | [Fix] Run FlashInfer autotune on non-default stream for NCCL 2.29+ compatibility (#18987) |
| 2026-02-20 23:20:29 | DarkSharpness | [Fix] DO NOT skip save_kv_cache for dllm (#19020) |
| 2026-02-20 22:00:09 | Mohammad Miadh Angkad | Fix NSA FP8 KV cache path for both-trtllm MHA one-shot (#18931) |
| 2026-02-20 21:16:08 | Mick | [diffusion] feat: support nunchaku for Z-Image-Turbo and flux.1 (int4) (#18959) |
| 2026-02-20 21:01:05 | Yuan Luo | [jit kernel] Support per_token_group_quant_8bit jit kernel (#18905) |
| 2026-02-20 19:57:06 | Mick | [diffusion] logging: log available mem when each stage starts in debug level (#18998) |
| 2026-02-20 15:45:24 | fzyzcjy | Fix lint on main (#19054) |
| 2026-02-20 15:37:40 | Douglas Yang | feature: docker patch workflow (#19025) |
| 2026-02-20 15:30:57 | Cheng Wan | fix lint on main (#19052) |
| 2026-02-20 15:04:15 | Duyi-Wang | [AMD] Replace msgpack with msgspec in MORI-IO (#19007) |
| 2026-02-20 14:31:26 | YAMY | [Fix][Qwen3.5] Pass max_mamba_cache_size to mamba pool in disaggregation decode path (#19002) |
| 2026-02-20 13:58:15 | chengshuang18 | Feature/sdar support (#19044) |
| 2026-02-20 12:30:24 | fzyzcjy | Support using SGLang port in dumper (#19038) |
| 2026-02-20 12:29:09 | fzyzcjy | Support resetting and enhance HTTP endpoints for dumper (#19046) |
| 2026-02-20 12:28:10 | fzyzcjy | Enhance configure and env parsing in dumper (#19034) |
| 2026-02-20 12:27:12 | fzyzcjy | Support filtering labels in dumper (#19018) |
| 2026-02-20 12:26:24 | fzyzcjy | Support captured dump output and console output control in dumper (#19017) |
| 2026-02-20 12:25:54 | fzyzcjy | Hint users when wrongly execute it with partial ranks in dumper (#19014) |
| 2026-02-20 12:25:21 | fzyzcjy | Support cleanup previous dumps in dumper (#19013) |
| 2026-02-20 12:02:21 | Cheng Wan | Fix flashinfer autotune to only wrap run_once() (#19004) |
| 2026-02-20 11:15:05 | Cheng Wan | Fix long prompt KV allocation by falling back to torch native APIs when exceeding Triton tensor limit (#18250) |
| 2026-02-20 09:32:32 | Nicolas Castet | Register tensors with symmetric memory for qwen (#18643) |
| 2026-02-20 08:03:56 | Cheng Wan | Revert "Add SDAR model support" (#19032) |
| 2026-02-20 05:26:30 | Liangsheng Yin | Tiny remove duplicate coredump env injection (#19023) |
| 2026-02-20 03:38:25 | Liangsheng Yin | [spec v2]Fix torch gc of future indices (#18958) |
| 2026-02-20 03:20:32 | chengshuang18 | Add SDAR model support (#18318) |

### 📊 统计摘要
> 本日共 27 个提交 | 🔴高 2 | 🟡中 10 | 🟢低 15
## 📋 目录

- [sgl-project/sglang](#sgl-project-sglang)
  - [📊 统计摘要](#-统计摘要)
  - [🔴 高重要度变更 (2)](#-🔴-高重要度变更-2)
    - [[diffusion] feat: support nunchaku for Z-Image-Turbo and ...](#8d789b5)
    - [[jit kernel] Support per_token_group_quant_8bit jit kerne...](#7d95344)
  - [🟡 中重要度变更 (10)](#-🟡-中重要度变更-10)
    - [[diffusion] logging: log available mem when each stage st...](#38a6965)
    - [Feature/sdar support (#19044)](#295bc17)
    - [Support using SGLang port in dumper (#19038)](#046ef0a)
    - [Support resetting and enhance HTTP endpoints for dumper (...](#2fecc2c)
    - [Enhance configure and env parsing in dumper (#19034)](#503bf30)
    - [Support filtering labels in dumper (#19018)](#df995aa)
    - [Support captured dump output and console output control i...](#261bca3)
    - [Hint users when wrongly execute it with partial ranks in ...](#fc1500a)
    - [Revert "Add SDAR model support" (#19032)](#73a7f0d)
    - [Add SDAR model support (#18318)](#44ab752)
  - [🟢 低重要度变更 (15)](#-🟢-低重要度变更-15)
    - [Fix adjust_num_token_non_padded_for_attn_tp returning CPU...](#38ee749)
    - [[Fix] Run FlashInfer autotune on non-default stream for N...](#3358ba8)
    - [[Fix] DO NOT skip save_kv_cache for dllm (#19020)](#5285240)
    - [Fix NSA FP8 KV cache path for both-trtllm MHA one-shot (#...](#f23a23c)
    - [Fix lint on main (#19054)](#0d20cf5)
    - [feature: docker patch workflow (#19025)](#77fdb6a)
    - [fix lint on main (#19052)](#b59a22f)
    - [[AMD] Replace msgpack with msgspec in MORI-IO (#19007)](#b0786cd)
    - [[Fix][Qwen3.5] Pass max_mamba_cache_size to mamba pool in...](#8541b11)
    - [Support cleanup previous dumps in dumper (#19013)](#b41d412)
    - [Fix flashinfer autotune to only wrap run_once() (#19004)](#13a4a04)
    - [Fix long prompt KV allocation by falling back to torch na...](#64bca53)
    - [Register tensors with symmetric memory for qwen (#18643)](#99df920)
    - [Tiny remove duplicate coredump env injection (#19023)](#db34c1c)
    - [[spec v2]Fix torch gc of future indices (#18958)](#5ff5aa6)
#### 🔴 高重要度变更 (2)

### [diffusion] feat: support nunchaku for Z-Image-Turbo and flux.1 (int4) (#18959)
**SHA**: `8d789b5` | 🔗 [查看提交](https://github.com/sgl-project/sglang/commit/8d789b5c3d7ed3f585dd27c6052b2e12fb5b96d0)

**🎯 变更类型**：功能增强 / 架构变更 / 性能优化  
**⚡ 重要程度**：🔴高  

**📋 变更摘要**  
- 为 Flux、Z‑Image‑Turbo、Qwen‑Image 等 DiT 系列模型新增对 **Nunchaku** 量化（int4/ nvfp4） 的完整支持，实现 **nunchaku checkpoint** 的权重映射、量化规则获取以及融合算子调用。  
- 引入 `MergedColumnParallelLinear`、`QuantizationConfig` 扩展，提供 **统一的量化配置**；在注意力、FeedForward、LayerNorm 等关键子层中根据配置自动切换为 fused‑qkv、fused‑mlp 路径。  
- 完善模型加载、参数映射、FSDP 分片等底层实现，确保在有/无 nunchaku 环境下均能正常工作。  

**🎯 影响范围**  
- `sglang/multimodal_gen/configs/models/dits/flux.py` – 权重名称映射扩展。  
- `sglang/multimodal_gen/runtime/layers/quantization/configs/nunchaku_config.py` – 量化规则统一抽取、配置结构化。  
- `sglang/multimodal_gen/runtime/loader/component_loaders/transformer_loader.py` – 将模型类注入到 `NunchakuConfig`。  
- `sglang/multimodal_gen/runtime/loader/fsdp_load.py`、`utils.py` – 参数映射与分片逻辑调整。  
- `sglang/multimodal_gen/runtime/models/dits/base.py`、`flux.py`、`qwen_image.py`、`zimage.py` – 核心 DiT 模型实现改造，新增融合路径、量化规则接口。  
- 相关公共层（`linear.py`、`mlp.py`、`attention.py`）以及 Fused‑GELU MLP 实现。  

---

### 🔍 技术洞察  

| 维度 | 影响描述 |
|------|----------|
| **架构影响** | • 引入 `NunchakuConfig` 作为统一的量化配置对象，所有支持 nunchaku 的子层（Linear、Attention、FeedForward）通过 `quant_config` 参数感知是否走量化路径。<br>• 新增 `MergedColumnParallelLinear`，在同一层内部一次性完成 Q‑K‑V（或 Q‑K‑V‑Add）三个 Linear 的权重读取与 fused 计算，显著简化模型结构。<br>• 每个模型类 (`FluxTransformer2DModel`, `ZImageTransformer2DModel`, `QwenImageTransformer2DModel`) 实现 `get_nunchaku_quant_rules`，统一提供 **skip / svdq / awq** pattern，解耦了模型层级与量化策略。<br>• 参数名称映射扩展，支持 **HF、Diffusers、raw nunchaku** 三种命名体系，实现了跨 checkpoint 的兼容性。 |
| **性能影响** | • **内存**：int4、nvfp4 权重量化将模型显存需求降低约 **3‑4 倍**（从 FP16/FP32 下降至 4‑bit ）。<br>• **吞吐**：通过 `nunchaku.ops.gemm.svdq_gemm_w4a4_cuda` 与 `svdq_quantize_w4a4_act_fuse_lora_cuda` 实现的 ** fused qkv、 fused gelu‑mlp**，在显卡上可一次性完成矩阵乘、激活、scale/shift、LoRA 合并等，理论上比逐步算子提升 **1.5‑2.2×** 的推理速度。<br>• **回退路径**：若 nunchaku 库不可用或未检测到兼容的 GPU，代码会自动走常规 FP16/FP32 路径，性能回退至原有实现。 |
| **安全考虑** | • 动态 `import nunchaku.*` 加上 `try/except` 防护，确保缺失库时不会抛异常导致服务崩溃。<br>• 仅在 **模型加载阶段** 检查 `is_nunchaku_available()`，未对外暴露任何文件系统或网络操作；风险主要来源于 **外部 C++/CUDA 插件**（内核）的安全性，需依赖官方或可信渠道的二进制发行版。 |
| **可维护性** | • 量化规则由模型类统一提供，新增模型只需实现 `get_nunchaku_quant_rules`，保持了 **开闭原则**。<br>• 参数映射函数 `get_param_names_mapping` 现在支持 **链式转换** 与 **多步迭代**，兼容更多 checkpoint 变体，但代码可读性略有下降，建议添加单元测试覆盖所有正则。 |
| **兼容性** | • 对已有 **非量化** checkpoint 完全兼容，`quant_config` 为 `None` 时仍使用原始 `ColumnParallelLinear` / `FeedForward` 实现。<br>• 新增 `quant_config.model_cls` 注入，保证在加载阶段能够获取模型的量化规则，避免在运行时遗漏。 |

---

### ⚠️ 潜在风险  

1. **外部依赖缺失**  
   - nunchaku 库必须在运行环境中编译并可被 `torch` 加载；若版本不匹配或缺少 CUDA 编译支持，模型会回退但可能 **未触发警告**，导致用户误以为已使用 int4 加速。  
2. **权重映射错误**  
   - 复杂的正则映射链式转换若出现误匹配，会导致参数 **shape 不匹配** 或 **数值漂移**，在大模型上可能只在少数层出现，难以定位。  
3. **数值差异**  
   - 融合 GEMM + GELU 的实现对 **激活范围、零点偏移** 做了特定假设（如 0.171875 shift），若模型在训练时未使用对应的尺度，推理结果可能出现显著偏差。  
4. **FSDP/Offload 交互**  
   - `fsdp_load` 中对 `sharded_sd` 变量的重复声明以及 `custom_param_sd` → `sharded_sd` 的流转方式有改动，若 `param_names_mapping` 包含跨分片的重命名，可能导致 **分片不一致**，在多机器训练/推理环境中出现 checkpoint 失效。  
5. **混合精度/LoRA**  
   - 在 fused 路径里 LoRA 参数被直接注入到 GEMM 中，若用户自行对 LoRA 进行 **微调**（梯度更新），需要确保更新后的 LoRA 权重仍符合 nunchaku 的 **int4 结构**，否则会产生类型错误。  
6. **调试难度提升**  
   - 融合算子把多个算子压缩为单个 CUDA 调用，若出现 **NaN/Inf**，很难在 Python 层定位具体哪一步出错。  

---

### 💡 关注建议  

| 建议 | 说明 |
|------|------|
| **单元/集成测试** | 为每个模型（Flux、Z‑Image‑Turbo、Qwen‑Image）分别准备 **HF、Diffusers、raw nunchaku** 三种 checkpoint，验证：<br>1.

---

### [jit kernel] Support per_token_group_quant_8bit jit kernel (#18905)
**SHA**: `7d95344` | 🔗 [查看提交](https://github.com/sgl-project/sglang/commit/7d953440ec965032b6b5af386d56c427ae4e6da1)

**🎯 变更类型**：功能增强 / 性能优化 / 重构  
**⚡ 重要程度**：🔴高  

**📋 变更摘要**  
本次提交为 SGLang 引入了 **per‑token‑group‑quant‑8bit** JIT 量化算子，包含 CUDA C++ 实现、Python 封装、基准测试脚本以及单元测试。通过 `sglang.jit_kernel.per_token_group_quant_8bit` 可在 JIT 编译路径下直接调用该 kernel，`sglang.srt.layers.quantization.fp8_kernel` 中提供开关支持在 FP8‑Quant 化流程中使用该实现，从而在多数场景下提升量化吞吐并降低内存占用。  

**🎯 影响范围**  
- **core / cuda**：`python/sglang/jit_kernel/csrc/gemm/per_token_group_quant_8bit.cuh`（新 CUDA kernel）  
- **Python JIT 接口**：`python/sglang/jit_kernel/per_token_group_quant_8bit.py`（加载并包装 C++ kernel）  
- **工具链**：`utils.py` 中新增 `torch.float8_e4m3fn` 与 `torch.int8` 的 C++ dtype 映射  
- **量化层**：`python/sglang/srt/layers/quantization/fp8_kernel.py` 增加对 JIT 实现的条件调用  
- **基准**：`python/sglang/jit_kernel/benchmark/bench_per_token_group_quant_8bit.py`（性能对比）  
- **测试**：`python/sglang/jit_kernel/tests/test_per_token_group_quant_8bit.py`（覆盖多维度配置）  

---

### 🔍 技术洞察

| 维度 | 影响 |
|------|------|
| **架构影响** | - 将原本只在 Triton（或手写 CUDA）层实现的 per‑token‑group‑quant 拆分为 **JIT 编译路径** 与 **原实现路径**，保持向后兼容。<br>- 通过 `cache_once` 与 `load_jit` 在首次调用时编译生成 PTX，后续调用成本几乎为 0，符合 SGLang “即插即用” 的模块化设计。<br>- 新增 `CPP_DTYPE_MAP` 使得 `torch.float8_e4m3fn` 与 `int8` 能在模板实例化时映射到对应的 C++ 类型，拓展了 JIT kernel 支持的数值范围。 |
| **性能影响** | - CUDA kernel 采用 **16 线程 / 组** 的向量化加载 (`AlignedVector<T, kVecSize>`)，并使用 **warp‑level reduction** (`GroupReduceMax`) 计算组内最大绝对值，显著降低全局同步开销。<br>- `compute_groups_per_block` 动态决定每个 block 处理的 group 数，确保在不同 `num_groups` 场景下能较好地占满 SM。<br>- 基准脚本对比了 Triton 实现（包括 `fuse_silu_and_mul` 前置）与 JIT 实现，预期在 **大规模 token × hidden_dim**（如 8192×16384）上可提升 10%‑30% 的吞吐。<br>- 对 `scale_ue8m0`（UE8M0）路径的支持仅在 Blackwell（CUDA Compute Capability ≥ 9.0）上启用，避免在旧硬件上产生不必要的分支开销。 |
| **安全考虑** | - 代码没有新增网络或文件 I/O，只涉及 GPU 内存操作。主要安全风险在于 **GPU 越界访问** 或 **未对齐的指针**：<br>  - kernel 中对 `group_size`、`num_groups_per_row` 与 `scale_stride` 的计算已在 host 端做了断言。<br>  - `scale_output` 的指针在列主序（column‑major）路径下进行多维索引，仍需在不同 `kScaleUE8M0` 情形下确保不越界。<br>- `torch.float8_*` 在不同 PyTorch 版本的实现细节有所差异，需在升级时验证 JIT 编译能成功链接对应的 CUDA 类型别名。 |
| **可维护性** | - 代码分层明确：CUDA kernel、Python wrapper、工具函数、统一的配置/benchmark。<br>- 使用 `cache_once` 与模板化的 `make_cpp_args` 减少重复代码，便于以后扩展到其它 dtype（如 `bfloat16` → `fp8`）。<br>- 单元测试覆盖了 **GEMM‑like** 与 **MoE‑like** 两大使用场景以及多种 flag 组合，基本保证回归安全。 |

---

### ⚠️ 潜在风险

1. **硬件兼容性**  
   - `scale_ue8m0` 只在 Compute Capability ≥ 9.0（Blackwell）上有效，若在旧卡上误开该标志会触发 `torch.cuda.assert`（在 `sglang_per_token_group_quant_fp8` 中已有 `skip`），但 JIT 路径仍可能被误调用。建议在 `per_token_group_quant_8bit` wrapper 中加入运行时检查并抛出友好错误。  
2. **dtype 映射一致性**  
   - `CPP_DTYPE_MAP` 新增了 `torch.float8_e4m3fn` 与 `torch.int8`，若未来 PyTorch 改名或移除这些类型，编译会失败。可考虑使用 `hasattr(torch, "float8_e4m3fn")` 做兼容层。  
3. **列主序（column_major_scales）索引**  
   - 当 `output_s` 为列主序且 `scale_ue8m0=True` 时，`scale_output` 的计算涉及 `scale_stride` 与 `kElemsPerPack`，一旦 `scale_stride` 与 `group_size` 不匹配，可能出现未对齐写。建议在 host 端添加断言校验 `scale_stride % kElemsPerPack == 0`。  
4. **基准环境差异**  
   - `bench_per_token_group_quant_8bit.py` 中通过 `IS_CI` 控制测试规模，CI 机器若更换 GPU（如从 A100 → H100）会导致基准结果不可直接对比。建议在 CI 中固定 `NUM_TESTS` 与 `NUM_TOKENS_RANGE`，或在报告中显式注明硬件信息。  
5. **异常恢复**  
   - JIT 编译失败（如 CUDA 编译器错误）会抛出 `RuntimeError`，当前未捕获，可能导致整个服务启动失败。可以在 `load_jit` 包装层加入 fallback（回退到原 Triton 实现）以提升鲁棒性。  

---

### 💡 关注建议

| 对象 | 建议 |
|------|------|
| **开发者** | 1. 在 `per_token_group_quant_8bit` 入口加入 **GPU 兼容性检查**（Compute Capability、torch.float8 支持）。<br>2. 为 `scale_output` 计算添加 **断言**，防止列主序下的 stride 错误导致非法写。<br>3. 将 `CPP_DTYPE_MAP` 的更新放入专门的兼容层，避免未来 PyTorch 版本升级导致编译错误。 |
| **CI / 自动化** | 1. 在 CI 脚本中显式声明使用的 GPU 型号，并将基准结果归档为 artifact，便于回归分析。<br>2. 为新添加的单元测试配置 **timeout**，防止大规模配置导致 CI 卡死。 |
| **用户** | 1. 在配置文件或 runtime 参数中明确 `enable_sgl_per_token_group_quant_8bit` 与 `scale_ue8m0` 的开关，若使用旧硬件请关闭 `scale_ue8m0`。<br>2. 如遇 `torch.float8` 相关报错，请检查 PyTorch 版本是否 ≥ 2.2（该特性在 2.2 起正式支持）。 |
| **文档** | 补充 **JIT kernel 使用指南**，包括支持的 dtype、GPU 架构限制、调参建议（`group_size`、`column_major_scales`）以及与 Triton 实现的性能对比图。 |

--- 

综上，此次提交为 SGLang 增添了高效的 8‑bit per

---

#### 🟡 中重要度变更 (10)

### [diffusion] logging: log available mem when each stage starts in debug level (#18998)
**SHA**: `38a6965` | 🔗 [查看提交](https://github.com/sgl-project/sglang/commit/38a69652e62b5b9682916bacd676afeea9f60614)

**🎯 变更类型**：功能增强 & 重构  
**⚡ 重要程度**：🟡 中  
**📋 变更摘要**：将原先的 `timings` 字段统一改为 `metrics`，并在每个阶段启动、结束时记录可用显存（MemorySnapshot）。同时完善日志信息，新增 OOM 捕获工具，调整性能日志的序列化/反序列化逻辑，并在加载模块时直接对比可用显存。  

**🎯 影响范围**  
- `cli/generate.py`、`diffusion_generator.py`、`openai/utils.py`：对外接口改为 `metrics`。  
- `runtime/utils/perf_logger.py`、`runtime/managers/gpu_worker.py`、`runtime/managers/scheduler.py`：StageProfiler、PerformanceLogger 均改用 `metrics` 并加入显存快照。  
- `runtime/pipelines_core/*`（schedule_batch、stages、executors）以及 `runtime/entrypoints/utils.py`：所有涉及 `timings` 的属性、参数均改为 `metrics`。  
- `loader/component_loader.py`：日志从模型大小改为显存消耗。  
- 新增 `current_platform.get_available_gpu_memory()` 的调试输出。  

**💡 关注建议**  
1. **兼容性**：确认旧版 JSON/日志文件仍能被旧工具读取，或者提供迁移脚本。  
2. **序列化**：`MemorySnapshot` 从 dict 恢复的逻辑已加入 `maybe_dump_performance`，务必在单元测试中覆盖多步骤的 snapshot 序列化/反序列化。  
3. **性能**：显存查询会在每个 stage 开始时产生轻微开销，建议通过环境变量 `SGLANG_DIFFUSION_STAGE_LOGGING` 控制。  
4. **异常处理**：新增 `_oom_exceptions` 捕获不同 PyTorch 版本的 OOM 异常，确认在非 CUDA 环境下不会误报。  
5. **文档 & 测试**：更新所有公开 API 文档中的 `timings` → `metrics`，并补充对应的类型提示 (`GenerationResult | list[GenerationResult] | None`)。  
6. **日志可读性**：已在 `StageProfiler.__enter__` 中加入剩余显存打印，建议统一使用 `CYAN/RESET` 颜色，避免混淆。  

总体而言，改动统一了性能指标的命名并加入了显存可视化，提升调试体验；但改动范围较大，需要重点验证序列化兼容性和旧脚本的兼容性。

---

### Feature/sdar support (#19044)
**SHA**: `295bc17` | 🔗 [查看提交](https://github.com/sgl-project/sglang/commit/295bc175760a1d690ca3f8e7c963dd5221df3815)

**🎯 变更类型**：功能增强（新增 SDAR 与 SDAR‑MoE 扩散语言模型支持）  
**⚡ 重要程度**：🟡 中  
**📋 变更摘要**：在 SGLang 中加入对 JetLM SDAR 系列（稠密与 MoE）模型的完整实现。新增 `sdar.py`、`sdar_moe.py` 两大模型文件，扩展模型配置映射 (`dllm/config.py`) 与文档，提供了嵌入、注意力、MLP、稀疏 MoE、权重加载、日志处理等全链路实现，并对 pipeline‑parallel 进行限制（MoE 仅支持 pp_size=1）。  

**🎯 影响范围**  
- `python/sglang/srt/models/*`：全新模型类 `SDARModel/SDARForCausalLM`、`SDARMoeModel/SDARMoeForCausalLM`。  
- `python/sglang/srt/dllm/config.py`：模型架构‑参数映射改为字典查表。  
- 文档 `docs/supported_models/...`：新增 SDAR 条目。  
- 权重加载逻辑：新增对 `SDAR*`、`SDARMoe*` 的 stacked 参数映射、expert 权重处理以及 rotary 缓存的兼容。  

**💡 关注建议**  
1. **权重兼容性**：确保 PyTorch checkpoint 中的 `architectures` 名称正好匹配 `DLLM_PARAMS` 中的键，避免运行时 `Unknown diffusion LLM`。  
2. **并行限制**：MoE 仍要求 `pp_size=1`，在多节点部署时需显式配置 pipeline parallel 为 1，否则会抛异常。  
3. **性能验证**：新增的 `alt_stream`、`_is_cuda` 分支应在 GPU 与 CPU 环境下分别跑一次基准，以确认没有遗漏的同步或类型转换（尤其是 `rl_on_policy_target` 相关的 bf16 路径）。  
4. **稀疏 MoE 路径**：`forward_deepep` 依赖 `forward_batch`，确保在所有调用链（包括推理服务 `srt/server.py`）传递该对象，否则会触发断言。  
5. **测试覆盖**：补充单元测试：  
   - `from_server_args` 能正确映射 `block_size`/`mask_id`。  
   - `SDARForCausalLM` 与 `SDARMoeForCausalLM` 的 `load_weights` 能覆盖普通、sharded、expert 权重三种情况。  
   - `pipeline_parallel` 限制的报错信息。  
6. **文档同步**：在模型列表里加入 `mask_id` 与 `block_size` 解释，以帮助用户在 `srt serve` 时正确设置 `--max-running-requests` 等参数。  

总体上，此次提交为 SGLang 引入重要的扩散语言模型家族，实现完整且可扩展，但需关注并行限制、权重映射的细节以及增加相应的测试与文档说明，以防在实际部署中出现不可预期的加载或性能问题。

---

### Support using SGLang port in dumper (#19038)
**SHA**: `046ef0a` | 🔗 [查看提交](https://github.com/sgl-project/sglang/commit/046ef0aa355fce3722502ea46e6aa5e5ee67458d)

**🎯 变更类型**：功能增强  
**⚡ 重要程度**：🟡 中  
**📋 变更摘要**：为 `sglang.srt.debug_utils.dumper` 增加对 **SGLang 端口** 的统一控制。新增 `server_port` 配置、解析逻辑以及 ZMQ RPC 广播，使 **standalone** 与 **sglang server** 两种模式均可通过统一 HTTP 接口（/dumper/*）进行 `configure / reset / get_state` 等操作。相应的请求/响应结构、调度器与 tokenizer‑communicator 也做了适配，并添加完整的端到端测试。

**🎯 影响范围**  
- `python/sglang/srt/debug_utils/dumper.py`（核心实现、配置结构、HTTP 与 ZMQ 集成）  
- `python/sglang/srt/entrypoints/http_server.py`（新增 `/dumper/{method}` 路由）  
- `python/sglang/srt/managers/*`（scheduler、tokenizer_communicator_mixin）  
- `python/sglang/srt/managers/io_struct.py`（新增 `DumperControlReq*` 数据类）  
- 单元测试 `test/registered/debug_utils/test_dumper.py`（覆盖 standalone 与 sglang 两种部署模式）  

**💡 关注建议**  
1. **配置校验**：`_DumperConfig.server_port` 允许 `"reuse"`、正整数或 `-1`，但目前仅在 `_ensure_http_server` 中进行简单判断。建议在 `_parse_env_field` 或专门校验函数中加入类型/范围检查，防止用户误传 `"0"`、负数或非整数字符串导致隐式失败。  
2. **后向兼容**：默认仍使用旧环境变量 `SGLANG_DUMPER_SERVER_PORT`，但新实现通过 `server_port` 字段覆盖。文档和示例中需要明确两者的优先级与使用场景，避免部署时出现“端口被两次绑定”的错误。  
3. **RPC 广播统一**：`_rpc_broadcast` 现在在非 0 rank 上默认使用 `_LocalOnlyBroadcast`，而 0 rank 通过 ZMQ 获得真实广播对象。请确保所有调用（如 `dumper._handle_http_control_request_inner`) 均走同一代码路径，避免在多机环境下因 `_rpc_broadcast` 未初始化导致 `AttributeError`。可以在 `__init__` 中加入断言或延迟初始化保护。  
4. **错误返回**：HTTP 处理现在统一返回 JSON 列表，错误时仍返回 400。建议在 `dumper._handle_http_control_request_inner` 中捕获字段校验异常，返回结构化错误信息（如 `{ "error": "unknown field xxx" }`），便于前端调试。  
5. **测试可靠性**：`TestDumperHttp` 启动独立进程并通过 `multiprocessing.Event` 控制停止，需确认 CI 环境中端口回收及时。可以在 `tearDown` 阶段显式 `proc.terminate()` 并 `proc.wait()`，避免端口占用导致后续测试 flaky。  
6. **文档更新**：README/使用手册中应加入 “SGLang mode” 示例（端口 30000）以及 `SGLANG_DUMPER_SERVER_PORT= reuse` 的意义说明，帮助用户快速切换到新模型。  

总体而言，改动实现了统一的 HTTP 控制入口，提升了 Dumper 在分布式与单机部署间的可操作性。只需对配置校验、错误返回及文档进行细化，即可确保在生产环境中的平滑迁移。

---

### Support resetting and enhance HTTP endpoints for dumper (#19046)
**SHA**: `2fecc2c` | 🔗 [查看提交](https://github.com/sgl-project/sglang/commit/2fecc2c075a18d2e6ec8165aeaa8e7ecdb71e77c)

**🎯 变更类型**：功能增强 / 轻量 bug 修复  
**⚡ 重要程度**：🟡 中  
**📋 变更摘要**：为 `sglang.srt.debug_utils.dumper`新增 **reset** 接口，并将原先单一的 `/dumper` POST 改为统一的 `/dumper/configure` + `/dumper/reset`，使用 ZMQ 广播实现多进程同步配置。对应测试用例同步更新，覆盖配置、错误处理以及 reset 后的状态恢复。  

**🎯 影响范围**  
- `python/sglang/srt/debug_utils/dumper.py`（核心逻辑、HTTP 处理、ZMQ RPC）  
- `test/registered/debug_utils/test_dumper.py`（新增/修改单元/集成测试）  
- 依赖 ZMQ 广播的多进程启动路径  

**💡 关注建议**  
1. **参数校验**：`_make_http_handler` 直接 `getattr(target, method)` 并调用，建议对 `method` 是否在白名单（configure、reset）进行限制，防止任意 RPC 被执行。  
2. **错误信息统一**：当前返回 `400` 时仅 `str(e)`，可考虑包装为 JSON `{error: ..., details: ...}`，便于调用方解析。  
3. **并发安全**：`reset` 只重置本地计数器，若在多进程环境中其它进程仍持有旧计数，建议在 `reset` 前后通过 ZMQ 广播同步（已实现），但需确认 `reset` 前的 pending `dump` 不会产生竞态。  
4. **文档同步**：README/CLI 示例仍使用旧 `/dumper` 路径，需更新为 `/dumper/configure` 与 `/dumper/reset`，并明确 `filter=None` 用于清除。  
5. **兼容性**：对旧版本的 HTTP 调用（仍发送 `/dumper`）返回 404，若有下游工具依赖，考虑保留兼容层或给出迁移提示。  

总体来看，改动提升了调试 dump 的可控性与可恢复性，测试覆盖充分。保持上述细节的稳健实现即可放心合入。

---

### Enhance configure and env parsing in dumper (#19034)
**SHA**: `503bf30` | 🔗 [查看提交](https://github.com/sgl-project/sglang/commit/503bf3047a51b398b9f8c57d70a9216216b5b1d9)

**🟢 变更概览**  
- 引入 `@dataclass(frozen=True)` 的 `_FrozenConfig` 与 `_DumperConfig`，统一管理 Dumper 所有可配置项，并在实例化时自动进行类型校验。  
- `_Dumper` 构造函数改为接受 `config: _DumperConfig`，内部属性全部迁移至 `self._config`，并提供 `configure` / `configure_default` 动态覆写方式。  
- 移除旧的 `get_bool_env_var`、`_get_str_env_var` 等 env‑helper，统一使用 `_DumperConfig.from_env()`。  
- 相关逻辑（如 HTTP 服务器、partial_name、路径拼接、日志输出）全部改为读取 `self._config`。  
- 测试用例同步更新，新增 `TestDumperConfig` 验证 env‑解析、类型检查与 `configure_default` 行为。  

**⚡ 影响范围**  
- `sglang/srt/debug_utils/dumper.py`（核心实现）  
- 依赖 Dumper 的内部 RPC（`DumperRpcHandler`）以及所有测试模块。  

**🔎 关键影响**  
1. **配置统一与安全**：所有配置项现在是不可变的 dataclass，类型错误会在实例化时抛异常，提升运行时可靠性。  
2. **向后兼容风险**：原来的 ` _Dumper(**kwargs) ` 直接传参方式已被删除，外部代码若仍使用旧构造函数会报错。  
3. **环境变量解析集中**：`_DumperConfig.from_env()` 替代了散落的 `_get_*_env_var`，但其他模块若自行读取 `SGLANG_DUMPER_*` 环境变量需改为使用该入口。  
4. **动态配置 API**：`configure`（强制覆盖）与 `configure_default`（仅在 env 未定义时生效）提供更细粒度的运行时控制，现有 `override_enable` 已被移除。  
5. **路径/目录逻辑变更**：`self._config.dir` 与 `self._config.partial_name` 直接用于构造 dump 路径，确保在 `configure_default` 之后仍保持一致。  

**💡 建议**  

*对开发者*  
- 在项目文档和 `README` 中明确标注 `*_Dumper` 已改为 “config‑first” 构造方式，建议保留一个兼容层（例如 `@classmethod from_legacy(**kwargs)`）以平滑迁移。  
- 确认项目其余子模块（如 `sglang/srt/debug_utils/dump_comparator.py`）是否仍调用废弃的 env‑helper，统一改为 `._DumperConfig.from_env()`。  
- 为关键配置字段加入 `metadata={"description": "..."} `，配合 `dataclasses.asdict` 生成文档或 UI。  
- 考虑在 `configure_default` 中加入日志提示，帮助用户了解哪些字段被 env 覆盖。  

*对用户*  
- 如需在运行时临时关闭 Dump，只需调用 `dumper.configure(enable=False)`，无需再使用 `override_enable`。  
- 若想在代码中设定默认值而不被环境变量覆盖，使用 `dumper.configure_default(...)`；否则直接 `configure` 覆盖所有。  
- 迁移至新 API 后，确保使用的 `SGLANG_DUMPER_*` 环境变量与 `_DumperConfig` 中的字段名保持一致（大小写、下划线转大写）。  

总体而言，此次重构显著提升了配置的可维护性与安全性，但必须同步更新所有外部调用并做好迁移指引，以避免因构造函数签名改变导致的破坏性回归。

---

### Support filtering labels in dumper (#19018)
**SHA**: `df995aa` | 🔗 [查看提交](https://github.com/sgl-project/sglang/commit/df995aab565db64a2ae99aafd4b0dacf52274c5e)

**🎯 变更类型**：功能增强  
**⚡ 重要程度**：🟡 中  

**📋 变更摘要**  
1. 为 `Dumper` 引入 “标签” 概念，所有 dump、grad‑hook、捕获输出等入口统一使用 `tags: dict` 而非单一 `name` 参数。  
2. 新增 `_format_tags` 用于把标签字典序列化为文件名片段，实现基于任意 KV（包括 `name`、额外关键字、全局上下文）的过滤。  
3. 过滤逻辑从 `re.search(filter, name)` 改为 `re.search(filter, _format_tags(tags))`，并相应调整了内部调用路径。  
4. 单元测试全面覆盖：过滤匹配 name、extra kwargs、全局上下文、正则写法以及无过滤的默认行为。  

**🎯 影响范围**  
- `python/sglang/srt/debug_utils/dumper.py`（核心实现）  
- 相关测试 `test/registered/debug_utils/test_dumper.py`（新增 KV‑filter 用例）  
- 可能的外部调用：任何使用 `SGLANG_DUMPER_FILTER` 环境变量或 `Dumper.dump(..., **kwargs)` 的代码。  

**💡 关注建议**  

| 类别 | 建议 |
|------|------|
| **向后兼容** | 目前过滤表达式必须匹配键值形式（如 `name=keep`），旧的 `^keep` 将失效。建议在 `__init__` 中检测未包含 `=` 的模式，自动转为 `name=` 前缀，或在文档明确说明迁移步骤。 |
| **文件名确定性** | `_format_tags` 按 dict 插入顺序拼接，若 `extra_kwargs` 的顺序不同会生成不同文件名。为保证可重复性，可改为 `"_".join(f"{k}={v}" for k, v in sorted(kwargs.items()))`，并在 `tags = dict(name=…, **extra, **global)` 前统一排序。 |
| **空值处理** | 当前 `None` 会被序列化为 `"None"`，可能导致意外过滤匹配。可在 `_format_tags` 中过滤掉值为 `None` 的键，或在 `dump` 前统一剔除。 |
| **性能** | 过滤每次都调用 `re.search` 与 `_format_tags`（涉及遍历字典并创建新字符串），在高频 dump 场景下潜在开销。若性能敏感，可预编译正则并在 `filter` 为 `None` 时跳过字符串拼接。 |
| **文档 & 示例** | 更新 README / API 文档，示例展示 `SGLANG_DUMPER_FILTER="layer_id=0"`、`"name=keep"`、正则写法等，用例应说明过滤键的来源（extra kwargs、全局 ctx）。 |
| **测试** | 已覆盖主要分支，建议再补充：<br>• `extra_kwargs` 为非标量（如列表、Tensor）时的序列化是否符合预期；<br>• 多线程/分布式并发下标签合并的正确性。 |

总体而言，此次改动显著提升了 `Dumper` 的可筛选性，代码结构已从单纯 “name” 转向更通用的 KV 体系。只要注意上述兼容性与确定性细节，即可安心合并。

---

### Support captured dump output and console output control in dumper (#19017)
**SHA**: `261bca3` | 🔗 [查看提交](https://github.com/sgl-project/sglang/commit/261bca3c58c617def40aa226b92be137167397d4)

**🎯 变更类型**：功能增强  
**⚡ 重要程度**：🟡 中  
**📋 变更摘要**：为 `sglang.srt.debug_utils.dumper.Dumper` 增加了 **控制台输出** 与 **文件写入** 的独立开关，并实现了 **捕获 dump 输出** 的上下文管理器，使得在单元测试或调试时可以仅在内存中获取 `value`/`meta` 而不产生磁盘文件。相应的环境变量 `SGLANG_DUMPER_OUTPUT_FILE`、`SGLANG_DUMPER_OUTPUT_CONSOLE` 也同步添加。  
**🎯 影响范围**：  
- `python/sglang/srt/debug_utils/dumper.py`（核心逻辑）  
- `test/registered/debug_utils/test_dumper.py`（新增测试）  
- 使用 `Dumper` 的所有上层模块（如模型推理、SRT runner）会受到默认行为变化的影响。  

**💡 关注建议**  
1. **向后兼容**：原来的 `enable_write_file` 参数已改名，保持 `from_env` 的默认值不变即可；若项目外部仍通过关键字 `enable_write_file` 实例化，需要更新调用方或在 `__init__` 中添加兼容别名。  
2. **环境变量文档**：在 README / env 说明里补充 `SGLANG_DUMPER_OUTPUT_FILE`、`SGLANG_DUMPER_OUTPUT_CONSOLE` 的含义及默认值。  
3. **线程安全**：`capture_output` 通过实例属性 `_captured_output_data` 保存临时字典，在多线程并发 dump 时可能出现冲突。建议在文档中明确该上下文只能在单线程/单进程环境下使用，或改为 `threading.local()`。  
4. **深拷贝行为**：捕获模式下会 `clone` Tensor（或 `deepcopy`），确保不会因后续修改导致数据不一致。若后续加入自定义对象（非 Tensor）需确认 `deepcopy` 仍可接受。  
5. **性能影响**：打开 `capture_output` 时仍会执行元数据计算，只是跳过文件 I/O，开销基本保持不变；关闭文件写入可显著降低磁盘负载，建议在大规模调试时显式关闭。  
6. **测试覆盖**：新增 `TestOutputControl` 已验证基本功能，但未覆盖异常情况（如嵌套 `capture_output`、在捕获期间调用 `override_enable`）。可考虑补充这些 edge‑case 测试。  

综上，此次改动提升了调试灵活性，只要在调用方更新参数名称并注意捕获上下文的使用限制，即可安全迁移。  

---

### Hint users when wrongly execute it with partial ranks in dumper (#19014)
**SHA**: `fc1500a` | 🔗 [查看提交](https://github.com/sgl-project/sglang/commit/fc1500adc628e657d19a94d9d997a5176c623753)

**🎯 变更类型**：功能增强 / 稳定性提升  
**⚡ 重要程度**：🟡 中  

**📋 变更摘要**  
- 在 `sglang/srt/debug_utils/dumper.py` 中为所有涉及 `torch.distributed` 的集合操作（`broadcast_object_list`、`all_gather_object` 等）加入超时守护线程 ` _collective_with_timeout`。  
- 新增 `collective_timeout` 参数（默认 60 s），并在 `Dumper` 实例化、环境变量加载以及 HTTP/ZMQ 服务启动时使用。  
- 通过打印 WARNING，提醒用户在部分 rank 未参与时可能导致进程卡死。  
- 添加对应单元测试，验证 watchdog 在超时后会输出提示信息，并在分布式环境下能够捕获。  

**🎯 影响范围**  
- `python/sglang/srt/debug_utils/dumper.py`（核心调试/dump 功能）  
- 关联的 HTTP 控制服务器与 ZeroMQ RPC 创建逻辑  
- 分布式环境下的 `sglang` 运行时（`dist.is_initialized()` 时）。  
- 新增 `test/registered/debug_utils/test_dumper.py` 中的超时相关测试。  

**💡 关注建议**  

1. **配置验证**：`collective_timeout` 默认 60 s，业务方若在大规模集群上使用 Dumper，建议通过环境变量 `SGLANG_DUMPER_COLLECTIVE_TIMEOUT`（或在代码中显式传参）调大，以免误报。  
2. **异常路径**：超时仅打印警告，不抛异常；如果业务需要强制终止，请在外层捕获并自行处理。  
3. **线程安全**：`_collective_with_timeout` 使用 `threading.Event` 与守护线程，确保在函数返回后及时 `set()`；若在自定义的 collect 操作中出现阻塞的 C++ 调用，仍可能导致进程卡死，请评估是否需要在 C++ 层面加入超时。  
4. **测试覆盖**：新加入的测试使用 `threading.Event` 模拟阻塞，已验证警告输出。后续若增加其他集合调用（如 `all_reduce`），记得在对应位置加入 `_collective_with_timeout` 并补充测试。  
5. **文档与日志**：建议在官方 README 或 `debug_utils` 文档中说明该超时机制及调参方法，并在日志中统一使用 `[Dumper]` 前缀，便于用户搜索。  

总体来说，此次改动提升了 Dumper 在不完整分布式环境下的可观测性，降低了因集合操作阻塞导致的卡死风险。只要确认 timeout 参数符合实际集群规模，即可安全上线。

---

### Revert "Add SDAR model support" (#19032)
**SHA**: `73a7f0d` | 🔗 [查看提交](https://github.com/sgl-project/sglang/commit/73a7f0d04997aa7528abacf18c90c07ec4819ef3)

**🎯 变更类型**：其他（撤回功能）  
**⚡ 重要程度**：🟡 中  

**📋 变更摘要**  
- 将文档中 SDAR（JetLM）模型条目删去。  
- `srt/dllm/config.py` 只保留对 `LLaDA2MoeModelLM` 的硬编码参数，移除统一的 `DLLM_PARAMS` 表并改写异常提示。  
- 完整删除 `sdar.py`、`sdar_moe.py` 两套模型实现以及对应的测试 `test_sdar.py`。  

**🎯 影响范围**  
- **模型加载层**：`from_server_args` 现在只能识别 `LLaDA2MoeModelLM`，其他 diffusion‑LLM（如 SDAR）会直接抛 `Unknown diffusion LLM`。  
- **文档**：`diffusion_language_models.md` 中不再展示 SDAR。  
- **代码库**：全部与 SDAR 相关的类、权重加载、MoE 实现全部移除，导致 `import sglang.srt.models.sdar*` 的路径失效。  
- **CI/测试**：删除 `test/registered/dllm/test_sdar.py`，相应的 CI 任务不再执行。  

**💡 关注建议**  
1. **兼容性检查**：确认项目其他模块（如模型注册表、示例脚本、第三方插件）没有硬编码 `SDAR*` 类名或 `model_path`。若有，需要同步移除或给出提示。  
2. **异常信息**：当前异常信息只返回模型架构字符串，建议在文档或 README 中明确说明已不再支持 SDAR，避免用户在调用时因 “Unknown diffusion LLM” 而误判为 bug。  
3. **权重下载**：若已有 SDAR checkpoint cached，提醒用户手动删除或忽略，否则 `from_server_args` 会直接报错。  
4. **代码清理**：搜索 `SDAR` 关键字，确保没有残留的 `import`、注释或 `if` 判断，防止 import‑error 在运行时出现。  
5. **版本发布说明**：在发布日志中注明 “撤回 SDAR 模型支持”，并提供迁移指南（如改用 LLaDA2.0）。  

此轮回滚主要是恢复到仅支持 LLaDA2 系列的状态，影响范围局限于模型加载与文档展示。只要上述检查完成，现有功能不受影响，后续可在新的 PR 中重新引入 SDAR 时再做更完善的集成。

---

### Add SDAR model support (#18318)
**SHA**: `44ab752` | 🔗 [查看提交](https://github.com/sgl-project/sglang/commit/44ab752b7aeaf4a26ce6cbab972a74372126879b)

**🎯 变更类型**：功能增强（新增 SDAR 系列 Diffusion‑LLM 支持）  
**⚡ 重要程度**：🟡 中  

**📋 变更摘要**  
1. 在文档表格中加入 SDAR‑8B、SDAR‑30B 两种模型的说明。  
2. `dllm/config.py` 将模型‑>参数映射抽象为 `DLLM_PARAMS`，统一处理 LLaDA2 与 SDAR 的 `block_size`、`mask_id`。  
3. 新增 `sdar.py`（dense 版本）与 `sdar_moe.py`（MoE 版本）两套模型实现，完整复制 LLaMA‑style `BlockDiffusion` 流程：embedding → 多层 `SDARBlock/SDARMoeBlock` → RMSNorm → LM‑head → logits。  
4. 为新模型补充权重加载逻辑，兼容 GPTQ、colossal‑AI 产生的额外张量以及分片 weight。  
5. 添加 CI 测例 `test_sdar.py`：一次性请求和 GSM8K Few‑Shot 评测，验证准确率 > 0.88、吞吐 > 80/250 token/s（AMD / CUDA）。  

**🎯 影响范围**  
- **核心模块**：`sglang/srt/models/*`（SDAR、SDARMoe）、`sglang/srt/dllm/config.py`、权重加载通用函数。  
- **文档**：`docs/supported_models/...`。  
- **测试**：`test/registered/dllm/test_sdar.py`。  
- **分布式/并行**：依赖 PP、TP、MoE‑EP 实现，保持与已有模型一致的调度与 All‑Reduce/Reduce‑Scatter 行为。  

**💡 关注建议**  
1. **兼容性**：`DLLM_PARAMS` 只覆盖当前已知 arch，新增其他 dLLM 时请同步更新；考虑在 `from_server_args` 中加入 fallback 提示，防止因 typo 抛出 `RuntimeError`。  
2. **权重加载**：`load_weights` 中对 `model.` 前缀的处理较为隐式，建议抽取为工具函数，以免后续模型路径变化导致遗漏。  
3. **MoE 路由**：`SDARMoeSparseMoeBlock` 对 `expert_parallel` 的依赖在非‑MoE 环境下仍会创建 `ep_size`，建议加 `if get_moe_a2a_backend().is_enabled():` 防止不必要的初始化。  
4. **性能**：`SDAR` 的 `block_size` 设为 4，可能影响 token‑level并行度；在高并发（>64）场景下建议提供可配置的 block_size 参数。  
5. **测试可靠性**：CI 中对吞吐的阈值硬编码，建议放入配置或通过 `--min-throughput` 参数驱动，避免不同硬件/驱动差异导致误报。  
6. **文档**：新增模型后，请同步到模型列表页面的搜索关键字，以免用户找不到对应模型。  

总体来看，此次提交为项目首次引入 SDAR（Dense 与 MoE）Diffusion‑LLM，实现完整、测试覆盖合理，但在参数映射、权重加载抽象以及 MoE 初始化上还有进一步提升的空间。

---

#### 🟢 低重要度变更 (15)

### Fix adjust_num_token_non_padded_for_attn_tp returning CPU tensor (#19051)
**SHA**: `38ee749` | 🔗 [查看提交](https://github.com/sgl-project/sglang/commit/38ee749dd90cdab572d393bb856430ef92c981d2)

**🎯 变更类型**：代码重构  
**⚡ 重要程度**：🟢低  
**📋 摘要**：将 `compute_local_num_token_non_padded` 参数统一为张量，去除对 `int` 的临时转换，并在 `adjust_num_token_non_padded_for_attn_tp` 中直接使用 `self.num_token_non_padded`，修复返回 CPU 张量的问题。

---

### [Fix] Run FlashInfer autotune on non-default stream for NCCL 2.29+ compatibility (#18987)
**SHA**: `3358ba8` | 🔗 [查看提交](https://github.com/sgl-project/sglang/commit/3358ba894588f25da97c1c29fea9e32569669d60)

**🎯 变更类型**：代码重构  
**⚡ 重要程度**：🟢低  
**📋 摘要**：在 NCCL 2.29+ 环境下，为避免默认流上的 cudaMemcpyBatchAsync 错误，将 FlashInfer 自动调优搬到非默认流执行，并在分配器中加入临时目录清理和进程同步。  

简要说明：  
- `pynccl_allocator.py` 创建并清理 `symm_allocator` 临时目录，使用 `torch.distributed.barrier()` 保证跨进程同步。  
- `model_runner.py` 在 `forward_stream` 上执行 autotune，使用 `wait_stream` 确保流顺序，防止 NCCL 2.29+ 的不兼容问题。  

整体改动提升了多进程/多卡环境下的兼容性和稳定性。

---

### [Fix] DO NOT skip save_kv_cache for dllm (#19020)
**SHA**: `5285240` | 🔗 [查看提交](https://github.com/sgl-project/sglang/commit/52852404c869d7be291b386073baca850f69aaef)

**🎯 变更类型**：代码重构（Bug 修复）  
**⚡ 重要程度**：🟢 低  
**📋 摘要**：在 `flashinfer_backend.py` 中，将原先仅在 ENCODER_ONLY 时强制关闭 `save_kv_cache` 的条件改为“当模型不是 DLLM 且为 ENCODER_ONLY 时”才关闭，避免在 DLLM 场景下错误跳过 KV 缓存保存。

---

### Fix NSA FP8 KV cache path for both-trtllm MHA one-shot (#18931)
**SHA**: `f23a23c` | 🔗 [查看提交](https://github.com/sgl-project/sglang/commit/f23a23cc05fca67d296426e4acb9ce69524f26e4)

**🎯 变更类型**：其他  
**⚡ 重要程度**：🟢低  
**📋 摘要**：在 `forward_mha.py` 中为 NSA 的 FP8 KV 缓存路径加入额外条件，防止在两端均使用 TRTLLM 时误走 FP8 路径，从而修复对应的错误。

---

### Fix lint on main (#19054)
**SHA**: `0d20cf5` | 🔗 [查看提交](https://github.com/sgl-project/sglang/commit/0d20cf5a66531eed4db554589dd80c045b5c9e17)

**🎯 变更类型**：代码重构  
**⚡ 重要程度**：🟢低  
**📋 摘要**：修复 lint 警告，去除了未使用的 `Self` 导入并将 `from_env`、`with_defaults` 的返回类型改为字符串前向声明；调整 `scheduler.py` 中对 `dumper` 的导入位置，改为函数内部按需导入。

---

### feature: docker patch workflow (#19025)
**SHA**: `77fdb6a` | 🔗 [查看提交](https://github.com/sgl-project/sglang/commit/77fdb6af8146947095186c9f9d4629f2a372af4d)

**🎯 变更类型**：配置调整  
**⚡ 重要程度**：🟢低  
**📋 摘要**：新增 `.github/workflows/patch-docker-dev.yml` 工作流，实现通过指定 PR 编号或对比主分支，生成补丁并基于指定标签的 Docker 镜像重新构建、推送。

---

### fix lint on main (#19052)
**SHA**: `b59a22f` | 🔗 [查看提交](https://github.com/sgl-project/sglang/commit/b59a22f781ef2f7090367b76d58e8ae722ed5ace)

**🎯 变更类型**：代码重构  
**⚡ 重要程度**：🟢低  
**📋 摘要**：在 `python/sglang/srt/debug_utils/dumper.py` 中新增一行空行，调整类定义之间的间距，以通过 lint 检查。

---

### [AMD] Replace msgpack with msgspec in MORI-IO (#19007)
**SHA**: `b0786cd` | 🔗 [查看提交](https://github.com/sgl-project/sglang/commit/b0786cdf94935f0dec701079ea7e66d008560746)

**🎯 变更类型**：代码重构  
**⚡ 重要程度**：🟢低  
**📋 摘要**：在 `mori/conn.py` 中将序列化库从 `msgpack` 替换为 `msgspec.msgpack`，相应地调整了 `packb`、`unpackb` 为 `encode`、`decode`，并更新了对应的 import。  

简洁、功能等价的库替换，影响范围局限于该文件的序列化/反序列化实现。

---

### [Fix][Qwen3.5] Pass max_mamba_cache_size to mamba pool in disaggregation decode path (#19002)
**SHA**: `8541b11` | 🔗 [查看提交](https://github.com/sgl-project/sglang/commit/8541b1118d6cb396fe9c8f580ea597996635f8fb)

**🎯 变更类型**：代码重构  
**⚡ 重要程度**：🟢 低  
**📋 摘要**：在 `disaggregation/decode.py` 中新增 `mamba_size` 参数，并在初始化时使用 `max_mamba_cache_size` 代替默认值，以正确配置 Mamba 缓存大小；相应在 `model_runner_kv_cache_mixin.py` 传递该参数。  

---

### Support cleanup previous dumps in dumper (#19013)
**SHA**: `b41d412` | 🔗 [查看提交](https://github.com/sgl-project/sglang/commit/b41d412c3d9ec606edadfb4bdc61f3076faf1ef2)

**🎯 变更类型**：代码重构/功能扩展  
**⚡ 重要程度**：🟢 低  
**📋 摘要**：在 `dumper` 中新增 `SGLANG_DUMPER_CLEANUP_PREVIOUS` 环境变量及 `cleanup_previous` 参数，实现首次写入前自动清理旧的 dump 目录；并补充相应单元测试验证默认不清理与开启清理的行为。

---

### Fix flashinfer autotune to only wrap run_once() (#19004)
**SHA**: `13a4a04` | 🔗 [查看提交](https://github.com/sgl-project/sglang/commit/13a4a0406eecb8bcd85c1a3994fc89ec386b42b0)

**🎯 变更类型**：代码重构  
**⚡ 重要程度**：🟢低  
**📋 摘要**：在 `model_runner.py` 中为 `_flashinfer_autotune` 与 `_dummy_run` 新增 `run_ctx` 参数，改为仅在实际 `run_once` 调用时包装 `autotune()`（或默认空上下文），避免对整个 dummy run 施加推理模式，提升自动调优的粒度与安全性。

---

### Fix long prompt KV allocation by falling back to torch native APIs when exceeding Triton tensor limit (#18250)
**SHA**: `64bca53` | 🔗 [查看提交](https://github.com/sgl-project/sglang/commit/64bca5315f59ae6b7e57cf4d8a13180f0e7e518f)

**🎯 变更类型**：代码重构  
**⚡ 重要程度**：🟢低  
**📋 摘要**：在 `allocator.py` 中，当扩展的 token 数超出 Triton 张量上限时，改为回退使用纯 PyTorch 实现的 `alloc_extend_naive`，并对 `seen_max_num_extend_tokens_next_power_of_2` 取上限防止溢出，提升长提示场景的稳定性。

---

### Register tensors with symmetric memory for qwen (#18643)
**SHA**: `99df920` | 🔗 [查看提交](https://github.com/sgl-project/sglang/commit/99df920cdbba20f033ba58765f5da04f59efe4fe)

**🎯 变更类型**：代码重构  
**⚡ 重要程度**：🟢低  
**📋 摘要**：将 `final_hidden_states = final_hidden_states + shared_output` 改为原位加 `final_hidden_states += shared_output`，确保在开启对称内存时保持张量位于对称内存池，防止后续对称集体操作失效。

---

### Tiny remove duplicate coredump env injection (#19023)
**SHA**: `db34c1c` | 🔗 [查看提交](https://github.com/sgl-project/sglang/commit/db34c1cbfbf1f74152cee4965fcd9365d1d69aa9)

**🎯 变更类型**：代码重构  
**⚡ 重要程度**：🟢低  
**📋 摘要**：在 `cuda_coredump.py` 中去除重复的环境变量注入逻辑，改用 `warnings.warn` 替代日志，使用标准输出打印检测信息并加入 sentinel 标记防止多次注入。

---

### [spec v2]Fix torch gc of future indices (#18958)
**SHA**: `5ff5aa6` | 🔗 [查看提交](https://github.com/sgl-project/sglang/commit/5ff5aa6923b914b03b4592b841ee9d69bfde664e)

**🎯 变更类型**：代码重构  
**⚡ 重要程度**：🟢低  
**📋 摘要**：在 `resolve_future` 中为 `indices` 张量添加 `record_stream`，防止其在前向流使用期间被 Torch 垃圾回收，修复了未来索引的内存回收问题。

---

