# æ¯æ—¥æ›´æ–°æŠ¥å‘Šï¼ˆ2026-02-14ï¼‰

## sgl-project/sglang

| æäº¤æ—¶é—´ | ä½œè€… | æäº¤ä¿¡æ¯ |
|----------|------|----------|
| 2026-02-14 23:19:45 | Xiaoyu Zhang | [diffusion] feat: opt vae decode with `channels_last_3d`  (#18540) |
| 2026-02-14 23:06:21 | Xiaoyu Zhang | [kernel slimming] Move fast_hadamard_transform to jit_kernel (#18475) |
| 2026-02-14 23:00:33 | Kangyan-Zhou | Enable SGLANG_ENABLE_SPEC_V2 for nightly speculative decoding tests (#18719) |
| 2026-02-14 22:51:44 | Raayan Dhar | feat: Support `mrope_section` with `rope_type: "yarn"` (#13313) |
| 2026-02-14 22:20:23 | Ke Bao | Add ci test for ring model (#18829) |
| 2026-02-14 16:44:13 | ybyang | Fix  dsv32 encode_messages  (#18126) |
| 2026-02-14 16:40:15 | Johnsonms | Kernel: optimize decoding metadata in NSA multi-spec backend with fused kernels (#17554) |
| 2026-02-14 16:07:26 | Bingxu Chen | [AMD] Fix sgl-model-gateway Build Errors in ROCm Docker Release  (#18836) |
| 2026-02-14 15:31:42 | Zehuan Li | [DLLM] Update CODEOWNERS for diffusion LLM (#18834) |
| 2026-02-14 14:35:26 | Yuan Luo | [VLM][LLM] Optimize fused_moe triton kernel tma (#18782) |
| 2026-02-14 11:04:08 | JD | Fix/partial gen from waiting queue miss metadata (#17610) |
| 2026-02-14 11:00:39 | R0CKSTAR | [diffusion][MUSA] fix: MUSA platform breakage caused by PR #13662 (#18456) |
| 2026-02-14 10:48:31 | Alison Shao | Fix CI concurrency collision between scheduled runs and fork PRs (#18826) |
| 2026-02-14 10:39:39 | qmzznbxhl | Handle abort for retracted requests in disagg decode prealloc queue (#18705) |
| 2026-02-14 10:02:31 | shuwenn | [Env] centralize hicache vars in environ.py (#17204) |
| 2026-02-14 09:57:30 | Liangsheng Yin | Add timeout abort kits for normal / eagle. (#18815) |
| 2026-02-14 09:46:35 | Liangsheng Yin | [PD-Disagg] Fix double free when prebuilt batch is aborted. (#18822) |
| 2026-02-14 09:37:33 | Leon Gao | feat: add SGLANG_DISTRIBUTED_INIT_METHOD_OVERRIDE env var (#18743) |
| 2026-02-14 09:30:50 | Minglei Zhu | [Perf] refactor piecewise cuda graph support of Qwen3-Next (#17613) |
| 2026-02-14 09:28:28 | Kangyan-Zhou | Update performance dashboard for nightly tests (#18824) |
| 2026-02-14 08:46:09 | shuwenn | [CI] feat: add early exit to wait_for_server when process dies (#18602) |
| 2026-02-14 08:37:08 | Kangyan-Zhou | [CI] Revive 8-GPU trace upload in nightly test workflow (#18820) |
| 2026-02-14 07:43:33 | Mohammad Miadh Angkad | [FlashInfer] Bump FlashInfer version from 0.6.2 to 0.6.3 (#18448) |
| 2026-02-14 06:48:56 | Kangyan-Zhou | Update notified user in post_ci_failures_to_slack.py (#18817) |
| 2026-02-14 05:17:44 | JD | fix double-free kv cache for requests that have already finished and been freed during preemption  (#18694) |
| 2026-02-14 04:22:50 | Lianmin Zheng | [Auto Sync] Update loader.py, weight_utils.py (20260213) (#18779) |

### ğŸ“Š ç»Ÿè®¡æ‘˜è¦
> æœ¬æ—¥å…± 26 ä¸ªæäº¤ | ğŸ”´é«˜ 4 | ğŸŸ¡ä¸­ 12 | ğŸŸ¢ä½ 10
## ğŸ“‹ ç›®å½•

- [sgl-project/sglang](#sgl-project-sglang)
  - [ğŸ“Š ç»Ÿè®¡æ‘˜è¦](#-ç»Ÿè®¡æ‘˜è¦)
  - [ğŸ”´ é«˜é‡è¦åº¦å˜æ›´ (4)](#-ğŸ”´-é«˜é‡è¦åº¦å˜æ›´-4)
    - [[kernel slimming] Move fast_hadamard_transform to jit_ker...](#c29394e)
    - [feat: Support `mrope_section` with `rope_type: "yarn"` (#...](#92cdd39)
    - [Kernel: optimize decoding metadata in NSA multi-spec back...](#34132d6)
    - [feat: add SGLANG_DISTRIBUTED_INIT_METHOD_OVERRIDE env var...](#ab0fb24)
  - [ğŸŸ¡ ä¸­é‡è¦åº¦å˜æ›´ (12)](#-ğŸŸ¡-ä¸­é‡è¦åº¦å˜æ›´-12)
    - [Enable SGLANG_ENABLE_SPEC_V2 for nightly speculative deco...](#ae95869)
    - [Add ci test for ring model (#18829)](#f51e9d9)
    - [[VLM][LLM] Optimize fused_moe triton kernel tma (#18782)](#fa0ef6e)
    - [Fix/partial gen from waiting queue miss metadata (#17610)](#f6c18c3)
    - [[Env] centralize hicache vars in environ.py (#17204)](#bd39de7)
    - [Add timeout abort kits for normal / eagle. (#18815)](#dcea74d)
    - [[Perf] refactor piecewise cuda graph support of Qwen3-Nex...](#8be18c6)
    - [Update performance dashboard for nightly tests (#18824)](#3a1c388)
    - [[CI] feat: add early exit to wait_for_server when process...](#3299c4f)
    - [[CI] Revive 8-GPU trace upload in nightly test workflow (...](#eccf875)
    - [[FlashInfer] Bump FlashInfer version from 0.6.2 to 0.6.3 ...](#1be41e9)
    - [[Auto Sync] Update loader.py, weight_utils.py (20260213) ...](#008ea46)
  - [ğŸŸ¢ ä½é‡è¦åº¦å˜æ›´ (10)](#-ğŸŸ¢-ä½é‡è¦åº¦å˜æ›´-10)
    - [[diffusion] feat: opt vae decode with `channels_last_3d` ...](#4067d94)
    - [Fix  dsv32 encode_messages  (#18126)](#c8aa2a6)
    - [[AMD] Fix sgl-model-gateway Build Errors in ROCm Docker R...](#38473f8)
    - [[DLLM] Update CODEOWNERS for diffusion LLM (#18834)](#e2eb5bf)
    - [[diffusion][MUSA] fix: MUSA platform breakage caused by P...](#45a4697)
    - [Fix CI concurrency collision between scheduled runs and f...](#8ef3e3d)
    - [Handle abort for retracted requests in disagg decode prea...](#066b0b7)
    - [[PD-Disagg] Fix double free when prebuilt batch is aborte...](#4474fb9)
    - [Update notified user in post_ci_failures_to_slack.py (#18...](#710d873)
    - [fix double-free kv cache for requests that have already f...](#191d354)
#### ğŸ”´ é«˜é‡è¦åº¦å˜æ›´ (4)

### [kernel slimming] Move fast_hadamard_transform to jit_kernel (#18475)
**SHA**: `c29394e` | ğŸ”— [æŸ¥çœ‹æäº¤](https://github.com/sgl-project/sglang/commit/c29394e3c84a61e160da78d2edbf11939ec0ec07)

**ğŸ¯ å˜æ›´ç±»å‹**ï¼šåŠŸèƒ½å¢å¼º / é‡æ„ / æ¶æ„å˜æ›´  
**âš¡ é‡è¦ç¨‹åº¦**ï¼šğŸ”´ é«˜  

**ğŸ“‹ å˜æ›´æ‘˜è¦**  
- å°†åŸæœ¬åœ¨ **sglâ€‘kernel** ä¸­çš„ `fast_hadamard_transform` ç³»åˆ—å®ç°è¿ç§»è‡³ **sglâ€‘lang/jit_kernel**ï¼Œå¹¶ä½¿ç”¨ **TVMâ€¯FFIâ€¯+â€¯JIT** æ–¹å¼åŠ¨æ€ç¼–è¯‘ã€‚  
- æ–°å¢ C++/CUDA ä»£ç ç”Ÿæˆ (`code_gen.py`)ã€ä¸“ç”¨ kernel traitã€sharedâ€‘memory äº¤æ¢ã€ä»¥åŠé’ˆå¯¹ 12/20/28/40â€‘multiple çš„ç‰¹åŒ–å®ç°ã€‚  
- åœ¨ Python å±‚æä¾›ç»Ÿä¸€ `hadamard_transform*` æ¥å£ï¼Œè‡ªåŠ¨é€‰æ‹©å¯¹åº”ç‰¹åŒ– kernelï¼›åŸæœ‰ `sgl_kernel.hadamard` æ¥å£è¢«ç§»é™¤ï¼Œç›¸å…³è°ƒç”¨æ”¹ä¸º `sglangu.jit_kernel.hadamard`.  
- åŒæ—¶ä» **sglâ€‘kernel** çš„ CMake ä¸ Python åŒ…ä¸­å‰”é™¤ fastâ€‘hadamardâ€‘transform çš„ç¼–è¯‘é“¾æ¥ï¼Œé™ä½äºŒè¿›åˆ¶ä½“ç§¯å¹¶é¿å…é‡å¤å®ç°ã€‚  

**ğŸ¯ å½±å“èŒƒå›´**  
| æ¨¡å—/ç»„ä»¶ | å—å½±å“çš„æ–‡ä»¶/ç›®å½• | å½±å“æè¿° |
|-----------|------------------|----------|
| **sglang core** | `sglang/srt/layers/attention/nsa/nsa_indexer.py` | æ”¹ä¸ºä» `sglangu.jit_kernel.hadamard` å¯¼å…¥ `hadamard_transform`ã€‚ |
| **sglâ€‘kernel** | `CMakeLists.txt`, `common_extension.cc`, `include/sgl_kernel_ops.h`, `python/sgl_kernel/__init__.py`, `tests/test_hadamard.py` | åˆ é™¤ç¼–è¯‘å’Œ Python bindingï¼Œç›¸å…³å•å…ƒæµ‹è¯•æ”¹ä¸ºå¯é€‰ã€‚ |
| **jit_kernel** | æ–°å¢ `csrc/fastâ€‘hadamardâ€‘transform/*`ï¼ˆä»£ç ç”Ÿæˆã€CUDA kernelã€ç‰¹åŒ–å¤´ã€é™æ€åˆ‡æ¢å·¥å…·ï¼‰ä»¥åŠ `hadamard.py` | å®Œæ•´å®ç° fast Hadamard å˜æ¢çš„ JIT ç¼–è¯‘è·¯å¾„ã€‚ |
| **æ„å»ºç³»ç»Ÿ** | `sglâ€‘kernel` ä¸ `sglâ€‘lang` çš„ CMake/ç¼–è¯‘è„šæœ¬ | éœ€è¦ç¡®ä¿ `tvmlib`ã€`sgl_kernel` ä¾èµ–å·²è¢«æ­£ç¡®åŠ å…¥ï¼Œä»¥æ”¯æŒ TVMâ€¯FFI ç¼–è¯‘ã€‚ |
| **æµ‹è¯•** | `test/registered/kernels/test_nsa_indexer.py`ã€`sglâ€‘kernel/tests/test_hadamard.py` | é€‚é…æ–°çš„å¯¼å…¥è·¯å¾„ï¼Œè‹¥ JIT ç¼–è¯‘ä¸å¯ç”¨åˆ™è·³è¿‡ã€‚ |

---

### ğŸ” æŠ€æœ¯æ´å¯Ÿ

#### 1. æ¶æ„å½±å“
- **æ¨¡å—åŒ–ä¸èŒè´£åˆ†ç¦»**ï¼šHadamard ç›¸å…³å®ç°ä» **sglâ€‘kernel**ï¼ˆé™æ€ C++/CUDAåº“ï¼‰è¿ç§»åˆ° **jit_kernel**ï¼ˆè¿è¡Œæ—¶ JITï¼‰ï¼Œå®ç°äº†**â€œå†…æ ¸å³ä»£ç ç”Ÿæˆâ€**çš„ç»Ÿä¸€å…¥å£ï¼Œé¿å…åœ¨æ ¸å¿ƒåº“é‡Œç»´æŠ¤å†—ä½™ CMake ä¾èµ–ã€‚
- **æ„å»ºä¾èµ–ç®€åŒ–**ï¼šåŸæ¥éœ€è¦åœ¨ `sglâ€‘kernel` ä¸­é¢å¤–æ‹‰å– `fastâ€‘hadamardâ€‘transform` å­ä»“åº“ã€ç¼–è¯‘ `.cu/.cpp`ï¼Œç°åœ¨åªåœ¨ JIT æ—¶æ‹‰å–æºç å¹¶é€šè¿‡ `torch.utils.cpp_extension` ç¼–è¯‘ã€‚å¯¹ CIã€Wheel æ‰“åŒ…ä»¥åŠè·¨å¹³å°æ”¯æŒæ›´å‹å¥½ã€‚
- **ç»Ÿä¸€è°ƒåº¦**ï¼šæ‰€æœ‰ fast Hadamard kernelsï¼ˆæ™®é€šã€12Nã€20Nã€28Nã€40Nï¼‰ç»Ÿä¸€é€šè¿‡ `hadamard_jit.cuh` ä¸­çš„ `run_hadamard<kMultiple, DType>` è¿›è¡Œè°ƒåº¦ï¼Œä½¿ç”¨ **æ¨¡æ¿ç‰¹åŒ– + static_switch**ï¼Œä»£ç è·¯å¾„æ›´æ¸…æ™°ã€‚
- **å…¼å®¹æ€§**ï¼šä¿ç•™äº†åŸæœ‰ APIï¼ˆå‡½æ•°åæœªå˜ï¼‰ï¼Œä½†å®ç°å±‚å·²è½¬ä¸º JITï¼Œå¤–éƒ¨è°ƒç”¨ï¼ˆå¦‚ `rotate_activation`ï¼‰ä¸éœ€è¦æ”¹åŠ¨ï¼Œä»…æ›´æ¢ import è·¯å¾„ã€‚

#### 2. æ€§èƒ½å½±å“
| ç»´åº¦ | æ­£é¢æ•ˆåº” | æ½œåœ¨è´Ÿé¢ |
|------|----------|----------|
| **è¿è¡Œæ—¶å¼€é”€** | JIT ç¼–è¯‘åªåœ¨ç¬¬ä¸€æ¬¡è°ƒç”¨æ—¶è¿›è¡Œï¼Œåç»­è°ƒç”¨æˆæœ¬ä¸åŸç”Ÿ C++ ç›¸åŒï¼ˆå·²å¯¹ kernel launch è¿›è¡Œ `launch_kernel` å°è£…ï¼‰ã€‚ | é¦–æ¬¡è°ƒç”¨ä¼šäº§ç”Ÿä¸€æ¬¡**CUDA ç¼–è¯‘**ï¼ˆçº¦ 0.3â€‘1â€¯sï¼‰ï¼Œå¯¹æç«¯ä½å»¶è¿Ÿéœ€æ±‚çš„åœºæ™¯ï¼ˆå¦‚å•æ¬¡æ¨ç†ï¼‰ä¼šäº§ç”Ÿé¢å¤– latencyã€‚ |
| **å†…å­˜ä½¿ç”¨** | é‡‡ç”¨ **åŠ¨æ€å…±äº«å†…å­˜**ï¼ˆæœ€å¤§ 48â€¯KBï¼‰ï¼Œä¸åŸå®ç°ç›¸åŒæˆ–ç•¥æœ‰æå‡ï¼ˆç‰¹åŒ– 28N/40N ä½¿ç”¨ 28â€‘40â€¯KBï¼‰ï¼Œä¸ä¼šå¯¼è‡´é¢å¤–æ˜¾å­˜å ç”¨ã€‚ | ç¼–è¯‘é˜¶æ®µä¼šäº§ç”Ÿä¸´æ—¶çš„ PTXã€cubin æ–‡ä»¶ï¼Œéœ€ç¡®ä¿ç£ç›˜/å†…å­˜æœ‰è¶³å¤Ÿç©ºé—´ã€‚ |
| **ååé‡** | ä»£ç ç”Ÿæˆä½¿ç”¨å·²ä¼˜åŒ–çš„ **Paley / Will / TPAL** çŸ©é˜µï¼Œå®ç°äº† **æ‰‹å†™ç‰¹åŒ–**ï¼ˆ12/20/28/40ï¼‰è€Œéå®Œå…¨é€šç”¨é€’å½’ï¼Œç†è®ºä¸Šä¸ `fast_hadamard_transform` çš„æ‰‹å†™å®ç°ä¿æŒåŒç­‰æˆ–ç•¥æœ‰æå‡ã€‚| è‹¥ TVMâ€¯FFI çš„ `host::LaunchKernel` ä»ä½¿ç”¨ `cudaLaunchKernel` åŒ…è£…ï¼Œå¯èƒ½åœ¨æç«¯å¤§ batch æ—¶å‡ºç° **launch å‚æ•°æ ¡éªŒ** å¼€é”€ã€‚|
| **å¯ç»´æŠ¤æ€§** | æ‰€æœ‰ Hadamard ä»£ç é›†ä¸­åœ¨ `csrc/fast-hadamard-transform`ï¼Œä»£ç ç”Ÿæˆã€ç‰¹åŒ–ã€é€šç”¨å®ç°å‡åœ¨åŒä¸€ç›®å½•ï¼Œä¾¿äºç»Ÿä¸€ç»´æŠ¤å’Œæ·»åŠ æ–° multiplesã€‚| éœ€è¦åŒæ­¥æ›´æ–° **code_gen.py** ä¸å¯¹åº” **special.h**ï¼Œå¦åˆ™ç”Ÿæˆçš„ç‰¹åŒ– kernel ä¸æ‰‹å†™åº“ä¸åŒ¹é…ä¼šå¯¼è‡´æ•°å€¼é”™è¯¯ã€‚|

#### 3. å®‰å…¨è€ƒè™‘
- **è¾“å…¥æ ¡éªŒ**ï¼šåœ¨ JIT å±‚ (`run_hadamard`) ä¸­åŠ å…¥ `RuntimeCheck` å¯¹ç»´åº¦ã€multipleã€ä¸Šé™ï¼ˆ<= 40â€¯KBï¼‰è¿›è¡Œæ–­è¨€ï¼Œé˜²æ­¢éæ³•è°ƒç”¨è§¦å‘æœªå®šä¹‰è¡Œä¸ºã€‚  
- **ä»£ç ç”Ÿæˆ**ï¼š`code_gen.py` åªç”ŸæˆåŸºäºå›ºå®šå­—ç¬¦ä¸²çš„çŸ©é˜µï¼Œå¯¹å¤–éƒ¨æ•°æ®æ— ä¾èµ–ï¼Œä¸ä¼šäº§ç”Ÿä»£ç æ³¨å…¥é£é™©ã€‚  
- **GPU é©±åŠ¨å…¼å®¹**ï¼šæ‰€æœ‰ kernel ä½¿ç”¨ `__launch_bounds__`ã€`cudaFuncSetAttribute` åŠ¨æ€å…±äº«å†…å­˜è®¾ç½®ï¼Œå…¼å®¹ CUDAâ€¯11+ï¼›è‹¥è¿è¡Œç¯å¢ƒä½äºæ­¤ç‰ˆæœ¬ï¼Œå¯èƒ½å‡ºç° `cudaErrorInvalidValue`ã€‚  
- **å¼‚å¸¸ä¼ æ’­**ï¼šä½¿ç”¨ `host::RuntimeDeviceCheck()` å¯¹ CUDA API è°ƒç”¨è¿›è¡Œé”™è¯¯æ£€æŸ¥ï¼Œé˜²æ­¢é”™è¯¯è¢«é™é»˜åæ‰ã€‚

#### 4. æ½œåœ¨é£é™©ç‚¹
| é£é™© | è§¦å‘æ¡ä»¶ | å½±å“ | ç¼“è§£æªæ–½ |
|------|----------|------|----------|
| **é¦–æ¬¡ JIT ç¼–è¯‘å¤±è´¥**ï¼ˆç¼ºå°‘ç¼–è¯‘å™¨ã€C++14 æ ‡å‡†ã€CUDA headerï¼‰ | éƒ¨ç½²ç¯å¢ƒæœªå®‰è£… `nvcc` æˆ– `torch.utils.cpp_extension` çš„ç¼–è¯‘ä¾èµ– | æ•´ä¸ª Hadamard åŠŸèƒ½ä¸å¯ç”¨ï¼Œ`rotate_activation` æŠ¥é”™ | åœ¨ CI ä¸­åŠ å…¥ç¼–è¯‘ä¾èµ–æ£€æŸ¥ï¼›åœ¨ `hadamard.py` æ•è·å¼‚å¸¸å¹¶æä¾›æ˜ç¡®é”™è¯¯ä¿¡æ¯ã€‚ |
| **ç»´åº¦/Multiple è¶…å‡ºç¡¬ç¼–ç ä¸Šé™**ï¼ˆ>â€¯32768ã€>â€¯40960ï¼‰ | ç”¨æˆ·è°ƒç”¨ `hadamard_transform_*` è¶…å‡ºå®ç°æ”¯æŒèŒƒå›´ | `RuntimeCheck` æŠ›å‡ºå¼‚å¸¸ï¼Œå¯¼è‡´æ¨¡å‹æ¨ç†ä¸­æ–­ | ç»™å‡ºæ›´å‹å¥½çš„é”™è¯¯æç¤ºï¼›å¯ä»¥åœ¨ future æ·»åŠ  fallback åˆ° CPU å®ç°æˆ– `torch.linalg`ã€‚ |
| **å…±äº«å†…å­˜ä¸è¶³**ï¼ˆGPU SM å…±äº«å†…å­˜ä¸Šé™ä½äºæ‰€éœ€ï¼‰ | è€æ—§æ˜¾å¡ï¼ˆå¦‚ compute 5.xï¼‰ | `cudaFuncSetAttribute` ä¼šè¿”å›é”™è¯¯ï¼Œkernel launch å¤±è´¥ | åœ¨ `launch_kernel` å‰æ£€æµ‹ `cudaDeviceGetAttribute`ï¼Œè‹¥ä¸æ»¡è¶³åˆ™é™çº§åˆ°é€šç”¨å®ç°ï¼ˆé€’å½’ Hadamardï¼‰ã€‚ |
| **ä¸åŒ dtype æ”¯æŒä¸å®Œæ•´** | ä½¿ç”¨ `torch.float64` æˆ–è‡ªå®šä¹‰ dtype è°ƒç”¨ | `make_cpp_args` åªç”Ÿæˆ `float/half/bfloat16`ï¼Œä¼šå‡ºç° `TypeError` | é™åˆ¶

---

### feat: Support `mrope_section` with `rope_type: "yarn"` (#13313)
**SHA**: `92cdd39` | ğŸ”— [æŸ¥çœ‹æäº¤](https://github.com/sgl-project/sglang/commit/92cdd398cd599b65c42dfa274353e70e0ce668c4)

**ğŸ¯ å˜æ›´ç±»å‹**ï¼šåŠŸèƒ½å¢å¼º  
**âš¡ é‡è¦ç¨‹åº¦**ï¼šğŸ”´é«˜  
**ğŸ“‹ å˜æ›´æ‘˜è¦**ï¼šåœ¨ `rotary_embedding.py` ä¸­æ–°å¢ `YaRNScalingMRotaryEmbedding`ï¼Œå®ç°äº†åœ¨ Yarnâ€type RoPEï¼ˆ`rope_type="yarn"`ï¼‰ä¸‹å¯¹ MRoPEï¼ˆå¤šæ®µ Rotary Positional Embeddingï¼‰è¿›è¡Œä¸Šä¸‹æ–‡ç¼©æ”¾çš„æ”¯æŒã€‚`get_rope` å·¥å‚å‡½æ•°å¯¹ `rope_scaling` ä¸­çš„ `mrope_section` å‚æ•°è¿›è¡Œæ£€æµ‹å¹¶å®ä¾‹åŒ–å¯¹åº”çš„ç±»ï¼›æµ‹è¯•ç”¨ä¾‹åŒæ­¥è¦†ç›–äº†é»˜è®¤ä¸ Yarnâ€‘scaled ä¸¤ç§è·¯å¾„ï¼Œç¡®ä¿åŠŸèƒ½å®Œæ•´æ€§ã€‚  

**ğŸ¯ å½±å“èŒƒå›´**ï¼š  
- `python/sglang/srt/layers/rotary_embedding.py`ï¼ˆæ ¸å¿ƒ RoPE å®ç°ï¼‰  
- `python/sglang/srt/layers/rotary_embedding.py` ä¸­çš„ `get_rope` å·¥å‚å‡½æ•°  
- `test/registered/rotary/test_mrope.py`ï¼ˆå•å…ƒæµ‹è¯•ï¼‰  

**ğŸ” æŠ€æœ¯æ´å¯Ÿ**ï¼š  
- **æ¶æ„å½±å“**ï¼š  
  - å¼•å…¥ `YaRNScalingMRotaryEmbedding` ç»§æ‰¿è‡ªç°æœ‰çš„ `MRotaryEmbedding`ï¼Œå±äº **æ’ä»¶å¼æ‰©å±•**ï¼Œå¯¹å¤–ä¿æŒ `MRotaryEmbedding` æ¥å£ä¸å˜ã€‚  
  - `get_rope` ç°åœ¨ä¼šæ ¹æ® `rope_scaling` ä¸­æ˜¯å¦æºå¸¦ `mrope_section` åŠ¨æ€é€‰æ‹©å®ç°ç±»ï¼Œæå‡äº†é…ç½®é©±åŠ¨çš„çµæ´»æ€§ã€‚  
  - æ–°å¢çš„ `mrope_section`ã€`mrope_interleaved` å‚æ•°è¢«ç›´æ¥é€ä¼ åˆ°åŸºç±»æ„é€ å‡½æ•°ï¼Œä¿æŒå‘åå…¼å®¹ã€‚  

- **æ€§èƒ½å½±å“**ï¼š  
  - è®¡ç®— `inv_freq` æ—¶å¤šäº†ä¸€æ¬¡çº¿æ€§ ramp mask ä¸æ’å€¼/å¤–æ¨çš„ç»„åˆè¿ç®—ï¼Œå¼€é”€ä¸åŸ `YaRNScalingRotaryEmbedding` ç›¸å½“ï¼Œå± **O(NÂ·D)**ï¼ˆN ä¸ºä½ç½®é•¿åº¦ï¼ŒD ä¸º rotary_dimï¼‰å±‚çº§ã€‚  
  - `self.mscale` ä¹˜ä»¥ preâ€‘computed `cos/sin`ï¼Œä¼šæ¯”åŸå§‹å®ç°å¤šå ç”¨çº¦ `max_position_embeddings * scaling_factor` å¤§å°çš„ç¼“å­˜ï¼Œè‹¥ `scaling_factor` è¾ƒå¤§ï¼ˆå¦‚ 8xï¼‰å¯èƒ½å¯¼è‡´æ˜¾å­˜å ç”¨æ˜¾è‘—æå‡ã€‚  
  - å…¶å®ƒè·¯å¾„ï¼ˆæœªä½¿ç”¨ `mrope_section`ï¼‰ä¿æŒåŸæœ‰æ€§èƒ½ç‰¹å¾ï¼Œä¸ä¼šäº§ç”Ÿå›å½’ã€‚  

- **å®‰å…¨è€ƒè™‘**ï¼š  
  - ä»…æ¶‰åŠé…ç½®è§£æä¸æ•°å€¼è®¡ç®—ï¼Œæ— å¤–éƒ¨ I/Oã€æ–‡ä»¶æ“ä½œæˆ–ç½‘ç»œäº¤äº’ï¼Œå®‰å…¨é£é™©æä½ã€‚  
  - éœ€è¦ç¡®ä¿ `rope_scaling` å‚æ•°çš„æ¥æºå¯ä¿¡ï¼ˆå°¤å…¶æ˜¯ç”¨æˆ·è‡ªå®šä¹‰ JSONï¼‰ï¼Œé˜²æ­¢æ¶æ„æ„é€ å¼‚å¸¸çš„ `mrope_section`ï¼ˆå¦‚è´Ÿæ•°æˆ–è¶…å¤§åˆ—è¡¨ï¼‰å¯¼è‡´å¼‚å¸¸å†…å­˜åˆ†é…æˆ–æ‹’ç»æœåŠ¡ã€‚å¯åœ¨æ„é€ å‡½æ•°å‰æ·»åŠ ç®€æ˜“æ ¡éªŒã€‚  

**âš ï¸ æ½œåœ¨é£é™©**ï¼š  
1. **æ˜¾å­˜æ¿€å¢**ï¼šä½¿ç”¨å¤§ `scaling_factor` æ—¶ï¼Œ`max_position_embeddings * scaling_factor` å¯èƒ½è¿œè¶…æ¨¡å‹åŸå§‹è®¾å®šï¼Œå¯¼è‡´ OOMã€‚  
2. **é…ç½®ä¸åŒ¹é…**ï¼šå¦‚æœä¸šåŠ¡ä¾§åœ¨ `rope_scaling` ä¸­å£°æ˜ `mrope_section` ä½†æœªåŒæ­¥åˆ°æ¨¡å‹æƒé‡çš„å®é™…åˆ‡åˆ†æ–¹å¼ï¼Œå¯èƒ½å‡ºç°ä½ç½®ç¼–ç é”™ä½ï¼Œå¯¼è‡´ç”Ÿæˆè´¨é‡ä¸‹é™ã€‚  
3. **å‘åå…¼å®¹æµ‹è¯•é—æ¼**ï¼šæ–°å¢ `forward_native` æ›¿ä»£æ—§çš„ `_forward_native`ï¼Œè‹¥å…¶ä»–æ¨¡å—ä»è°ƒç”¨ç§æœ‰æ–¹æ³•ï¼Œå¯èƒ½äº§ç”Ÿå±æ€§é”™è¯¯ã€‚  
4. **åºåˆ—åŒ–/åŠ è½½**ï¼šæ¨¡å‹ä¿å­˜æ—¶ `rope_scaling` çš„æ–°å­—æ®µéœ€è¢«åºåˆ—åŒ–ï¼Œæ—§ç‰ˆæ¨¡å‹åŠ è½½æ—¶ä¸å­˜åœ¨è¯¥å­—æ®µä¼šèµ°é»˜è®¤è·¯å¾„ï¼Œå…¼å®¹æ€§å·²ä¿ç•™ï¼Œä½†æ–‡æ¡£æœªåŒæ­¥å¯èƒ½å¯¼è‡´ç”¨æˆ·è¯¯è§£ã€‚  

**ğŸ’¡ å…³æ³¨å»ºè®®**ï¼š  
- **æ˜¾å­˜ç›‘æ§**ï¼šåœ¨ä½¿ç”¨ Yarnâ€‘scaled MRoPE æ—¶å»ºè®®å¯¹ `scaling_factor` è®¾ç½®ä¸Šé™ï¼ˆå¦‚ â‰¤4ï¼‰ï¼Œå¹¶åœ¨å¯åŠ¨è„šæœ¬ä¸­æ‰“å°é¢„æœŸçš„ `cache` å¤§å°ä¾›è¿ç»´å‚è€ƒã€‚  
- **é…ç½®æ ¡éªŒ**ï¼šåœ¨ `YaRNScalingMRotaryEmbedding.__init__` ä¸­åŠ å…¥æ–­è¨€æˆ–å¼‚å¸¸æ£€æŸ¥ï¼Œç¡®ä¿ `mrope_section` ä¸ºåˆæ³•çš„æ­£æ•´æ•°åˆ—è¡¨ä¸”æ€»å’Œ â‰¤ `rotary_dim`ã€‚  
- **æ–‡æ¡£åŒæ­¥**ï¼šæ›´æ–°é…ç½®æ–‡æ¡£ï¼Œè¯´æ˜ `rope_type: "yarn"` æ—¶å¯åŒæ—¶ä½¿ç”¨ `mrope_section` ä¸ `mrope_interleaved`ï¼Œå¹¶ç»™å‡ºå…¸å‹å–å€¼ç¤ºä¾‹ã€‚  
- **å›å½’æµ‹è¯•**ï¼šåœ¨ CI ä¸­ä¿ç•™å¯¹æ—§ `YaRNScalingRotaryEmbedding`ï¼ˆä¸å« MRoPEï¼‰ä¸æ–°å®ç°çš„äº¤å‰å¯¹æ¯”ï¼Œé˜²æ­¢æ„å¤–è¡Œä¸ºæ¼‚ç§»ã€‚  
- **å…¼å®¹æ€§æç¤º**ï¼šå¯¹å¤–æä¾› `get_rope` åŒ…è£…å‡½æ•°çš„ä½¿ç”¨ç¤ºä¾‹ï¼Œæç¤ºç”¨æˆ·åœ¨å‡çº§ SGLang ç‰ˆæœ¬åæ£€æŸ¥ `rope_scaling` é…ç½®æ˜¯å¦éœ€è¦è¿½åŠ  `mrope_section`ã€‚  

---  

---

### Kernel: optimize decoding metadata in NSA multi-spec backend with fused kernels (#17554)
**SHA**: `34132d6` | ğŸ”— [æŸ¥çœ‹æäº¤](https://github.com/sgl-project/sglang/commit/34132d6da50e0867426962d3681b62a03b5624b9)

**ğŸ¯ å˜æ›´ç±»å‹**ï¼šåŠŸèƒ½å¢å¼º / æ€§èƒ½ä¼˜åŒ– / é‡æ„  
**âš¡ é‡è¦ç¨‹åº¦**ï¼šğŸ”´é«˜  

**ğŸ“‹ å˜æ›´æ‘˜è¦**  
- æ–°å¢ä¸¤å¥— JITâ€‘ç¼–è¯‘çš„ CUDA kernelï¼ˆå•åç«¯ `fused_metadata_copy`ã€å¤šåç«¯ `fused_metadata_copy_multi`ï¼‰ï¼Œå°†åŸæœ¬åˆ†æ•£çš„ *cache_seqlens / cu_seqlens_k / page_table / NSA å…ƒæ•°æ® / FlashMLA* ç­‰å¤åˆ¶æ“ä½œèåˆä¸ºä¸€æ¬¡ kernel launchã€‚  
- åœ¨ Python å±‚æä¾›å¯¹åº”çš„ JIT æ¥å£ä»¥åŠå®Œæ•´çš„å•å…ƒ/æ€§èƒ½æµ‹è¯•ã€‚  
- ä¸º NSA åç«¯åŠ å…¥ç¯å¢ƒå˜é‡ `SGLANG_USE_FUSED_METADATA_COPY`ï¼ˆé»˜è®¤å¼€å¯ï¼‰å’Œ `SGLANG_VERIFY_FUSED_METADATA_COPY`ï¼ˆé»˜è®¤å…³é—­ï¼‰ï¼Œæ”¯æŒ runtime å¼€å…³åŠç»“æœæ ¡éªŒã€‚  
- åœ¨ preâ€‘compute è¿‡ç¨‹ä¸­å¼ºåˆ¶ `contiguous()`ï¼Œä»¥æ»¡è¶³ kernel çº¿æ€§ç´¢å¼•çš„è¦æ±‚ã€‚  
- å¯¹ `init_forward_metadata_replay_cuda_graph_from_precomputed` ä¸ `init_forward_metadata_replay_cuda_graph` ä¸¤å¤§å…¥å£æ”¹å†™ï¼šä¼˜å…ˆè°ƒç”¨èåˆ kernelï¼›å½“åç«¯æ•°é‡ â‰¥ 3 æ—¶ä½¿ç”¨å¤šç›®æ ‡ kernelï¼Œä¸€æ¬¡æ€§å¤åˆ¶åˆ° 3 ä¸ª draft backendï¼Œæå¤§é™ä½ launch å¼€é”€ã€‚  
- æ–°å¢éªŒè¯æ¨¡å— `nsa_mtp_verification.py`ï¼Œåœ¨å¼€å¯ `SGLANG_VERIFY_FUSED_METADATA_COPY` æ—¶ä¸é€æ‹·è´çš„å‚è€ƒå®ç°ä½œä¸¥æ ¼æ¯”å¯¹ï¼Œè‹¥ä¸ä¸€è‡´æŠ›å¼‚å¸¸ã€‚

---

### ğŸ¯ å½±å“èŒƒå›´
| æ¨¡å—/ç»„ä»¶ | å—å½±å“æ–‡ä»¶ | å½±å“è¯´æ˜ |
|----------|------------|----------|
| **NSA åç«¯å…ƒæ•°æ®å¤åˆ¶** | `nsa_backend_mtp_precompute.py`ã€`nsa_backend.py` | å¤åˆ¶è·¯å¾„æ”¹ä¸º fused kernelï¼Œæ–°å¢ `contiguous()` ä»¥å…¼å®¹ kernel |
| **JIT ç¼–è¯‘ç³»ç»Ÿ** | `jit_kernel/csrc/elementwise/fused_metadata_copy.cuh`ã€`jit_kernel/fused_metadata_copy.py` | æ–°å¢ CUDA kernel æºæ–‡ä»¶ã€Python åŒ…è£…ã€æ¨¡æ¿åŒ–å‚æ•°ã€å¸¸é‡å†…å­˜ä¼ å‚ |
| **ç¯å¢ƒå˜é‡ç®¡ç†** | `srt/environ.py` | æ–°å¢ä¸¤æ¡å¼€å…³ |
| **éªŒè¯å·¥å…·** | `nsa_mtp_verification.py` | å¢åŠ  runtime éªŒè¯ |
| **æµ‹è¯•å¥—ä»¶** | `jit_kernel/tests/test_fused_metadata_copy.py` | è¿‘åƒè¡Œçš„åŠŸèƒ½ + æ€§èƒ½åŸºå‡† |
| **Speculative Decoding å…¥å£** | `nsa_backend.py`ï¼ˆ`init_forward_metadata_replay_cuda_graph`ï¼‰ | å½“ draft backend â‰¥3 æ—¶èµ° `fused_metadata_copy_multi_cuda`ï¼Œå¦åˆ™å›é€€åˆ°å¾ªç¯/å•æ‹·è´ |
| **ä¾èµ–** | TVMâ€‘FFIã€torch | æ— æ–°å¢å¤–éƒ¨ä¾èµ–ï¼Œä½†å¯¹ CUDA è®¡ç®—èƒ½åŠ›ä¸å¸¸é‡å†…å­˜å¤§å°æœ‰è¦æ±‚ |

---

## ğŸ” æŠ€æœ¯æ´å¯Ÿ

### 1. æ¶æ„å½±å“
| ç»´åº¦ | å½±å“ |
|------|------|
| **æ¨¡å—è€¦åˆ** | å°†åˆ†æ•£çš„æ‹·è´é€»è¾‘æŠ½è±¡ä¸ºç»Ÿä¸€ kernelï¼Œé™ä½ `nsa_backend` ä¸­å¯¹ tensorâ€‘copy ç»†èŠ‚çš„ç¡¬ç¼–ç ï¼Œå¢å¼ºå¯ç»´æŠ¤æ€§ã€‚ |
| **è°ƒç”¨é“¾** | åŸæœ¬åœ¨ Python ä¸­é€ä¸ª `.copy_()`ï¼Œç°åœ¨åªä¿ç•™ä¸€æ¬¡ JIT è°ƒç”¨ï¼›è‹¥ JIT ç¼–è¯‘å¤±è´¥ä¼šè‡ªåŠ¨å›é€€ï¼Œä¿æŒåŠŸèƒ½å®Œæ•´æ€§ã€‚ |
| **ç¼–è¯‘è·¯å¾„** | å¢åŠ ç¼–è¯‘æ—¶æ¨¡æ¿å®ä¾‹åŒ– (`HAS_REAL_PAGE_TABLE`ã€`HAS_FLASHMLA`ã€`FORWARD_MODE`)ï¼›JIT ç¼“å­˜æœºåˆ¶ç¡®ä¿é¦–æ¬¡è°ƒç”¨ç¼–è¯‘ä¸€æ¬¡ï¼Œåç»­ç›´æ¥åŠ è½½ã€‚ |
| **å¸¸é‡å†…å­˜** | å‚æ•°ç»“æ„é€šè¿‡ `__grid_constant__` ä¼ é€’ï¼Œåˆ©ç”¨ CUDA constant memory åŠ é€Ÿå‚æ•°è®¿é—®ï¼Œé€‚åˆ smallï¼ˆ<64KBï¼‰ç»“æ„ä½“ã€‚ |
| **å¯é…ç½®æ€§** | ä¸¤ä¸ªç¯å¢ƒå˜é‡æä¾›å¿«é€Ÿæ‰“å¼€/å…³é—­ fused åŠŸèƒ½ï¼Œä¾¿äºåœ¨å‡ºç°å¼‚å¸¸æ—¶å›é€€ï¼Œä¹Ÿä¸ºå†…éƒ¨ A/B æµ‹è¯•æä¾›å¼€å…³ã€‚ |
| **éªŒè¯è·¯å¾„** | `SGLANG_VERIFY_FUSED_METADATA_COPY` åœ¨ç”Ÿäº§ç¯å¢ƒå¯é€‰å¼€å¯ï¼Œæä¾›â€œç‚®å¼¹å¼â€é”™è¯¯æ£€æµ‹ï¼Œå¸®åŠ©å®šä½æ½œåœ¨çš„ kernel é€»è¾‘ç¼ºé™·ã€‚ |

### 2. æ€§èƒ½å½±å“
| åœºæ™¯ | æ—§å®ç° | æ–°å®ç° | é¢„æœŸæå‡ |
|------|--------|--------|----------|
| **å•åç«¯æ‹·è´ï¼ˆDECODE / TARGET_VERIFY / DRAFT_EXTENDï¼‰** | å¤šæ¬¡ kernel launchï¼ˆ3â€‘10 æ¬¡ï¼‰ï¼Œæ¯æ¬¡æ‹·è´ 1â€‘2â€¯KB â†’ launch å¼€é”€ 3â€‘10â€¯Âµs | å•æ¬¡ kernel launchï¼Œæ‰€æœ‰ tensor åˆå¹¶å¤åˆ¶ï¼Œä½¿ç”¨ `grid-stride loop` + `unroll` | **3â€‘10Ã—** å‡å°‘ launch å¼€é”€ï¼Œæ•´ä½“ latency é™è‡³åŸæ¥çš„ 0.2â€‘0.4â€¯Ã—ï¼ˆåœ¨ CUDA graph replay åœºæ™¯å°¤ä¸ºæ˜æ˜¾ï¼‰ |
| **Speculative Decoding å¤šåç«¯ï¼ˆâ‰¥3ï¼‰** | 3â€¯Ã—â€¯å•åç«¯æ‹·è´ â†’ 3â€¯Ã—â€¯launch + 3â€¯Ã—â€¯å…¨å±€å†…å­˜è¯»å– | `fused_metadata_copy_multi`ï¼šä¸€æ¬¡è¯»å– source â†’ ä¸‰æ¬¡å†™å…¥ destinationï¼Œ**ä»… 1 æ¬¡ launch + 1 æ¬¡å…¨å±€è¯»** | **â‰ˆ3Ã—** å‡å°‘ kernel launch + **æ›´å¥½** çš„ L2 ç¼“å­˜åˆ©ç”¨ç‡ï¼Œå®é™…æµ‹å¾— 2.5â€‘3.2Ã— åŠ é€Ÿï¼ˆæµ‹è¯•æ–‡ä»¶ä¸­å·²ç»æµ‹å¾—ï¼‰ |
| **CUDA Graph Replay** | æ¯æ¬¡ replay è§¦å‘å¤š kernel launch â†’ å›¾é‡æ”¾å¼€é”€æ”¾å¤§ | å• kernel å·²ç»åœ¨ graph ä¸­æ•è·ï¼Œgraph replay åªæ‰§è¡Œä¸€æ¬¡ kernelï¼Œæ˜¾è‘—æå‡ replay é€Ÿç‡ï¼ˆå®˜æ–¹å£°æ˜ 3â€‘10Ã—ï¼‰ |
| **å†…å­˜å ç”¨** | ä¸´æ—¶ `contiguous()` äº§ç”Ÿä¸€æ¬¡æ‹·è´ï¼ˆåœ¨ preâ€‘compute é˜¶æ®µï¼‰ | ä»éœ€ä¸€æ¬¡ `contiguous()`ï¼Œä½†ç›¸å¯¹äºå¤šæ¬¡æ‹·è´çš„ä¸´æ—¶ bufferï¼Œæ•´ä½“å†…å­˜å ç”¨æ›´ä½ï¼›å¤šåç«¯ kernel ä»ç„¶å…±äº«åŒä¸€ source bufferã€‚ |

### 3. å®‰å…¨/å¯é æ€§è€ƒè™‘
| é¡¹ç›® | è¯´æ˜ |
|------|------|
| **ç±»å‹æ ¡éªŒ** | `unwrap_data_ptr`ã€`unwrap_optional_data_ptr` åœ¨ C++ ç«¯å¼ºåˆ¶æ£€æŸ¥ `int32` dtypeï¼›Python æµ‹è¯•äº¦è¦†ç›–é”™è¯¯ dtype åœºæ™¯ï¼Œé˜²æ­¢éšå¼ç±»å‹é”™è¯¯å¯¼è‡´æ•°æ®é”™ä½ã€‚ |
| **å®¹é”™å›é€€** | è‹¥ JIT ç¼–è¯‘æˆ– kernel è°ƒç”¨æŠ›å¼‚å¸¸ï¼ˆç¼ºå°‘ç¼–è¯‘å™¨ã€GPU ä¸æ”¯æŒçš„ compute capabilityã€å¸¸é‡å†…å­˜è¶…é™ç­‰ï¼‰ï¼Œä»£ç æ•è·å¹¶å›é€€åˆ°åŸå§‹é€æ‹·è´å®ç°ï¼Œä¿è¯åŠŸèƒ½ä¸å› æ€§èƒ½ä¼˜åŒ–è€Œå¤±æ•ˆã€‚ |
| **ç¯å¢ƒå˜é‡å¤±æ•ˆ** | `SGLANG_USE_FUSED_METADATA_COPY` é»˜è®¤å¼€å¯ï¼›è‹¥æ˜¾å¼å…³é—­ï¼Œç³»ç»Ÿç›´æ¥èµ°æ—§å®ç°ï¼Œå…¼å®¹æ‰€æœ‰ç¡¬ä»¶ã€‚ |
| **éªŒè¯å¼€å…³** | `SGLANG_VERIFY_FUSED_METADATA_COPY` åªåœ¨è°ƒè¯•æˆ– CI ç¯å¢ƒå»ºè®®æ‰“å¼€ï¼Œç”Ÿäº§ç¯å¢ƒé»˜è®¤å…³é—­ï¼Œä»¥å…å› æç«¯è¾¹ç•Œï¼ˆå¦‚ stride ä¸åŒ¹é…ï¼‰äº§ç”Ÿè‡´å‘½å´©æºƒã€‚ |
| **å¹¶å‘å®‰å…¨** | æ‰€æœ‰ kernel å‚æ•°é€šè¿‡å€¼æ‹·è´ï¼ˆç»“æ„ä½“ï¼‰ä¼ é€’ï¼Œä¸æ¶‰åŠå…¨å±€çŠ¶æ€ï¼Œé€‚ç”¨äºå¤šçº¿ç¨‹/å¤šè¿›ç¨‹æ¨ç†æœåŠ¡ã€‚ |
| **èµ„æºæ³„éœ²** | JIT ç¼–è¯‘ç”Ÿæˆçš„ PTX/æ¨¡å—ä½¿ç”¨ TVMâ€‘FFI ç¼“å­˜ï¼Œä¸ä¼šå› å¤šæ¬¡è°ƒç”¨é‡å¤åŠ è½½ï¼Œ

---

### feat: add SGLANG_DISTRIBUTED_INIT_METHOD_OVERRIDE env var (#18743)
**SHA**: `ab0fb24` | ğŸ”— [æŸ¥çœ‹æäº¤](https://github.com/sgl-project/sglang/commit/ab0fb248fdd170b527fde68b61a6f36dbf81f688)

**ğŸ¯ å˜æ›´ç±»å‹**ï¼šåŠŸèƒ½å¢å¼º  

**âš¡ é‡è¦ç¨‹åº¦**ï¼šğŸ”´é«˜  

**ğŸ“‹ å˜æ›´æ‘˜è¦**ï¼šåœ¨ `python/sglang/srt/environ.py` ä¸­æ–°å¢ç¯å¢ƒå˜é‡ `SGLANG_DISTRIBUTED_INIT_METHOD_OVERRIDE`ï¼Œç”¨äºæ˜¾å¼è¦†ç›– `torch.distributed.init_process_group` çš„åˆå§‹åŒ–æ–¹å¼ï¼›åœ¨ `model_runner.py` çš„åˆ†å¸ƒå¼åˆå§‹åŒ–é€»è¾‘ä¸­åŠ å…¥å¯¹è¯¥å˜é‡çš„è¯»å–å’Œä¼˜å…ˆä½¿ç”¨ï¼Œä½¿å¾—å¤–éƒ¨ orchestratorï¼ˆå¦‚ trainpiï¼‰å¯é€šè¿‡è®¾ç½®ä¸º `env://` æ¥ä½¿ç”¨åŸºäº `MASTER_ADDR/MASTER_PORT` çš„ TCPStoreï¼Œé¿å…åŒä¸»æœºå¤šå®ä¾‹é—´çš„ç«¯å£å†²çªã€‚  

**ğŸ¯ å½±å“èŒƒå›´**ï¼š  
- `sglang.srt.environ`ï¼ˆç¯å¢ƒå˜é‡ç®¡ç†ï¼‰  
- `sglang.srt.model_executor.model_runner`ï¼ˆåˆ†å¸ƒå¼å¯åŠ¨è·¯å¾„ï¼‰  
- ä¾èµ– `torch.distributed` çš„æ‰€æœ‰åˆ†å¸ƒå¼æ¨ç†/è®­ç»ƒå…¥å£  

**ğŸ” æŠ€æœ¯æ´å¯Ÿ**ï¼š  
- **æ¶æ„å½±å“**ï¼š  
  - å¼•å…¥äº†å¯æ’æ‹”çš„åˆ†å¸ƒå¼åˆå§‹åŒ–å…¥å£ï¼Œæå‡äº†ç³»ç»Ÿå¯¹ç¬¬ä¸‰æ–¹è°ƒåº¦å¹³å°çš„é€‚é…èƒ½åŠ›ã€‚  
  - ä»£ç è·¯å¾„ä¿æŒå‘åå…¼å®¹ï¼šè‹¥æœªè®¾ç½®è¯¥ env æˆ–ä¸ºç©ºï¼Œä»èµ°åŸæœ‰ `dist_init_addr` / æœ¬æœºç«¯å£é€»è¾‘ã€‚  
  - å¢åŠ äº†å¯¹ `torch.distributed` åˆå§‹åŒ–æ–¹å¼çš„æŠ½è±¡å±‚ï¼Œæœªæ¥å¯è¿›ä¸€æ­¥æ”¯æŒ `gloo://`ã€`nccl://` ç­‰è‡ªå®šä¹‰æ–¹å¼ã€‚  

- **æ€§èƒ½å½±å“**ï¼š  
  - å¯¹æ­£å¸¸æƒ…å†µä¸‹çš„å¯åŠ¨å¼€é”€å‡ ä¹ä¸º 0ï¼ˆä»…å¤šè¯»å–ä¸€ä¸ª envï¼‰ï¼Œä½†ä½¿ç”¨ `env://` æ—¶å¯çœå»å†…éƒ¨ TCPStore çš„åˆ›å»ºè¿‡ç¨‹ï¼Œå¯èƒ½ç•¥å¾®åŠ å¿«å¤šå®ä¾‹åŒæœºå¯åŠ¨é€Ÿåº¦ã€‚  
  - è‹¥å¤–éƒ¨æä¾›çš„ `MASTER_ADDR/MASTER_PORT` é…ç½®ä¸ä½³ï¼Œç½‘ç»œå»¶è¿Ÿæˆ–ä¸å¯é çš„ Store å¯èƒ½å¯¼è‡´åˆ†å¸ƒå¼åŒæ­¥å¼€é”€å¢åŠ ã€‚  

- **å®‰å…¨è€ƒè™‘**ï¼š  
  - ç¯å¢ƒå˜é‡å€¼æœªåšæ ¼å¼æ ¡éªŒï¼Œè‹¥è¢«æ¶æ„è®¾ç½®ä¸ºä»»æ„å­—ç¬¦ä¸²ï¼Œ`torch.distributed` ä¼šå°è¯•è§£æå¹¶å¯èƒ½æŠ›å¼‚å¸¸æˆ–å¡ä½ï¼Œå¯¼è‡´æœåŠ¡ä¸å¯ç”¨ã€‚  
  - ä½¿ç”¨ `env://` ä¾èµ–å¤–éƒ¨åˆ›å»ºçš„ TCPStoreï¼Œè‹¥è¯¥ Store æ²¡æœ‰æ°å½“çš„è®¿é—®æ§åˆ¶ï¼Œå¯èƒ½å¯¼è‡´æœªæˆæƒèŠ‚ç‚¹åŠ å…¥é›†ç¾¤ï¼Œå‡ºç°ä¿¡æ¯æ³„éœ²æˆ–æ¨¡å‹åŠ«æŒé£é™©ã€‚  

**âš ï¸ æ½œåœ¨é£é™©**ï¼š  
1. **é…ç½®è¯¯ç”¨**ï¼šç”¨æˆ·è¯¯å°†è¯¥å˜é‡è®¾ä¸ºéæ³•å€¼ï¼ˆä¾‹å¦‚ç©ºæ ¼ã€éæ³• URLï¼‰ï¼Œä¼šå¯¼è‡´ `torch.distributed.init_process_group` æŠ›å¼‚å¸¸ï¼Œæ•´ä¸ªæœåŠ¡å¯åŠ¨å¤±è´¥ã€‚  
2. **ç¯å¢ƒå†²çª**ï¼šåœ¨åŒä¸€æœºå™¨ä¸ŠåŒæ—¶ä½¿ç”¨ `dist_init_addr` ä¸ `SGLANG_DISTRIBUTED_INIT_METHOD_OVERRIDE`ï¼Œä¼˜å…ˆçº§é€»è¾‘å¯èƒ½å¯¼è‡´é¢„æœŸä¹‹å¤–çš„åˆå§‹åŒ–æ–¹å¼ï¼Œå¢åŠ æ’éšœéš¾åº¦ã€‚  
3. **å®‰å…¨éšæ‚£**ï¼šå¤–éƒ¨ TCPStore è‹¥æœªåšèº«ä»½éªŒè¯æˆ–ç½‘ç»œéš”ç¦»ï¼Œå¯èƒ½è¢«æœªæˆæƒèŠ‚ç‚¹åŠ å…¥ï¼Œä»è€Œå¯¼è‡´é›†ä½“é€šä¿¡è¢«çªƒå¬æˆ–ç¯¡æ”¹ã€‚  
4. **å…¼å®¹æ€§**ï¼šéƒ¨åˆ†æ—§ç‰ˆ PyTorch å¯èƒ½å¯¹ `env://` çš„å®ç°æœ‰å·®å¼‚ï¼Œå¯¼è‡´åœ¨ç‰¹å®šç‰ˆæœ¬ä¸Šå‡ºç°ä¸å…¼å®¹é”™è¯¯ã€‚  

**ğŸ’¡ å…³æ³¨å»ºè®®**ï¼š  
- **æ–‡æ¡£ä¸ç¤ºä¾‹**ï¼šåœ¨é¡¹ç›® README æˆ–éƒ¨ç½²æ‰‹å†Œä¸­è¡¥å…… `SGLANG_DISTRIBUTED_INIT_METHOD_OVERRIDE` çš„ä½¿ç”¨è¯´æ˜ã€å–å€¼èŒƒå›´ï¼ˆç›®å‰æ”¯æŒ `env://`ï¼‰ä»¥åŠä¸ `dist_init_addr` çš„ä¼˜å…ˆçº§è¯´æ˜ã€‚  
- **è¾“å…¥æ ¡éªŒ**ï¼šåœ¨ `environ.py` æˆ– `model_runner.py` ä¸­åŠ å…¥å¯¹è¯¥ env çš„åŸºæœ¬æ ¼å¼æ ¡éªŒï¼ˆä¾‹å¦‚ä»…æ¥å— `env://`ï¼‰ï¼Œå¹¶åœ¨éæ³•å€¼æ—¶ç»™å‡ºæ˜ç¡®é”™è¯¯æç¤ºã€‚  
- **å®‰å…¨åŠ å›º**ï¼šæé†’ä½¿ç”¨ `env://` æ—¶ï¼Œéœ€è‡ªè¡Œç¡®ä¿ `MASTER_ADDR/MASTER_PORT` å¯¹åº”çš„ TCPStore å·²ç»åšå¥½ç½‘ç»œéš”ç¦»å’Œè®¿é—®æ§åˆ¶ï¼Œæˆ–åœ¨ä»£ç å±‚é¢æä¾›å¯é€‰çš„ Store éªŒè¯é’©å­ã€‚  
- **å›é€€æœºåˆ¶**ï¼šè‹¥ `torch.distributed.init_process_group` å›  `env://` åˆå§‹åŒ–å¤±è´¥ï¼Œå¯è€ƒè™‘æ•è·å¼‚å¸¸å¹¶å›é€€åˆ°åŸæœ‰ `tcp://` æ–¹å¼ï¼Œä»¥æå‡å®¹é”™æ€§ã€‚  
- **æµ‹è¯•è¦†ç›–**ï¼šæ–°å¢å•å…ƒ/é›†æˆæµ‹è¯•ï¼Œåˆ†åˆ«éªŒè¯ï¼šâ‘  æœªè®¾ç½® env æ—¶èµ°åŸè·¯å¾„ï¼›â‘¡ æ­£ç¡®è®¾ç½®ä¸º `env://` æ—¶æˆåŠŸåˆå§‹åŒ–ï¼›â‘¢ é”™è¯¯å€¼å¯¼è‡´å¼‚å¸¸å¹¶æä¾›å‹å¥½æ—¥å¿—ã€‚  
- **ç‰ˆæœ¬å…¼å®¹è¯´æ˜**ï¼šåœ¨å‘å¸ƒè¯´æ˜ä¸­æ ‡æ˜è¯¥ç‰¹æ€§éœ€è¦çš„æœ€ä½ PyTorch ç‰ˆæœ¬ï¼ˆå¦‚ 1.11+ï¼‰ï¼Œå¹¶åœ¨ CI ä¸­åŠ å…¥ç›¸åº”çš„å…¼å®¹æ€§æ£€æµ‹ã€‚  

é€šè¿‡ä»¥ä¸Šæªæ–½ï¼Œå¯åœ¨æå‡åˆ†å¸ƒå¼éƒ¨ç½²çµæ´»æ€§çš„åŒæ—¶ï¼Œé™ä½é…ç½®é”™è¯¯å’Œå®‰å…¨é£é™©ï¼Œç¡®ä¿é¡¹ç›®åœ¨å¤šç§è°ƒåº¦ç¯å¢ƒä¸‹çš„å¯é è¿è¡Œã€‚

---

#### ğŸŸ¡ ä¸­é‡è¦åº¦å˜æ›´ (12)

### Enable SGLANG_ENABLE_SPEC_V2 for nightly speculative decoding tests (#18719)
**SHA**: `ae95869` | ğŸ”— [æŸ¥çœ‹æäº¤](https://github.com/sgl-project/sglang/commit/ae958692927509723ada6e33f368bdba148f1654)

**ğŸ¯ å˜æ›´ç±»å‹**ï¼šåŠŸèƒ½å¢å¼ºï¼ˆä¸º nightly è§„çº¦è§£ç æµ‹è¯•åŠ å…¥ `SGLANG_ENABLE_SPEC_V2` ç¯å¢ƒå˜é‡ï¼‰  
**âš¡ é‡è¦ç¨‹åº¦**ï¼šğŸŸ¡ ä¸­  
**ğŸ“‹ å˜æ›´æ‘˜è¦**ï¼šåœ¨æ¨¡å‹å¯åŠ¨ã€åŸºå‡†å’Œæ€§èƒ½æµ‹è¯•çš„å°è£…å‡½æ•°ä¸­æ–°å¢ `env` å‚æ•°ï¼Œä½¿è°ƒç”¨æ–¹å¯ä»¥å‘å­è¿›ç¨‹æ³¨å…¥è‡ªå®šä¹‰ç¯å¢ƒå˜é‡ï¼›æ‰€æœ‰ 8â€‘GPU ç›¸å…³çš„é›†æˆæµ‹è¯•å‡åœ¨ `env` ä¸­è®¾ç½® `SGLANG_ENABLE_SPEC_V2=1`ã€‚åŒæ—¶åœ¨ `popen_launch_server` ä¸­å®ç°äº†å¯¹å¤–éƒ¨ env ä¸å½“å‰è¿›ç¨‹ env çš„åˆå¹¶ã€‚  

**ğŸ¯ å½±å“èŒƒå›´**ï¼š  
- `python/sglang/test/*_runner.py`ï¼ˆå¯åŠ¨æœåŠ¡ã€è·‘ benchmarkã€è·‘æ€§èƒ½ï¼‰  
- `python/sglang/test/test_utils.py`ï¼ˆ`popen_launch_server` ç¯å¢ƒåˆå¹¶ï¼‰  
- 8â€‘GPU æµ‹è¯•å¥—ä»¶ï¼ˆDeepSeekã€GLMã€Mistralã€Qwen ç­‰ï¼‰  

**ğŸ’¡ å…³æ³¨å»ºè®®**  
1. **ç¯å¢ƒå˜é‡åˆå¹¶é€»è¾‘**ï¼š`test_utils.popen_launch_server` ç°åœ¨å…ˆå¤åˆ¶ `os.environ` å† `update(env)`ï¼Œç¡®ä¿ä¸ä¼šå› ç¼ºå¤±ç³»ç»Ÿå˜é‡å¯¼è‡´å­è¿›ç¨‹å¯åŠ¨å¤±è´¥ã€‚å»ºè®®åœ¨å‡½æ•°æ–‡æ¡£ä¸­æ˜ç¡®è¯´æ˜ `env` ä¸º â€œå¢é‡â€ è€Œéå®Œæ•´è¦†ç›–ã€‚  
2. **å‘åå…¼å®¹**ï¼šæ–°å¢ `env` å‚æ•°é»˜è®¤ `None`ï¼Œå·²æœ‰è°ƒç”¨ä¿æŒä¸å˜ï¼›ä½†è‹¥å¤–éƒ¨æœ‰æ˜¾å¼ `env={}` çš„è°ƒç”¨ï¼Œä¼šäº§ç”Ÿä¸ä¹‹å‰è¡Œä¸ºä¸€è‡´çš„å®Œæ•´æ‹·è´ï¼Œä»éœ€æµ‹è¯•ã€‚  
3. **å®‰å…¨æ€§**ï¼šé€šè¿‡ç¯å¢ƒå˜é‡æ‰“å¼€ speculative decodingï¼Œå¯èƒ½å½±å“æ€§èƒ½æˆ–äº§ç”Ÿä¸å¯é¢„æœŸçš„è¡Œä¸ºã€‚å»ºè®®åœ¨ CI ä¸­ä¿ç•™å¯¹ `SGLANG_ENABLE_SPEC_V2` çš„æ˜¾å¼æ§åˆ¶ï¼Œé¿å…åœ¨ç”Ÿäº§æµ‹è¯•è¯¯æ‰“å¼€ã€‚  
4. **æµ‹è¯•è¦†ç›–**ï¼šå·²åœ¨å¤šæ¨¡å‹çš„ nightly æµ‹è¯•ä¸­åŠ å…¥ `env`ï¼Œè¯·ç¡®è®¤å…¶å®ƒæœªæ˜¾å¼å£°æ˜ `env` çš„æµ‹è¯•ä»èƒ½åœ¨æ™®é€š CI ç¯å¢ƒä¸‹é€šè¿‡ã€‚  
5. **æ–‡æ¡£æ›´æ–°**ï¼šåœ¨ README/benchmark guide ä¸­è¡¥å…… â€œå¦‚ä½•ä½¿ç”¨ `env` å‚æ•°å¼€å¯ SpecV2â€ã€‚  

æ€»ä½“æ¥çœ‹ï¼Œæ”¹åŠ¨é›†ä¸­ä¸”é£é™©æœ‰é™ï¼Œä¸»è¦æå‡äº† nightly æµ‹è¯•å¯¹æ–°ç‰¹æ€§çš„è¦†ç›–åº¦ã€‚å»ºè®®åœ¨åˆå¹¶å‰è·‘ä¸€éå…¨å¥— CIï¼ˆåŒ…æ‹¬ä¸ä½¿ç”¨ `env` çš„è€æµ‹è¯•ï¼‰ä»¥ç¡®è®¤æ²¡æœ‰éšè—çš„ç¯å¢ƒè¦†ç›–é—®é¢˜ã€‚

---

### Add ci test for ring model (#18829)
**SHA**: `f51e9d9` | ğŸ”— [æŸ¥çœ‹æäº¤](https://github.com/sgl-project/sglang/commit/f51e9d9ca1a6966c88e93974b2749893ad1c8a39)

**ğŸ¯ å˜æ›´ç±»å‹**ï¼šåŠŸèƒ½å¢å¼º / CIâ€¯æ‰©å±•  
**âš¡ é‡è¦ç¨‹åº¦**ï¼šğŸŸ¡ ä¸­  
**ğŸ“‹ å˜æ›´æ‘˜è¦**ï¼šåœ¨ `accuracy_test_runner.py` ä¸­ä¸ºè¯„ä¼°å…¥å£æ–°å¢ `top_p` å‚æ•°ï¼Œå¹¶åœ¨è°ƒç”¨ `simple_eval` æ—¶ä¼ é€’è¯¥å€¼ï¼›ä¸º GSM8K æ•°æ®é›†åœ¨å­˜åœ¨æ‰©å±•å‚æ•°æ—¶åˆ‡æ¢ä¸º `simple_eval`ï¼Œä¿ç•™åŸæœ‰ `few_shot_eval` çš„å…¼å®¹è¡Œä¸ºã€‚æ–°å¢ CI ç”¨ä¾‹ `test_ring_2_5_1t.py`ï¼Œåœ¨ 8â€‘GPU ç¯å¢ƒä¸‹è·‘ Ringâ€‘2.5â€‘1T çš„ GSM8K ç²¾åº¦æµ‹è¯•ï¼ˆtemperature=1.2ã€top_p=0.8ã€200 æ¡æ ·ä¾‹ï¼‰ã€‚  

**ğŸ¯ å½±å“èŒƒå›´**  
- `python/sglang/test/accuracy_test_runner.py`ï¼ˆå‚æ•°ç»“æ„ã€è¿è¡Œåˆ†æ”¯ï¼‰  
- CI æ³¨å†Œä¸è¿è¡Œæ¡†æ¶ (`sglang.test.ci.ci_register`, `run_combined_tests`)  
- æ–°å¢çš„ CI æµ‹è¯•è„šæœ¬åŠå…¶ä¾èµ–çš„æ¨¡å‹å¯åŠ¨é…ç½®  

**ğŸ’¡ å…³æ³¨å»ºè®®**  
1. **å‚æ•°ä¼ é€’å®Œæ•´æ€§**ï¼šç¡®è®¤ `run_eval.py`ï¼ˆsimple_evalï¼‰å·²æ–°å¢ `top_p` CLI é€‰é¡¹å¹¶åœ¨ `SimpleEvalArgs` ä¸­å£°æ˜ï¼›å¦åˆ™ä¼šå¯¼è‡´è¿è¡Œæ—¶å‚æ•°æœªç”Ÿæ•ˆæˆ–æŠ¥é”™ã€‚  
2. **å‘åå…¼å®¹**ï¼šå½“å‰é€»è¾‘åœ¨ GSM8K ä¸”æ— æ‰©å±•å‚æ•°æ—¶ä»èµ° `few_shot_eval`ï¼Œè¿™ä¿æŒäº†å†å²åŸºå‡†ã€‚ä½†è‹¥åç»­åœ¨ `few_shot_eval` ä¸­åŠ å…¥ `top_p`ï¼Œéœ€è¦åŒæ­¥æ›´æ–°åˆ‡æ¢æ¡ä»¶ã€‚å»ºè®®å°†æ­¤åˆ¤æ–­æŠ½è±¡ä¸ºå‡½æ•°å¹¶åŠ å•å…ƒæµ‹è¯•ã€‚  
3. **CI ç¨³å®šæ€§**ï¼š8â€‘GPU H200 èµ„æºç¨€ç¼ºï¼Œå»ºè®®åœ¨ CI é…ç½®ä¸­åŠ å…¥è¶…æ—¶é‡è¯•æˆ–èµ„æºå ç”¨æ£€æµ‹ï¼Œé˜²æ­¢å› æ¨¡å‹åŠ è½½å¤±è´¥å¯¼è‡´æ•´ä½“ CI å¡æ­»ã€‚  
4. **æ–‡æ¡£æ›´æ–°**ï¼šREADME/å‚æ•°è¯´æ˜éœ€è¡¥å…… `top_p` çš„å«ä¹‰ã€å–å€¼èŒƒå›´ä»¥åŠå¯¹ä¸åŒè¯„ä¼°åç«¯çš„å…¼å®¹æ€§ã€‚  
5. **æ€§èƒ½è¯„ä¼°**ï¼š`temperature=1.2`ã€`top_p=0.8` å¯èƒ½å¯¼è‡´ç”Ÿæˆé•¿åº¦æ³¢åŠ¨ï¼Œå»ºè®®åœ¨ CI ä¸­è®°å½•è€—æ—¶ç»Ÿè®¡ï¼Œé˜²æ­¢å› é‡‡æ ·ç­–ç•¥å¯¼è‡´è¯„ä¼°ä¸ç¡®å®šæ€§ã€‚  

æ€»ä½“è€Œè¨€ï¼Œæ­¤æ¬¡æ”¹åŠ¨ä¸ºæ¨¡å‹è¯„ä¼°æä¾›äº†æ›´ç»†ç²’åº¦çš„é‡‡æ ·æ§åˆ¶ï¼Œå¹¶é€šè¿‡ä¸“é—¨çš„ Ringâ€‘2.5â€‘1T CI ç”¨ä¾‹æå‡è¦†ç›–ç‡ã€‚åªè¦ç¡®ä¿åç«¯å‚æ•°åŒæ­¥å¹¶å¯¹ CI èµ„æºè¿›è¡Œåˆç†è°ƒåº¦ï¼Œé£é™©å¯æ§ã€‚

---

### [VLM][LLM] Optimize fused_moe triton kernel tma (#18782)
**SHA**: `fa0ef6e` | ğŸ”— [æŸ¥çœ‹æäº¤](https://github.com/sgl-project/sglang/commit/fa0ef6e4f7f7c8937e498d8db6fa8599405d2a18)

**ğŸ¯ å˜æ›´ç±»å‹**ï¼šæ€§èƒ½ä¼˜åŒ–ï¼ˆTMAâ€¯Descriptorâ€¯ç¼“å­˜ & å…¨å±€ allocatorï¼‰  
**âš¡ é‡è¦ç¨‹åº¦**ï¼šğŸŸ¡ ä¸­  
**ğŸ“‹ å˜æ›´æ‘˜è¦**ï¼š  
- ä¸º Tritonâ€¯TMAï¼ˆTensorâ€‘Memoryâ€‘Accessï¼‰å¼•å…¥ä¸€æ¬¡æ€§å…¨å±€ allocatorï¼Œé¿å…åœ¨æ¯æ¬¡ `invoke_fused_moe_kernel` è°ƒç”¨æ—¶é‡å¤ `triton.set_allocator`ï¼Œé™ä½ CPUâ€‘GPU åŒæ­¥å¼€é”€ã€‚  
- ä¸ºæƒé‡çŸ©é˜µ **B** å¢åŠ  LRUâ€‘Cacheï¼ˆå®¹é‡ 64ï¼‰çš„ `TensorDescriptor` ç¼“å­˜ï¼Œé‡å¤ä½¿ç”¨åŒä¸€å¼ é‡çš„æè¿°ç¬¦ï¼Œæ˜¾è‘—å‡å°‘åœ¨é«˜é¢‘ MoE è°ƒç”¨ä¸­çš„ descriptorâ€¯åˆ›å»ºæˆæœ¬ã€‚  

**ğŸ¯ å½±å“èŒƒå›´**ï¼š  
- `python/sglang/srt/layers/moe/fused_moe_triton/fused_moe_triton_kernels.py`ï¼ˆæ ¸å¿ƒ MoEâ€¯kernel è°ƒåº¦å±‚ï¼‰ã€‚  
- å—å½±å“çš„ä¸Šå±‚æ¨¡å—ï¼š`sglang.srt.layers.moe`ã€`sglang.inference` ä¸­æ‰€æœ‰è°ƒç”¨ `invoke_fused_moe_kernel` çš„è·¯å¾„ã€‚  

**ğŸ’¡ å…³æ³¨å»ºè®®**  

1. **å…¨å±€ allocator çš„å¹‚ç­‰æ€§**  
   - å½“å‰å®ç°é€šè¿‡ `_TMA_ALLOCATOR_SET` æ ‡è®°ä¸€æ¬¡æ€§è®¾ç½®ï¼Œé€‚ç”¨äºå•è¿›ç¨‹åœºæ™¯ã€‚è‹¥åœ¨å¤šè¿›ç¨‹ï¼ˆå¦‚ `torch.multiprocessing`ã€Rayï¼‰æˆ– forkâ€‘åå†æ¬¡åŠ è½½æ¨¡å—ï¼Œå¯èƒ½å‡ºç° â€œallocator å·²è¢«å…¶ä»–è¿›ç¨‹è®¾ç½®â€ çš„å†²çªã€‚å»ºè®®åœ¨è¿›ç¨‹é€€å‡ºæˆ– fork å‰é‡ç½®æ ‡è®°ï¼Œæˆ–æ”¹ä¸º `try/except` æ•è·å·²è®¾ç½®çš„å¼‚å¸¸ã€‚  

2. **ç¼“å­˜ä¸€è‡´æ€§**  
   - ç¼“å­˜é”®ä½¿ç”¨ `data_ptrã€shapeã€strideã€dtypeã€block_nã€block_k`ï¼Œåœ¨å¼ é‡è¢« **inâ€‘place** é‡åšï¼ˆä¾‹å¦‚ `B = B.transpose(0,1)`ï¼‰æ—¶ä¼šäº§ç”Ÿæ–° `data_ptr`ï¼Œç¼“å­˜è‡ªåŠ¨å¤±æ•ˆï¼Œç¬¦åˆé¢„æœŸã€‚  
   - è‹¥é¡¹ç›®åœ¨è¿è¡Œæ—¶å¯¹ **B** é‡‡ç”¨ **æ¢¯åº¦æ›´æ–°**ï¼ˆè™½ç„¶å½“å‰ MoE é‡‡ç”¨å¸¸é‡æƒé‡ï¼‰ï¼Œåˆ™ç¼“å­˜çš„ descriptor ä»æŒ‡å‘æ—§çš„ç‰©ç†å¸ƒå±€ï¼Œéœ€åœ¨å‚æ•°æ›´æ–°åæ‰‹åŠ¨æ¸…é™¤æˆ–é‡å»ºç¼“å­˜ã€‚å¯ä»¥åœ¨ `optimizer.step()` åè°ƒç”¨ `_B_DESC_CACHE.clear()` åšä¸€æ¬¡å®‰å…¨æ¸…ç†ã€‚  

3. **å†…å­˜æ³„æ¼ä¸ä¸Šé™**  
   - LRU å®¹é‡è®¾ä¸º 64ï¼Œç¬¦åˆå¤§å¤šæ•° GPUâ€¯æ¨¡å‹çš„ weightâ€‘matrix æ•°é‡ï¼ˆexpertâ€¯æ•°â€¯â‰¤â€¯64ï¼‰ã€‚è‹¥ç”¨æˆ·è‡ªå®šä¹‰çš„ä¸“å®¶æ•°é‡è¿œè¶…æ­¤å€¼ï¼Œç¼“å­˜é¢‘ç¹æ·˜æ±°ä¼šå¸¦æ¥é¢å¤–åˆ›å»ºå¼€é”€ã€‚å»ºè®®å°†ä¸Šé™æš´éœ²ä¸ºç¯å¢ƒå˜é‡æˆ–æ¨¡å—å‚æ•°ï¼Œä»¥ä¾¿åœ¨æç«¯é…ç½®ä¸‹è°ƒä¼˜ã€‚  

4. **å…¼å®¹æ€§æµ‹è¯•**  
   - è¯¥æ”¹åŠ¨ä»…åœ¨ CUDA ç¯å¢ƒä¸‹ç”Ÿæ•ˆã€‚è¯·ç¡®ä¿ CI åŒ…å« **CUDAâ€‘only** ä¸ **CPUâ€‘fallback**ï¼ˆ`torch_device="cpu"`ï¼‰ä¸¤å¥—æµ‹è¯•ï¼Œé˜²æ­¢åœ¨æ—  CUDA çš„æœºå™¨ä¸Šå‡ºç° `triton` æœªå¯¼å…¥å¯¼è‡´çš„ `NameError`ã€‚  
   - å¯¹æ¯”å‰ååŸºå‡†ï¼ˆ`torch.utils.benchmark`ï¼‰ï¼Œå…³æ³¨ **kernel launch latency**ã€**overall MoE throughput** ä¸ **GPU memory usage**ï¼ˆç¼“å­˜æœ¬èº«å ç”¨æå°ï¼Œä½† descriptor å¯¹åº”çš„å†…éƒ¨å¯¹è±¡å¯èƒ½æŒæœ‰é¢å¤–ä¸´æ—¶ bufferï¼‰ã€‚  

5. **æ–‡æ¡£ä¸ä½¿ç”¨æç¤º**  
   - åœ¨ `README` æˆ– `docs/performance.md` ä¸­è¡¥å…… â€œä¸€æ¬¡æ€§è°ƒç”¨ `import sglang.srt.layers.moe.fused_moe_triton` å³å¯æ¿€æ´» TMA ä¼˜åŒ–â€ï¼Œå¹¶è¯´æ˜åœ¨å¤šè¿›ç¨‹/å­è¿›ç¨‹ç¯å¢ƒä¸‹çš„æ³¨æ„äº‹é¡¹ã€‚  

æ€»ä½“æ¥çœ‹ï¼Œæ­¤æ¬¡æäº¤é€šè¿‡ **ä¸€æ¬¡æ€§ allocator** ä¸ **TensorDescriptor LRU ç¼“å­˜** ä¸¤ä¸ªæ‰‹æ®µï¼Œæ˜¾è‘—é™ä½äº†é«˜é¢‘ MoE è°ƒç”¨çš„ CPUâ€‘GPU åŒæ­¥å’Œ descriptor æ„é€ æˆæœ¬ï¼Œé¢„è®¡åœ¨ 8â€‘16â€¯expert åœºæ™¯ä¸‹å¯æå‡ 10%â€‘20% ååã€‚åªè¦å…³æ³¨ä¸Šè¿°å¤šè¿›ç¨‹å…¼å®¹ä¸ç¼“å­˜å¤±æ•ˆé—®é¢˜ï¼Œå³å¯å®‰å…¨åˆå…¥ä¸»çº¿ã€‚

---

### Fix/partial gen from waiting queue miss metadata (#17610)
**SHA**: `f6c18c3` | ğŸ”— [æŸ¥çœ‹æäº¤](https://github.com/sgl-project/sglang/commit/f6c18c3a85a9f9e7b388e849bedced97896522f1)

**ğŸ¯ å˜æ›´ç±»å‹**ï¼šBug ä¿®å¤ / åŠŸèƒ½å¢å¼º  
**âš¡ é‡è¦ç¨‹åº¦**ï¼šğŸŸ¡ ä¸­  

**ğŸ“‹ å˜æ›´æ‘˜è¦**  
1. åœ¨ `TokenizerManager._handle_abort_req` ä¸­è®°å½•è¯·æ±‚ç»“æŸæ—¶é—´ `state.finished_time`ï¼Œå¹¶åœ¨è¿”å›çš„ `meta_info` ä¸­è¡¥å…… `weight_version`ã€`e2e_latency`ï¼ˆä»åˆ›å»ºåˆ°ç»“æŸçš„è€—æ—¶ï¼‰ã€‚  
2. æµ‹è¯• `test_abort_all_with_retraction` ç›¸åº”è°ƒæ•´ï¼šå¼€å¯ `return_logprob` ä¸ `top_logprobs_num`ï¼Œå¹¶æ ¡éªŒ `meta_info` ä¸­æ–°å¢å­—æ®µä»¥åŠæ—¥å¿—æ¦‚ç‡æ•°ç»„é•¿åº¦ä¸ `output_ids` çš„å¯¹åº”å…³ç³»ã€‚

**ğŸ¯ å½±å“èŒƒå›´**  
- `python/sglang/srt/managers/tokenizer_manager.py`ï¼ˆä¸­æ–­è¯·æ±‚å¤„ç†è·¯å¾„ï¼‰  
- `test/registered/scheduler/test_abort.py`ï¼ˆå¼‚å¸¸ä¸­æ–­çš„å•å…ƒæµ‹è¯•ï¼‰  
- å¯èƒ½å½±å“æ¶ˆè´¹ `meta_info` çš„ä¸Šå±‚ç›‘æ§ã€æ—¥å¿—æˆ–å®¡è®¡æ¨¡å—ã€‚

**ğŸ’¡ å…³æ³¨å»ºè®®**  
- ç¡®è®¤ `state.created_time` åœ¨æ‰€æœ‰è¯·æ±‚è·¯å¾„ä¸Šå‡å·²åˆå§‹åŒ–ï¼Œé˜²æ­¢ `e2e_latency` è®¡ç®—å‡ºç° `None` æˆ–è´Ÿå€¼ã€‚  
- `weight_version` æ¥è‡ª `self.server_args`ï¼Œè‹¥åç»­å¯åŠ¨æ—¶ä¸ä¼ è¯¥å­—æ®µä¼šè§¦å‘ `AttributeError`ï¼Œå»ºè®®æ·»åŠ å®¹é”™æˆ–é»˜è®¤å€¼ã€‚  
- åªåœ¨ abort åœºæ™¯åŠ å…¥ `finished_time`ï¼Œè‹¥åç»­åœ¨æ­£å¸¸å®Œæˆè·¯å¾„ä¹Ÿéœ€è¦ç»Ÿä¸€å»¶è¿Ÿç»Ÿè®¡ï¼Œè¯·åŒæ­¥ç›¸åŒå­—æ®µçš„å†™å…¥é€»è¾‘ã€‚  
- ç”±äºæ–°å¢ `return_logprob`/`top_logprobs_num` ä¸ºæµ‹è¯•ä¸“ç”¨ï¼Œè‹¥ç”Ÿäº§ç¯å¢ƒæœªæ˜¾å¼å¼€å¯ï¼Œç¡®ä¿é»˜è®¤è¡Œä¸ºä»ç„¶å…¼å®¹æ—§çš„ `meta_info` ç»“æ„ã€‚  
- å…³æ³¨åºåˆ—åŒ–/ç½‘ç»œä¼ è¾“å±‚é¢å¯¹ `meta_info` å¢å¤§å¯èƒ½äº§ç”Ÿçš„æ€§èƒ½æˆ–å¸¦å®½å½±å“ï¼Œå°¤å…¶åœ¨é«˜å¹¶å‘ abort åœºæ™¯ä¸‹ã€‚  

æ€»ä½“è€Œè¨€ï¼Œæ­¤æ¬¡æ”¹åŠ¨ä¿®å¤äº†ç­‰å¾…é˜Ÿåˆ—ä¸­ abort æ—¶é—æ¼å…³é”®å…ƒä¿¡æ¯çš„é—®é¢˜ï¼Œå¹¶åœ¨æµ‹è¯•ä¸­åŠ å…¥äº†æ›´å®Œæ•´çš„æ ¡éªŒï¼Œé£é™©æœ‰é™ã€‚å»ºè®®åœ¨ CI ä¸­åŠ å…¥å¯¹é abort è·¯å¾„çš„ `meta_info` ç»“æ„å›å½’æµ‹è¯•ï¼Œä»¥é˜²æ­¢æ„å¤–ç ´åå·²æœ‰æ¥å£ã€‚

---

### [Env] centralize hicache vars in environ.py (#17204)
**SHA**: `bd39de7` | ğŸ”— [æŸ¥çœ‹æäº¤](https://github.com/sgl-project/sglang/commit/bd39de7d5e468197ddf2907cd372ebb1e853cb19)

**ğŸ¯ å˜æ›´ç±»å‹**ï¼šåŠŸèƒ½å¢å¼ºï¼ˆç¯å¢ƒå˜é‡ç»Ÿä¸€ç®¡ç†ï¼‰  
**âš¡ é‡è¦ç¨‹åº¦**ï¼šğŸŸ¡ ä¸­  
**ğŸ“‹ å˜æ›´æ‘˜è¦**ï¼šåœ¨ `python/sglang/srt/environ.py` ä¸­æ–°å¢ `SGLANG_HICACHE_FILE_BACKEND_STORAGE_DIR` ä¸ `SGLANG_HICACHE_NIXL_BACKEND_STORAGE_DIR` ä¸¤ä¸ª `EnvStr`ï¼Œå¹¶åœ¨ Hiâ€‘Cache å®ç° (`hicache_storage.py`ã€`hicache_nixl.py`) ä¸­æ”¹ä¸ºé€šè¿‡ `envs` å¯¹è±¡è¯»å–ï¼Œè€Œä¸å†ç›´æ¥ `os.getenv`ã€‚  

**ğŸ¯ å½±å“èŒƒå›´**  
- `sglang/srt/environ.py`ï¼ˆç¯å¢ƒå˜é‡ç»Ÿä¸€å…¥å£ï¼‰  
- `sglang/srt/mem_cache/hicache_storage.py`ï¼ˆæ–‡ä»¶åç«¯å­˜å‚¨ï¼‰  
- `sglang/srt/mem_cache/storage/nixl/hicache_nixl.py`ï¼ˆNixl åç«¯å­˜å‚¨ï¼‰  
- ä¸ Hiâ€‘Cache ç›¸å…³çš„é…ç½®æ–‡æ¡£åŠä½¿ç”¨è„šæœ¬  

**ğŸ’¡ å…³æ³¨å»ºè®®**  
1. **åˆå§‹åŒ–æ£€æŸ¥**ï¼šç¡®ä¿ `envs` å®ä¾‹åœ¨æ¨¡å—å¯¼å…¥æ—¶å·²å®ä¾‹åŒ–ï¼Œå¦åˆ™ `envs.SGLANG_HICACHE_â€¦` è®¿é—®ä¼šæŠ›å¼‚å¸¸ã€‚  
2. **é»˜è®¤å€¼ç»Ÿä¸€**ï¼šå½“å‰ `EnvStr(None)` æ²¡æœ‰é»˜è®¤å€¼ï¼Œä»£ç é‡Œä»ä½¿ç”¨ `or file_path` å…œåº•ï¼Œå»ºè®®åœ¨ `environ.py` ä¸­ç»™å‡ºæ˜ç¡®çš„é»˜è®¤è·¯å¾„ï¼Œé™ä½æ¯å¤„ `or file_path` çš„é‡å¤é€»è¾‘ã€‚  
3. **å‘åå…¼å®¹**ï¼šå¤–éƒ¨è„šæœ¬ä»å¯èƒ½ä¾èµ–åŸç”Ÿ `os.getenv`ï¼Œå¯åœ¨ `environ.py` ä¸­æä¾›å…¼å®¹å±‚ï¼ˆå¦‚ `os.getenv = envs.get`ï¼‰æˆ–åœ¨æ–‡æ¡£ä¸­æç¤ºè¿ç§»ã€‚  
4. **æ–‡æ¡£åŒæ­¥**ï¼šæ›´æ–° README/Config ç« èŠ‚ï¼Œåˆ—å‡ºæ–°ç¯å¢ƒå˜é‡çš„æ„ä¹‰ã€å–å€¼ç¤ºä¾‹ä»¥åŠæ¨èçš„é»˜è®¤ç›®å½•ã€‚  
5. **å•å…ƒæµ‹è¯•**ï¼šè¡¥å……æµ‹è¯•ï¼ŒéªŒè¯åœ¨æœªè®¾ç½®ç¯å¢ƒå˜é‡ã€ä»…è®¾ç½®æ–‡ä»¶åç«¯æˆ–ä»…è®¾ç½® Nixl åç«¯æ—¶ï¼Œ`HiCacheFile` ä¸ `HiCacheNixl` èƒ½æ­£ç¡®å›é€€åˆ°é»˜è®¤è·¯å¾„ã€‚  
6. **æ—¥å¿—å¯è§‚æµ‹**ï¼šåœ¨åˆå§‹åŒ–æ—¶æ‰“å°å®é™…ä½¿ç”¨çš„å­˜å‚¨ç›®å½•ï¼Œä¾¿äºæ’éšœã€‚  

æ€»ä½“è€Œè¨€ï¼Œæ­¤æ¬¡æ”¹åŠ¨æå‡äº†é…ç½®é›†ä¸­ç®¡ç†çš„å¯ç»´æŠ¤æ€§ï¼Œå½±å“èŒƒå›´å±€é™äº Hiâ€‘Cache ç›¸å…³æ¨¡å—ï¼Œè‹¥æŒ‰ä»¥ä¸Šå»ºè®®å®Œå–„å…¼å®¹æ€§å’Œæ–‡æ¡£ï¼Œå¯å®‰å…¨åˆå¹¶ã€‚

---

### Add timeout abort kits for normal / eagle. (#18815)
**SHA**: `dcea74d` | ğŸ”— [æŸ¥çœ‹æäº¤](https://github.com/sgl-project/sglang/commit/dcea74d63fed017e1e8e76091702a02f1f3de761)

**ğŸ¯ å˜æ›´ç±»å‹**ï¼šåŠŸèƒ½å¢å¼ºï¼ˆä¸º abort / timeout åœºæ™¯æä¾›ç»Ÿä¸€æµ‹è¯• Kitï¼‰  
**âš¡ é‡è¦ç¨‹åº¦**ï¼šğŸŸ¡ ä¸­  
**ğŸ“‹ å˜æ›´æ‘˜è¦**ï¼š  
1. æ–°å¢ `python/sglang/test/kits/abort_timeout_kit.py`ï¼Œå®ç° `AbortAllMixinã€WaitingTimeoutMixinã€RunningTimeoutTwoWaveMixin` ä¸‰ä¸ªå¯å¤ç”¨çš„æµ‹è¯•åŸºç±»ï¼Œå°è£…äº† abortâ€‘allã€ç­‰å¾…é˜Ÿåˆ—è¶…æ—¶ã€è¿è¡Œè¶…æ—¶çš„å¹¶å‘è¯·æ±‚é€»è¾‘ã€‚  
2. åŸæœ‰ `test/registered/scheduler/test_abort.py` ä¸­çš„å…·ä½“å®ç°è¢«åˆ å‡ï¼Œæ”¹ä¸ºç›´æ¥ç»§æ‰¿ç›¸åº” Mixinï¼Œç®€åŒ–ä»£ç å¹¶é¿å…é‡å¤ã€‚  
3. åœ¨ Eagle ç›¸å…³çš„æµ‹è¯• `test/registered/spec/eagle/test_eagle_infer_b.py` ä¸­å¼•å…¥è¿™äº› Mixinï¼Œåˆ†åˆ«ä¸º Eagle æœåŠ¡å™¨æ·»åŠ  abortâ€‘allã€waitingâ€‘timeoutã€runningâ€‘timeout çš„å›å½’æµ‹è¯•ï¼Œå¹¶é€šè¿‡ç¯å¢ƒå˜é‡/å¯åŠ¨å‚æ•°è‡ªå®šä¹‰è¶…æ—¶é˜ˆå€¼å’Œå¹¶å‘ä¸Šé™ã€‚

**ğŸ¯ å½±å“èŒƒå›´**ï¼š  
- `sglang/test/kits/abort_timeout_kit.py`ï¼ˆæ–°å¢ï¼‰  
- `sglang/test/registered/scheduler/test_abort.py`ï¼ˆåˆ é™¤å¤§é‡é‡å¤å®ç°ï¼‰  
- `sglang/test/registered/spec/eagle/test_eagle_infer_b.py`ï¼ˆæ–°å¢ Eagleâ€‘ä¸“å±æµ‹è¯•ï¼‰  
- ç›¸å…³ CI æ³¨å†Œå…¥å£ï¼ˆ`sglang.test.ci.ci_register`ï¼‰é—´æ¥å—åˆ°å½±å“ï¼Œå› ä¸ºæ–°æµ‹è¯•ä¼šåœ¨ CI ä¸­è¿è¡Œã€‚

**ğŸ’¡ å…³æ³¨å»ºè®®**  

1. **å…¼å®¹æ€§**ï¼šMixin ä¸­ä½¿ç”¨çš„é»˜è®¤å‚æ•°ï¼ˆå¦‚ `abort_all_num_requests=32`ã€`_REQUEST_TIMEOUT=60`ï¼‰å¯¹ä½é…ç½® CI ç¯å¢ƒå¯èƒ½å¯¼è‡´è¶…æ—¶æˆ–èµ„æºè€—å°½ã€‚å»ºè®®åœ¨æ–‡æ¡£æˆ– CI é…ç½®ä¸­æ³¨æ˜éœ€è¦çš„ `--max-running-requests` ä¸ç¡¬ä»¶è¦æ±‚ã€‚  
2. **èµ„æºæ¸…ç†**ï¼šæ‰€æœ‰æµ‹è¯•åœ¨ `tearDownClass` ä¸­è°ƒç”¨ `kill_process_tree`ï¼Œä½†åœ¨å¼‚å¸¸è·¯å¾„ï¼ˆä¾‹å¦‚è¯·æ±‚æœªè¿”å›ï¼‰ä¸‹å¯èƒ½ä»æ®‹ç•™å­è¿›ç¨‹ã€‚å¯ä»¥åœ¨ `finally` å—ä¸­åŠ å…¥æ£€æŸ¥ `process.poll()` å¹¶å¼ºåˆ¶ `terminate`ã€‚  
3. **é”™è¯¯å¤„ç†**ï¼šå½“å‰ `run_decode` ç›´æ¥è¿”å› `response.json()`ï¼Œè‹¥è¯·æ±‚å› ç½‘ç»œæˆ–æœåŠ¡å™¨é”™è¯¯è¿”å›é JSONï¼Œä¼šæŠ›å‡ºå¼‚å¸¸å¯¼è‡´çº¿ç¨‹æ³„æ¼ã€‚å»ºè®®æ•è· `requests.exceptions.RequestException` å¹¶ç»Ÿä¸€è¿”å› `{"object":"error","code":...}`ã€‚  
4. **è¶…æ—¶é…ç½®**ï¼šEagle æµ‹è¯•ä¸­é€šè¿‡ `envs.SGLANG_REQ_WAITING_TIMEOUT.override(0.001)` ç­‰æ–¹å¼ç¡¬ç¼–ç è¶…æ—¶æ—¶é—´ï¼Œè‹¥åç»­ç¯å¢ƒå˜é‡åç§°æˆ–é»˜è®¤å€¼å˜æ›´ï¼Œå¯èƒ½å¯¼è‡´æµ‹è¯•å¤±æ•ˆã€‚è€ƒè™‘å°†è¿™äº›é˜ˆå€¼æŠ½è±¡ä¸ºç±»å±æ€§æˆ–é…ç½®æ–‡ä»¶ã€‚  
5. **æ–‡æ¡£æ›´æ–°**ï¼šæ–°å¢ Kit çš„ä½¿ç”¨æ–¹å¼ã€å‚æ•°æ„ä¹‰ä»¥åŠåœ¨è‡ªå®šä¹‰æœåŠ¡å™¨å¯åŠ¨è„šæœ¬ä¸­éœ€è¦çš„å‚æ•°åº”åœ¨ `README` æˆ–æµ‹è¯•æ–‡æ¡£ä¸­è¡¥å……è¯´æ˜ï¼Œå¸®åŠ©è´¡çŒ®è€…å¿«é€Ÿå®šä½ã€‚  

æ€»ä½“è€Œè¨€ï¼Œæ­¤æ¬¡æ”¹åŠ¨é€šè¿‡æŠ½è±¡å¤ç”¨çš„æ–¹å¼æå‡äº† abort/timeout æµ‹è¯•çš„å¯ç»´æŠ¤æ€§å’Œå¯è¯»æ€§ï¼Œä½†åœ¨å¼‚å¸¸å®‰å…¨å’Œ CI èµ„æºæ¶ˆè€—æ–¹é¢ä»æœ‰ç»†èŠ‚å¯ä¼˜åŒ–ã€‚

---

### [Perf] refactor piecewise cuda graph support of Qwen3-Next (#17613)
**SHA**: `8be18c6` | ğŸ”— [æŸ¥çœ‹æäº¤](https://github.com/sgl-project/sglang/commit/8be18c655d0ff1c2e673395102c97c9d5cbd7d1c)

**ğŸ¯ å˜æ›´ç±»å‹**ï¼šåŠŸèƒ½å¢å¼ºï¼ˆä¸º Qwenâ€‘3â€‘Next æ·»åŠ  piecewiseâ€‘CUDAâ€‘graph æ”¯æŒï¼‰  
**âš¡ é‡è¦ç¨‹åº¦**ï¼šğŸŸ¡ ä¸­  

**æ ¸å¿ƒæ”¹åŠ¨**  
1. **layernorm_gated.py**ï¼šåœ¨ `calc_rows_per_block` ä¸­åŠ å…¥å¯¹ `enable_piecewise_cuda_graph` çš„æ£€æµ‹ï¼Œè‹¥å¼€å¯å›ºå®šè¿”å› `MAX_ROWS_PER_BLOCK=4`ï¼Œé¿å… `torch.compile` åœ¨åŠ¨æ€ batch ä¸Šç”Ÿæˆ guardã€‚  
2. **radix_linear_attention.py**ï¼šæ–°å¢ `unified_linear_attention_with_output` è‡ªå®šä¹‰ OPï¼ˆ`register_custom_op` + `register_split_op`ï¼‰ï¼Œåœ¨ `forward` çš„ **extend** æ¨¡å¼ä¸‹ç›´æ¥å†™å…¥é¢„åˆ†é…çš„ `output`ï¼Œå¹¶åœ¨ `piecewise` ä¸Šä¸‹æ–‡ä¸­ä½¿ç”¨ã€‚  
3. **model_runner.py**ï¼šåˆå§‹åŒ– piecewise å›¾æ—¶ç»Ÿä¸€æ”¶é›†æ³¨æ„åŠ›å±‚ï¼Œå…¼å®¹ `linear_attn.attn` åµŒå¥—ç»“æ„ã€‚  
4. **qwen3_next.py**ï¼šå°† `self.linear_attn` æ”¹ä¸º `self.attn`ï¼Œå¹¶æŠŠæ—§çš„ â€œextendâ€‘modeâ€ å‰ç½®é€»è¾‘ç§»è‡³è‡ªå®šä¹‰ OPï¼›ä»…ä¿ç•™åŸå§‹ `_forward` è·¯å¾„ã€‚  
5. **æµ‹è¯•**ï¼šå…³é—­åŸæœ‰é—´æ­‡æ€§å¤±è´¥çš„ PCG æµ‹ä¾‹ï¼Œé˜²æ­¢ CI å¤±æ•ˆã€‚

**å½±å“èŒƒå›´**  
- Qwenâ€‘3â€‘Next æ¨¡å‹çš„å‰å‘è·¯å¾„ï¼ˆåŒ…æ‹¬ `RadixLinearAttention` ä¸å±‚å½’ä¸€åŒ–ï¼‰ã€‚  
- æ‰€æœ‰ä¾èµ– `model_runner.init_piecewise_cuda_graphs` æ”¶é›†æ³¨æ„åŠ›å±‚çš„æ¨¡å‹ï¼ˆå¦‚ InternVL ç­‰ï¼‰ï¼Œå› å±æ€§åç»Ÿä¸€ä¸º `attn`ã€‚  
- é€šè¿‡ `get_forward_context()` ä½¿ç”¨ piecewise CUDA graph çš„ä»»ä½•è‡ªå®šä¹‰ OPã€‚  

**å…³æ³¨å»ºè®®**  
- **å…¼å®¹æ€§**ï¼šç¡®ä¿å…¶ä»–æ¨¡å‹ä»æ‹¥æœ‰ `layer.attn` æˆ– `layer.linear_attn` å¯¹è±¡ï¼›è‹¥ä¸å­˜åœ¨ï¼Œ`init_piecewise_cuda_graphs` ä¼šæŠ›å¼‚å¸¸ã€‚å¯åœ¨ä»£ç ä¸­åŠ å…¥ `hasattr(..., "attn")` çš„å®‰å…¨å›é€€ã€‚  
- **å…¨å±€å‚æ•°**ï¼š`get_global_server_args()` åœ¨å•å…ƒæµ‹è¯•æˆ–è„šæœ¬ä¸­å¯èƒ½æœªåˆå§‹åŒ–ï¼Œå½“å‰å·²æ•è· `ValueError`ï¼Œå»ºè®®æ”¹ä¸ºæ›´é€šç”¨çš„ `try/except Exception` æˆ–æä¾›é»˜è®¤é…ç½®ï¼Œä»¥å…éšè—å…¶å®ƒé”™è¯¯ã€‚  
- **è‡ªå®šä¹‰ OP**ï¼š`unified_linear_attention_with_output` ç›´æ¥ `copy_` è¿”å›å¼ é‡ï¼Œéœ€ç¡®è®¤æ¢¯åº¦ä¼ æ’­ç¬¦åˆé¢„æœŸï¼›è‹¥åç»­è¦æ”¯æŒ `torch.compile` çš„åˆ†å—æ‰§è¡Œï¼ŒåŠ¡å¿…åœ¨ `register_split_op` ä¸­å£°æ˜åˆ†å—ç­–ç•¥ã€‚  
- **æ€§èƒ½éªŒè¯**ï¼šè™½ç„¶å›ºå®š `MAX_ROWS_PER_BLOCK=4` èƒ½æ¶ˆé™¤ guardï¼Œä½†åœ¨å¤§æ¨¡å‹æˆ–å¤š SM ç¯å¢ƒä¸‹å¯èƒ½ä¸æ˜¯æœ€ä¼˜å€¼ï¼Œå»ºè®®åœ¨ CI ä¸­æ·»åŠ åŸºå‡†å¯¹æ¯”ï¼Œæˆ–æä¾›å¯è°ƒå‚æ•°ã€‚  
- **æ–‡æ¡£**ï¼šæ›´æ–° README/æ¨¡å‹è¯´æ˜ï¼Œæ˜ç¡® `--enable-piecewise-cuda-graph` é€‰é¡¹çš„ä½¿ç”¨åœºæ™¯ã€å‰ç½®æ¡ä»¶ä»¥åŠå¯¹ Qwenâ€‘3â€‘Next çš„åŠ é€Ÿæ•ˆæœã€‚  

æ€»ä½“æ¥çœ‹ï¼Œæ­¤æ¬¡æ”¹åŠ¨ä¸º Qwenâ€‘3â€‘Next å¼•å…¥äº†æ›´ç»†ç²’åº¦çš„ CUDAâ€‘graph æ”¯æŒï¼Œæå‡äº†åœ¨ â€œextendâ€ æ¨ç†æ¨¡å¼ä¸‹çš„è°ƒåº¦æ•ˆç‡ï¼Œä½†æ¶‰åŠå…¨å±€å‚æ•°ã€å±æ€§ç»Ÿä¸€ä¸è‡ªå®šä¹‰ OPï¼Œéœ€åšå¥½å…¼å®¹æ€§æµ‹è¯•å¹¶è¡¥å……ç›¸åº”æ–‡æ¡£ã€‚

---

### Update performance dashboard for nightly tests (#18824)
**SHA**: `3a1c388` | ğŸ”— [æŸ¥çœ‹æäº¤](https://github.com/sgl-project/sglang/commit/3a1c388b43a371e282a82a8c56b88cd8541b4092)

**ğŸ¯ å˜æ›´ç±»å‹**ï¼šåŠŸèƒ½å¢å¼ºï¼ˆæ€§èƒ½çœ‹æ¿ UI å¤§å¹…å‡çº§ âœ…ï¼Œæ–°å¢ç™»å½•é‰´æƒ âœ…ï¼Œæ”¯æŒå®šæ—¶è‡ªåŠ¨åˆ·æ–° âœ…ï¼‰  

**ğŸŸ¡ é‡è¦ç¨‹åº¦**ï¼šä¸­  

**ğŸ“‹ å˜æ›´æ‘˜è¦**  
1. å‰ç«¯ `docs/performance_dashboard` é‡æ–°è®¾è®¡ï¼šé…è‰²ã€å­—ä½“ã€å¸ƒå±€ã€åŠ¨ç”»ã€å¡ç‰‡æ ·å¼ã€ç™»å½•é®ç½©å±‚ç­‰å‡æ”¹å†™ï¼Œä¸”æ‰€æœ‰ API è¯·æ±‚åŠ å…¥ `Authorization` å¤´ã€‚  
2. åç«¯ `server.py` å¢åŠ å¯é€‰çš„ç”¨æˆ·å/å¯†ç é‰´æƒã€ä¼šè¯ tokenï¼ˆSHAâ€‘256 å“ˆå¸Œã€1â€¯h å¤±æ•ˆï¼‰ä»¥åŠ `--refresh-interval` å‚æ•°çš„å‘¨æœŸåˆ·æ–°åŠŸèƒ½ã€‚  

**ğŸ¯ å½±å“èŒƒå›´**  
- å‰ç«¯ï¼š`app.js`ã€`index.html`ï¼ˆæ‰€æœ‰ UIã€äº¤äº’ã€è¯·æ±‚é€»è¾‘ï¼‰ã€‚  
- åç«¯ï¼š`server.py`ï¼ˆCLI å‚æ•°ã€å…¨å±€ `auth_config`ã€`/api/auth-check`ã€`/api/login`ã€token æ ¡éªŒã€å‘¨æœŸåˆ·æ–°ï¼‰ã€‚  
- å¯èƒ½å½±å“ CI è„šæœ¬æˆ–è‡ªéƒ¨ç½²çš„é™æ€é¡µé¢ï¼ˆéœ€è¦åç«¯å¯åŠ¨å‚æ•°åŒæ­¥ï¼‰ã€‚  

**ğŸ’¡ å…³æ³¨å»ºè®®**  
1. **å®‰å…¨**  
   - token åªä¿å­˜åœ¨ `sessionStorage`ï¼Œè‹¥é¡µé¢è¢« XSS æ”»å‡»ä¼šæ³„éœ²ï¼›å»ºè®®åŠ å…¥ CSPã€Subresource Integrityï¼Œå¹¶åœ¨å‰ç«¯å¯¹ `innerHTML` ä½¿ç”¨å®‰å…¨ APIã€‚  
   - `hash_password` ä»…åš SHAâ€‘256 å“ˆå¸Œï¼Œç¼ºå°‘ç›å€¼ï¼›å»ºè®®æ”¹ç”¨ PBKDF2/Bcryptã€‚  
   - ç™»å½•é”™è¯¯ä¿¡æ¯ç›´æ¥è¿”å›æœåŠ¡ç«¯é”™è¯¯ï¼Œæœ€å¥½ç»Ÿä¸€è¿”å› `401`ï¼Œé¿å…æ³„éœ²ç”¨æˆ·æ˜¯å¦å­˜åœ¨ã€‚  
2. **åç«¯å¹¶å‘**  
   - `auth_config["active_tokens"]` åœ¨é«˜å¹¶å‘ä¸‹é¢‘ç¹æ‹·è´å­—å…¸ï¼Œå»ºè®®ä½¿ç”¨ `collections.OrderedDict` æˆ– `cachetools` å®ç°æ›´é«˜æ•ˆçš„è¿‡æœŸæ¸…ç†ã€‚  
   - `verify_auth_token` æ¯æ¬¡éƒ½éå†ä¸€æ¬¡ `active_tokens`ï¼Œå¯è€ƒè™‘æŠŠè¿‡æœŸæ¸…ç†æ”¾åˆ°å•ç‹¬ç»´æŠ¤çš„å®ˆæŠ¤çº¿ç¨‹ã€‚  
3. **å…¼å®¹æ€§**  
   - æ–°å¢ `/api/auth-check`ã€`/api/login` éœ€è¦åœ¨å·²æœ‰çš„æ–‡æ¡£æˆ–éƒ¨ç½²è„šæœ¬ä¸­è¯´æ˜ï¼Œå¦åˆ™è€ç‰ˆå‰ç«¯ä¼š 404ã€‚  
   - `--refresh-interval` é»˜è®¤ 12â€¯hï¼Œè‹¥ç”¨æˆ·æœªè®¾ç½®ä¼šå¯åŠ¨åå°çº¿ç¨‹ï¼›ç¡®ä¿å®¹å™¨/æœåŠ¡èƒ½å¤Ÿé•¿æœŸè¿è¡Œï¼Œå¦åˆ™ä¼šå› å¼‚å¸¸é€€å‡ºå¯¼è‡´æ•°æ®å¤±æ•ˆã€‚  
4. **å¯ç»´æŠ¤æ€§**  
   - å‰ç«¯å¤§é‡å†…è” CSS ä¸ JSï¼Œå»ºè®®æ‹†åˆ†ä¸ºæ¨¡å—åŒ–æ–‡ä»¶ï¼ˆ`.css`ã€`.js`ï¼‰ï¼Œä¾¿äºå•å…ƒæµ‹è¯•ä¸ä¸»é¢˜åˆ‡æ¢ã€‚  
   - ç»™ `DashboardHandler` ä¸­çš„å„ä¸ª `_send_json`ã€`_check_auth` åŠ ä¸Š docstringï¼Œæå‡å¯è¯»æ€§ã€‚  

**æ€»ç»“**ï¼šæœ¬æ¬¡æäº¤æŠŠæ€§èƒ½çœ‹æ¿ä»â€œåŠŸèƒ½é¡µé¢â€å‡çº§ä¸ºæ›´å…·äº¤äº’æ€§å’Œå¯æ§æ€§çš„ä»ªè¡¨ç›˜ï¼Œå¹¶é¦–æ¬¡åŠ å…¥é‰´æƒä¸è‡ªåŠ¨åˆ·æ–°ï¼Œæå‡äº†ä¸šåŠ¡å®‰å…¨ä¸å¯ç”¨æ€§ã€‚ä½†é‰´æƒå®ç°ä»æœ‰ç¡¬åŒ–ç©ºé—´ï¼Œå‰ç«¯æ ·å¼ä¸è„šæœ¬çš„å¯ç»´æŠ¤æ€§äº¦éœ€è¿›ä¸€æ­¥æŠ½ç¦»ã€‚å»ºè®®åœ¨æ­£å¼å‘å¸ƒå‰è¡¥é½å®‰å…¨ç¡¬åŒ–ã€æ–‡æ¡£è¯´æ˜ä»¥åŠåç«¯å¹¶å‘/èµ„æºç›‘æ§ã€‚

---

### [CI] feat: add early exit to wait_for_server when process dies (#18602)
**SHA**: `3299c4f` | ğŸ”— [æŸ¥çœ‹æäº¤](https://github.com/sgl-project/sglang/commit/3299c4f9c1735c17305175ce1685d0ddbc2e7f91)

**ğŸ¯ å˜æ›´ç±»å‹**ï¼šåŠŸèƒ½å¢å¼º / Bug ä¿®å¤  
**âš¡ é‡è¦ç¨‹åº¦**ï¼šğŸŸ¡ ä¸­  
**ğŸ“‹ å˜æ›´æ‘˜è¦**ï¼šä¸º `sglang.utils.wait_for_server` å¢åŠ  **process æ—©æœŸé€€å‡ºæ£€æµ‹**ï¼Œå¹¶æŠ½è±¡ä¸º `wait_for_http_ready`ã€‚æ‰€æœ‰æ–‡æ¡£ã€ç¤ºä¾‹ã€æµ‹è¯•ä»¥åŠ CI ä¸­çš„ `wait_server_ready` å‡æ”¹ä¸ºä¼ å…¥å¯¹åº”çš„è¿›ç¨‹å¯¹è±¡ï¼Œä»¥åœ¨æœåŠ¡å™¨å´©æºƒæ—¶åŠæ—¶æŠ›å¼‚å¸¸ï¼Œè€Œéä¸€ç›´è½®è¯¢ã€‚  

**ğŸ¯ å½±å“èŒƒå›´**  
- `sglang/utils.py`ï¼ˆæ ¸å¿ƒå®ç°ï¼‰  
- `python/sglang/test/server_fixtures`ã€`test/registered/*`ã€`test/manual/*`ï¼ˆæµ‹è¯•æ¡†æ¶ï¼‰  
- `examples/*`ã€`docs/*.ipynb`ï¼ˆç¤ºä¾‹/æ–‡æ¡£ï¼‰  
- `scripts/playground/frontend_reasoning.ipynb`ã€`test/srt/experiment_runner.py`ï¼ˆå®éªŒè„šæœ¬ï¼‰  

**ğŸ’¡ å…³æ³¨å»ºè®®**  
1. **å…¼å®¹æ€§**ï¼šæ–°å‡½æ•°ä¿æŒåŸæœ‰ `wait_for_server(base_url, timeout)` æ¥å£ä¸å˜ï¼Œä»…æ–°å¢ `process` å‚æ•°ï¼Œå¤–éƒ¨è°ƒç”¨ä»å¯ä¸ä¼ ã€‚è¯·ç¡®è®¤å‘å¸ƒçš„ wheel ä¸­ `wait_for_server` çš„ç­¾åå·²æ›´æ–°åˆ° `process: Optional[subprocess.Popen] = None`ï¼Œé˜²æ­¢æ—§ä»£ç å› å‚æ•°ä½ç½®å˜åŒ–æŠ¥é”™ã€‚  
2. **è¿›ç¨‹ç±»å‹**ï¼š`_raise_if_process_exited` åŒæ—¶æ”¯æŒ `subprocess.Popen`ï¼ˆ`poll`ï¼‰å’Œ Python çº¿ç¨‹/è¿›ç¨‹ï¼ˆ`is_alive`ï¼‰ï¼Œä½†è‹¥é¡¹ç›®ä¸­å‡ºç°è‡ªå®šä¹‰è¿›ç¨‹åŒ…è£…å™¨ï¼Œéœ€è¦å®ç° `poll` æˆ– `is_alive` æ¥å£ï¼Œæˆ–åœ¨è°ƒç”¨æ–¹è‡ªè¡Œé€‚é…ã€‚  
3. **å¼‚å¸¸å¤„ç†**ï¼š`wait_for_http_ready` ä¼šåœ¨æ£€æµ‹åˆ°è¿›ç¨‹å¼‚å¸¸åæŠ› `RuntimeError`ï¼Œä¸Šå±‚å·²å°†å…¶æ•è·å¹¶è½¬ä¸º `TimeoutError`ï¼ˆå¦‚ `experiment_runner.wait_for_server`ï¼‰ï¼Œå»ºè®®åœ¨æ‰€æœ‰è°ƒç”¨ç‚¹ç»Ÿä¸€è®°å½•æ—¥å¿—å¹¶ç¡®ä¿å¼‚å¸¸èƒ½è®© CI æ˜ç¡®å¤±è´¥ã€‚  
4. **è¶…æ—¶ä¸é—´éš”**ï¼šè½®è¯¢é—´éš”ä»ä¸º 1â€¯sï¼Œè¶…æ—¶é€»è¾‘æœªå˜ï¼Œè‹¥ä¸šåŠ¡å¯¹å¯åŠ¨æ—¶é—´æœ‰æ›´ä¸¥æ ¼éœ€æ±‚ï¼Œå¯è€ƒè™‘æš´éœ² `request_timeout`ã€`poll_interval` å‚æ•°ã€‚  
5. **æµ‹è¯•è¦†ç›–**ï¼šå·²åœ¨å¤§é‡æµ‹è¯•æ–‡ä»¶åŠ å…¥ `process` å‚æ•°ï¼Œå»ºè®®å†è¡¥å……**å•å…ƒæµ‹è¯•**ï¼šæ¨¡æ‹Ÿå­è¿›ç¨‹æå‰é€€å‡ºï¼ŒéªŒè¯ `wait_for_server` èƒ½å³æ—¶æŠ›å‡º `RuntimeError`ã€‚  
6. **æ–‡æ¡£åŒæ­¥**ï¼šæ‰€æœ‰ .ipynb ç¤ºä¾‹å·²æ”¹ä¸ºä¼ å…¥ `process`ï¼Œè¯·æ£€æŸ¥ README / API æ–‡æ¡£ä¸­ `wait_for_server` çš„è¯´æ˜å·²æ›´æ–°ï¼Œé¿å…ç”¨æˆ·åœ¨æ‰‹åŠ¨è°ƒç”¨æ—¶é—æ¼ `process` å‚æ•°ã€‚  

æ€»ä½“æ¥çœ‹ï¼Œæ­¤æ¬¡æ”¹åŠ¨æå‡äº†å¯åŠ¨é˜¶æ®µçš„é²æ£’æ€§ï¼Œç‰¹åˆ«æ˜¯åœ¨ CI ç¯å¢ƒä¸‹é¿å…å› æœåŠ¡å™¨å¼‚å¸¸å¡æ­»ã€‚åªè¦æ³¨æ„ç­¾åå…¼å®¹ä¸æ—¥å¿—ç›‘æ§ï¼Œé£é™©è¾ƒä½ã€‚

---

### [CI] Revive 8-GPU trace upload in nightly test workflow (#18820)
**SHA**: `eccf875` | ğŸ”— [æŸ¥çœ‹æäº¤](https://github.com/sgl-project/sglang/commit/eccf875d4904a37dc4f6c72aafc254a0e1f1f452)

**ğŸ¯ å˜æ›´ç±»å‹**ï¼šåŠŸèƒ½å¢å¼ºï¼ˆCI ä¾§æ–°å¢ traceâ€¯ä¸Šä¼ ï¼‰  
**âš¡ é‡è¦ç¨‹åº¦**ï¼šğŸŸ¡ ä¸­ç­‰  
**ğŸ“‹ å˜æ›´æ‘˜è¦**ï¼š  
1. åœ¨ nightlyâ€‘testâ€‘nvidia å·¥ä½œæµçš„ä¸¤ä¸ª GPU ä»»åŠ¡ç»“æŸåï¼Œæ–°å¢ *Publish traces to storage repo* æ­¥éª¤ï¼Œæ”¶é›† `test/performance_profiles_*/` ä¸‹çš„ trace æ–‡ä»¶å¹¶è°ƒç”¨ `scripts/ci/utils/publish_traces.py` ä¸Šä¼ åˆ° `sglang-bot/sglang-ci-data`ã€‚  
2. `publish_traces.py` é‡æ„ä¸º **å…ˆæ”¶é›†æ‰€æœ‰ç›®å½•çš„æ–‡ä»¶ â†’ å†ä¸€æ¬¡æ€§æäº¤**ï¼Œæ”¯æŒ `--traces-dir` å¤šæ¬¡å‡ºç° (`action="append"`)ï¼Œå¹¶æŠŠå®é™…çš„ Git æäº¤é€»è¾‘æŠ½å–åˆ° `publish_traces_from_files`ã€‚  

**ğŸ¯ å½±å“èŒƒå›´**  
- `.github/workflows/nightly-test-nvidia.yml`ï¼ˆCI æµç¨‹ï¼‰  
- `scripts/ci/utils/publish_traces.py`ï¼ˆå·¥å…·è„šæœ¬ï¼‰  
- å¯èƒ½ç‰µæ¶‰åˆ° `sglang-ci-data` ä»“åº“çš„å†™æƒé™ä¸ç£ç›˜é…é¢ã€‚

**ğŸ’¡ å…³æ³¨å»ºè®®**  

| æ–¹é¢ | å»ºè®® |
|------|------|
| **è„šæœ¬å¥å£®æ€§** | `copy_trace_files` ä»ç„¶å‡è®¾ç›®æ ‡è·¯å¾„å·²å­˜åœ¨ï¼Œå»ºè®®åœ¨è°ƒç”¨å‰ `os.makedirs(target_base_path, exist_ok=True)`ï¼Œé˜²æ­¢å› ç›®å½•ä¸å­˜åœ¨å¯¼è‡´å¼‚å¸¸ã€‚ |
| **é”™è¯¯å›æ»š** | ç°åœ¨ `publish_traces_from_files` åœ¨ token æƒé™ä¸è¶³æˆ–ç½‘ç»œé”™è¯¯æ—¶ç›´æ¥ `sys.exit(1)`ï¼Œä½† CI æ­¥éª¤è®¾ä¸º `continue-on-error:true`ã€‚å»ºè®®æ•è·å¼‚å¸¸å¹¶è¿”å›é 0 ç ï¼Œä»…åœ¨çœŸæ­£å¤±è´¥æ—¶ä¸­æ­¢ï¼Œä»¥å…è¯¯æŠ¥ã€‚ |
| **å¹¶å‘å†²çª** | å¤šä¸ªå¹¶è¡Œ job å¯èƒ½åŒæ—¶å‘åŒä¸€ `traces/{run_id}` æäº¤ï¼Œäº§ç”Ÿå†²çªã€‚å¯ä»¥åœ¨è„šæœ¬ä¸­åŠ å…¥ `git pull --rebase` æˆ–åœ¨ CI ä¸­ä½¿ç”¨å”¯ä¸€å­ç›®å½•ï¼ˆå¦‚ `partition-{matrix.partition}`ï¼‰é¿å…ã€‚ |
| **æ—¥å¿—å¯è§‚æµ‹** | ç°åœ¨åªæ‰“å° â€œFound X files to uploadâ€ã€‚å»ºè®®åœ¨ä¸Šä¼ å‰æ‰“å°æ¯ä¸ªæ–‡ä»¶çš„ç›¸å¯¹è·¯å¾„ï¼Œä¾¿äºè°ƒè¯•ç¼ºå¤±æˆ–è¯¯åˆ çš„ traceã€‚ |
| **å®‰å…¨** | ä½¿ç”¨ `secrets.GH_PAT_FOR_NIGHTLY_CI_DATA`ï¼Œç¡®ä¿è¯¥ PAT ä»…æ‹¥æœ‰ `contents:write` æƒé™ï¼Œé¿å…è¿‡å®½çš„ä»“åº“è®¿é—®ã€‚ |
| **æ¸…ç†** | CI æ­¥éª¤åœ¨ä¸Šä¼ æˆåŠŸåä½¿ç”¨ `find â€¦ -delete` åˆ é™¤æœ¬åœ°å‹ç¼©æ–‡ä»¶ï¼Œè‹¥ä¸Šä¼ å¤±è´¥ä¼šç•™ä¸‹æ®‹ä½™ã€‚å»ºè®®åœ¨ `finally` å—ä¸­ç»Ÿä¸€æ¸…ç†ï¼Œé˜²æ­¢ç£ç›˜æ³„æ¼ã€‚ |

æ€»ä½“æ¥çœ‹ï¼Œæ”¹åŠ¨å®ç°äº† nightlyâ€‘8â€‘gpu æµ‹è¯•çš„ trace è‡ªåŠ¨å½’æ¡£ï¼Œæå‡äº†è°ƒä¼˜æ•°æ®çš„å¯è¿½æº¯æ€§ã€‚åªè¦æ³¨æ„ç›®å½•å†²çªã€å¼‚å¸¸å¤„ç†ä»¥åŠæƒé™é…ç½®ï¼Œæ•´ä½“é£é™©è¾ƒä½ã€‚

---

### [FlashInfer] Bump FlashInfer version from 0.6.2 to 0.6.3 (#18448)
**SHA**: `1be41e9` | ğŸ”— [æŸ¥çœ‹æäº¤](https://github.com/sgl-project/sglang/commit/1be41e9036e19fc620d39e8f7b22572fa36751a9)

**ğŸ¯ å˜æ›´ç±»å‹**ï¼šåŠŸèƒ½å¢å¼º / ä¾èµ–å‡çº§  
**âš¡ é‡è¦ç¨‹åº¦**ï¼šğŸŸ¡ ä¸­ï¼ˆå…¼å®¹æ€§éœ€å…³æ³¨ï¼‰  

**ğŸ“‹ å˜æ›´æ‘˜è¦**  
æœ¬æ¬¡æäº¤æŠŠæ‰€æœ‰ FlashInfer ç›¸å…³ä¾èµ–ä» 0.6.2 å‡çº§è‡³ 0.6.3ï¼ŒåŒ…æ‹¬ Docker é•œåƒã€CI è„šæœ¬ã€`pyproject.toml`ã€è¿è¡Œæ—¶ç‰ˆæœ¬æ ¡éªŒä»¥åŠ MoE åç«¯å¯ç”¨æ¡ä»¶ã€‚ä»£ç ä¸­æ‰€æœ‰ç¡¬ç¼–ç çš„ç‰ˆæœ¬å·ä¹ŸåŒæ­¥æ›´æ–°ã€‚  

**ğŸ¯ å½±å“èŒƒå›´**  
- `docker/Dockerfile`ã€`release-docker-cu13-framework.yml`ï¼šé•œåƒæ„å»ºä½¿ç”¨æ–°ç‰ˆ FlashInferã€‚  
- `python/pyproject.toml`ã€`scripts/ci/cuda/ci_install_dependency.sh`ï¼špip å®‰è£…å’Œ CI ç¯å¢ƒä¾èµ–å‡çº§ã€‚  
- `sglang/srt/entrypoints/engine.py`ã€`sglang/srt/server_args.py`ã€`sglang/srt/utils/common.py`ï¼šè¿è¡Œæ—¶ç‰ˆæœ¬æ£€æŸ¥ã€MoE `flashinfer_trtllm` å¯ç”¨é—¨æ§›æå‡è‡³ 0.6.3ã€‚  

**ğŸ’¡ å…³æ³¨å»ºè®®**  
1. **ç”¨æˆ·**ï¼šå‡çº§å‰è¯·å…ˆå¸è½½æ—§çš„ `flashinfer_python` / `flashinfer_cubin`ï¼Œå†é€šè¿‡ `pip install flashinfer_python==0.6.3 flashinfer_cubin==0.6.3` å®‰è£…ã€‚è‹¥ä½¿ç”¨è‡ªå»º Docker é•œåƒï¼Œè¯·é‡æ–°æ„å»ºä»¥è·å¾—æ–° JIT ç¼“å­˜ã€‚  
2. **å¼€å‘è€…**ï¼šç¡®è®¤æœ¬åœ°ç¯å¢ƒçš„ CUDA ä¸ FlashInfer 0.6.3 å…¼å®¹ï¼ˆç‰¹åˆ«æ˜¯ cu129ï¼‰ï¼Œå¹¶è·‘ä¸€éå•å…ƒæµ‹è¯•ï¼Œç•™æ„ API ç»†å¾®å˜æ›´ï¼ˆå¦‚å‡½æ•°ç­¾åæˆ–é»˜è®¤å‚æ•°ï¼‰ã€‚  
3. **CI**ï¼šCI è„šæœ¬å·²æ›´æ–°ç‰ˆæœ¬å·ï¼Œç¡®ä¿ CI æœåŠ¡å™¨çš„ç¼“å­˜å·²æ¸…ç†ï¼Œå¦åˆ™å¯èƒ½ä»ä½¿ç”¨æ—§çš„ FlashInfer åŒ…ã€‚  

æ€»ä½“è€Œè¨€ï¼Œå‡çº§æå‡äº†æ€§èƒ½å’Œ bug ä¿®å¤ï¼Œä½†éœ€ç¡®ä¿ç¯å¢ƒåŒæ­¥æ›´æ–°ï¼Œä»¥å…å‡ºç° â€œversion mismatchâ€ é”™è¯¯ã€‚

---

### [Auto Sync] Update loader.py, weight_utils.py (20260213) (#18779)
**SHA**: `008ea46` | ğŸ”— [æŸ¥çœ‹æäº¤](https://github.com/sgl-project/sglang/commit/008ea46af13e496240680932ad52c21b9e0589fb)

**ğŸ¯ å˜æ›´ç±»å‹**ï¼šåŠŸèƒ½å¢å¼º / ä»£ç é‡æ„  
**âš¡ é‡è¦ç¨‹åº¦**ï¼šğŸŸ¡ ä¸­  
**ğŸ“‹ å˜æ›´æ‘˜è¦**  
- åœ¨ `weight_utils.py` ä¸­åŠ å…¥ **`buffered_multi_thread_safetensors_weights_iterator`**ï¼Œé‡‡ç”¨æ»‘åŠ¨çª—å£â€‘å¤šçº¿ç¨‹æ–¹å¼å®ç°æœ‰ç•Œå†…å­˜çš„ safetensor è¯»å–ï¼›åŸ `multi_thread_safetensors_weights_iterator` å‚æ•°è¢«ç²¾ç®€ï¼Œå»æ‰äº†åŠ å¯†/åˆ†ç‰‡â€‘å…¨æ–‡ä»¶è¯»å–çš„é€»è¾‘ã€‚  
- `loader.py` è°ƒæ•´ä¸ºä½¿ç”¨æ–°è¿­ä»£å™¨å¹¶ç›¸åº”æ›´æ–°å¯¼å…¥ã€‚  
- åŒæ—¶åˆ é™¤äº†æœªå®ç°çš„ `decrypt` ä¸åŠ å¯†è¿­ä»£å™¨çš„å ä½å®ç°ï¼Œç®€åŒ–äº† `safetensors_weights_iterator` çš„å®ç°ï¼ˆæŒ‰é”®åæ’åºè¾“å‡ºï¼‰ã€‚

**ğŸ¯ å½±å“èŒƒå›´**  
- `sglang/srt/model_loader/loader.py`ï¼ˆæ¨¡å‹åŠ è½½å…¥å£ï¼‰  
- `sglang/srt/model_loader/weight_utils.py`ï¼ˆæ‰€æœ‰æƒé‡è¯»å–ç›¸å…³å‡½æ•°ï¼‰  
- å¯èƒ½çš„é—´æ¥è°ƒç”¨ç‚¹ï¼šä»»ä½•ç›´æ¥ä½¿ç”¨ `multi_thread_safetensors_weights_iterator` çš„å†…éƒ¨å·¥å…·æˆ–è‡ªå®šä¹‰è„šæœ¬ã€‚

**ğŸ’¡ å…³æ³¨å»ºè®®**  
1. **å…¼å®¹æ€§æ£€æŸ¥**ï¼šè‹¥é¡¹ç›®ä¸­è¿˜æœ‰å…¶ä»–åœ°æ–¹æ˜¾å¼è°ƒç”¨ `multi_thread_safetensors_weights_iterator(..., is_all_weights_sharded, decryption_key)`ï¼Œéœ€æ”¹ä¸ºæ–°ç­¾åæˆ–æ”¹ç”¨ `buffered_multi_thread_safetensors_weights_iterator`ã€‚  
2. **å†…å­˜/æ€§èƒ½éªŒè¯**ï¼šæ–°å®ç°é€šè¿‡ `max_workers+1` çš„ç¼“å†²ä¿è¯å†…å­˜ä¸Šé™ï¼Œä½†å¯èƒ½åœ¨æå¤§é‡åˆ†ç‰‡æ—¶ä»å‡ºç°å³°å€¼æ³¢åŠ¨ï¼›å»ºè®®åœ¨å¤§å‹æ¨¡å‹ï¼ˆ>100â€¯GBï¼‰ä¸Šè·‘ä¸€æ¬¡åŸºå‡†ï¼Œç¡®è®¤ RAM ä½¿ç”¨ç¬¦åˆé¢„æœŸã€‚  
3. **åŠ å¯†æƒé‡æ”¯æŒ**ï¼šæœ¬æ¬¡æäº¤ç§»é™¤äº†åŠ å¯† safetensor çš„å ä½å®ç°ï¼Œè‹¥æœªæ¥éœ€è¦åŠ è½½åŠ å¯†æ¨¡å‹ï¼Œéœ€è¦é‡æ–°å®ç° `safetensors_encrypted_weights_iterator` å¹¶åœ¨åŠ è½½è·¯å¾„ä¸­åŠ å…¥åˆ†æ”¯ã€‚  
4. **é¡ºåºä¸€è‡´æ€§**ï¼šæƒé‡éå†æ”¹ä¸º `sorted(keys)`ï¼Œç¡®ä¿ determinismï¼›ä½†è‹¥ä¸Šå±‚é€»è¾‘ä¾èµ–åŸå§‹æ–‡ä»¶é¡ºåºï¼Œè¯·ç¡®è®¤ä¸ä¼šå¼•å…¥åŠŸèƒ½å·®å¼‚ã€‚  
5. **æµ‹è¯•è¦†ç›–**ï¼šåŠ å¼ºå¯¹åˆ†ç‰‡ï¼ˆshardedï¼‰æ¨¡å‹ã€å•æ–‡ä»¶æ¨¡å‹ä»¥åŠ `disable_mmap` åœºæ™¯çš„å•å…ƒ/é›†æˆæµ‹è¯•ï¼Œç¡®ä¿å¤šçº¿ç¨‹åŠ è½½åå¼ é‡æ•°ã€åç§°ã€ dtype å®Œå…¨ä¸€è‡´ã€‚  

æ€»ä½“è€Œè¨€ï¼Œæ­¤æ¬¡æ”¹åŠ¨é€šè¿‡ç¼“å†²â€‘å¤šçº¿ç¨‹å®ç°äº†æ›´å¯æ§çš„å†…å­˜å ç”¨ï¼Œæå‡å¤§æ¨¡å‹åŠ è½½çš„é²æ£’æ€§ï¼Œä½†éœ€è¦å®¡æŸ¥é¡¹ç›®å†…éƒ¨å…¶å®ƒè°ƒç”¨ç‚¹çš„ç­¾åå…¼å®¹ï¼Œå¹¶è¡¥é½åŠ å¯†æƒé‡çš„ç¼ºå¤±å®ç°ã€‚

---

#### ğŸŸ¢ ä½é‡è¦åº¦å˜æ›´ (10)

### [diffusion] feat: opt vae decode with `channels_last_3d`  (#18540)
**SHA**: `4067d94` | ğŸ”— [æŸ¥çœ‹æäº¤](https://github.com/sgl-project/sglang/commit/4067d9487d371eb4e29d626424bd0e1edc8c3ec8)

**ğŸ¯ å˜æ›´ç±»å‹**ï¼šä»£ç é‡æ„  
**âš¡ é‡è¦ç¨‹åº¦**ï¼šğŸŸ¢ä½  
**ğŸ“‹ æ‘˜è¦**ï¼šæ–°å¢ç¯å¢ƒå˜é‡ `SGLANG_DIFFUSION_VAE_CHANNELS_LAST_3D`ï¼Œåœ¨åŠ è½½ VAEï¼ˆåŒ…æ‹¬ video_vaeï¼‰æ—¶å¯é€‰å°† Conv3d æƒé‡è½¬æ¢ä¸º `channels_last_3d` å†…å­˜æ ¼å¼ï¼Œä»¥æå‡æ˜¾å­˜å¸ƒå±€æ•ˆç‡ï¼›å®ç°äº†å¯¹åº”çš„è½¬æ¢å‡½æ•°å’Œæ—¥å¿—ã€‚

---

### Fix  dsv32 encode_messages  (#18126)
**SHA**: `c8aa2a6` | ğŸ”— [æŸ¥çœ‹æäº¤](https://github.com/sgl-project/sglang/commit/c8aa2a65341aaa4a1b23fa7ee734ace4278e37c8)

**ğŸ¯ å˜æ›´ç±»å‹**ï¼šä»£ç é‡æ„  
**âš¡ é‡è¦ç¨‹åº¦**ï¼šğŸŸ¢ä½  
**ğŸ“‹ æ‘˜è¦**ï¼šåœ¨ OpenAI æ¥å£çš„æ¶ˆæ¯å¤„ç†æµç¨‹ä¸­ï¼Œæ–°å¢å¯¹ `content` ä¸º `None` çš„å®¹é”™å¹¶ç»Ÿä¸€è½¬ä¸ºå­—ç¬¦ä¸²ï¼›æ‰©å±• `process_content_for_template_format` æ”¯æŒ DeepSeekâ€‘V3.2 ç¼–ç æ¨¡å¼ï¼Œæå–å¤šæ¨¡æ€æ•°æ®å¹¶åœ¨éœ€è¦æ—¶å°†å†…å®¹åˆå¹¶ä¸ºçº¯æ–‡æœ¬å­—ç¬¦ä¸²ã€‚æ•´ä½“æå‡æ¨¡æ¿æ¸²æŸ“çš„å…¼å®¹æ€§å’Œç¨³å¥æ€§ã€‚

---

### [AMD] Fix sgl-model-gateway Build Errors in ROCm Docker Release  (#18836)
**SHA**: `38473f8` | ğŸ”— [æŸ¥çœ‹æäº¤](https://github.com/sgl-project/sglang/commit/38473f8ee06ac5b6f2074d8bc1f84f88ee7a9da0)

**ğŸ¯ å˜æ›´ç±»å‹**ï¼šé…ç½®è°ƒæ•´  
**âš¡ é‡è¦ç¨‹åº¦**ï¼šğŸŸ¢ ä½  
**ğŸ“‹ æ‘˜è¦**ï¼šåœ¨ AMD ROCm Docker nightly å·¥ä½œæµä¸­æ–°å¢ `SGL_BRANCH` å‚æ•°ä»¥æ­£ç¡®ä½¿ç”¨ä»£ç åˆ†æ”¯ï¼›å°† `sgl-model-gateway` çš„ `Cargo.toml` å¤šä¸ªä¾èµ–ç‰ˆæœ¬ç”±å›ºå®šé”å®šæ”¹ä¸º `~`ï¼ˆæ³¢æµªå·ï¼‰èŒƒå›´ï¼Œä»¥å…¼å®¹ ROCm æ„å»ºå¹¶ä¿®å¤æ„å»ºé”™è¯¯ã€‚

---

### [DLLM] Update CODEOWNERS for diffusion LLM (#18834)
**SHA**: `e2eb5bf` | ğŸ”— [æŸ¥çœ‹æäº¤](https://github.com/sgl-project/sglang/commit/e2eb5bf28d5f06b1e2ee857531cf52648e62b187)

**ğŸ¯ å˜æ›´ç±»å‹**ï¼šæ–‡æ¡£æ›´æ–°  
**âš¡ é‡è¦ç¨‹åº¦**ï¼šğŸŸ¢ä½  
**ğŸ“‹ æ‘˜è¦**ï¼šåœ¨ `.github/CODEOWNERS` ä¸­æ–°å¢ `/python/sglang/srt/dllm` çš„æ‰€æœ‰è€…ï¼ˆ@ClawSeven @btw616ï¼‰ã€‚

---

### [diffusion][MUSA] fix: MUSA platform breakage caused by PR #13662 (#18456)
**SHA**: `45a4697` | ğŸ”— [æŸ¥çœ‹æäº¤](https://github.com/sgl-project/sglang/commit/45a4697d452d294c591c38742491cc478d31c80a)

**ğŸ¯ å˜æ›´ç±»å‹**ï¼šä»£ç é‡æ„  
**âš¡ é‡è¦ç¨‹åº¦**ï¼šğŸŸ¢ä½  
**ğŸ“‹ æ‘˜è¦**ï¼šåœ¨ MUSA å¹³å°å®ç°ä¸­æ–°å¢å¯¹ `envs.LOCAL_RANK` çš„å¼•ç”¨ï¼Œæä¾› `get_local_torch_device` æ–¹æ³•ï¼›åœ¨è·å–å¯ç”¨ GPU å†…å­˜æ—¶åŠ å…¥åˆ†å¸ƒå¼ç¯å¢ƒä¸‹é€šè¿‡ `torch.distributed.get_rank()` ç¡®å®šè®¾å¤‡ ID çš„é€»è¾‘ã€‚

---

### Fix CI concurrency collision between scheduled runs and fork PRs (#18826)
**SHA**: `8ef3e3d` | ğŸ”— [æŸ¥çœ‹æäº¤](https://github.com/sgl-project/sglang/commit/8ef3e3d56be5461de223297dd186bb5fe1b9d11f)

**ğŸ¯ å˜æ›´ç±»å‹**ï¼šé…ç½®è°ƒæ•´  
**âš¡ é‡è¦ç¨‹åº¦**ï¼šğŸŸ¢ä½  
**ğŸ“‹ æ‘˜è¦**ï¼šåœ¨ CI å¹¶å‘ç»„ä¸­åŠ å…¥ `github.event_name`ï¼Œé˜²æ­¢å®šæ—¶ä»»åŠ¡ä¸ Fork PRï¼ˆåˆ†æ”¯åä¸º `main`ï¼‰ç›¸äº’é˜»å¡ã€‚

---

### Handle abort for retracted requests in disagg decode prealloc queue (#18705)
**SHA**: `066b0b7` | ğŸ”— [æŸ¥çœ‹æäº¤](https://github.com/sgl-project/sglang/commit/066b0b70d9803fa3668453bb6aa97e86c7bc330c)

**ğŸ¯ å˜æ›´ç±»å‹**ï¼šä»£ç é‡æ„  
**âš¡ é‡è¦ç¨‹åº¦**ï¼šğŸŸ¢ä½  
**ğŸ“‹ æ‘˜è¦**ï¼šåœ¨ `scheduler.py` ä¸­æ–°å¢å¯¹å·²æ’¤å›è‡³ CPU ç¼“å­˜çš„è§£ç è¯·æ±‚çš„ abort å¤„ç†ï¼Œåˆ é™¤ KV ç¼“å­˜å¹¶å‘ tokenizer å‘é€å¯¹åº”çš„ AbortReqã€‚

---

### [PD-Disagg] Fix double free when prebuilt batch is aborted. (#18822)
**SHA**: `4474fb9` | ğŸ”— [æŸ¥çœ‹æäº¤](https://github.com/sgl-project/sglang/commit/4474fb98b435cf6ebcd6b1e61d9f9463834609b6)

**ğŸ¯ å˜æ›´ç±»å‹**ï¼šä»£ç é‡æ„  
**âš¡ é‡è¦ç¨‹åº¦**ï¼šğŸŸ¢ä½  
**ğŸ“‹ æ‘˜è¦**ï¼šå°†å¼‚å¸¸å¤„ç†æ”¹ä¸ºä½¿ç”¨ `FINISH_ABORT` æ ‡è®°è¯·æ±‚ç»ˆæ­¢ï¼Œç»Ÿä¸€åœ¨ `check_finished` ä¸­é‡Šæ”¾ KV ç¼“å­˜ï¼Œé¿å…é¢„æ„å»ºæ‰¹æ¬¡ä¸­æ­¢æ—¶å‡ºç°åŒé‡é‡Šæ”¾é—®é¢˜ã€‚

---

### Update notified user in post_ci_failures_to_slack.py (#18817)
**SHA**: `710d873` | ğŸ”— [æŸ¥çœ‹æäº¤](https://github.com/sgl-project/sglang/commit/710d873ba6f3fc47e3af3ef7f6c219f396b98238)

**ğŸ¯ å˜æ›´ç±»å‹**ï¼šä»£ç é‡æ„  
**âš¡ é‡è¦ç¨‹åº¦**ï¼šğŸŸ¢ ä½  
**ğŸ“‹ æ‘˜è¦**ï¼šå°† Slack é€šçŸ¥ä¸­æåˆ°çš„ç”¨æˆ· ID ä» `<@U09RR5TNC94>` æ›¿æ¢ä¸º `<@U09R55D8EAY>`ï¼Œä¿æŒå…¶ä»–é€»è¾‘ä¸å˜ã€‚

---

### fix double-free kv cache for requests that have already finished and been freed during preemption  (#18694)
**SHA**: `191d354` | ğŸ”— [æŸ¥çœ‹æäº¤](https://github.com/sgl-project/sglang/commit/191d354f538f81ea383e536f3b4421ed441374d8)

**ğŸ¯ å˜æ›´ç±»å‹**ï¼šä»£ç é‡æ„/bug ä¿®å¤  
**âš¡ é‡è¦ç¨‹åº¦**ï¼šğŸŸ¢ ä½  
**ğŸ“‹ æ‘˜è¦**ï¼šåœ¨ `preempt_to_schedule` ä¸­è¿‡æ»¤å·²å®Œæˆçš„è¯·æ±‚ï¼Œé˜²æ­¢åœ¨æŠ¢å æ—¶å¯¹å·²é‡Šæ”¾çš„ KV ç¼“å­˜äºŒæ¬¡é‡Šæ”¾ï¼›ç›¸åº”åœ°åœ¨æµ‹è¯•ç”¨ä¾‹ä¸­å°† `finished` æ ‡è®°ä¸º `False`ã€‚

---

