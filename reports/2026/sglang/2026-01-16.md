# 每日更新报告（2026-01-16）

## sgl-project/sglang

| 提交时间 | 作者 | 提交信息 |
|----------|------|----------|
| 2026-01-16 22:40:25 | billishyahao | [bugfix] fix qwen3-next alt_stream none issue (#17016) |
| 2026-01-16 20:53:36 | Mohammad Miadh Angkad | [Doc] Tiny docs update for CUDA 13 (#17200) |
| 2026-01-16 20:44:37 | Nicolas Castet | Add clear error message when OOM with symmetric memory (#17038) |
| 2026-01-16 20:35:42 | Raghav Ravishankar | Add AFMoE model implementation (#13216) |
| 2026-01-16 17:55:09 | StonyPort | feat: add request queued timeout (#17143) |
| 2026-01-16 17:01:09 | R0CKSTAR | [diffusion] hardware: support diffusion (single GPU, 3/N) (#17105) |
| 2026-01-16 16:21:04 | Zhiqiang Xie | fix AMD CI failure of NUMA binding (#17184) |
| 2026-01-16 16:16:17 | Adarsh Shirawalmath | [diffusion] model: support flux Klein (#17173) |
| 2026-01-16 15:32:42 | YAMY | [ConfigArgumentMerger] Improve ConfigArgumentMerger compatibility with external callers (#17051) |
| 2026-01-16 13:58:46 | YC Tseng | [AMD] Enable DeepseekV3.2 test for AMD CI (#16934) |
| 2026-01-16 13:02:40 | Chang Su | [model-gateway] Consolidate "unknown" model id usage (#17186) |
| 2026-01-16 12:15:33 | Hudson Xing | ci: enable offline mode when local cache is complete to avoid HF Hub … (#16121) |
| 2026-01-16 12:14:09 | Xiaoyu Zhang | [Diffusion] Hot fix broken output_path default value (#17180) |
| 2026-01-16 12:00:06 | shuwenn | feature: support uvicorn access log filter(disable logging /metrics) (#15513) |
| 2026-01-16 11:10:17 | YAMY | [eval] GSM8k support for run_eval (#17041) |
| 2026-01-16 11:06:14 | b8zhong | [Benchmark] Add GSM8K Platinum Eval (#14565) |
| 2026-01-16 10:38:01 | Lianmin Zheng | Fix grammar sync across TP ranks (#17100) |
| 2026-01-16 10:29:38 | Ratish P | [diffusion] feat: add cloud storage support for API (#14579) |
| 2026-01-16 08:53:06 | hlu1 | Remove deepseek-r1 from THINKING_MODE_CHOICES in run_eval.py (#17178) |
| 2026-01-16 08:13:35 | Qiaolin Yu | Add dpsk-r1-fp4 in nightly perf ci (#16882) |
| 2026-01-16 07:23:35 | Alison Shao | [CI] Reorganize stage-b 1-GPU tests for 5090 compatibility (#16826) |
| 2026-01-16 07:14:38 | PiteXChen | fix【hicache】fix the KV cache resource occupation  and invalid loading from prefetch when pending requests are aborted. (#16369) |
| 2026-01-16 07:12:45 | Alison Shao | Disable unit-test-deepep-8-gpu (#17176) |
| 2026-01-16 06:12:26 | Baizhou Zhang | [Doc] Tiny update Cuda 13 environment instructions (#17174) |
| 2026-01-16 06:11:49 | JinYan Su | feat(hicache): support numa detect to reduce long tail latency (#11028) |
| 2026-01-16 05:30:18 | b8zhong | [Doc] Add tip on how to use Spec V2 (#15455) |
| 2026-01-16 04:25:20 | Yi Zhong | Show how to use cu13 image with B300 (#17170) |
| 2026-01-16 04:15:41 | huangtingwei | Add mooncake store read/write bandwidth logs (#10598) |
| 2026-01-16 03:23:19 | Douglas Yang | fix: adding matrix partitioning for h200 and b200 nightly tests (#17091) |
| 2026-01-16 03:22:18 | Simo Lin | [smg] release 0.3.2 (#17168) |
| 2026-01-16 03:00:53 | Simo Lin | [smg][ci] add make cmd to patch versions (#17167) |
| 2026-01-16 01:29:40 | Guy Stone | [Docs] add v1/score api to native api documentation (#16568) |
| 2026-01-16 01:09:52 | Yi Zhong | docs only add kimi k2 thinking and kimi linear  (#15789) |
| 2026-01-16 01:07:18 | shuwenn | [Docs] sort and update `server_arguments.md` (#17163) |

### 📊 统计摘要
> 本日共 34 个提交 | 🔴高 5 | 🟡中 14 | 🟢低 15
## 📋 目录

- [sgl-project/sglang](#sgl-project-sglang)
  - [📊 统计摘要](#-统计摘要)
  - [🔴 高重要度变更 (5)](#-🔴-高重要度变更-5)
    - [feat: add request queued timeout (#17143)](#3355b6e)
    - [[diffusion] model: support flux Klein (#17173)](#7c39ea6)
    - [[CI] Reorganize stage-b 1-GPU tests for 5090 compatibilit...](#146b5fc)
    - [feat(hicache): support numa detect to reduce long tail la...](#72e2f70)
    - [fix: adding matrix partitioning for h200 and b200 nightly...](#655d2c7)
  - [🟡 中重要度变更 (14)](#-🟡-中重要度变更-14)
    - [Add AFMoE model implementation (#13216)](#daea513)
    - [[diffusion] hardware: support diffusion (single GPU, 3/N)...](#a1dd3d4)
    - [[AMD] Enable DeepseekV3.2 test for AMD CI (#16934)](#968c4f5)
    - [[model-gateway] Consolidate "unknown" model id usage (#17...](#669d309)
    - [ci: enable offline mode when local cache is complete to a...](#21ee597)
    - [feature: support uvicorn access log filter(disable loggin...](#8ec160e)
    - [[eval] GSM8k support for run_eval (#17041)](#2740ed1)
    - [[Benchmark] Add GSM8K Platinum Eval (#14565)](#d44f09a)
    - [Fix grammar sync across TP ranks (#17100)](#e7dc85c)
    - [[diffusion] feat: add cloud storage support for API (#14579)](#c81bad1)
    - [Add dpsk-r1-fp4 in nightly perf ci (#16882)](#e3a9507)
    - [fix【hicache】fix the KV cache resource occupation  and inv...](#8b22dee)
    - [Disable unit-test-deepep-8-gpu (#17176)](#69822c7)
    - [[Docs] add v1/score api to native api documentation (#16568)](#cd23c2f)
  - [🟢 低重要度变更 (15)](#-🟢-低重要度变更-15)
    - [[bugfix] fix qwen3-next alt_stream none issue (#17016)](#6f10e17)
    - [[Doc] Tiny docs update for CUDA 13 (#17200)](#c771933)
    - [Add clear error message when OOM with symmetric memory (#...](#9d8bbd4)
    - [fix AMD CI failure of NUMA binding (#17184)](#d9ed80b)
    - [[ConfigArgumentMerger] Improve ConfigArgumentMerger compa...](#daa4841)
    - [[Diffusion] Hot fix broken output_path default value (#17...](#6ee970a)
    - [Remove deepseek-r1 from THINKING_MODE_CHOICES in run_eval...](#0e86de7)
    - [[Doc] Tiny update Cuda 13 environment instructions (#17174)](#8b99af9)
    - [[Doc] Add tip on how to use Spec V2 (#15455)](#3d72944)
    - [Show how to use cu13 image with B300 (#17170)](#7dde343)
    - [Add mooncake store read/write bandwidth logs (#10598)](#77fc4c4)
    - [[smg] release 0.3.2 (#17168)](#3f44268)
    - [[smg][ci] add make cmd to patch versions (#17167)](#f7ec817)
    - [docs only add kimi k2 thinking and kimi linear  (#15789)](#d1110e1)
    - [[Docs] sort and update `server_arguments.md` (#17163)](#9227d9f)
#### 🔴 高重要度变更 (5)

### feat: add request queued timeout (#17143)
**SHA**: `3355b6e` | 🔗 [查看提交](https://github.com/sgl-project/sglang/commit/3355b6e21b8c031fc2dd9bd446c83c8bc92e34ef)

**🎯 变更类型**：功能增强  
**⚡ 重要程度**：🔴高  
**📋 变更摘要**：新增环境变量 `SGLANG_QUEUED_TIMEOUT_MS`（默认 -1，表示关闭），用于限制请求在调度队列中的最长等待时间。调度器在每轮调度前检测超时请求并以 503 Service Unavailable 中止它们；同时修复请求日志中对 `e2e_latency` 的取值方式，防止 KeyError。新增对应文档说明和单元测试验证超时行为。  

**🎯 影响范围**：  
- `python/sglang/srt/environ.py`（环境变量定义）  
- `python/sglang/srt/managers/scheduler.py`（队列超时检测与中止）  
- `python/sglang/srt/utils/request_logger.py`（日志容错）  
- 文档 `docs/references/environment_variables.md`  
- 测试 `test/registered/scheduler/test_abort.py`  

**🔍 技术洞察**：  
- **架构影响**：  
  - 在调度器的主循环 `get_next_batch_to_run` 前新增 `_abort_on_queued_timeout`，形成“等待队列 → 超时检测 → 中止请求 → 继续调度”的新分支。该分支与已有的 `max_running_requests`、`_abort_on_queued_limit` 互补，保持调度器单例内部状态不变。  
  - 中止操作通过 `self.send_to_tokenizer.send_output(AbortReq(...), req)` 直接发送到 tokenizer，遵循现有的异常传播路径，无需额外同步机制。  

- **性能影响**：  
  - 每次调度前遍历一次 `waiting_queue`（通常规模受 `max-running-requests` 限制），时间复杂度 O(N)。在高并发、队列长度接近上限时会产生轻微的 CPU 开销，但相较于模型推理的成本可以忽略。  
  - 超时检测可以在请求堆积时及时释放资源，防止长时间占用内存和调度槽位，整体对系统吞吐量有潜在正面作用。  

- **安全考虑**：  
  - 返回的错误码为 `HTTPStatus.SERVICE_UNAVAILABLE (503)`，不泄露内部实现细节，符合 HTTP 错误语义。  
  - 环境变量值通过 `EnvInt` 读取，已在 `environ.py` 中限定为整数，未引入代码注入或越界风险。  

**⚠️ 潜在风险**：  
1. **误配置导致业务受影响**：若运营方误将 `SGLANG_QUEUED_TIMEOUT_MS` 设为过小（如 1 ms），正常的排队请求会被频繁 abort，导致显著的 503 错误率。  
2. **并发安全**：`_abort_on_queued_timeout` 在遍历 `waiting_queue` 时先收集待删除请求，再一次性过滤，已避免在遍历期间修改集合导致的迭代错误，但仍需确认调度器在多线程/多进程模式下的锁机制是否足够，防止竞争条件。  
3. **日志兼容性**：`request_logger` 改为 `out["meta_info"].get("e2e_latency", 0)`，若上游代码原本依赖 `e2e_latency` 必定存在的假设，可能导致监控指标缺失，需要确认 downstream 是否有依赖。  

**💡 关注建议**：  
- **配置管理**：在生产环境发布前，建议在灰度环境中设置一个合理的超时阈值（如 500 ms~2000 ms）并观察 503 错误比例，避免因阈值过低导致业务异常。  
- **监控 & 报警**：新增 `scheduler_queue_timeout_abort_total`（或类似）Prometheus 指标，统计因超时被 abort 的请求数量，配合报警规则及时发现异常配置。  
- **文档提示**：在官方文档中明确说明 “-1 表示关闭，正整数为毫秒，建议设置为大于服务端平均排队延迟的数值”。  
- **并发测试**：在多线程 / 多进程负载下运行完整的调度器回归测试，确保 `waiting_queue` 的删除操作在所有并发模型下均保持一致性。  
- **回退方案**：提供快速关闭方式（如环境变量动态重载或通过 API 暂时关闭超时功能），以应对突发的业务异常。  

以上即本次变更的技术评估与建议，供开发与运维团队参考。

---

### [diffusion] model: support flux Klein (#17173)
**SHA**: `7c39ea6` | 🔗 [查看提交](https://github.com/sgl-project/sglang/commit/7c39ea68f3d021eb984650f6d52f9d799246f985)

**🎯 变更类型**：功能增强  

**⚡ 重要程度**：🔴高  

**📋 变更摘要**：  
1. 为 SGLang Diffusion 添加对 **Flux 2‑Klein**（4B/9B）模型的完整支持，包含文档、模型注册、Pipeline 与配置。  
2. 引入 **Qwen‑3** 文本编码器实现，完成权重加载、张量并行、FSDP 支持以及对应的配置类、注册和 Pipeline。  
3. 对 Flux 2 的时间步长与 guidance 嵌入实现可选化，满足 Klein 模型不使用 guidance embeddings 的需求。  

**🎯 影响范围**：  
- `python/sglang/multimodal_gen/configs/*`（新增 Qwen3 配置、Flux2Klein 配置）  
- `python/sglang/multimodal_gen/runtime/models/encoders/qwen3.py`（全新 Qwen3 实现）  
- `python/sglang/multimodal_gen/runtime/models/dits/flux_2.py`（guidance 参数可选）  
- `python/sglang/multimodal_gen/runtime/pipelines/flux_2_klein.py`（新 Pipeline）  
- 文档 `docs/supported_models/diffusion_models.md`、`support_matrix.md`、`README.md`  
- 注册表 `registry.py`（Flux2Klein 注册）  

---

### 🔍 技术洞察  

#### 架构影响  
- **新文本编码器层**：Qwen‑3 通过 `VocabParallelEmbedding`、`RMSNorm`、`QKVParallelLinear`、`MergedColumnParallelLinear` 等模块实现，完整支持张量并行（TP）和 FSDP CPU offload。  
- **Pipeline 扩展**：`Flux2KleinPipeline` 继承自 `Flux2Pipeline`，仅改变 `should_use_guidance = False`、使用 `Qwen3TextConfig`、以及新的 `flux2_klein_postprocess_text`（取第 9/18/27 层的 hidden state 并拼接）。  
- **模型注册**：在 `registry._register_configs` 中为 Klein 添加专属 detector，确保 HF `black-forest-labs/FLUX.2-klein-*` 自动映射到 `Flux2KleinPipelineConfig`。  
- **Guidance 嵌入可选**：`Flux2TimestepGuidanceEmbeddings` 新增 `guidance_embeds` 参数，默认 `True`，Klein 模型实例化时传 `False`，避免不必要的计算与内存占用。  

#### 性能影响  
- **正向推理**：新增 Qwen‑3 编码器在 `hidden_size=2560`、`num_hidden_layers=36` 的情况下，算力需求介于 LLaMA‑2‑7B 与 13B 之间；在 TP 场景下可保持线性扩展。  
- **Guidance 跳过**：对 Klein 模型关闭 guidance embedding，可降低约 15%‑20% 的计算量（取决于 batch size 与 seq_len）。  
- **内存占用**：Qwen‑3 的权重加载使用分块映射（`stacked_params_mapping`），在 8‑GPU 环境下约 12 GB VRAM（BF16），比同规模的 LLaMA‑2 稍高但仍在 H100/4090 可接受范围。  
- **I/O 与调度**：新增 `flux2_klein_postprocess_text` 需要在调度阶段对 hidden states 做一次 `torch.stack` 与 `permute`，开销可忽略（<1 ms）。  

#### 安全考虑  
- **权重加载**：实现了严格的 `name` 映射与 KV‑scale 重命名，防止误加载导致的数值错误或内存泄漏。  
- **外部输入**：新增的 `tokenize_prompt` 对 `apply_chat_template` 包装了异常捕获，兼容不同版本的 tokenizer，避免因接口变化导致的崩溃。  
- **依赖升级**：仅涉及内部代码，无新增第三方依赖，风险极低。  

---

**⚠️ 潜在风险**  

| 风险点 | 说明 | 可能影响 |
|--------|------|----------|
| **张量并行不匹配** | Qwen‑3 的 `total_num_heads` 与 `tp_world_size` 必须整除。若用户在非 2/4/8‑GPU 环境下启动，可能触发断言错误。 | 启动失败 |
| **权重映射遗漏** | `stacked_params_mapping` 只覆盖 `qkv_proj`、`gate_up_proj`；若模型未来添加新子层（如 `ffn_gate_proj`），加载会 silently 忽略。 | 生成质量下降 |
| **Guidance 参数遗漏** | `Flux2TimestepGuidanceEmbeddings` 在 `guidance=None` 时直接返回 `timesteps_emb`，但上层 `Flux2Modulation` 仍会传递 `guidance`（可能为 `None`），若后续代码出现 `guidance.shape` 调用会报错。 | 运行时异常 |
| **文档/注册不一致** | 文档已列出 `FLUX.2‑Klein-9B`，但注册器仅加入 `4B` 与 `9B` 路径，一致性需在 CI 中验证。 | 用户未知模型不可用 |
| **FSDP / CPU Offload** | Qwen‑3 配置的 `_fsdp_shard_conditions` 依赖 `is_transformer_layer`、`is_embeddings`、`is_final_norm`，若层命名发生变化会导致 shard 失效，导致显存激增。 | OOM |

---

**💡 关注建议**  

1. **测试覆盖**  
   - 在多种 TP 配置（1、2、4、8）下跑完整的单元/集成测试，确保 `assert` 不会因不整除而中断。  
   - 增加对 `FLUX.2‑Klein-9B` 的权重加载与推理回归，用与官方基准对比 PSNR/SSIM。  

2. **文档同步**  
   - 确保 `docs/supported_models/*` 与 `registry.py` 中的 `hf_model_paths` 完全匹配，防止用户在 CLI 中看见但实际不可用的模型。  

3. **配置默认**  
   - 在 `pipeline_configs/flux.py` 中为 Klein 提供明确的 `guidance_embeds=False` 默认值，避免用户手动覆盖导致隐蔽 bug。  

4. **监控 & Profiling**  
   - 在生产环境开启显存/算力监控，记录 Qwen‑3 编码阶段的 GPU 使用峰值，提供调优建议（如开启 `torch.compile` 或 BF16）。  

5. **兼容性回退**  
   - 为 `Qwen3TextConfig` 增加 `fallback_to_lora` 或 `use_original_weights` 标记，方便在 LoRA 调优或量化模型时快速切换。  

6. **安全审计**  
   - 复审 `weight_loader` 中的 `maybe_remap_kv_scale_name` 逻辑，确保在未来添加新名称时不会误删或错写。  

7. **CI 检查**  
   - 在 CI 中加入对 `Flux2KleinPipeline` 的自动化生成示例（`sgl generate ... --model black-forest-labs/FLUX.2-klein-4B`），确保 end‑to‑end 流程完整。  

通过上述措施，可在保持新模型强大功能的同时，降低兼容性、资源占用和潜在崩溃风险，提升 SGLang Diffusion 在多模态生成场景的可靠性与可维护性。

---

### [CI] Reorganize stage-b 1-GPU tests for 5090 compatibility (#16826)
**SHA**: `146b5fc` | 🔗 [查看提交](https://github.com/sgl-project/sglang/commit/146b5fcc84101123baf743eb9480ad7ce60a0e92)

**🎯 变更类型**：重构 / 架构变更（CI 工作流重组，使 stage‑b 1‑GPU 测试兼容 RTX 5090）

**⚡ 重要程度**：🔴 高  

**📋 变更摘要**  
1. 在 GitHub Actions 中新增 `1-gpu-5090` Runner，统一在同一作业中以 `IS_BLACKWELL="1"` 标记 Blackwell GPU（RTX 5090），并将原先专门针对 5090 的 `stage-b-test-small-1-gpu-5090` job 删除。  
2. 调整 `stage-b-test-small-1-gpu` 的并行度与分区数（`max-parallel` 从自动改为 4、partition 从 0‑13 降至 0‑7），并在运行前统一加载 `sglang-ci.sh` 环境变量。  
3. 大量同步更新测试注册（`register_cuda_ci`/`register_amd_ci`）的目标 suite：把原本只在 “small‑1‑gpu‑5090” 里运行的测试迁移到 “large‑1‑gpu” 或直接移除 5090‑specific 条目。  
4. 对部分模型、量化、MoE、VLM、Eagle 等子目录的 CI 注册顺序做了微调，使其在新的 “large‑1‑gpu” 套件中执行，保持原有的执行时长估算。  

**🎯 影响范围**  
- CI 流水线：`.github/workflows/pr-test.yml`、`test/run_suite.py`  
- 所有 `test/registered/**` 中的 CI 注册脚本（几百个 `register_cuda_ci` 调用）  
- 依赖的 Runner 标签：`1-gpu-runner` → `1-gpu-5090`（Blackwell）  
- CI 环境变量 `IS_BLACKWELL`、`SGLANG_CI` 脚本  

**🔍 技术洞察**  

| 维度 | 影响描述 |
|------|----------|
| **架构影响** | - 将原本针对 RTX 5090 的独立 job 合并到通用的 `stage-b-test-small-1-gpu`，简化了 CI DAG，降低了维护成本。<br>- 通过 `IS_BLACKWELL=1` 环境变量让测试代码自行感知是否在 Blackwell GPU 上运行，避免了在 CI 配置层面硬编码硬件差异。 |
| **性能影响** | - `max-parallel` 从自动上限降至固定 4，配合分区数从 14 → 8，单次提交的 CI 时长会略有下降（总体并行度下降），但每个分区的负载变重，可能导致单机 GPU 使用率上升。<br>- 删除 `stage-b-test-small-1-gpu-5090` 后，原本专门在 24 GB GPU 上跑的低显存子集（FP8、FA3 等）不再单独跑，改为在 `large‑1‑gpu`（使用 24 GB+ GPU）上执行，可能出现显存不足的风险。 |
| **安全考虑** | - 仅涉及 CI 编排，无代码运行时安全影响。<br>- 新增的 `source /etc/profile.d/sglang-ci.sh` 可能引入环境变量泄露风险，但该文件是内部 CI 脚本，访问受限于 GitHub Actions runner，风险极低。 |
| **可维护性** | - 移除大量 “‑5090” 的冗余注册，统一使用 `stage-b-test-large-1-gpu`，代码可读性提升。<br>- 需要在项目文档（CI 运行指南、硬件需求）同步更新，防止新贡献者误以为仍需维护 `‑5090` suite。 |
| **兼容性** | - 已经在 `stage-b-test-large-2-gpu`（H200）保留了对高显存、SM 90 的专门测试，确保 Blackwell 兼容性仍被间接验证。<br>- 对于只能在 24 GB GPU 上跑的某些低显存模型（如 `test_create_kvindices`、`test_mamba_*_5090` 等），已经迁移到 `large‑1‑gpu`，需要确认这些模型在实际 RTX 5090（24 GB）上仍能顺利通过。 |

**⚠️ 潜在风险**  

1. **显存/硬件适配回归**  
   - 部分原本只在 “small‑1‑gpu‑5090” 运行的测试现在在 “large‑1‑gpu”（可能使用 24 GB RTX 4090/8090）上执行，如果实际运行的 GPU 显存不足（如在 CI 中使用 16 GB GPU），会出现 OOM 导致 CI 失效。  
2. **并行度下降导致整体 pipeline 时长波动**  
   - `max-parallel` 固定为 4，若 CI 机器上可用 GPU 更多（如 8 卡），未能充分利用，导致更长的提交检查时间。  
3. **误删/遗漏的 5090‑Only 测试**  
   - 部分测试文件仅删除了注册行，但仍保留对特定硬件特性的代码路径（如 FP8、FA3），若这些路径在 RTX 5090 上有已知缺陷，缺少专门的 dry‑run 验证可能导致回归。  
4. **环境变量依赖**  
   - 代码中任何使用 `os.getenv("IS_BLACKWELL")` 的分支若未做好默认处理，可能在非‑Blackwell runner（如普通 1‑gpu‑runner）上出现未预期的行为。  

**💡 关注建议**  

1. **显存检测与容错**  
   - 在测试入口（`run_suite.py`）加入显存检查：`if torch.cuda.get_device_properties(0).total_memory < X: skip`，确保在显存不足的 runner 上自动跳过不兼容的子测试。  
   - 对关键的 FP8/FA3/高 VRAM 测试在 `register_cuda_ci` 中使用 `disabled` 或 `skip_if` 参数，显式注明 “仅在 RTX 5090 / H200 上执行”。  

2. **并行度弹性**  
   - 将 `max-parallel` 恢复为 `${{ fromJson(needs.check-changes.outputs.max_parallel) }}` 或在 CI 中依据 `runner.labels` 动态计算，以适配多卡环境。  
   - 同时在 `stage-b-test-large-1-gpu` 的 `strategy.matrix.partition` 增大到 0‑13（或根据实际 GPU 数量调节），防止单分区运行时间过长。  

3. **文档同步**  
   - 更新 `README-CI.md`、`CONTRIBUTING.md` 中的 “GPU runner 标签” 与 “Blackwell compatibility” 部分，明确 **不再需要** `stage-b-test-small-1-gpu-5090`，所有 5090 相关测试已统一到 `large‑1‑gpu`。  
   - 在 PR 模板或 CI 检查脚本中加入提示：若新增只能在 24 GB GPU 上跑的测试，请使用 `suite="stage-b-test-large-1-gpu"` 并在代码中加 `IS_BLACKWELL=1` 判定。  

4. **监控与回滚**  
   - 在 GitHub Actions 中添加一个“后续检查” job，对最近 3 天的 `stage-b-test-large-1-gpu` 失败率做统计，如果出现 OOM 或 Blackwell‑only 失效的聚类错误，触发自动提醒并考虑回滚到原先的 `‑5090` job。  

5. **测试覆盖验证**  
   - 在本地或专用 CI 环境使用真实 RTX 5090（或 H200）跑一次完整的 `large‑1‑gpu` suite，确保所有迁移的测试仍能通过。  
   - 对于已删除的 `‑5090` suite，保留一个 “dry‑run” 手动触发的入口（如通过 `/rerun-stage`），以便在需要时单独验证 5090 兼容性。  

通过上述措施，可在保持 CI

---

### feat(hicache): support numa detect to reduce long tail latency (#11028)
**SHA**: `72e2f70` | 🔗 [查看提交](https://github.com/sgl-project/sglang/commit/72e2f70ef741035a5a621747d3d3b2dfb286f67f)

**🎯 变更类型**：功能增强（feat）  
**⚡ 重要程度**：🔴 高  

**📋 变更摘要**  
1. 在层级缓存（hicache）初始化阶段新增对 NUMA（Non‑Uniform Memory Access）节点的检测与绑定，默认开启，可通过 `--disable-hicache-numa-detect` 关闭。  
2. 为实现该功能，新增一套实用函数（`bind_to_closest_numa_node`、`get_current_device_numa_node` 等），并对 `get_physical_device_id` 进行参数化改造。  
3. 同时对 benchmark 脚本 `bench_multiturn.py` 加入更细粒度的性能统计（p99、max）并抽象了百分位计算函数，提高可读性与可复用性。  

**🎯 影响范围**  
- 核心缓存模块：`python/sglang/srt/mem_cache/hiradix_cache.py`  
- 服务器配置与 CLI：`python/sglang/srt/server_args.py`  
- 公共工具函数：`python/sglang/srt/utils/common.py`  
- 基准测试脚本：`benchmark/hicache/bench_multiturn.py`  
- 依赖的外部库：`libnuma`、`nvidia-smi`（通过子进程调用）

---

### 🔍 技术洞察  

| 维度 | 影响描述 |
|------|----------|
| **架构影响** | - 引入了 **NUMA 绑定层**，在进程启动后立即将 CPU 亲和性绑定到与当前 CUDA 设备最近的 NUMA 节点，避免跨节点的内存访问，符合高性能计算（HPC）常见的 “CPU‑GPU 亲和” 设计。<br>- `ServerArgs` 中新增 `disable_hicache_numa_detect` 参数，保持向后兼容；所有已有业务路径仍可正常运行。 |
| **性能影响** | - 通过 **NUMA 亲和**，层级缓存的内存分配与访问更可能落在同一 NUMA 节点，显著降低 **长尾延迟（tail latency）**，尤其在多卡多进程场景下。<br>- 新增的 benchmark 统计（p99、max）帮助用户更直观地评估延迟分布。<br>- 可能引入极小的启动时开销（一次 `nvidia‑smi` 调用、`libnuma` 初始化），相对于整体吞吐量影响可忽略。 |
| **安全考虑** | - 代码通过 `ctypes` 加载系统库 `libnuma.so` 并执行 `numa_run_on_node`、`numa_set_preferred`，这些调用本身是系统级的 **CPU 亲和** 操作，不涉及特权提升，风险极低。<br>- 使用 `subprocess.run` 调用 `nvidia-smi`，已显式指定 `check=True`，若命令失败会抛异常，避免返回错误的 NUMA 信息导致错误绑定。<br>- 对外部依赖（`nvidia-smi`、`libnuma`）未做权限检查，假设运行环境已被信任（典型的科研/服务器场景）。 |
| **可维护性** | - 将 NUMA 相关逻辑集中在 `utils/common.py`，实现了 **单一职责**，后续修改或替换实现更方便。<br>- `get_physical_device_id` 改为接受逻辑设备 ID，提升函数可复用性，兼容 `CUDA_VISIBLE_DEVICES` 多卡情况。<br>- 新增 `@lru_cache` 缓存 `get_current_device_numa_node`，避免重复子进程调用。 |
| **兼容性** | - 默认行为仍是 **启用** NUMA 绑定，若部署环境缺少 `libnuma` 或 `nvidia-smi`，调用 `is_numa_available()` 将返回 `False`，进而跳过绑定，不会导致启动失败。<br>- 通过 CLI 开关 `--disable-hicache-numa-detect`，可以在不想使用 NUMA（如容器化环境）时显式关闭。 |

---

### ⚠️ 潜在风险  

1. **依赖缺失或版本不匹配**  
   - 若系统未安装 `libnuma.so` 或 `nvidia-smi` 不在 `PATH`，`is_numa_available()` 会返回 `False`，但在 `bind_to_closest_numa_node` 仍会尝试调用 `numa_bind_to_node`，可能抛出 `SystemError`。建议在调用前再次检查 `is_numa_available()` 或捕获异常。  

2. **多进程/容器环境的 CPU 亲和冲突**  
   - 在容器或 Kubernetes 中，容器的 CPU 配额可能与宿主机的 NUMA 拓扑不匹配，强制绑定到某个 NUMA 节点可能导致 **CPU 资源不足** 或 **调度冲突**。  
   - 对于使用 `torch.distributed` 多进程的部署，需要确保每个进程在不同 GPU 上时，各自绑定的 NUMA 节点不同，否则会产生资源竞争。  

3. **性能回退**  
   - 在单 NUMA 节点或显存与 CPU 亲和度本就相同的机器上，额外的 `nvidia-smi` 调用和绑定操作几乎没有收益，且会增加微小的启动延迟。  

4. **错误的 NUMA 信息解析**  
   - `nvidia-smi topo -C -i <gpu>` 的输出格式可能随驱动版本改变，当前实现仅解析形如 `NUMA IDs of closest CPU: X` 的单值情况。若未来出现多值或不同前缀，代码会进入回退逻辑，可能产生不均衡的节点分配。  

---

### 💡 关注建议  

| 对象 | 建议 |
|------|------|
| **开发者** | - 为 `bind_to_closest_numa_node` 增加 **异常捕获**，在 `RuntimeError`/`OSError` 时记录警告并安全返回，避免因为系统环境问题导致整个服务启动失败。<br>- 在 CI 测试中加入 **NUMA 可用性检测**（Mock `libnuma`），确保逻辑在无 NUMA 环境下仍能通过。 |
| **运维/部署** | - 确认目标机器已装有 `numactl`（提供 `libnuma.so`）以及 `nvidia-smi`，并在容器镜像中加入相应的二进制。<br>- 对于容器化部署，建议 **显式设置 CPU 亲和**（如 `--cpuset-cpus`），与 `bind_to_closest_numa_node` 的绑定保持一致，防止冲突。 |
| **使用者** | - 在多卡、多进程场景下，若观察到 **CPU 亲和冲突**（如 `numactl: failed to set affinity`），可使用 `--disable-hicache-numa-detect` 关闭该特性。<br>- 通过 `sglang bench_multiturn.py` 提供的 p99 与 max 延迟指标，评估 NUMA 绑定是否带来实际收益，必要时对比 `--disable-hicache-numa-detect` 前后的结果。 |
| **未来改进** | - 将 NUMA 绑定抽象为 **插件**，允许用户自定义 “绑定策略”（如 round‑robin、手动指定节点）。<br>- 考虑在 `get_current_device_numa_node` 中加入 **缓存失效** 机制，以兼容 GPU 动态迁移（如 MIG）或系统拓扑变更。 |

---  

**结论**：本次提交在层级缓存的启动流程中加入了 NUMA 亲和检测与绑定，能够在具备多 NUMA 节点的 GPU 服务器上有效降低内存访问跨节点导致的长尾延迟，提升整体吞吐与响应一致性。实现上保持向后兼容并提供关闭开关，风险主要集中在外部依赖与容器化环境的 CPU 亲和冲突。建议在生产部署前验证系统的 NUMA 能力并做好异常捕获，以确保新功能平滑落地。

---

### fix: adding matrix partitioning for h200 and b200 nightly tests (#17091)
**SHA**: `655d2c7` | 🔗 [查看提交](https://github.com/sgl-project/sglang/commit/655d2c7c2aa42d7b097498a2c0d48cd697aeda61)

**🎯 变更类型**：Bug修复 / CI改进  
**⚡ 重要程度**：🔴高  
**📋 变更摘要**：  
- 为 NVIDIA H200 与 B200 8‑GPU nightly 测试工作流加入矩阵分区（partition），将原本一次性执行的测试集拆分为 3 份并行运行，降低单节点超时风险。  
- 同时在 8‑GPU 模型测试注册文件中统一把 `est_time` 调整为更合理的值（多数降至 1800 s，DeepSeek 系列降至 5400 s），使 CI 调度更精准。

**🎯 影响范围**：  
- `.github/workflows/nightly-test-nvidia.yml`（H200 与 B200 两个 nightly job）  
- `test/registered/8-gpu-models/` 目录下的 12 份模型测试注册脚本

**🔍 技术洞察**  

- **架构影响**：  
  - 仅在 CI 层面增加 GitHub Actions 的矩阵策略 (`strategy.matrix.partition`)，不涉及运行时代码或库的架构改动。  
  - 通过 `--auto-partition-id` 与 `--auto-partition-size` 参数将测试套件内部的自动分区功能激活，依赖现有的 `run_suite.py` 实现，保持向后兼容。

- **性能影响**：  
  - **正向**：将原本一次性执行的全部 8‑GPU 测试拆分为 3 组并行，可显著缩短每个 runner 的执行时长，降低因超时导致的 job 失败率。  
  - **负向**：分区后每组仍会占用完整的 8‑GPU 资源，整体资源消耗（GPU‑hours）略有提升；若分区不均衡，某些分区可能仍出现资源瓶颈。  
  - 调整后的 `est_time` 参数帮助调度系统更准确预估资源需求，进一步提升 CI 效率。

- **安全考虑**：  
  - 变更局限于 CI 配置与测试元数据，无新增代码执行路径，未引入安全风险。  
  - 需确认 `run_suite.py` 对 `--auto-partition-id/size` 参数的解析安全可靠，避免潜在的参数注入或路径遍历（已在项目中实现安全检测）。

**⚠️ 潜在风险**  

1. **分区不均衡**：若测试用例分布不均导致某一分区显著耗时，会出现“单分区超时”而其他分区正常的情况，影响整体 nightly 通过率。  
2. **参数兼容性**：`--auto-partition-id` 与 `--auto-partition-size` 需要在 `run_suite.py` 中正确解析；若旧版分支或本地重复运行未带此参数，可能出现测试遗漏或重复执行。  
3. **资源争用**：3 个并行 job 同时占用 8‑GPU 节点，若集群资源紧张可能导致调度延迟或排队超时。  
4. **估算时间失准**：部分模型的 `est_time` 调整幅度较大（如从 12000s 降至 1800s），若实际运行时间仍远超预估，调度器仍可能错误触发超时或资源不足警告。

**💡 关注建议**  

- **监控分区分布**：在首次运行后通过 CI 报表检查每个 `partition` 的实际耗时，必要时调整 `auto-partition-size` 或在 `run_suite.py` 中实现更精细的用例分配策略。  
- **回滚方案**：保留未使用矩阵策略的旧 job 定义（可通过条件 `if: false` 暂时保留），在出现分区异常时快速回滚到单一 job。  
- **文档更新**：在项目的 CI/Testing 文档中注明 `--auto-partition-id` 与 `--auto-partition-size` 的用途、取值范围及常见故障排查方法。  
- **资源配额评估**：与 CI 基础设施团队确认同时运行 3 个 8‑GPU job 是否会影响其他流水线，必要时在 `concurrency` 或 `resource_group` 中添加限制。  
- **持续更新 `est_time`**：建议在每次模型测试完成后自动上报实际执行时间，以便后续对 `register_cuda_ci(est_time=…)` 参数进行更加精准的调整。

---

#### 🟡 中重要度变更 (14)

### Add AFMoE model implementation (#13216)
**SHA**: `daea513` | 🔗 [查看提交](https://github.com/sgl-project/sglang/commit/daea51385d2e6b81e1ff2623e10752b1538e2e4d)

**🎯 变更类型**：功能增强  
**⚡ 重要程度**：🟡 中  
**📋 变更摘要**：为 SGLang 添加了完整的 **AfMoE**（Mixture‑of‑Experts）模型实现，新增 `AfmoeConfig`、`AfmoeForCausalLM` 及其内部层、注意力、MLP、MoE 逻辑；在配置注册、文档与 HF 工具中加入对应入口。  

**🎯 影响范围**  
- **模型加载/推理**：`python/sglang/srt/models/afmoe.py` 引入大量新层（`AfmoeAttention、AfmoeMLP、AfmoeMoE`），涉及张量并行、RMSNorm、RadixAttention、fused_moe（triton）等。  
- **配置体系**：`sglang/srt/configs/afmoe.py`、`__init__.py`、`hf_transformers_utils.py` 新增注册，影响 `from_pretrained` 的模型发现。  
- **文档**：`supported_models/generative_models.md` 增加对 Trinity‑MoE 系列的说明。  
- **权重加载**：新增 `AfmoeForCausalLM.load_weights`，处理 HF 权重的堆叠、路由门权重等。  

**💡 关注建议**  
1. **单元/集成测试**：新增模型的每一层（尤其 `AfmoeMoE` 的 `fused_moe`、`TopK`、`grouped_topk`）需覆盖 FP32 与量化路径，验证 TP（tensor‑parallel）下的分片与 all‑reduce 正确性。  
2. **路由行为**：`score_func="sigmoid"` 与 `softmax` 两种路由的归一化、bias 处理已写在 `_custom_routing_function`，请确保在实际 HF 权重（`router.gate`）中对应字段名的兼容性。  
3. **性能基准**：AfMoE 引入大量并行算子，建议在不同 TP 大小（1、2、4、8）上跑一次吞吐/延迟基准，确保 `fused_moe` 的分块大小与 `MoeRunnerConfig.inplace` 配置匹配。  
4. **异常容错**：`load_weights` 中对未知/缺失参数的 “skip” 逻辑可能掩盖错误，建议在调试模式下加入日志报警，防止模型结构与权重不匹配。  
5. **文档同步**：更新 `README`、模型列表及示例脚本，说明 `AfmoeConfig` 必填字段（`num_experts`、`num_experts_per_tok` 等），并提供 `torchrun` 启动时的 TP/PP 参数示例。  

**总体评估**：本次提交为 SGLang 引入了全新的 MoE 推理后端，改动范围大但结构清晰。只要通过上述测试与基准验证，即可安全合并，并为社区提供对 Trinity‑MoE 系列的高效支持。

---

### [diffusion] hardware: support diffusion (single GPU, 3/N) (#17105)
**SHA**: `a1dd3d4` | 🔗 [查看提交](https://github.com/sgl-project/sglang/commit/a1dd3d48ac2352de6014b65d40077e9a7666954d)

**🎯 变更类型**：功能增强  
**⚡ 重要程度**：🟡 中  
**📋 变更摘要**：在 `sglang` 中新增对 **MUSA（MThreads）GPU** 的完整平台抽象，并为 diffusion 模型提供对应的依赖与安装选项；同时在分布式初始化、DITS 系列模型的 `dtype` 选取、平台插件注册等多处加入对 `MUSA` 的兼容逻辑。  
**🎯 影响范围**：`python/sglang/multimodal_gen/runtime/platforms/*`（新增 `musa.py`、平台插件注册）、`parallel_state.py`、`dit*` 模型实现、`pyproject.toml`/`pyproject_other.toml`（新增 `diffusion_musa`、`all_musa`、`dev_musa`），以及 Dockerfile 与文档。  

**💡 关注建议**  
1. **torch 接口统一**：当前 `MusaPlatform` 中仍使用 `torch.cuda.*`（如 `torch.cuda.get_device_properties`），在仅装有 `torch-musa` 的环境下可能报错，建议统一改为 `torch.musa.*` 或在运行时做别名适配。  
2. **依赖可用性**：`pymtml` 为 MTML 库，若用户未安装会在插件加载阶段抛异常。请确保在 `pyproject` 中声明可选依赖或在代码里捕获 `ImportError`，避免 `docker build` 失败。  
3. **平台检测顺序**：`resolve_current_platform_cls_qualname` 先检查 CUDA/ROCM/MPS，再 fallback 到 MUSA。若机器同时装有 CUDA 与 MUSA，MUSA 可能被误判为主平台。可以在文档说明优先级或提供显式环境变量切换。  
4. **单元测试**：新增针对 `musa_platform_plugin`、`is_musa`、`dtype` 分支的测试，确保分布式初始化时 `extra_args` 正确为空。  
5. **文档同步**：README 与平台说明已更新，但仍缺少对 `diffusion_musa` 的使用示例，建议补充。  

总体来看，此次 PR 为 MUSA GPU 打通了完整的运行时链路，是对多硬件支持的重要补充；但需注意上述兼容性细节，以防在仅装 MUSA 环境下出现意外的 `torch.cuda` 调用错误。

---

### [AMD] Enable DeepseekV3.2 test for AMD CI (#16934)
**SHA**: `968c4f5` | 🔗 [查看提交](https://github.com/sgl-project/sglang/commit/968c4f55b194a18f41a5cdda78d6ab625aaa84fb)

**变更类型**：功能增强 / CI 扩展  

**重要程度**：🟡 中  

**变更摘要**  
1. CI 工作流 `.github/workflows/pr-test-amd.yml` 引入 `part` 参数，将原本的大型 AMD 测试套件按 3 份并行执行，避免单个 job 超时。  
2. 启动容器脚本 `scripts/ci/amd_ci_start_container.sh` 新增 `PYTHONPATH="/opt/tilelang:${PYTHONPATH:-}"`，为后端 `tilelang` 提供 Python 模块搜索路径。  
3. 新增两套 DeepSeek‑V3.2 测试（basic + mtp），包括模型启动、few‑shot GSM8K 评估、单句基准以及多步预估（EAGLE）性能阈值。针对 AMD 环境自动开启 `tilelang` backend，并在非 AMD CI 上通过 `skipIf` 规避。

**影响范围**  
- **CI 体系**：AMD CI 现在会生成 3× 更细粒度的 job；每个 job 仍会拉取模型、启动服务器，可能略增整体资源消耗。  
- **容器镜像**：新增 `PYTHONPATH` 可能对其他非 AMD job 的 Python 导入产生影响（若 `/opt/tilelang` 不存在会被忽略，但若存在会被提前搜索）。  
- **测试套件**：`test/registered/amd/` 下的两组新文件会在 AMD CI 中跑，涉及大量 GPU 资源（8 GPU, TP/DP = 8），可能导致资源占用峰值上升。  
- **代码路径**：使用 `--nsa-prefill-backend`、`--nsa-decode-backend` 参数的地方，只有 AMD CI 会触发 `tilelang`，对其他平台保持兼容。

**关注建议**  
1. **资源评估**：确认 CI 额外的 3 × 并行 job 不会踩满自托管的 AMD GPU 队列，必要时在 CI 配额或调度上做预留。  
2. **环境隔离**：`PYTHONPATH` 的追加应在容器镜像中确保 `/opt/tilelang` 只在 AMD 镜像里存在，避免意外影响 CPU/GPU CI。可以改为 `-e PYTHONPATH="${PYTHONPATH:-}:/opt/tilelang"`。  
3. **模型下载**：DeepSeek‑V3.2‑Exp 体积较大，首次运行会耗时并可能触发网络/存储配额报警，建议在 CI 前缓存模型或使用 `--model-loader-extra-config` 的 `num_threads` 参数调优。  
4. **阈值容忍**：性能断言（speed > 10 token/s on AMD, > 35 token/s for mtp）相对宽松，但仍要关注未来硬件或驱动升级导致波动。可在 CI 报告中加入实际测得值的可视化，便于趋势监控。  
5. **回滚路径**：若新测试导致 CI 持续失败，可通过 `skipIf(is_in_amd_ci())` 临时关闭，或在工作流中加 `continue-on-error` 仅对该 matrix 项生效，保证主线 PR 不被卡住。  

总体而言，此次改动为 AMD 平台引入了 DeepSeek‑V3.2 的功能验证，覆盖了单卡、DP、MTP 与预估三大场景，提升了平台兼容性和回归保障，只要妥善管理资源与环境隔离即可安全合入。

---

### [model-gateway] Consolidate "unknown" model id usage (#17186)
**SHA**: `669d309` | 🔗 [查看提交](https://github.com/sgl-project/sglang/commit/669d309a8bf71238dfb790eb1f5b0ee8fdce387b)

**🎯 变更类型**：功能增强（统一“unknown”模型 ID）  
**⚡ 重要程度**：🟡 中  
**📋 变更摘要**：在 `sgl-model-gateway` 中引入 `UNKNOWN_MODEL_ID` 常量，用以统一对未指定或未知模型的标识。原先散落在代码里的 `"default"`、`"unknown"` 等硬编码字符串被全部替换为该常量，涉及缓存感知策略、Worker 选择、HTTP/GRPC 路由、模型网格同步以及 tokenizer 回退逻辑。  

**🎯 影响范围**  
- `core::UNKNOWN_MODEL_ID`（新增）  
- `CacheAwarePolicy::normalize_mesh_model_id`（mesh 同步键）  
- 所有 `Metrics::record_worker_selection` 调用的 `model_id` 默认值  
- HTTP/GRPC 路由层的模型 ID 解析  
- `tokenize::handlers::get_tokenizer` 的回退判断  
- 对应单元测试的默认模型名改为 `UNKNOWN_MODEL_ID`  

**💡 关注建议**  
1. **常量导出与文档**：`UNKNOWN_MODEL_ID` 现在是公共常量，建议在 `core` 模块的文档里明确说明其语义（“未指明模型”），并在 CHANGELOG 中记录迁移指南，防止老代码仍写死 `"default"`。  
2. **兼容性检查**：其他子仓库（如 `sgl-models`、`sgl-cli`）若仍使用 `"default"` 进行模型路由，需同步改为 `UNKNOWN_MODEL_ID`，否则可能出现 mesh 同步不一致或度量标签错位。  
3. **性能影响**：仅是字符串常量替换，对运行时无额外开销；但 `CacheAwarePolicy::normalize_mesh_model_id` 现在只检查空串，若仍有旧代码显式传 `"unknown"`，会被当作真实模型名，建议在上层统一把 `"unknown"` 转为 `UNKNOWN_MODEL_ID`，或在该函数中保留对 `"unknown"` 的兼容判断。  
4. **测试覆盖**：新增了对 `UNKNOWN_MODEL_ID` 的单元测试，建议扩展到缓存、负载均衡以及 mesh 同步的端到端测试，确保在无模型 ID 场景下仍能正确创建/同步树结构。  
5. **日志与监控**：记录的 `model_id` 现在会出现 `UNKNOWN_MODEL_ID`，监控面板可能需要添加相应的过滤/别名，以免误判为异常。  

总体来看，此次改动统一了“未知模型”标识，提升代码可读性和一致性，风险主要在于老代码的硬编码仍未迁移。完成上述兼容检查与文档更新后即可安全发布。

---

### ci: enable offline mode when local cache is complete to avoid HF Hub … (#16121)
**SHA**: `21ee597` | 🔗 [查看提交](https://github.com/sgl-project/sglang/commit/21ee597e4a56a3d2ab87b8bd008ccfe35c6e52d2)

**🛠️ 核心变更**  
1. **模型配置加载 (`model_config.py`)**：在读取 `hf_quant_config.json` 前先检查 `HF_HUB_OFFLINE`，离线模式下直接跳过 `hf_api.file_exists` 调用，改为 `local_files_only=True` 下载/读取本地缓存，避免 `OfflineModeIsEnabled` 异常。  
2. **模型权重加载 (`loader.py`)**：所有 `from_pretrained` / `from_safetensors` 调用都加入 `local_files_only=HF_HUB_OFFLINE`，保证离线环境下不触发网络请求。  
3. **CI 侧缓存校验 (`ci_weight_validation.py`)**：实现 **完整性校验**（config、tokenizer、权重、`hf_quant_config.json`、`auto_map` 等），写入 **snapshot‑level 标记**（`VALIDATION_MARKER_VERSION=5`），支持 **每次 CI 运行的 per‑run marker**，并提供轻量/详细两套校验函数。  
4. **测试工具 (`test_utils.py`)**：在启动服务器前先调用 `_try_enable_offline_mode_if_cache_complete`，读取 per‑run 标记并在必要时设置 `HF_HUB_OFFLINE=1`；若离线启动失败会 **回退到在线模式** 并删除标记。  
5. **CI 初始化脚本**：`prepare_runner.sh` 增加 `prevalidate_cached_models.py`，在 runner 启动时遍历 `~/.cache/huggingface/hub/`，对每个快照执行完整校验并输出详细错误，**不再写全局 marker**，只留下 per‑run marker。  

**📦 影响范围**  
- **模型加载路径**：所有通过 `sglang.srt` 加载的 HuggingFace 模型（包括 ModelOpt、AWQ、GPTQ、Diffusers）现在受 `HF_HUB_OFFLINE` 控制。  
- **CI 流程**：CI 机器在每次跑测试前会预先验证缓存完整性，未完整的模型仍会走在线模式；离线模式可显著提升 CI 速度。  
- **本地运行**：若手动设置 `HF_HUB_OFFLINE=1`，只要本地缓存满足校验条件即可无网络启动，否则会回退或报错。  

**🔍 关注建议**  
1. **标记清理**：per‑run 标记保存在 `/tmp/sglang_ci_offline_markers`，CI 结束后未显式删除，可能残留占用磁盘。建议在 `cleanup_hf_cache.py` 或 CI 完结脚本中统一清理该目录。  
2. **并发安全**：多个测试进程可能同时写同一个 per‑run 标记（同快照），使用 `tempfile.NamedTemporaryFile → os.replace` 已避免冲突，但仍需确认文件系统对原子替换的兼容性（如 NFS）。  
3. **跨平台兼容**：`os.replace`、`tempfile` 在 Windows 上表现略有差异，CI 主要跑 Linux，但若用户在 Windows 本地离线运行，需验证标记写入/读取不抛异常。  
4. **性能成本**：完整校验会递归遍历快照并解析多个 JSON，CI 脚本对总时长设了 5 min 限制；在模型数量极多的缓存（>千个）时仍可能拖慢 runner 启动，建议在 CI 环境通过 `HF_HUB_OFFLINE=1` 直接跳过不需要的模型或限制扫描深度。  
5. **回退逻辑**：离线启动失败后会删除 per‑run 标记并重新启动在线。确保 `kill_process_tree` 在异常情况下不会留下僵尸进程；可在 `finally` 块里再次确认子进程已结束。  
6. **向后兼容**：对旧版 `sglang`（未使用 CI）仍保持相同行为，因为默认 `HF_HUB_OFFLINE` 为 `0`，只在 CI 环境调用 `is_in_ci()` 时激活。若有用户自行在本地设置 `HF_HUB_OFFLINE=1`，仍会进行完整校验，若缓存不完整会自动回退到在线，这一点需要在文档中明确。  

**结论**：本次 PR 大幅提升 CI 离线运行的可靠性与速度，同时让本地离线模式更安全。只要注意标记管理、跨平台测试以及对异常回滚的资源清理，即可平滑投产。

---

### feature: support uvicorn access log filter(disable logging /metrics) (#15513)
**SHA**: `8ec160e` | 🔗 [查看提交](https://github.com/sgl-project/sglang/commit/8ec160ed46f0ccd7ad5526670fcde9144df8c6fd)

**🎯 变更类型**：功能增强  
**⚡ 重要程度**：🟡 中  

**📋 变更摘要**  
1. 新增 CLI 参数 `--uvicorn-access-log-exclude-prefixes`，可在启动时指定一组请求路径前缀，过滤掉对应的 Uvicorn access 日志（如 `/metrics`、`/health`）。  
2. 实现 `UvicornAccessLogFilter` 并在 `set_uvicorn_logging_configs` 中动态挂载到 uvicorn 的 `access` 处理器与 `uvicorn.access` logger。  
3. 文档、参数解析及调用链相应更新（`http_server.launch_server` 传递 `server_args`）。

**🎯 影响范围**  
- `python/sglang/srt/server_args.py`（新增属性 & CLI 参数）  
- `python/sglang/srt/utils/common.py`（日志过滤实现）  
- `python/sglang/srt/entrypoints/http_server.py`（调用 `set_uvicorn_logging_configs(server_args)`）  
- 文档 `docs/advanced_features/server_arguments.md`

**💡 关注建议**  
1. **兼容性**：`set_uvicorn_logging_configs` 现在接受 `server_args=None`，但在未传参的旧路径调用仍会保持原行为。确认所有内部或外部调用均已更新为带参形式。  
2. **过滤规则**：过滤逻辑对 `request_line`、`record.getMessage()` 进行多层解析，已基本覆盖常见格式，但对自定义 uvicorn formatter 仍可能漏掉。建议在 README 中说明仅在默认 `uvicorn` access formatter 下有效。  
3. **性能**：过滤实现使用元组和一次性解析，开销极低；但在高并发场景下仍建议通过单元测试验证无额外延迟。  
4. **测试覆盖**：加入对 `UvicornAccessLogFilter` 的单元测试，覆盖：普通路径、带查询字符串、绝对 URL、空前缀、字符串 vs 列表输入等。  
5. **日志配置**：若用户自行在 `logging.config.dictConfig` 中覆盖 uvicorn 配置，确保新 filter 不被意外剔除；可以在文档里提醒“在自定义 LOGGING_CONFIG 时保持 `filters` 中的 `sglang_uvicorn_access_path_filter`”。  

整体上，此次改动实现了对噪声日志的细粒度控制，代码结构清晰，风险有限。完成后建议跑一次完整的启动脚本，验证 `/metrics` 请求不再输出 access 日志。

---

### [eval] GSM8k support for run_eval (#17041)
**SHA**: `2740ed1` | 🔗 [查看提交](https://github.com/sgl-project/sglang/commit/2740ed1ae7e6179d788359a33affe7912871d2df)

**🎯 变更类型**：功能增强  
**⚡ 重要程度**：🟡 中  

**📋 变更摘要**  
1. 为 `run_eval` 增加 GSM8K 数学题目评测入口，支持 `--eval-name gsm8k`。  
2. 新增 `simple_eval_gsm8k.py`，实现 `GSM8KEval` 类，提供少样本（few‑shot）提示、答案抽取与得分计算。  
3. 命令行新增 `--num-shots` 与 `--gsm8k-data-path` 参数，默认 5‑shot、自动下载原始数据。  

**🎯 影响范围**  
- `python/sglang/test/run_eval.py`（调度与 CLI 参数）  
- `python/sglang/test/simple_eval_gsm8k.py`（核心评测实现）  
- 依赖 `sglang.test.simple_eval_common`、`sglang.utils.download_and_cache_file`、`sglang.utils.read_jsonl`  

**💡 关注建议**  

1. **数据泄漏检查**：当前实现把前 `num_shots` 条作为 few‑shot 示例后，直接从同一列表切除，这会导致评测集与示例集合交叉（若 `num_examples` 较小）。建议在读取后先抽取 `num_shots` 示例，再再抽取评测子集，或使用 `random.sample` 分离。  
2. **异常与网络容错**：`download_and_cache_file` 可能因网络失败抛异常，建议捕获并给出明确错误提示；同时在 `read_jsonl` 前检查文件是否存在、是否为空。  
3. **答案抽取鲁棒性**：`get_answer_value` 只取最后一个数字，可能误判（如 “10 ± 2”）。可考虑使用 OpenAI 的 `simple-evals` 中更完整的解析逻辑或加入容错。  
4. **线程安全与资源占用**：`self._lines` 全部加载到内存，GSM8K 约 13 k 条记录，仍在可接受范围，但若后续换更大数据集应考虑流式读取或分块。  
5. **CLI 参数校验**：`--num-shots` 不能大于数据集实际长度，建议在 `GSM8KEval.__init__` 中加入检查并给出友好错误。  
6. **文档与测试**：更新 README/CLI 手册说明 GSM8K 评测使用方法；新增单元测试，覆盖下载、few‑shot拼接、答案抽取及异常路径。  

总体而言，此次改动为 sglang 添加了面向数学推理的评测能力，影响集中在评测入口与新评测实现。只要注意上述数据泄漏与容错细节，即可安全合并并发布。

---

### [Benchmark] Add GSM8K Platinum Eval (#14565)
**SHA**: `d44f09a` | 🔗 [查看提交](https://github.com/sgl-project/sglang/commit/d44f09ad98ae0126587d2e34ef725cae05e132e2)

**🎯 变更类型**：功能增强  
**⚡ 重要程度**：🟡 中  
**📋 变更摘要**：在 GSM8K 基准评测中加入对 *GSM8K Platinum* 数据集的支持，通过 `--platinum` 标志即可切换；更新 README、命令行参数以及结果记录的 task 名称。  
**🎯 影响范围**：`benchmark/gsm8k/bench_sglang.py`、`benchmark/gsm8k/bench_other.py`、`benchmark/gsm8k/README.md`（核心评测脚本与文档）。  

**💡 关注建议**  
1. **依赖管理**：新增 `datasets` 包，需在 `requirements.txt`/`pyproject.toml` 中声明并在 CI 中安装，防止运行时 `ImportError`。  
2. **离线/缓存**：`load_dataset` 默认会尝试下载，建议提供 `--offline` 或提前缓存的方式，以免在无网络环境下报错。  
3. **结果兼容性**：输出的 `task` 字段会变为 `gsm8k-platinum`，下游分析脚本需适配新 task 名称或统一处理。  
4. **版本固定**：`load_dataset("madrylab/gsm8k-platinum", "main", ...)` 未锁定数据集版本，建议指定 `revision`（如特定 commit 或 tag），确保复现性。  
5. **文档同步**：README 已更新，但可以再补充 `datasets` 依赖说明、示例运行时间估计以及与原 GSM8K 的对比。  
6. **测试覆盖**：加入针对 `--platinum` 标志的单元测试，验证数据加载、prompt 构造和结果写入逻辑不受其他参数影响。  

总体来说，此改动为评测提供更可靠的数据集，保持向后兼容；只需注意依赖、缓存及下游兼容性即可顺利发布。

---

### Fix grammar sync across TP ranks (#17100)
**SHA**: `e7dc85c` | 🔗 [查看提交](https://github.com/sgl-project/sglang/commit/e7dc85c50baf434fcd5faeee30a4e1d0cd9ddaed)

**🎯 变更类型**：Bug 修复 / 功能增强  
**⚡ 重要程度**：🟡 中  
**📋 变更摘要**：  
1. 重新实现 `GrammarManager.get_ready_grammar_requests`，改用基于时间窗口的轮询、全局 `all_gather_object` 同步，统一返回 **就绪** 与 **超时失败** 请求，去掉旧的 `GRAMMAR_TIMEOUT/GRAMMAR_POLL_INTERVAL` 计算方式。  
2. 将原来的随机模拟超时逻辑删除，改为通过 `SGLANG_GRAMMAR_MAX_POLL_ITERATIONS` 与 `SGLANG_GRAMMAR_POLL_INTERVAL` 控制最大等待次数。  
3. 环境变量 `SGLANG_GRAMMAR_POLL_INTERVAL` 默认降至 0.005 s，新增 `SGLANG_GRAMMAR_MAX_POLL_ITERATIONS`（默 10000），去除已废弃的 `SGLANG_GRAMMAR_TIMEOUT`、`SGLANG_GRAMMAR_SIMULATE_TIMEOUT`。  
4. 小幅清理日志（去除 rerank 启动时的 token‑id 输出），并在分布式测试中删除对 `GRAMMAR_SIMULATE_TIMEOUT` 的覆盖。

**🎯 影响范围**：  
- `python/sglang/srt/constrained/grammar_manager.py`（核心同步逻辑）  
- `python/sglang/srt/environ.py`（新增/修改环境变量）  
- `python/sglang/srt/entrypoints/openai/serving_rerank.py`（日志）  
- `test/registered/distributed/test_dp_attention_large.py`（测试启动参数）

**💡 关注建议**  
1. **兼容性**：已移除 `SGLANG_GRAMMAR_TIMEOUT` 与 `SGLANG_GRAMMAR_SIMULATE_TIMEOUT`，请确认外部脚本或文档未再引用这些变量。  
2. **性能**：轮询间隔缩短到 5 ms，可能增加 CPU 负载；若有性能回归，建议通过 `SGLANG_GRAMMAR_POLL_INTERVAL` 调整。  
3. **超时策略**：`SGLANG_GRAMMAR_MAX_POLL_ITERATIONS` 与实际前向批处理延迟耦合，调优时注意两者比例，否则可能误判为超时。  
4. **测试**：新实现使用 `torch.distributed.all_gather_object`，确保所有分布式后端（nccl、gloo）均已支持对象收集；在 CI 中加入针对不同后端的验证。  
5. **日志**：若需要追踪语法同步过程，建议在 `GrammarManager` 中补充调试日志（例如每轮轮询的 ready/failed 集合大小），便于排查稀有同步不一致问题。

---

### [diffusion] feat: add cloud storage support for API (#14579)
**SHA**: `c81bad1` | 🔗 [查看提交](https://github.com/sgl-project/sglang/commit/c81bad1bf76296c9c9db1a56d5e954476a0f8e75)

**🛠️ 变更类型**：功能增强（为 Diffusion 的图片/视频 API 增加 S3‑compatible 云存储支持）  
**⚡ 重要程度**：🟡 中  
**📋 变更摘要**：  
- 新增 `cloud_storage` 模块，实现基于 `boto3` 的文件上传、URL 生成以及本地临时文件自动清理。  
- `image_api` 与 `video_api` 在生成完毕后会调用该模块，将产物上传至云端并在响应中返回 `url`（`response_format=url` 仅在开启云存储时可用）。  
- 文档与环境变量说明同步更新，提供 `SGLANG_CLOUD_STORAGE_TYPE=s3`、桶名、凭证、endpoint 等配置。  
- 新增单元/集成测试覆盖上传成功、失败、区域/自定义 endpoint、Content‑Type 判定等场景。

**🎯 影响范围**  
- `python/sglang/multimodal_gen/runtime/entrypoints/openai/*`（image、video、相关下载接口）  
- 新增 `storage.py` 与对应的测试文件  
- 文档 `cli.md`、`environment_variables.md`  
- 依赖：运行时需要 `boto3`，且环境变量必须完整，否则会在运行时静默失效。

**💡 关注建议**  

1. **向后兼容性**  
   - `response_format=url` 现在仅在云存储开启时可用，调用方若未配置 S3 将得到 400 错误。建议在 API 文档中明确说明，并在代码里加入更友好的错误提示（如自动回退到本地 `b64_json`）。  
   - `download_image_content` / `download_video_content` 在检测到已上传的 `url` 时直接报 400，防止误用本地路径；若后续需要支持 “预签名 URL” 下载，可在这里做统一封装。

2. **错误处理与回滚**  
   - 当前 `upload_and_cleanup` 在上传失败时只返回 `None`，但并未将异常信息回传给调用方，导致上层仍把 `file_path` 设为 `None`（在 `image_api` 中）。建议在失败路径保留本地文件并在响应中返回 `b64_json`，或在 `url` 字段返回错误描述。  
   - 对 `os.remove` 的异常只记录 warning，若临时文件残留可能导致磁盘占满，考虑在启动脚本中加入定期清理或在异常后主动删除。

3. **并发与资源**  
   - 上传采用 `asyncio.run_in_executor`，默认使用默认线程池，且每个请求都会创建一次 `CloudStorage` 实例（单例全局），但 `boto3` client 本身是线程安全的。若高并发场景下有大量并行上传，建议显式指定 `max_workers` 或使用专用线程池，以防出现线程竞争。  

4. **安全**  
   - 环境变量中携带 `SGLANG_S3_ACCESS_KEY_ID` 与 `SGLANG_S3_SECRET_ACCESS_KEY`，务必在部署平台（Docker/K8s）使用 secret 管理，避免日志泄露。`storage.py` 已将 `boto3` 导入延迟，防止缺少依赖时启动失败。  

5. **测试与 CI**  
   - 单元测试直接修改全局 `cloud_storage` 实例的属性，可能导致测试间相互影响。建议在每个 test 用 `fixture` 重建 `CloudStorage`，或在 `setup_module/teardown_module` 中恢复默认状态。  
   - 集成测试依赖 `moto`，CI 环境需预装 `moto[server]` 与 `boto3`，否则该用例会被跳过。  

**总体评价**：本次改动为 SGLang Diffusion 引入了实用的云存储功能，提升了生成内容的可共享性。实现思路清晰，文档同步完善，但涉及的错误回退、并发控制以及测试隔离仍有提升空间。建议在正式发布前加强异常返回的用户友好性，并在 CI 中验证高并发上传表现。

---

### Add dpsk-r1-fp4 in nightly perf ci (#16882)
**SHA**: `e3a9507` | 🔗 [查看提交](https://github.com/sgl-project/sglang/commit/e3a95077bc9aeb0fd0b939a3bbe48cf6c0d7083d)

**🎯 变更类型**：功能增强（新增 Nightly CI 性能/准确性测试）  
**⚡ 重要程度**：🟡 中  
**📋 变更摘要**：  
1. 将 `.github/workflows/nightly-test-nvidia.yml` 中的单文件超时从 60 分钟提升至 300 分钟，并为整个套件加入 `--timeout-per-file 12000` 参数，以容纳更长的测试。  
2. 新增 `test/registered/perf/test_dpsk_r1_fp4_4gpu_perf.py`，在 nightly‑4‑gpu‑b200 套件中注册 DeepSeek‑R1‑FP4 模型的性能与准确性联合测试，覆盖标准 TP=4 与 TP=4+EAGLE MTP 两个变体。

**🎯 影响范围**：  
- CI 工作流（`nightly-test-nvidia.yml`）  
- 测试注册模块 `sglang.test.ci.ci_register`  
- 性能/准确性运行器 `performance_test_runner.py`、`accuracy_test_runner.py`  
- 模型启动设置 `ModelLaunchSettings` 与合并测试入口 `run_combined_tests`  
- 可能的性能基准目录 `performance_profiles_deepseek_r1_fp4`

**💡 关注建议**：  
- **CI 时长**：新增 300 min 超时和 per‑file 12000 s 可能导致 nightly 运行时间显著增长，建议在 CI 机器上监控实际耗时，必要时拆分测试或调低超时阈值。  
- **资源使用**：EAGLE 规格需约 0.7 mem‑frac，确认 B200 GPU 具备足够显存，否则可能出现 OOM。  
- **基准阈值**：准确性基准设为 0.935（gsm8k），若模型更新或数据集变化，需同步调整。  
- **模型可达性**：确保 `nvidia/DeepSeek-R1-0528-NVFP4-v2` 镜像在 nightly 环境中可拉取，避免因网络/凭证导致 CI 失败。  
- **文档同步**：在项目文档或发布说明中加入该模型的支持情况、运行参数及预期性能，以便使用者了解新增能力。

---

### fix【hicache】fix the KV cache resource occupation  and invalid loading from prefetch when pending requests are aborted. (#16369)
**SHA**: `8b22dee` | 🔗 [查看提交](https://github.com/sgl-project/sglang/commit/8b22deef5bea4ebd6e73a35f88ad316857213a21)

**变更类型**：功能增强  
**重要程度**：🟡 中  

**核心改动**  
1. `scheduler.py` 在 `_abort_on_queued_limit` 中加入 `self.tree_cache.terminate_prefetch(candidate_req.rid)`，当高优先级请求抢占并撤销排队请求时，主动终止该请求在层次缓存中的预取任务。  
2. `hiradix_cache.py` 新增 `terminate_prefetch` 实现：若预取仍在 `ongoing_prefetch` 中且已有 `host_indices`，调用 `operation.mark_terminate()` 标记终止，以防止 KV‑cache 资源被无效占用。  
3. `cache_controller.py` 仅去除了一行空行，不影响逻辑。

**影响范围**  
- 层次 KV‑cache（`hiradix_cache`）的预取管理  
- 调度器的请求撤销流程  
- 可能涉及的并发线程（预取线程、调度线程）

**关注建议**  
- 确认 `operation.mark_terminate()` 在多线程环境下是线程安全的，避免竞态导致资源泄漏或异常。  
- 为撤销预取的路径补充单元/集成测试，验证高优先级抢占后 `ongoing_prefetch` 被正确清除，且 KV‑cache 的占用恢复。  
- 监控实际部署时的 KV‑cache 内存曲线，确保新增终止逻辑没有引入新泄漏。  
- 若项目仍可关闭层次缓存（`enable_hierarchical_cache=False`），保持该分支的行为不变，以免影响已有不使用层次缓存的用户。  

总体而言，本次改动解决了 “预取被中止后仍占用 KV‑cache” 的 bug，风险主要在并发终止的正确性和对应的测试覆盖。建议在发布前做一次并发压测和内存回收验证。

---

### Disable unit-test-deepep-8-gpu (#17176)
**SHA**: `69822c7` | 🔗 [查看提交](https://github.com/sgl-project/sglang/commit/69822c72712387a9c6f3bb145e786997bfd2e068)

**🎯 变更类型**：功能增强（CI 稳定性提升）  
**⚡ 重要程度**：🟡 中  
**📋 变更摘要**：在 GitHub Actions 工作流中将 `unit-test-deepep-8-gpu` 相关任务全部注释掉，并在 `test/srt/run_suite.py` 中同步屏蔽对应的 DeepEP 大模型测试。原因是 8‑GPU H200 Runner 存在 `IBGDA/cudaHostRegister` 环境异常，导致 CI 不稳定（参见 #17175）。

**🎯 影响范围**  
- CI 配置文件 `.github/workflows/pr-test.yml`（删除 8‑GPU DeepEP 测试阶段）  
- 测试套件 `test/srt/run_suite.py`（隐藏 `per-commit-8-gpu-h200-deepep` 与 `ep/test_deepep_large.py`）  
- 受影响的模块主要是 **DeepEP**（`ep/` 目录）以及 **CI/CD 流程**。

**💡 关注建议**  
1. **暂时回退风险**：关闭 8‑GPU DeepEP 测试后，若后续代码修改触及 `ep/test_deepep_large.py` 中的边缘情况，CI 将不再捕获。建议在本地或专用机器上手动运行该测试，确保功能不被退化。  
2. **文档同步**：在项目 README 或 CI 说明中标记此测试已被屏蔽，并给出临时 workaround（如在本地使用 `CUDA_VISIBLE_DEVICES=0,1,2,3` 运行）。  
3. **后续修复路线**：追踪 #17175，定位 `IBGDA/cudaHostRegister` 的根本原因；当 runner 环境恢复后，及时恢复该任务及对应的测试条目。  
4. **测试覆盖**：确保 4‑GPU DeepEP 测试（已保留）足以覆盖关键路径；如果覆盖率下降，可考虑在其他平台（如自建 GPU 节点）补充大模型的回归测试。  

总体而言，此次改动提升了每日 CI 的成功率，但需留意隐藏的大模型测试可能带来的潜在回归风险，并在可行时尽快恢复。

---

### [Docs] add v1/score api to native api documentation (#16568)
**SHA**: `cd23c2f` | 🔗 [查看提交](https://github.com/sgl-project/sglang/commit/cd23c2f0a3419a49716691517446fc94444cc23b)

**🎯 变更类型**：文档新增（功能说明）  
**⚡ 重要程度**：🟡 中  

**📋 变更摘要**  
在 `docs/basic_usage/native_api.ipynb` 中加入了 **`/v1/score`** 接口的使用示例和说明。该接口用于 **decoder‑only 计分**：给定 `query` 与若干 `items`，返回 `label_token_ids` 对应的 token 概率（可选 softmax），便于分类、概率评估等场景。

**🎯 影响范围**  
- **文档层面**：新增章节、代码块、示例请求。  
- **用户层面**：可以直接参考 notebook 调用新 API。  
- **代码层面**：本次提交未修改实现，只是文档；若实现细节在后续迭代与文档不一致，可能导致调用错误。

**💡 关注建议**  
1. **保持同步**：确保后端 `v1/score` 实际参数、返回字段（`scores`）与文档完全一致；尤其是 `apply_softmax`、`item_first` 的默认值。  
2. **测试覆盖**：在 CI 中加入对该接口的单元/集成测试，验证不同 `label_token_ids`、`items` 长度、`item_first` 布局的返回。  
3. **示例稳健**：示例代码使用了硬编码的 token ID（9454、2753），建议在文档中说明获取 token ID 的方式，或提供 `tokenizer.encode` 示例，以免用户自行搜寻。  
4. **错误处理**：在实际使用时，建议在 notebook 中加入对 `response.status_code` 与异常的检查，提升教学示例的容错性。  
5. **后续文档更新**：若后期对 `v1/score` 增加新参数（如 `temperature`、`top_p`）或改变返回结构，及时在该 notebook 中补充说明，避免用户产生误解。  

总体而言，此次改动对功能本身无影响，仅提升了对 **v1/score** 的可见性和使用指导，建议在下一个发布周期确认实现与文档的一致性后即可推广给用户。

---

#### 🟢 低重要度变更 (15)

### [bugfix] fix qwen3-next alt_stream none issue (#17016)
**SHA**: `6f10e17` | 🔗 [查看提交](https://github.com/sgl-project/sglang/commit/6f10e17b4a68df3cea7d37d30859409f62f720dc)

**🎯 变更类型**：其他  
**⚡ 重要程度**：🟢低  
**📋 摘要**：在 `qwen3_next.py` 的 `_forward_input_proj` 中，追加对 `self.alt_stream` 为非空且处于 capture 模式的检查，仅在满足这些条件时才等待 CUDA 流，从而避免 `alt_stream` 为 `None` 时导致的错误。

---

### [Doc] Tiny docs update for CUDA 13 (#17200)
**SHA**: `c771933` | 🔗 [查看提交](https://github.com/sgl-project/sglang/commit/c771933dc5dda77fc4f91463ab4217210e563ca2)

**🎯 变更类型**：文档更新  
**⚡ 重要程度**：🟢低  
**📋 摘要**：在 `install.md` 中新增 CUDA 13 Docker 推荐及手动安装 `sgl_kernel` wheel 的说明，修正 “Cuda” 为 “CUDA”，并更新 B300/GB300 的 PTXAS 错误修复指令。

---

### Add clear error message when OOM with symmetric memory (#17038)
**SHA**: `9d8bbd4` | 🔗 [查看提交](https://github.com/sgl-project/sglang/commit/9d8bbd4223508dd2be7aad0273161d4e47340614)

**🎯 变更类型**：代码重构  
**⚡ 重要程度**：🟢低  
**📋 摘要**：在 `pynccl_allocator.py` 中新增 `NCCLCHECK` 宏，捕获 NCCL 对称内存分配/注册错误并输出明确的 OOM 提示。

---

### fix AMD CI failure of NUMA binding (#17184)
**SHA**: `d9ed80b` | 🔗 [查看提交](https://github.com/sgl-project/sglang/commit/d9ed80b9f195c98dacf9979ada35d24b56aa7bfc)

**🎯 变更类型**：代码重构  
**⚡ 重要程度**：🟢低  
**📋 摘要**：将原 NUMA 绑定实现从 CPU 改为 CUDA 设备，新增 GPU 检测函数并重命名相关 API，简化 `hiradix_cache` 中的调用逻辑。

---

### [ConfigArgumentMerger] Improve ConfigArgumentMerger compatibility with external callers (#17051)
**SHA**: `daa4841` | 🔗 [查看提交](https://github.com/sgl-project/sglang/commit/daa4841e867fe54495559e8259f4c9f6922d6a89)

**🎯 变更类型**：代码重构  
**⚡ 重要程度**：🟢低  
**📋 摘要**：改进 `ConfigArgumentMerger` 构造函数，新增可选参数 `parser` 与 `boolean_actions`，在未提供 `parser` 时支持旧式仅传入布尔动作列表的调用方式，避免在外部调用时因缺少 `argparse` 对象而出错。

---

### [Diffusion] Hot fix broken output_path default value (#17180)
**SHA**: `6ee970a` | 🔗 [查看提交](https://github.com/sgl-project/sglang/commit/6ee970a36509dfc28388368f19ebed0895180670)

**🎯 变更类型**：代码重构  
**⚡ 重要程度**：🟢 低  
**📋 摘要**：将 `output_path` 默认值由 `None` 改为 `"outputs/"`，修复因缺省路径导致的输出异常。代码仅涉及单行修改，影响范围局限于默认参数设置。

---

### Remove deepseek-r1 from THINKING_MODE_CHOICES in run_eval.py (#17178)
**SHA**: `0e86de7` | 🔗 [查看提交](https://github.com/sgl-project/sglang/commit/0e86de7c0be179db4e2f32e5e89e4dcefcbd513e)

**🎯 变更类型**：代码重构  
**⚡ 重要程度**：🟢低  
**📋 摘要**：在 `run_eval.py` 中移除已下线的 `deepseek-r1` 选项，更新思考模式列表及帮助信息，并在 `get_thinking_kwargs` 添加对 Qwen3 的注释。

---

### [Doc] Tiny update Cuda 13 environment instructions (#17174)
**SHA**: `8b99af9` | 🔗 [查看提交](https://github.com/sgl-project/sglang/commit/8b99af9af87df54154915068320303a1e7104020)

**🎯 变更类型**：文档更新  
**⚡ 重要程度**：🟢低  
**📋 摘要**：在安装指南中补充了 CUDA 13 环境的 Docker 镜像推荐及使用说明，加入了针对 `sm_103a` 错误的修复步骤，并优化了原有提示。

---

### [Doc] Add tip on how to use Spec V2 (#15455)
**SHA**: `3d72944` | 🔗 [查看提交](https://github.com/sgl-project/sglang/commit/3d72944fb89842672cf9d663228663e05096d8c6)

**🎯 变更类型**：文档更新  
**⚡ 重要程度**：🟢低  
**📋 摘要**：在 DeepSeek、GLM‑4.5/4.6 和 GPT‑OSS 使用说明中新增关于实验性 Overlap Scheduler（通过环境变量 `SGLANG_ENABLE_SPEC_V2=1`）的使用提示，补充了 Spec V2 的开启方法及示例。

---

### Show how to use cu13 image with B300 (#17170)
**SHA**: `7dde343` | 🔗 [查看提交](https://github.com/sgl-project/sglang/commit/7dde3438e204d14b351b6e9ae2a8925392b5b798)

**🎯 变更类型**：文档更新  
**⚡ 重要程度**：🟢低  
**📋 摘要**：在 `install.md` 中新增了 B300（SM103）使用 cu13 镜像的说明，建议使用 `lmsysorg/sglang:dev-cu13` 并避免在容器内重新编辑安装，以免覆盖镜像中预装的库版本。

---

### Add mooncake store read/write bandwidth logs (#10598)
**SHA**: `77fc4c4` | 🔗 [查看提交](https://github.com/sgl-project/sglang/commit/77fc4c4a53f1d2f4f5047e77c2c1e9ced50a4e1c)

**🎯 变更类型**：代码重构  
**⚡ 重要程度**：🟢低  
**📋 摘要**：在 MooncakeStore 中新增读写带宽统计字段，并在 batch_set/batch_get 中记录操作时长，提供 `get_stats` 方法返回 `StorageMetrics` 用于监控存储性能。

---

### [smg] release 0.3.2 (#17168)
**SHA**: `3f44268` | 🔗 [查看提交](https://github.com/sgl-project/sglang/commit/3f44268fe57ebd70ef52963ea9fb7621e99f185c)

**🎯 变更类型**：配置调整  
**⚡ 重要程度**：🟢低  
**📋 摘要**：将 sgl-model-gateway 及其 Go、Python 绑定的 Cargo.toml、pyproject.toml 与 Python 版本文件中的版本号统一从 0.3.1 升级至 0.3.2。

---

### [smg][ci] add make cmd to patch versions (#17167)
**SHA**: `f7ec817` | 🔗 [查看提交](https://github.com/sgl-project/sglang/commit/f7ec8174db17b54b040b522f4727911d39055f25)

**🎯 变更类型**：代码重构  
**⚡ 重要程度**：🟢低  
**📋 摘要**：在 `sgl-model-gateway/Makefile` 中新增 `show-version` 与 `bump-version` 命令，实现跨 Cargo、PyPI、Python 版本文件的统一查看与批量升级。

---

### docs only add kimi k2 thinking and kimi linear  (#15789)
**SHA**: `d1110e1` | 🔗 [查看提交](https://github.com/sgl-project/sglang/commit/d1110e1c3e1a2f68cac4541261169545a6fc2547)

**🎯 变更类型**：文档更新  
**⚡ 重要程度**：🟢低  
**📋 摘要**：在文档中新增对 Kimi K2 Thinking 与 Kimi Linear 模型的说明，更新思考标签及对应解析器要求，并在支持模型列表中加入 Kimi K2 与 Kimi Linear 的条目。

---

### [Docs] sort and update `server_arguments.md` (#17163)
**SHA**: `9227d9f` | 🔗 [查看提交](https://github.com/sgl-project/sglang/commit/9227d9f60c33a46b1eec4c3c8cbbb84e787259ea)

**🎯 变更类型**：文档更新  
**⚡ 重要程度**：🟢低  
**📋 摘要**：对 `server_arguments.md` 进行排序与扩充，新增多项服务器参数说明（如 load‑format、prefill‑delayer、日志格式等），并在 Ascend 支持文档中加入 `--admin-api-key` 条目。

---

