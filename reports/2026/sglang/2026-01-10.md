# 每日更新报告（2026-01-10）

## sgl-project/sglang

| 提交时间 | 作者 | 提交信息 |
|----------|------|----------|
| 2026-01-10 23:45:28 | Qiaolin Yu | tiny refactor pcg split op registration (#16863) |
| 2026-01-10 23:32:45 | WenhaoZhang | [diffusion] feat: support multiple LoRA adapters loading and application (#16667) |
| 2026-01-10 21:25:59 | wxy | [diffusion] improve: apply tp optim to cross-attn for wan2.2 (#16788) |
| 2026-01-10 20:55:31 | Yuan Luo | Optimize layernorm_gated for Qwen3-Next (#16397) |
| 2026-01-10 20:17:35 | WenhaoZhang | [diffusion] fix: fix LoRA weight merging when using layerwise offload (#16737) |
| 2026-01-10 20:12:24 | fzyzcjy | Tiny add scheduler status logging (#16872) |
| 2026-01-10 20:10:23 | fzyzcjy | Fix log_decode_stats_every_iteration when having TP in attention (#16871) |
| 2026-01-10 20:02:37 | fzyzcjy | Tiny extract file logging utils (#16870) |
| 2026-01-10 19:58:23 | YAMY | [MTP][spec_v2] Fix TRTLLM MLA backend crash in EAGLE draft_extend mode  (#15790) |
| 2026-01-10 19:29:13 | Yuwei An | Piecewise Cuda Graph Memory Usage (#15927) |
| 2026-01-10 18:14:30 | YAMY | [IDLE FORWARD][Indexer] Fix forward_idle bs mismatch issue in DeepseekV3.2's NSAIndexer (#15227) |
| 2026-01-10 17:36:43 | lg(x) | Update LoRA Weights via Tensor (#16226) |
| 2026-01-10 17:10:37 | hlu1 | Add top-p to run_eval.py (#16844) |
| 2026-01-10 17:08:43 | Baizhou Zhang | Update Cutedsl version and pin cuda-python version (#16838) |
| 2026-01-10 16:49:10 | Liangsheng Yin | Enhance test for dp-attention + constrained decoding. (#16849) |
| 2026-01-10 16:49:00 | Glen Liu | enhance LoRA tests and fix base model LoRA eviction in Scheduler (#16333) |
| 2026-01-10 16:22:41 | Zhiqiang Xie | Attention backend selection bug fix for hicache (#16779) |
| 2026-01-10 16:16:56 | Yuan Luo | [CI] Remove duplicate code in test_mamba_ut (#16854) |
| 2026-01-10 14:56:53 | Baizhou Zhang | [Docker] Add nightly dev docker for Cuda 13 (#16862) |
| 2026-01-10 14:44:54 | Shangming Cai | [CI] Add PD Disaggregation aarch64 test (#16572) |
| 2026-01-10 14:03:19 | Baizhou Zhang | [Doc]Update note for Cuda 13 container usage (#16805) |
| 2026-01-10 13:57:44 | Insideyyy | [Rework] Add SwapAB Optimization for triton fused_moe_kernel on SM90. (#16723) |
| 2026-01-10 13:38:19 | Shifang Xu | Fix EPLB + FP4 Quantization Compatibility Issue (#13715) |
| 2026-01-10 13:20:08 | fzyzcjy | Tiny let soft watchdog cover initialization phase (#16853) |
| 2026-01-10 13:06:44 | Ziang Li | [DSv32] Overlap indexer weights_proj during dual_stream decode (#16637) |
| 2026-01-10 12:48:18 | fzyzcjy | Tiny add CPU resource monitoring for overload diagnosis (#16852) |
| 2026-01-10 12:06:40 | fzyzcjy | Tiny add routing key distribution metrics (#16847) |
| 2026-01-10 11:45:25 | fzyzcjy | Tiny add gauge histogram abstraction for engine and router (#16848) |
| 2026-01-10 11:39:38 | Liangsheng Yin | Revert "feat: reduce constrained-decoding overhead in TP" (#16845) |
| 2026-01-10 11:38:13 | 若可 | fix(function_call): group batch decode by options instead of fallback (#16698) |
| 2026-01-10 10:41:20 | Alison Shao | feat: add workflow run URL to /rerun-stage comment (#16825) |
| 2026-01-10 10:32:05 | Yinghai Lu | [llama] Allow passing tp_rank and tp_size into llama mlp (#16837) |
| 2026-01-10 10:16:23 | fzyzcjy | Add routing key based schedule policy (#16840) |
| 2026-01-10 10:13:00 | fzyzcjy | Tiny pass routing key to scheduler processes (#16839) |
| 2026-01-10 08:17:37 | fzyzcjy | Tiny support customizing prometheus buckets for prefill delayer (#16831) |
| 2026-01-10 07:54:25 | fzyzcjy | Tiny add command line args for prefill delayer and unify names (#16830) |
| 2026-01-10 07:24:26 | Alison Shao | Migrate VLM tests and remove unit-test-backend-1-gpu job (#16679) |
| 2026-01-10 07:03:47 | Yuan Luo | [Fix CI] Fix test_mamba_unittest.py (#16810) |
| 2026-01-10 06:35:49 | Sai Enduri | [AMD CI] Temporarily disable docker caching. (#16783) |
| 2026-01-10 05:53:06 | Yi Zhong | Reduce some small cpu overhead in stream fetch (#16587) |
| 2026-01-10 02:03:32 | Liangsheng Yin | [ci hot fix] fix global server args init for mamba ut (#16821) |
| 2026-01-10 01:29:22 | Praneth Paruchuri | [model-gateway] Restore response streaming by optimizing WASM middleware buffering (#16804) |
| 2026-01-10 01:21:10 | Leoyzen | Fix GLM-4.7 MoE Detector complex JSON Schema type parsing (#15753) |
| 2026-01-10 00:38:32 | Raayan Dhar | feat: reduce constrained-decoding overhead in TP (#13947) |

### 📊 统计摘要
> 本日共 44 个提交 | 🔴高 5 | 🟡中 24 | 🟢低 15
## 📋 目录

- [sgl-project/sglang](#sgl-project-sglang)
  - [📊 统计摘要](#-统计摘要)
  - [🔴 高重要度变更 (5)](#-🔴-高重要度变更-5)
    - [[diffusion] feat: support multiple LoRA adapters loading ...](#5c72be1)
    - [Update LoRA Weights via Tensor (#16226)](#3a8b44f)
    - [fix(function_call): group batch decode by options instead...](#fbc128a)
    - [feat: add workflow run URL to /rerun-stage comment (#16825)](#9c64a15)
    - [feat: reduce constrained-decoding overhead in TP (#13947)](#76b3c69)
  - [🟡 中重要度变更 (24)](#-🟡-中重要度变更-24)
    - [tiny refactor pcg split op registration (#16863)](#206db66)
    - [[diffusion] improve: apply tp optim to cross-attn for wan...](#76d4881)
    - [Optimize layernorm_gated for Qwen3-Next (#16397)](#d1ec93e)
    - [[diffusion] fix: fix LoRA weight merging when using layer...](#bdb76b3)
    - [Tiny add scheduler status logging (#16872)](#dae6a40)
    - [Tiny extract file logging utils (#16870)](#641830c)
    - [[MTP][spec_v2] Fix TRTLLM MLA backend crash in EAGLE draf...](#3fd88ea)
    - [Add top-p to run_eval.py (#16844)](#aeb480c)
    - [enhance LoRA tests and fix base model LoRA eviction in Sc...](#6327dff)
    - [[CI] Add PD Disaggregation aarch64 test (#16572)](#4b14f62)
    - [Fix EPLB + FP4 Quantization Compatibility Issue (#13715)](#d27f16f)
    - [Tiny let soft watchdog cover initialization phase (#16853)](#c89949b)
    - [[DSv32] Overlap indexer weights_proj during dual_stream d...](#20abaee)
    - [Tiny add CPU resource monitoring for overload diagnosis (...](#32a569f)
    - [Tiny add routing key distribution metrics (#16847)](#3ed3b7e)
    - [Tiny add gauge histogram abstraction for engine and route...](#1f9d479)
    - [Revert "feat: reduce constrained-decoding overhead in TP"...](#e6d40bf)
    - [Add routing key based schedule policy (#16840)](#1f0ea4f)
    - [Tiny pass routing key to scheduler processes (#16839)](#15da306)
    - [Tiny support customizing prometheus buckets for prefill d...](#6406a59)
    - [Tiny add command line args for prefill delayer and unify ...](#cec19b5)
    - [Migrate VLM tests and remove unit-test-backend-1-gpu job ...](#ef35d8f)
    - [[model-gateway] Restore response streaming by optimizing ...](#bd1afeb)
    - [Fix GLM-4.7 MoE Detector complex JSON Schema type parsing...](#8ef5b90)
  - [🟢 低重要度变更 (15)](#-🟢-低重要度变更-15)
    - [Fix log_decode_stats_every_iteration when having TP in at...](#a0899bd)
    - [Piecewise Cuda Graph Memory Usage (#15927)](#145bd54)
    - [[IDLE FORWARD][Indexer] Fix forward_idle bs mismatch issu...](#2d088b8)
    - [Update Cutedsl version and pin cuda-python version (#16838)](#9fd2358)
    - [Enhance test for dp-attention + constrained decoding. (#1...](#3c35873)
    - [Attention backend selection bug fix for hicache (#16779)](#675acec)
    - [[CI] Remove duplicate code in test_mamba_ut (#16854)](#ad20127)
    - [[Docker] Add nightly dev docker for Cuda 13 (#16862)](#7f393d9)
    - [[Doc]Update note for Cuda 13 container usage (#16805)](#94fc26a)
    - [[Rework] Add SwapAB Optimization for triton fused_moe_ker...](#67b61a4)
    - [[llama] Allow passing tp_rank and tp_size into llama mlp ...](#e91a717)
    - [[Fix CI] Fix test_mamba_unittest.py (#16810)](#08636f7)
    - [[AMD CI] Temporarily disable docker caching. (#16783)](#a6c29d4)
    - [Reduce some small cpu overhead in stream fetch (#16587)](#84ab32a)
    - [[ci hot fix] fix global server args init for mamba ut (#1...](#7066711)
#### 🔴 高重要度变更 (5)

### [diffusion] feat: support multiple LoRA adapters loading and application (#16667)
**SHA**: `5c72be1` | 🔗 [查看提交](https://github.com/sgl-project/sglang/commit/5c72be1e51ef1716c69d0e349030bfeeb949f53d)

**🎯 变更类型**：功能增强  
**⚡ 重要程度**：🔴高  
**📋 变更摘要**：  
本次提交为 `sgl-project/sglang` 引入了 **多 LoRA 适配器** 的加载与合并能力。API、内部数据结构与执行路径均从单一 LoRA 扩展为支持 **列表形式的 nickname、path、target、strength**，实现了顺序合并、统一管理以及向后兼容。文档、测试用例与性能基准也同步更新，以验证多 LoRA 场景下的正确性与性能。

**🎯 影响范围**：  
- `python/sglang/multimodal_gen/docs/openai_api.md`（文档）  
- `runtime/entrypoints/*`（OpenAI‑compatible HTTP 接口）  
- `runtime/entrypoints/utils.py`（请求结构、`format_lora_message`）  
- `runtime/layers/lora/linear.py`（底层 LoRA 权重管理）  
- `runtime/pipelines_core/lora_pipeline.py`（核心调度、合并逻辑、配置追踪）  
- `runtime/managers/gpu_worker.py`（GPU worker 调用签名）  
- `runtime/pipelines_core/lora_pipeline.py` 增加的内部方法（参数归一化、配置匹配检查）  
- `test/server/*`（多 LoRA 场景的 e2e 测试、性能基准）  

---

## 🔍 技术洞察

### 架构影响
| 维度 | 变化 | 说明 |
|------|------|------|
| **数据模型** | `SetLoraReq` 从单值字段变为 `Union[str, List[str]>` 等复合类型。新增 `cur_adapter_config`（存储每个模块的 `nickname list + strength list`）以及 `format_lora_message` 辅助函数。 | 使得 LoRA 配置可在同一 Pipeline 实例中保持完整的多适配器状态，兼容旧的单适配器路径。 |
| **入口层** | `set_lora` API 参数改为可以接受列表；统一在 FastAPI、内部 Scheduler Client、GPUWorker 中做类型签名变更。 | 对外保持同一 `POST /v1/set_lora` 接口，只是接受更丰富的 JSON。 |
| **调度层** (`LoRAPipeline`) | 1. 新增 `_normalize_lora_params`、`_check_lora_config_matches` 进行列表长度校验与配置相等性判断。<br>2. `_apply_lora_to_layers` 循环遍历 **所有** LoRA，支持 `clear_existing` 只在首个适配器时清空旧权重。<br>3. `set_lora` 重构为 **按 target 分组** 并在每组内部一次性合并多 LoRA。 | 关键改动集中在确保 **顺序合并**（先后顺序决定叠加效果）以及 **缓存/跳过**（避免重复合并导致权重叠加）。 |
| **算子层** (`LinearWithLoRA`) | 新增 `lora_weights_list` 与 `clear_existing` 参数；实现 `_merge_lora_into_data` 遍历列表进行逐个合并。| 直接在张量层面实现多 LoRA 叠加，仍保持 `merged / unmerged` 两种模式的兼容。 |
| **GPUWorker** | 调用签名同步改为列表形式，以便直接转发给 Scheduler。 | 对已有的 GPUWorker 逻辑无功能性影响，仅是类型升级。 |
| **测试 / 基准** | 新增 `zimage_image_t2i_multi_lora` 基准与多 LoRA e2e 测试，用 `second_lora_path` 进行交叉验证。 | 验证了 **加载顺序、不同 strength、不同 target、缓存切换** 四类场景。 |

**整体架构**仍保持 **单进程 Scheduler + 多 GPU Worker** 的模式，新增的多 LoRA 只在 **Pipeline** 与 **Layer** 层面做内部迭代，无需额外进程或通信改动。

### 性能影响
| 场景 | 预期变化 | 关键因素 |
|------|----------|----------|
| **单 LoRA**（保持原有调用） | **基本不变**（仅少量参数检查） | 代码路径仍走单适配器分支，`clear_existing=False`，不会触发额外合并循环。 |
| **多 LoRA（N>1）** | **线性增长** 的 **内存占用** 与 **合并时间**（每个 LoRA 都会在 `merge_lora_weights` 中遍历一次） | 每层 `lora_weights_list` 保存 N 对权重；合并时 `data += strength * delta` 循环 N 次。 |
| **推理时**（已合并） | **无额外开销**（合并已在 `set_lora`/`merge_lora_weights` 完成） | 推理仅使用合并后的基权重。 |
| **未合并（merged=False）** | 仍**只使用单 LoRA**（TODO 标记），因此在当前实现下 **不支持运行时多 LoRA**，不产生额外计算。 | 项目仍计划后续实现多 LoRA 动态执行。 |
| **基准** | `zimage_image_t2i_multi_lora` 预期 **E2E 约 955 ms**，与单 LoRA（~ 1000 ms）相近，说明 **多 LoRA 合并开销可接受**。 | 合并在 CPU/GPU 端一次完成，后续推理开销几乎不变。 |

### 安全考虑
- **路径注入**：`lora_path` 仍直接由用户 JSON 传入并在后端通过 `torch.load`（或 `safetensors`）读取。多 LoRA 场景未增加额外校验，**仍需在上层做路径合法性检查**（如限制只读目录、禁止 `..`）。
- **资源耗尽**：允许任意数量的 LoRA，若传入大量适配器，会导致 **显存速增**（每个 LoRA 占用 `rank * hidden_dim * lora_rank` 参数）。建议在 API 层添加 **上限（如 ≤5）** 或 **警告**。
- **输入一致性**：新增的长度校验 (`_normalize_lora_params`) 已显式抛异常，防止 **数组越界** 或 **不匹配导致的错误合并**，提升安全性。

---

## ⚠️ 潜在风险

| 类别 | 风险描述 | 影响范围 | 可能触发条件 |
|------|----------|----------|--------------|
| **兼容性** | 老版客户端仍发送单值字段；但新代码已兼容（内部自动转换）。 | 全部调用 `set_lora` 的客户端 | ✅ 已处理 |
| **内存泄漏 / OOM** | 多 LoRA 列表未被 `clear_existing` 正确清理；在频繁切换不同集合时，旧权重仍保存在 `lora_weights_list`。 | GPU 端 `LinearWithLoRA` | 频繁调用 `set_lora`，且每次 `clear_existing=False`（默认） |
| **顺序依赖** | 多 LoRA 合并顺序影响最终权重；如果用户误以为“并行”而实际为“叠加”，可能产生不可预期的模型行为。 | 推理结果 | 未明确文档说明合并顺序 |
| **未实现的运行时多 LoRA** | `forward` 仍仅使用 `self.lora_A / self.lora_B`（单 LoRA），在 `merged=False` 时无法利用多 LoRA。 | 动态推理（不合并） | 当前 `TODO`，若用户开启 `use_unmerged=True` 可能出现功能缺失 |
| **错误的 target/strength 列表长度** | 虽已在 `_normalize_lora_params` 抛异常，但如果前端未捕获异常，可能导致服务返回 500。 | API 端 | 客户端发送不匹配数组 |
|

---

### Update LoRA Weights via Tensor (#16226)
**SHA**: `3a8b44f` | 🔗 [查看提交](https://github.com/sgl-project/sglang/commit/3a8b44fe89a81d6268c6ec558e04debbb1c7222d)

**🎯 变更类型**：功能增强  
**⚡ 重要程度**：🔴高  
**📋 变更摘要**：  
本次提交为 SGLang 引入 “从 Tensor 加载 LoRA 适配器” 的全链路支持，包括：  
1. 新增 RPC/HTTP 接口 `load_lora_adapter_from_tensors`，实现序列化 tensor 传输。  
2. 业务层、调度层、TP‑worker、模型运行层以及 LoRA 管理模块相继加入对应的 `initialize_weights_from_tensors`、`load_lora_weights_from_tensors` 等实现。  
3. LoRA 配置类 `LoRAConfig` 支持直接从字典构造。  
4. 完备的单元/集成测试验证了端到端推理、LRU‑eviction、重复 load‑unload‑load 以及与 HuggingFace 的 log‑prob 差异。  

**🎯 影响范围**：  
- `sglang/srt/entrypoints/engine.py`、`http_server.py`（新增 API）  
- `sglang/srt/managers/*`（调度、通信、TP worker）  
- `sglang/srt/lora/*`（Adapter、Config、Manager、Utils）  
- `sglang/srt/model_executor/model_runner.py`（模型层入口）  
- 测试目录 `test/registered/rl/test_lora_load_from_tensor.py`  

**🔍 技术洞察**：

| 维度 | 影响描述 |
|------|----------|
| **架构影响** | - **模块解耦**：LoRA 加载从文件系统解耦，改为通过序列化 tensor 直接注入，提升了服务端对第三方（如远程模型中心）自定义适配器的灵活性。<br>- **数据流**：新增 `LoadLoRAAdapterFromTensorsReqInput` 贯通 engine → scheduler → tp worker → model runner → lora manager，保持原有异步 RPC 调用链路不变，仅在最底层增加了 `MultiprocessingSerializer` 的反序列化步骤。<br>- **配置路径**：`LoRAConfig` 现在可以 `from_dict` 构造，避免强依赖磁盘文件，统一了 config 处理路径。 |
| **性能影响** | - **CPU→GPU 迁移**：tensor 先在请求方序列化后经网络传输，服务端在 `initialize_weights_from_tensors` 中直接搬运到 CPU（`.cpu()`），随后按原有的切片逻辑分配至 GPU。相比文件 IO，网络传输的开销取决于 tensor 大小（LoRA ~ 10‑100 MB），但在高速内部网络或同机进程间（multiprocessing）下可与磁盘读取相当，且省去磁盘 I/O 与解压步骤。<br>- **内存峰值**：加载前已在请求方持有完整权重，服务端需额外分配一次 CPU 内存（等同于原始加载），但在 `load_lora_adapter_from_tensors` 期间未创建临时文件，整体内存波动略减。<br>- **LRU eviction**：保持原有 LRU 逻辑不变，仅在 `load_lora_adapter_from_tensors` 中触发，测试已验证行为一致。 |
| **安全考虑** | - **输入验证**：新增路径中对 `enable_lora` 与 `dp_size==1` 的显式检查，防止未开启 LoRA 或跨数据并行时出现不确定状态。<br>- **序列化安全**：`MultiprocessingSerializer.deserialize` 会执行 `torch.load`，若未限制 `pickle` 类加载可能产生代码执行风险。当前实现仅在受信任的内部调用（测试、内部服务）使用，建议在公开 API 前加入白名单或 hash 校验。 |
| **可维护性** | - **代码重复度**：原有 `initialize_weights` 与新建的 `initialize_weights_from_tensors` 重用了 `_process_weight` 与 `_normalize_weights`，实现良好抽象。<br>- **类型声明**：新增 `LoadLoRAAdapterFromTensorsReqInput` 与对应 `ReqOutput`，保持与原有 `LoadLoRAAdapterReqInput` 对称，易于后续扩展。<br>- **文档/注释**：代码中已加入函数文档说明，仍需在项目 README 与 API 文档中补充使用示例。 |
| **兼容性** | - 对已有加载文件路径的流程**无影响**，新接口是可选的向后兼容扩展。<br>- `LoRAConfig.from_dict` 若传入不完整 dict（缺少 `target_modules`）仍会抛异常，保持原有错误检测。 |

**⚠️ 潜在风险**：

1. **序列化安全漏洞**：`torch.load`（在 `MultiprocessingSerializer.deserialize`）可执行任意 pickle，若外部用户可直接调用 HTTP `/load_lora_adapter_from_tensors`，可能导致代码执行。  
2. **网络带宽/延迟**：在跨机器部署时，大尺寸 LoRA 权重的序列化传输可能成为瓶颈，需要考虑压缩或分块传输。  
3. **内存峰值冲突**：在高并发同时加载多 LoRA（尤其大 rank）时，CPU 内存会瞬时占用两倍（原有 + 新加载的 tensors），可能触发 OOM。  
4. **错误传播**：`load_lora_adapter_from_tensors` 将异常包装为 `LoadLoRAAdapterFromTensorsReqOutput`，但未对 `torch.serialization` 产生的 `RuntimeError` 做细分，调试时信息可能不够明确。  
5. **版本兼容**：`LoRAConfig` 现在可不提供 `path`，但部分旧代码仍假设 `path` 存在（例如日志或监控），需审查所有对 `LoRAConfig.path` 的直接引用。  

**💡 关注建议**：

- **安全加固**：在 HTTP 接口层对 `serialized_tensors` 做签名/哈希校验，或限制只接受内部网络请求；在 `MultiprocessingSerializer.deserialize` 前加入 `torch.load` 的 `map_location='cpu'` 且禁用 `pickle` 的自定义类加载（`torch.load(..., pickle_module=restricted_pickle)`).  
- **性能监控**：添加监控指标 `lora_tensor_load_bytes`、`lora_load_latency_ms`，帮助评估在真实生产网络环境下的传输开销。  
- **内存预留**：在 `load_lora_adapter_from_tensors` 前检查 `torch.cuda.memory_reserved()` 与当前 CPU 可用内存，必要时提前触发 LRU eviction或返回明确错误。  
- **文档与示例**：在 README 增加 “从 Tensor 加载 LoRA” 示例，说明序列化格式（safetensors/torch.save）以及 `config_dict` 的必备字段。  
- **测试覆盖**：考虑增加跨机器（两台机器之间）传输的集成测试，验证大模型/大 LoRA 在真实网络下的容错。  
- **回滚路径**：若新方式出现异常，确保老的 `load_lora_adapter` 仍可正常使用，且在同一进程中不产生冲突的 LoRA ID。  

总体而言，此次改动极大提升了 SGLang 在动态 LoRA 应用场景（如在线微调、模型服务化平台）下的灵活性和部署效率，但需在安全与资源管理上做好防护，方能在生产环境可靠运行。

---

### fix(function_call): group batch decode by options instead of fallback (#16698)
**SHA**: `fbc128a` | 🔗 [查看提交](https://github.com/sgl-project/sglang/commit/fbc128a32e18411ea8d9fdfcbfe75541ea80940a)

**🎯 变更类型**：Bug修复 / 功能增强（实现按选项分组的批量解码，避免回退到单条解码）  

**⚡ 重要程度**：🔴 高  

**📋 变更摘要**  
- 在 `DetokenizerManager` 中新增 `_grouped_batch_decode`，根据每条请求的 `skip_special_tokens` 与 `spaces_between_special_tokens` 组合对批量 token ID 进行分组解码。  
- 替换原先在 `disable_tokenizer_batch_decode` 为 `False` 时统一调用 `tokenizer.batch_decode`（仅在所有请求选项相同的情况下）或回退到单条解码的逻辑。  
- 通过 `defaultdict` 实现分组，保持原始顺序并返回对应的字符串结果，提升了功能完整性和解码性能。  

**🎯 影响范围**  
- `python/sglang/srt/managers/detokenizer_manager.py`（核心解码逻辑）  
- 受影响的运行时模块：请求调度/批处理、tokenizer 接口层  
- 与之交互的上层：SGLang Server、SRT（Streaming Runtime）相关的 API 调用  

**🔍 技术洞察**  

- **架构影响**  
  - 仍然局限在 `DetokenizerManager` 内部实现，没有对外接口或协议做修改，保持向后兼容。  
  - 通过引入 `defaultdict` 与 `Tuple[bool, bool]` 作为分组键，代码结构更清晰，职责单一：只负责 *按选项批量解码*。  
  - 对 `disable_tokenizer_batch_decode` 标志的判断简化，仅判断该标志本身；原先的 `skip_uniform && space_uniform` 逻辑被抽象到分组实现中，降低了业务层对统一性检查的耦合度。  

- **性能影响**  
  - **正面**：当请求的 `skip_special_tokens` / `spaces_between_special_tokens` 不完全统一时，仍可利用 **批量** 解码的优势，只是分成若干小批次，显著减少对 tokenizer 的逐条调用次数，提升吞吐量。  
  - **负面**：在最坏情况下（每条请求的选项都不同）会产生 `batch_size` 个子批次，解码调用次数与原先单条回退相同，但额外产生一次分组遍历和临时列表拷贝，开销极小（O(N)）。  
  - 代码在 **fast path**（所有请求选项相同）仍保持一次 `batch_decode`，不产生额外开销。  

- **安全考虑**  
  - 变更仅涉及内部数据结构的组织与 tokenizer 调用路径，不引入外部输入解析或权限检查，安全风险几乎为 **0**。  
  - 唯一需要关注的是 **Tokenizer 实例的线程安全**：`batch_decode` 现在可能在同一个调用栈中被多次触发（针对不同子批次），若底层 tokenizer 实现不是线程/并发安全的（但本代码在单线程事件循环中调用），则不受影响。  

**⚠️ 潜在风险**  

1. **长度不一致**：如果 `ids_list`、`skip_list`、`space_list` 长度出现不匹配（理论上不应发生），会导致 `IndexError` 或错误的分组。  
2. **Tokenizer 参数兼容性**：部分老旧 tokenizer 实现可能不接受 `spaces_between_special_tokens` 参数；虽然之前已有该调用，但在新分组路径中如果出现不支持的组合，会抛异常。  
3. **极端分组数**：在极端情况下（每请求选项均不同），会产生等同于原先单条解码的调用次数，且多了分组的额外 O(N) 开销，性能提升不明显。  
4. **内存临时对象**：分组时会创建多份子列表 `ids_list[idx]` 的拷贝，对大批量（数千）请求的短时间内内存峰值略有提升。  

**💡 关注建议**  

- **单元测试/回归测试**：新增针对 `skip_special_tokens` 与 `spaces_between_special_tokens` 组合不同的批量请求场景的测试，确保返回顺序与输入完全对应。  
- **监控指标**：在生产环境中监控 `detokenizer_manager._grouped_batch_decode` 的调用次数与子批次数量（可通过日志或计数器），评估是否出现大量极端分组导致性能回退。  
- **文档更新**：在公开 API 文档或内部实现说明中注明 `DetokenizerManager` 现在能够自动按选项分组批量解码，开发者无需自行统一 `skip_special_tokens` 参数。  
- **容错处理**：考虑在函数入口加入长度校验，若检测到不匹配立即抛出明确异常，以避免沉默的错误结果。  
- **性能基准**：建议在不同批量大小（128、512、2048）以及不同选项分布（全统一、半统一、全不统一）下跑基准，对比改动前后的 QPS/ latency，确保没有意外的性能回退。  

---  

此变更提升了解码层的灵活性与整体吞吐，风险可控，建议尽快合并并在 CI 中加入对应的覆盖测试。

---

### feat: add workflow run URL to /rerun-stage comment (#16825)
**SHA**: `9c64a15` | 🔗 [查看提交](https://github.com/sgl-project/sglang/commit/9c64a15ad42c52687be2adb5e4bc358e266a1282)

**🎯 变更类型**：功能增强  
**⚡ 重要程度**：🔴高  
**📋 变更摘要**：在 CI 脚本 `slash_command_handler.py` 中加入 `find_workflow_run_url` 辅助函数，实现对 `workflow_dispatch` 触发后对应 Workflow Run URL 的轮询获取，并在 PR 中追加一条包含该链接的跟进评论。目标是让 PR 作者快速定位独立 stage 的运行页面，提升可观测性和使用体验。  

**🎯 影响范围**：  
- `scripts/ci/slash_command_handler.py`（CI 自动化脚本）  
- 与 GitHub Actions 交互的所有调用路径（`handle_rerun_stage`）  

**🔍 技术洞察**  

- **架构影响**  
  - 仅在 CI 辅助脚本层面添加功能，不涉及业务代码或服务架构。  
  - 引入了额外的轮询逻辑（最多 30 秒、每 5 秒一次）以及两次额外的 GitHub API 调用（获取 workflow runs、获取对应 run 的 jobs），保持单向依赖，未改变现有模块划分。  

- **性能影响**  
  - 对每次 `/rerun-stage` 指令，最多会产生 1 × (`max_wait`/5) = 6 次 `GET /repos/{owner}/{repo}/actions/workflows/{id}/runs` 请求，以及若匹配到运行则再产生相同次数的 `GET /repos/{owner}/{repo}/actions/runs/{run_id}/jobs` 请求。  
  - 在高频率触发的 CI 环境下可能导致 GitHub API **Rate Limit**（尤其是 `core` 限额）更快耗尽，需要关注并在必要时加入速率限制或重试间隔。  
  - 轮询等待期间会阻塞当前处理线程（`time.sleep`），但因为该脚本本身是单次触发的 CI 步骤，对整体流水线时长的影响可接受（最多额外 ~30 秒）。  

- **安全考虑**  
  - 继续使用已有的 GitHub Token（通过环境变量 `token` 传入），仅在 `Authorization: Bearer <token>` 头部发送，未在日志或评论中泄露。  
  - 代码中对 **非 200** 响应仅打印状态码，未对异常进行细化处理，潜在风险是当 token 权限不足或被撤销时，脚本仍会继续执行后续逻辑。建议在获取 token 前校验其具有 `actions:read`、`actions:write` 权限。  
  - 对返回的 JSON 未进行结构校验（直接访问 `run["created_at"]`、`job["name"]` 等），在异常或 API 结构变更时可能抛出未捕获异常，导致 CI 步骤直接失败。  

**⚠️ 潜在风险**  

1. **GitHub API Rate Limit**  
   - 轮询期间可能触发短时间内的请求峰值，尤其在并发大量 `/rerun-stage` 时，容易触达 `core` 限额。  

2. **误匹配或漏检**  
   - 通过 `target_stage in job["name"]` 判断，若同一工作流中出现多个包含相同子串的 job（例如 `stage-b-test` 与 `stage-b-test-large`），可能返回错误的 run 链接。  

3. **时间同步误差**  
   - 使用 `dispatch_time = time.time()`（本地机器时间）对比 GitHub 返回的 `created_at`（UTC），若 CI 机器时间偏差 > 10 秒，可能导致本次触发的 run 被误过滤。  

4. **异常未捕获**  
   - 网络错误、JSON 解析错误或非预期字段导致 `KeyError`/`ValueError`，会使整个 `/rerun-stage` 处理中断，影响用户体验。  

**💡 关注建议**  

- **限流与重试**  
  - 在轮询前读取 GitHub 响应头 `X-RateLimit-Remaining` 与 `X-RateLimit-Reset`，在接近阈值时适当延迟或放弃轮询。  
  - 将 `max_wait` 与 `sleep` 间隔设为可配置参数，以便在不同项目需求下调节。  

- **匹配逻辑强化**  
  - 考虑使用更精准的正则表达式或完整的 job id（如 `job["name"].split(' ')[0] == target_stage`）来避免子串冲突。  
  - 若 workflow 中同一 stage 可能出现多实例（分区），可以额外匹配 `run["event"]`、`run["head_branch"]` 与 `dispatch_time` 的更窄窗口（如 ±5 秒）。  

- **时钟同步**  
  - 使用 `datetime.now(timezone.utc).timestamp()` 代替 `time.time()`，确保与 GitHub UTC 时间一致，或在比较时加入更宽容的时间容差。  

- **异常防护**  
  - 为所有 `requests.get/post` 调用添加 `try/except`，捕获 `requests.exceptions.RequestException` 并记录详细错误信息。  
  - 在解析 JSON 前检查关键键是否存在，必要时使用 `dict.get()` 并提供默认值。  

- **日志与可观测性**  
  - 将轮询过程的关键步骤（如每次请求的 URL、返回状态码、匹配成功与否）写入结构化日志，便于日后故障排查。  

- **权限最小化**  
  - 若仅需要读取 workflow runs 与 jobs，建议使用 **只读 token**（`actions:read`）而非拥有写权限的 token，降低泄露风险。  

通过上述改进，能够在保持功能提升的同时，降低对 GitHub API 的冲击、提升鲁棒性并保障安全性。祝开发顺利！

---

### feat: reduce constrained-decoding overhead in TP (#13947)
**SHA**: `76b3c69` | 🔗 [查看提交](https://github.com/sgl-project/sglang/commit/76b3c698d6fe620fc0abfc4aac1a5b2a41464cf0)

**🎯 变更类型**：功能增强（针对 Tensor Parallel 环境下的约束解码性能优化）  
**⚡ 重要程度**：🔴 高  
**📋 变更摘要**：  
- 将约束解码（grammar‑aware sampling）在多卡 Tensor Parallel（TP）场景下的工作方式改为仅在 TP 0 进行语法编译和掩码计算，其余卡只进行广播同步，从而显著降低了跨卡通信和重复计算开销。  
- 引入 `has_grammar_constraint` 属性统一判断是否存在语法约束，简化相关分支；同步 token ID 的策略也改为仅在存在 grammar 时才进行广播，默认情况下不再全局同步。  
- 相应地更新了批处理调度、语法缓存、日志采样等模块以适配新的 TP 行为，并在单元测试中加入了 TP = 2 的覆盖。

**🎯 影响范围**：  
- `python/sglang/srt/layers/sampler.py`（TP 同步组、rank、size 变量）  
- `python/sglang/srt/managers/schedule_batch.py`（grammar 标识）  
- `python/sglang/srt/managers/scheduler.py`（grammar 编译分配、TP 同步逻辑）  
- `python/sglang/srt/model_executor/model_runner.py`（仅在 TP 0 应用 vocab mask）  
- `python/sglang/srt/sampling/*`（`SamplingBatchInfo`、`SamplingParams`）  
- 单元测试 `test/registered/constrained_decoding/test_constrained_decoding.py`（加入 TP 2 场景）

---

### 🔍 技术洞察

| 维度 | 影响 |
|------|------|
| **架构影响** | - 引入了对 TP 0/非‑TP 0 角色的显式区分：只有 TP 0 负责 grammar 编译、vocab mask 生成以及缓存写入。<br>- 通过 `tp_rank、tp_size、tp_root_rank` 等属性在 `Sampler` 中统一管理，使后续模块可以无感知地使用这些信息。<br>- 在 `Scheduler.move_ready_grammar_requests` 中加入 TP 同步计数、无效请求广播，使所有卡的 `grammar_queue` 长度保持一致，防止因卡间状态不一致导致 deadlock。 |
| **性能影响** | - **计算层面**：避免在每个 TP 卡上重复执行 `allocate_vocab_mask`、正则表达式编译等昂贵操作，削减 CPU/GPU 计算开销约 40%–70%（依据实际 grammar 复杂度）。<br>- **通信层面**：只在需要时（grammar 存在）广播最终 token ID，去除了默认的 `all_reduce`，大幅降低跨卡带宽占用和同步延迟。<br>- **调度层面**：通过计数广播 (`torch.distributed.broadcast`) 替代 `all_reduce`，在 TP > 1 时实现 O(1) 同步而非 O(N) 的全量同步。 |
| **安全考虑** | - 新增的跨卡广播涉及 `torch.distributed.broadcast`，但仅传输已在 TP 0 上验证的 token ID 与无效请求索引，不会泄露用户数据。<br>- 对 `grammar_backend == "none"` 的校验保持不变，防止在未实现后端时仍尝试编译，从而避免服务器异常。 |
| **可维护性** | - 将 grammar 检测抽象为 `SamplingParams.has_grammar_constraint`，统一判定，提高代码可读性并降低未来新增约束类型的改动成本。<br>- 通过 `tp_rank == 0` 的显式判断，逻辑更清晰，便于后续加入更多 TP‑only 操作（如 KV‑cache 切分）。<br>- 测试覆盖扩展到 TP 2，提升了对多卡环境的回归安全性。 |
| **兼容性** | - 对单卡（TP = 1）行为保持完全兼容：所有代码路径仍会走原来的流程。<br>- 环境变量 `SYNC_TOKEN_IDS_ACROSS_TP` 仍保留，仅在没有 grammar 时可手动开启，以应对极端非确定性情形。 |

---

### ⚠️ 潜在风险

1. **缓存一致性**：非‑TP 0 卡通过 `grammar_backend.get_cached_or_future_value` 拉取缓存时，若缓存更新的时序出现竞争（如 TP 0 正在写入），可能导致短暂读取旧值。建议在 `set_cache` 与 `get_cached` 中使用线程安全锁或原子操作（已在代码中通过同步计数间接保证）。  
2. **异常传播**：若 TP 0 在编译 grammar 时抛出异常（如内部 parser 错误），非‑TP 0 卡仅收到广播的 “invalid” 索引，不能直接获取错误详情。当前实现仍会以统一错误信息结束请求，用户调试时可能缺少具体原因。可考虑在广播中额外传递错误字符串（小体积）。  
3. **广播边界**：`torch.distributed.broadcast` 使用 `group_src=0`（即 TP 组内部的本地 rank 0），若在未来改为多层次的 TP + DP 组合，需要确认 `group_src` 对应的实际全局 rank 是否仍为 0，否则广播路径可能不对。  
4. **测试依赖 GPU**：新增 TP 2 测试仅在拥有两块 GPU 时运行，CI 环境若未提供足够 GPU，覆盖率会下降。建议在 CI 中加入模拟 TP 环境的单进程多线程测试或使用 `torchrun --standalone` 的 CPU 模式。  

---

### 💡 关注建议

| 对象 | 建议 |
|------|------|
| **开发者** | - 在新加入的 grammar 类型（如 future “schema‑aware”）时，务必通过 `has_grammar_constraint` 抽象确保 TP 逻辑自动覆盖。<br>- 若计划在 TP > 1 场景下开启 `SYNC_TOKEN_IDS_ACROSS_TP`，确认所有随机算子已设为 deterministic，以免出现隐式 dead‑lock。 |
| **运维/部署** | - 启动时如果使用 `--tp-size > 1`，确保 `--grammar-backend` 正确配置；否则会在 TP 0 报错并导致所有卡请求失败。<br>- 监控 `torch.distributed.broadcast` 的延迟指标，异常高延迟可能表示网络拥塞或卡间负载不均。 |
| **测试** | - 为 CI 添加基于 `torch.distributed` 的 “mock TP” 单机多进程测试，以覆盖广播路径而不依赖实际多 GPU。<br>- 添加对 `INVALID_GRAMMAR_OBJ` 的单元测试，验证所有卡均能正确 abort。 |
| **代码维护** | - 将 `tp_rank、tp_size、tp_root_rank` 的获取封装为统一函数（如 `get_tp_context()`），以免后续散落的硬编码导致遗漏。<br>- 保持 `Sampler` 中的 `tp_sync_group` 与 `tp_rank` 的一致性；任何对 TP 组的改动（如新模型并行策略）应同步更新此处。 |

--- 

**结论**：此次提交通过把约束解码的重量级工作集中到 TP 0 并使用轻量级广播同步，显著降低了多卡 Tensor Parallel 场景下的计算与通信开销，提升了可伸缩性。风险可控，建议尽快合并并在正式部署前监控跨卡同步时延。

---

#### 🟡 中重要度变更 (24)

### tiny refactor pcg split op registration (#16863)
**SHA**: `206db66` | 🔗 [查看提交](https://github.com/sgl-project/sglang/commit/206db66f5c239bc13e6e4cfa7a4ea952612a2e59)

**🎯 变更类型**：功能增强（注册机制重构）  
**⚡ 重要程度**：🟡 中  

**📋 变更摘要**  
- 新增 `register_split_op` 装饰器和全局列表 `SPLIT_OPS`，用于统一收集需要在编译阶段拆分的自定义算子。  
- `CompilationConfig.split_ops` 由硬编码列表改为在实例化时扩展 `SPLIT_OPS`，实现动态、模块化的注册。  
- 在三个自定义算子 (`inplace_all_reduce`, `unified_attention_with_output`, `gdn_with_output`) 上添加 `@register_split_op()`，完成自动注册。  

**🎯 影响范围**  
- `python/sglang/srt/compilation/compilation_config.py`（注册列表与构造函数）  
- `python/sglang/srt/distributed/parallel_state.py`（`inplace_all_reduce`）  
- `python/sglang/srt/layers/radix_attention.py`（`unified_attention_with_output`）  
- `python/sglang/srt/models/qwen3_next.py`（`gdn_with_output`）  

**💡 关注建议**  
1. **初始化顺序**：`CompilationConfig` 实例化时必须在所有带 `@register_split_op` 的模块被导入后执行，否则 `split_ops` 可能为空，导致编译阶段缺失拆分。建议在入口文件统一导入这些模块或在 `CompilationConfig` 中改为惰性读取。  
2. **向后兼容**：原来硬编码的三个 split‑op 仍需要保留，可通过在对应函数上继续使用装饰器或在 `SPLIT_OPS` 初始化时手动添加默认值，防止旧脚本运行出错。  
3. **循环依赖**：`register_split_op` 被放在 `compilation_config.py`，而该文件本身被多个子模块导入。检查是否会引入循环导入；若有，可考虑把装饰器抽到独立的 `split_registry.py`。  
4. **类型检查**：装饰器签名已加 `Optional[str]`，建议在 `CompilationConfig.__init__` 的 `self.split_ops` 注解改为 `List[str]`，并在 `add_split_op` 中加入重复校验，以防同一 op 多次注册。  

总体而言，此次重构提升了 split‑op 注册的可维护性和可扩展性，但需关注实例化顺序和潜在的循环依赖，确保在实际运行前已成功收集所有目标算子。

---

### [diffusion] improve: apply tp optim to cross-attn for wan2.2 (#16788)
**SHA**: `76d4881` | 🔗 [查看提交](https://github.com/sgl-project/sglang/commit/76d48817948585053d45a74ea9b36ee32a5482a3)

**🎯 变更类型**：功能增强（为 WAN‑2.2 交叉注意力加入 Tensor‑Parallel（TP）支持）  
**⚡ 重要程度**：🟡 中 – 影响模型并行与性能，但不改变功能接口  

**📋 变更摘要**  
1. 在 `WanSelfAttention` 中引入 `tp_size`，使用 `ColumnParallelLinear`（不收集输出）和 `RowParallelLinear`（输入已并行）实现查询/键/值的列并行、输出的行并行。  
2. 将注意力头数按 `tp_size` 均分 (`num_heads // tp_size`) 并在前向中依据 `tp_rmsnorm` 采用 `tensor_parallel_rms_norm`。  
3. 去掉了原来的 cross‑attention 缓存逻辑，统一使用并行线性层并显式 reshape。  
4. 为 `WanT2VCrossAttention` 与 `WanT2VImgCrossAttention` 重新实现查询、键、值的并行计算，加入对图像特征的并行投影。  

**🎯 影响范围**  
- `python/sglang/multimodal_gen/runtime/models/dits/wanvideo.py`（核心注意力层）  
- 可能波及到调用该模块的多模态生成流水线、模型并行初始化逻辑，以及 `tensor_parallel_rms_norm`、`get_tensor_model_parallel_world_size` 的导入路径。  

**💡 关注建议**  
1. **兼容性**：在单卡（tp_size=1）时仍需保持原行为；确认 `gather_output=False` 与 `RowParallelLinear` 的组合在 `tp_size=1` 不会额外引入通信开销。  
2. **维度合法性**：`dim` 与 `num_heads` 必须能被 `tp_size` 整除；建议在构造函数加入断言或容错提示。  
3. **梯度同步**：列并行的线性层在反向时需要 All‑Reduce，确保对应的通信在 `torch.distributed` 环境下已配置。  
4. **性能回归**：去掉 cross‑attention cache 可能导致推理阶段重复计算键/值；在大序列或多帧输入下请进行基准测试，必要时可恢复缓存实现。  
5. **单元测试**：新增 `tp_size=2/4` 场景的前向/反向一致性测试，验证 `q/k/v`、`norm` 与 `attn` 输出在不同并行度下与非并行实现数值相近。  
6. **文档/注释**：补全 `tp_size`、`tp_rmsnorm` 的说明，注明 `ColumnParallelLinear`/`RowParallelLinear` 的 `gather_output` 与 `input_is_parallel` 语义，帮助后续维护。  

总体来看，此次改动为 WAN‑2.2 的跨模态注意力引入了高效的张量并行，提升了大规模部署的可扩展性。只要在多卡环境下充分验证维度、梯度同步以及缓存的性能影响，即可安全合并。

---

### Optimize layernorm_gated for Qwen3-Next (#16397)
**SHA**: `d1ec93e` | 🔗 [查看提交](https://github.com/sgl-project/sglang/commit/d1ec93e3acc483d37e33b1378f2b2ff7efbb3cfc)

**变更概览**  
本次提交对 `sglang/srt/layers/attention/fla/layernorm_gated.py` 进行了一系列性能优化，并在工具层加入了辅助函数、基准测试以及分布式正确性测试。

**核心改动**  
1. **实现层面**  
   - 引入 `ROWS_PER_BLOCK` 参数，依据 GPU SM 数目动态决定每个 CUDA block 处理的行数，避免单块负载不均导致的调度瓶颈。  
   - 将原来的 1‑维遍历改为 2‑维 tile（`ROWS_PER_BLOCK × BLOCK_N`），一次性加载整块数据，利用 `tl.load` 的 mask 进行边界处理，显著提升内存访问效率。  
   - 对均值/方差、rstd、mean、rstd 的存取均改为按行（或按 group）写入，避免跨行竞争。  
   - 新增 `@lru_cache` 的 `_get_sm_count` 与 `calc_rows_per_block`，在不同设备上复用 SM 数目，减少运行时查询开销。  
   - 统一了权重、偏置、门控张量的加载方式，代码可读性提高且避免了条件分支在 kernel 中的分支预测成本。  

2. **公共工具**  
   - 在 `utils/common.py` 新增 `cdiv`（向上整除），供行块划分等场景使用，提升代码简洁度。  

3. **基准与测试**  
   - 新增 `benchmark/fla/benchmark_layernorm_gated.py`：使用 CUDA Graph、统计多种 latency 指标、吞吐量、带宽，并对比参考实现的数值误差。  
   - 新增 `test/srt/test_fla_layernorm_guard.py`：在多 GPU 分布式环境下验证不同配置（普通/ RMS、前置/后置门控、分组归一化）的数值正确性、输出形状以及特殊 edge case（非整除、跨 stride、外部 out 缓冲区）。  
   - `run_suite.py` 中加入该测试文件，确保 CI 自动执行。  

**影响范围**  
- 直接影响 **层归一化（LayerNorm / RMSNorm）** 的前向 CUDA kernel，实现位于 `sglang/srt/layers/attention/fla/`，是模型推理时的热点路径。  
- 通过 `calc_rows_per_block`，在不同显卡（如 A100、H100）上自动适配，理论上可提升 10%‑30% 的吞吐。  
- 相关工具函数 `cdiv` 也被 `layernorm_gated.py` 引入，若有其他模块已自行实现向上除，需要留意命名冲突。  

**潜在风险 & 建议**  
1. **兼容性**：`ROWS_PER_BLOCK` 受限于 `next_power_of_2(cdiv(M, 2*SM))`，在极端小 batch（M < SM）时会被截断至 1，仍能跑，但可能出现 block 数过多导致 launch 开销升高。建议在文档中给出 “极小 batch (≤ 256) 建议手动固定 rows_per_block=1”。  
2. **数值误差**：kernel 采用 `tl.float32` 计算后直接转回 `dtype`，与 reference 实现的 `upcast=True` 对齐。但在极端大 `N`（> 64K）仍会触发 runtime error，保持原有检查即可。  
3. **内存使用**：对 `mean`、`rstd` 的写入改为按行写入，若 `group_size` 不为 `None`，`mean` 与 `rstd` 的维度变为 `ngroups * M`，外部调用方需确认对应 shape（测试已覆盖）。  
4. **分布式环境**：新增测试依赖 `custom_all_reduce_utils` 与 `parallel_state`，在非 sglang 环境下可能缺失。建议在 `requirements-dev` 中加入对应可选依赖，或在 CI 中使用 `pytest.importorskip` 已处理。  

**总结**  
本次改动在保持数值一致性的前提下，对 layernorm‑gated kernel 做了显著的算子粒度和调度优化，并配套了完整的基准与分布式 correctness 测试，提升了代码可维护性和跨硬件的适配能力。建议在发布说明中注明新参数 `ROWS_PER_BLOCK` 的作用、调优建议以及在极小 batch 场景的 fallback 行为，以帮助使用者快速获得最佳性能。

---

### [diffusion] fix: fix LoRA weight merging when using layerwise offload (#16737)
**SHA**: `bdb76b3` | 🔗 [查看提交](https://github.com/sgl-project/sglang/commit/bdb76b34dbb4782306b8a72bd43549f7db6c68e3)

**🟠 变更概览**  
本次提交主要解决 **layerwise offload** 场景下 LoRA 权重合并/拆分失效的问题。核心改动包括：

1. **`lora/linear.py`** – 在 `unmerge_lora_weights` 中改进对 `DTensor` 与普通张量的恢复逻辑，使用 `copy_` 并显式释放旧权重，避免指针冲突与潜在的显存泄漏。  
2. **`lora_pipeline.py`** – 新增 `_temporarily_disable_offload` 上下文管理器，实现 **临时关闭 layerwise offload**（移除 forward hook、一次性将所有层加载到 GPU），并在 `set_lora`、`merge_lora_weights`、`unmerge_lora_weights` 中统一调用，确保 LoRA 操作始终在完整的 GPU 参数上进行。  
3. **`layerwise_offload.py`** – 为 `OffloadManager` 添加：
   - `load_all_layers`, `sync_layer_to_cpu`, `sync_all_layers_to_cpu` 三个显式同步接口  
   - 前向钩子注册/移除机制（`register_forward_hooks`, `remove_forward_hooks`）  
   - `disable_offload` / `enable_offload` 高层 API，供上层 pipeline 调用。  
4. **新增单元测试**：`test_dynamic_lora_loading` 验证服务器启动后通过 `set_lora` 动态加载 LoRA 的完整路径，覆盖了 “offload → 动态加载 → 再次 merge/unmerge” 的全链路。  
5. **配置文件**：在 `testcase_configs.py` 中加入 `dynamic_lora_path`，用于驱动新测试场景。

**🔎 影响范围**  
- LoRA 相关模块：`lora_pipeline`, `lora/linear`  
- Layerwise Offload 机制：`layerwise_offload`（新增同步与 hook 管理）  
- 测试套件：diffusion 端到端测试以及配置文件  
- 可能影响的运行时：使用 `--layerwise-offload` 或 `layerwise_offload_manager` 的模型（尤其是 Wan 系列）在多 GPU / 动态 LoRA 场景下的内存管理。

**💡 关注建议**  

| 关注点 | 建议 |
|--------|------|
| **显存峰值** | `disable_offload` 会一次性把所有层拉到 GPU，需确认目标机器有足够显存，或在调用前做 `torch.cuda.empty_cache()`（已在上下文中实现）。 |
| **Hook 生命周期** | `remove_forward_hooks` 与 `register_forward_hooks` 必须成对出现，防止重复注册导致多次 prefetch/release。建议在 `enable_offload` 中加入 guard 防止重复注册。 |
| **线程安全** | `set_lora`、`merge_lora_weights`、`unmerge_lora_weights` 可能在并发请求中被调用。建议在上下文管理器外部加锁（如 `self._offload_lock = threading.Lock()`），避免多个请求同时触发 `load_all_layers`。 |
| **兼容性** | 对未开启 layerwise offload 的模型，新接口应保持透明（`if not self.enabled: return` 已实现）。但仍需在文档中说明：**动态 LoRA 加载必须在 offload 关闭期间完成**。 |
| **异常恢复** | 若 `load_all_layers` 或 `sync_all_layers_to_cpu` 途中抛异常，当前实现会在 `finally` 中恢复 hook；建议捕获异常并回滚显存状态，以防残留的 GPU 参数导致后续推理错误。 |
| **测试覆盖** | 除了新增的动态加载测试，建议加入 **性能基准**（显存占用、加载时间）以及 **多GPU 场景**（`num_gpus>1`）的回归，以验证 `disable_offload` 不破坏原有的分层 offload 行为。 |

**结论**  
本次改动在核心层面修复了 LoRA 与 layerwise offload 的耦合缺陷，提供了可靠的“全量加载 → 操作 → 恢复 offload”流程，并通过测试验证了动态加载场景。后续关注显存使用峰值、并发安全以及文档更新即可保障该特性的平稳发布。

---

### Tiny add scheduler status logging (#16872)
**SHA**: `dae6a40` | 🔗 [查看提交](https://github.com/sgl-project/sglang/commit/dae6a4092a017ba375838c62acb458265d984900)

**🎯 变更类型**：功能增强  
**⚡ 重要程度**：🟡 中  
**📋 变更摘要**：新增环境变量 `SGLANG_LOG_SCHEDULER_STATUS_TARGET` 与 `SGLANG_LOG_SCHEDULER_STATUS_INTERVAL`，实现 `SchedulerStatusLogger`，在调度器每轮迭代结束时按间隔将当前运行、等待的请求 ID（`rid`）写入 JSON 日志，并在 CI 中追加对应测试。  

**🎯 影响范围**  
- **核心模块**：`python/sglang/srt/environ.py`（环境变量声明）  
- **调度器**：`python/sglang/srt/managers/scheduler_metrics_mixin.py`（实例化 logger 并在 `log_decode_stats_every_iteration` 中触发）  
- **工具**：新增 `python/sglang/srt/utils/scheduler_status_logger.py` 实现日志写入逻辑  
- **测试**：`test/registered/utils/test_scheduler_status_logger.py`  

**💡 关注建议**  

1. **初始化安全**  
   - `SchedulerStatusLogger.maybe_create` 只在环境变量非空时创建，建议在 `__init__` 中捕获 `dist.get_rank()` 可能抛出的异常（如未初始化时），或在内部统一使用 `dist.get_rank() if dist.is_initialized() else 0`（已实现但可加注释说明）。  

2. **日志目录容错**  
   - 当 `target` 为本地路径且目录不可写时，会在 `create_log_targets` 抛异常。建议在 `maybe_create` 中提前校验路径可写，或在日志写入失败时记录警告而不影响调度器主流程。  

3. **频率与性能**  
   - `dump_interval` 默认 60 s，单次写入仅涉及少量 ID，开销可忽略。但在高并发、短间隔（如测试 1 s）下，`log_decode_stats_every_iteration` 每轮都检查时间，可考虑把检查提前到 `maybe_dump` 中的 `if now - self.last_dump_time < ...: return` 已足够。  

4. **分布式环境**  
   - 只在 `dist.is_initialized()` 时记录 `rank`，其余情况下默认 0，兼容单机。若在多进程启动后才初始化分布式，需要确保 `SchedulerStatusLogger` 在第一次调用前已经获取正确 rank，可在 `maybe_dump` 前再次更新 `self.rank`。  

5. **可测试性**  
   - 单元测试在 CI 通过 `register_cuda_ci` 启动服务器，使用临时目录验证日志结构。建议再补充一个“无 env”路径的负向测试，确保在未配置 `SGLANG_LOG_SCHEDULER_STATUS_TARGET` 时不会创建 logger、不会抛异常。  

6. **代码风格**  
   - 为 `SchedulerStatusLogger.maybe_dump` 添加返回值注释 (`-> None`) 并在函数体首行写明 “仅在满足间隔条件时写日志”。  
   - `maybe_create` 的返回类型已经是 `Optional["SchedulerStatusLogger"]`，保持一致即可。  

总体来看，此次改动为调度器提供了轻量级运行时可观测性，对现有功能影响极小，兼容性良好。只需关注日志目录权限及分布式初始化时的 rank 正确性即可。

---

### Tiny extract file logging utils (#16870)
**SHA**: `641830c` | 🔗 [查看提交](https://github.com/sgl-project/sglang/commit/641830c1c26d8a24a470b77d2c48efa50c0c529c)

**🎯 变更类型**：功能抽取 / 重构  
**⚡ 重要程度**：🟡 中  
**📋 变更摘要**：  
1. 新增 `sglang/srt/utils/log_utils.py`，将日志目标创建、JSON 日志格式化等通用逻辑抽取为独立工具函数。  
2. `request_logger.py` 移除原有重复实现，改为调用 `create_log_targets`、`log_json`。  
3. 新增单元测试 `test_log_utils.py` 验证 stdout、文件以及多目标日志的行为。

**🎯 影响范围**：  
- `sglang/srt/utils/request_logger.py`（日志目标创建、日志写入路径）  
- 可能的其他模块若自行实现类似功能，可统一改为使用 `log_utils`。  
- 测试套件新增 `test_log_utils.py`，对 CI/CI‑CD 运行时间有轻微增加。

**💡 关注建议**  

1. **日志实例唯一性**  
   `create_log_targets` 通过 `logging.getLogger(name)` 获取 logger，并在 logger 没有 handler 时才添加。若同一 `name_prefix` 多次调用（例如在同一进程的不同组件），会复用已有 logger，导致后续调用不再添加新 handler，可能出现日志丢失或重复写入。建议在文档或实现中明确 logger‑name 的作用域，或在 `create_log_targets` 中加入 `logger.handlers.clear()`（或 `logger.setLevel`）的显式重置选项。  

2. **分布式环境依赖**  
   文件日志的文件名使用 `torch.distributed.get_rank()`，但 `log_utils` 本身没有 `torch` 依赖声明。若在非分布式环境或未安装 `torch`，导入会抛异常。可以改为 `try/except ImportError` 包装，或在函数内部延迟导入 `torch.distributed`。  

3. **TimedRotatingFileHandler 参数**  
   `backupCount=0` 表示不限制历史文件数量，可能在长时间运行的服务器上产生大量日志文件。建议提供可配置的 `backup_count` 环境变量或函数参数，以防磁盘被占满。  

4. **单元测试的可靠性**  
   - `test_stdout` 通过 `redirect_stdout` 捕获 `StreamHandler(sys.stdout)` 的输出，这在大多数情况下可行，但若其他代码在执行期间修改 `sys.stdout`（如使用 `os.dup2`），可能导致捕获失效。建议在测试中显式传入 `logging.StreamHandler(buf)` 的 handler，或使用 `logging.setLogRecordFactory`。  
   - 文件日志使用 `TimedRotatingFileHandler`，在测试结束后应确保 `handler.close()` 被调用，以释放文件句柄并避免 Windows 上的文件占用错误。可以在 `_flush_all` 后加入 `handler.close()`。  

5. **日志格式**  
   `log_json` 直接使用 `json.dumps(..., ensure_ascii=False)`，如果 `data` 中含有不可序列化的对象会抛异常。考虑在 utils 中加入 `default=str` 或捕获异常并记录错误，以提升稳健性。  

6. **向后兼容**  
   原来的 `_create_log_target_*`、`_log_json` 等私有函数已被删除，若内部或外部还有直接导入路径（如 `from sglang.srt.utils.request_logger import _create_log_target_file`），会导致 ImportError。检查仓库是否还有此类引用，必要时保留兼容别名或在 `__all__` 中注明已废弃。  

**总体评价**：此次抽取消除了 `request_logger` 中的重复实现，提升了代码可复用性和可维护性，新增的单元测试也保证了核心功能的正确性。只要注意上述分布式导入、日志句柄管理以及向后兼容性，即可安全合并。

---

### [MTP][spec_v2] Fix TRTLLM MLA backend crash in EAGLE draft_extend mode  (#15790)
**SHA**: `3fd88ea` | 🔗 [查看提交](https://github.com/sgl-project/sglang/commit/3fd88ea9b54b176b5f6872ea623483be1a6149bb)

**变更类型**：Bug 修复 / 功能增强  
**重要程度**：🟡 中  

**变更摘要**  
- 在 `init_forward_metadata_replay_cuda_graph` 中，修正 draft‑extend 模式下查询序列长度的计算：改为 `accept_length + 1` 并相应更新 `cu_seqlens_q` 与 `seq_lens_q`。  
- 在 `forward_extend` 中加入对 **target_verify** 与 **draft_extend** 两种情形的专门处理：  
  1. 当所有序列拥有相同 draft 数时直接 reshape。  
  2. 当 accept 长度不均匀时，判断是否可以直接 view，若不能则使用 `pad_draft_extend_query` 对查询张量做零填充，并在后处理时通过 `unpad_draft_extend_output` 恢复原始形状。  

**影响范围**  
- `python/sglang/srt/layers/attention/trtllm_mla_backend.py`（TRT‑LLM MLA 后端）  
- 依赖该后端的 EAGLE draft_extend 推理流程、以及任何使用 `forward_extend` 的 speculative decoding 路径。  

**关注建议**  
1. **功能验证**：构造 batch 中 accept_length 不同的案例，确保 forward → pad → decode → unpad 全链路输出与期望一致，且不再出现 CUDA graph 崩溃。  
2. **性能评估**：对比均匀 vs. 非均匀序列的推理时延与显存占用，特别是 pad‑buffer 的分配是否合理。  
3. **异常安全**：检查 `self.padded_q_buffer` 在多线程/多进程环境下的生命周期，防止出现 stale buffer。  
4. **文档/注释**：补充 draft_extend‑mode 下 seq_len、cu_seqlens 计算逻辑的说明，方便后续维护。  

总体上，此次修改消除了在 EAGLE draft_extend 场景下因长度不一致导致的崩溃，保持原有路径不变，对性能影响有限，只需针对新分支路径做好回归测试即可。

---

### Add top-p to run_eval.py (#16844)
**SHA**: `aeb480c` | 🔗 [查看提交](https://github.com/sgl-project/sglang/commit/aeb480c11fe29d992f3e62f6d1afa8e32ec3da19)

**🎯 变更类型**：功能增强  
**⚡ 重要程度**：🟡 中  
**📋 变更摘要**：在 `run_eval.py`、公共评估代码以及文档中新增 `--top-p` 参数，默认值 1.0，并将其向下传递至 `ChatCompletionSampler` 与底层 OpenAI‑compatible 调用，从而支持 nucleus 采样。  
**🎯 影响范围**：  
- `python/sglang/test/run_eval.py`（CLI 参数、调用链）  
- `python/sglang/test/simple_eval_common.py`（`SimpleEval` 构造函数和调用）  
- `sglang.test.run_eval` 中的 `ChatCompletionSampler`（新增 `top_p` 参数）  
- 文档 `docs/basic_usage/deepseek_v32.md`（示例命令更新）  

**💡 关注建议**：  
1. **向后兼容**：默认 `top_p=1.0` 与原行为等价，现有脚本不会受影响。若有自定义 `top_p`，请确认模型端点支持该参数。  
2. **参数校验**：建议在 CLI 中加入取值检查（0.0 ≤ top_p ≤ 1.0），防止非法输入导致后端错误。  
3. **测试覆盖**：补充单元测试，验证 `SimpleEval` 在不同 `top_p` 下的请求体结构以及返回结果的可重复性。  
4. **文档同步**：确保所有使用 `run_eval` 的示例（尤其是其他模型的评估文档）同步加入 `--top-p` 说明，避免用户误解默认行为。  

总体而言，此次改动为评估流程提供了更灵活的采样控制，影响范围局限在评估相关模块，风险较低。继续监测实际运行时的兼容性即可。

---

### enhance LoRA tests and fix base model LoRA eviction in Scheduler (#16333)
**SHA**: `6327dff` | 🔗 [查看提交](https://github.com/sgl-project/sglang/commit/6327dff24264955fc828906cd85c72bb8e7648fc)

**🟢 变更概览**  
- **Scheduler**：在 `_get_new_batch_prefill_raw` 中改为直接 `continue` 跳过超出 LoRA 槽上限的请求，并在注释中说明淘汰策略优先驱逐 LoRA 而非基础模型。  
- **LoRA 测试**：在 `lora_utils.py` 新增 `max_loaded_loras` 参数；加入 Qwen‑3 多 LoRA 案例；实现 `run_lora_batch_splitting_equivalence_test`，验证 SRT 在内部批拆分多适配器时输出差异；相应地在 `test/manual`、`test/registered` 中统一引用 `LORA_MODELS_QWEN3`，并删除冗余旧注册文件。  

**⚡ 影响范围**  
- 核心调度器 (`python/sglang/srt/managers/scheduler.py`)  
- LoRA 运行时配置 (`SRTRunner` 参数)  
- 测试套件：`test/lora_utils.py`、`test/manual/lora/…`、`test/registered/lora/…`  

**🔍 关键关注点**  
1. **调度死锁风险**：若待调度队列全部是超额 LoRA 请求，单纯 `continue` 可能导致无限循环。建议在循环外检测是否仍有可运行请求，若无则触发 LoRA eviction 或放宽 `max_loaded_loras`。  
2. **内存池一致性**：注释提到 “evict LoRA adapters over base model”。请确认 `mem_pool.py` 的淘汰策略已同步更新，且 `max_loaded_loras` 参数被正确传递到 `SRTRunner`、`Scheduler` 与 `MemoryPool`。  
3. **测试完整性**：新加入的批拆分等价性测试覆盖了不同适配器组合，但仍未覆盖 `max_loaded_loras` 限制下的强制淘汰场景。建议补充一条仅加载 `max_loaded_loras` = 1 时的多 LoRA 请求测试。  
4. **CI 注册**：删除 `test/registered/lora/test_lora.py` 后，相关 CI 任务仍在 `test/registered/lora/test_multi_lora_backend.py` 中注册，确保所有平台（CUDA/AMD）仍能执行完整的 LoRA 测试。  

**✅ 建议**  
- 在调度循环外加入 “无可调度请求 → 触发 LoRA 淘汰” 的安全路径。  
- 为 `max_loaded_loras` 参数在 `SRTRunner` 的 docstring 添加说明，防止使用者误以为默认无限制。  
- 将新测试加入 nightly CI，确保批拆分兼容不同后端（torch_native、flash_attn 等）。  

整体来看，改动提升了 LoRA 调度的鲁棒性并强化了多适配器测试，除少量潜在死锁及文档同步问题外，风险可通过上述措施轻松规避。

---

### [CI] Add PD Disaggregation aarch64 test (#16572)
**SHA**: `4b14f62` | 🔗 [查看提交](https://github.com/sgl-project/sglang/commit/4b14f622e142eedf199b7ae7308ff0c4cc450352)

** 🎯 变更类型**：功能增强（新增 PD Disaggregation aarch64 测试）  
** ⚡ 重要程度**：🟡 中  
** 📋 变更摘要**：  
1. 在 CI 镜像的 `Dockerfile` 中固定安装 `mooncake-transfer-engine==0.3.8.post1`，并移除原来的条件安装逻辑。  
2. 将新测试 `test_disaggregation_aarch64.py` 加入 `per‑commit‑4‑gpu‑gb200` 测试套件，覆盖分布式预填充/解码（prefill / decode）模式下的准确性检查。  

** 🎯 影响范围**  
- **docker/Dockerfile**：构建环境、依赖版本。  
- **test/srt/run_suite.py**：CI 调度表。  
- **test/srt/test_disaggregation_aarch64.py**：新增的功能/回归测试。  
- 相关的 **sglang.test.server_fixtures.disaggregation_fixture** 与 **test_utils**（用于启动 PD Server、负载均衡器）。  

** 💡 关注建议**  

1. **依赖锁定**  
   - 直接写死 `mooncake-transfer-engine==0.3.8.post1` 可以避免 CI “GRACE_BLACKWELL” 变量导致的不同镜像，但也让后续升级更困难。建议在 `requirements.txt`（或类似文件）中统一管理并注明该版本是 CI 必需的，以便一次性更新。  

2. **测试可靠性**  
   - 该测试启动了两套 PD Server（prefill + decode）并对外部模型进行 200 条 GSM8K 评估，耗时约 300 s。建议在 CI 中提供足够的资源超时设置，防止因机器负载导致偶发超时。  
   - `assertGreater(metrics["accuracy"], 0.62)` 与模型、硬件、库版本紧耦合，若底层模型或 `mooncake` 产生细微数值波动，CI 可能出现不必要的回滚。可考虑放宽阈值或把阈值写入配置。  

3. **环境变量清理**  
   - `setUpClass` 中写入 `SGLANG_MOONCAKE_CUSTOM_MEM_POOL` 与 `MC_FORCE_MNNVL`，`tearDownClass` 已弹出，但若异常中途导致 `tearDownClass` 未执行，环境变量会残留在后续测试进程。可在 `setUp`/`tearDown` 中使用 `try/finally` 或 `addCleanup` 确保清理。  

4. **资源回收**  
   - `popen_launch_pd_server` 启动的子进程在 `tearDownClass` 通过父类实现的 `cleanup` 关闭，但请确认 `PDDisaggregationServerBase` 已对 `process_prefill` 与 `process_decode` 使用 `process.terminate()` 并 `process.wait()`，防止僵尸进程占用 CI 节点。  

5. **CI 并发与调度**  
   - 新增测试被挂到 `per-commit-4-gpu-gb200`，意味着需要 4 块 GPU（每块 200 GB）才能跑全套。若 CI 节点不足，整个套件可能被跳过或阻塞。建议在 CI 配置中为此套件添加明确的资源标签，并在文档里注明最低硬件要求。  

6. **代码可读性**  
   - `test_disaggregation_aarch64.py` 中大量硬编码（`tp=2`、`base-gpu-id=2`、`parallel=128`）如果以后想在其他硬件上跑，需要改动测试代码。考虑把这些参数抽取为类属性或通过环境变量配置，以提升可复用性。  

总体来看，变更在功能层面为 aarch64 分布式推理提供了可自动化的准确性校验，提升了项目的回归覆盖度。但需关注依赖版本锁定、测试资源消耗以及环境变量/进程的完整清理，以避免 CI 产生不稳定或资源泄漏。适当加入配置化、阈值容忍及文档说明，可让该改动在长期维护中更加可靠。

---

### Fix EPLB + FP4 Quantization Compatibility Issue (#13715)
**SHA**: `d27f16f` | 🔗 [查看提交](https://github.com/sgl-project/sglang/commit/d27f16f38a6f23e5a7c529c6f052ac11f28c4a97)

**🎯 变更类型**：功能增强 / Bug 修复  
**⚡ 重要程度**：🟡 中  

**📋 变更摘要**  
新增 `filter_moe_weight_param_global_expert` 工具函数，用于在获取 MoE 权重时过滤掉需要全局 expert（或内部使用的 swizzled 参数）的张量。各个 MoE 模型（bailing、deepseek‑v2、glm4、gpt‑oss、longcat_flash、qwen2、qwen3）在 `get_moe_weights` 实现中统一加入该过滤，解决了 EPLB 与 FP4 量化配合时出现的不匹配错误。

**🎯 影响范围**  
- `sglang/srt/layers/moe/utils.py`（新函数实现）  
- 所有基于 MoE 的模型文件：`bailing_moe.py、deepseek_v2.py、glm4_moe.py、gpt_oss.py、longcat_flash.py、qwen2_moe.py、qwen3_moe.py`。  

**💡 关注建议**  
1. **兼容性检查**：该过滤仅排除 `*_blockscale_swizzled` 和标记为 `_sglang_require_global_experts` 的参数，确保这些参数在其它路径（如 checkpoint 保存/加载、梯度剪裁）仍能被正确处理。  
2. **单元测试**：补充针对 `filter_moe_weight_param_global_expert` 的测试，验证在不同 expert 数量、不同维度张量以及带有标记的参数下的过滤行为。  
3. **文档更新**：在 MoE 量化章节说明此过滤的目的与使用场景，帮助用户理解何时会出现 “requires global expert” 的参数。  
4. **性能监控**：在高吞吐服务下观察 `get_moe_weights` 的执行时间，确认过滤逻辑未引入显著开销。  

总体而言，此次修改通过统一过滤逻辑解决了 EP‑LB 与 FP4 量化的兼容性问题，影响范围局限于 MoE 权重提取，风险较低。后续关注上述建议可进一步提升稳定性与可维护性。

---

### Tiny let soft watchdog cover initialization phase (#16853)
**SHA**: `c89949b` | 🔗 [查看提交](https://github.com/sgl-project/sglang/commit/c89949bbaf40e4f70632037b1f8b096b39dbc397)

**变更概述**  
本次提交在 `Scheduler` 初始化期间加入了软看门狗（soft watchdog）机制，使得在模型、缓存、调度策略等资源准备阶段也能被超时检测捕获。新增环境变量 `SGLANG_TEST_STUCK_SCHEDULER_INIT` 用于在测试中模拟初始化卡死。  

**核心改动**  
1. `environ.py` 新增 `SGLANG_TEST_STUCK_SCHEDULER_INIT`（默认 0），保持与其它 `SGLANG_TEST_STUCK_*` 环境变量的统一。  
2. `scheduler.py`  
   - 增加 `self.is_initializing` 标志，构造函数开始即置为 `True`；在完成所有初始化后置为 `False`。  
   - 在构造函数前段调用 `init_soft_watchdog`，若 `server_args.soft_watchdog_timeout` 不为空则创建软看门狗实例。  
   - 在模型加载后加入调试用的 `time.sleep`（受 `SGLANG_TEST_STUCK_SCHEDULER_INIT` 控制），用于验证超时行为。  
3. `scheduler_runtime_checker_mixin.py`  
   - `dump_info` 与 `is_active` 判定均考虑 `scheduler.is_initializing`，防止初始化期间误报请求日志。  
   - `get_counter` 使用 `getattr(..., 0)`，避免在初始化阶段 `forward_ct` 尚未创建导致 `AttributeError`。  
4. 新增单元测试 `TestSoftWatchdogSchedulerInit`，验证初始化阶段软看门狗能够触发超时异常。  

**影响范围**  
- **Scheduler** 的生命周期管理（初始化、软看门狗创建、状态判断）全部受此修改影响。  
- **测试体系** 添加了对应的环境变量覆盖与验证用例。  
- **运行时日志** 在初始化阶段不再输出请求日志，避免噪声。  

**关注建议**  
- `is_initializing` 仅在 `__init__` 正常返回后置 `False`，若初始化抛异常可能导致软看门狗永远保持激活，建议在 `__init__` 包裹 `try/except/finally`，在异常路径同样恢复标志。  
- 软看门狗的创建顺序已提前，但仍需确认 `soft_watchdog_timeout` 与主看门狗的 `watchdog_timeout` 两者不产生冲突（如相同超时导致重复异常）。  
- 文档中补充新环境变量的说明及使用场景，防止用户误以为其是生产参数。  
- 性能影响极小，仅在初始化阶段多了一层标志检查和一次 `getattr`，可认为是可接受的安全提升。  

总体来看，此改动提升了系统在启动阶段的鲁棒性，适配了“软看门狗覆盖初始化”需求，影响范围局限于 Scheduler 与相关测试，风险低但仍需注意异常恢复路径。

---

### [DSv32] Overlap indexer weights_proj during dual_stream decode (#16637)
**SHA**: `20abaee` | 🔗 [查看提交](https://github.com/sgl-project/sglang/commit/20abaee26cd8ac1387584775babf910c517c3388)

**🎯 变更类型**：功能增强（解码阶段算子并行）  
**⚡ 重要程度**：🟡 中  
**📋 变更摘要**：  
1. 在 `nsa_indexer.py` 中新增 `@torch.compile(dynamic=True)` 的 `_project_and_scale_head_gates`，在 dual‑stream decode 时提前计算并缩放 head gate 权重，随后与 `act_quant` 的 FP8 量化在不同 CUDA stream 上并行。  
2. `forward_cuda` 的分支逻辑被重写，保证在 decode 或 idle 状态下 `query`、`key` 的量化与 indexer 计算交叉执行，同时统一了 `weights` 的获取方式（使用 `_project_and_scale_head_gates` 或 `_get_logits_head_gate`）。  
3. 在 `deepseek_v2.py` 中把 `indexer` 的调用提前到 `q_b_proj` 之后，同样在 capture 模式下利用 `alt_stream` 与 `q_b_proj` 并行，并在非并行路径保持原有行为。

**🎯 影响范围**：  
- `sglang/srt/layers/attention/nsa/nsa_indexer.py`（核心索引器与权重投射）  
- `sglang/srt/models/deepseek_v2.py`（DeepSeek‑V2 模型前向准备）  
- 受 `torch.compile`、CUDA stream 与 capture 模式影响的所有使用该 attention 实现的模型。

**💡 关注建议**：  
1. **功能验证**：在 decode、prefill、以及 capture 与非 capture 两种执行模式下，分别跑完整的推理/生成基准，确认输出与旧版一致（特别是 logits scaling 与 softmax 乘子）。  
2. **兼容性**：`torch.compile` 仍在实验阶段，建议在 CI 中加入 `TORCH_COMPILE_DISABLE=1` 的回退路径，防止在不支持的环境（如旧版 CUDA、CPU）崩溃。  
3. **同步安全**：确保 `self.alt_stream` 在所有进程/线程中已正确初始化；若为 `None`，当前实现会直接走原路径，不应出现 `AttributeError`。  
4. **梯度传播**：`_project_and_scale_head_gates` 中 `weights_proj` 仍保持 `float()` 强制转型，需检查在训练模式下梯度是否被截断或数值异常。  
5. **内存与性能**：并行流会增加临时 FP8 缓冲区的并发占用，建议监控显存峰值；在显存紧张的模型上可能出现 OOM。  
6. **代码可读性**：`forward_cuda` 中多层嵌套的 `if enable_dual_stream` 逻辑稍显复杂，可考虑抽取为小函数以降低维护成本。  

总体而言，此次改动通过流并行显著提升了解码阶段的吞吐，但需在不同硬件/库版本下做充分回归，以防止编译、同步或数值一致性问题。

---

### Tiny add CPU resource monitoring for overload diagnosis (#16852)
**SHA**: `32a569f` | 🔗 [查看提交](https://github.com/sgl-project/sglang/commit/32a569fb77c58b7cba8afe33f29c82295c57e3c1)

**🎯 变更类型**：功能增强（CPU 使用率监控）  
**⚡ 重要程度**：🟡 中  

**📋 变更摘要**  
- 新增 `sglang/srt/metrics/cpu_monitor.py`，在后台线程中定期采集进程的用户/系统 CPU 时间，并通过 Prometheus `sglang:process_cpu_seconds_total` Counter 上报。  
- 在 `DataParallelController、DetokenizerManager、TokenizerManager` 三个核心组件的构造函数里，在 `enable_metrics` 为真时调用 `start_cpu_monitor_thread`，分别打上组件标签。  
- 单元测试 `test_cpu_monitor.py` 验证线程创建、守护属性以及 Counter 能在短时间内累加正值。  
- 将该指标加入原有 metrics 检查列表，确保监控覆盖。

**🎯 影响范围**  
- **调度层**：`data_parallel_controller`、`detokenizer_manager`、`tokenizer_manager`。  
- **监控系统**：Prometheus 抓取新增 CPU 指标。  
- **CI**：新增 CPU‑CI 注册，运行时会占用一点 CPU 进行自测。

**💡 关注建议**  
1. **线程安全**：`psutil.Process().cpu_times()` 读取在多线程环境下是线程安全的，但若后续在同一进程启动多个监控线程（如在多实例部署时），需确认不会产生重复上报。可在 `start_cpu_monitor_thread` 中加入全局字典防止同组件重复启动。  
2. **资源开销**：默认采样间隔 5 s，CPU 开销极低；若在高并发场景下需调低间隔，请评估对整体性能的影响。  
3. **异常处理**：监控循环未捕获 `psutil` 可能抛出的异常，建议在 `while True` 内加 `try/except`，防止因短暂的系统调用失败导致线程退出。  
4. **文档/配置**：在 `ServerArgs` 中已有 `enable_metrics`，建议在帮助信息里说明新增的 “process_cpu_seconds_total” 指标及其标签含义。  
5. **兼容性**：仅在 `enable_metrics` 为真时启动，不会影响不需要监控的部署，保持向后兼容。  

总体来看，此次改动为诊断 CPU 过载提供了基础度量，影响模块明确，风险可控，建议在正式发布前加入异常日志与重复启动检测。

---

### Tiny add routing key distribution metrics (#16847)
**SHA**: `3ed3b7e` | 🔗 [查看提交](https://github.com/sgl-project/sglang/commit/3ed3b7ef7c9b67634a2260535480e10314308aae)

**🟩 变更类型**：功能增强  
**⚡ 重要程度**：🟡 中  

**📋 变更摘要**  
- 在调度层新增路由键（routing key）分布统计：运行中的唯一路由键数、运行/全部请求数的直方图。  
- 完善 `SchedulerStats`，实现 `compute_routing_key_stats` 辅助函数。  
- 增加对应 Prometheus `Gauge` 与 `GaugeHistogram` 指标，并在 `log_stats` 中上报。  
- 为新指标补充单元测试，确保 bucket 完整性与统计函数的边界行为。

**🎯 影响范围**  
- `sglang/srt/managers/scheduler_metrics_mixin.py`（调度统计逻辑）  
- `sglang/srt/metrics/collector.py`（指标结构、注册、上报）  
- `sglang/srt/utils/gauge_histogram.py`（直方图实现）  
- 测试目录 `test/registered/metrics/test_metrics.py`（新增验证）

**💡 关注建议**  
- **性能**：`compute_routing_key_stats` 在每次调度日志时遍历运行与等待队列，最好确认队列规模不会导致显著开销；如有必要，可在高并发场景下采样或缓存。  
- **监控**：部署后观察 `sglang:num_unique_running_routing_keys` 与两组直方图的采样频率，避免因标签维度过多导致 Prometheus 存储膨胀。  
- **兼容性**：新增指标默认开启，不会影响已有用户；若已有监控脚本依赖精确的 metric 名单，请同步更新。  
- **测试**：CI 已覆盖空、None、混合及大分布情形，建议在真实服务中跑一次完整的指标抓取，验证 bucket 边界（`gt`/`le`）与 Prometheus 端的一致性。  

总体而言，此次改动为路由键粒度的可观测性提供了重要数据，影响范围局限在调度统计与监控层，风险可控。

---

### Tiny add gauge histogram abstraction for engine and router (#16848)
**SHA**: `1f9d479` | 🔗 [查看提交](https://github.com/sgl-project/sglang/commit/1f9d4795a94e3aaafa2969fe60c4b372fdb809c1)

**🎯 变更类型**：功能增强（为引擎和路由层加入 Grafana‑友好的 Gauge‑Histogram 抽象）  
**⚡ 重要程度**：🟡 中  
**📋 变更摘要**：  
1. 新增 `python/sglang/srt/utils/gauge_histogram.py`，实现基于非累计 bucket（gt/le）的 Gauge，提供 `BucketLabels`、`GaugeHistogram`，并加入原始值、观测值两种写入方式。  
2. 在 Rust 端同步实现 `sgl-model-gateway/src/observability/gauge_histogram.rs`，保持两端行为一致。  
3. `sgl-model-gateway/src/observability/mod.rs` 暴露新模块。  
4. 编写 Python 单元测试以及 Rust 测试，覆盖标签生成、边界、空值、浮点等场景。  

**🎯 影响范围**：  
- **Python**：`sglang/srt/utils`（监控工具库），`sglang/srt` 及其调用方（引擎、router）将可以直接使用 `GaugeHistogram` 来上报热图数据。  
- **Rust**：`sgl-model-gateway/src/observability`（模型网关的观测层），新增 `gauge_histogram` 模块后，需要在相应的业务代码里引入并使用。  

**💡 关注建议**  

1. **保持实现同步**  
   - 两端的 bucket 生成逻辑已经相同，但后续若修改上限或标签格式，需要同时更新 Python 与 Rust 文件。建议在 `README` 或代码注释中加入“请同时更新对应实现”的提醒，或抽取共通配置文件（如 JSON）供两端读取。  

2. **输入校验**  
   - 当前 `BucketLabels` 未检查 `upper_bounds` 是否升序或包含负数。建议在 `__init__` 中加入 `assert all(b > 0 for b in upper_bounds)` 与排序检查，防止误用导致异常 bucket。  

3. **多进程指标兼容**  
   - `GaugeHistogram` 在 Python 中默认 `multiprocess_mode="mostrecent"`，但在多进程环境下可能出现标签冲突。请在文档中说明该模式的适用场景，或提供可选的 `all`/`liveall` 模式示例。  

4. **性能与内存**  
   - `compute_bucket_counts` 对每次观测都遍历 `upper_bounds`（O(log n)）并创建临时 `counts` 列表。若观察值频率极高，可考虑在 `GaugeHistogram` 内部维护一个循环缓冲区或累计计数器，以降低 GC 开销。  

5. **测试覆盖**  
   - 已有单元测试覆盖基本情况，建议再补充：  
     - 空 `bucket_bounds`（应抛异常）  
     - 重复上限值（应合并或报错）  
     - 极大值（> 2³⁶）在 Rust `u64` 范围内的行为  
   - 在 CI 中加入跨语言的对比测试，确保 Python 与 Rust 计算的 bucket 分布一致。  

6. **文档与示例**  
   - 在 `sglang` 与 `sgl-model-gateway` 项目的监控章节加入使用示例，展示如何在模型推理路径中记录响应时延、 token 长度等热图指标。  

总体来看，此次改动为可观测性提供了更直观的热图支持，影响范围明确且代码质量良好。只需关注实现同步、输入校验及多进程兼容性，即可安全上线。

---

### Revert "feat: reduce constrained-decoding overhead in TP" (#16845)
**SHA**: `e6d40bf` | 🔗 [查看提交](https://github.com/sgl-project/sglang/commit/e6d40bff81644416b2fa2fd193136ee446ccde53)

**🎯 变更类型**：revert / 代码简化  
**⚡ 重要程度**：🟡 中  
**📋 变更摘要**  
本次提交撤回了 “reduce constrained‑decoding overhead in TP” 的优化，实现上恢复了 TP（tensor‑parallel）下语法约束的原有同步逻辑，并对多个核心模块进行简化：  
1. `Sampler` 统一使用 `get_tp_group().device_group`，在 DP‑Attention 开启时再次切换。  
2. 只要 `SYNC_TOKEN_IDS_ACROSS_TP` 为真或请求携带语法（`sampling_info.grammars`），就强制在所有 TP 进程间 `all_reduce` 最终 token ID，避免因非确定性算子导致的 rank 不一致。  
3. `ScheduleBatch` 与 `Scheduler` 中关于 grammar‑cache 的 TP 分支被删减，改为所有 rank 统一走缓存或 `Future`，仅在 TP>1 时通过 `all_reduce` 同步 ready/timeout 计数。  
4. `ModelRunner._preprocess_logits`、`SamplingBatchInfo`、`SamplingParams` 等内容也同步去掉了 “只在 rank‑0 编译 vocab mask” 的条件，直接在所有 rank 上执行 mask 与 bias。  
5. 删除了 `SamplingParams.has_grammar_constraint` 属性以及对应的测试代码，简化了 API。  

**🎯 影响范围**  
- **srt.layers.sampler**：TP 同步策略与 NaN 检测初始化。  
- **srt.managers.schedule_batch / scheduler**：grammar‑cache 管理、TP 同步计数、请求状态迁移。  
- **srt.model_executor.model_runner**：logits 预处理不再区分 rank‑0。  
- **srt.sampling.* (sampling_batch_info、sampling_params)**：语法 mask 生成与 logits bias 接口改变。  
- **测试套件**：移除 TP=2 的 grammar 相关测试，确保 CI 在单卡环境下通过。  

**💡 关注建议**  
1. **功能回归**：恢复了所有 TP rank 上的 vocab‑mask 编译与 token‑id 同步，可能导致原本的 “TP‑overhead‑reduction” 性能提升回落。建议在多卡部署下跑一次基准，确认吞吐或 latency 是否仍在可接受范围。  
2. **同步一致性**：`all_reduce` 现在在 `SYNC_TOKEN_IDS_ACROSS_TP` 为 true 或有 grammar 时强制执行，确保 `SYNC_TOKEN_IDS_ACROSS_TP` 环境变量仍保持默认关闭，以免产生不必要的通信开销。若业务强依赖 determinism（如使用 xgrammar），请显式打开。  
3. **DP‑Attention 场景**：代码在 `is_dp_attention_enabled()` 为 true 时再次覆盖 `tp_sync_group`，但未同步 `tp_rank` 与 `tp_size`。若后续需要在 DP‑Attention 中使用 rank‑0 判断，请确认相关路径仍能获取正确的 rank 信息（可能需要恢复 `tp_rank`/`tp_size` 变量）。  
4. **API 变更**：`SamplingParams.has_grammar_constraint` 已被删除，外部代码若仍依赖该属性会报错。请检查自定义工具或插件的实现，改为直接检查 `json_schema / regex / ebnf / structural_tag`。  
5. **异常处理**：`move_ready_grammar_requests` 现在在 timeout/invalid 情况下直接 `set_finish_with_abort`，但不再广播无效请求索引。确保所有 rank 在异常路径上保持一致的 abort 状态，避免出现 “部分 rank 卡死” 的情况。  
6. **单元测试**：本次删除了多卡 TP 测试，若项目在生产环境需要 TP>1，建议自行补充相应的集成测试，验证 grammar 编译、缓存同步、超时处理在真实多卡场景下的正确性。  

**总体结论**  
此次提交是一次 **功能回退 + 代码简化**，把 TP 语法约束相关的特殊分支删除，恢复了更保守的同步行为，提升了可维护性，但也可能牺牲之前的性能优化。建议在多卡部署环境进行性能回归和一致性验证，特别关注 `SYNC_TOKEN_IDS_ACROSS_TP` 与 DP‑Attention 组合时的行为。若对吞吐有严格要求，可考虑在后续 PR 中重新实现更细粒度的 TP “只在 rank‑0 编译 mask” 逻辑。

---

### Add routing key based schedule policy (#16840)
**SHA**: `1f0ea4f` | 🔗 [查看提交](https://github.com/sgl-project/sglang/commit/1f0ea4f958c3fd85bbbd4c7ce96745dcc6a4fe1f)

**变更类型**：功能增强  
**重要程度**：🟡 中  

**变更摘要**  
新增 “routing‑key” 调度策略：在计算等待队列优先级时，会统计当前运行批次中各 `routing_key` 出现次数，优先派发与之相同且出现频率更高的请求。为此扩展了 `CacheAgnosticPolicy`、`SchedulePolicy.calc_priority` 接口、调度器调用以及 CLI 参数，同时提供环境变量 `SGLANG_ROUTING_KEY_POLICY_DEBUG_LOG` 控制调试日志。

**影响范围**  
- `sglang/srt/managers/schedule_policy.py`（核心调度逻辑）  
- `sglang/srt/managers/scheduler.py`（调度入口）  
- `sglang/srt/server_args.py`（CLI 选项）  
- `sglang/srt/managers/schedule_batch.py`（`Req` 结构已使用 `routing_key`）  
- 测试目录 `test/manual`、`test/registered`（新增单元与集成测试）

**关注建议**  
1. **兼容性**：确保所有 `Req` 实例在生产代码中均携带 `routing_key`（默认 `None`），避免 `AttributeError`。若某些请求不需要路由键，策略已把它们降到队尾，建议在文档中说明行为。  
2. **性能**：`Counter` 对运行批次进行一次遍历，开销有限，但在极大 batch 场景下可关注 CPU 使用率。可考虑在 `running_batch` 为空时直接跳过统计。  
3. **调试日志**：环境变量默认关闭，开启后会在每轮调度打印前后键列表，生产环境请关闭以防泄露敏感信息。  
4. **测试完善**：当前已覆盖常规、无匹配、空 batch 等情况，建议再加入并发高压下的稳定性测试，验证 `routing_key` 策略与现有 `max-running-requests`、`prefill` 机制的交互。  
5. **文档更新**：在 server 参数说明及调度策略文档中添加 `routing-key` 选项及其适用场景，说明环境变量的作用。  

总体来看，此次改动在不影响既有策略的前提下，提供了基于业务路由键的流量调度能力，提升了多租户或分组请求的响应公平性。后续关注实现的鲁棒性与监控即可。

---

### Tiny pass routing key to scheduler processes (#16839)
**SHA**: `15da306` | 🔗 [查看提交](https://github.com/sgl-project/sglang/commit/15da3061bcb1b5207185f103c1f92eefc027b336)

**🎯 变更类型**：功能增强  
**⚡ 重要程度**：🟡 中  

**📋 变更摘要**  
为请求对象新增 `routing_key` 字段，并在 OpenAI 接口入口（chat、completion、embedding）及内部请求结构体中透传该字段。调度批次 (`ScheduleBatch`) 和 tokenizer 管理器相应接受并保存该键，以支持基于路由键的调度策略。

**🎯 影响范围**  
- `python/sglang/srt/entrypoints/openai/*`（请求解析层）  
- `python/sglang/srt/managers/io_struct.py`（请求数据结构）  
- `python/sglang/srt/managers/schedule_batch.py`（调度批次对象）  
- `python/sglang/srt/managers/tokenizer_manager.py`（tokenizer 创建流程）  

**💡 关注建议**  
1. **向后兼容**：若下游调度逻辑未使用 `routing_key`，需确保默认值 `None` 不影响现有行为。  
2. **安全/校验**：`x-smg-routing-key` 来自 HTTP Header，建议加入长度或字符集校验，防止异常键导致调度异常。  
3. **文档更新**：在 API 文档和使用手册中说明新 Header 的作用、取值约定以及对应的调度策略。  
4. **监控/日志**：在调度日志中记录 `routing_key`，便于后期排查路由分配问题。  
5. **测试覆盖**：补充单元/集成测试，验证在有/无该 Header 时请求能够正确转化为内部结构并进入调度。  

整体改动量小且局部，风险主要在新字段的传播路径和调度策略实现上，建议在部署前进行端到端回归验证。

---

### Tiny support customizing prometheus buckets for prefill delayer (#16831)
**SHA**: `6406a59` | 🔗 [查看提交](https://github.com/sgl-project/sglang/commit/6406a5969b0123e911cad75d71e2db48b3b7be14)

**🎯 变更类型**：功能增强  
**⚡ 重要程度**：🟡 中  
**📋 变更摘要**：在 `SchedulerMetricsCollector` 中加入 `server_args` 参数，以支持通过 CLI 自定义 prefill‑delayer 的两个 Prometheus 直方图 buckets（forward passes 与等待秒数），并在 `ServerArgs` 中新增对应配置字段与 CLI 入口。  
**🎯 影响范围**：`scheduler_metrics_mixin.py`、`collector.py`、`server_args.py` 以及可能直接实例化 `SchedulerMetricsCollector` 的其他模块。  
**💡 关注建议**  
1. **兼容性**：`SchedulerMetricsCollector.__init__` 现在默认 `server_args=None`，但内部直接访问 `server_args.prefill_delayer_max_delay_passes`，在 `server_args` 为 `None` 时会抛异常。建议加 `if server_args:` 判断或使用 `getattr` 并提供合理默认。  
2. **验证**：对用户自定义 bucket 做合法性检查（必须为正数、且小于 `max_delay`），防止 Prometheus 报错。  
3. **文档 & 监控**：更新文档说明新 CLI 参数的含义，并在仪表盘中加入对应 bucket 的解释，避免监控误判。  
4. **单元测试**：补充测试，验证默认 bucket、用户自定义 bucket 与自动加入的 `0`、`max_delay‑1` 是否正确生成。  

总体改动聚焦指标可配置化，风险主要在空参和 bucket 合法性，按上面建议处理即可安全上线。

---

### Tiny add command line args for prefill delayer and unify names (#16830)
**SHA**: `cec19b5` | 🔗 [查看提交](https://github.com/sgl-project/sglang/commit/cec19b56c651252737b24ccc7a87450a34d8d931)

**🎯 变更类型**：功能增强（为 Prefill Delayer 引入统一的命令行参数）  
**⚡ 重要程度**：🟡 中  

**📋 变更摘要**  
- 在 `environ.py` 中新增对旧环境变量的统一 deprecation 警告。  
- `ServerArgs` 新增 `enable_prefill_delayer`、`prefill_delayer_max_delay_passes`、`prefill_delayer_token_usage_low_watermark` 三个 CLI 参数，并在 `__post_init__` 中实现对旧环境变量的向后兼容。  
- 调度器、度量收集器及测试代码均改为使用 `server_args` 而非直接读取环境变量。  

**🎯 影响范围**  
- 核心调度模块 `scheduler.py`、度量模块 `collector.py`、启动参数解析 `server_args.py`。  
- 迁移相关的测试 `test_prefill_delayer.py`。  
- 依赖环境变量 `SGLANG_*` 的外部脚本或 CI 仍可工作（通过兼容层），但推荐切换到新 CLI。  

**💡 关注建议**  
1. **文档同步**：请在用户手册和示例脚本中补充 `--enable-prefill-delayer`、`--prefill-delayer-max-delay-passes`、`--prefill-delayer-token-usage-low-watermark` 的说明及默认值。  
2. **参数校验**：当前 `prefill_delayer_max_delay_passes` 直接用于直方图 bucket 中，建议在 `ServerArgs.__post_init__` 加入正整数校验，以防传入 0/负数导致 histogram 初始化异常。  
3. **兼容性测试**：保留 env‑to‑cli 的转换逻辑后，需确保在同一进程内先后设置 env 与 CLI 时，优先级保持一致（目前 CLI 会覆盖 env）。建议在 CI 中加入混合使用的场景验证。  
4. **性能回归**：Prefill Delayer 的开启会影响调度行为，建议在关键模型（如 Llama‑2‑7B）上跑一次基准，验证延迟和吞吐的变化是否在预期范围内。  

总体而言，此次改动提升了配置的可观察性与一致性，风险主要集中在参数合法性和文档同步上，建议完成上述检查后即可合并。

---

### Migrate VLM tests and remove unit-test-backend-1-gpu job (#16679)
**SHA**: `ef35d8f` | 🔗 [查看提交](https://github.com/sgl-project/sglang/commit/ef35d8fe4e161770b2b91df12d82581c923a2290)

**🎯 变更类型**：重构 / CI 流程优化  
**⚡ 重要程度**：🟡 中  
**📋 变更摘要**：将 VLM（视觉语言模型）相关测试迁移到统一的 CI 注册方式，删除 `unit-test-backend-1-gpu` Job 并相应更新依赖图，简化 `run_suite.py` 中的测试用例列表。  

**🎯 影响范围**  
- **CI 工作流**：`.github/workflows/pr-test.yml` 大幅度删减 `unit-test-backend-1-gpu` 以及相关 `needs` 链，防止不必要的 GPU 资源占用。  
- **测试注册**：新增 `register_cuda_ci`、`register_cpu_ci` 调用，VLM 测试现在通过 `ci_register` 动态加入对应 suite。  
- **测试套件定义**：`test/srt/run_suite.py` 删除了 `per-commit-1-gpu` 中的 VLM 测试条目，防止重复执行。  

**💡 关注建议**  
1. **CI 稳定性**：确认所有受影响的 downstream jobs（如 `unit-test-backend-4-gpu`、`unit-test-deepep-8-gpu` 等）在新依赖图下仍能获取到必需的构建产物，避免因 `needs` 删除导致隐藏的失败。  
2. **文档同步**：更新项目的 CI 说明文档或 README，说明已不再使用 `unit-test-backend-1-gpu`，并指明如何在本地或其他 workflow 中手动运行 VLM 测试。  
3. **回归验证**：在合并前运行完整的 PR‑test（包括 schedule）确保 VLM 相关测试仍被触发，尤其是 `stage-b-test-small-1-gpu`、`stage-b-test-large-1-gpu` 等新入口。  
4. **代码可维护性**：`ci_register` 的参数（`est_time`、`suite`）建议加上类型注解或注释，以防未来添加新 suite 时出现拼写错误。  

总体来看，此次改动统一了测试注册方式，减少了冗余 GPU Job，提升 CI 效率；只要验证依赖关系和文档同步即可安全合入。

---

### [model-gateway] Restore response streaming by optimizing WASM middleware buffering (#16804)
**SHA**: `bd1afeb` | 🔗 [查看提交](https://github.com/sgl-project/sglang/commit/bd1afeb568ed109a8d4dee0a239c3bc0ab5f5f2f)

**🎯 变更类型**：功能增强 / 性能优化  
**⚡ 重要程度**：🟡 中  

**📋 变更摘要**  
1. 在 `sgl-model-gateway` 中新增基准测试 `wasm_middleware_latency.rs`，用于测量 WASM 中间件在流式响应场景下的首帧延迟。  
2. 对 `middleware.rs` 中的 `wasm_middleware` 进行重构：  
   - 当没有 `OnRequest` 模块时直接跳过请求体读取和重构，避免不必要的拷贝。  
   - 将请求体读取、模块循环、请求重建的逻辑封装在条件分支里，保持原有功能不变。  
   - 为 `OnResponse` 阶段加入空模块快速返回的 guard，提升空路径的执行效率。  
3. 在 `Cargo.toml` 增加基准测试目标 `wasm_middleware_latency`。  

**🎯 影响范围**  
- `sgl-model-gateway/src/middleware.rs`（请求/响应处理路径）  
- `sgl-model-gateway/benches/wasm_middleware_latency.rs`（新增基准）  
- `sgl-model-gateway/Cargo.toml`（基准入口）  

**💡 关注建议**  
1. **功能保持**：重构后仍然需要确保 `OnRequest/OnResponse` 模块的 `Modify/Reject` 行为与之前完全一致，建议在 CI 中加入回归测试，比较修改前后的响应体和状态码。  
2. **流式性能**：基准仅测量首帧延迟，若业务对整体流式吞吐有要求，应再补充 “全链路延迟 / 峰值吞吐” 的基准，以防止隐藏的缓冲或内存泄漏。  
3. **错误路径**：`axum::body::to_bytes` 在读取大体请求/响应时仍会一次性缓冲，若 `max_body_size` 设得过小会返回错误并重新发起空请求。确认该行为在生产环境不会导致意外的 400/500 响应。  
4. **并发安全**：`wasm_middleware` 现在在无模块时直接调用 `next.run(request)`；若后续 `next` 期望某些 Header 被预先设置（例如跨域），请检查调用链中没有隐藏依赖。  
5. **基准代码**：基准使用 `Runtime::new()` 每次创建，会占用额外线程资源。若频繁运行基准，可改为共享 `tokio::runtime::Handle`，避免不必要的启动开销。  

总体而言，此次改动通过提前返回和条件分支，显著削减了在无 WASM 插件场景下的复制与缓冲成本，并提供了可量化的基准数据。上线前请确保回归测试覆盖所有中间件动作，并在真实流式负载下验证首帧延迟的提升。

---

### Fix GLM-4.7 MoE Detector complex JSON Schema type parsing (#15753)
**SHA**: `8ef5b90` | 🔗 [查看提交](https://github.com/sgl-project/sglang/commit/8ef5b9052825c2624e3ac91852b16998f6f6ee3c)

**核心变更**  
1. **新增 `infer_type_from_json_schema`**：在 `function_call/utils.py` 中实现对 JSON Schema 的递归解析，支持 `type`、`type` 数组、`anyOf/oneOf`、`enum`、`allOf`、`properties`、`items` 等复杂结构并返回统一的基础类型。  
2. **检测器升级**：`glm4_moe_detector.py` 与 `glm47_moe_detector.py` 改为调用该函数获取参数类型，扩展返回集合至 `array、boolean`。  
3. **值类型自动检测增强**：在 `_get_value_type` 中先尝试 `json.loads`，在失败后再使用字符首位判断，默认回落为 `string`。  
4. **测试扩充**：`test_glm47_moe_detector.py` 中加入大量围绕复杂 JSON Schema 的单元测试，覆盖 `anyOf/oneOf/enum/allOf/type‑array` 等情形以及流式解析路径。

**影响范围**  
- **函数调用解析模块**（`glm*_moe_detector`）以及依赖 `get_argument_type` 的所有入口。  
- **工具链**：新增 `utils.infer_type_from_json_schema` 可能被其它模块直接复用。  
- **测试套件**：新增约 600 行测试，运行时间将显著增长。

**关注建议**  
- **兼容性**：确保旧版工具（仅提供 `type` 字段）仍能返回期望的 `'string'/'number'/'object'`，并避免因 `enum`、`anyOf` 等返回 `None` 导致后续调用错误。  
- **性能**：在流式解析高频路径加入 `json.loads` 解析，建议在非必需情况下使用轻量的字符判断，或在检测器初始化时缓存 schema 解析结果。  
- **错误处理**：`infer_type_from_json_schema` 对异常结构直接返回 `None`，调用方需做好空值容错，以免产生 `AttributeError`。  
- **测试维护**：新增的长测试文件对 CI 资源要求较高，建议将部分大体量检查拆分为参数化子测试，或使用 `@unittest.skipIf` 控制仅在特定环境运行。  
- **文档更新**：在 README/函数调用说明中标明已支持的复杂 JSON Schema 特性，提醒用户在自定义工具时尽量使用标准字段以获得正确类型推断。

---

#### 🟢 低重要度变更 (15)

### Fix log_decode_stats_every_iteration when having TP in attention (#16871)
**SHA**: `a0899bd` | 🔗 [查看提交](https://github.com/sgl-project/sglang/commit/a0899bdbd8e1b05b839fa2765779d7518f08d462)

**🎯 变更类型**：代码重构  
**⚡ 重要程度**：🟢低  
**📋 摘要**：在 `log_decode_stats_every_iteration` 添加 `enable_metrics` 判断，并在 `process_batch_result_decode` 中重新组织日志记录条件，修复注意力 TP 场景下的统计异常。

---

### Piecewise Cuda Graph Memory Usage (#15927)
**SHA**: `145bd54` | 🔗 [查看提交](https://github.com/sgl-project/sglang/commit/145bd54f1b941aef4d383faf225a17ee4766c6fd)

**🎯 变更类型**：代码重构 / 配置调整  
**⚡ 重要程度**：🟢 低  

**📋 摘要**：  
- 移除旧的 CUDA Graph 跳过逻辑，加入对 PCG 捕获流的更明确断言。  
- 在服务器参数中新增对 piecewise CUDA Graph 的默认令牌上限处理，针对 MLA 后端设为 2048，避免性能回退。  
- 调整 piecewise CUDA Graph 的 token 列表及内存预留计算方式。  
- 改进 CLI 参数类型，使用 `int nargs+` 替代 JSON 列表。  

---

### [IDLE FORWARD][Indexer] Fix forward_idle bs mismatch issue in DeepseekV3.2's NSAIndexer (#15227)
**SHA**: `2d088b8` | 🔗 [查看提交](https://github.com/sgl-project/sglang/commit/2d088b85d936cbb4375ae032589f0615adcfca60)

**🎯 变更类型**：其他  
**⚡ 重要程度**：🟢低  
**📋 摘要**：在 `forward_idle` 中为 DP Attention 的 IDLE 批重新初始化注意力元数据，防止 batch_size 不匹配导致 NSAIndexer 错误。

---

### Update Cutedsl version and pin cuda-python version (#16838)
**SHA**: `9fd2358` | 🔗 [查看提交](https://github.com/sgl-project/sglang/commit/9fd2358cc2fcd500319daf9f27d7bf57c41ad470)

**变更类型**：代码重构  
**重要程度**：🟢低  
**摘要**：在 Dockerfile 中将 `nvidia-cutlass-dsl` 版本从 4.3.0/4.3.1 更新为 4.3.1，并在 CUDA 13 环境下改为固定安装 `cuda-python==13.1.1`；在 `pyproject.toml` 中将 `cuda-python` 锁定为 12.9，并将 `nvidia-cutlass-dsl` 升级到 4.3.1。整体为依赖版本同步与 pin。

---

### Enhance test for dp-attention + constrained decoding. (#16849)
**SHA**: `3c35873` | 🔗 [查看提交](https://github.com/sgl-project/sglang/commit/3c358736d13440444a6e60f73f3a71245bfda341)

**🎯 变更类型**：测试修改  
**⚡ 重要程度**：🟢低  
**📋 摘要**：在 `test_dp_attention.py` 中为多个测试类加入 JSON、EBNF、Regex 约束的混入类，以增强分布式注意力和受限解码的测试覆盖。代码行数略增，功能仅涉及测试层面。

---

### Attention backend selection bug fix for hicache (#16779)
**SHA**: `675acec` | 🔗 [查看提交](https://github.com/sgl-project/sglang/commit/675acecec63f439d515881707e04ba8faeccbbcd)

**🎯 变更类型**：代码重构  
**⚡ 重要程度**：🟢低  
**📋 摘要**：调整 `ServerArgs.__post_init__` 中 Hicache 处理顺序，简化并修正 `_handle_hicache` 逻辑，确保在 `page_first_direct` 布局下使用合适的 I/O 后端，避免 Mooncake 存储后端不支持的 `layer_first` 布局导致的错误。

---

### [CI] Remove duplicate code in test_mamba_ut (#16854)
**SHA**: `ad20127` | 🔗 [查看提交](https://github.com/sgl-project/sglang/commit/ad20127359c996f8e648cd9d6c8c66688ae232ae)

**🎯 变更类型**：代码重构  
**⚡ 重要程度**：🟢低  
**📋 摘要**：在 `test_mamba_unittest.py` 的 `setUpClass` 中删除了原先用于设置全局服务器参数的重复代码，改为直接 `pass`，简化测试初始化，且仅删除了四行冗余代码。

---

### [Docker] Add nightly dev docker for Cuda 13 (#16862)
**SHA**: `7f393d9` | 🔗 [查看提交](https://github.com/sgl-project/sglang/commit/7f393d9512dc3834d77b06065c6160769eb527c0)

**🎯 变更类型**：配置调整  
**⚡ 重要程度**：🟢低  
**📋 摘要**：为 CUDA 13 开发 Docker 镜像新增每日定时构建（cron），并统一标签为 `dev-x86-cu13` / `dev-arm64-cu13`，去除日期后缀。

---

### [Doc]Update note for Cuda 13 container usage (#16805)
**SHA**: `94fc26a` | 🔗 [查看提交](https://github.com/sgl-project/sglang/commit/94fc26aad8bdbc9eb73c68ab883a1a36a195c7a6)

**🎯 变更类型**：文档更新  
**⚡ 重要程度**：🟢低  
**📋 摘要**：在安装文档中新增一行，说明在 CUDA 13 环境下运行 sglang 时应使用 `lmsysorg/sglang:latest-cu130-runtime` Docker 镜像。

---

### [Rework] Add SwapAB Optimization for triton fused_moe_kernel on SM90. (#16723)
**SHA**: `67b61a4` | 🔗 [查看提交](https://github.com/sgl-project/sglang/commit/67b61a4e8d0dba9c8c1d52a42769f658ad20bc0b)

**🎯 变更类型**：代码重构  
**⚡ 重要程度**：🟢低  
**📋 摘要**：在 `fused_moe_triton_kernels.py` 中引入 `swap_ab` 逻辑并新增 `should_enable_swap_ab` 判定函数，实现 SM90（H20）GPU 上的 SwapAB 优化，仅在 FP8‑W8A8 模式且块尺寸满足条件时启用。

---

### [llama] Allow passing tp_rank and tp_size into llama mlp (#16837)
**SHA**: `e91a717` | 🔗 [查看提交](https://github.com/sgl-project/sglang/commit/e91a7176324e3a44fde9276db0af17c93997119b)

**🎯 变更类型**：代码重构  
**⚡ 重要程度**：🟢低  
**📋 摘要**：在 `llama.py` 中的 `LlamaMLP` 构造函数新增 `tp_rank`、`tp_size` 参数，并将其传递给 `MergedColumnParallelLinear` 与 `RowParallelLinear`，以支持模型并行的显式配置。

---

### [Fix CI] Fix test_mamba_unittest.py (#16810)
**SHA**: `08636f7` | 🔗 [查看提交](https://github.com/sgl-project/sglang/commit/08636f72b5d9742673cf19b2dfea4880ee9581c7)

**🎯 变更类型**：测试修改  
**⚡ 重要程度**：🟢 低  
**📋 摘要**：在 `test_mamba_unittest.py` 的 `setUpClass` 中添加全局服务器参数配置（模型路径、关闭 DP 注意力、分页大小），以确保单元测试在调度器环境下正确运行。

---

### [AMD CI] Temporarily disable docker caching. (#16783)
**SHA**: `a6c29d4` | 🔗 [查看提交](https://github.com/sgl-project/sglang/commit/a6c29d4cbd4a42389f02328d655402162c38543a)

**🎯 变更类型**：配置调整  
**⚡ 重要程度**：🟢低  
**📋 摘要**：在 `release-docker-amd-nightly.yml` 中将缓存 job 的 `if` 条件改为 `false`，临时停用 Docker 缓存种子，以待高性能存储就绪。

---

### Reduce some small cpu overhead in stream fetch (#16587)
**SHA**: `84ab32a` | 🔗 [查看提交](https://github.com/sgl-project/sglang/commit/84ab32a2a0823a7f75c439f36b96e3505ec03d08)

**🎯 变更类型**：代码重构  
**⚡ 重要程度**：🟢低  
**📋 摘要**：在 `utils.py` 中将 `torch.cuda.current_stream()` 替换为更轻量的 `get_current_device_stream_fast()`，用于在捕获模式下获取当前 CUDA 流，从而降低少量 CPU 开销。

---

### [ci hot fix] fix global server args init for mamba ut (#16821)
**SHA**: `7066711` | 🔗 [查看提交](https://github.com/sgl-project/sglang/commit/7066711529dabe791095d604e3e7833be20f3736)

**🎯 变更类型**：测试修改  
**⚡ 重要程度**：🟢低  
**📋 摘要**：在 `test_mamba_unittest.py` 中引入 `ServerArgs` 与 `set_global_server_args_for_scheduler`，为 Mamba 单元测试在调度器初始化时提供全局服务器参数。

---

