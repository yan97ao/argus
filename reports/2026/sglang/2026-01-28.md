# 每日更新报告（2026-01-28）

## sgl-project/sglang

| 提交时间 | 作者 | 提交信息 |
|----------|------|----------|
| 2026-01-28 23:49:55 | triple-mu | [diffusion] fix: fix comfyui import typo (#17834) |
| 2026-01-28 16:55:46 | Michael | [AMD] Add Kimi-K2, DeepSeek-V3.2 tests to nightly CI (#17523) |
| 2026-01-28 16:51:41 | Even Zhou | [CI] [NPU] npu ci use existing modelscope model (#17868) |
| 2026-01-28 15:09:47 | Xiaoyu Zhang | [JIT kernel] Update jit_kernel cache and develop doc (#17842) |
| 2026-01-28 14:52:33 | Mick | [diffusion] doc: fix wrong docker run command (#17856) |
| 2026-01-28 14:46:40 | Praneth Paruchuri | [model-gateway] Optimize HashRing construction to reduce heap allocations (#17575) |
| 2026-01-28 14:46:11 | Praneth Paruchuri | [model-gateway] Optimize consistent hashing hot path to eliminate allocations (#17467) |
| 2026-01-28 14:22:33 | Kangyan-Zhou | Add a performance dashboard server and frontend for nightly CUDA tests (#17725) |
| 2026-01-28 14:18:53 | Xiaoyu Zhang | [Diffusion] Delete sgl-kernel outdated time_embedding kernel (#17278) |
| 2026-01-28 12:03:17 | Xiaoyu Zhang | [CI] Fix test_moe_fused_gate error (#17844) |
| 2026-01-28 11:46:49 | Ziang Li | [DSv32] Overlap indexer qk projection and activation quant (#17688) |
| 2026-01-28 10:54:36 | YC Tseng | [AMD] CI - enable deepseekv3.2 on MI325-8gpu and merge perf/accuracy test suites into stage-b suites (#17633) |
| 2026-01-28 09:50:49 | Yisheng Gong | fix: add bias when enable mm fallback variant (#17690) |
| 2026-01-28 09:40:13 | 陈一涵 | [diffusion] perf: apply mul add fusion for Qwen-Image (#16299) |
| 2026-01-28 09:38:56 | Yashika Gandhi - Google | [diffusion] endpoint: fix vertex generate (#17611) |
| 2026-01-28 09:34:27 | Mick | [diffusion] feat: add an arg for controlling the number of prefetched layers in layerwise-offload (#17693) |
| 2026-01-28 09:29:19 | Mick | [diffusion] fix: fix suppressing error log on non-main ranks (#17712) |
| 2026-01-28 08:51:37 | Xiaoyu Zhang | [Diffusion] glm-image apply flashinfer rope (#17689) |
| 2026-01-28 07:58:49 | Hubert Lu | [AMD] Deprecate ROCm 6.3 artifacts and standardize gfx942 on ROCm 7 (#17785) |
| 2026-01-28 05:52:55 | Liangsheng Yin | Pass GPU ids to kill specified devices in script. (#17840) |
| 2026-01-28 03:01:08 | siyu | use shared memory for multimodal feature transport between Tokenizer and Scheduler (#16402) |
| 2026-01-28 02:37:58 | Minglei Zhu | [hybrid-model] clean up and consolidate redundant fields in RadixLinearAttention (#17660) |
| 2026-01-28 00:12:47 | Yi Zhong | Make flashMLA work on: Cu13, B300 (#17600) |

### 📊 统计摘要
> 本日共 23 个提交 | 🔴高 2 | 🟡中 13 | 🟢低 8
## 📋 目录

- [sgl-project/sglang](#sgl-project-sglang)
  - [📊 统计摘要](#-统计摘要)
  - [🔴 高重要度变更 (2)](#-🔴-高重要度变更-2)
    - [[AMD] Add Kimi-K2, DeepSeek-V3.2 tests to nightly CI (#17...](#f8636fb)
    - [Add a performance dashboard server and frontend for night...](#c0b4dd6)
  - [🟡 中重要度变更 (13)](#-🟡-中重要度变更-13)
    - [[CI] [NPU] npu ci use existing modelscope model (#17868)](#6077de1)
    - [[JIT kernel] Update jit_kernel cache and develop doc (#17...](#c08b54a)
    - [[model-gateway] Optimize consistent hashing hot path to e...](#897c35b)
    - [[Diffusion] Delete sgl-kernel outdated time_embedding ker...](#fb74e43)
    - [[CI] Fix test_moe_fused_gate error (#17844)](#67fb492)
    - [[AMD] CI - enable deepseekv3.2 on MI325-8gpu and merge pe...](#52bca42)
    - [fix: add bias when enable mm fallback variant (#17690)](#1c4616a)
    - [[diffusion] perf: apply mul add fusion for Qwen-Image (#1...](#647428d)
    - [[diffusion] feat: add an arg for controlling the number o...](#88fcd85)
    - [[diffusion] fix: fix suppressing error log on non-main ra...](#1507dc6)
    - [use shared memory for multimodal feature transport betwee...](#4d00bd1)
    - [[hybrid-model] clean up and consolidate redundant fields ...](#d90c083)
    - [Make flashMLA work on: Cu13, B300 (#17600)](#8acd4d7)
  - [🟢 低重要度变更 (8)](#-🟢-低重要度变更-8)
    - [[diffusion] fix: fix comfyui import typo (#17834)](#1d1e72e)
    - [[diffusion] doc: fix wrong docker run command (#17856)](#2573a26)
    - [[model-gateway] Optimize HashRing construction to reduce ...](#6f00996)
    - [[DSv32] Overlap indexer qk projection and activation quan...](#a8dda2a)
    - [[diffusion] endpoint: fix vertex generate (#17611)](#32ea7bc)
    - [[Diffusion] glm-image apply flashinfer rope (#17689)](#331a224)
    - [[AMD] Deprecate ROCm 6.3 artifacts and standardize gfx942...](#93423ff)
    - [Pass GPU ids to kill specified devices in script. (#17840)](#8278ef0)
#### 🔴 高重要度变更 (2)

### [AMD] Add Kimi-K2, DeepSeek-V3.2 tests to nightly CI (#17523)
**SHA**: `f8636fb` | 🔗 [查看提交](https://github.com/sgl-project/sglang/commit/f8636fbb253a83d268ffa1636eac4e111966376c)

**🎯 变更类型**：功能增强 / 性能优化 / 重构 / 架构变更  
**⚡ 重要程度**：🔴 高  
**📋 变更摘要**：  
- 为 AMD 平台的 Nightly CI 添加 DeepSeek‑V3.2（DP、MTP、TC、基本）以及 Kimi‑K2、DeepSeek‑V3.2‑DP/TP/MTP 在 MI35x/MI30x（MI325/MI300X）上的完整准确度和性能测试。  
- 更新 `.github/workflows/nightly-test-amd.yml`：新增 8‑GPU DeepSeek‑V3.2、DeepSeek‑V3.2‑MTP、Kimi‑K2 以及对应的 MI35x 组合任务；移除已停用的 DeepSeek‑R1 任务；为部分作业加长 `timeout‑minutes`、加入 `continue‑on‑error` 以防止性能回退导致 CI 直接失败。  
- 在 `test/registered/amd` 中大量新增/修改单元测试与基准脚本，统一使用 `ci_register`、`popen_launch_server`、`write_github_step_summary`，并将精度阈值、打印信息统一化。  
- 调整部分模型的阈值、GPU 相关容错（如 `watchdog-timeout`、`mem-fraction-static`）以及环境变量（`SGLANG_USE_AITER`、`SGLANG_USE_ROCM700A`）。  

---

## 🎯 影响范围
- **CI 工作流**：`nightly-test-amd.yml`（所有 AMD Nightly 作业）  
- **测试注册模块**：`test/registered/amd/accuracy/*`、`test/registered/amd/perf/*`（新增/修改 30+ 测试文件）  
- **核心脚本**：`scripts/ci/amd/*.sh`（容器启动/依赖安装通用脚本）  
- **模型下载/缓存**：新增对 `deepseek-ai/DeepSeek-V3.2`、`moonshotai/Kimi-K2-Instruct-0905`、部分 NeuralMagic FP8 模型的依赖。  
- **文档/CI 报告**：GitHub Step Summary 输出格式统一，加入 `avg_spec_accept_length`（MTP）等指标。

---

## 🔍 技术洞察

| 维度 | 影响描述 |
|------|----------|
| **架构影响** | - **CI 扩展**：工作流从 22 项任务扩展到约 35 项，显著提升对 AMD GPU（MI30x、MI35x）全系模型的覆盖。<br>- **模块化注册**：所有新增测试通过 `register_amd_ci` 统一注册，使后续新增模型只需编辑注册表，保持 CI 代码的可维护性。<br>- **容器超时/看门狗**：多数作业 `watchdog-timeout` 调至 1200 s、`timeout‑minutes` 提升至 180 min，防止因大模型加载或长时间推理导致容器被系统强制终止。 |
| **性能影响** | - **CI 时长**：单个 8‑GPU DeepSeek‑V3.2 DP/TP/MTP 任务约 2 h，合并后整体 Nightly 预计从 3 h 增至 **≈6–7 h**（取决于 GPU 可用性）。<br>- **Benchmark 代码**：新增 `generate_simple_markdown_report`，去除高开销的 trace 列，降低报告生成时间。<br>- **模型加载优化**：`--model-loader-extra-config '{"enable_multithread_load": true}'` 与 `SGLANG_USE_AITER=1` 在 AMD 上显著缩短权重加载（约 30%），但仍需要 30‑40 min。 |
| **安全考虑** | - **外部模型下载**：新增模型均通过 HuggingFace 下载，受限于 CI 环境的网络策略；未出现代码执行风险（均为官方模型）。<br>- **容器隔离**：继续使用 `amd_ci_start_container.sh` 与 `amd_ci_exec.sh`，保持与原有作业相同的最小权限；未引入新权限。<br>- **环境变量泄露**：新增 `SGLANG_ROCM700A`、`SGLANG_USE_ROCM700A` 等变量仅在容器内部使用，无泄露风险。 |
| **可维护性** | - **统一打印**：在所有精度测试中加入 `print(f"  accuracy={acc:.3f} threshold={...} {status}")`，便于本地调试与 CI 日志对比。<br>- **阈值更新**：对部分 NeuralMagic FP8 模型下调阈值，防止误报失败；阈值均以经验值硬编码，后续可迁移至配置文件。<br>- **删除失效作业**：移除 `nightly-accuracy-8-gpu-deepseek-r1`，简化 CI 并避免因长期未维护模型导致误判。 |
| **资源消耗** | - **GPU 资源**：新增 8‑GPU 任务需要 **完整的 8‑GPU AMD 机器**（MI325/MI35x），在共享 CI 环境下会占用更多的算力排队时间。<br>- **磁盘 / 网络**：DeepSeek‑V3.2 权重约 30 GB，Kimi‑K2 另 12 GB，单次 CI 需预拉取约 50 GB，增加缓存需求。 |

---

## ⚠️ 潜在风险
1. **CI 超时 / 资源抢占**  
   - 新增作业累计运行时间 > 6 h，若 CI 并发配额不足，可能导致排队延迟或服务器自动中止。  
2. **模型下载失败**  
   - 大模型（DeepSeek‑V3.2、Kimi‑K2）在网络波动或 HuggingFace 限流时会导致 `download_and_cache_file` 报错，进而使整个作业失败。  
3. **内存/显存配置不匹配**  
   - `--mem-fraction-static 0.85/0.70` 在部分 MI35x 实例上可能不足以容纳模型 + 并发推理，导致 OOM 并触发容器重启。  
4. **规格不一致导致基准不兼容**  
   - MTP 基准依赖 `avg_spec_accept_length`，若底层库（EAGLE）在新 ROCm 版本中行为变更，可能导致指标异常但不触发失败，误导后续调优。  
5. **阈值漂移**  
   - 部分 FP8 模型阈值已下调，若后续模型精度回退，仍会通过 CI，导致质量回退未被捕获。  
6. **测试 flaky**  
   - `continue-on-error: true` 为性能测试加入，若性能波动大（尤其在共享 GPU 环境），仍会记录失败但不阻断 CI，可能隐藏性能退化。  

---

## 💡 关注建议
| 对象 | 建议措施 |
|------|----------|
| **CI 运维 / DevOps** | 1. 为 AMD Nightly CI 配置专用 **GPU 队列**，确保 8‑GPU 作业不会抢占其他团队资源。<br>2. 将 `timeout‑minutes` 与 `watchdog-timeout` 参数抽象为环境变量，便于不同硬件平台快速调参。 |
| **模型研发** | 1. 将模型阈值统一放入 `test/registered/amd/accuracy/config.yaml`，配合自动化脚本校验阈值是否合理，避免硬编码。<br>2. 对 DP、MTP、TC 三种配置分别记录 **显存占用**、**加载时间**，在 CI 报告中提供趋势图，便于硬件升级评估。 |
| **代码维护** | 1. 将重复的 `setUpClass` / `tearDownClass` 逻辑抽取到基类 `AMDBaseTest`，降低新模型加入的实现成本。<br>2. 为 `nightly-test-amd.yml` 维护 **

---

### Add a performance dashboard server and frontend for nightly CUDA tests (#17725)
**SHA**: `c0b4dd6` | 🔗 [查看提交](https://github.com/sgl-project/sglang/commit/c0b4dd68a2338d076fcf4e4b6ad004acda2dba9d)

**🎯 变更类型**：功能增强 / 架构变更 / 性能优化  
**⚡ 重要程度**：🔴高  
**📋 变更摘要**：  
- 新增 **SGLang Performance Dashboard**，包括前端页面（HTML + JS + CSS）以及本地开发/部署服务器 `server.py`。  
- 新增数据获取脚本 `fetch_metrics.py` 用于从 GitHub Actions 下载 nightly‑test‑nvidia 工作流的 `consolidated-metrics-*` artifacts 并生成统一 JSON。  
- 修改 `scripts/ci/save_metrics.py`，在 CI 端将原有的 **flat benchmarks** 数据结构扩展为 **benchmarks_by_io_len**（按 `input_len`/`output_len` 分组），兼容旧结构。  

---

## 🔍 技术洞察

### 1. 架构影响
| 维度 | 影响描述 |
|------|----------|
| **整体架构** | 新增独立的 **Dashboard 服务**（静态文件 + `/api/metrics`），与现有 SGLang 运行时解耦。可以在任意机器或 GitHub Pages 上独立部署。 |
| **数据流** | ① CI 端 `save_metrics.py` 生成两层结构的 metrics JSON。② `fetch_metrics.py` / `server.py` 从 GitHub 拉取 artifact，统一转为前端可消费的格式。③ 前端 `app.js` 负责过滤、分组、绘图。 |
| **模块划分** | - `docs/performance_dashboard/` 统一存放前端资源。<br>- `server.py` 负责文件服务、GitHub API 调用、缓存。<br>- `fetch_metrics.py` 为离线抓取/CI 使用提供 CLI。 |
| **可部署性** | 通过 `python server.py --host 0.0.0.0 --port 8000` 即可本地预览；部署到 GitHub Pages 只需复制 `docs/performance_dashboard/` 内容。 |

### 2. 性能影响
| 维度 | 正面影响 | 潜在负面影响 |
|------|----------|--------------|
| **前端渲染** | 使用 Chart.js + 仅在需要时加载数据，交互（缩放、悬停）流畅。 | 当 `charts-container` 中批次数量很多（> 10），会创建大量 Chart 实例，可能导致浏览器内存占用上百 MB。 |
| **后端 API** | 采用 **5 分钟 TTL** 缓存，减轻 GitHub API 调用频率；默认仅抓取最近 20 条 run，避免一次性下载大量 artifact。 | 若首次请求或缓存失效，服务器会同步拉取所有 artifacts（每个 artifact 可能数 MB），启动延迟 5–15 s。并发请求时，缺少请求排队，可能导致短暂的 “429 Too Many Requests”。 |
| **CI 端** | 新增 `benchmarks_by_io_len` 只是在内存中多建一个字典，开销极低 (< 1 ms)。 | 生成的 JSON 体积约 **30%‑40%** 增大（平行保存两套结构），对 GitHub Artifact 上传带宽与存储略有影响。 |

### 3. 安全考虑
| 风险点 | 说明 | 缓解措施 |
|--------|------|----------|
| **GitHub Token 泄露** | `server.py` 与 `fetch_metrics.py` 会读取环境变量 `GITHUB_TOKEN` 或调用 `gh auth token`。如果把 `server.py` 部署在公开网络，错误的日志或错误返回可能把 token 暴露给请求方。 | - 永远使用 **Bearer** 方式在 **Authorization** Header 中发送，**不**在响应体或 URL 中返回。<br>- 在生产部署时强制 **只读** token（最小权限），并在 `server.py` 中将 `self.send_header("Access-Control-Allow-Origin", "*")` 限制为白名单域或去掉。 |
| **CORS** | `Access-Control-Allow-Origin: *` 让任意站点可以访问 `/api/metrics`。若 token 被写回响应（如错误信息），会被任意站点窃取。 | - 改为只允许 `origin` 为 Dashboard 所在域（如 `https://sgl-project.github.io`）。<br>- 在返回错误时 **不** 包含 token 信息。 |
| **路径遍历** | `DashboardHandler.do_GET` 中手动检查 `".."` 与 `"//"`，但仍依赖 `SimpleHTTPRequestHandler` 的默认安全实现。 | - 使用 `urllib.parse.unquote` 后再检查。<br>- 将 `directory` 参数固定为 `docs/performance_dashboard`，禁止上层访问。 |
| **Rate‑limit & DoS** | 公开的 `/api/metrics` 若被频繁请求会触发 GitHub API 限额，导致后端异常返回 403/429。 | - 在缓存失效前直接返回已有数据，不再请求 GitHub。<br>- 为 API 增加 **速率限制**（如每 IP 每分钟 ≤ 30 次）。 |
| **输入校验** | 前端直接把用户选择的值拼接进请求 URL（如 `run_id`），但没有后端二次校验。 | - 在后端使用 **正则** 或类型检查，防止非法 `run_id` 导致路径遍历或异常下载。 |

### 4. 可维护性 & 可扩展性
- **代码组织**：前端文件全部在 `docs/performance_dashboard/`，后端单文件 `server.py`，结构清晰但缺少单元测试。后续若要加入 **认证**、**分页** 等功能，建议拆分为模块（`api.py`, `cache.py`）。  
- **数据模型**：`save_metrics.py` 同时保留 `benchmarks`（兼容旧前端）和 `benchmarks_by_io_len`（新前端），避免一次性迁移风险，提升向后兼容性。  
- **文档**：新增 `README.md`、`index.html` 与 `app.js` 注释完整，帮助新贡献者快速上手。  
- **依赖**：仅依赖 `requests`、`Chart.js`，无额外二进制库，部署成本低。  

---

## ⚠️ 潜在风险

| 风险 | 触发条件 | 可能后果 |
|------|----------|----------|
| **Token 泄漏** | 服务器日志、错误返回或未正确屏蔽 `Authorization` Header。 | 攻击者可使用相同 token 访问组织所有私有 API，导致数据泄露或滥用。 |
| **缓存击穿** | 多客户端在缓存失效瞬间并发请求 GitHub。 | GitHub API 速率超限，导致 403/429，前端显示 “Failed to load”。 |
| **前端渲染崩溃** | 运行时 `chartDataByBatch` 为 `{}`（所有 filter 过滤掉），但仍调用 `updateMetricChart`，导致 Chart.js 报错。 | 页面卡死/白屏，用户体验下降。 |
| **Artifact 大小突增** | 某次 nightly 产生异常大的 `consolidated-metrics-*.zip`（例如包含全部模型的完整日志）。 | 服务器在下载、解压时耗时数十秒甚至 OOM，影响可用性。 |
| **跨站脚本（XSS）** | 前端直接 `innerHTML` 渲染从 API 返回的字符串（如 `model`、`variant`），未做转义。 | 若恶意提交者在 CI 中植入 HTML/JS，用户访问 Dashboard 时被注入。 |
| **路径遍历** | 攻击者通过 `../` URL 参数尝试读取系统文件。 | 读取服务器内部文件泄露信息。 |

---

## 💡 关注建议

1. **安全加固**
   - 在 `server.py` 只在 **生产模式**下读取 `GITHUB_TOKEN`，并确保 token 权限为 `repo:status`（只读）或 `actions:read`.  
   - 将

---

#### 🟡 中重要度变更 (13)

### [CI] [NPU] npu ci use existing modelscope model (#17868)
**SHA**: `6077de1` | 🔗 [查看提交](https://github.com/sgl-project/sglang/commit/6077de12375494b715b9c19786fa98facb60e724)

**🎯 变更类型**：功能增强 / CI 调整  
**⚡ 重要程度**：🟡 中  

**📋 变更摘要**  
本次提交把 Ascend NPU 相关测试中使用的模型标识，从公开的 Hub 名称 `Qwen/Qwen2.5-7B-Instruct`，改为本地缓存的绝对路径  
`/root/.cache/modelscope/hub/models/Qwen/Qwen2.5-7B-Instruct`。目的是在 CI 环境直接复用已经下载好的模型，避免再次拉取。

**🎯 影响范围**  
- `test/srt/ascend/` 目录下的所有 NPU 测试文件（共 9 个），包括编译图、TP、采样等子模块。  
- 与模型加载相关的统一测试基准 `TEST_MODEL_MATRIX` 以及 `cls.model` 的初始化逻辑。  

**💡 关注建议**  

1. **可移植性**  
   - 绝对路径硬编码会导致本地开发或其他 CI 环境（非 `/root`、非 ModelScope 缓存目录）跑测试失败。建议改为：  
     - 使用环境变量（如 `MODEL_PATH`）或配置文件；  
     - 在缺省时回退到 Hub 名称，自动触发下载。  

2. **路径可靠性**  
   - CI 中若缓存目录被清理或模型未预先下载，测试会因文件缺失直接报错。可以在测试前加入 “检查‑下载‑缓存” 的前置步骤，确保路径存在或自动下载。  

3. **代码复用**  
   - 将路径解析抽象为统一函数（例如 `get_test_model_path(name)`），避免在每个测试文件里重复硬编码，便于后期统一修改。  

4. **文档说明**  
   - 在 CI 文档或 README 中明确说明需预置该缓存路径或设置对应环境变量，帮助贡献者快速搭建本地测试环境。  

**结论**  
此次改动提升了 CI 对已有模型的复用效率，但引入了对特定文件系统结构的依赖。若按上述建议抽象路径并提供回退机制，可兼顾 CI 稳定性与代码可搬移性，降低因环境差异导致的测试失效风险。

---

### [JIT kernel] Update jit_kernel cache and develop doc (#17842)
**SHA**: `c08b54a` | 🔗 [查看提交](https://github.com/sgl-project/sglang/commit/c08b54a575d268d98770d5ce9eaa43cd21dfd3c7)

**变更类型**： 重构 （用自实现的 `cache_once` 替换 `functools.lru_cache`，并同步文档）  

**核心改动**  
- 在 `sglang/jit_kernel/utils.py` 中实现 `cache_once`（基于普通 dict），并将原先的 `@functools.lru_cache / @functools.cache` 装饰器全部换成该实现。  
- 所有 JIT kernel 模块（`add_constant、cuda_wait_value、flash_attention/*、hicache、timestep_embedding` 等）相应改为 `@cache_once`。  
- 文档 `development_jit_kernel_guide.md` 更新，提示用户使用 `cache_once`，并把该指南加入站点索引。  
- 小幅细节修正：`cuda_wait_value` 的 wrapper 名称从 `stream_wait_value` 改为 `cuda_wait_value`；测试文件路径更新。  

**影响范围**  
- `python/sglang/jit_kernel/*`（几乎所有 JIT kernel 实现）  
- `sglang/jit_kernel/utils.py`（新增装饰器、移除 `lru_cache` 导入）  
- 文档层面：开发者指南、站点索引  

**关注建议**  
1. **兼容性**：`cache_once` 只在进程生命周期内缓存一次，未实现 `maxsize`、过期或线程安全。若在多线程/分布式场景下使用 JIT 编译，需确认不会出现竞争写入。可以考虑在实现里加 `threading.Lock` 或直接使用 `functools.lru_cache` 并在 `torch.compile` 环境外包装。  
2. **内存泄漏**：所有已缓存的模块将在进程结束前一直保留，累计大量不同模板参数时可能导致显存/CPU 内存飙升。建议在上层提供显式清理或限制可缓存的键集合。  
3. **测试**：确保现有单元测试覆盖所有 `@cache_once` 的路径，尤其是相同参数多次调用是否返回同一 `Module` 实例。  
4. **文档**：开发者指南已更新，但仍需在 README 或快速入门示例中提醒使用 `sglang.jit_kernel.utils.cache_once` 替代 `lru_cache`，并解释其与 `torch.compile` 的冲突原因。  

总体而言，此次重构解决了 JIT 与 `torch.compile` 的兼容问题，但引入的简易缓存机制需要在并发、内存管理上额外关注。若后续需要更细粒度的缓存策略，可在 `cache_once` 基础上实现可配置的 `maxsize` 或采用第三方 LRU 实现。

---

### [model-gateway] Optimize consistent hashing hot path to eliminate allocations (#17467)
**SHA**: `897c35b` | 🔗 [查看提交](https://github.com/sgl-project/sglang/commit/897c35b4575dd91b5eb54918e970ffa4ab56e16e)

**🔧 变更类型**：性能优化  
**⚡ 重要程度**：🟡 中  

**📋 变更摘要**  
- 将 `ConsistentHashRing::get_owners` 从返回 `Vec<String>` 改为返回 `Vec<&str>`，在遍历环时直接保存对内部字符串切片的引用，避免了每一次调用的堆分配。  
- `is_owner` 直接基于 `&str` 进行比较，去掉了不必要的 `to_string`。  
- `RateLimitStore::get_owners` 重新包装为 `Vec<String>`，只在对外 API 需要时进行一次转换，保持向后兼容。  
- 新增 Criterion 基准 `consistent_hash_bench`，对 10、100、500 节点规模下的 `get_owners` 与 `is_owner` 进行微基准。  

**🎯 影响范围**  
- `sgl-model-gateway/src/mesh/consistent_hash.rs`（核心一致性哈希实现）  
- `sgl-model-gateway/src/mesh/stores.rs`（限流存储层）  
- 相关单元测试与公共 API（返回类型仍为 `Vec<String>`）  

**💡 关注建议**  
1. **生命周期安全**：`get_owners` 返回的 `&str` 引用指向内部 `String`，确保 `ConsistentHashRing` 本身在返回值使用期间未被移动或销毁；如有跨线程使用，建议在文档中明确要求 `Ring` 的所有者保持存活。  
2. **兼容性**：外部调用仍通过 `RateLimitStore::get_owners` 获取 `Vec<String>`，性能提升只在内部路径生效，确认没有遗漏直接调用 `ConsistentHashRing::get_owners` 的业务场景。  
3. **基准回归**：CI 中加入基准对比，确保在不同负载下分配次数确实下降且没有引入隐藏的性能回退。  
4. **测试覆盖**：现有单元测试已更新为 `&str`，建议再添加一次大规模（>1000 节点）环的所有权遍历，以防止 `while` 循环在极端节点数下出现无限循环。  

总体而言，此次改动通过消除热点路径的堆分配显著降低了一致性哈希的 CPU 开销，风险主要在于引用生命周期的正确使用，建议在文档和 CI 中加入相应检查。

---

### [Diffusion] Delete sgl-kernel outdated time_embedding kernel (#17278)
**SHA**: `fb74e43` | 🔗 [查看提交](https://github.com/sgl-project/sglang/commit/fb74e4370779b988ef08e16afe67c801a44e4c11)

**🎯 变更类型**：功能移除（删除已废弃的 `timestep_embedding` kernel）  
**⚡ 重要程度**：🟡 中  
**📋 变更摘要**：本次提交彻底删除了 `sgl-kernel` 中用于 Diffusion 的 `timestep_embedding` 实现，包括 CUDA/HIP 源文件、CMake 编译入口、Python 入口函数、头文件声明以及对应的单元测试和 CI 调用。所有与该算子相关的注册、导出和文档代码均被清理。  

**🎯 影响范围**  
- **编译系统**：`CMakeLists.txt`、`rocm_hipify.py`、`setup_rocm.py` 更新，避免找不到源码。  
- **C++/CUDA 代码**：`common_extension.cc`、`common_extension_rocm.cc` 中的 `torch.ops` 注册被移除。  
- **Python 包**：`sgl_kernel/__init__.py`、`sgl_kernel/elementwise.py`、`sgl_kernel_ops.h` 中的导入和声明被删掉。  
- **测试/CI**：`sgl-kernel/tests/sgl_diffusion/test_timestep_embedding.py` 与 CI workflow 中的对应执行步骤均被移除。  

**💡 关注建议**  
1. **兼容性检查**：确认 SGLang 主项目及外部依赖（如 Diffusers 示例、视觉嵌入层）不再调用 `torch.ops.sgl_kernel.timestep_embedding`。若仍有使用，需要改为官方 `diffusers` 实现或自行实现对应功能。  
2. **文档更新**：在 changelog 或 API 文档中明确标记 `timestep_embedding` 已删除，建议用户迁移路径。  
3. **版本号**：该破坏性改动应伴随次版本号提升（如 0.X → 0.Y）或在发布说明中标记 `BREAKING CHANGE`。  
4. **回滚路径**：如果后续发现真的有业务依赖，考虑保留一个轻量的 wrapper（调用 `diffusers.get_timestep_embedding`），而不是完全删除。  
5. **CI 健康**：删除的 CI 步骤已同步，建议在本地跑一遍完整的 AMD 与 CUDA CI，确保没有遗漏的引用导致构建或运行时错误。  

总体而言，本次删除清理了长期未维护的 Diffusion 代码，降低了维护成本，但请务必在发布前确认所有上游代码已完成迁移，以避免运行时 `AttributeError` 或链接错误。  

---

### [CI] Fix test_moe_fused_gate error (#17844)
**SHA**: `67fb492` | 🔗 [查看提交](https://github.com/sgl-project/sglang/commit/67fb492c9a8a11617fd730c0b63f9a5e76c6fb1b)

**🎯 变更类型**：其他（测试代码补丁）  
**⚡ 重要程度**：🟡 中  
**📋 变更摘要**：为 `sgl-kernel/tests/test_moe_fused_gate.py` 添加了本地实现 `biased_grouped_topk_impl` 并封装为 `biased_grouped_topk`，取代原先从 `sglang.srt.layers.moe.topk` 的导入，目的是修复 CI 中出现的 `test_moe_fused_gate` 错误。  

**🎯 影响范围**：仅影响测试目录 `sgl-kernel/tests/`，不触及生产代码或核心库。  

**💡 关注建议**  
1. **实现一致性**：本地实现与库中真实实现保持功能同步非常关键，建议在后续版本中把测试直接引用库实现，或将此实现抽取为公共工具，避免因库代码更新导致测试失效。  
2. **参数与返回类型**：检查所有可选参数的默认值、类型提示以及返回 dtype（`float32`、`int32`）与官方实现保持一致，防止隐藏的数值误差。  
3. **代码可维护性**：当前实现较长且包含循环（`for i in range(num_fused_shared_experts)`），若业务不再需要该逻辑，可考虑简化或使用向量化操作，以提升可读性和执行速度。  
4. **测试覆盖**：新增的实现应配套完整的单元测试，验证 `renormalize`、`routed_scaling_factor`、`apply_routed_scaling_factor_on_output` 等分支的正确性。  
5. **CI 稳定性**：由于修改仅在测试层面，建议在 CI 中保留对原实现的回归检查，防止两侧实现出现不一致。  

总体而言，此次变更修复了 CI 失效，风险局限于测试代码本身。后续可通过同步实现或直接引用库代码来降低维护成本。

---

### [AMD] CI - enable deepseekv3.2 on MI325-8gpu and merge perf/accuracy test suites into stage-b suites (#17633)
**SHA**: `52bca42` | 🔗 [查看提交](https://github.com/sgl-project/sglang/commit/52bca4287033a0e514d64e2a8798e45b132f9a4b)

**变更类型**：功能增强 / CI 调整  
**重要程度**：🟡 中  

**变更概要**  
本次 PR 主要对 AMD CI 流程进行重构与扩展：  
1. 新增 `stage-b-test-large-1-gpu-amd` 作业，并在相应矩阵中加入分片 (`part`) 与超时参数，使其在 `linux-mi325-gpu-1` 上并行运行。  
2. 调整已有大规模作业的分片数或 `auto-partition-size`（如 8‑GPU 大测试改为 3‑片），并统一超时上限。  
3. 移除原有的性能/精度专用作业（`stage-b-test‑*‑performance‑amd`、`accuracy‑amd`），改为统一的功能测试套件。  
4. 在 `scripts/ci/utils/slash_command_handler.py` 中加入新作业名，使 `/rerun` 指令支持对应 stage。  
5. 多个 AMD‑CI 注册的测试用例调低阈值（speed、accuracy）或在 CI 环境下禁用 AITER，以适配 MI‑325/MI‑35X 硬件的实际表现。  
6. `test/run_suite.py` 中同步更新可用的 AMD suite 列表，去除已删除的作业。

**影响范围**  
- CI 工作流文件 `.github/workflows/pr-test-amd.yml`（所有 AMD 相关的测试调度）。  
- 重新映射的测试套件列表、分片配置、超时设置。  
- `scripts/ci/utils/slash_command_handler.py`（命令触发的有效 stage）。  
- 多个 AMD 注册测试文件（`test_deepseek_v32_*`、`test_kimi_k2_instruct`、`test_triton_sliding_window`、`test_eval_accuracy_large`、`test_moe_eval_accuracy_large`），涉及阈值与环境变量的修改。  

**关注建议**  

1. **分片与超时一致性**：`auto-partition-size` 已从 2 调整为 3（8‑GPU）或保持 2（2‑GPU），请确认分片总数与实际 GPU 数匹配，防止出现 “part 超出范围” 的错误。  
2. **阈值回归**：多数阈值被下调（如 speed >15 → >20，accuracy >0.60 → >0.55），建议在后续迭代中逐步恢复到原始目标，避免因过宽的容忍度掩盖潜在性能回退。  
3. **环境变量保护**：在 `test_moe_eval_accuracy_large` 中显式设置 `SGLANG_USE_AITER=0` 等，确保仅在 AMD CI 环境生效；请在文档注明此行为，防止本地调试时意外关闭 AITER。  
4. **删除的作业**：性能/精度专用作业被移除后，若后续仍需单独跑这些基准，请在 CI 中重新加入或提供手动触发脚本。  
5. **CI 稳定性**：新增的 `stage-b-test-large-1-gpu-amd` 与分片逻辑可能引入并发竞争（如 VRAM 清理、容器启动），建议在 PR 合并前多跑几次完整的 AMD 流程，观察是否出现偶发失败。  

总体而言，此次改动提升了 AMD 平台的大模型测试覆盖度，简化了作业结构，但需关注分片配置与阈值回归的合理性，以确保 CI 结果的可靠性。

---

### fix: add bias when enable mm fallback variant (#17690)
**SHA**: `1c4616a` | 🔗 [查看提交](https://github.com/sgl-project/sglang/commit/1c4616a034496078461062a62771467e378c6a6b)

**🎯 变更类型**：Bug 修复  
**⚡ 重要程度**：🟡 中  

**📋 变更摘要**  
在 `matmul_persistent` 的 MM fallback 分支中，原实现仅返回 `torch.einsum` 的乘积结果，未对传入的 `bias` 做加法，导致在启用 fallback 时出现 “bias 丢失” 的错误。此次补丁在 fallback 路径显式计算乘积后若 `bias` 不为 `None` 即 `out += bias`，保持与深度 GEMM 与 Triton 实现一致的行为。

**🎯 影响范围**  
- `python/sglang/srt/batch_invariant_ops/batch_invariant_ops.py` 中的矩阵乘法入口。  
- 可能波及到所有使用 `matmul_persistent(..., bias=…)` 的上层算子（如多头注意力、前馈网络等），尤其在 `MM_FALLBACK_VARIANT` 被打开的机器上。

**💡 关注建议**  
1. **测试覆盖**：在 CI 中加入针对 `bias` 不为 `None` 的 `matmul_persistent` 调用的对照测试，验证 fallback 与非 fallback 结果一致。  
2. **参数校验**：若 `bias` 与输出形状不匹配，当前代码会直接抛异常，建议在函数头部加入形状检查，给出更友好的错误信息。  
3. **文档更新**：在 `README`/API 文档中说明开启 `MM_FALLBACK_VARIANT` 时，bias 仍会被正确使用，避免用户误以为该路径不支持 bias。  
4. **性能评估**：fallback 使用 `einsum`，在大规模张量上可能慢于 Triton 实现，建议在模型启动时记录 fallback 与非 fallback 的耗时差异，以帮助用户决定是否开启该特性。  

总体而言，此次修改恢复了功能完整性，对上层模型行为影响有限，但应通过测试和文档确保不会引入新的回归。

---

### [diffusion] perf: apply mul add fusion for Qwen-Image (#16299)
**SHA**: `647428d` | 🔗 [查看提交](https://github.com/sgl-project/sglang/commit/647428d8d6232bb29f19844fb80cfed172bfb6d8)

**🎯 变更类型**：性能优化（算子融合）  

**⚡ 重要程度**：🟡 中  

**📋 变更摘要**  
- 新增 `MulAdd` 自定义算子，实现 `a * (k + b) + c` 的一次 CUDA 计算；在 4‑D（帧）和 2‑D 两种 shape 上均有分支。  
- `triton_ops` 中的 `fuse_scale_shift_kernel` 重新签名，加入 `scale_constant` 参数，使其既能完成 “scale+1” 与 “scale+0” 的两种情况。  
- 删除 `ScaleResidual`（原先的 gated residual）并在所有 DiT 系列模型（`wanvideo`, `causal_wanvideo`, `hunyuanvideo`, `qwen_image`）中改为使用 `MulAdd`。  

**🎯 影响范围**  
- **算子层**：`sglang/multimodal_gen/runtime/layers/elementwise.py`, `sglang/multimodal_gen/runtime/layers/triton_ops.py`。  
- **模型层**：`sglang/multimodal_gen/runtime/models/dits/*` 系列文件（共 5+ 个模型）。  
- **其它**：`layernorm.py` 中移除 `ScaleResidual` 定义。  

**💡 关注建议**  
1. **功能验证**：跑通已有的多模态 / 视频生成基准，用相同随机种子比对 `MulAdd` 前后的 `hidden_states` 与 `output`，确保数值误差在容忍范围（尤其是 4‑D 帧展开路径）。  
2. **回退路径**：`forward_native` 已实现同等逻辑，建议在单卡 CPU/GPU 环境强制使用 native（`torch.compile` 时关闭自定义 CUDA），确认两者输出一致。  
3. **参数 `k`**：目前在模型中统一传入 `1.0`（对应原来的 `1 + scale`），若后续出现 `k=0` 场景，请确认 `triton` kernel 的 `scale_constant` 常量已正确编译（TL 常量只能是编译时整数/float）。  
4. **兼容性**：`MulAdd` 继承自 `CustomOp`，确保其在 `torch.fx`、`torch.compile`、`torch.jit.script` 中仍能被序列化；若出现 `torch.save` 错误，考虑在 `CustomOp` 中实现 `__reduce__`。  
5. **性能基准**：在 8‑GPU B40/B50 环境下对比前后每个 Transformer block 的显存占用与前向时间，特别注意 4‑D 场景（每帧多张图）是否真的实现了算子一次性计算而非两次拷贝。  

总体来看，此合并将原本的 “scale+1 * x + shift” 与 gated residual 合并为单核 Triton kernel，理论上可减少一次读写、提升吞吐。若数值及兼容性测试通过，可在 CI 中加入对 `MulAdd` 的单元测试，避免后续回归。

---

### [diffusion] feat: add an arg for controlling the number of prefetched layers in layerwise-offload (#17693)
**SHA**: `88fcd85` | 🔗 [查看提交](https://github.com/sgl-project/sglang/commit/88fcd8535fe1ceff3d28bf7872ba73c0a025403c)

**变更概述**  
- 为 DiT 层级 CPU‑offload 新增 `--dit-offload-prefetch-size` 参数，支持按比例或绝对层数预取。  
- `LayerwiseOffloadManager` 增加 `prefetch_size`、预取事件、批量预取与细粒度同步逻辑。  
- `OffloadableDiTMixin`、`denoising`、测试脚本相应改为 `prepare_for_next_req` 并在每轮结束时显式 `release_all`。  

**影响范围**  
- `runtime/pipelines_core/stages/denoising.py`（内存释放）  
- `runtime/server_args.py`（CLI 与参数校验）  
- `utils/layerwise_offload.py`（核心 offload 实现）  
- `test/*`（新增/修改测试用例）  

**关注点 & 建议**  
1. **内存/性能平衡**：预取层数越多峰值显存接近全加载，延迟下降；太少则频繁拷贝增大延迟。建议在不同显卡容量下做基准，以确定合适的 `prefetch_size`（如 0.2‑0.4）。  
2. **参数校验**：当前仅对 `>1` 且非整数进行取整，且对 `0.5‑1.0` 给出提示。可考虑在 CLI 加入明确的错误信息或限制上下界，防止误用。  
3. **兼容性**：`dit_layerwise_offload` 为 `True` 时必须保证 `dit_offload_prefetch_size` ≥ 0；其它 offload 选项（FSAD、cache‑dit）仍会被自动禁用，保持旧行为。  
4. **文档/示例**：更新 README 与 CLI 帮助，说明比例/绝对两种写法的含义及推荐取值范围。提供一个 `--dit-offload-prefetch-size 0.3` 的示例。  
5. **回退路径**：在 `prepare_for_next_req` 中已加入 `release_all`，但若用户自行在外部调用 `release_layer`，可能出现未同步的事件，建议在 `LayerwiseOffloadManager.release_all` 中统一清理 `_prefetch_events`。  

**结论**  
该改动为 DiT 层级 offload 引入可调预取，可在显存受限与吞吐需求之间灵活切换。开发者需完成充分的性能评估并同步文档，用户则应根据实际显卡容量选取合适的 `prefetch_size`，避免出现 “显存峰值≈无 offload” 的副作用。

---

### [diffusion] fix: fix suppressing error log on non-main ranks (#17712)
**SHA**: `1507dc6` | 🔗 [查看提交](https://github.com/sgl-project/sglang/commit/1507dc6cdf3def789aaaa6c08cf42157fe4200dd)

**🎯 变更类型**：功能增强 / 重构  
**⚡ 重要程度**：🟡 中  

**📋 变更摘要**  
1. 在 `gpu_worker.py` 中抽取内存分析逻辑 `do_mem_analysis()`，并在主卡（rank 0）且 `req.suppress_logs=False` 时统一输出峰值显存、可驻留组件及对应的 offload 参数建议。  
2. 将图像 resize 的日志从 `info` 降级为 `debug`，降低非关键信息的噪声。  
3. 删除原来的 `_current_server_args` 与对应的 `set_current_server_args`/`get_current_server_args`，改为仅使用 `_global_server_args`。  
4. `logging_utils` 中 `_log_process_aware` 增加 `server_log_level` 参数并在判断中加入 `server_log_level <= DEBUG`，同时把 `error` 方法的 `local_main_process_only` 改为 `False`，使错误日志不再受进程限制。  

**🎯 影响范围**  
- `python/sglang/multimodal_gen/runtime/managers/gpu_worker.py`（显存分析与日志抑制）  
- `python/sglang/multimodal_gen/runtime/pipelines_core/stages/input_validation.py`（日志级别）  
- `python/sglang/multimodal_gen/runtime/server_args.py`（全局/当前服务参数管理）  
- `python/sglang/multimodal_gen/runtime/utils/logging_utils.py`（日志过滤与错误日志行为）  

**💡 关注建议**  
1. **显存日志**：确认 `req.suppress_logs` 在所有调用方均已正确传递；若有旧代码仍依赖 `get_current_server_args()`，需迁移到 `get_global_server_args()` 或自行维护全局变量。  
2. **日志噪声**：`server_log_level <= DEBUG` 的新判定会在所有进程上强制输出 DEBUG 级别日志，需检查是否会泄露大量内部信息或影响性能。  
3. **错误日志**：`error` 现在在非本地主进程也会打印，确保集群日志聚合系统能接受增加的错误日志量。  
4. **兼容性**：搜索项目中对 `set_current_server_args`、`get_current_server_args` 的引用，避免运行时 `AttributeError`。  
5. **性能**：`do_mem_analysis()` 在每个 batch 结束后执行，虽开销不大，但在高吞吐场景下建议在 profiling 中确认不会成为瓶颈。  

总体来说，改动提升了显存使用可视化并简化了配置管理，但需留意日志过滤逻辑的副作用以及可能的 API 破坏。建议在分布式 CI 中加入对 `suppress_logs`、`error` 跨进程行为的回归测试。

---

### use shared memory for multimodal feature transport between Tokenizer and Scheduler (#16402)
**SHA**: `4d00bd1` | 🔗 [查看提交](https://github.com/sgl-project/sglang/commit/4d00bd17a37ea442f87c6b11168be2d30ac8ca61)

**🎯 变更类型**：功能增强  
**⚡ 重要程度**：🟡 中  

**📋 变更摘要**  
- 为多模态特征在 Tokenizer 与 Scheduler 之间的跨进程传输引入共享内存（`shared_memory`）实现。  
- 新增 `ShmPointerMMData`、`wrap_shm_features`、`unwrap_shm_features`，在 Tokenizer 发送前把 CPU‑Tensor 包装成共享内存指针，在 Scheduler 收到后恢复为 Tensor。  
- 通过 `_determine_tensor_transport_mode` 判断是否使用默认（pickle）模式，或在 `skip_tokenizer_init` 场景下保持旧行为。  

**🎯 影响范围**  
- `python/sglang/srt/managers/mm_utils.py`（核心实现）  
- `python/sglang/srt/managers/tokenizer_manager.py`（发送前包装）  
- `python/sglang/srt/managers/scheduler.py`（接收后解包）  

**💡 关注建议**  

1. **共享内存生命周期**：当前在 `__setstate__` 中 `shm_handle.close(); shm_handle.unlink()`，若解包后仍有引用会导致数据被提前删除。建议在解包后返回的 Tensor 持有 `shm_handle`，或在 `ShmPointerMMData` 中实现显式的 `release` 方法，由调用方在不再需要时手动清理。  
2. **异常安全**：`ShmPointerMMData.__init__` 在写入共享内存后立即 `close()`，但若写入过程中抛异常会留下未 unlink 的块。可在 `finally` 中加入 `self.shm.unlink()`，或使用 `contextmanager` 包装。  
3. **GPU Tensor 兼容**：包装仅针对 `item.feature.is_cpu`，但在实际使用中可能出现 GPU‑Tensor 直接传输的需求。若未来改为跨设备迁移，需在 `wrap_shm_features` 中加入 `tensor.to('cpu')` 前的显式警告或 fallback。  
4. **配置透明度**：`_get_is_default_transport` 依赖 `get_global_server_args()`，在 CLI 参数中未显式说明会导致用户误以为已生效。建议在日志中打印 “使用共享内存传输 multimodal features” 或提供 `--tensor-transport=shm` 开关。  
5. **兼容性测试**：共享内存仅在 Linux/macOS 上可用，Windows 需要 `multiprocessing.shared_memory` 同样支持但路径可能不同。建议在 CI 中加入平台判定，若不支持则自动回退到默认 pickle。  
6. **性能基准**：新增的 `np.ndarray` 视图拷贝以及 `torch.frombuffer` 可能带来额外 CPU 开销。建议提供基准对比（大模型/大图片）以验证收益符合预期。  

总体而言，本次改动显著降低跨进程大尺寸多模态特征的序列化开销，但需留意共享内存的管理与异常处理，防止潜在内存泄漏或数据竞争。若对应建议逐步完善，可提升系统的鲁棒性与可维护性。

---

### [hybrid-model] clean up and consolidate redundant fields in RadixLinearAttention (#17660)
**SHA**: `d90c083` | 🔗 [查看提交](https://github.com/sgl-project/sglang/commit/d90c0837e5b812864a7570234b1a498740a01e85)

**🎯 变更类型**：功能增强 / 重构  
**⚡ 重要程度**：🟡 中  

**📋 变更摘要**  
- 将 `RadixLinearAttention` 中原有的 “Q & K 共享 head/维度、attention_tp_size” 等冗余字段拆分为独立的 `num_q_heads / num_k_heads`、`head_q_dim / head_k_dim`，去除 `attention_tp_size` 参数。  
- 相应地在 `HybridLinearAttnBackend` 中统一使用 `layer.head_q_dim、layer.head_k_dim、layer.head_v_dim` 进行 reshape，删掉了多余的局部变量 (如 `head_dim、beta、g` 等)。  
- 更新模型层构造（kimi_linear、qwen3_next）以匹配新签名，移除对 `attention_tp_size` 的依赖。  

**🎯 影响范围**  
- `python/sglang/srt/layers/radix_linear_attention.py`（核心 Attention 类）  
- `python/sglang/srt/layers/attention/hybrid_linear_attn_backend.py`（后端实现）  
- 使用该 Attention 的模型文件 `kimi_linear.py`、`qwen3_next.py`（以及可能的其他模型）  

**💡 关注建议**  
1. **兼容性检查**：确认旧的 checkpoint/模型文件仍能在新代码下加载，若不兼容需提供迁移脚本或兼容层。  
2. **形状校验**：新增的 `num_q_heads、num_k_heads、head_q_dim、head_k_dim` 组合后，`rearrange` 的 reshape 逻辑必须严格对应 `layer.num_*_heads * layer.head_*_dim`，建议在单元测试里加入断言。  
3. **性能验证**：去除冗余变量后，功能未变，但请跑一次推理基准，对比前后 latency/显存，确保无意外回退。  
4. **文档/注释**：更新 `RadixLinearAttention` 的 API 文档，说明不再需要 `attention_tp_size`，并解释 `head_q_dim / head_k_dim` 与原 `head_qk_dim` 的映射关系。  
5. **回滚路径**：若出现异常，可临时恢复旧字段的属性（如保持 `self.head_qk_dim = self.head_q_dim`），以保证快速回滚。  

总体来看，此次重构消除了冗余字段，使代码结构更清晰，后端实现也更加统一。项目在完成上述验证后即可安全合并。

---

### Make flashMLA work on: Cu13, B300 (#17600)
**SHA**: `8acd4d7` | 🔗 [查看提交](https://github.com/sgl-project/sglang/commit/8acd4d7d7e6f436601ef3ae51678f130fdc04d25)

**🎯 变更类型**：功能增强  
**⚡ 重要程度**：🟡 中  
**📋 变更摘要**：在 `sgl-kernel/cmake/flashmla.cmake` 中加入针对 CUDA 13+ 的补丁，使 FlashMLA 能在新架构 **SM103a (Cu13, B300)** 上编译运行。通过修改 `flashmla_utils.h` 与 Cutlass 的 `arch/config.h`，并在 `CUDA_COMPILE_FLAGS` 中追加 `-gencode=arch=compute_103a,code=sm_103a`。

**🎯 影响范围**  
- `flashmla` 子模块（C++/CUDA 代码）  
- Cutlass 依赖的编译配置文件  
- CMake 构建流程（仅在检测到 CUDA ≥ 13 时生效）  

**💡 关注建议**  
1. **补丁可重复性**：当前在 CMake 里直接 `file(READ/WRITE)` 修改源码，若用户多次运行 CMake 可能产生累计写入。建议改为使用 `configure_file` 生成本地副本或在源码树外维护 patch 文件，以保持源码的幂等性。  
2. **向后兼容**：`IS_SM100` 判断从 `==1000` 改为 `>=1000 && <1100`，请确认这不会误将 SM10x（如 1010）纳入 SM100 家族，导致不兼容的代码路径被错误启用。可在 CI 中加入旧版 GPU（如 A100）编译测试。  
3. **条件编译检查**：`CUTLASS_ARCH_MMA_SM103_SUPPORTED` 与 `CUTLASS_ARCH_MMA_SM103_ENABLED` 的宏定义仅在 `__CUDACC_VER_MAJOR__ >= 13` 时生效，确保其它编译器（Clang‑CUDA、NVCC <13）仍保持原有行为。  
4. **文档与版本声明**：在项目 README/CHANGELOG 中注明需要 CUDA 13+ 才能使用 SM103a，避免用户在旧版 CUDA 环境下遇到 “未知架构” 编译错误。  
5. **回归测试**：建议在 CI 中加入针对 SM103a 的单元/性能基准（可使用模拟 `__CUDA_ARCH__=1030` 编译），并保留对 SM100/SM101 的测试，以确保新补丁不破坏既有路径。  

总体而言，此次改动为新硬件提供了必需的编译支持，但涉及对上游源码的直接更改，需加强幂等性、回归验证以及文档提示。

---

#### 🟢 低重要度变更 (8)

### [diffusion] fix: fix comfyui import typo (#17834)
**SHA**: `1d1e72e` | 🔗 [查看提交](https://github.com/sgl-project/sglang/commit/1d1e72e516f7f9df2f682283ee9e35692e2b9e66)

**🎯 变更类型**：代码重构  
**⚡ 重要程度**：🟢低  
**📋 摘要**：修正 `comfyui_qwen_image_pipeline.py` 中的导入错误，将 `set_default_dtype` 替换为正确的 `set_default_torch_dtype`，并相应更新上下文中的调用。

---

### [diffusion] doc: fix wrong docker run command (#17856)
**SHA**: `2573a26` | 🔗 [查看提交](https://github.com/sgl-project/sglang/commit/2573a262afc00b66af02cdfc5ab1e98f414150a0)

**🎯 变更类型**：文档更新  
**⚡ 重要程度**：🟢低  
**📋 摘要**：在 `install.md` 中修正 Docker 运行指令，添加了在容器内安装 diffusion 依赖的步骤，并改为使用 `zsh -c` 包裹完整的安装与运行命令。

---

### [model-gateway] Optimize HashRing construction to reduce heap allocations (#17575)
**SHA**: `6f00996` | 🔗 [查看提交](https://github.com/sgl-project/sglang/commit/6f009961bb940fcca681832a3a8dbc01fb25c0f4)

**🎯 变更类型**：代码重构  
**⚡ 重要程度**：🟢低  
**📋 摘要**：在 `HashRing` 构造中，将原先的 `format!` 与 `hash_position` 替换为直接使用 `blake3` 哈希器，并对 URL 只创建一次 `Arc<str>`，以减少堆分配和提升构建效率。

---

### [DSv32] Overlap indexer qk projection and activation quant (#17688)
**SHA**: `a8dda2a` | 🔗 [查看提交](https://github.com/sgl-project/sglang/commit/a8dda2aa5727a7dfa54fa7323d334cb6e0aa69e0)

**🎯 变更类型**：代码重构  
**⚡ 重要程度**：🟢低  
**📋 摘要**：将 Q、K 的 BF16 计算与激活量化合并到主流 CUDA 流中，移除冗余的双流分支，以提升注意力索引器的计算效率。

---

### [diffusion] endpoint: fix vertex generate (#17611)
**SHA**: `32ea7bc` | 🔗 [查看提交](https://github.com/sgl-project/sglang/commit/32ea7bcdd81913631ddc4add00e37fca5cdb1607)

**🎯 变更类型**：代码重构  
**⚡ 重要程度**：🟢低  
**📋 摘要**：在 `vertex_generate` 中构建参数字典并过滤 `None`，防止 `SamplingParams` 的默认值被覆盖，提升生成接口的健壮性。

---

### [Diffusion] glm-image apply flashinfer rope (#17689)
**SHA**: `331a224` | 🔗 [查看提交](https://github.com/sgl-project/sglang/commit/331a22427c7fcce880f6f5e282cef40350111774)

**🎯 变更类型**：代码重构  
**⚡ 重要程度**：🟢低  
**📋 摘要**：在 `glm_image.py` 中新增对 FlashInfer ROPE 的 CUDA 加速实现，加入平台检查与条件分支，并相应更新导入和变量定义。

---

### [AMD] Deprecate ROCm 6.3 artifacts and standardize gfx942 on ROCm 7 (#17785)
**SHA**: `93423ff` | 🔗 [查看提交](https://github.com/sgl-project/sglang/commit/93423ff78043d19d0c4b9d0cedf8f0eab543aa71)

**🎯 变更类型**：配置调整  
**⚡ 重要程度**：🟢 低  

**📋 摘要**：在 CI 工作流、Docker 镜像及文档中移除 ROCm 6.3（rocm630）相关构建，统一使用 ROCm 7（rocm700）并仅保留 gfx942 与 gfx950 两个架构。相关标签、基础镜像及示例命令均已更新。

---

### Pass GPU ids to kill specified devices in script. (#17840)
**SHA**: `8278ef0` | 🔗 [查看提交](https://github.com/sgl-project/sglang/commit/8278ef0e68471be47872553374ed6e8ddf61d976)

**🎯 变更类型**：代码重构  

**⚡ 重要程度**：🟢低  

**📋 摘要**：更新 `scripts/killall_sglang.sh`，支持通过参数指定GPU ID 或全部GPU进行进程清理；相应修改 CI 工作流调用方式，从原先的 `"nuk_gpus"` 改为 `"all"`。

---

