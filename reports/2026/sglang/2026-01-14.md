# 每日更新报告（2026-01-14）

## sgl-project/sglang

| 提交时间 | 作者 | 提交信息 |
|----------|------|----------|
| 2026-01-14 23:31:46 | Yuan Luo | [diffusion] fix: revise fa4 backend to support blackwell (#17077) |
| 2026-01-14 23:06:01 | shuwenn | [Env] centralize pd vars in environ.py (#16264) |
| 2026-01-14 17:44:40 | fxmarty-amd | [AMD][Quantization] Add `int4fp8_moe` online quantization on ROCm (#7392) |
| 2026-01-14 17:29:23 | Yuan Luo | [VLM] Support ViT CUDA Graph for InternVL (#16732) |
| 2026-01-14 17:26:48 | Netanel Haber | Fix issues/16714: Revert comment out of `tl.debug_barrier()` in causal_conv1d_triton (#16899) |
| 2026-01-14 17:08:27 | roikoren755 | [NemotronH] Use ReplicatedLinear for fc1_latent_proj (#16569) |
| 2026-01-14 16:30:35 | shaharmor98 | Feat/support nemotron h mtp (#17013) |
| 2026-01-14 15:41:45 | Michael | [AMD] Add AMD CI registration (1-gpu unit test) to nightly CI.  (#16941) |
| 2026-01-14 14:44:10 | HuangJi | [diffusion] fix: fix --warmup-resolutions' conflict with CacheDiT (#16962) |
| 2026-01-14 13:27:49 | sglang-bot | chore: bump sgl-kernel version to 0.3.21 (#16888) |
| 2026-01-14 12:21:55 | shuwenn | feat: add --admin-api-key for finer-grained endpoint auth (#15908) |
| 2026-01-14 12:18:42 | Alison Shao | test: split Qwen3 Next tests and disable PCG tests due to intermittent failures (#16989) |
| 2026-01-14 12:16:32 | Alison Shao | [CI] Fix max_parallel for scheduled runs (#17046) |
| 2026-01-14 11:36:27 | Mick | [diffusion] chore: avoid raising error when output resolution is not optimal (#17030) |
| 2026-01-14 11:35:06 | Mick | [diffusion] chore: refactor warmup logic (#17027) |
| 2026-01-14 11:19:26 | ybyang | Update deepseekV32 Cp doc (#17054) |
| 2026-01-14 10:26:31 | Liangsheng Yin | fix grammar timeout sync across tp ranks. (#16898) |
| 2026-01-14 10:14:32 | Lianmin Zheng | Fix kernel type annotations for fp8 quant and logging (#16994) |
| 2026-01-14 09:36:01 | Hubert Lu | [AMD] enable CUDA graph for NSA backend and fix NSA FP8 fused RMSNorm group quant (#16841) |
| 2026-01-14 09:28:32 | Ziwen Zhao | [model-gateway] add --disable-health-check option to skip worker health probes (#17002) |
| 2026-01-14 09:03:39 | Tony Lu | [model-gateway] HA - Lightweight State Layer + gRPC Mesh (#14108) |
| 2026-01-14 06:12:33 | Alison Shao | Add 5090 dry run stage to PR test workflow (#17022) |
| 2026-01-14 04:39:14 | Byron Hsu | [logprob] Fix logprob + streaming for long concurrent decode by caching already processed logprob  (#17005) |
| 2026-01-14 04:38:39 | Lianmin Zheng | Code clean up for fp8 quantization (#16982) |
| 2026-01-14 02:02:03 | Yuhao Yang | [diffusion] model: GLM-Image (#16894) |

### 📊 统计摘要
> 本日共 25 个提交 | 🔴高 7 | 🟡中 11 | 🟢低 7
## 📋 目录

- [sgl-project/sglang](#sgl-project-sglang)
  - [📊 统计摘要](#-统计摘要)
  - [🔴 高重要度变更 (7)](#-🔴-高重要度变更-7)
    - [[AMD][Quantization] Add `int4fp8_moe` online quantization...](#5af84c8)
    - [[AMD] Add AMD CI registration (1-gpu unit test) to nightl...](#b025cff)
    - [feat: add --admin-api-key for finer-grained endpoint auth...](#cd33694)
    - [Fix kernel type annotations for fp8 quant and logging (#1...](#a4825ed)
    - [[model-gateway] HA - Lightweight State Layer + gRPC Mesh ...](#5938c3b)
    - [Code clean up for fp8 quantization (#16982)](#075c5a5)
    - [[diffusion] model: GLM-Image (#16894)](#a0b4ba9)
  - [🟡 中重要度变更 (11)](#-🟡-中重要度变更-11)
    - [[diffusion] fix: revise fa4 backend to support blackwell ...](#969faaa)
    - [[Env] centralize pd vars in environ.py (#16264)](#48c2aca)
    - [[VLM] Support ViT CUDA Graph for InternVL (#16732)](#feae615)
    - [Feat/support nemotron h mtp (#17013)](#ba625c2)
    - [test: split Qwen3 Next tests and disable PCG tests due to...](#c5e363e)
    - [[CI] Fix max_parallel for scheduled runs (#17046)](#9479eca)
    - [fix grammar timeout sync across tp ranks. (#16898)](#e2c8a50)
    - [[AMD] enable CUDA graph for NSA backend and fix NSA FP8 f...](#afe285f)
    - [[model-gateway] add --disable-health-check option to skip...](#cf25852)
    - [Add 5090 dry run stage to PR test workflow (#17022)](#b880607)
    - [[logprob] Fix logprob + streaming for long concurrent dec...](#339915c)
  - [🟢 低重要度变更 (7)](#-🟢-低重要度变更-7)
    - [Fix issues/16714: Revert comment out of `tl.debug_barrier...](#e75299a)
    - [[NemotronH] Use ReplicatedLinear for fc1_latent_proj (#16...](#72bacc8)
    - [[diffusion] fix: fix --warmup-resolutions' conflict with ...](#030496e)
    - [chore: bump sgl-kernel version to 0.3.21 (#16888)](#c86ca12)
    - [[diffusion] chore: avoid raising error when output resolu...](#a5348ea)
    - [[diffusion] chore: refactor warmup logic (#17027)](#9524040)
    - [Update deepseekV32 Cp doc (#17054)](#2122fea)
#### 🔴 高重要度变更 (7)

### [AMD][Quantization] Add `int4fp8_moe` online quantization on ROCm (#7392)
**SHA**: `5af84c8` | 🔗 [查看提交](https://github.com/sgl-project/sglang/commit/5af84c8af554fa0e6fb55890b39b97f155275372)

**🎯 变更类型**：功能增强 / 架构变更 / 性能优化  
**⚡ 重要程度**：🔴高  
**📋 变更摘要**：  
- 在 AMD GPU（ROCm）上新增 `int4fp8_moe` 在线量化方案，针对 MoE（Mixtral 等）模型实现 **权重量化为 INT4、计算升级为 FP8**，显著降低显存占用并提升吞吐。  
- 完整实现量化工具链（scale 计算、INT4‑>INT32 打包、权重加载与重新标度）、模型配置、命令行选项、文档及端到端测试。  

**🎯 影响范围**：  
- `sglang/srt/layers/`（新增 `int4fp8_utils.py`、`quantization/quark_int4fp8_moe.py`）  
- 配置/模型加载 (`model_config.py`, `utils/common.py`, `model_loader/*`)  
- 服务器启动参数 (`server_args.py`)  
- 文档 `docs/advanced_features/quantization.md`  
- 端到端测试 `test/srt/test_int4fp8_moe.py`  
- 进度条统一常量 `BAR_FORMAT`（影响所有权重下载/加载过程）  

**🔍 技术洞察**  

| 维度 | 影响分析 |
|------|----------|
| **架构影响** | 1. **新增量化子系统**：`QuarkInt4Fp8Config` 与 `QuarkInt4Fp8MoEMethod` 实现了 **FusedMoE** 的自定义权重加载、scale 计算与后处理。<br>2. **依赖 AMD‑specific 库**：通过 `aiter`（`fused_moe`, `shuffle_weight`）实现 INT4‑FP8 计算，仅在 ROCm/AMD GPU 上可用；非 AMD 环境会在 `__init__` 抛出 `NotImplementedError`。<br>3. **模型配置、参数注册**：新增 `quark_int4fp8_moe` 选项，并将其加入 `QUANTIZATION_CHOICES`、`mixtral_supported` 列表，确保在模型加载时被识别。 |
| **性能影响** | 1. **显存占用**：INT4 权重使用 **32 位 packed** (8×4‑bit → 1×int32) ，相较原始 BF16/FP16 可降低约 **75%** 的显存。<br>2. **计算吞吐**：FP8 (E4M3FN) 计算在 CDNA3/4 上原生加速，理论 FLOPS 提升 2×‑3×；实际提升取决于 `fused_moe` 内部实现（已对 `shuffle_weight` 进行预处理）。<br>3. **在线量化开销**：权重加载时会在设备上完成 quantize/scale，进度条通过 `online_quant_progress_bar` 可观察。单次模型启动额外增加 **≈ 5–10%** 的加载时间（主要为 scale 计算与 pack）。 |
| **安全考虑** | - 仅在本地 GPU 运行，不涉及网络交互；无新增外部依赖泄漏风险。<br>- 使用 `torch.float8_e4m3fn` 需要硬件/驱动支持；若在不兼容设备上误用会触发 **RuntimeError**，已在代码层做 `NotImplementedError` 防护。<br>- `pack_int4_to_int32` 中未检查负数的符号位扩展，可能在极端数值下产生 **位溢出**，但已通过 `& 0x0F` 掩码限制。 |
| **可维护性** | - 新增文件与大量实现细节（约 500 行）集中在 `quark_int4fp8_moe.py`，逻辑相对独立，易于单独测试。<br>- 通过统一的 `BAR_FORMAT` 防止日志干扰，提升多进程/多节点调试体验。<br>- 文档已同步说明使用方式，降低学习成本。 |

**⚠️ 潜在风险**  
1. **硬件限定**：仅在 AMD CDNA3/4（MI300X 等）上可用；在 CUDA 环境会直接报错，可能导致 CI/用户误解。  
2. **数值稳定性**：INT4 → FP8 的双尺度 (int4_scale / fp8_scale) 乘法在极端权重分布下可能出现 **溢出/下溢**，进而导致推理精度下降。  
3. **兼容性回退**：`model_config._verify_quantization` 新增 `"quark_int4fp8_moe"`，但如果用户自行修改 `quantization` 参数或使用旧版本配置文件，可能出现 **未匹配的 quant_config** 错误。  
4. **依赖 `aiter` 版本**：`aiter` 的 API 变动（如 `QuantType.per_Token`）会直接破坏 `fused_moe` 调用；缺少 pin 依赖声明可能导致安装失败。  
5. **进度条并发**：虽然统一了 `BAR_FORMAT`，但在多进程/多节点加载时多个 `online_quant_progress_bar` 仍可能竞争 `tqdm` 的 `position`，导致 UI 混乱。  

**💡 关注建议**  
- **硬件检测与友好提示**：在命令行入口（`launch_server`）提前检测 `torch.cuda.is_available()` 与 `is_hip()`，若检测到不兼容平台，给出明确错误信息并建议使用其他量化方案。  
- **数值校准**：在 `process_weights_after_loading` 中加入 **scale 範围检查**（如 `torch.isfinite`），并在异常时回退到 FP16/BF16。可提供 `--skip-scale-check` 选项供高性能需求用户关闭。  
- **CI 扩展**：新增 AMD‑GPU（ROCm）CI 作业，运行 `test_int4fp8_moe.py`，确保量化路径在未来代码改动中保持兼容。  
- **文档增强**：在 `quantization.md` 中标明“仅在 AMD CDNA3/4，Python ≥3.10，torch ≥2.3，ROCm ≥5.7” 的前置条件，并提供 `pip install aiter` 版本指引。  
- **包装层抽象**：将 `pack_int4_to_int32` 与 `quantize_*` 抽成公共子模块（已在 `int4fp8_utils.py`），后续若支撑 NVIDIA FP8，可在同一接口下实现不同实现路径。  
- **兼容回退**：在 `QuarkInt4Fp8Config.get_quant_method` 中，当检测到非 `FusedMoE` 层时，返回 `None` 并记录 **warning**，避免因误用导致整个模型加载失败。  

---  

总体来看，此次 PR 为 SGLang 在 AMD GPU 上引入了 **极具竞争力的低精度 MoE 量化**，在显存友好度与吞吐上都有显著提升。只要在硬件兼容检查、数值校准与 CI 覆盖上做好把控，即可在保持项目稳定性的前提下，为 Mixtral 等大模型提供更高效的部署方案。

---

### [AMD] Add AMD CI registration (1-gpu unit test) to nightly CI.  (#16941)
**SHA**: `b025cff` | 🔗 [查看提交](https://github.com/sgl-project/sglang/commit/b025cff441e187646b5bed6dbaf6152a1dd11522)

**🎯 变更类型**：功能增强 / 架构变更 / 性能优化  
**⚡ 重要程度**：🔴 高  

**📋 变更摘要**  
- 为 AMD GPU（MI30x、MI35x）在 Nightly CI 中新增 1‑GPU 单元测试、2‑GPU 与 8‑GPU 准确度（accuracy）以及结合准确度+性能（accuracy+perf）的综合测试，覆盖 GPT‑OSS、DeepSeek‑R1、DeepSeek‑V3.1、Grok‑1（FP8/INT4）与 Grok‑2 等模型。  
- 重构 `.github/workflows/nightly-test-amd.yml`，细化 job 名称、输入选项并将原有 8‑GPU 性能测试拆分为独立 suite（e.g. `nightly‑8‑gpu‑grok1‑int4`、`nightly‑8‑gpu‑deepseek‑v31` 等），支持 MI30x 与 MI35x 两类硬件。  
- 新增大量 **AMD 注册**（`register_amd_ci`）代码，使各测试能够在 AMD CI 环境中自动登记，分别对应不同的 suite 与预估时间。  
- 将原有的大而全的 GSM8K、Grok 性能/准确度测试拆分为 **细粒度文件**（如 `test_grok1_fp8_eval_amd.py`、`test_grok1_int4_perf_mi35x.py` 等），并对部分不兼容的测试（VLM、CPP radix cache、模型文件验证等）**取消 AMD 注册**。  
- 更新若干已有测试（bench_fn、batch_invariant_ops、debug_utils、lora 等）以在 AMD 环境下也能执行，并在注释中说明 MI300 与 MI35x 的共享内存差异或 C++ 实现限制。  

**🎯 影响范围**  
- **CI 工作流**：`.github/workflows/nightly-test-amd.yml`（所有 AMD‑related jobs）。  
- **测试套件**：  
  - `test/registered/amd/*`（accuracy、perf、unit、vlm、nightly）  
  - `test/registered/perf/*`（新增 `test_grok*_perf.py`、`test_deepseek*_perf_mi35x.py` 等）  
  - 部分 CUDA‐only测试加入 AMD 注册（`bench_fn`, `batch_invariant_ops`, `debug_utils`, `lora`, `scheduler`, `utils`）。  
- **代码库**：`sglang/test/ci/`, `sglang/test/registered/amd/`、`sglang/test/registered/perf/`、`sglang/test/registered/core/` 等目录。  
- **运行时**：所有新加入的模型评估与性能基准将会在 AMD CI runner（linux‑mi325‑gpu‑*、linux‑mi35x‑gpu‑*）上实际执行。  

---

### 🔍 技术洞察  

| 维度 | 影响描述 |
|------|----------|
| **架构影响** | - 引入 **AMD CI 注册** (`register_amd_ci`) 与 **suite** 概念，使 CI 框架可以统一管理 CUDA 与 AMD 两套硬件的作业调度。<br>- 工作流中通过 `inputs.job_filter` 支持灵活选择子 job，避免一次性在所有 runner 上跑所有模型，提升排队效率。<br>- 将大型混合测试拆分成更细的 suite（如 `nightly‑8‑gpu‑grok1‑int4`），使得每个 CI runner 只负责单一模型/配置，降低资源冲突、缓存污染的风险。<br>- 新增 **模型路径层级**（env → 本地路径 → HF ID），在 AMD 环境下优先使用本地缓存，降低网络下载开销。 |
| **性能影响** | - **单元测试**（1‑GPU）采用 `timeout-per-file 600s`，显著缩短 CI 周期，对 AMD 低功耗/少显存卡（MI30x）更友好。<br>- **准确度基准**（GSM8K few‑shot）以及 **VLM/MMMU** 基准在 AMD 上保持原有逻辑，只是改为 `--attention-backend aiter`、`--mem-fraction-static 0.85` 等参数，以适配 AMD ROCm 7.x 的内存管理。<br>- **性能基准** 采用 `NightlyBenchmarkRunner`，在报告中去除 trace 与 cost 列，专注于 **latency、input/output throughput、ITL**，便于对不同硬件（MI300X vs MI35x）进行直接对比。<br>- 为 MI35x 添加 `RCCL_MSCCL_ENABLE=0`、`SGLANG_USE_AITER=1`、`SGLANG_INT4_WEIGHT` 等环境变量，以规避 MI35x 上的 MSCCL/共享内存限制。 |
| **安全考虑** | - 所有新增测试均通过 `register_amd_ci(..., nightly=True)` 只在 **内部 CI** 运行，未引入外部网络服务。<br>- 仍保留对 **HF_TOKEN**（访问受限模型）和 **HF_HUB_CACHE** 环境变量的配置，未泄露凭证。<br>- `ci_register` 中的 `est_time` 与 `suite` 仅用于调度，无安全隐患。 |
| **可维护性** | - 将庞大的单文件测试拆分为 **模型/配置粒度** 的多个文件（≈150 KB/文件），代码更易阅读、增删模型时只需编辑对应文件。<br>- 统一使用 `ModelConfig` dataclass，所有模型参数集中管理，避免硬编码散落。<br>- 为每个 suite 添加 **文档注释**，明确 MI30x 与 MI35x 兼容性差异，降低后续维护的认知成本。 |
| **兼容性** | - 部分原有的 **CUDA‑only** 测试（如 `test_cpp_radix_cache.py`、`test_model_file_verifier.py`）已 **移除 AMD 注册**，因为在 AMD 环境下存在 C++ 实现或共享内存限制的问题，避免 CI 失败。<br>- 其余测试在 `register_amd_ci` 与 `register_cuda_ci` 同时登记，保证 **双平台**（CUDA + ROCm）均能跑通。 |

---

### ⚠️ 潜在风险  

1. **模型下载与缓存**  
   - 部分模型（如 DeepSeek‑R1‑MXFP4、Grok‑1‑INT4）默认走 HF 下载，如果 CI 节点的 HF 缓存目录（`/data2/models/huggingface`）未预热，首次跑可能超出 `timeout-per-file`，导致 job 超时。  
2. **环境变量冲突**  
   - 多个 suite 同时使用 `RCCL_MSCCL_ENABLE=0`、`SGLANG_USE_AITER=1`，若 runner 共享进程或容器未完全隔离，可能出现残留环境导致后续 job 行为异常。  
3. **资源竞争**  
   - 8‑GPU jobs 在同一 runner 上会并行启动 8 个 GPU 进程，若前置的 1‑GPU 单元测试仍在运行，可能导致显存不足；需要 CI 调度确保互斥。  
4. **代码重复/维护负担**  
   - 拆分后产生大量相似的 benchmark 脚本（Grok‑1‑FP8、INT4、Grok‑2…），若底层 benchmark 参数（如 `--mem-fraction-static`）需统一调整，必须手动同步所有文件，易产生不一致。  
5. **特定硬件限制**  
   - MI35x 的共享内存上限（64 KB）与某些 kernel（如 `batch_invariant_ops`）需求不匹配，已在注释中标记，但仍有可能在后续模型或算子更新时触发 **LaunchFailure**。  

---

### 💡 关注建议  

| 建议 | 说明 |
|------|------|
| **统一基准配置** | 将所有 benchmark 参数抽取到公共模块（如 `benchmark_common.py`），让每个具体 test 只引用该模块，降低后期统一修改的成本。 |
| **缓存预热策略** | 在 CI workflow 开头加入 **模型预下载** 步骤（`actions/cache` + `snapshot_download`），或在 `nightly-test-amd.yml` 中为需要的大模型（DeepSeek‑R1‑MXFP4、Grok‑2）

---

### feat: add --admin-api-key for finer-grained endpoint auth (#15908)
**SHA**: `cd33694` | 🔗 [查看提交](https://github.com/sgl-project/sglang/commit/cd336945854669e69b2d62b4604d212ca508ee00)

**🎯 变更类型**：功能增强（细粒度的管理端点鉴权）  
**⚡ 重要程度**：🔴 高  

**📋 变更摘要**  
- 新增 `--admin-api-key` 参数，可为仅限管理/控制类 HTTP 接口设置专属的 **admin** 鉴权密钥。  
- 引入 `sglang.srt.utils.auth` 模块，实现三层鉴权模型（NORMAL、ADMIN_OPTIONAL、ADMIN_FORCE）并提供统一的中间件。  
- 为所有现有的内部管理 API（权重更新、缓存刷新、profiling、LoRA 管理等）统一打上 `@auth_level(AuthLevel.ADMIN_OPTIONAL)`，实现 **admin‑only** 访问控制。  
- 更新 CLI 参数、文档及单元测试，删除旧的 `add_api_key_middleware` 实现，保持向后兼容。  

**🎯 影响范围**  
- `python/sglang/srt/entrypoints/http_server.py`（所有管理类路由）  
- `python/sglang/srt/server_args.py`（新增 `admin_api_key` 配置）  
- `python/sglang/srt/utils/auth.py`（全新鉴权实现）  
- `python/sglang/srt/utils/common.py`（移除旧鉴权函数）  
- 文档 `docs/advanced_features/server_arguments.md`  
- 测试 `python/sglang/test/test_http_server_auth.py`  

---

### 🔍 技术洞察

| 维度 | 影响描述 |
|------|----------|
| **架构影响** | - 将鉴权职责从散落的单个中间件迁移到 **独立、可复用的 auth 模块**，实现了 **职责分离**；<br>- 引入 `AuthLevel` 标记，使得路由与安全策略解耦，后续新增 “强制管理员” (`ADMIN_FORCE`) 接口只需在函数上标注即可，无需改动中间件逻辑。<br>- `add_api_key_middleware` 仍保留在 `auth.py`，便于统一在 `launch_server` 中一次性挂载，降低代码重复。 |
| **性能影响** | - 鉴权实现仅在 HTTP 请求入口进行一次 **常数时间** 的 token 比较（`secrets.compare_digest`），与原实现相当。<br>- 通过 **懒加载**（仅在实际使用时 import FastAPI/Starlette）避免对单元测试环境的额外依赖，未对核心推理路径产生额外开销。 |
| **安全考虑** | - **细粒度的 admin 密钥**：管理员操作（权重更新、缓存清理、日志配置等）不再共享普通 `--api-key`，降低因泄露普通密钥而导致的高危操作风险。<br>- `ADMIN_FORCE` 端点（目前暂无实现）在未配置 `admin_api_key` 时会返回 **403**，防止默认开放。<br>- 统一的错误返回（401/403）避免信息泄露；健康/指标端点保持公开，支持 K8s/Prometheus 监控。<br>- 采用 **常量时间比较** 防止时序侧信道攻击。 |
| **可维护性** | - 通过装饰器 `@auth_level` 明确每个路由的安全级别，代码可读性提升。<br>- 中间件逻辑统一在 `auth.py`，以后若需增加更复杂的鉴权（RBAC、IP 白名单等）只需在该模块扩展 `decide_request_auth`。 |
| **向后兼容** | - 旧的 `--api-key` 行为保持不变（所有普通端点仍受 `api_key` 保护）。<br>- 当仅配置 `admin_api_key`，普通端点默认 **开放**（保持与历史行为一致），但 `ADMIN_OPTIONAL`/`ADMIN_FORCE` 仍受保护。<br>- `launch_server` 中的兼容逻辑检测任意一个密钥或任意 `ADMIN_FORCE` 端点，确保在未配置密钥的情况下仍会添加中间件（但不进行校验），避免因缺失中间件导致 404。 |

---

### ⚠️ 潜在风险

1. **配置误解**  
   - 用户可能误以为 `--admin-api-key` 只影响管理员端点，实际上在 **同时配置** `api_key` 与 `admin_api_key` 时，普通端点仍必须使用 `api_key`，而管理员端点只能使用 `admin_api_key`。文档需明确说明该优先级规则，防止运维错误导致请求被拒绝。  

2. **未标记的敏感端点**  
   - 目前已有大量管理端点添加了 `ADMIN_OPTIONAL`，但若后续新加入的高危操作忘记标记，仍会受到 `api_key`（若存在）或公开访问的风险。建议在代码审查或 CI 中加入 **安全审计**，确保所有可能影响模型权重、内存或日志的路由都被标记。  

3. **强制管理员端点 (`ADMIN_FORCE`) 尚未使用**  
   - 若未来引入 `ADMIN_FORCE` 而忘记配置 `admin_api_key`，该端点会统一返回 403，可能导致业务中断。需要在发布说明中提醒用户在启用此类端点前务必配置 `admin_api_key`。  

4. **多实例共享密钥**  
   - 在多节点部署（如多 tokenizer 模式）时，`admin_api_key` 需要在所有节点上保持一致。缺乏统一管理可能导致部分节点拒绝请求。建议在集群部署脚本中同步该参数。  

5. **依赖冲突**  
   - 新增 `auth.py` 中对 `fastapi.responses.ORJSONResponse` 的懒加载没有显式声明依赖，若运行环境缺少 `orjson`，会在首次请求时抛出 ImportError。建议在 `setup.cfg/pyproject.toml` 中添加 `orjson` 为可选运行时依赖。  

---

### 💡 关注建议

| 对象 | 建议 |
|------|------|
| **开发者** | - 在新增或修改 HTTP 路由时，明确使用 `@auth_level` 装饰器；将高危操作默认标记为 `ADMIN_FORCE`。<br>- 在 CI 中加入对未标记路由的检查脚本（例如正则搜索 `app.api_route` 并确保存在 `_auth_level`）。 |
| **运维/用户** | - 部署时若需要细粒度的管理功能，请务必同时配置 `--api-key`（普通请求）和 `--admin-api-key`（管理员请求），并在文档中记录两者的使用场景。<br>- 在集群环境使用统一的密钥管理（如 Kubernetes Secret）同步给所有工作进程。 |
| **安全审计** | - 定期审计 `admin_api_key` 的使用日志，确保只有可信 IP/用户通过 `Authorization: Bearer <admin_key>` 访问管理端点。<br>- 考虑在未来支持 **审计日志**（记录 admin 操作的时间、调用者、操作类型）。 |
| **文档** | - 在 `server_arguments.md` 中补充 “`--api-key` 与 `--admin-api-key` 的优先级及兼容行为” 小节，附上典型配置示例。 |
| **测试** | - 将现有 `test_http_server_auth.py` 纳入持续集成的 **单元测试**，并在新功能引入时扩展覆盖范围（包括 `ADMIN_FORCE` 场景）。 |

---

**结论**：本次提交为 SGLang 引入了更安全、可扩展的管理员鉴权机制，整体架构更清晰、对安全的支撑更强。只要在部署文档中明确配置规则并在代码审查中保持对新路由的安全标记，风险可控，推荐尽快合并并在后续版本中持续完善管理员审计功能。

---

### Fix kernel type annotations for fp8 quant and logging (#16994)
**SHA**: `a4825ed` | 🔗 [查看提交](https://github.com/sgl-project/sglang/commit/a4825ed58815be3f75454609d80dfce9c981bceb)

**🎯 变更类型**：功能增强 / 重构 / 架构变更  
**⚡ 重要程度**：🔴高  

**📋 变更摘要**  
1. 将原有的 `bench_one_batch_server.py` 大幅重构，抽离出 **内部基准测试实现**（`bench_one_batch_server_internal.py`），在主入口只负责参数解析、随机种子设置以及调用内部函数。  
2. 为 FP8 量化相关的 C++ kernel 添加 **就地输出（Tensor!）注解**，并统一使用 `apply_weight_name_mapper` 替代旧的 `apply_sglang_mapper` 接口。  
3. 将日志记录中对 `logging` 的误用更正为项目统一的 `logger`。  

**🎯 影响范围**  
- **Benchmark 体系**：`python/sglang/bench_one_batch_server.py`、`python/sglang/test/bench_one_batch_server_internal.py`  
- **量化配置**：`python/sglang/srt/layers/quantization/base_config.py`、`compressed_tensors/compressed_tensors.py`、`loader.py`  
- **CUDA kernel 接口**：`sgl-kernel/csrc/common_extension.cc`（FP8 相关 kernel）  
- **日志模块**：`sglang/srt/constrained/llguidance_backend.py`  

---

### 🔍 技术洞察  

| 维度 | 影响细节 |
|------|-----------|
| **架构影响** | • 将基准测试逻辑抽离为 **内部库**，降低 `bench_one_batch_server.py` 的耦合度，使其更像 CLI 包装层。<br>• 新增 `run_benchmark_internal`，返回 `(results, server_info)`，便于其它模块（如 CI、实验平台）复用而无需启动子进程。<br>• 量化配置 API 统一为 `apply_weight_name_mapper`，提升可读性并避免在不同层级出现同义词。 |
| **性能影响** | • Tensor!（in‑place）注解让 CUDA kernel 可以 **原地写入** `output_q`、`output_s`，省去一次显存复制，理论上提升 FP8 量化路径 ~5‑10%（取决于 token 数）。<br>• 基准测试内部实现加入 **缓存命中率** 采集（Prometheus `/metrics`），帮助用户评估 KV‑cache 效率，对调参有直接价值。<br>• 重构后去掉了大量重复的 `import`、`seed` 设置，启动和运行时的 Python 解析开销略有下降。 |
| **安全/可靠性** | • 将 `logging.error` 改为项目统一的 `logger.error`，防止在未导入 `logging` 时抛出 `NameError`。<br>• 新增对 Prometheus 抓取的异常捕获，确保即使指标不可达也不会导致 benchmark 失败（返回 `None`）。<br>• 统一的 `apply_weight_name_mapper` 接口如果在某些自定义模型中未实现，仍会抛出 `NotImplementedError`，保持原有行为。 |
| **可维护性** | • `bench_one_batch_server.py` 现在仅负责 **CLI 参数** 与 **种子**，逻辑清晰；内部实现拥有完整的函数/类注释，便于后续单元测试。<br>• 方法名统一后，查找 “mapper” 相关代码的搜索范围缩小，降低误改风险。<br>• 使用 `Tensor!` 注解直接映射到 ATen 的 **mutating** 参数，代码意图明确，后续实现者易于辨认需要在 C++ 端保持 `&` 输出。 |
| **兼容性** | • 对外 API `apply_sglang_mapper` 已删除，若有第三方插件仍调用旧名会失效，需要迁移。<br>• 新的 kernel 定义在 C++ 中已使用 `Tensor!`，若旧的 `torch.ops.sgl_kernel.xxx` 调用仍保持同样签名，则兼容；否则会在运行时触发 **type mismatch**。 |

---

### ⚠️ 潜在风险  

1. **向后兼容性**  
   - 第三方代码仍引用 `apply_sglang_mapper` 会报 AttributeError。需要在发行说明中提醒迁移。  
   - 某些模型的自定义 `QuantConfig` 若未实现 `apply_weight_name_mapper`，在加载时会直接抛出 `NotImplementedError`（与原行为相同），但错误信息中出现新方法名，可能引起混淆。  

2. **CUDA Kernel 参数不匹配**  
   - `Tensor!` 注解要求 **原位写入**；若 C++ 实现仍返回新 Tensor（而非写入传入），会导致 **内存泄漏或未定义行为**。确保 `sgl_per_token_group_quant_8bit*`、`sgl_per_tensor_quant_fp8`、`sgl_per_token_quant_fp8` 实现已改为 `output_q`、`output_s` 的引用写入。  

3. **Prometheus 指标依赖**  
   - 在没有启用 `sglang` metrics 导出的环境下，`get_cache_tokens_from_metrics` 会返回 `None`，导致 `cache_hit_rate` 为 `None`。这已被安全处理，但 CI 报告中会出现 “cache hit rate: n/a”，可能误导。  

4. **日志变量 `logger`**  
   - `llguidance_backend.py` 改为 `logger.error`，确认模块顶部已 `from sglang.srt.utils import logger`（或类似）否则会产生 `NameError`。  
   - 如果项目统一使用 `logging.getLogger(__name__)` 并未导入 `logger`，需同步改动。  

5. **种子初始化**  
   - 旧的 `bench_one_batch_server.py` 在 `__main__` 中设置 `random.seed`、`np.random.seed`，现在已迁移至内部实现。若用户仅调用旧脚本但未进入内部函数（比如仅导入模块），随机性会保持默认，可能导致不可复现的基准结果。  

---

### 💡 关注建议  

| 对象 | 建议 |
|------|------|
| **核心开发者** | - 在下一个 **minor** 发行版中保留兼容层：在 `QuantizationConfig` 中添加 `apply_sglang_mapper = apply_weight_name_mapper` 的别名，降低第三方破坏性升级风险。<br>- 在 C++ 代码中加入单元测试，验证 `Tensor!` 参数确实是原地写入，避免未来误改回复制返回。 |
| **使用者 / CI** | - 若依赖旧的 `apply_sglang_mapper`，请尽快迁移到 `apply_weight_name_mapper`。<br>- 在 CI 环境中确保 **Prometheus metrics** 服务已暴露，否则基准报告中的缓存命中率将缺失。 |
| **文档/社区** | - 更新 **benchmark 文档**，说明新的 `bench_one_batch_server_internal` 可直接被其他脚本调用，提供示例代码。<br>- 在量化章节注明 FP8 kernel 参数已改为就地写入，并解释 `Tensor!` 含义。 |
| **测试** | - 为 `run_benchmark_internal` 添加 **pytest**，覆盖：<br>  * 正常路径（无缓存），<br>  * `cache_hit_rate > 0` 时的 metrics 抓取与计算，<br>  * `profile=True` 的路径。<br>- 添加对 `apply_weight_name_mapper` 与 `apply_sglang_mapper` 别名的兼容性测试。 |
| **安全/运维** | - 确认 `logger` 在 `llguidance_backend.py` 中已正确实例化，防止服务启动时日志记录失败导致隐藏的错误。 |

**总体结论**：此次提交通过**结构化

---

### [model-gateway] HA - Lightweight State Layer + gRPC Mesh (#14108)
**SHA**: `5938c3b` | 🔗 [查看提交](https://github.com/sgl-project/sglang/commit/5938c3b06a6f18341e594718d866571b4fecde43)

## 🎯 变更概览

本次 PR 向 **sgl‑model‑gateway** 注入了一个全新的 *Mesh* 子系统，实现了 **多节点 HA（高可用）** 与 **全局状态同步**。核心功能包括：

| 模块 | 主要职责 |
|------|----------|
| **crdt** | 基于 `crdts` 库实现 `LWWRegister`, `SyncCRDTMap`, `SyncPNCounter`（支持事件最终一致的键值和计数）。 |
| **stores** | 四类状态存储（Membership / App / Worker / Policy）以及 Rate‑Limit Store（使用一致性哈希环决定所有者）。 |
| **gossip / ping_server** | 基于 gRPC 的双向流 `SyncStream`，实现 **增量（Incremental）** 与 **快照（Snapshot）** 同步。 |
| **controller** | 节点发现、心跳、Ping‑Req、故障恢复的周期性任务。 |
| **node_state_machine** | 节点从 `NotReady → Joining → SnapshotPull → Converging → Ready` 的生命周期管理，带有收敛检测。 |
| **partition** | 检测网络分区、判定 quorum，决定是否继续提供服务。 |
| **topology** | 根据集群规模自动在 *Full‑Mesh* 与 *Sparse‑Mesh* 之间切换，并通过 Region/AZ 元数据做细粒度连接控制。 |
| **consistent_hash** | 为 Rate‑Limit 键构造虚拟节点环，实现所有者（owner）选举与迁移。 |
| **rate_limit_window** | 每秒重置一次全局速率限制计数器。 |
| **mesh_sync** | 对外提供 `MeshSyncManager`，负责把本地 `Worker/Policy/Tree` 状态写入 CRDT store、合并远端更新、查询全局速率限制、维护 Rate‑Limit 哈希环等。 |
| **mtls** | 可选的双向 TLS 加密层（证书热加载），为 Gossip 链路提供安全保障。 |
| **metrics** | 丰富的 Prometheus 指标（收敛时延、流量、快照、分区、状态完整性、速率限制漂移等）。 |
| **endpoints** | `/ha/*` 系列 REST 接口（节点状态、worker/policy 列表、全局速率限制、配置管理、优雅关机）。 |
| **service discovery** | 现在可以额外发现 “Router” Pod 并将其写入 Mesh 集群状态（`router_selector` / `router_mesh_port_annotation`）。 |
| **policy_registry / CacheAwarePolicy** | 支持把 *Cache‑Aware* 路由的 radix‑tree 操作同步到 Mesh，节点启动时会从 Mesh 恢复树结构。 |
| **middleware** | 在请求入口做全局速率限制检查，优先使用 Mesh‑wide 统计；若未开启 Mesh 则使用本地限流。 |
| **startup** | `mesh_run!` 宏创建 Mesh Server，`ServerConfig` 新增 `mesh_server_config`，并在 `startup()` 中启动 Mesh、Rate‑Limit 窗口、以及对 `WorkerRegistry`、`PolicyRegistry` 注入 `MeshSyncManager`。 |

> **关键点**：Mesh 完全可选（默认关闭），不影响现有单节点部署；一旦开启，所有核心路径（worker/worker‑registry、policy registration、cache‑aware）将自动走 CRDT 同步路径。

---

## 🔍 多维度技术洞察

### 1️⃣ 架构影响

| 维度 | 正向影响 | 潜在副作用 |
|------|----------|------------|
| **模块化** | 将 HA、状态同步、分区检测抽离为独立子包，职责清晰，便于单独演化。 | 代码体量激增（≈ 3000 行新代码），维护窗口扩大。 |
| **依赖** | 新增 `crdts`、`rand`, `tonic`, `prost-build`, `rustls`, `parking_lot`。 | 依赖图更复杂，编译时间显著增长（尤其是 protobuf 生成）。 |
| **数据流** | 所有 `Worker` / `Policy` 更新走 **MeshSyncManager → CRDT Store** →（gossip）→ 远端。<br>Cache‑Aware 的 radix‑tree 通过 `TreeOperation` 同步。 | 现有路径（直接写 `WorkerRegistry` / `policy_registry`）仍保留，但可能出现 **双写**（本地+Mesh）导致状态不一致的瞬时冲突。 |
| **启动顺序** | `MeshServerBuilder::build_with_stores` 需要在 `WorkerRegistry`、`PolicyRegistry` 之前创建 `StateStores`，否则会出现空的 Rate‑Limit 哈希环。 | 如果用户在 `ServerConfig` 中启用了 Mesh 但忘记配置 `mesh_peer_urls`，集群可能形成 *孤岛*（只有一个节点），导致快速收敛失效。 |
| **可配置性** | 新增 CLI 参数（`--enable-mesh`、`--mesh-peer-urls` 等）以及 `DiscoveryConfig` 新字段（router selector）。 | 配置验证缺失：例如 `router_mesh_port_annotation` 与实际 Pod 注解不匹配会导致 **Router discovery silently fails**。 |

### 2

---

### Code clean up for fp8 quantization (#16982)
**SHA**: `075c5a5` | 🔗 [查看提交](https://github.com/sgl-project/sglang/commit/075c5a5789e77de393dc5490099a8f7d3ccd4d12)

**🎯 变更类型**：功能增强 / 重构 / 性能优化  
**⚡ 重要程度**：🔴高  
**📋 变更摘要**：本次提交对 FP8 量化相关代码进行大规模清理与完善，新增 dtype 排序与拷贝校验、防止下采样；引入块量化形状检查函数以提前捕获不匹配错误；统一日志、异常处理，并在性能计数器中加入预填充重试统计；通过 `lru_cache`、`temp_attr_context` 等工具提升代码可维护性和运行时开销的可控性。  

**🎯 影响范围**：  
- `sglang/srt/layers/parameter.py`（dtype 检查与 copy）  
- `sglang/srt/layers/linear.py`（权重加载路径调整）  
- `sglang/srt/layers/quantization/fp8.py`、`fp8_utils.py`、`fp8_kernel.py`（块量化、FP8 检测、fake op 注册）  
- `sglang/srt/metrics/collector.py`（预填充重试计数）  
- `sglang/bench_one_batch_server.py`、`srt/constrained/xgrammar_backend.py`（日志、异常细化）  
- 公共工具 `sglang/srt/utils/common.py`（warning 缓存、临时属性上下文）  

**🔍 技术洞察**  

- **架构影响**  
  - 引入 `copy_with_check` 与 `_dtype_rank`，在参数加载阶段强制禁止非法下采样，提升模型加载的安全性与一致性，防止意外的精度损失。  
  - `validate_block_quant_shapes` 将块量化维度约束前置至权重创建阶段，避免后续因分区不对齐导致的运行时异常，提升分布式张量并行（TP）与 MoE 场景的鲁棒性。  
  - 通过 `is_checkpoint_fp8_serialized` 属性抽象，统一了 FP8 与 FP16/BF16 checkpoint 的处理路径，降低了后续对新 checkpoint 格式的适配成本。  
  - 新增 `temp_attr_context` 为临时修改对象属性提供安全上下文，便于在单元测试或临时调优时避免副作用。  

- **性能影响**  
  - `cutlass_fp8_supported` 与 `print_warning_once` 均使用 `@lru_cache`，在进程生命周期内仅计算一次，几乎无额外开销。  
  - `copy_with_check` 增加了 dtype 与 shape 检查，仅在模型加载阶段执行，影响可忽略不计。  
  - 对 `apply_fp8_linear` 的分支整理去掉了冗余的 `cutlass_compatible_b` 判断逻辑，略微提升了分支预测和代码可读性。  
  - `strict=False` 参数用于 `zip(..., strict=False)`，兼容 Python 3.11+ 中的严格模式，避免因元素数量不匹配抛异常，提高了容错性。  

- **安全考虑**  
  - 捕获 `UnicodeDecodeError`，防止因非法字符导致的服务崩溃。  
  - 禁止下采样的拷贝检查防止意外的精度下降，避免潜在的数值错误对下游业务产生影响。  
  - 所有新增的异常信息均保持可审计，未引入外部依赖或网络调用，无新增攻击面。  

- **可维护性**  
  - 统一使用 `logger`（替换原 `logging`）并加入 `logger.warning` 的统一入口，日志风格更加一致。  
  - `temp_attr_context` 与 `lru_cache` 的引入为后续功能扩展提供了更好的工具箱。  
  - 代码块量化检查抽离为独立函数，逻辑清晰，可单独单元测试。  

**⚠️ 潜在风险**  

1. **拷贝校验触发异常**  
   - 当外部模型使用不在 `_dtype_rank` 支持范围的 dtype（例如自定义低精度类型）时，会抛 `ValueError`，导致加载失败。需要在 CI 中覆盖所有可能的 dtype 场景或提供回退路径。  

2. **块量化形状检查**  
   - `validate_block_quant_shapes` 在 TP > 1 时强制要求 `input_size_per_partition % block_k == 0` 与 `output_partition_size % block_n == 0`。若已有模型在特定硬件（如 CPU 非 AMX）使用非整数块大小，会在加载阶段报错，需要提前迁移或在配置中显式 `skip_block_quant_check=True`。  

3. **Metric 增加**  
   - 新增 `sglang:num_prefill_retries_total` 计数器若未在监控平台注册，可能导致 Prometheus 报错或仪表板缺失。  

4. **环境变量行为变更**  
   - `SGLANG_DISABLE_SGL_KERNEL_FAKE_REGISTER` 的逻辑被去掉，改为始终注册 fake op。若用户依赖该变量关闭注册，可能出现 NaN。建议在文档中说明已默认开启且仅在异常模型上出现问题时通过 envvar 手动关闭。  

5. **对外部依赖的兼容性**  
   - `cutlass_fp8_supported` 静态缓存后如果运行时切换 GPU（例如在同一进程里切换 CUDA 设备），缓存的结果可能不再适用。当前实现假设进程只能使用单一设备，需在多GPU 多进程场景下确保每个进程单独启动。  

**💡 关注建议**  

- **单元/集成测试**：  
  - 为 `copy_with_check` 添加覆盖所有支持的 dtype 组合，验证下采样路径会抛异常。  
  - 针对 `validate_block_quant_shapes` 编写参数化测试，确保在 `skip_block_quant_check=False` 时能捕获不匹配的模型。  

- **文档与部署**：  
  - 在量化章节更新说明：块量化对分区大小的要求、如何使用 `skip_block_quant_check` 进行兼容。  
  - 补充 `SGLANG_DISABLE_SGL_KERNEL_FAKE_REGISTER` 已被废弃的说明，或保留兼容逻辑（如在代码中仍检查 envvar 并在异常时打印警告）。  

- **监控**：  
  - 确认 Prometheus 抓取规则已包含 `sglang:num_prefill_retries_total`，并在 Grafana 中添加可视化。  

- **异常处理**：  
  - 在 `dispatch_json`、`dispatch_structural_tag` 等函数中改为统一使用 `logger`（已完成），同时保证日志级别与业务需求匹配，避免生产环境过多 error 级日志。  

- **性能基准**：  
  - 通过 `bench_one_batch_server.py` 重新跑基准，确认因 `strict=False` 与 `lru_cache` 带来的微小性能提升（预计 < 1%），并记录在发布说明中。  

通过上述改动，项目在 FP8 量化路径的健壮性、安全性和可维护性都有显著提升，唯一需要关注的是对非标准 dtype 与块大小模型的兼容策略。建议在下一个发布周期完成相应的测试与文档更新后再正式上线。

---

### [diffusion] model: GLM-Image (#16894)
**SHA**: `a0b4ba9` | 🔗 [查看提交](https://github.com/sgl-project/sglang/commit/a0b4ba9032c40d68c78571d8f287d48363ab2016)

**🎯 变更类型**：功能增强 / 架构变更  
**⚡ 重要程度**：🔴高  

**📋 变更摘要**  
1. 为 SGLang 引入全新的 **GLM‑Image** 多模态模型，包括 DiT（Diffusion Transformer）和 VAE 配置、模型实现及运行时 pipeline。  
2. 新增 **vision_language_encoder** 加载器，实现对 `GlmImageForConditionalGeneration` 的动态加载，并在 registry 中注册对应的 pipeline 与采样参数。  
3. 实现完整的前向‑后处理链：AR（自回归）先生成 token → DiT 进行扩散去噪 → VAE 解码成图像，支持文本‑到‑图像、图‑到‑图等场景。  

**🎯 影响范围**  
- `sglang/multimodal_gen/configs/models/*`（DiT、VAE）  
- `sglang/multimodal_gen/configs/pipeline_configs/glm_image.py`  
- `sglang/multimodal_gen/configs/sample/glmimage.py`  
- `sglang/multimodal_gen/registry.py`（pipeline 与 sampler 注册）  
- `sglang/multimodal_gen/runtime/loader/component_loader.py`（新增 VisionLanguageEncoderLoader）  
- `sglang/multimodal_gen/runtime/models/dits/glm_image.py`（核心 DiT 实现）  
- `sglang/multimodal_gen/runtime/models/model_stages/glm_image.py`（前置 token 生成与 KV‑cache 预填充）  
- `sglang/multimodal_gen/runtime/pipelines/glm_image.py`（完整 pipeline 组装）  
- `sglang/multimodal_gen/runtime/pipelines_core/stages/decoding.py`（后处理钩子）  

---

### 🔍 技术洞察  

| 维度 | 影响说明 |
|------|----------|
| **架构影响** | - **新增子系统**：GLM‑Image 作为独立的 pipeline 被加入，包含 **AR 编码器 → DiT → VAE** 三段流水线。<br>- **模块化加载**：`VisionLanguageEncoderLoader` 使得模型可以像其他组件一样通过统一 `ComponentLoader` 加载，保持代码风格一致性。<br>- **KV‑Cache 机制**：为 DiT 引入层级 KV 缓存（`GlmImageKVCache`、`GlmImageLayerKVCache`），支持跨步缓存复用，提升长序列推理效率。<br>- **配置层次**：采用 `DiTConfig`/`VAEConfig` 的继承体系，统一管理 `patch_size`、`num_layers`、`attention_head_dim` 等超参数。 |
| **性能影响** | - **内存占用**：模型规模（30 层、64 heads、hidden ≈ 2560）+ 2×VAE 以及 KV‑cache 将显著增加显存需求，尤其在 BF16/FP16 混合精度下仍需 > 24 GB（取决于 batch = 1）。<br>- **计算路径**：引入 **USPAttention**（自定义高效实现）以及 **ReplicatedLinear**，在 GPU 上可以利用张量并行分块加速，但仍会比原有 Flux/QLora 等模型慢 1.5‑2×。<br>- **流水线并行**：`GlmImageBeforeDenoisingStage` 完成 token 生成后立刻写入 KV‑cache，后续的 DiT 去噪阶段可直接复用，理论上可减少 30% 的 attention 计算。<br>- **后处理**：`post_decoding` 通过 `VaeImageProcessor.postprocess(..., output_type="latent")` 返回 latent，避免在 CPU 上的图像转换，提高整体吞吐。 |
| **安全考虑** | - **`trust_remote_code`**：新增 `VisionLanguageEncoderLoader` 使用 `GlmImageForConditionalGeneration.from_pretrained(..., trust_remote_code=server_args.trust_remote_code)`，如果未显式关闭，将执行模型仓库的自定义代码，存在 **代码注入** 风险。<br>- **输入解析**：`_parse_and_expand_shape_info` 直接从用户 prompt 中正则提取 `<sop>H W<eop>`，若输入被恶意构造（如非常大的数值）可能导致 **OOM** 或 **整数溢出**。<br>- **文件 I/O**：`runtime/entrypoints/openai/image_api.py` 在返回 `b64_json` 前读取本地文件，若 `save_file_path` 被外部可控路径覆盖，可能泄露任意文件。 |
| **可维护性** | - **代码量激增**：单文件 `glm_image.py` 超 800 行，包含自定义层、KV‑cache、前向逻辑，一次性变更导致审查、单元测试难度加大。<br>- **重复实现**：在 `glm_image.py` 与 `model_stages/glm_image.py` 中均实现了 **timestep/condition embedding** 与 **patch up‑sampling**，若后续模型结构微调，需要在两个位置同步。<br>- **类型不一致**：`GlmImagePipelineConfig` 中 `vae_precision` 仍是字符串，未在运行时强制转换为 `torch.dtype`，可能导致 dtype 不匹配。 |

---

### ⚠️ 潜在风险  

1. **显存泄漏 / OOM**  
   - KV‑cache 持久化至所有层（30 × 2 tensors）在高分辨率（> 1024）时易触发显存溢出。  
2. **不安全的远程代码执行**  
   - `trust_remote_code=True` 默认在某些部署脚本中可能被误开启，导致加载恶意 HF 模型。  
3. **输入解析导致异常**  
   - 负数或极大数值的 `<sop>` 可能造成 `torch.nn.functional.interpolate` 生成非法尺寸，从而抛出 RuntimeError。  
4. **复用旧实现导致错误**  
   - `post_decoding` 钩子在 `decoding.py` 直接调用，若后端改为其他图像处理库（如 PIL），可能产生不兼容的张量形状。  
5. **兼容性回退**  
   - 旧版本的 `sglang` 仍会尝试在 `registry` 中注册 `glm-image` 检测器，若未正确安装新依赖（`transformers>=4.40`），会在加载阶段报 `ImportError`。  
6. **调度器时序错误**  
   - `retrieve_timesteps` 根据 `mu` 参数动态缩放 `timesteps`，若 `scheduler` 不支持 `sigmas` 或 `mu`，可能产生 **timesteps 与 sigma 不匹配** 的错误。

---

### 💡 关注建议  

| 目标 | 建议 |
|------|------|
| **安全** | - 将 `trust_remote_code` 在默认配置中强制设为 `False`，并在文档中提醒使用者显式开启。<br>- 对 Prompt 中的 `<sop>` 检查数值范围（如 16 ≤ H,W ≤ 2048）并对异常抛出友好错误。 |
| **资源管理** | - 在 `GlmImageKVCache` 中加入 **显存回收**（`torch.cuda.empty_cache()`）和 **最大缓存大小** 限制。<br>- 提供可选的 **Offload** 开关，利用 `OffloadableDiTMixin` 将中间层移到 CPU。 |
| **测试** | - 新增 **单元测试**：<br>  • `test_glm_image_token_upsampling`（验证 d32→d16 上采样的形状/数值）<br>  • `test_kv_cache_write_read_skip`（覆盖三种模式）<br>  • `test_invalid_shape_prompt_raises`（异常路径）<br>- 添加 **性能基准**：在 1‑GPU、2‑GPU 环境分别测量 **前向时间**、**显存峰值** 与 **KV‑cache 重用效率**。 |
| **兼容性**

---

#### 🟡 中重要度变更 (11)

### [diffusion] fix: revise fa4 backend to support blackwell (#17077)
**SHA**: `969faaa` | 🔗 [查看提交](https://github.com/sgl-project/sglang/commit/969faaa4107369cbbde548c9cfd895695c2e226a)

**🎯 变更类型**：功能增强 / 重构  
**⚡ 重要程度**：🟡 中  

**📋 变更摘要**  
1. 为 FlashAttention‑v4 添加了两套 “fake” 实现：`flash_attn_varlen_func_fake_out`（仅返回 Tensor）和 `flash_attn_varlen_func_fake_out_lse`（返回 Tensor 与 LSE），并统一为自定义 op 提供固定返回签名。  
2. 注册的自定义 op 分别对应这两种返回结构，增加了参数校验（`return_softmax_lse` 必须与 op 类型对应），并在 `flash_attn_varlen_func_op`/`_op_lse` 中显式抛错。  
3. 为 `maybe_contiguous`、`set_fa_ver`、`FlashAttentionMetadataBuilder.__init__` 等函数补全了类型注解。  
4. 在 `FlashAttentionImpl.forward` 中加入对 `fa_ver`（3 与 4） 的分支逻辑，确保在 v4 时调用固定‑schema 的 op，并对返回值进行统一包装。  

**🎯 影响范围**  
- `python/sglang/multimodal_gen/runtime/layers/attention/backends/flash_attn.py`（核心注意力算子）  
- `FlashAttentionImpl` 的前向路径及元数据构造器  
- 依赖 FlashAttention‑v4（如 Blackwell GPU） 的所有多模态生成模型  

**💡 关注建议**  
1. **使用者**：切换至 `fa_ver=4` 前，请确认代码中不再依赖 `flash_attn_varlen_func_op` 返回可变结构；若需要 LSE，请改用 `flash_attn_varlen_func_op_lse`。  
2. **测试**：在 Blackwell 环境下跑全链路推理，重点验证 `return_softmax_lse=True` 的路径是否返回 `(Tensor, Tensor)`，以及 `False` 时仅返回 `Tensor`。  
3. **兼容性**：仍保留 `fa_ver=3` 代码路径，故旧版 GPU（未支持 v4）可正常工作；但建议在迁移后逐步淘汰对 v3 的依赖。  
4. **代码审查**：留意 `maybe_contiguous` 的 `None` 分支与新 `Optional[torch.Tensor]` 注解是否在调用方被正确处理，防止潜在的 `NoneType` 错误。  

整体来看，此次改动为 FlashAttention‑v4 在 Blackwell 上的可用性奠定了稳定接口，提升了类型安全与错误提示，对现有模型迁移影响有限，建议在 CI 中加入 v4‑path 的单元测试。

---

### [Env] centralize pd vars in environ.py (#16264)
**SHA**: `48c2aca` | 🔗 [查看提交](https://github.com/sgl-project/sglang/commit/48c2aca9ba739a0c98b059698237a133f290f07f)

**🎯 变更类型** 功能增强  
**⚡ 重要程度** 🟡 中  
**📋 变更摘要** 将分布式（PD）相关的环境变量统一抽取到 `sglang/srt/environ.py`，通过 `envs` 对象统一读取，删除了零散的 `get_int_env_var`/`os.getenv` 调用，并在 `mooncake` 与 `nixl` 两个 disaggregation 后端的连接实现中改用统一接口。  

**🎯 影响范围** - `python/sglang/srt/disaggregation/mooncake/conn.py`  
- `python/sglang/srt/disaggregation/nixl/conn.py`  
- 新增/修改 `python/sglang/srt/environ.py` 中的数个 `EnvInt/EnvFloat` 常量  

**💡 关注建议**  

1. **默认值与运行时计算**：`SGLANG_DISAGGREGATION_THREAD_POOL_SIZE` 被设为 `EnvInt(None)`，随后在 `conn.py` 中手动 fallback 为 `min(max(4, int(0.5 * cpu_count) // 8), 12)`。请确保 `EnvInt` 能接受 `None`（不抛异常）并在 `get()` 时返回 `None`，否则会导致启动失败。  
2. **兼容性**：项目中仍有 `get_int_env_var` 的直接调用（如其它模块），建议统一迁移或保留兼容包装，以免出现未迁移的遗漏。  
3. **测试覆盖**：新增环境变量的读取路径应增加单元测试，尤其是：① 未设置时使用动态默认；② 设置非法值（非数字）时抛出友好错误；③ 多进程/多线程并发读取是否稳定。  
4. **文档更新**：`README`/`doc` 中的环境变量说明需同步更新，明确这些 PD 参数的作用与推荐值。  
5. **代码可读性**：在 `conn.py` 中对 `transfer_thread_pool_size`、`heartbeat_interval` 等进行 `if is None` 判断后再使用默认值的逻辑可以抽成小工具函数，保持初始化块的简洁。  

总体而言，此次改动提升了配置管理的一致性，风险主要在 `EnvInt(None)` 的空值处理以及未同步迁移的旧代码上。完成上述检查后即可安全合并。

---

### [VLM] Support ViT CUDA Graph for InternVL (#16732)
**SHA**: `feae615` | 🔗 [查看提交](https://github.com/sgl-project/sglang/commit/feae615b1146ec7869c203ddf7e997c3a3a59f6e)

**🎯 变更类型**：功能增强（为 InternVL/VIT 引入 CUDA‑Graph 加速）  
**⚡ 重要程度**：🟡 中  
**📋 变更摘要**：  
1. 新增 `InternViTCudaGraphRunner`，在 GPU 上捕获 Vision 编码器的前向计算图，以实现零拷贝、低延迟的推理路径。  
2. 在 `internvl.py` 与 `qwen2_5_vl.py` 中加入对环境变量 `SGLANG_VIT_ENABLE_CUDA_GRAPH` 的检测，只有在 CUDA 环境下且该开关打开时才会实例化对应的 runner。  
3. 对 Vision 编码层的 `forward` 接口新增 `output_ws` 参数，以便在 CUDA‑Graph 模式下复用工作空间。  
4. 对 `forward` 逻辑做条件分支：在开启 CG 且不需要返回隐藏层时直接走图路径，仅返回 `last_hidden_state`。  

**🎯 影响范围**：  
- `sglang/srt/models/internvl.py`（Vision 编码器与其层）  
- `sglang/srt/models/qwen2_5_vl.py`（VIT 前向路径）  
- 新增模块 `sglang/srt/multimodal/internvl_vit_cuda_graph_runner.py`  
- 相关环境配置 `sglang/srt/environ.py`（新增 env 读取）  

**💡 关注建议**：  
1. **兼容性检查**：确保在非 CUDA 环境或 `SGLANG_VIT_ENABLE_CUDA_GRAPH=False` 时仍能正常回退到原始实现，防止因 `torch.cuda.CUDAGraph` 不可用导致异常。  
2. **内存管理**：CUDA‑Graph 会持有输入、cu‑seq、workspace 等张量的引用，建议在模型释放或进程退出前显式 `del` 这些缓存，防止显存泄漏。  
3. **调试路径**：因为图路径跳过了 `return_dict` 中的 `hidden_states`，若上层代码依赖该字段需额外判断 `enable_cg` 并在需要时关闭 CG。  
4. **性能回归**：在不同 batch‑size / seq‑len 组合下对比带图/不带图的吞吐与延迟，确保在实际推理场景（如多轮对话）真正获益。  
5. **文档与测试**：补充环境变量的说明，新增单元测试覆盖 `create_graph`、`run` 两个路径，防止未来改动破坏图捕获逻辑。  

总体而言，此次改动为 VIT 推理提供了潜在的显著加速手段，但需在部署前完成上述兼容性、资源管理和回归验证。

---

### Feat/support nemotron h mtp (#17013)
**SHA**: `ba625c2` | 🔗 [查看提交](https://github.com/sgl-project/sglang/commit/ba625c2d908ab10427bb9b4d459ad8902d127007)

**🎯 变更类型**：功能增强  
**⚡ 重要程度**：🟡 中  

**📋 变更摘要**  
本次提交为 **Nemotron‑H** 系列模型添加了 *MTP（Multi‑Token Predictor）* 支持。  
1. `model_config.py` 中识别 Draft‑MTP 模型并把架构名改为 `NemotronHForCausalLMMTP`，并设置 `num_nextn_predict_layers=1`。  
2. `model_runner.py` 对 Draft‑MTP 的 `HybridLinearAttnBackend` 做了规避：若配置的 `mtp_hybrid_override_pattern` 中不含 “M”，则返回 `None`，避免在没有 Mamba 层的模型上使用 Mamba‑2 后端。  
3. `nemotron_h.py` 扩展了权重加载逻辑：  
   - 新增 `get_embed_and_head` / `set_embed_and_head` 接口用于在目标模型与 Draft‑MTP 模型之间切换权重。  
   - `load_weights` 增加 `is_mtp` 参数，仅加载带有 `mtp` 前缀的权重或过滤掉不相关的权重。  
4. 新增 `nemotron_h_mtp.py`，实现 `NemotronHMTPAttentionDecoderLayer`、`NemotronHMTPMoEDecoderLayer`、`NemotronHMultiTokenPredictor` 以及包装类 `NemotronHForCausalLMMTP`，完成 **MTP 前向、层融合、归一化** 等核心功能。  

**🎯 影响范围**  
- **模型配置**：`sglang/srt/configs/model_config.py`  
- **模型执行器**：`sglang/srt/model_executor/model_runner.py`  
- **原 Nemotron‑H 实现**：`sglang/srt/models/nemotron_h.py`（权重加载、embed/head 处理）  
- **全新 MTP 实现**：`sglang/srt/models/nemotron_h_mtp.py`  
- **可能的上层调用**：服务器/推理入口在加载 Draft‑MTP 权重时会触发新路径。  

**💡 关注建议**  

1. **配置完整性**：确保 `NemotronHConfig` 在使用 MTP 时提供 `mtp_hybrid_override_pattern`、`num_nextn_predict_layers` 等字段；缺失会导致 `AttributeError`。  
2. **权重映射**：`load_weights(..., is_mtp=True)` 只保留 `mtp.` 前缀的参数，若原模型权重命名规则改变（如迁移到新版本），需要同步更新映射逻辑。  
3. **混合后端兼容**：`hybrid_gdn_config` 中的 `pattern` 检查仅针对 “M” 字符，若未来出现其他不含 Mamba 层的字符，需要相应扩展。  
4. **内存与同步**：`set_embed_and_head` 在切换权重后调用 `torch.cuda.empty_cache()` 与 `torch.cuda.synchronize()`，在多 GPU/PP 环境下请确认不会引入额外的同步瓶颈。  
5. **单层限制**：当前实现仅支持 `num_nextn_predict_layers == 1`（断言），若后续需要多层 MTP，需要重构 `NemotronHMultiTokenPredictor` 的层构造逻辑。  
6. **测试覆盖**：新增单元测试应覆盖：  
   - `ModelConfig` 对 Draft‑MTP 的自动识别。  
   - `ModelRunner` 在 MTP 场景下返回 `None` 的 hybrid 配置。  
   - 权重加载的过滤与重命名路径。  
   - 前向传播的完整路径（包括 start‑projection、end‑norm）。  

总体来看，改动为 Nemotron‑H 引入了完整的 MTP 流水线，影响点集中在配置识别、权重加载以及混合后端选择。若在部署前做好配置检查与权重映射校验，兼容性风险可控制在可接受范围。

---

### test: split Qwen3 Next tests and disable PCG tests due to intermittent failures (#16989)
**SHA**: `c5e363e` | 🔗 [查看提交](https://github.com/sgl-project/sglang/commit/c5e363e8e0ea7c1fe9873b951f556979fb949196)

**🎯 变更类型**：功能增强 / 其他（测试结构重构）  
**⚡ 重要程度**：🟡 中  

**📋 变更摘要**  
1. 将原 `test_qwen3_next_models.py` 中的 MTP、Top‑k、Piecewise‑CUDA‑Graph 三套测试拆分为独立文件 `test_qwen3_next_models_mtp.py`、`test_qwen3_next_models_pcg.py`。  
2. 为 MTP 测试单独维护了更宽松的 KL‑div 阈值 `ACC_THRESHOLDS_MTP`。  
3. 通过 `@unittest.skip` 暂停了 Piecewise‑CUDA‑Graph（PCG）测试，并在 `run_suite.py` 中标记为“间歇性失败”。  
4. 调整了原 `test_qwen3_next_models.py` 在 CI 中的超时配额（350 → 650），并在套件列表中新增 `test_qwen3_next_models_mtp.py`。  

**🎯 影响范围**  
- **测试层**：`sglang/srt/models` 目录下的 Qwen3‑Next 相关单元测试全部迁移或禁用。  
- **CI 流程**：`per-commit-4-gpu` 套件执行时会额外启动两套服务器（MTP、Top‑k），导致 GPU 资源占用和运行时长略增。  
- **代码库**：仅涉及测试文件、测试套件配置及阈值常量，无业务代码改动。  

**💡 关注建议**  
1. **监控 flaky**：PCG 测试已被 skip，后续应尽快定位 5‑10% 失败根因，稳定后恢复入套。  
2. **阈值维护**：`ACC_THRESHOLDS_MTP` 的 KL‑div 提高到 0.008，建议在新模型或算法调优后定期回归，防止阈值过宽掩盖性能回退。  
3. **资源调度**：CI 机器使用 4‑GPU 并行启动三套服务器，检查是否会出现端口冲突或显存不足的情况，必要时在 `run_suite.py` 中加入资源检查或动态端口分配。  
4. **文档同步**：更新 README / CONTRIBUTING 中的测试说明，明确 MTP 与 PCG 测试的启动参数及已知 flaky 状态，方便新贡献者快速定位。  

总体来看，此次改动仅影响测试层，提升了测试组织的可维护性，并通过显式 skip 防止不稳定的 PCG 测试阻断 CI。后续重点在于解决 PCG flaky 并确保新增 MTP 测试的资源使用在 CI 环境可接受。

---

### [CI] Fix max_parallel for scheduled runs (#17046)
**SHA**: `9479eca` | 🔗 [查看提交](https://github.com/sgl-project/sglang/commit/9479eca75dc971ae87b76b1b97703e6457f40d38)

**🔧 变更类型**：CI 配置调整（功能增强 / 轻微 Bug 修复）  
**⚡ 重要程度**：🟡 中  
**📋 变更摘要**：  
1. 将 `max_parallel` 的取值统一为 14，针对 **schedule** 触发的流水线以及标记为 **high priority** 的 PR；其余情况维持 3。  
2. 将 `stage-b-test-4-gpu-b200` 作业从文件末尾迁移到更靠前的位置，保留原有依赖关系，同时删除了原来的重复定义。  

**🎯 影响范围**  
- `.github/workflows/pr-test.yml`（CI 工作流）  
- 受 `max_parallel` 影响的所有矩阵并行作业（尤其是 GPU 大规模测试）  
- 依赖 `stage-b-test-4-gpu-b200` 的后续作业（如 `unit-test-backend-4-gpu`）  

**💡 关注建议**  

1. **并行度上限**：把 `max_parallel` 提到 14 已超过原来的 15（仅对 high‑priority PR），但 runner 的并发容量可能受限。建议在自托管 runner（b200）或 GitHub 托管的 GPU runner 上确认能够同时运行 14 条作业，否则可能出现排队延迟或资源争抢。  
2. **标签检测语法**：`contains(github.event.pull_request.labels.*.name, 'high priority')` 在 GitHub Actions 中仍然有效，但如果后续改成 `pull_request_target` 事件，需要同步更新。可在本地或 sandbox 中跑一次带标签的 PR，确认判断分支走向正确。  
3. **作业顺序**：迁移 `stage-b-test-4-gpu-b200` 后，其 `needs` 列表保持不变（仍依赖 `check-changes、call-gate、stage-a-test-1、sgl-kernel-build-wheels`），并且后续作业 `unit-test-backend-4-gpu` 仍然声明依赖它。请检查是否有其他作业在原位置使用了 `if: always()` 或类似条件导致逻辑变更。  
4. **Artifact 下载路径**：保持 `pattern: wheel-python3.10-cuda12.9` 不变，但迁移后若有缓存层级或 runner 标签变化，需确认对应的 runner（`b200_runner`）上已装载相同的 CUDA 环境。  
5. **回滚与监控**：建议在合并后开启一次手动调度（schedule）和一次带 “high priority” 标签的 PR，观察并行度是否达到 14、作业是否按预期完成；若出现超时或资源耗尽，可快速回滚 `max_parallel` 为 12 或 10。  

总体来看，此次改动提升了定时任务和高优先级 PR 的测试吞吐，但务必确认并行度上限与 runner 实际能力匹配，防止 CI 反而变慢或出现资源竞争。

---

### fix grammar timeout sync across tp ranks. (#16898)
**SHA**: `e2c8a50` | 🔗 [查看提交](https://github.com/sgl-project/sglang/commit/e2c8a50b383a00f6b5d655e2dde635240f6cc643)

**🎯 变更类型**：功能增强 / Bug 修复  
**⚡ 重要程度**：🟡 中  
**📋 变更摘要**：  
1. 为约束解码的 Grammar 预处理加入跨 Tensor‑Parallel (TP) / Data‑Parallel (DP) 组的同步机制，使用 `dp_tp_group` 确保所有 TP‑rank 上的 ready 请求数保持一致。  
2. 引入 `SGLANG_GRAMMAR_SIMULATE_TIMEOUT` 与 `SGLANG_GRAMMAR_POLL_INTERVAL` 两个 env 变量，以支持超时模拟和可调轮询间隔。  
3. 重构 `get_ready_grammar_requests` 的超时、就绪与缓存写入逻辑，新增 `finalize_grammar` 辅助函数。  
4. 新增分布式 DP‑Attention 大模型测试，验证在模拟超时场景下的功能完整性。

**🎯 影响范围**：  
- `python/sglang/srt/constrained/grammar_manager.py`（核心同步与超时逻辑）  
- `python/sglang/srt/environ.py`（新增 env）  
- 新增的分布式测试脚本 `test/registered/distributed/test_dp_attention_large.py`（CI 运行时会调用）。

**💡 关注建议**  

1. **同步语义**：当前通过 `torch.distributed.all_reduce` 的 MIN/负数技巧实现 “最小 ready / 最大 timeout” 的广播，代码可读性较差。建议加上详细注释或抽象为 `sync_ready_timeout` 小函数，防止误用。  
2. **超时模拟**：`SGLANG_GRAMMAR_SIMULATE_TIMEOUT` 默认 `-1`，在非 entry rank 时仍会执行 `random.random() < sim_timeout_prob`，需确认 `-1` 不会触发概率计算异常（当前实现会把 `-1` 视为大于 0，导致不必要的模拟）。可以改为 `if sim_timeout_prob > 0`。  
3. **性能影响**：引入 `GRAMMAR_POLL_INTERVAL`（默认 0.03 s）后，每次轮询均会阻塞该时长，若 TP/DP 规模增大可能累计增加延迟。建议在文档中说明调参指南，并在高并发场景下评估实际影响。  
4. **错误路径**：在非模拟模式下，超时请求会被标记为 `INVALID_GRAMMAR_OBJ` 并 `set_finish_with_abort`，但在模拟模式下仍可能留下未 cancel 的 `Future`。确认 `finalize_grammar` 对已取消的 future 能安全返回。  
5. **兼容性**：`self.grammar_sync_group`、`self.grammar_sync_size` 等属性在 `scheduler` 未开启 DP‑Attention 时仍会被创建，需确保 `scheduler.dp_tp_group` 在所有启动路径下均已初始化，防止属性访问错误。  
6. **测试覆盖**：新增的分布式测试依赖 `envs.SGLANG_GRAMMAR_SIMULATE_TIMEOUT.override(0.5)`，请在 CI 环境验证该覆盖是否在所有平台（GPU、AMD）均生效，避免因 env 覆盖失效导致测试卡死。  

总体来看，改动解决了跨 TP‑rank 语法预处理的同步不一致问题，并提供了超时模拟手段，提升了约束解码在大规模 DP‑Attention 场景下的鲁棒性。只要注意上述细节并补充文档说明，即可安全合并。

---

### [AMD] enable CUDA graph for NSA backend and fix NSA FP8 fused RMSNorm group quant (#16841)
**SHA**: `afe285f` | 🔗 [查看提交](https://github.com/sgl-project/sglang/commit/afe285f7bd9a2f377b5fc50ed713f7cf9889edf8)

**🔧 变更类型**：功能增强（AMD/ROCm 支持）+ Bug 修复（NSA FP8 fused RMSNorm）  

**📝 变更摘要**  
- 为 NSA 后端新增 `is_hip` 判定，实现 ROCm 上的 CUDA‑Graph、页表尺寸从 64→1、以及相应的深度 GEMM 调用路径。  
- 拓展 `BaseIndexerMetadata`，分别返回 64‑size 与 1‑size 的 page‑table。  
- 在 `deepseek_v2` 中加入对 FP8‑RMSNorm+量化的兼容逻辑，提供未量化的 `q_lora`。  
- 统一全局 `_is_cuda/_is_hip/_is_npu` 标志，避免多次 `is_*()` 调用。  
- 修正 `tilelang_kernel` 中累加清零逻辑、更新 `memory_pool` 对 page‑size 的断言。  

**🎯 影响范围**  
- `sglang/srt/layers/attention/nsa/*`（索引器、页表、kernel）  
- `sglang/srt/mem_cache/memory_pool.py`（页大小、HIP 标志）  
- `sglang/srt/models/deepseek_v2.py`（FP8 fused RMSNorm）  
- `sglang/srt/server_args.py`（页面大小默认值）  

**💡 关注建议**  
1. **Hip 路径验证**：CI 中加入 ROCm（gfx9x）节点，重点跑 `test_nsa_*` 与 `test_deepseek_fp8`，确保 `page_size==1` 的分配、调度元数据、deep_gemm 替代实现均能通过。  
2. **统一标志使用**：建议把 `_is_hip` 等变量集中在 `sglang/srt/utils/__init__.py`，并在其他文件 `from ... import _is_hip`，避免出现 `is_hip()` 与 `_is_hip` 混用导致逻辑不一致。  
3. **fallback 检查**：`aiter.ops.triton.*` 只在 HIP 下导入，若库缺失会抛异常，建议提供明确的错误提示或回退到 CUDA 实现（即使性能降低）。  
4. **页面表接口**：新增 `get_page_table_1` 已在 `nsa_backend` 暴露，但调用方（如 `forward_indexer`）仍假设 64‑size；请审查所有 `metadata.get_page_table_*` 使用场景，防止遗漏。  
5. **文档与日志**：在 README/CHANGELOG 中补充 “ROCm (HIP) 支持，页大小 1，适用于 gfx95”。同时在 `server_args` 与关键路径加入 `logger.info`，便于用户确认当前执行路径。  

总体来说，此次 PR 为 AMD GPU 引入了完整的 NSA 流程，改动较大但结构清晰。重点在于 CI 覆盖和统一标志管理，确保两套平台的行为保持一致后即可合入。

---

### [model-gateway] add --disable-health-check option to skip worker health probes (#17002)
**SHA**: `cf25852` | 🔗 [查看提交](https://github.com/sgl-project/sglang/commit/cf25852a1d9025d8550d704dd6fa17901dba85d3)

**🎯 变更类型**：功能增强  
**⚡ 重要程度**：🟡 中  
**📋 变更摘要**：在模型网关（sgl‑model‑gateway）新增 `--disable-health-check` CLI 选项，默认关闭全局和单任务的健康检查；相应地在配置结构体、Worker 构建、健康检查调度、注册中心过滤、API 返回体等多处加入 `disable_health_check` 字段，并补充了对应的单元/端到端测试与文档说明。  

**🎯 影响范围**  
- `src/config/types.rs`、`src/core/worker.rs`、`src/core/worker_builder.rs`、`src/core/steps/*`：健康检查配置结构体及默认值、构造函数、创建 worker 时的健康标记逻辑。  
- `src/server.rs`、`src/worker_registry.rs`、`src/service_discovery.rs`：启动全局健康检查任务的条件分支。  
- Python 绑定 (`bindings/python/src`)：CLI 参数、`RouterArgs`、文档同步。  
- 多项单元测试、e2e 测试、路由策略测试以及 README。  

**💡 关注建议**  
1. **兼容性**：默认 `disable_health_check = false`，确保已有部署行为不变；若已有外部系统依赖健康状态，启用该选项后可能导致误判，需在发布说明中明确提示。  
2. **监控/治理**：禁用健康检查后，Circuit Breaker、负载均衡仍依据 worker 的“healthy”标记（默认直接标记为 healthy），请确认监控面板和告警策略已考虑此情况。  
3. **配置合并**：`WorkerConfigRequest` 现在支持 `disable_health_check`，在 API `/workers` 的创建/更新请求时应进行字段校验，防止与全局开关冲突。  
4. **代码审查**：检查 `worker.set_healthy(true/false)` 的分支是否覆盖所有 builder（DP‑aware、wildcard、local）路径，防止遗漏导致状态不一致。  
5. **文档与示例**：README 已更新，但建议在官方教程和 CI 检查中加入 “禁用健康检查” 场景的使用示例，帮助用户快速验证。  

总体而言，此次改动实现了灵活的健康检查开关，业务能在启动阶段快速跳过探活，提升部署速度；但需在监控、故障恢复以及 API 使用层面做好说明与测试，以防因关闭探活导致不可见的异常。

---

### Add 5090 dry run stage to PR test workflow (#17022)
**SHA**: `b880607` | 🔗 [查看提交](https://github.com/sgl-project/sglang/commit/b880607108691db83fd215a315e5e4afc63b0fed)

**变更概览**  
1. 在 GitHub Actions `pr-test.yml` 新增 **stage‑b‑test‑small‑1‑gpu‑5090**，仅在 schedule 触发或通过 `/rerun-stage` 手动指定时运行，使用 `1‑gpu‑5090` Runner，矩阵并行 8 份。  
2. `scripts/ci/ci_install_dependency.sh` 加入 **Blackwell（5090）机器**的条件判断，避免在已装好对应版本时强制 `--force-reinstall`（sgl‑kernel、nvshmem、cudnn），防止并发写入导致的 race。  
3. `slash_command_handler.py` 支持新 stage 的 `/rerun-stage`。  
4. 大量测试文件通过 `register_cuda_ci(..., suite="stage-b-test-small-1-gpu-5090")` 注册，同步加入 `run_suite.py` 的 suite 列表。  

**影响范围**  
- CI 流水线（pr‑test、schedule）以及对应的 Runner（需要存在 `1‑gpu‑5090` 标签）。  
- 依赖安装脚本在 Blackwell 环境下的行为；若 `IS_BLACKWELL` 未传递会退回到原有强制 reinstall。  
- 所有原先属于 `stage-b-test-small-1-gpu` 的单元测试现在会在 5090 上多跑一遍，CI 时长和资源消耗显著提升。  

**风险与建议**  
- **Runner 可用性**：确认项目已配置 `self‑hosted` 或云端 `1‑gpu‑5090` 机器，且标签与 `runs-on` 匹配。  
- **continue‑on‑error** 为 `true`，若 5090 环境出现隐藏错误，PR 检查仍会通过。建议在关键测试（如性能基准）改为 `false` 或在后续阶段显式报错。  
- **变量传播**：`IS_BLACKWELL` 只在工作流里定义，手动触发时可能缺失。可在 `ci_install_dependency.sh` 加入默认值 `IS_BLACKWELL=${IS_BLACKWELL:-0}`，防止误判。  
- **重复安装逻辑**：使用 `pip show` 判断版本已经相当可靠，但若多 Python 环境共存（virtualenv/conda）可能失效，考虑显式指定 `python -m pip`.  
- **CI 时长**：新增 8× 并行矩阵会把整个 suite 运行时间拉长 ~20‑30%。若资源紧张，可将 `max-parallel` 调低或仅在 `schedule`（而非 PR）运行。  
- **文档更新**：在贡献指南或 CI 文档中说明新增 “5090 dry‑run” 阶段的目的、触发方式以及对应的环境变量。  

总体而言，此次改动为 5090 GPU 的兼容性预热提供了完整的测试覆盖，同时通过条件 reinstall 降低了机器竞争风险。但要确保 Runner 配置、变量传递以及错误可见性，以免引入潜在的 CI 脱敏或资源浪费。

---

### [logprob] Fix logprob + streaming for long concurrent decode by caching already processed logprob  (#17005)
**SHA**: `339915c` | 🔗 [查看提交](https://github.com/sgl-project/sglang/commit/339915ce2b8c9c6cb73a4a52d3d084d8f66c967f)

**🎯 变更类型**：功能增强 / Bug 修复（针对长序列并发解码的 logprob/streaming 进行增量缓存）  
**⚡ 重要程度**：🟡 中

**📋 变更摘要**  
1. 为 `ReqState` 新增了 6 个列表（`input_token_logprobs`、`output_token_logprobs`、`input_top_logprobs`、`output_top_logprobs`、`input_token_ids_logprobs`、`output_token_ids_logprobs`），用于保存已经完成的 detokenize 结果。  
2. `add_logprob_to_meta_info` 逻辑改为**增量**处理：仅对新产生的 logprob 数据进行 `detokenize_*`，随后把结果追加到状态对象，再把缓存好的列表直接写入 `meta_info`。  
3. 相对应的分支（普通 logprob、top‑logprobs、token‑ids‑logprob）均加入了长度比较与切片，以防重复计算。

**🎯 影响范围**  
- `python/sglang/srt/managers/tokenizer_manager.py`（核心）  
- 与之交互的请求调度层 (`ReqState` 的创建/复用)  
- 可能波及到 `streaming`、`logprob` 相关的 API 响应格式与单元测试  

**💡 关注建议**  

| 关注点 | 建议 |
|--------|------|
| **状态清理** | 确认每次请求结束后 `ReqState` 中新加的列表会被完整重置，否则长时间运行会导致内存泄漏。 |
| **线程安全** | `ReqState` 在并发解码场景下会被多个协程共享，列表的 `extend` 操作需确保不会出现竞争（当前使用的是单请求对象，若改为共享对象请加锁或转为不可变结构）。 |
| **空切片安全** | `len(state.xxx) == 0` 时的切片仍会返回空列表，建议在 `detokenize_*` 前显式检查避免不必要的函数调用。 |
| **类型导入** | 新增字段使用 `Any`，请在文件头部加入 `from typing import Any`，防止运行时 `NameError`。 |
| **性能基准** | 添加长序列（>10k token）并发解码的基准测试，验证增量缓存对 latency 与吞吐的实际提升。 |
| **兼容性** | 旧版 `meta_info` 结构未变，仍保持 `input_token_logprobs`、`output_token_logprobs` 等键，只是值来源改为缓存，建议在文档中注明 “日志概率在流式输出中会被增量缓存”。 |

总体而言，此次改动有效解决了在长序列并发解码时重复 detokenize 导致的性能回退问题。只要确保状态清理和并发安全，改动对现有功能的兼容性应保持良好。后续可通过更完整的压力测试验证收益并监控内存占用。

---

#### 🟢 低重要度变更 (7)

### Fix issues/16714: Revert comment out of `tl.debug_barrier()` in causal_conv1d_triton (#16899)
**SHA**: `e75299a` | 🔗 [查看提交](https://github.com/sgl-project/sglang/commit/e75299a111fb879579b727bfb97c50a3dec7a935)

**🎯 变更类型**：代码重构  
**⚡ 重要程度**：🟢低  
**📋 摘要**：恢复在 `causal_conv1d_triton.py` 中因 Triton 编译器 bug 而被注释的 `tl.debug_barrier()`，并取消对应测试的 skip，确保卷积实现正确运行。

---

### [NemotronH] Use ReplicatedLinear for fc1_latent_proj (#16569)
**SHA**: `72bacc8` | 🔗 [查看提交](https://github.com/sgl-project/sglang/commit/72bacc88c8a08c4a028ef452add7ccf550ae052e)

**🎯 变更类型**：代码重构  
**⚡ 重要程度**：🟢 低  
**📋 摘要**：在 `nemotron_h.py` 中将 `fc1_latent_proj` 的实现从 `ColumnParallelLinear` 替换为 `ReplicatedLinear`，并移除 `gather_output` 参数，以保持与 `fc2_latent_proj` 的一致性。

---

### [diffusion] fix: fix --warmup-resolutions' conflict with CacheDiT (#16962)
**SHA**: `030496e` | 🔗 [查看提交](https://github.com/sgl-project/sglang/commit/030496eb06472f76fcb11de53d93f10cefb4604f)

**🎯 变更类型**：代码重构  
**⚡ 重要程度**：🟢低  
**📋 摘要**：修复 `--warmup-resolutions` 与 CacheDiT 的冲突。`scheduler.py` 中更正暖启动计数逻辑，避免误报；`denoising.py` 在开启 CacheDiT 前判断批次是否为暖启动请求，防止在暖启动阶段使用 CacheDiT。

---

### chore: bump sgl-kernel version to 0.3.21 (#16888)
**SHA**: `c86ca12` | 🔗 [查看提交](https://github.com/sgl-project/sglang/commit/c86ca12875bbdea8f39267f02a0d55c68ea99d8e)

**🎯 变更类型**：配置调整  
**⚡ 重要程度**：🟢低  
**📋 摘要**：将 sgl-kernel 的版本号从 0.3.20 更新至 0.3.21，统一修改了三个 pyproject 配置文件和 Python 版本常量。

---

### [diffusion] chore: avoid raising error when output resolution is not optimal (#17030)
**SHA**: `a5348ea` | 🔗 [查看提交](https://github.com/sgl-project/sglang/commit/a5348eac4c720ae3af852a20d6bcaf7e0fb5e81e)

**🎯 变更类型**：代码重构  
**⚡ 重要程度**：🟢低  
**📋 摘要**：将不支持的输出分辨率从抛异常改为记录警告并继续执行，提示可能导致画质下降。

---

### [diffusion] chore: refactor warmup logic (#17027)
**SHA**: `9524040` | 🔗 [查看提交](https://github.com/sgl-project/sglang/commit/95240402206e2228435bb540c069f709805cc5ac)

**🎯 变更类型**：代码重构  
**⚡ 重要程度**：🟢低  
**📋 摘要**：将请求的 warmup 初始化从 `__post_init__` 重构为 `validate`，并新增 `set_as_warmup` 方法统一处理 warmup 标记与参数修改；相应更新调度器插入 warmup 请求的调用方式。

---

### Update deepseekV32 Cp doc (#17054)
**SHA**: `2122fea` | 🔗 [查看提交](https://github.com/sgl-project/sglang/commit/2122fea3c4088440ee1b5398e70970a17ceadf57)

**🎯 变更类型**：文档更新  
**⚡ 重要程度**：🟢低  
**📋 摘要**：将 DeepSeek V32 使用说明中的 `--nsa-prefill-cp-mode` 默认值从 `continuous-split` 修改为 `round-robin-split`，同步更新两处示例代码。

---

