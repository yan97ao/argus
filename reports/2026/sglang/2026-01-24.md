# æ¯æ—¥æ›´æ–°æŠ¥å‘Šï¼ˆ2026-01-24ï¼‰

## sgl-project/sglang

| æäº¤æ—¶é—´ | ä½œè€… | æäº¤ä¿¡æ¯ |
|----------|------|----------|
| 2026-01-24 22:59:55 | Trevor Morris | [NVIDIA] Add flashinfer all-to-all MOE dispatcher (#14668) |
| 2026-01-24 22:55:49 | TMC | [NPU] torch_npu profiler tensorboard path type fix (#17545) |
| 2026-01-24 21:27:13 | Yuan Luo | [Kimi-Linear] Refactor Kimi-Linear to support RadixLinearAttention (#17506) |
| 2026-01-24 19:16:22 | yunkchen | [Bugfix] fix TypeError when log-requests-level >=2 in prefill node warmup (#17129) |
| 2026-01-24 18:52:47 | Lianmin Zheng | [Auto Sync] Update test_deterministic.py (20260124) (#17665) |
| 2026-01-24 15:33:16 | Glen Liu | add documentation example for LoRA overlap loading and cleanup unused function (#17464) |
| 2026-01-24 15:25:03 | Xiaoyu Zhang | Move fa4 from sgl-kernel to jit kernel (#17353) |
| 2026-01-24 14:27:08 | Xiaoyu Zhang | [Diffusion] Add diffusion time embedding to jit kernel (#17658) |
| 2026-01-24 13:37:44 | Ke Bao | Use attn tp group in embedding for more models (#17570) |
| 2026-01-24 13:35:14 | strgrb | Fix: mistake sigmoid in kda (#17508) |
| 2026-01-24 12:57:58 | Qi Yuhang | [JIT Kernel]Add Some CUDA Runtime API Wrapper for JIT Kernel Header (#17588) |
| 2026-01-24 12:51:52 | Douglas Yang | fix: nightly wheel naming for non-post versions (#17538) |
| 2026-01-24 12:51:37 | GMI Xiao Jin | [diffusion] model: LTX-2 Support (2/2) (#17496) |
| 2026-01-24 11:59:48 | GMI Xiao Jin | [diffusion] model: LTX-2 (1/2) (#17495) |
| 2026-01-24 11:29:52 | Ananya | Refactor: Extract DeepSeek common utilities into shared module (#16969) |
| 2026-01-24 11:27:03 | Baizhou Zhang | [Docker] Install cudnn==9.16 for cuda 13 image to avoid check error (#17668) |
| 2026-01-24 09:57:41 | Lianmin Zheng | [Auto Sync] Update logits_processor.py, test_logprobs.py (20260124) (#17664) |
| 2026-01-24 09:56:09 | R0CKSTAR | Add yeahdongcn to CI permissions (#17667) |
| 2026-01-24 08:27:38 | McZyWu | [NPU] solve accuracy problem for stablelm-2-1-6b for npu (#17470) |
| 2026-01-24 08:25:12 | McZyWu | [NPU]support model MiniCPM3-4B for npu (#16866) |
| 2026-01-24 08:04:28 | Douglas Yang | feature: adding openai compatible API request to bench_serving (#17219) |
| 2026-01-24 07:43:37 | Nan Jiang | fix post_residual_addition more generally (#17286) |
| 2026-01-24 06:41:47 | R0CKSTAR | [MUSA][2/N] sgl-kernel build (#17053) |
| 2026-01-24 06:41:17 | R0CKSTAR | [MUSA][1/N] sglang.check_env (#16959) |
| 2026-01-24 04:12:36 | Mansoor | Add return routed experts to the completions and chat/completions endpoints (#17434) |
| 2026-01-24 01:52:39 | Tiwei Bie | [DLLM] Remove cuda graph batch size limitation (#17458) |
| 2026-01-24 01:16:55 | Jerry Ji | [Refactor] Algebraic data type for nextn config + some basic refactors (#17347) |

### ğŸ“Š ç»Ÿè®¡æ‘˜è¦
> æœ¬æ—¥å…± 27 ä¸ªæäº¤ | ğŸ”´é«˜ 4 | ğŸŸ¡ä¸­ 14 | ğŸŸ¢ä½ 9
## ğŸ“‹ ç›®å½•

- [sgl-project/sglang](#sgl-project-sglang)
  - [ğŸ“Š ç»Ÿè®¡æ‘˜è¦](#-ç»Ÿè®¡æ‘˜è¦)
  - [ğŸ”´ é«˜é‡è¦åº¦å˜æ›´ (4)](#-ğŸ”´-é«˜é‡è¦åº¦å˜æ›´-4)
    - [[NVIDIA] Add flashinfer all-to-all MOE dispatcher (#14668)](#2c2c4e4)
    - [Move fa4 from sgl-kernel to jit kernel (#17353)](#3992a02)
    - [[diffusion] model: LTX-2 Support (2/2) (#17496)](#d0919be)
    - [[diffusion] model: LTX-2 (1/2) (#17495)](#797a981)
  - [ğŸŸ¡ ä¸­é‡è¦åº¦å˜æ›´ (14)](#-ğŸŸ¡-ä¸­é‡è¦åº¦å˜æ›´-14)
    - [[Kimi-Linear] Refactor Kimi-Linear to support RadixLinear...](#0c8165f)
    - [add documentation example for LoRA overlap loading and cl...](#a6280b2)
    - [[Diffusion] Add diffusion time embedding to jit kernel (#...](#7a4bb0d)
    - [Use attn tp group in embedding for more models (#17570)](#fb683be)
    - [Fix: mistake sigmoid in kda (#17508)](#176da1b)
    - [fix: nightly wheel naming for non-post versions (#17538)](#58799d9)
    - [Refactor: Extract DeepSeek common utilities into shared m...](#894928a)
    - [[NPU] solve accuracy problem for stablelm-2-1-6b for npu ...](#b4a611f)
    - [[NPU]support model MiniCPM3-4B for npu (#16866)](#8a5ed24)
    - [feature: adding openai compatible API request to bench_se...](#4c7136b)
    - [[MUSA][2/N] sgl-kernel build (#17053)](#628ab5d)
    - [[MUSA][1/N] sglang.check_env (#16959)](#a77729a)
    - [Add return routed experts to the completions and chat/com...](#bdaa3de)
    - [[Refactor] Algebraic data type for nextn config + some ba...](#010c17a)
  - [ğŸŸ¢ ä½é‡è¦åº¦å˜æ›´ (9)](#-ğŸŸ¢-ä½é‡è¦åº¦å˜æ›´-9)
    - [[NPU] torch_npu profiler tensorboard path type fix (#17545)](#458a43d)
    - [[Bugfix] fix TypeError when log-requests-level >=2 in pre...](#bf19d20)
    - [[Auto Sync] Update test_deterministic.py (20260124) (#17665)](#0834f9a)
    - [[JIT Kernel]Add Some CUDA Runtime API Wrapper for JIT Ker...](#4c512a7)
    - [[Docker] Install cudnn==9.16 for cuda 13 image to avoid c...](#0dfe46d)
    - [[Auto Sync] Update logits_processor.py, test_logprobs.py ...](#bc6f0b5)
    - [Add yeahdongcn to CI permissions (#17667)](#e1833c4)
    - [fix post_residual_addition more generally (#17286)](#ad05782)
    - [[DLLM] Remove cuda graph batch size limitation (#17458)](#5438cd2)
#### ğŸ”´ é«˜é‡è¦åº¦å˜æ›´ (4)

### [NVIDIA] Add flashinfer all-to-all MOE dispatcher (#14668)
**SHA**: `2c2c4e4` | ğŸ”— [æŸ¥çœ‹æäº¤](https://github.com/sgl-project/sglang/commit/2c2c4e446b99c529896b3377b24e1b48b6a52e61)

**ğŸ¯ å˜æ›´ç±»å‹**ï¼šåŠŸèƒ½å¢å¼º / æ¶æ„å˜æ›´ / æ–°å¢åç«¯æ”¯æŒ  
**âš¡ é‡è¦ç¨‹åº¦**ï¼šğŸ”´é«˜  

**ğŸ“‹ å˜æ›´æ‘˜è¦**  
- ä¸º SGLang çš„ä¸“å®¶å¹¶è¡Œï¼ˆMoEï¼‰æ–°å¢ *Flashinfer* Allâ€‘toâ€‘All è°ƒåº¦å™¨ï¼Œå®ç°åŸºäº Flashinfer é€šä¿¡åº“çš„ token åˆ†å‘ä¸åˆå¹¶ã€‚  
- åœ¨é…ç½®å±‚é¢åŠ å…¥ `flashinfer` ä½œä¸º `--moe-a2a-backend` é€‰é¡¹ï¼Œæ›´æ–°æ–‡æ¡£ã€ç¯å¢ƒå˜é‡ã€æœåŠ¡å™¨å‚æ•°ä»¥åŠç›¸å…³æ¨¡å‹åˆå§‹åŒ–é€»è¾‘ã€‚  
- æ–°å¢ `FlashinferDispatcher`ã€`FlashinferCombineInput/Output`ã€é€šä¿¡åç«¯é€‚é… (`TorchDistributedCommBackend`) å¹¶åœ¨ MoE ä»£ç è·¯å¾„ä¸­ç»Ÿä¸€äº†æ ¼å¼åˆ¤å®š (`DispatchOutputFormat.FLASHINFER`)ã€‚  
- å¯¹ç°æœ‰ `StandardDispatcher`ã€`DeepEPNormalDispatcher`ã€`MooncakeDispatcher` ç­‰ä¿æŒå…¼å®¹ï¼Œä¸”åœ¨æ¨¡å‹ runner ä¸­åŠ å…¥å¯¹ Flashinferâ€‘Cutlass MoE çš„ç‰¹æ®Šå¤„ç†ï¼ˆå¦‚ `enable_alltoall` æ ‡è®°ï¼‰ã€‚  

**ğŸ¯ å½±å“èŒƒå›´**  
- **æ ¸å¿ƒè°ƒåº¦å±‚**ï¼š`sglang/srt/layers/moe/token_dispatcher/*`ï¼ˆæ–°å¢ flashinfer å®ç°ã€æšä¸¾æ‰©å±•ï¼‰  
- **é…ç½®/å¯åŠ¨å‚æ•°**ï¼š`sglang/srt/server_args.py`ã€`sglang/srt/layers/moe/utils.py`ã€`sglang/srt/models/*`ï¼ˆDeepSeekâ€‘V2ã€GLMâ€‘4ï¼‰  
- **æ–‡æ¡£**ï¼š`docs/advanced_features/expert_parallelism.md`ã€`docs/references/environment_variables.md`  
- **æµ‹è¯•**ï¼šæ–°å¢ `test_flashinfer_dispatcher.py`ï¼ˆè¦†ç›–åŸºæœ¬ã€ç©º tokenã€FP4 é‡åŒ–ä¸‰ç§æƒ…å½¢ï¼‰  
- **ä¾èµ–**ï¼šå¼•å…¥ `flashinfer`ï¼ˆè‹¥æœªå®‰è£…åˆ™åœ¨è¿è¡Œæ—¶æŠ›é”™è¯¯ï¼‰ï¼Œå¹¶é€šè¿‡ `torch.distributed` å®ç°åç«¯å…¼å®¹ã€‚  

**ğŸ” æŠ€æœ¯æ´å¯Ÿ**  

| ç»´åº¦ | å½±å“è¯´æ˜ |
|------|----------|
| **æ¶æ„å½±å“** | - **åç«¯æŠ½è±¡æ‰©å±•**ï¼š`MoeA2ABackend` æ–°å¢ `FLASHINFER`ï¼Œå¹¶åœ¨ `create_moe_dispatcher` ä¸­å®Œæˆå®ä¾‹åŒ–ï¼Œå®ç°â€œä¸€é”®åˆ‡æ¢â€ã€‚<br>- **ç»Ÿä¸€æ ¼å¼æ£€æŸ¥**ï¼š`DispatchOutput.format_is_flashinfer` ä¸ `CombineInput.format_is_flashinfer` ä¸ºåç»­æ¨¡å—ï¼ˆå¦‚ Fusion MoEã€Speculativeï¼‰æä¾›ç»Ÿä¸€åˆ¤å®šï¼Œä¿æŒä»£ç è·¯å¾„çš„å¯ç»„åˆæ€§ã€‚<br>- **ä¸“å®¶å¹¶è¡Œå°ºå¯¸**ï¼šåœ¨ `ServerArgs._handle_a2a_moe` ä¸­å¼ºåˆ¶ `ep_size == tp_size`ï¼Œç¡®ä¿ Flashinfer åªåœ¨ **Tensorâ€‘Parallel åŒæ­¥** åœºæ™¯ä½¿ç”¨ï¼Œé¿å… EP ä¸ TP ä¸åŒ¹é…å¯¼è‡´çš„è·¯ç”±é”™è¯¯ã€‚ |
| **æ€§èƒ½å½±å“** | - **é€šä¿¡è·¯å¾„ä¼˜åŒ–**ï¼šFlashinfer ä½¿ç”¨è‡ªç ”çš„ NCCLâ€‘+â€‘MNNVL å®ç°çš„ Allâ€‘toâ€‘Allï¼Œç†è®ºä¸Šæ¯” DeepEP/Mooncake çš„ Allâ€‘Reduce / Allâ€‘Gather å…·æœ‰æ›´ä½çš„å¸¦å®½å ç”¨å’Œæ›´å°‘çš„åŒæ­¥ç‚¹ï¼Œå°¤å…¶åœ¨ **å¤§æ¨¡å‹ã€Expert æ•°é‡ â‰« TP** æ—¶æå‡æ˜¾è‘—ã€‚<br>- **FP4 é‡åŒ–è·¯å¾„**ï¼šåœ¨ `dispatch` ä¸­ä¾æ® `MOE_NVFP4_DISPATCH` è‡ªåŠ¨åˆ‡æ¢ä¸º NVFP4â€‘FP4 æ‰“åŒ…ï¼Œå‡å° payload å¤§å°è‡³ `hidden/2 + hidden/16`ï¼Œé…åˆ Flashinfer çš„ **workspaceâ€‘aware** æœºåˆ¶ï¼Œèƒ½å¤Ÿè¿›ä¸€æ­¥é™ä½é€šä¿¡å¼€é”€ã€‚<br>- **å†…å­˜å ç”¨**ï¼š`payload_in_workspace` é€‰é¡¹æ‰“å¼€æ—¶ï¼Œåˆå¹¶é˜¶æ®µç›´æ¥å†™å…¥é¢„åˆ†é… workspaceï¼Œé¿å…é¢å¤–çš„æ‹·è´ï¼Œæå‡ååã€‚<br>- **æ½œåœ¨ç“¶é¢ˆ**ï¼šè‹¥èŠ‚ç‚¹æ•°å¾ˆå¤§æˆ– GPU ä¹‹é—´ç½‘ç»œä¸å‡è¡¡ï¼ŒFlashinfer çš„ Allâ€‘toâ€‘All ä»å—åˆ° NCCL æ‹“æ‰‘é™åˆ¶ï¼›éœ€è¦ç¡®ä¿ `max_num_tokens` ä¸ `workspace_size` è¶³å¤Ÿå¤§ï¼Œå¦åˆ™ä¼šè§¦å‘å†…éƒ¨é‡åˆ†é…å¯¼è‡´æŠ–åŠ¨ã€‚ |
| **å®‰å…¨è€ƒè™‘** | - æœ¬æ¬¡æ”¹åŠ¨ä¸æ¶‰åŠå¤–éƒ¨è¾“å…¥è§£ææˆ–ç½‘ç»œæœåŠ¡ä»£ç ï¼Œä»…åœ¨å†…éƒ¨è¿›ç¨‹é—´é€šä¿¡å±‚ä½¿ç”¨ `torch.distributed` ä¸ Flashinfer è‡ªå¸¦çš„ MNNVLã€‚<br>- `TorchDistributedCommBackend` ä»…åŒ…è£…äº†å¸¸è§„ NCCL æ¥å£ï¼Œæœªå¼•å…¥é¢å¤–çš„åºåˆ—åŒ–æˆ–æ–‡ä»¶ I/Oï¼Œé£é™©æä½ã€‚<br>- ä»éœ€å…³æ³¨ **Flashinfer ç‰ˆæœ¬å…¼å®¹æ€§**ï¼šä¸åŒå‘å¸ƒç‰ˆçš„ ABI å˜åŒ–å¯èƒ½å¯¼è‡´è¿è¡Œæ—¶å´©æºƒï¼Œå»ºè®®åœ¨ CI ä¸­é”å®š Flashinfer ç‰ˆæœ¬æˆ–åœ¨å®‰è£…è„šæœ¬ä¸­æ£€æŸ¥ `flashinfer.__version__`ã€‚ |
| **å¯ç»´æŠ¤æ€§** | - æ–°å¢çš„ `flashinfer_utils.py` å°†ä¾èµ–æ£€æŸ¥å°è£…ï¼Œé˜²æ­¢ importâ€‘time å¤±è´¥ã€‚<br>- `DispatchOutput` ä¸ `CombineInput` çš„åè®®æ£€æŸ¥ä¿æŒäº† **Protocol + TypeGuard** æ–¹å¼ï¼Œç±»å‹å®‰å…¨ä¸”æ˜“äºæ‰©å±•ã€‚<br>- æ–‡æ¡£åŒæ­¥å®Œæˆï¼Œç”¨æˆ·å¯ä»¥é€šè¿‡ `--moe-a2a-backend=flashinfer` æ˜ç¡®å¯ç”¨ã€‚<br>- ä»£ç é‡çº¦ 700 è¡Œæ–°å¢ï¼Œä¸»è¦é›†ä¸­åœ¨è°ƒåº¦å±‚ï¼Œæ”¹åŠ¨èŒƒå›´å¯æ§ã€‚ |

**âš ï¸ æ½œåœ¨é£é™©**  
1. **ä¾èµ–ç¼ºå¤±**ï¼šå¦‚æœè¿è¡Œç¯å¢ƒæœªè£…é…æ”¯æŒ Allâ€‘toâ€‘All çš„ Flashinferï¼ˆæˆ–å®‰è£…çš„ç‰ˆæœ¬ä¸å…¼å®¹ï¼‰ï¼Œ`ImportError` ä¼šåœ¨è°ƒåº¦å™¨å®ä¾‹åŒ–æ—¶æŠ›å‡ºï¼Œå¯èƒ½å¯¼è‡´æœåŠ¡å¯åŠ¨å¤±è´¥ã€‚  
2. **å‚æ•°ä¸åŒ¹é…**ï¼š`ep_size` è¢«å¼ºåˆ¶ç­‰äº `tp_size`ï¼Œä½†å·²æœ‰ç”¨æˆ·åœ¨ç”Ÿäº§ç¯å¢ƒä¸­å¯èƒ½ä½¿ç”¨ **ä¸ç­‰çš„ EP/TP**ï¼ˆå¦‚è·¨èŠ‚ç‚¹çš„ä¸“å®¶åˆ’åˆ†ï¼‰ï¼Œæ­¤æ—¶å¯åŠ¨ä¼šæŠ¥é”™æˆ–è‡ªåŠ¨é™çº§ä¸º `none`ï¼Œéœ€è¦åœ¨å‡çº§è¯´æ˜ä¸­æé†’ã€‚  
3. **å†…å­˜/å·¥ä½œç©ºé—´é…ç½®**ï¼š`max_num_tokens` ä¹˜ä»¥ EP å¤§å°åé»˜è®¤ä¸Šé™ 1024*EPï¼Œè‹¥æ¨¡å‹å®é™… token æ•°è¶…è¿‡è¯¥é˜ˆå€¼ï¼ˆå¦‚é•¿æ–‡ç”Ÿæˆï¼‰ï¼Œéœ€è‡ªè¡Œè°ƒå¤§ `SGLANG_FLASHINFER_NUM_MAX_DISPATCH_TOKENS_PER_RANK`ï¼Œå¦åˆ™ä¼šè§¦å‘ **workspace overflow**ã€‚  
4. **é‡åŒ–è·¯å¾„å…¼å®¹**ï¼š`MOE_NVFP4_DISPATCH` ä¸ `FP4` é‡åŒ–ä»ä¾èµ– `flashinfer` çš„å†…éƒ¨å®ç°ï¼Œè‹¥åç»­ Flashinfer æ›´æ”¹äº† FP4 æ¥å£ï¼Œ`dispatch` ä¸­çš„ `fp4_quantize`/`nvfp4_block_scale_interleave` å¯èƒ½å¤±æ•ˆã€‚  
5. **è°ƒåº¦å™¨è¿”å› `moe_output` ä¸ºç©º**ï¼šåœ¨é `payload_in_workspace` åœºæ™¯ï¼Œ`StandardCombineInput` ä»ä¼šåˆ›å»ºé¢å¤– bufferï¼Œè‹¥åç»­ä»£ç åœ¨ `combine` å‰å¿˜è®°é‡Šæ”¾ï¼Œå¯èƒ½å¯¼è‡´æ˜¾å­˜ç¢ç‰‡ã€‚  

**ğŸ’¡ å…³æ³¨å»ºè®®**  
- **å…¼å®¹æ€§æ£€éªŒ**ï¼šåœ¨å¯åŠ¨å‰åŠ å…¥ç‰ˆæœ¬æ£€æµ‹ï¼Œå¦‚ `assert flashinfer.__version__ >= "0.1.7"`ï¼Œå¹¶åœ¨ `ServerArgs` ä¸­ç»™å‡ºæ¸…æ™°çš„é”™è¯¯æç¤ºã€‚  
- **é…ç½®æ–‡æ¡£**ï¼šåœ¨ `environment_variables.md` ä¸­æ³¨æ˜ `SGLANG_FLASHINFER_NUM_MAX_DISPATCH_TOKENS_PER_RANK` çš„é»˜è®¤å€¼ä¸è°ƒèŠ‚èŒƒå›´ï¼Œä»¥åŠä½•æ—¶éœ€è¦æ‰‹åŠ¨å¢å¤§ã€‚  
- **å›é€€æœºåˆ¶**ï¼šè‹¥ç”¨æˆ·æ˜¾å¼æŒ‡å®š `--moe-a2a-backend=flashinfer` ä½†æ£€æµ‹åˆ°ä¸æ»¡è¶³ `ep_size == tp_size`ï¼Œå¯ä»¥è‡ªåŠ¨é™çº§ä¸º `none` å¹¶ç»™å‡º WARNï¼Œé˜²æ­¢æ„å¤–å¯åŠ¨å¤±è´¥ã€‚  
- **æ€§èƒ½åŸºå‡†**ï¼šå»ºè®®åœ¨ CI ä¸­åŠ å…¥å¯¹æ¯”åŸºå‡†ï¼ˆDeepEP vs Flashinferï¼‰åœ¨ 8â€‘GPUã€16â€‘GPU åœºæ™¯ä¸‹çš„ **åå/å»¶è¿Ÿ**ï¼Œå¸®åŠ©ç”¨æˆ·è¯„ä¼°æ˜¯å¦å€¼å¾—åˆ‡æ¢ã€‚  
- **æµ‹è¯•è¦†ç›–**ï¼šç°æœ‰å•å…ƒæµ‹è¯•å·²è¦†ç›–åŸºæœ¬ã€ç©º tokenã€FP4 ä¸‰ç§æƒ…å†µï¼Œåç»­åº”è¡¥å…… **å¤šæ¨¡ Expert åˆ†å¸ƒä¸å‡**ã€**è·¨èŠ‚ç‚¹**ï¼ˆä¸åŒ NCCL æ‹“æ‰‘ï¼‰ä»¥åŠ **å¤§åºåˆ—**ï¼ˆè¶…è¿‡é»˜è®¤ max tokenï¼‰åœºæ™¯ã€‚  
- **ç›‘æ§æŒ‡æ ‡**ï¼šåœ¨è¿è¡Œæ—¶æš´éœ² `flashinfer_workspace_used_bytes`ã€`flashinfer_alltoall_latency_ms` ç­‰æŒ‡æ ‡ï¼Œä¾¿äºè¿ç»´å®šä½é€šä¿¡ç“¶é¢ˆã€‚  

---  
æ­¤æäº¤ä¸º SGLang å¼•å…¥äº†é«˜æ•ˆçš„ Flashinfer Allâ€‘toâ€‘All MoE è°ƒåº¦å®ç°ï¼Œæå¤§æå‡äº†å¤§è§„æ¨¡ä¸“å®¶å¹¶è¡Œçš„é€šä¿¡æ•ˆç‡ã€‚ä½†åŒæ—¶ä¹Ÿå¼•å…¥äº†å¯¹ç¯å¢ƒã€é…ç½®å’Œç¡¬ä»¶æ‹“æ‰‘çš„æ›´é«˜ä¾èµ–ï¼Œå»ºè®®åœ¨ç”Ÿäº§ç¯å¢ƒä¸­é€æ­¥éªŒè¯å¹¶

---

### Move fa4 from sgl-kernel to jit kernel (#17353)
**SHA**: `3992a02` | ğŸ”— [æŸ¥çœ‹æäº¤](https://github.com/sgl-project/sglang/commit/3992a023e65ed68cb203fc90164a6962378f187d)

âš ï¸ LLMåˆ†æå¤±è´¥ï¼ˆå·²é‡è¯•3æ¬¡ï¼‰: APIè¯·æ±‚å¤±è´¥: 400 Client Error: Bad Request for url: https://integrate.api.nvidia.com/v1/chat/completions

*æš‚æ— åˆ†æ*

---

### [diffusion] model: LTX-2 Support (2/2) (#17496)
**SHA**: `d0919be` | ğŸ”— [æŸ¥çœ‹æäº¤](https://github.com/sgl-project/sglang/commit/d0919be733d593b91817f9124895f20ce2609afc)

**ğŸ¯ å˜æ›´ç±»å‹**ï¼šåŠŸèƒ½å¢å¼º / æ¶æ„æ‰©å±•ï¼ˆä¸º LTXâ€‘2 å¤šæ¨¡æ€è§†é¢‘â€‘éŸ³é¢‘ç”Ÿæˆæ¨¡å‹æä¾›å®Œæ•´çš„é…ç½®ã€æ¨¡å‹å®ç°ã€æµæ°´çº¿ä¸è°ƒåº¦å±‚ï¼‰

**âš¡ é‡è¦ç¨‹åº¦**ï¼šğŸ”´ é«˜  

**ğŸ“‹ å˜æ›´æ‘˜è¦**  
- åœ¨ `sglang` ä¸­ä¸€æ¬¡æ€§åŠ å…¥å¯¹ **LTXâ€‘2**ï¼ˆè§†é¢‘â€¯+â€¯éŸ³é¢‘ï¼‰æ¨¡å‹çš„å…¨é“¾è·¯æ”¯æŒï¼šæ–°å¢é…ç½®ç±»ã€æ¨¡å‹å®ç°ï¼ˆDiTâ€‘style è§†é¢‘â€‘éŸ³é¢‘ transformerã€ä¸“ç”¨ VAE ä¸éŸ³é¢‘ VAEã€Vocoderã€Gemmaâ€‘3 æ–‡æœ¬ç¼–ç å™¨ã€é€‚é…å™¨ï¼‰ä»¥åŠ **Pipeline**ã€**Stage**ã€**æ³¨å†Œ** ä»£ç ã€‚  
- å¼•å…¥ **RoPE** åæ ‡ç”Ÿæˆã€è·¨ **SPï¼ˆpipeline parallelï¼‰** çš„æ—¶åºåˆ‡åˆ†ã€**Tensorâ€‘Parallel** å…¼å®¹ã€ä»¥åŠå¯é€‰ **tiling / slicing** ä»¥é™ä½æ˜¾å­˜éœ€æ±‚ã€‚  
- æ–°å¢ **LTXâ€‘2â€‘Connector** è´Ÿè´£å°† Gemmaâ€‘3 çš„éšè—æ€åˆ‡åˆ†ä¸ºç‹¬ç«‹çš„ video/audio ä¸Šä¸‹æ–‡ï¼Œå¹¶æä¾› learnable registersã€å±‚å½’ä¸€åŒ–ç­‰å¤šç§å¯é…ç½®é€‰é¡¹ã€‚  
- å®Œæ•´æµæ°´çº¿ `LTX2Pipeline` åŒ…æ‹¬ï¼šè¾“å…¥æ ¡éªŒ â†’ æ–‡æœ¬ç¼–ç  â†’ è¿æ¥å™¨ â†’ æ—¶é—´/å™ªå£°å‡†å¤‡ â†’ è§†é¢‘â€‘éŸ³é¢‘ latent ç”Ÿæˆ â†’ äº¤å‰æ³¨æ„ (a2v / v2a) â†’ å¤šæ­¥å»å™ª â†’ VAE è§£ç  â†’ éŸ³é¢‘ VAE + Vocoder â†’ æœ€ç»ˆè§†é¢‘/éŸ³é¢‘è¾“å‡ºã€‚  

**ğŸ¯ å½±å“èŒƒå›´**  
- **æ¨¡å‹å±‚**ï¼š`sglang.multimodal_gen.models`ï¼ˆadapterã€ditsã€encodersã€vaesã€vocoderï¼‰  
- **é…ç½®å±‚**ï¼š`sglang.multimodal_gen.configs.models`ï¼ˆadapterã€ditsã€encodersã€vaesã€vocoderã€pipelineï¼‰  
- **è¿è¡Œæ—¶å±‚**ï¼š`sglang.multimodal_gen.runtime.models`ã€`runtime.pipelines_core.stages`ï¼ˆæ–°å¢ 4 æ¡å…³é”® Stageï¼‰  
- **æ³¨å†Œ/è°ƒåº¦**ï¼š`sglang.multimodal_gen.registry` ä¸ `runtime.pipelines_core.stages.__init__` ä¸­çš„æ–°å¢æ˜ å°„  
- **ä¾èµ–**ï¼šPILã€Diffusersã€torch â‰¥ 2.0 çš„ `torch.autocast`ã€è‡ªå®šä¹‰ `USPAttention`ã€`Row/ColumnParallelLinear`ã€`OffloadableDiTMixin` ç­‰  

**ğŸ” æŠ€æœ¯æ´å¯Ÿ**  

| ç»´åº¦ | å½±å“è¯´æ˜ |
|------|----------|
| **æ¶æ„** | <ul><li>**åŒæµ DiT**ï¼š`LTX2VideoTransformer3DModel` åŒæ—¶æ¥å— video ä¸ audio latentsï¼Œå†…éƒ¨å®ç° 6â€‘è·¯äº¤å‰æ³¨æ„ (audioâ†’videoã€videoâ†’audio) ä»¥åŠç‹¬ç«‹è‡ªæ³¨æ„ï¼›ä½¿ç”¨ **RMSâ€‘Norm across heads** å…¼å®¹ Tensorâ€‘Parallelã€‚</li><li>**Adapterâ€¯Connector**ï¼š`LTX2TextConnectors` å°† Gemmaâ€‘3 å…¨ token hiddenâ€‘states â†’ ä¸¤å¥—ç‹¬ç«‹ Transformerï¼ˆvideo/audioï¼‰å¹¶æ”¯æŒ **learnable registers**ã€**RoPE ç±»å‹ (interleaved / split)**ã€å¯é€‰ **causal temporal positioning**ã€‚</li><li>**VAE ç»“æ„**ï¼šä» LTXâ€‘1 è¿ç§»åˆ° **3â€‘D encoder/decoder**ï¼ŒåŠ å…¥ **attentionâ€‘based ResNet blocksã€causal Conv3D**ï¼Œæ”¯æŒ **spatioâ€‘temporal down/upsampling**ï¼Œå¹¶å¯¹ **audio VAE** å®ç° **causal Conv2D**ã€**attention blocks**ã€**perâ€‘channel RMSNorm**ã€‚</li><li>**Vocoder**ï¼šåŸºäº LTXâ€‘2 è®¾è®¡çš„ 1â€‘D éšæœºæ®‹å·®å—ï¼Œæ”¯æŒ **å¤šå°ºåº¦ä¸Šé‡‡æ ·** ä¸ **å¯é…ç½®æ¼æ–—å·ç§¯**ã€‚</li></ul> |
| **æ€§èƒ½** | <ul><li>**æ˜¾å­˜éœ€æ±‚æ˜¾è‘—æå‡**ï¼šè§†é¢‘ transformer + åŒ VAE + éŸ³é¢‘ VAE + vocoderï¼Œå•å¡ > 30â€¯GBï¼ˆå–å†³äºåˆ†è¾¨ç‡ã€å¸§æ•°ã€TP/PP é…ç½®ï¼‰ã€‚</li><li>**å¹¶è¡Œç­–ç•¥**ï¼šå®ç°äº† **Tensorâ€‘Parallel (TP)**ã€**Sequenceâ€‘Parallel (SP)**ã€**Fullyâ€‘Sharded Data Parallel (FSDP)** å¤šå±‚å…¼å®¹ï¼›ä½†å¯¹ **RoPE åˆ‡ç‰‡**ã€**SP æ—¶é—´åˆ‡ç‰‡** çš„å®ç°æå…¶ç»†è‡´ï¼Œè‹¥ TP/SP é…ç½®ä¸åŒ¹é…ä¼šåœ¨ `RuntimeError` ä¸­æŠ¥ç»´åº¦ä¸æ•´é™¤ã€‚</li><li>**æ—¶é—´æ­¥ï¼ˆsigmaï¼‰é‡‡æ ·**ï¼šæ”¹ä¸º **sigmaâ€‘space Euler**ï¼ˆFlowâ€‘Matchingï¼‰ä»£æ›¿ä¼ ç»Ÿ DDIMï¼Œç†è®ºä¸Šæ›´é«˜è´¨é‡ä½†æ¯æ­¥éœ€è®¡ç®— **v = (xâ€‘xâ‚€)/Ïƒ**ã€**sigma_nextâ€‘sigma**ï¼Œå¯¼è‡´é¢å¤– `torch` è®¡ç®—ã€‚</li><li>**å¯é€‰ tiling / slicing**ï¼š`AutoencoderKLLTX2Video` å¼•å…¥ **tileâ€‘decode** ä¸ **frameâ€‘wise** é€‰é¡¹ï¼Œæ˜¾è‘—é™ä½æ˜¾å­˜ï¼ˆâ‰ˆ 2â€‘3Ã—ï¼‰ï¼Œä½†ä¼šå¢åŠ  CPUâ†”GPU æ•°æ®æ‹·è´æ¬¡æ•°ã€‚</li></ul> |
| **å®‰å…¨** | <ul><li>**æƒé‡åŠ è½½**ï¼šæ–°å¢ `load_weights` é€»è¾‘ä¼šéå† checkpointï¼Œä½¿ç”¨ `weight_loader`ã€`shard_id` å…¼å®¹ä¸åŒ fusing æ–¹å¼ã€‚è‹¥ checkpoint è¢«æ¶æ„ç¯¡æ”¹ï¼ˆæ¯”å¦‚æ³¨å…¥éå¸¸å¤§æ•°å€¼ï¼‰ï¼Œå¯èƒ½å¯¼è‡´ **æ•°å€¼æº¢å‡º / NaN**ï¼Œå»ºè®®åœ¨åŠ è½½åæ‰§è¡Œ **å¼‚å¸¸æ£€æµ‹**ï¼ˆ`torch.isnan`ã€`torch.isfinite`ï¼‰ã€‚</li><li

---

### [diffusion] model: LTX-2 (1/2) (#17495)
**SHA**: `797a981` | ğŸ”— [æŸ¥çœ‹æäº¤](https://github.com/sgl-project/sglang/commit/797a9811a2dc7704ac3761e5d3a64e037edf8565)

**ğŸ¯ å˜æ›´ç±»å‹**ï¼šåŠŸèƒ½å¢å¼º / å¤šæ¨¡æ€æ‰©å±•ï¼ˆæ–°å¢éŸ³è§†é¢‘ç”Ÿæˆèƒ½åŠ›ã€çº¿æ€§ç¼©æ”¾ RoPEã€ä¸“ç”¨åŠ è½½å™¨ï¼‰  

**âš¡ é‡è¦ç¨‹åº¦**ï¼šğŸ”´é«˜  

**ğŸ“‹ å˜æ›´æ‘˜è¦**  
1. åœ¨ Diffusion ç”Ÿæˆè·¯å¾„ä¸­åŠ å…¥å¯¹ **audio**ï¼ˆä»¥åŠ videoâ€‘audio å¤åˆï¼‰è¾“å‡ºçš„æ”¯æŒï¼Œå®ç° `sample, audio` çš„ç»Ÿä¸€åŒ…è£…ã€éŸ³é¢‘é‡‡æ ·ç‡ä¼ é€’ä¸åå¤„ç†ã€‚  
2. æ–°å¢ **LinearScalingRotaryEmbedding**ï¼Œå®ç° RoPE çš„çº¿æ€§ç¼©æ”¾å¹¶åœ¨ `get_rope` ä¸­æ ¹æ® `rope_scaling` è‡ªåŠ¨åˆ‡æ¢ã€‚  
3. å¼•å…¥ **Audio/Vocoder/Adapter** ä¸“ç”¨ `ComponentLoader`ï¼Œå¹¶åœ¨æ¨¡å‹åŠ è½½é˜¶æ®µå®Œæˆå¯¹åº”æƒé‡çš„è£…è½½ã€è®¾å¤‡è¿ç§»åŠç²¾åº¦è®¾ç½®ã€‚  
4. æ‰©å±• **OutputBatch / Req** æ•°æ®ç»“æ„ï¼ŒåŠ å…¥ audioã€audio_sample_rateã€éŸ³é¢‘æ½œåœ¨å¼ é‡ã€fpsã€generate_audio ç­‰å­—æ®µã€‚  
5. åœ¨ `post_process_sample` ä¸­å®ç°éŸ³é¢‘â€‘è§†é¢‘ **mux**ï¼ˆåˆ©ç”¨ ffmpeg + scipyï¼‰ï¼Œå¹¶åœ¨ `utils` ä¸­åŠ å…¥éŸ³é¢‘å½’ä¸€åŒ–ã€é‡‡æ ·ç‡æ¨æ–­åŠå¼‚å¸¸å®¹é”™ã€‚  
6. è°ƒæ•´è‹¥å¹² pipeline stageï¼ˆtext_encodingã€timestep_preparationï¼‰ä»¥é€‚é…æ–°å­—æ®µã€‚  

**ğŸ¯ å½±å“èŒƒå›´**  
- `sglang/multimodal_gen/runtime/entrypoints/*`ï¼ˆdiffusion_generatorã€http_serverã€openai/utilsï¼‰  
- `sglang/multimodal_gen/runtime/utils.py`ï¼ˆéŸ³è§†é¢‘åå¤„ç†ï¼‰  
- `sglang/multimodal_gen/runtime/layers/rotary_embedding.py`ï¼ˆRoPEï¼‰  
- `sglang/multimodal_gen/runtime/loader/component_loader.py`ï¼ˆaudio/vocoder/adapterï¼‰  
- `sglang/multimodal_gen/runtime/pipelines_core/*`ï¼ˆReq/OutputBatchã€stagesï¼‰  
- ä¾èµ–çš„ç¬¬ä¸‰æ–¹åº“ï¼š`torch`, `numpy`, `imageio`, `ffmpeg`, `scipy.io.wavfile`  

**ğŸ” æŠ€æœ¯æ´å¯Ÿ**  

- **æ¶æ„å½±å“**  
  - åœ¨æ ¸å¿ƒæ•°æ®ç»“æ„ä¸­åŠ å…¥éŸ³é¢‘å­—æ®µï¼Œä½¿ç”Ÿæˆ pipeline èƒ½å¤Ÿç»Ÿä¸€å¤„ç†å›¾åƒã€è§†é¢‘ã€éŸ³é¢‘ä¸‰ç±»æ¨¡æ€ï¼Œä¿æŒå‘åå…¼å®¹ï¼ˆè€æ¨¡å‹ä»å¯ä½¿ç”¨æ—§å­—æ®µï¼‰ã€‚  
  - æ–°å¢ `LinearScalingRotaryEmbedding`ï¼Œåœ¨ RoPE æ”¯æŒçº¿æ€§ç¼©æ”¾çš„åŒæ—¶ä¿æŒç°æœ‰ `RotaryEmbedding` æ¥å£ä¸å˜ï¼Œå…¼å®¹å·²æœ‰æ¨¡å‹ã€‚  
  - é€šè¿‡ä¸“ç”¨ `ComponentLoader`ï¼ˆAudioVAEã€Vocoderã€Adapterï¼‰å°†éŸ³è§†é¢‘å­æ¨¡å‹çš„åŠ è½½ã€ç²¾åº¦ä¸è®¾å¤‡ç®¡ç†æŠ½è±¡å‡ºæ¥ï¼Œé¿å…åœ¨ä¸» pipeline ä¸­ç¡¬ç¼–ç ã€‚  

- **æ€§èƒ½å½±å“**  
  - éŸ³é¢‘æ•°æ®åœ¨ CPUâ†’GPU ä¹‹é—´çš„æ‹·è´åœ¨ `post_process_sample` å‰å®Œæˆï¼Œä»…åœ¨ MUX é˜¶æ®µä½¿ç”¨ CPUï¼ˆffmpegï¼‰å†™å…¥ï¼ŒåŸºæœ¬ä¸å½±å“æ¨ç†æ—¶çš„ååã€‚  
  - æ–°çš„ RoPE è®¡ç®—åœ¨ `LinearScalingRotaryEmbedding` ä¸­åŠ å…¥é™¤ä»¥ `scaling_factor` çš„ä¸€æ­¥ï¼Œå¼€é”€æå°ï¼ˆä¸€æ¬¡æ€§ç¼“å­˜ï¼‰ã€‚  
  - é€šè¿‡ `should_offload` ä¸ `target_device` æ§åˆ¶éŸ³é¢‘/è§†é¢‘å­æ¨¡å‹çš„åŠ è½½ä½ç½®ï¼Œä»å¯å—ç›Šäº FSDP/CPUâ€‘offè½½ç­–ç•¥ã€‚  

- **å®‰å…¨è€ƒè™‘**  
  - å¼•å…¥å¤–éƒ¨å¯æ‰§è¡Œæ–‡ä»¶ `ffmpeg`ï¼Œåœ¨ `_resolve_ffmpeg_exe` ä¸­å¯¹è·¯å¾„è¿›è¡Œæ ¡éªŒï¼Œé˜²æ­¢ä»»æ„ä»£ç æ‰§è¡Œã€‚  
  - å¯¹éŸ³é¢‘æ•°æ®è¿›è¡Œç±»å‹æ£€æŸ¥ä¸æ•°å€¼æˆªæ–­ï¼Œé˜²æ­¢ NaN/Inf ä¼ æ’­å¯¼è‡´åç»­å´©æºƒã€‚  
  - æ‰€æœ‰æ–°å¢å¯¹æ–‡ä»¶ç³»ç»Ÿçš„å†™å…¥ï¼ˆä¸´æ—¶ wavã€muxâ€‘tmpï¼‰ä½¿ç”¨ `tempfile` ä¸ `os.replace`ï¼Œä¿è¯åŸå­æ€§å¹¶é¿å…æ³„éœ²ã€‚  

**âš ï¸ æ½œåœ¨é£é™©**  

1. **ä¾èµ–ç¼ºå¤±**ï¼šå¦‚æœè¿è¡Œç¯å¢ƒæœªå®‰è£… `ffmpeg`ã€`scipy` æˆ–å¯¹åº”çš„ `imageio_ffmpeg`ï¼ŒéŸ³é¢‘â€‘è§†é¢‘åˆæˆä¼šå›é€€ä¸ºæ— å£°è§†é¢‘ï¼Œå¯èƒ½å¯¼è‡´ç”¨æˆ·è¯¯ä»¥ä¸ºåŠŸèƒ½å¤±æ•ˆã€‚  
2. **éŸ³é¢‘ç»´åº¦çº¦å®š**ï¼šå¯¹ `torch.Tensor`/`np.ndarray` çš„ç»´åº¦æ¨æ–­é€»è¾‘è¾ƒä¸ºå®½æ¾ï¼Œè‹¥æ¨¡å‹è¿”å›éæ ‡å‡†å½¢çŠ¶ï¼ˆå¦‚å¤šé€šé“éŸ³é¢‘ï¼‰ï¼Œå¯èƒ½äº§ç”Ÿé”™è¯¯çš„å£°é“æ˜ å°„æˆ–è¢«é”™è¯¯ä¸¢å¼ƒã€‚  
3. **å†…å­˜å³°å€¼**ï¼šåœ¨å¤§åˆ†è¾¨ç‡è§†é¢‘+é«˜é‡‡æ ·ç‡éŸ³é¢‘åŒæ—¶å†™å…¥æ—¶ï¼Œä¼šåœ¨ç”Ÿæˆä¸´æ—¶ wav æ–‡ä»¶æ—¶å ç”¨å¤§é‡å†…å­˜ï¼Œç‰¹åˆ«æ˜¯åœ¨å¤šå¡å¹¶è¡Œæ—¶éœ€å…³æ³¨ç£ç›˜ I/O ä¸å†…å­˜å ç”¨ã€‚  
4. **æ¨¡å‹å…¼å®¹æ€§**ï¼šæ–° `LinearScalingRotaryEmbedding` é»˜è®¤åœ¨ `rope_scaling` ä¸º `linear` æ—¶ä½¿ç”¨ï¼Œè‹¥æ—§æ¨¡å‹è¯¯é…ç½®æ­¤å­—æ®µå¯èƒ½å¯¼è‡´ä½ç½®ç¼–ç å¤±çœŸã€‚  
5. **å¹¶å‘è°ƒç”¨**ï¼š`_maybe_mux_audio_into_mp4` åœ¨å¤šè¯·æ±‚å¹¶å‘æ—¶ä½¿ç”¨åŒä¸€ä¸´æ—¶æ–‡ä»¶åï¼ˆé€šè¿‡ `tempfile.NamedTemporaryFile`ï¼‰ï¼Œç†è®ºå®‰å…¨ï¼Œä½†åœ¨æç«¯å¹¶å‘ä¸‹ä»éœ€ç¡®ä¿æ–‡ä»¶æè¿°ç¬¦è¶³å¤Ÿã€‚  

**ğŸ’¡ å…³æ³¨å»ºè®®**  

- **éƒ¨ç½²å‰æ£€æŸ¥**ï¼šåœ¨å¯åŠ¨æœåŠ¡å‰åŠ å…¥å¯åŠ¨è„šæœ¬æ£€æŸ¥ `ffmpeg` ä¸ `scipy` å¯ç”¨æ€§ï¼Œè‹¥ç¼ºå¤±ç»™å‡ºæ˜ç¡®æç¤ºã€‚  
- **æ–‡æ¡£æ›´æ–°**ï¼šæ˜ç¡®è¯´æ˜ **LTXâ€‘2** æ¨¡å‹éœ€è¦çš„ `audio_vae`, `vocoder`, `connectors` ä¸‰ä¸ª diffusers ç»„ä»¶çš„è·¯å¾„ä¸å¯¹åº” `pipeline_config` å‚æ•°ã€‚  
- **å‚æ•°æ ¡éªŒ**ï¼šåœ¨ API å±‚å¯¹ `audio`ã€`audio_sample_rate` åšæ˜¾å¼éªŒè¯ï¼Œè¿”å›å‹å¥½é”™è¯¯è€Œéå†…éƒ¨å¼‚å¸¸ã€‚  
- **èµ„æºç›‘æ§**ï¼šå»ºè®®åœ¨ç”Ÿäº§ç¯å¢ƒå¼€å¯ `ffmpeg` ä¸ä¸´æ—¶ wav æ–‡ä»¶çš„å¤§å°ç›‘æ§ï¼Œé˜²æ­¢ç£ç›˜è¢«å¿«é€Ÿå¡«æ»¡ã€‚  
- **å›é€€æœºåˆ¶**ï¼šå½“éŸ³é¢‘ MUX å¤±è´¥æ—¶ä¿ç•™å·²æœ‰æ— å£°è§†é¢‘ï¼Œå¹¶åœ¨è¿”å›çš„ `result_item` ä¸­åŠ å…¥ `audio_mux_error` å­—æ®µä¾›ä¸Šå±‚åˆ¤æ–­ã€‚  
- **æµ‹è¯•è¦†ç›–**ï¼šè¡¥å……å•å…ƒæµ‹è¯•è¦†ç›–ä»¥ä¸‹åœºæ™¯ï¼š  
  1. `sample` ä¸ºçº¯å›¾åƒã€çº¯è§†é¢‘ã€è§†é¢‘+éŸ³é¢‘ä¸‰ç§è¿”å›å½¢å¼ã€‚  
  2. `audio` ä¸º `torch.Tensor`ã€`np.ndarray`ã€ç©ºå€¼çš„åˆ†æ”¯ã€‚  
  3. `rope_scaling` ä¸º `default`ã€`linear`ã€æ— å­—æ®µçš„æƒ…å†µã€‚  
- **æ¸è¿›å‘å¸ƒ**ï¼šå»ºè®®å…ˆåœ¨å†…éƒ¨æˆ–å°æµé‡å®éªŒä¸­å¼€å¯éŸ³è§†é¢‘åŠŸèƒ½ï¼Œè§‚å¯Ÿèµ„æºå ç”¨ä¸é”™è¯¯ç‡åå†å…¨é‡æ¨å¹¿ã€‚  

---

#### ğŸŸ¡ ä¸­é‡è¦åº¦å˜æ›´ (14)

### [Kimi-Linear] Refactor Kimi-Linear to support RadixLinearAttention (#17506)
**SHA**: `0c8165f` | ğŸ”— [æŸ¥çœ‹æäº¤](https://github.com/sgl-project/sglang/commit/0c8165ffbd1bc7e7d6c64da1687d1718e42f2f4a)

**ğŸ¯ å˜æ›´ç±»å‹**ï¼šåŠŸèƒ½å¢å¼ºï¼ˆä¸º Kimiâ€‘Linear å¼•å…¥ RadixLinearAttentionï¼‰  
**âš¡ é‡è¦ç¨‹åº¦**ï¼šğŸŸ¡ ä¸­  
**ğŸ“‹ å˜æ›´æ‘˜è¦**ï¼š  
- å°†åŸæœ‰çš„ `KimiLinearAttnBackend` é‡æ„ä¸ºå…¼å®¹ `RadixLinearAttention`ï¼Œæ”¯æŒä¸¤ç§çº¿æ€§æ³¨æ„åŠ›å®ç°ï¼ˆGDN ä¸ KDAï¼‰ç»Ÿä¸€å…¥å£ï¼›  
- åœ¨ `RadixLinearAttention` ä¸­åŠ å…¥å¯¹å…±äº«å·ç§¯æƒé‡/åç½®çš„ `Tuple` åŒ…è£…ï¼Œæ–°å¢ `head_qk_dim`ã€`layer_id` ç­‰å±æ€§ï¼›  
- `KimiLinear` æ¨¡å‹å±‚çº§åˆ›å»º `RadixLinearAttention` å®ä¾‹å¹¶æŠŠå·ç§¯æƒé‡ã€åç½®ã€A_logã€dt_bias ç»Ÿä¸€ä¼ é€’ï¼›  
- è°ƒæ•´ `forward_decode / forward_extend` çš„ç­¾åå’Œå†…éƒ¨é€»è¾‘ï¼Œä½¿å…¶åœ¨ decode ä¸ extend ä¸¤ç§æ¨¡å¼ä¸‹å‡å¯å¤„ç† `mixed_qkv` ä¸ºå¼ é‡æˆ– `(q,k,v)` å…ƒç»„ï¼Œç»Ÿä¸€äº† `a`(gate) ä¸ `b`(beta) å‚æ•°çš„æ¥æºã€‚  

**ğŸ¯ å½±å“èŒƒå›´**ï¼š  
- `python/sglang/srt/layers/attention/hybrid_linear_attn_backend.py`ï¼ˆæ ¸å¿ƒæ³¨æ„åŠ›åç«¯ï¼‰  
- `python/sglang/srt/layers/radix_linear_attention.py`ï¼ˆæ–°æ³¨æ„åŠ›å±‚å®ç°ï¼‰  
- `python/sglang/srt/models/kimi_linear.py`ï¼ˆæ¨¡å‹å±‚è°ƒç”¨è·¯å¾„ï¼‰  

**ğŸ’¡ å…³æ³¨å»ºè®®**ï¼š  
1. **å…¼å®¹æ€§æµ‹è¯•**ï¼šç¡®ä¿æ—§çš„ GDN ä»£ç è·¯å¾„ä»èƒ½æ¥å—å•å¼ é‡ `mixed_qkv`ï¼Œè€Œæ–° KDA è·¯å¾„èƒ½å¤Ÿæ­£ç¡®è§£æ `(q,k,v)` å…ƒç»„ï¼›å»ºè®®åœ¨å•å…ƒæµ‹è¯•ä¸­åˆ†åˆ«è¦†ç›–ä¸¤ç§æƒ…å†µã€‚  
2. **ç±»å‹å®‰å…¨**ï¼šå¤§é‡ä½¿ç”¨ `assert isinstance(..., Tuple)`ï¼Œè‹¥å¤–éƒ¨è°ƒç”¨ä¼ å…¥ `list` æˆ–å…¶å®ƒåºåˆ—ä¼šè§¦å‘æ–­è¨€ï¼Œå»ºè®®æ”¹ä¸ºæ›´å®½å®¹çš„ `isinstance(..., (tuple, list))` æˆ–æ˜¾å¼è½¬æ¢ã€‚  
3. **æ€§èƒ½è¯„ä¼°**ï¼šæ–°çš„ `forward_decode` é€šè¿‡ `layer.conv_weights` ç›´æ¥è®¿é—®ï¼Œé¿å…äº† `kwargs` ä¼ é€’ï¼Œç†è®ºä¸Šå‡å°‘äº† Python å‚æ•°è§£æå¼€é”€ï¼Œä½†è¯·åœ¨å¤§æ¨¡å‹æ¨ç†åŸºå‡†ä¸ŠéªŒè¯æ˜¯å¦çœŸæ­£æå‡ã€‚  
4. **æ–‡æ¡£ä¸ç¤ºä¾‹**ï¼šæ›´æ–° README/ä½¿ç”¨æ–‡æ¡£ï¼Œè¯´æ˜ `RadixLinearAttention` çš„ `conv_weights` ä¸ `bias` éœ€è¦ä»¥ `Tuple` å½¢å¼ä¼ å…¥ï¼Œé˜²æ­¢ç”¨æˆ·è¯¯ç”¨ã€‚  
5. **é”™è¯¯å¤„ç†**ï¼š`forward_extend` ä¸­å¯¹ `mixed_qkv` ä¸º `torch.Tensor` çš„æ–­è¨€ä»…åœ¨ decode åœºæ™¯å‡ºç°ï¼Œè€ƒè™‘åœ¨é decode åœºæ™¯æä¾›æ›´å‹å¥½çš„é”™è¯¯ä¿¡æ¯ã€‚  

æ€»ä½“æ¥è¯´ï¼Œæ­¤æ¬¡é‡æ„ä¸º Kimiâ€‘Linear å¼•å…¥äº†æ›´çµæ´»çš„çº¿æ€§æ³¨æ„åŠ›å®ç°ï¼Œä»£ç ç»“æ„æ›´ç»Ÿä¸€ï¼Œä½†éœ€è¦å®Œå–„ç±»å‹æ£€æŸ¥ã€å…¼å®¹æ€§æµ‹è¯•ä»¥åŠæ–‡æ¡£è¯´æ˜ï¼Œä»¥é™ä½å›å½’é£é™©ã€‚

---

### add documentation example for LoRA overlap loading and cleanup unused function (#17464)
**SHA**: `a6280b2` | ğŸ”— [æŸ¥çœ‹æäº¤](https://github.com/sgl-project/sglang/commit/a6280b2a2399ddf01b38d7a374d1474b597de191)

**ğŸ¯ å˜æ›´ç±»å‹**ï¼šæ–‡æ¡£/ä»£ç è½»å¾®é‡æ„  
**âš¡ é‡è¦ç¨‹åº¦**ï¼šğŸŸ¡ ä¸­  

**ğŸ“‹ å˜æ›´æ‘˜è¦**  
1. åœ¨ `docs/advanced_features/lora.ipynb` ä¸­æ–°å¢â€œLoRA Overlap Loadingâ€ç¤ºä¾‹ï¼Œè¡¥å……ä½¿ç”¨æ–¹æ³•ã€é™åˆ¶è¯´æ˜ä»¥åŠå¯èƒ½å¯¼è‡´æ›´é«˜å»¶è¿Ÿçš„åœºæ™¯ã€‚  
2. åç«¯ä»£ç åšäº†å‡ é¡¹å°å¹…æ”¹åŠ¨ï¼š  
   - `lora_registry.get_backend_from_name` è¿”å›ç±»å‹ç”± `BaseLoRABackend` æ”¹ä¸º `Type[BaseLoRABackend]`ï¼ˆä»…ç±»å‹æç¤ºï¼‰ã€‚  
   - `LoraManager.__init__` å‚æ•°é¡ºåºè°ƒæ•´ï¼Œ`server_args` ç”±å¯é€‰å˜ä¸ºå¿…ä¼ ï¼Œå¹¶åœ¨ `ModelRunner.init_lora_manager` ä¸­ç›¸åº”ä¼ å‚ã€‚  
   - åˆ é™¤ `TPWorker.can_run_lora_batch` æ–¹æ³•ï¼ˆè°ƒåº¦å·²æ”¹ä¸ºç›´æ¥é€šè¿‡ `LoraManager.validate_lora_batch` ä½¿ç”¨ï¼‰ã€‚  

**ğŸ¯ å½±å“èŒƒå›´**  
- **æ–‡æ¡£**ï¼š`docs/advanced_features/lora.ipynb`ï¼ˆå¯¹ä½¿ç”¨è€…æ— å‰¯ä½œç”¨ï¼‰ã€‚  
- **æ ¸å¿ƒä»£ç **ï¼š`sglang/srt/lora/backend/lora_registry.py`ã€`sglang/srt/lora/lora_manager.py`ã€`sglang/srt/managers/tp_worker.py`ã€`sglang/srt/model_executor/model_runner.py`ã€‚  
- å¯èƒ½æ³¢åŠ **è‡ªå®šä¹‰è„šæœ¬**ã€**å•å…ƒæµ‹è¯•** æˆ– **å¤–éƒ¨åº“** ä¸­ç›´æ¥å®ä¾‹åŒ– `LoraManager` çš„ä»£ç ã€‚

**ğŸ’¡ å…³æ³¨å»ºè®®**  
1. **å…¼å®¹æ€§æ£€æŸ¥**ï¼šç¡®è®¤é¡¹ç›®ä¸­æ²¡æœ‰ç›´æ¥è°ƒç”¨ `LoraManager`ï¼ˆé™¤ `ModelRunner`ï¼‰ä¸”æœªä¼  `server_args` çš„è·¯å¾„ï¼Œå¦åˆ™ä¼šå‡ºç° `TypeError`ã€‚å¦‚æœ‰ï¼Œéœ€è¡¥å…¨å‚æ•°æˆ–ä¿æŒæ—§ç­¾åçš„å…¼å®¹åŒ…è£…ã€‚  
2. **è°ƒåº¦é€»è¾‘éªŒè¯**ï¼š`can_run_lora_batch` è¢«åˆ é™¤åï¼Œç¡®ä¿è°ƒåº¦å™¨ä»èƒ½æ­£ç¡®åˆ¤æ–­ LoRA æ‰¹æ¬¡å¯è¿è¡Œæ€§ï¼ˆç›®å‰ä¾èµ– `LoraManager.validate_lora_batch`ï¼‰ï¼Œå¹¶åœ¨ç›¸å…³å•å…ƒæµ‹è¯•ä¸­åŠ å…¥è¦†ç›–ã€‚  
3. **ç±»å‹æç¤ºåŒæ­¥**ï¼š`lora_registry` çš„è¿”å›ç±»å‹æ›´æ”¹ä»…å½±å“ç±»å‹æ£€æŸ¥å·¥å…·ï¼Œå»ºè®®æ›´æ–°ç›¸åº”çš„ `mypy`/`pyright` é…ç½®ï¼Œä»¥é¿å…è¯¯æŠ¥ã€‚  
4. **æ–‡æ¡£åŒæ­¥**ï¼šæ–°åŠ å…¥çš„ notebook æä¾›äº† `--enable-lora-overlap-loading` ä½¿ç”¨åœºæ™¯å’Œé™åˆ¶ï¼Œå»ºè®®åœ¨ README æˆ–å‚æ•°è¯´æ˜ä¸­åŠ å…¥å¯¹åº”çš„å¿«é€Ÿæç¤ºï¼Œé˜²æ­¢ç”¨æˆ·è¯¯å¼€è¯¥ç‰¹æ€§å¯¼è‡´æ€§èƒ½ä¸‹é™ã€‚  

æ€»ä½“æ¥è¯´ï¼Œæ­¤æ¬¡æ”¹åŠ¨ä¸»è¦æ˜¯å¯¹ LoRA é‡å åŠ è½½ç‰¹æ€§çš„æ–‡æ¡£è¡¥å…¨å’Œå°‘é‡å†…éƒ¨ API è°ƒæ•´ï¼Œå¯¹æ ¸å¿ƒåŠŸèƒ½å½±å“ä¸å¤§ï¼Œä½†éœ€ç•™æ„å‘åå…¼å®¹æ€§å’Œè°ƒåº¦è·¯å¾„çš„å®Œæ•´æ€§ã€‚

---

### [Diffusion] Add diffusion time embedding to jit kernel (#17658)
**SHA**: `7a4bb0d` | ğŸ”— [æŸ¥çœ‹æäº¤](https://github.com/sgl-project/sglang/commit/7a4bb0d516e16d58bee5899ec9283ef219783ad9)

**ğŸ¯ å˜æ›´ç±»å‹**ï¼šåŠŸèƒ½å¢å¼ºï¼ˆä¸º Diffusion æ¨¡å—æ–°å¢ JITâ€‘kernel å®ç°çš„æ—¶é—´æ­¥åµŒå…¥ï¼‰  
**âš¡ é‡è¦ç¨‹åº¦**ï¼šğŸŸ¡ ä¸­  
**ğŸ“‹ å˜æ›´æ‘˜è¦**ï¼š  
- åœ¨ `sglang/jit_kernel/csrc/diffusion` ä¸­å®ç°äº† `timestep_embedding` çš„ CUDA kernelï¼Œæ”¯æŒ `float16/bfloat16/float32` è¾“å…¥å¹¶é€šè¿‡ `float` è¾“å‡ºã€‚  
- ä¸º kernel è¡¥å……äº† `exp/sin/cos` çš„è®¾å¤‡å®ç°å¹¶åœ¨ `type.cuh` ä¸­åŠ å…¥äº†ä» `__half`ã€`__bfloat16` åˆ° `float` çš„è½¬æ¢ã€‚  
- æ–°å¢ Python åŒ…è£…å±‚ `jit_kernel.timestep_embedding`ï¼Œå¹¶åœ¨ `visual_embedding.py` ä¸­æ”¹ä¸ºå…ˆå°è¯• CUDA å®ç°ï¼Œè‹¥é CUDA ç¯å¢ƒå›é€€åˆ° Diffusers åŸå®ç°ã€‚  
- å®Œæ•´å•å…ƒæµ‹è¯•è¦†ç›–äº†å¤šæ‰¹æ¬¡ã€ä¸åŒç»´åº¦ã€å„ç§ dtypeã€å‚æ•°ç»„åˆåŠæ€§èƒ½åŸºå‡†ã€‚  

**ğŸ¯ å½±å“èŒƒå›´**  
- **æ ¸å¿ƒè®¡ç®—å±‚**ï¼š`sglang/jit_kernel`ï¼ˆæ–°å¢ CUDA æºæ–‡ä»¶ã€æ•°å­¦/ç±»å‹å·¥å…·ï¼‰  
- **è¿è¡Œæ—¶å±‚**ï¼š`sglang/multimodal_gen/runtime/layers/visual_embedding.py`ï¼ˆæ”¹ä¸ºæ¡ä»¶è°ƒç”¨ CUDA å®ç°ï¼‰  
- **æµ‹è¯•**ï¼š`sglang/jit_kernel/tests/test_timestep_embedding.py`ï¼ˆæ–°å¢ 160 è¡Œï¼‰  
- **éƒ¨ç½²è„šæœ¬/ä¾èµ–**ï¼šéœ€è¦ CUDA ç¼–è¯‘å™¨æ”¯æŒ `__half`ã€`__bfloat16`ï¼Œå¹¶ç¡®ä¿ `sgl_kernel` åŒ…åœ¨ç›®æ ‡æœºå™¨ä¸Šå¯ç”¨ã€‚  

**ğŸ’¡ å…³æ³¨å»ºè®®**  
1. **å…¼å®¹æ€§æ£€æŸ¥**ï¼šåœ¨ä¸åŒ CUDA ç‰ˆæœ¬ï¼ˆâ‰¥11.0ï¼‰ä»¥åŠä¸åŒæ˜¾å¡æ¶æ„ä¸Šç¼–è¯‘éªŒè¯ï¼Œé˜²æ­¢ `__half2float`/`__bfloat162float` åœ¨æ—§é©±åŠ¨ä¸Šç¼ºå¤±ã€‚  
2. **ç»´åº¦å¯¹é½**ï¼škernel å¼ºåˆ¶ `dim % 8 == 0`ï¼Œè°ƒç”¨æ–¹åº”åœ¨ä¸Šå±‚æå‰æ ¡éªŒæˆ–åœ¨ API ä¸­æŠ›å‡ºæ›´å‹å¥½çš„é”™è¯¯ä¿¡æ¯ã€‚  
3. **æ€§èƒ½åŸºå‡†**ï¼šCI ä¸­å·²åŠ å…¥å¯é€‰æ€§èƒ½æµ‹è¯•ï¼Œå»ºè®®åœ¨æ­£å¼å‘å¸ƒå‰åœ¨å¸¸ç”¨ batch/dim ç»„åˆä¸Šè·‘ä¸€æ¬¡ï¼Œä»¥ç¡®è®¤ç›¸è¾ƒäº Diffusers å®ç°çš„åŠ é€Ÿæ¯”ä¾‹ã€‚  
4. **å›é€€è·¯å¾„**ï¼š`visual_embedding.py` ä¸­çš„ `_is_cuda` åˆ¤æ–­ä¾èµ– `current_platform.is_cuda()`ï¼Œç¡®ä¿è¯¥å‡½æ•°åœ¨ CPU ç¯å¢ƒè¿”å› `False`ï¼Œå¦åˆ™ä¼šè¯¯è°ƒ CUDA kernel å¯¼è‡´å´©æºƒã€‚  
5. **æ–‡æ¡£å’Œç¤ºä¾‹**ï¼šè¡¥å…… `timestep_embedding` çš„ä½¿ç”¨è¯´æ˜ï¼ˆå‚æ•°æ„ä¹‰ã€dtype æ”¯æŒï¼‰ï¼Œå¹¶åœ¨æ¨¡å‹é…ç½®æ–‡ä»¶ä¸­æ ‡æ˜é»˜è®¤ä½¿ç”¨ JIT å®ç°ã€‚  

æ€»ä½“è€Œè¨€ï¼Œæ­¤æ¬¡æ”¹åŠ¨ä¸º Diffusion ç›¸å…³æ¨¡å‹æä¾›äº†é«˜æ•ˆçš„ CUDA å®ç°ï¼Œæå‡å¤§æ‰¹é‡æ¨ç†é€Ÿåº¦ï¼ŒåŒæ—¶ä¿ç•™äº†åŸæœ‰ CPU/é CUDA å›é€€è·¯å¾„ï¼Œå±äºç¨³å¦¥çš„åŠŸèƒ½å¢å¼ºã€‚è‹¥åç»­éœ€è¦è¿›ä¸€æ­¥æ”¯æŒ `float64` æˆ–è‡ªå®šä¹‰ `max_period`ï¼Œå¯åœ¨ kernel å‚æ•°ä¸­ç›´æ¥æ‰©å±•ã€‚

---

### Use attn tp group in embedding for more models (#17570)
**SHA**: `fb683be` | ğŸ”— [æŸ¥çœ‹æäº¤](https://github.com/sgl-project/sglang/commit/fb683be6eb7c6960f3d37ea91ca836c1b8e4120c)

**ğŸ¯ å˜æ›´ç±»å‹**ï¼šåŠŸèƒ½å¢å¼º  
**âš¡ é‡è¦ç¨‹åº¦**ï¼šğŸŸ¡ ä¸­  
**ğŸ“‹ å˜æ›´æ‘˜è¦**ï¼šåœ¨å¤šä¸ªæ¨¡å‹ï¼ˆBailingâ€‘MoEã€Falconâ€‘H1ã€GLMâ€‘4ã€GPTâ€‘OSSã€LLaMAâ€‘4ã€Qwenâ€‘2/3 ç­‰ï¼‰çš„è¯è¡¨/ä½ç½®åµŒå…¥åˆå§‹åŒ–ä¸­ï¼Œå°†åŸæ¥çš„ `enable_tp` å‚æ•°æ”¹ä¸º `use_attn_tp_group`ï¼Œå¹¶é€šè¿‡ `is_dp_attention_enabled()` åˆ¤æ–­æ˜¯å¦åœ¨ *DPâ€‘Attention* åœºæ™¯ä¸‹ä½¿ç”¨æ³¨æ„åŠ›å±‚çš„ TP ç»„ã€‚  

**ğŸ¯ å½±å“èŒƒå›´**ï¼š  
- `python/sglang/srt/models/*` ä¸­æ‰€æœ‰ä½¿ç”¨ `VocabParallelEmbedding` æˆ– `PPEmbedding` çš„æ¨¡å‹ã€‚  
- å…³è”çš„åˆ†å¸ƒå¼è®­ç»ƒ/æ¨ç†ä»£ç è·¯å¾„ï¼ˆTP/DP ç»„åˆç­–ç•¥ï¼‰ã€‚  

**ğŸ’¡ å…³æ³¨å»ºè®®**ï¼š  
1. **è¡Œä¸ºéªŒè¯**ï¼š`enable_tp=False` ä¸ `use_attn_tp_group=True` åœ¨åº•å±‚å®ç°ä¸Šå¯èƒ½å¹¶ä¸å®Œå…¨ç­‰ä»·ï¼ŒåŠ¡å¿…åœ¨ DPâ€‘Attention ä¸æ™®é€š TP ä¸¤ç§é…ç½®ä¸‹è·‘é€šå•å…ƒæµ‹è¯•å’Œç«¯åˆ°ç«¯æ¨ç†ï¼Œç¡®è®¤åµŒå…¥åˆ‡åˆ†ã€æ¢¯åº¦æ±‡èšç­‰æ²¡æœ‰å›å½’ã€‚  
2. **å…¼å®¹æ€§æ£€æŸ¥**ï¼šæ—§ç‰ˆå‚æ•°ä»åœ¨ä»£ç ä¸­è¢«å¼•ç”¨çš„åœ°æ–¹ï¼ˆå¦‚è‡ªå®šä¹‰æ¨¡å‹æˆ–æ’ä»¶ï¼‰éœ€è¦åŒæ­¥æ›´æ–°ï¼Œå¦åˆ™å¯èƒ½è§¦å‘ `TypeError`ã€‚å»ºè®®åœ¨ `VocabParallelEmbedding` æ„é€ å‡½æ•°ä¸­ä¿ç•™ `enable_tp` çš„å…¼å®¹åˆ«åæˆ–åŠ å…¥è­¦å‘Šã€‚  
3. **æ–‡æ¡£/ç¤ºä¾‹**ï¼šæ›´æ–°æ¨¡å‹é…ç½®æ–‡æ¡£ï¼Œè¯´æ˜ä½•æ—¶ `use_attn_tp_group` ä¸º `True`ï¼ˆå³ DPâ€‘Attention å¯ç”¨æ—¶ï¼‰ï¼Œå¹¶æä¾›å¯¹åº”çš„ `torch.distributed` ç¯å¢ƒå˜é‡ç¤ºä¾‹ã€‚  
4. **æ€§èƒ½ç›‘æ§**ï¼šå¼€å¯/å…³é—­æ³¨æ„åŠ› TP ç»„å¯¹é€šä¿¡æ¨¡å¼æœ‰å½±å“ï¼Œå»ºè®®åœ¨å¤§æ¨¡å‹ï¼ˆ>30Bï¼‰ä¸Šå¯¹æ¯”æ˜¾å­˜å ç”¨ã€é€šä¿¡å¸¦å®½å’Œååç‡ï¼Œç¡®ä¿æ–°è·¯å¾„ä¸å¯¼è‡´é¢å¤–çš„åŒæ­¥å¼€é”€ã€‚  

æ€»ä½“æ¥çœ‹ï¼Œæ­¤æ¬¡æ”¹åŠ¨æ˜¯ä¸ºç»Ÿä¸€ TP æ§åˆ¶ç²’åº¦ï¼Œæå‡åœ¨æ··åˆå¹¶è¡Œåœºæ™¯ä¸‹çš„å¯é…ç½®æ€§ã€‚åªè¦å®Œæˆä¸Šè¿°éªŒè¯ä¸æ–‡æ¡£åŒæ­¥ï¼Œå³å¯å®‰å…¨ä¸Šçº¿ã€‚

---

### Fix: mistake sigmoid in kda (#17508)
**SHA**: `176da1b` | ğŸ”— [æŸ¥çœ‹æäº¤](https://github.com/sgl-project/sglang/commit/176da1bbddbed865759d97942cf8038fdac16e82)

**ğŸ¯ å˜æ›´ç±»å‹**ï¼šBug ä¿®å¤  
**âš¡ é‡è¦ç¨‹åº¦**ï¼šğŸŸ¡ ä¸­  

**ğŸ“‹ å˜æ›´æ¦‚è¦**  
1. åœ¨ `sglang/srt/models/kimi_linear.py` ä¸­çº æ­£äº†å¯¹ `beta` çš„ Sigmoid ä½ç½®ï¼šå…ˆå–æŠ•å½±å¾—åˆ° float å¼ é‡ï¼Œéšååœ¨é decode æ¨¡å¼ä¸‹ç»Ÿä¸€æ‰§è¡Œ `.sigmoid()`ï¼Œé¿å…åœ¨è§£ç è·¯å¾„ä¸­é”™è¯¯æå‰å– Sigmoidã€‚  
2. æ–°å¢ `test/registered/attention/test_kda_kernels.py`ï¼Œé€šè¿‡å¯¹æ¯” `fused_sigmoid_gating_delta_rule_update` ä¸å‚è€ƒå®ç° `fused_kda_gate + fused_recurrent_kda`ï¼ŒéªŒè¯èåˆæ ¸è¡Œä¸ºä¸åŸç®—å­ä¸€è‡´ã€‚

**ğŸ¯ å½±å“èŒƒå›´**  
- `KimiLinearAttentionBackend`ï¼ˆ`kimi_linear.py`ï¼‰çš„å‰å‘è·¯å¾„  
- FLA èåˆå®ç°ï¼š`fused_sigmoid_gating_delta_rule_update`ã€`fused_kda_gate`ã€`fused_recurrent_kda`  
- CI æµ‹è¯•å¥—ä»¶ï¼ˆCUDA CI æ³¨å†Œï¼‰

**ğŸ’¡ å…³æ³¨å»ºè®®**  
- è¿è¡Œå®Œæ•´ CUDA CIï¼Œç¡®è®¤ä¿®æ”¹æœªå¼•å…¥æ•°å€¼åå·®æˆ–æ€§èƒ½å›é€€ã€‚  
- æ£€æŸ¥ decode æ¨¡å¼ä¸‹ä»ä¼šèµ°åˆ° `forward_batch.forward_mode.is_decode()` åˆ†æ”¯ï¼Œç¡®ä¿ `beta` æœªè¢«æå‰ Sigmoidï¼Œä¿æŒåŸæœ‰è¡Œä¸ºã€‚  
- å…³æ³¨ dtype è½¬æ¢ï¼ˆ`float().sigmoid()`ï¼‰æ˜¯å¦åœ¨ mixedâ€‘precision è®­ç»ƒä¸­äº§ç”Ÿé¢å¤–æ‹·è´ï¼Œå¿…è¦æ—¶å¯åœ¨ FP16/BF16 ä¸Šä¿æŒè®¡ç®—ã€‚  
- å°†æ–°å¢çš„å•å…ƒæµ‹è¯•åŠ å…¥æ—¥å¸¸å›å½’ï¼Œé˜²æ­¢æœªæ¥çš„èåˆ kernel æ”¹åŠ¨å†æ¬¡ç ´åä¸€è‡´æ€§ã€‚

---

### fix: nightly wheel naming for non-post versions (#17538)
**SHA**: `58799d9` | ğŸ”— [æŸ¥çœ‹æäº¤](https://github.com/sgl-project/sglang/commit/58799d91a719206f2f8c407c13e7119df3443a46)

**ğŸ¯ å˜æ›´ç±»å‹**ï¼šBug ä¿®å¤  
**âš¡ é‡è¦ç¨‹åº¦**ï¼šğŸŸ¡ ä¸­  

**ğŸ“‹ å˜æ›´æ‘˜è¦**  
æ­¤ PR è°ƒæ•´äº† `release-pypi-nightly.yml` å·¥ä½œæµä¸­ç”Ÿæˆ nightly wheel æ—¶çš„ç‰ˆæœ¬å¤„ç†é€»è¾‘ã€‚æ–°å¢å¯¹ `git describe` çš„è§£æï¼Œæ£€æµ‹æ˜¯å¦åœ¨æ ‡ç­¾ï¼ˆdistance=0ï¼‰ä¸Šæ„å»ºï¼›è‹¥æ˜¯ï¼Œåˆ™å¼ºåˆ¶ä½¿ç”¨ `x.y.z.dev0+<hash>` å½¢å¼çš„ç‰ˆæœ¬ï¼Œä»¥é¿å…åœ¨éâ€‘postï¼ˆå³æ­£å¼ï¼‰æ ‡ç­¾ä¸Šå‡ºç°é‡å¤çš„ wheel åç§°ã€‚  

**ğŸ¯ å½±å“èŒƒå›´**  
- **.github/workflows/release-pypi-nightly.yml**ï¼šå…¨éƒ¨ nightly åŒ…æ„å»ºæµç¨‹ã€‚  
- **setuptoolsâ€‘scm** ç‰ˆæœ¬è§£æï¼šå¼•å…¥ `SETUPTOOLS_SCM_PRETEND_VERSION` ç¯å¢ƒå˜é‡ï¼Œç¡®ä¿ `pyproject.toml` ä¸ CI ä¸­çš„ç‰ˆæœ¬ä¿æŒä¸€è‡´ã€‚  

**ğŸ’¡ å…³æ³¨å»ºè®®**  
- **å¼€å‘è€…**ï¼šåœ¨æœ¬åœ°æˆ– CI ä¸­æ¨¡æ‹Ÿ tagâ€‘zero åœºæ™¯ï¼Œç¡®è®¤å¼ºåˆ¶çš„ `dev0+hash` ç‰ˆæœ¬èƒ½å¤ŸæˆåŠŸå†™å…¥ `setup.cfg` å¹¶ç”Ÿæˆç¬¦åˆ PEPâ€¯440 çš„ wheelï¼›åŒæ—¶éªŒè¯æ™®é€šï¼ˆdistance>0ï¼‰æ„å»ºä»ä½¿ç”¨åŸå§‹ `setuptools_scm` ç”Ÿæˆçš„ç‰ˆæœ¬ã€‚  
- **ç»´æŠ¤è€…**ï¼šæ›´æ–°ç›¸å…³æ–‡æ¡£æˆ– release noteï¼Œè¯´æ˜ nightly åŒ…çš„å‘½åè§„åˆ™å·²ä» â€œpure tagâ€ æ”¹ä¸º â€œdev0+hashâ€ï¼Œé˜²æ­¢ç”¨æˆ·è¯¯ä»¥ä¸ºæ˜¯æ­£å¼å‘å¸ƒã€‚  
- **ç”¨æˆ·**ï¼šå¯¹ä½¿ç”¨ nightly wheel çš„ä½“éªŒåŸºæœ¬æ— å½±å“ï¼Œä»…ä¼šçœ‹åˆ°ä¸åŒçš„ç‰ˆæœ¬å·ï¼›è‹¥åœ¨ä¾èµ–ç®¡ç†ä¸­é”å®šå…·ä½“ç‰ˆæœ¬ï¼Œè¯·æ³¨æ„ `dev0+hash` ä¸æ­£å¼ `x.y.z` çš„åŒºåˆ«ã€‚  

æ€»ä½“æ¥è¯´ï¼Œæ­¤æ”¹åŠ¨æ¶ˆé™¤äº†åœ¨éâ€‘post ç‰ˆæœ¬ä¸Šäº§ç”Ÿé‡å¤ wheel åç§°çš„é£é™©ï¼Œæå‡äº† nightly åŒ…çš„å¯è¿½æº¯æ€§å’Œå‘å¸ƒå®‰å…¨æ€§ã€‚

---

### Refactor: Extract DeepSeek common utilities into shared module (#16969)
**SHA**: `894928a` | ğŸ”— [æŸ¥çœ‹æäº¤](https://github.com/sgl-project/sglang/commit/894928a9512440974032ce49e058d8c2c169b1cf)

**ğŸ¯ å˜æ›´ç±»å‹**ï¼šé‡æ„ï¼ˆæå– DeepSeek å…¬å…±å·¥å…·åˆ°å…±äº«æ¨¡å—ï¼‰  
**âš¡ é‡è¦ç¨‹åº¦**ï¼šğŸŸ¡ ä¸­  

**ğŸ“‹ å˜æ›´æ‘˜è¦**  
- åœ¨ `deepseek_common/utils.py` ä¸­æ–°å¢æ—¥å¿—ã€æ•°å­¦ã€`torch`ã€`QuantizationConfig` ç­‰ä¾èµ–ï¼ŒæŠ½å‡º `yarn_get_mscale`ã€`_get_llama_4_scaling`ã€å¸¸é‡åˆ—è¡¨ä»¥åŠ `_is_cublas_ge_129` çš„å®ç°ã€‚  
- `deepseek_v2.py` åˆ é™¤äº†é‡å¤å®ç°ï¼Œæ”¹ä¸ºä» `deepseek_common.utils` ä¸­å¯¼å…¥ç›¸åŒå‡½æ•°å’Œå¸¸é‡ã€‚  

**ğŸ¯ å½±å“èŒƒå›´**  
- `sglang.srt.models.deepseek_common.utils`ï¼ˆæ–°å»º/æ‰©å±•ï¼‰  
- `sglang.srt.models.deepseek_v2`ï¼ˆè°ƒç”¨è·¯å¾„å˜åŒ–ï¼‰  
- å¯èƒ½å—å½±å“çš„å…¶ä»– DeepSeek ç³»åˆ—æ¨¡å‹ï¼ˆè‹¥ç›´æ¥å¼•ç”¨äº†è¢«æŠ½èµ°çš„å®ç°ï¼‰  

**ğŸ’¡ å…³æ³¨å»ºè®®**  
1. **ä¾èµ–æ£€æŸ¥**ï¼š`utils.py` ç°åœ¨åœ¨æ¨¡å—é¡¶å±‚ç›´æ¥ `import torch`ï¼Œç¡®ä¿æ‰€æœ‰è¿è¡Œç¯å¢ƒå‡å·²è£…å¥½å¯¹åº”çš„ CUDA/CPU ç‰ˆæœ¬ï¼Œé¿å…åœ¨ä»…éœ€ CPU ç¯å¢ƒæ—¶è§¦å‘ä¸å¿…è¦çš„ GPU åˆå§‹åŒ–ã€‚  
2. **å‘åå…¼å®¹**ï¼šè‹¥æœ‰å¤–éƒ¨ä»£ç ä»æ—§ä» `deepseek_v2.py` å¯¼å…¥ `yarn_get_mscale` / `_get_llama_4_scaling`ï¼Œéœ€è¦åŒæ­¥æ›´æ–°å¯¼å…¥è·¯å¾„æˆ–åœ¨æ—§æ–‡ä»¶ä¸­ä¿ç•™å‘åå…¼å®¹çš„åˆ«åã€‚  
3. **æ—¥å¿—ä½¿ç”¨**ï¼š`logger` å·²åˆ›å»ºä½†æœªåœ¨æ–‡ä»¶ä¸­ä½¿ç”¨ï¼Œå»ºè®®åœ¨å…³é”®åˆ†æ”¯ï¼ˆå¦‚ `enable_nextn_moe_bf16_cast_to_fp8`ï¼‰åŠ å…¥è°ƒè¯•ä¿¡æ¯ï¼Œä¾¿äºæ’æŸ¥é‡åŒ–è·¯å¾„æ˜¯å¦è¢«æ¿€æ´»ã€‚  
4. **æµ‹è¯•è¦†ç›–**ï¼šé‡ç‚¹è·‘åŒ…å« FP8ã€FP4ã€MoEã€ä»¥åŠä¸åŒåç«¯ï¼ˆfa3ã€flashinferã€cutlass_mla ç­‰ï¼‰çš„å•å…ƒ/é›†æˆæµ‹è¯•ï¼Œç¡®è®¤æ–°æŠ½å–çš„å¸¸é‡ `FORWARD_ABSORB_CORE_ATTENTION_BACKENDS` ä¸åç«¯æ£€æµ‹é€»è¾‘ä¿æŒä¸€è‡´ã€‚  
5. **æ–‡æ¡£æ›´æ–°**ï¼šåœ¨é¡¹ç›®æ–‡æ¡£æˆ– `README` ä¸­æ ‡æ˜å…¬å…±å·¥å…·å·²è¿ç§»è‡³ `deepseek_common.utils`ï¼Œå¹¶è¯´æ˜ç›¸åº”çš„å¯¼å…¥æ–¹å¼ã€‚  

æ€»ä½“æ¥çœ‹ï¼Œæ­¤æ¬¡é‡æ„æ¶ˆé™¤äº†ä»£ç é‡å¤ï¼Œæå‡äº†å¯ç»´æŠ¤æ€§ï¼›åªè¦ç¡®ä¿å¯¼å…¥è·¯å¾„åŒæ­¥ã€ä¾èµ–ç¯å¢ƒæ»¡è¶³å³å¯å®‰å…¨åˆå¹¶ã€‚

---

### [NPU] solve accuracy problem for stablelm-2-1-6b for npu (#17470)
**SHA**: `b4a611f` | ğŸ”— [æŸ¥çœ‹æäº¤](https://github.com/sgl-project/sglang/commit/b4a611fb334fed48b47d2e9fbd178cdc32c64d58)

**ğŸ¯ å˜æ›´ç±»å‹**ï¼šBug ä¿®å¤ï¼ˆé’ˆå¯¹ NPU ä¸Š StableLMâ€‘2â€‘1â€‘6B çš„å‡†ç¡®ç‡é—®é¢˜ï¼‰  
**âš¡ é‡è¦ç¨‹åº¦**ï¼šğŸŸ¡ ä¸­  
**ğŸ“‹ å˜æ›´æ‘˜è¦**ï¼šåœ¨ `stablelm.py` ä¸­åŠ å…¥ NPU æ£€æµ‹å¹¶ä¸º NPU ç¯å¢ƒä¸‹çš„ Rotaryâ€‘Embedding å¼ºåˆ¶ä½¿ç”¨ `float32`ï¼Œé¿å…å› æ··åˆç²¾åº¦å¯¼è‡´çš„æ•°å€¼è¯¯å·®ï¼›åŒæ—¶åœ¨ CI ä¸­æ–°å¢é’ˆå¯¹ Ascend/NPU çš„æ¨¡å‹å‡†ç¡®ç‡æµ‹è¯•ã€‚  

**ğŸ¯ å½±å“èŒƒå›´**  
- `sglang/srt/models/stablelm.py`ï¼šæ–°å¢ `is_npu` åˆ¤å®šã€å…¨å±€ `_is_npu` å¹¶åœ¨æ„é€ å‡½æ•°ä¸ `forward` ä¸­åˆ†æ”¯å¤„ç† rotaryâ€embedding çš„ dtypeã€‚  
- `sglang/srt/utils.py`ï¼šä¾èµ– `is_npu` å®ç°ï¼ˆè‹¥æœªå¯¼å‡ºä¼šå¯¼è‡´å¯¼å…¥é”™è¯¯ï¼‰ã€‚  
- CI æµ‹è¯•å¥—ä»¶ï¼š`test/registered/ascend/llm_models/test_ascend_stablelm-2-1_6b.py` æ³¨å†Œ NPU nightlyï¼Œæ£€æŸ¥æ¨¡å‹åœ¨ GSM8K ä»»åŠ¡ä¸Šçš„å‡†ç¡®ç‡é˜ˆå€¼ã€‚  

**ğŸ’¡ å…³æ³¨å»ºè®®**  
1. **æ¥å£ä¸€è‡´æ€§**ï¼š`_is_npu` åœ¨æ¨¡å—å¯¼å…¥æ—¶å³ç¡®å®šï¼Œè‹¥è¿›ç¨‹åæœŸåˆ‡æ¢è®¾å¤‡ï¼ˆå¦‚ `CUDA_VISIBLE_DEVICES`ï¼‰å¯èƒ½ä¸ç”Ÿæ•ˆï¼Œå»ºè®®æ”¹ä¸ºå‡½æ•°è°ƒç”¨ `is_npu()` è€Œéå…¨å±€ç¼“å­˜ã€‚  
2. **æ€§èƒ½ä¸å†…å­˜**ï¼šåœ¨ NPU åˆ†æ”¯ä¸­å°† `q/k` æš‚æ—¶å‡ä¸º `float32` å†è½¬å›åŸ dtypeï¼Œè™½èƒ½æå‡æ•°å€¼ç¨³å®šæ€§ï¼Œä½†ä¼šå¢åŠ æ˜¾å­˜ä¸ç®—åŠ›å¼€é”€ï¼Œå»ºè®®åœ¨æ¨¡å‹é…ç½®ä¸­æä¾›å¯é€‰çš„ `--npu-rope-fp32` å¼€å…³ã€‚  
3. **å…¼å®¹æ€§æ£€æŸ¥**ï¼šç¡®è®¤å…¶å®ƒæ¨¡å‹ï¼ˆå¦‚ LLaMAã€ChatGLMï¼‰åœ¨ NPU ä¸Šä¹Ÿä½¿ç”¨ç›¸åŒçš„ rotary å®ç°ï¼Œé¿å…å‡ºç°ç±»ä¼¼ç²¾åº¦åå·®ã€‚  
4. **æµ‹è¯•ç»´æŠ¤**ï¼šCI æ–°å¢çš„ NPU æµ‹è¯•ä¾èµ– Ascend ç¯å¢ƒå’Œæ¨¡å‹ç¼“å­˜è·¯å¾„ï¼Œç¡®ä¿é•œåƒä¸­å·²é¢„è£… `modelscope` å¹¶èƒ½è®¿é—® `/root/.cache/...`ï¼Œå¦åˆ™ CI ä¼šæŠ¥é”™ã€‚  
5. **æ–‡æ¡£æ›´æ–°**ï¼šåœ¨ README/ä½¿ç”¨æŒ‡å—ä¸­æ ‡æ˜åœ¨ Ascend/NPU ä¸Šéœ€è¦é¢å¤–çš„ `--attention-backend ascend` ä¸ `--enable-torch-compile` å‚æ•°ï¼Œå¹¶æç¤ºå¯èƒ½çš„æ˜¾å­˜é…ç½®ï¼ˆå¦‚ `--mem-fraction-static 0.8`ï¼‰ã€‚  

æ•´ä½“æ¥çœ‹ï¼Œæ­¤æ¬¡æ”¹åŠ¨é€šè¿‡å¼ºåˆ¶ FP32 rotary è§£å†³äº† NPU ä¸Šçš„æ•°å€¼è¯¯å·®ï¼Œæå‡äº† StableLMâ€‘2â€‘1â€‘6B çš„æ¨ç†å‡†ç¡®ç‡ï¼Œå½±å“ä¸»è¦å±€é™åœ¨æ¨¡å‹åŠ è½½ä¸å‰å‘è·¯å¾„ï¼Œé£é™©è¾ƒä½ã€‚åç»­å¯è€ƒè™‘åœ¨ `WeightUtils` æˆ– `Attention` å±‚ç»Ÿä¸€å¤„ç† NPU ç‰¹æœ‰çš„ dtype è¦æ±‚ï¼Œä»¥å‡å°‘åˆ†æ”¯æ•£è½ã€‚

---

### [NPU]support model MiniCPM3-4B for npu (#16866)
**SHA**: `8a5ed24` | ğŸ”— [æŸ¥çœ‹æäº¤](https://github.com/sgl-project/sglang/commit/8a5ed2434f1a2f7989a2151c1e5bcc70fbc72910)

**ğŸ¯ å˜æ›´ç±»å‹**ï¼šåŠŸèƒ½å¢å¼ºï¼ˆåœ¨ NPU åç«¯åŠ å…¥ MiniCPM3â€‘4B çš„å…¼å®¹ï¼‰  
**âš¡ é‡è¦ç¨‹åº¦**ï¼šğŸŸ¡ ä¸­  
**ğŸ“‹ å˜æ›´æ‘˜è¦**ï¼š  
1. åœ¨ `ascend_backend.py` ä¸­ï¼Œæ ¹æ®æ¨¡å‹é…ç½®åŠ¨æ€è·å– `qk_nope_head_dim`ï¼Œå¹¶ä¸º MiniCPM3â€‘4B ç‰¹åŒ–äº† Fusedâ€‘Attention çš„åˆ†æ”¯ï¼ˆv_head_dim==256 æ—¶èµ°è‡ªå®šä¹‰ GQA æµç¨‹ï¼‰ã€‚  
2. `rotary_embedding.py` é‡‡ç”¨ `unflatten` æ›¿ä»£æ‰‹åŠ¨ `view`ï¼Œæå‡å¯è¯»æ€§å¹¶è§„é¿ç»´åº¦ä¸åŒ¹é…ã€‚  
3. KVâ€‘Cache åˆå§‹åŒ–æ”¹ä¸ºä»…åœ¨ NPUâ€‘NSA åœºæ™¯ä¼ å…¥ `index_head_dim`ï¼Œé˜²æ­¢é NPU æ¨¡å‹å‡ºç°æ— æ•ˆå‚æ•°ã€‚  
4. `minicpm3.py` ä¸­å¯¹ rotaryâ€‘embedding çš„ reshape æ–¹å¼åšäº†æ˜¾å¼ç»´åº¦å±•å¹³ï¼Œé¿å…æ½œåœ¨çš„ batchâ€‘dim é”™è¯¯ã€‚  
5. æ–°å¢ CI æµ‹ä¾‹ `test_ascend_minicpm3_4b.py`ï¼ŒéªŒè¯æ¨¡å‹åœ¨ Ascend NPU ä¸Šçš„æ¨ç†ç²¾åº¦ã€‚

**ğŸ¯ å½±å“èŒƒå›´**ï¼š  
- `python/sglang/srt/hardware_backend/npu/attention/ascend_backend.py`ï¼ˆæ ¸å¿ƒæ³¨æ„åŠ›å®ç°ï¼‰  
- `python/sglang/srt/layers/rotary_embedding.py`ï¼ˆä½ç½®ç¼–ç ï¼‰  
- KVâ€‘Cache ç›¸å…³åˆå§‹åŒ– (`model_runner_kv_cache_mixin.py`)  
- MiniCPM3â€‘4B æ¨¡å‹å‰å‘ (`models/minicpm3.py`)  
- CI æµ‹è¯•å¥—ä»¶

**ğŸ’¡ å…³æ³¨å»ºè®®**  

1. **æ¨¡å‹è¯†åˆ«å®‰å…¨æ€§**ï¼šå½“å‰é€šè¿‡ `hf_config.architectures` åˆ¤æ–­æ˜¯å¦ä¸º MiniCPM3ï¼Œå»ºè®®è¡¥å…… fallbackï¼ˆå¦‚ `model_type`ï¼‰å¹¶å¯¹æœªçŸ¥æ¶æ„æŠ›å‡ºæ˜ç¡®å¼‚å¸¸ï¼Œé˜²æ­¢è¯¯åˆ¤å¯¼è‡´ dim è®¡ç®—é”™è¯¯ã€‚  
2. **v_head_dim=256 æ¡ä»¶**ï¼šæ­¤åˆ†æ”¯ä»…åœ¨ â€œNO_QUANTâ€ åœºæ™¯ç”Ÿæ•ˆï¼Œä»£ç ä¸­ç¡¬ç¼–ç  `[256]`ï¼Œè‹¥åç»­å‡ºç°å…¶ä»– head_dim éœ€è¦æ‰‹åŠ¨ä¿®æ”¹ã€‚å¯æ”¹ä¸º `if layer.v_head_dim == self.qk_nope_head_dim:` ä¹‹ç±»çš„åŠ¨æ€åˆ¤æ–­ã€‚  
3. **å›¾æ¨¡å¼å…¼å®¹**ï¼š`forward_decode` ä¸­å¯¹ `q_rope` ä¸º `None` çš„ä¿æŠ¤å·²ç»åŠ å…¥ï¼Œä½†ä»ä¿ç•™ `assert self.graph_mode == False`ï¼Œè‹¥æœªæ¥æƒ³åœ¨å›¾æ¨¡å¼ä¸‹è¿è¡Œ MiniCPM3ï¼Œéœ€é‡æ–°è¯„ä¼°æ­¤é™åˆ¶ã€‚  
4. **KVâ€‘Cache å‚æ•°ä¼ é€’**ï¼š`index_head_dim` åœ¨é NSA åœºæ™¯ä¼  `None`ï¼Œè¯·ç¡®è®¤ä¸‹æ¸¸ä»£ç å¯¹ `None` çš„å®¹é”™å¤„ç†ï¼Œå¦åˆ™å¯èƒ½å‡ºç° `TypeError`ã€‚  
5. **æ€§èƒ½å›å½’**ï¼šæ–°åˆ†æ”¯ä¼šé¢å¤–è°ƒç”¨ `torch.ops.npu.npu_fused_infer_attention_score` å‰çš„ `native_attn._run_sdpa_forward_extend`ï¼Œå»ºè®®åœ¨ CI ä¸­åŠ å…¥å¯¹æ‰§è¡Œæ—¶é—´çš„åŸºå‡†æ¯”è¾ƒï¼Œé˜²æ­¢å‡ºç°æ˜¾è‘—çš„å»¶è¿Ÿã€‚  
6. **æµ‹è¯•è¦†ç›–**ï¼šç°æœ‰ CI åªéªŒè¯ MiniCPM3â€‘4Bï¼Œå»ºè®®è¡¥å……å·²æœ‰æ¨¡å‹ï¼ˆå¦‚ Llamaâ€‘2ï¼‰åœ¨åŒä¸€åç«¯çš„è·‘é€šï¼Œä»¥ç¡®ä¿æ”¹åŠ¨ä¸ä¼šç ´åé€šç”¨è·¯å¾„ã€‚  

æ€»ä½“è€Œè¨€ï¼Œæ­¤æ¬¡æäº¤ä¸º NPU å¹³å°å¼•å…¥äº†å¯¹ MiniCPM3â€‘4B çš„ä¸“å±é€‚é…ï¼Œæ”¹åŠ¨é›†ä¸­åœ¨æ³¨æ„åŠ›ç»´åº¦å¤„ç†ä¸ KVâ€‘Cache åˆå§‹åŒ–ï¼Œé£é™©ä¸»è¦åœ¨ç»´åº¦ç¡¬ç¼–ç å’Œæ¨¡å‹è¯†åˆ«çš„é²æ£’æ€§ã€‚å»ºè®®åœ¨åˆå¹¶å‰å®Œæˆä¸Šè¿°å®‰å…¨æ€§æ£€æŸ¥å¹¶æ‰©å±•å›å½’æµ‹è¯•ã€‚

---

### feature: adding openai compatible API request to bench_serving (#17219)
**SHA**: `4c7136b` | ğŸ”— [æŸ¥çœ‹æäº¤](https://github.com/sgl-project/sglang/commit/4c7136bb364d4fdf9ce0f0d31a6d7a92a3457822)

**ğŸ¯ å˜æ›´ç±»å‹**ï¼šåŠŸèƒ½å¢å¼º  
**âš¡ é‡è¦ç¨‹åº¦**ï¼šğŸŸ¡ ä¸­  

**ğŸ“‹ å˜æ›´æ‘˜è¦**  
- åœ¨ `bench_serving.py` ä¸­åŠ å…¥å¯¹ OpenAIâ€‘compatible Chat/Completion API çš„å®Œæ•´è¯·æ±‚æ„é€ ï¼Œæ”¯æŒ `temperatureã€ignore_eos` ç­‰é»˜è®¤å€¼å¯è¢« `extra_request_body` è¦†ç›–ã€‚  
- æ–°å¢ `openai` æ•°æ®é›†å…¥å£ã€`sample_openai_requests` è§£æ JSONL å¹¶æŠŠé™¤ `messagesã€max_tokens` ä¹‹å¤–çš„å­—æ®µä¿å­˜åˆ° `DatasetRow.extra_request_body`ã€‚  
- æ”¹è¿›å¤šè½®åˆ¤å®šé€»è¾‘ã€å…¨å±€/å•æ¡ `extra_request_body` åˆå¹¶é¡ºåºï¼Œå¹¶æŠŠ CLI é€‰é¡¹æ‰©å±•ä¸º `openai`ã€‚  

**ğŸ¯ å½±å“èŒƒå›´**  
- **æ ¸å¿ƒè¯·æ±‚å±‚**ï¼š`async_request_openai_completions / async_request_openai_chat_completions` çš„ payload ç»„è£…ã€‚  
- **æ•°æ®åŠ è½½**ï¼š`get_dataset`ã€`sample_openai_requests`ã€`DatasetRow` æ–°å¢å­—æ®µã€‚  
- **è°ƒåº¦ä¸é™æµ**ï¼š`limited_request_func` ä¸­çš„ `merged_extra_body` åˆå¹¶ã€‚  
- **å‘½ä»¤è¡Œ**ï¼š`--dataset-name` æ”¯æŒ `openai`ã€‚  

**ğŸ’¡ å…³æ³¨å»ºè®®**  
1. **å…¼å®¹æ€§**ï¼šç¡®ä¿æ—§çš„ `sharegpt`ã€`custom` æ•°æ®é›†åœ¨ä¸ä¼  `extra_request_body` æ—¶ä»ä¿æŒåŸæœ‰é»˜è®¤ï¼ˆ`temperature=0.0`ã€`ignore_eos` å–å†³äº `--disableâ€‘ignoreâ€‘eos`ï¼‰ã€‚  
2. **å­—æ®µå†²çª**ï¼šå½“å‰ `payload.update(extra_request_body)` ä¼šè¦†ç›–æ‰€æœ‰é»˜è®¤é”®ï¼Œå»ºè®®åœ¨æ–‡æ¡£ä¸­æ˜ç¡®å“ªäº›é”®å¯è¢«è¦†ç›–ï¼Œé˜²æ­¢æ„å¤–æŠŠ `model`ã€`max_tokens` ä¹‹ç±»å…³é”®å­—æ®µè¯¯æ”¹ã€‚  
3. **é”™è¯¯å®¹å¿**ï¼š`sample_openai_requests` å¯¹éæ³• JSON è¡Œç›´æ¥ `continue`ï¼Œå¯èƒ½å¯¼è‡´æ•°æ®é‡ä¸ç¬¦ï¼›å»ºè®®åœ¨è°ƒè¯•æ¨¡å¼ä¸‹æ‰“å°è¢«è·³è¿‡çš„è¡Œæˆ–æä¾›ç»Ÿè®¡ã€‚  
4. **token ç»Ÿè®¡**ï¼šå·¥å…·åˆ—è¡¨çš„ token è®¡æ•°é‡‡ç”¨ `json.dumps` å†ç¼–ç ï¼Œè‹¥å·¥å…·å†…å®¹è¾ƒå¤§å¯èƒ½é«˜ä¼°æˆ–ä½ä¼°ï¼Œå»ºè®®ä¸å®˜æ–¹ OpenAI client çš„è®¡æ•°ä¿æŒä¸€è‡´ã€‚  
5. **æ€§èƒ½**ï¼š`payload.update` ä¸å¤šæ¬¡ `if` æ£€æŸ¥äº§ç”Ÿçš„å¾®å°å¼€é”€åœ¨é«˜å¹¶å‘ä¸‹å¯å¿½ç•¥ï¼Œä½†è‹¥å¤§è§„æ¨¡åŸºå‡†æµ‹è¯•å‡ºç°å¼‚å¸¸ï¼Œè¯·ç¡®è®¤ `extra_request_body` çš„æ·±æ‹·è´ä¸ä¼šå¯¼è‡´å…±äº«çŠ¶æ€ã€‚  
6. **æµ‹è¯•**ï¼šæ–°å¢å•å…ƒ/é›†æˆæµ‹è¯•ï¼Œè¦†ç›–ï¼šâ‘  OpenAI æ•°æ®é›†åŠ è½½ï¼›â‘¡ `extra_request_body` è¦†ç›–é»˜è®¤ï¼›â‘¢ å¤šè½®ï¼ˆlist[str]ï¼‰ä¸ OpenAI æ¶ˆæ¯ï¼ˆlist[dict]ï¼‰çš„åˆ¤å®šåˆ†æ”¯ã€‚  
7. **æ–‡æ¡£**ï¼šæ›´æ–° README ä¸ CLI å¸®åŠ©ï¼Œè¯´æ˜ `--dataset-name openai` éœ€è¦çš„ JSONL æ ¼å¼åŠ `extra_request_body` çš„ä½¿ç”¨æ–¹å¼ã€‚

---

### [MUSA][2/N] sgl-kernel build (#17053)
**SHA**: `628ab5d` | ğŸ”— [æŸ¥çœ‹æäº¤](https://github.com/sgl-project/sglang/commit/628ab5d57b333f152386867ef24397ca7ca3c963)

**ğŸ¯ å˜æ›´ç±»å‹**ï¼šåŠŸèƒ½å¢å¼º  
**âš¡ é‡è¦ç¨‹åº¦**ï¼šğŸŸ¡ ä¸­  

**ğŸ“‹ å˜æ›´æ‘˜è¦**  
æœ¬æ¬¡æäº¤ä¸º SGLang å¢åŠ å¯¹ **Mooreâ€¯Threadsï¼ˆMUSAï¼‰GPU** çš„æ”¯æŒã€‚æ ¸å¿ƒå·¥ä½œåŒ…æ‹¬ï¼š  
1. åœ¨ `.gitignore` ä¸­åŠ å…¥ MUSA ç›¸å…³çš„ç”Ÿæˆæ–‡ä»¶å’Œç¬¬ä¸‰æ–¹æºç è·¯å¾„ã€‚  
2. æ–°å¢æ–‡æ¡£ `docs/platforms/mthreads_gpu.md`ï¼Œç»™å‡ºä»æºç ç¼–è¯‘ã€å®‰è£…çš„å®Œæ•´æ­¥éª¤ã€‚  
3. åœ¨ `sglâ€‘kernel` ä¸­æ·»åŠ  `common_extension_musa.cc`ï¼Œå®ç°ä¸€ç³»åˆ—é‡‡æ ·ã€å½’ä¸€åŒ–ç­‰ç®—å­å¹¶ä½¿ç”¨ `TORCH_LIBRARY_EXPAND` æ³¨å†Œåˆ° `torch::kMUSA`ã€‚  
4. æ–°å¢ `pyproject_musa.toml` ä¸ `setup_musa.py`ï¼ŒåŸºäº `torchada` ä¸ MUSA ç¼–è¯‘å™¨ï¼ˆ`mcc`ï¼‰ç¼–è¯‘ä¸Šè¿°ç®—å­ï¼Œå¹¶åœ¨æ„å»ºå‰è‡ªåŠ¨å…‹éš† `flashinfer`ã€`mutlass` ä¸¤ä¸ªç¬¬ä¸‰æ–¹ä»“åº“ã€‚  

**ğŸ¯ å½±å“èŒƒå›´**  
- **sglâ€‘kernel**ï¼šæ–°å¢ `csrc/common_extension_musa.cc`ã€ç¼–è¯‘è„šæœ¬ä¸ä¾èµ–é…ç½®ã€‚  
- **Python åŒ…**ï¼š`python/sglang` çš„å¯é€‰ä¾èµ– `all_musa` ç”± `pyproject_musa.toml` æä¾›ã€‚  
- **æ„å»ºç³»ç»Ÿ**ï¼š`setup_musa.py` æ›¿ä»£åŸæœ‰ `setup.py` ç”¨äº MUSA ç¯å¢ƒï¼›`torchada` æˆä¸ºå¿…è£…ä¾èµ–ã€‚  

**ğŸ’¡ å…³æ³¨å»ºè®®**  
1. **ä¾èµ–å…¼å®¹æ€§**ï¼š`torchada>=0.1.14` ä¸å½“å‰ PyTorch/MUSA ç‰ˆæœ¬éœ€ä¿æŒåŒ¹é…ï¼Œå»ºè®®åœ¨ CI ä¸­åŠ å…¥ç‰ˆæœ¬æ£€æµ‹ã€‚  
2. **ç¡¬ä»¶æ£€æµ‹**ï¼š`torch.musa.is_available()` çš„åˆ†æ”¯åœ¨ç¼ºå¤± MUSA ç¯å¢ƒæ—¶ç›´æ¥ `sys.exit(1)`ï¼Œå¯èƒ½å¯¼è‡´åœ¨çº¯ CPU/CUDA ç¯å¢ƒä¸‹æ„å»ºå¤±è´¥ã€‚å¯è€ƒè™‘åœ¨ `setup_musa.py` ä¸­æä¾› `--skip-musa` é€‰é¡¹æˆ–åœ¨ `pyproject.toml` ä¸­ä½¿ç”¨ extrasã€‚  
3. **ç¬¬ä¸‰æ–¹æºç å®‰å…¨**ï¼šå…‹éš† `flashinfer`ã€`mutlass` æ—¶é»˜è®¤ `git fetch --all`ï¼Œå»ºè®®å›ºå®š `--depth 1` ä»¥é™ä½ç½‘ç»œä¸æ„å»ºæ—¶é—´ï¼ŒåŒæ—¶æ£€æŸ¥ä»“åº“è®¸å¯è¯å…¼å®¹æ€§ã€‚  
4. **ç¼–è¯‘å‚æ•°**ï¼š`mcc` æ ‡å¿—ä¸­ç¡¬ç¼–ç äº† `-mtgpu`ã€`-x musa` ç­‰ï¼Œè‹¥æœªæ¥ MUSA ç¼–è¯‘å™¨æ›´æ”¹å‚æ•°éœ€åŒæ­¥æ›´æ–°ã€‚  
5. **æµ‹è¯•è¦†ç›–**ï¼šæ–°å¢ç®—å­ä»…åœ¨ `common_extension_musa.cc` ä¸­å®ç°ï¼Œéœ€è¡¥å……å•å…ƒæµ‹è¯•ï¼Œç¡®ä¿åœ¨ä¸åŒ `top_k / top_p / min_p` åœºæ™¯ä¸‹è¡Œä¸ºä¸€è‡´ã€‚  

æ€»ä½“è€Œè¨€ï¼Œæ”¹åŠ¨ä¸º SGLang åœ¨ MUSA å¹³å°æä¾›äº†å®Œæ•´çš„ç®—å­å®ç°å’Œæ„å»ºé“¾è·¯ï¼Œè‹¥åœ¨ CI ä¸­åŠ å…¥å¤šå¹³å°ï¼ˆCPUã€CUDAã€MUSAï¼‰éªŒè¯ï¼Œå¯è¿›ä¸€æ­¥æå‡å‘å¸ƒçš„ç¨³å¥æ€§ã€‚

---

### [MUSA][1/N] sglang.check_env (#16959)
**SHA**: `a77729a` | ğŸ”— [æŸ¥çœ‹æäº¤](https://github.com/sgl-project/sglang/commit/a77729a2760206c4de048bdbe3dedb08d3235766)

**ğŸ¯ å˜æ›´ç±»å‹**ï¼šåŠŸèƒ½å¢å¼ºï¼ˆæ–°å¢å¯¹ MThreadsâ€¯MUSA GPU ç¯å¢ƒçš„æ£€æµ‹ï¼‰  
**âš¡ é‡è¦ç¨‹åº¦**ï¼šğŸŸ¡ ä¸­  
**ğŸ“‹ å˜æ›´æ‘˜è¦**ï¼š  
1. åœ¨ `python/sglang/check_env.py` ä¸­åŠ å…¥ `MUSAEnv` ç±»ï¼Œå®ç° MUSA è®¾å¤‡å¯ç”¨æ€§ã€ç‰ˆæœ¬ã€é©±åŠ¨ã€æ‹“æ‰‘ç­‰ä¿¡æ¯çš„æ”¶é›†ã€‚  
2. `sglang.srt.utils.common.is_musa` æ–°å¢ï¼Œç”¨äºåˆ¤æ–­æ˜¯å¦åœ¨ MUSA ç¯å¢ƒï¼ˆé€šè¿‡ `torch.version.musa` æ£€æµ‹ï¼‰ã€‚  
3. `pyproject_other.toml` ç§»é™¤ `bidict` ä¾èµ–ï¼ˆå¯èƒ½æ˜¯æ¸…ç†æ— å…³ä¾èµ–ï¼‰ã€‚  
4. åœ¨ä¸»å…¥å£æ ¹æ® `is_musa()` é€‰æ‹© `MUSAEnv` å®ä¾‹è¿›è¡Œæ£€æŸ¥ã€‚

**ğŸ¯ å½±å“èŒƒå›´**ï¼š  
- `sglang/check_env.py`ï¼ˆæ–°å¢ç±» & å…¥å£åˆ†æ”¯ï¼‰  
- `sglang/srt/utils/common.py`ï¼ˆæ–°å¢ `is_musa` æ£€æµ‹ï¼‰  
- `pyproject_other.toml`ï¼ˆä¾èµ–åˆ—è¡¨å˜åŠ¨ï¼‰  

**ğŸ’¡ å…³æ³¨å»ºè®®**ï¼š  
1. **ä¾èµ–å£°æ˜**ï¼š`is_musa` ä½¿ç”¨äº† `torchada`ï¼ˆå®é™…åº”ä¸º `torch_musa`ï¼‰ï¼Œä½†é¡¹ç›®çš„ `requirements` æœªæ˜¾å¼æ·»åŠ  `torch_musa`ï¼Œå»ºè®®åœ¨å¯¹åº” `extra` æˆ– `requirements` ä¸­è¡¥å……ï¼Œä»¥é˜²ç”¨æˆ·åœ¨é MUSA ç¯å¢ƒæ‰§è¡Œæ—¶æŠ¥é”™ã€‚  
2. **å®¹é”™å¤„ç†**ï¼š`MUSAEnv._get_mcc_info`ã€`_get_musa_driver_version`ã€`get_topology` å‡æ•è· `subprocess.SubprocessError`ï¼Œä½†æœªæ•è· `FileNotFoundError`ï¼ˆå¦‚ `mthreads-gmi` æœªå®‰è£…ï¼‰ï¼Œå»ºè®®ç»Ÿä¸€æ•è· `Exception` å¹¶è¿”å› â€œNot Availableâ€ã€‚  
3. **æµ‹è¯•è¦†ç›–**ï¼šåœ¨ CI ä¸­æ–°å¢ MUSA ç¯å¢ƒçš„æ¨¡æ‹Ÿæµ‹è¯•ï¼ˆå¯ä»¥é€šè¿‡ mock `torch.musa.is_available`ã€`subprocess` è¾“å‡ºï¼‰ç¡®ä¿ä»£ç è·¯å¾„ä¸è¢«ç ´åã€‚  
4. **æ–‡æ¡£æ›´æ–°**ï¼šREADME/INSTALL ä¸­åŠ å…¥ MUSA æ”¯æŒè¯´æ˜ï¼Œåˆ—å‡ºé¢å¤–çš„ç³»ç»Ÿä¾èµ–ï¼ˆMCCã€mthreadsâ€‘gmiï¼‰ä»¥åŠ `torch_musa` å®‰è£…æ–¹æ³•ã€‚  
5. **å…¼å®¹æ€§**ï¼š`is_musa` é€šè¿‡ `import torchada`ï¼ˆå¯èƒ½æ˜¯ç¬”è¯¯ï¼‰ï¼Œå¦‚æœå®é™…å¯¼å…¥å¤±è´¥ä¼šå¯¼è‡´ `is_musa()` æ°¸è¿œè¿”å› `False`ï¼Œè¯·ç¡®è®¤å¯¼å…¥çš„åŒ…åæ˜¯ `torch_musa`ï¼Œå¹¶åœ¨ `except ImportError` ä¸­è®°å½•æ—¥å¿—æ–¹ä¾¿æ’æŸ¥ã€‚  

æ€»ä½“è€Œè¨€ï¼Œæ­¤æ¬¡æ”¹åŠ¨ä¸º MUSA GPU æä¾›äº†å®Œæ•´çš„ç¯å¢ƒæ£€æµ‹åŠŸèƒ½ï¼Œæå‡äº†è·¨ç¡¬ä»¶çš„å¯ç”¨æ€§ã€‚ä½†éœ€è¦å®Œå–„ä¾èµ–å£°æ˜ã€é”™è¯¯å®¹å¿ä»¥åŠç›¸åº”çš„æµ‹è¯•/æ–‡æ¡£ï¼Œä»¥é¿å…åœ¨é MUSA ç¯å¢ƒå‡ºç°éšè—çš„ import æˆ–å­è¿›ç¨‹é”™è¯¯ã€‚

---

### Add return routed experts to the completions and chat/completions endpoints (#17434)
**SHA**: `bdaa3de` | ğŸ”— [æŸ¥çœ‹æäº¤](https://github.com/sgl-project/sglang/commit/bdaa3de07567afd3295b762df5fc0b09f6318d29)

**ğŸ¯ å˜æ›´ç±»å‹**ï¼šåŠŸèƒ½å¢å¼º  
**âš¡ é‡è¦ç¨‹åº¦**ï¼šğŸŸ¡ ä¸­  
**ğŸ“‹ å˜æ›´æ‘˜è¦**ï¼šä¸º OpenAIâ€‘compatible `/v1/completions`ã€`/v1/chat/completions` ä»¥åŠåŸç”Ÿ `/generate` æ¥å£æ–°å¢ `return_routed_experts` å‚æ•°ï¼Œæ”¯æŒåœ¨ MoEï¼ˆMixtureâ€‘ofâ€‘Expertsï¼‰æ¨¡å‹æ¨ç†æ—¶è¿”å›è·¯ç”±ä¸“å®¶ä¿¡æ¯ã€‚å®ç°æ–¹å¼æ˜¯ï¼šåœ¨è¯·æ±‚æ¨¡å‹æ—¶é€ä¼ è¯¥æ ‡è®° â†’ åç«¯åœ¨ `meta_info` ä¸­æºå¸¦ `routed_experts`ï¼ˆBase64â€‘encoded int32ï¼‰ â†’ é€šè¿‡æ–°å¢çš„ `SglExt` æ‰©å±•ç»“æ„åœ¨å“åº”çš„ `sgl_ext.routed_experts` å­—æ®µä¸­è¿”å›ï¼Œå…¼å®¹æµå¼ä¸éæµå¼ä¸¤ç§è¿”å›æ¨¡å¼ã€‚

**ğŸ¯ å½±å“èŒƒå›´**  
- `python/sglang/srt/entrypoints/openai/protocol.py`ï¼ˆè¯·æ±‚/å“åº”æ¨¡å‹å¢åŠ å­—æ®µï¼‰  
- `serving_chat.py`ã€`serving_completions.py`ï¼ˆæµå¼/éæµå¼æ„é€ ã€è·¯ç”±ä¸“å®¶å¤„ç†ï¼‰  
- `utils.py`ã€`detokenizer_manager.py`ï¼ˆä¸“å®¶ä¿¡æ¯æå–ã€Base64 ç¼–ç ï¼‰  
- æ–‡æ¡£ `basic_usage/*.ipynb`ã€`sampling_params.md`ï¼ˆä½¿ç”¨è¯´æ˜ï¼‰  
- æ–°å¢æµ‹è¯• `test/registered/rl/test_return_routed_experts.py`  

**ğŸ’¡ å…³æ³¨å»ºè®®**  

1. **å‘åå…¼å®¹**ï¼šå·²åœ¨åºåˆ—åŒ–é˜¶æ®µå‰”é™¤ `None`ï¼Œä½†å»ºè®®åœ¨æ¥å£è¯´æ˜ä¸­å†æ¬¡æ˜ç¡® `sgl_ext` åªåœ¨ `return_routed_experts=True` ä¸”æœåŠ¡å™¨å¯ç”¨ `--enable-return-routed-experts` æ—¶å‡ºç°ï¼Œé˜²æ­¢è€å®¢æˆ·ç«¯è¯¯è§£æã€‚  
2. **æ ‡å¿—æ ¡éªŒ**ï¼šç›®å‰å‰ç«¯ä»…åœ¨ `request.return_routed_experts` ä¸º `True` æ—¶å‘é€ `routed_experts`ï¼›è‹¥æœåŠ¡å™¨æœªå¼€å¯å¯¹åº” flagï¼Œè¿”å› 400/500 é”™è¯¯åº”ç»™å‡ºæ˜ç¡®æç¤ºï¼Œé¿å…ç”¨æˆ·åœ¨æ—¥å¿—ä¸­çœ‹åˆ°â€œå­—æ®µç¼ºå¤±â€ã€‚  
3. **æ€§èƒ½ä¸å†…å­˜**ï¼šè·¯ç”±ä¿¡æ¯çš„ Base64 ç¼–ç ä¼šåœ¨æ¯ä¸ª token ä¸Šäº§ç”Ÿé¢å¤–å­—ç¬¦ä¸²ï¼Œå»ºè®®åœ¨ `process_routed_experts_from_ret` ä¸­åŠ å…¥å¯¹ `routed_experts` é•¿åº¦çš„ä¸Šé™æˆ–åœ¨æ–‡æ¡£ä¸­ç»™å‡ºä½¿ç”¨å»ºè®®ï¼ˆå¦‚ä»…åœ¨è°ƒè¯•/åˆ†æé˜¶æ®µå¼€å¯ï¼‰ã€‚  
4. **æµ‹è¯•è¦†ç›–**ï¼šæ–°å¢äº†å¯¹ä¸‰ç±» endpoint çš„è¦†ç›–ï¼Œå»ºè®®å†è¡¥å……ä¸€ä¸ªæ™®é€šï¼ˆé MoEï¼‰æ¨¡å‹çš„è¯·æ±‚ï¼Œç¡®ä¿åœ¨ä¸æ»¡è¶³æ¡ä»¶æ—¶ `sgl_ext` å®Œå…¨ç¼ºå¤±ï¼Œä¸äº§ç”Ÿç©ºå¯¹è±¡ã€‚  
5. **ç±»å‹å®‰å…¨**ï¼š`SglExt.routed_experts` ä»é‡‡ç”¨ `Optional[str]`ï¼Œè‹¥åç»­éœ€è¦è§£æä¸º `np.ndarray`ï¼Œå¯è€ƒè™‘æä¾› `decode_routed_experts` è¾…åŠ©å‡½æ•°ï¼Œä»¥å…åœ¨ç”¨æˆ·ä¾§è‡ªè¡Œå¤„ç† Base64/`int32` è½¬æ¢ã€‚  

æ€»ä½“æ¥çœ‹ï¼Œæ”¹åŠ¨å®ç°æ¸…æ™°ï¼Œå¯¹ç°æœ‰åŠŸèƒ½å½±å“æœ‰é™ï¼Œå»ºè®®åœ¨å‘å¸ƒå‰åŠ å…¥ä¸Šè¿°å…¼å®¹æ€§å’Œé”™è¯¯å¤„ç†ç»†èŠ‚ï¼Œä»¥æå‡ç”¨æˆ·ä½“éªŒã€‚

---

### [Refactor] Algebraic data type for nextn config + some basic refactors (#17347)
**SHA**: `010c17a` | ğŸ”— [æŸ¥çœ‹æäº¤](https://github.com/sgl-project/sglang/commit/010c17a133fa7443f83a18dfff1218e40dae335c)

**ğŸ¯ å˜æ›´ç±»å‹**ï¼šé‡æ„ + åŠŸèƒ½å¢å¼º  
**âš¡ é‡è¦ç¨‹åº¦**ï¼šğŸŸ¡ ä¸­

**ğŸ“‹ å˜æ›´æ‘˜è¦**  
1. ä¸º NextNï¼ˆæ¨æµ‹è§£ç ï¼‰é…ç½®å¼•å…¥ä»£æ•°æ•°æ®ç±»å‹ï¼ˆADTï¼‰ï¼Œä½¿ç”¨ `@dataclass` å®šä¹‰ `NextNEnabledConfig` ä¸ `NextNDisabledConfig`ï¼Œå¹¶é€šè¿‡ `NextNConfig = Enabled | Disabled` ç»Ÿä¸€ç±»å‹ã€‚  
2. å°†åŸæ¥æ•£è½åœ¨ `do_load_weights`ã€`_maybe_quant_weights_to_fp8_ue8m0` ç­‰æ–¹æ³•ä¸­çš„ NextN é€»è¾‘æŠ½å–åˆ° `_initialize_nextn_conf`ï¼Œå¹¶ä½¿ç”¨ `match â€¦ case` å¯¹é…ç½®è¿›è¡Œåˆ†æ”¯å¤„ç†ï¼Œæ¶ˆé™¤äº†å¤§é‡ `if is_nextn` æ¡ä»¶ã€‚  
3. ç›¸åº”åœ°è°ƒæ•´äº†æƒé‡åç§°æ˜ å°„ã€FP8 é‡åŒ–è·¯å¾„ä»¥åŠåç½®å¤„ç†ï¼Œä½¿å…¶ç»Ÿä¸€ä¾èµ– `NextNConfig`ï¼Œæå‡ä»£ç å¯è¯»æ€§å’Œå¯ç»´æŠ¤æ€§ã€‚

**ğŸ¯ å½±å“èŒƒå›´**  
- `python/sglang/srt/models/deepseek_common/deepseek_weight_loader.py`ï¼ˆæ ¸å¿ƒæƒé‡åŠ è½½é€»è¾‘ï¼‰  
- å¯èƒ½æ³¢åŠåˆ°è°ƒç”¨ `DeepseekV2WeightLoaderMixin.do_load_weights` çš„æ¨¡å‹åˆå§‹åŒ–è·¯å¾„ï¼ˆDeepSeek V2/V3ï¼‰  
- ä¸ç¯å¢ƒå˜é‡ `SGLANG_NVFP4_CKPT_FP8_*`ã€`quant_config` äº¤äº’çš„é‡åŒ–æ¨¡å—ã€‚

**ğŸ’¡ å…³æ³¨å»ºè®®**  
1. **å‘åå…¼å®¹**ï¼š`_initialize_nextn_conf` å¯¹ç¼ºå¤± `num_nextn_predict_layers` æŠ›å‡º `ValueError`ï¼Œè¯·ç¡®è®¤æ‰€æœ‰ä½¿ç”¨è¯¥ Mixin çš„æ¨¡å‹é…ç½®å·²ç»åŒ…å«è¯¥å­—æ®µï¼Œæˆ–åœ¨ä¸Šå±‚æä¾›å…¼å®¹å±‚ã€‚  
2. **å•æµ‹è¦†ç›–**ï¼šæ–°å¢çš„ `NextNConfig` åˆ†æ”¯åº”åˆ†åˆ«åœ¨æ™®é€šæƒé‡åŠ è½½ã€NextN æƒé‡åŠ è½½ã€ä»¥åŠ FP8 é‡åŒ–ä¸‰ç§åœºæ™¯ä¸‹åŠ å…¥å•å…ƒæµ‹è¯•ï¼Œç¡®ä¿ `match â€¦ case` è¡Œä¸ºåœ¨ä¸åŒ Python ç‰ˆæœ¬ï¼ˆ3.10+ï¼‰ä¸‹ä¸€è‡´ã€‚  
3. **æ€§èƒ½ç›‘æ§**ï¼š`match` ç»“æ„æœ¬èº«å¼€é”€æå°ï¼Œä½†æ–°å¢çš„ `partial_names` æ„é€ è·¯å¾„åœ¨å¤§æ¨¡å‹ä¸Šä»ä¼šéå†å…¨éƒ¨å±‚ï¼Œå»ºè®®åœ¨ `envs.SGLANG_NVFP4_CKPT_FP8_GEMM_IN_ATTN` ä¸º `False` æ—¶æå‰è¿”å›ï¼Œé¿å…ä¸å¿…è¦çš„åˆ—è¡¨æ„å»ºã€‚  
4. **æ–‡æ¡£æ›´æ–°**ï¼šåœ¨é¡¹ç›®æ–‡æ¡£æˆ–é…ç½®è¯´æ˜ä¸­è¡¥å…… `NextNEnabledConfig`ã€`NextNDisabledConfig` çš„å­—æ®µå«ä¹‰ï¼Œå°¤å…¶æ˜¯ `nextn_spec_weight_names` ä¸å®é™…æ¨¡å‹å±‚å¯¹åº”å…³ç³»ã€‚  

æ€»ä½“è€Œè¨€ï¼Œæ­¤æ¬¡é‡æ„æå‡äº† NextN ç›¸å…³ä»£ç çš„ç»“æ„åŒ–ç¨‹åº¦ï¼Œé™ä½äº†åˆ†æ”¯å¤æ‚åº¦ï¼Œè‹¥é…å¥—çš„å…¼å®¹æ€§æ£€æŸ¥ä¸æµ‹è¯•åˆ°ä½ï¼Œå°†å¯¹åç»­åŠŸèƒ½æ‰©å±•ï¼ˆå¦‚å¤šå±‚ NextNï¼‰æä¾›æ›´ç¨³å›ºçš„åŸºåº§ã€‚

---

#### ğŸŸ¢ ä½é‡è¦åº¦å˜æ›´ (9)

### [NPU] torch_npu profiler tensorboard path type fix (#17545)
**SHA**: `458a43d` | ğŸ”— [æŸ¥çœ‹æäº¤](https://github.com/sgl-project/sglang/commit/458a43d4acc20b41a610e024bf01cf8823838852)

**ğŸ¯ å˜æ›´ç±»å‹**ï¼šä»£ç é‡æ„  
**âš¡ é‡è¦ç¨‹åº¦**ï¼šğŸŸ¢ä½  
**ğŸ“‹ æ‘˜è¦**ï¼šå°† `torch_npu.profiler.tensorboard_trace_handler` çš„è·¯å¾„å‚æ•°ä» `Path` å¯¹è±¡æ”¹ä¸º `str`ï¼Œä¿®å¤ NPU ç¯å¢ƒä¸‹ profiler è¾“å‡ºç›®å½•ç±»å‹é”™è¯¯ã€‚

---

### [Bugfix] fix TypeError when log-requests-level >=2 in prefill node warmup (#17129)
**SHA**: `bf19d20` | ğŸ”— [æŸ¥çœ‹æäº¤](https://github.com/sgl-project/sglang/commit/bf19d20d89eebb74c8e7d5f1267daceb3f266600)

**ğŸ¯ å˜æ›´ç±»å‹**ï¼šä»£ç é‡æ„  
**âš¡ é‡è¦ç¨‹åº¦**ï¼šğŸŸ¢ä½  
**ğŸ“‹ æ‘˜è¦**ï¼šåœ¨ `log_received_request` ä¸­åŠ å…¥å¯¹ `obj.input_ids` ä¸ºäºŒç»´åˆ—è¡¨çš„åˆ¤æ–­ï¼Œé‡‡ç”¨å¾ªç¯è§£ç é¿å… `TypeError`ï¼Œä¿®å¤é¢„å¡«èŠ‚ç‚¹çƒ­èº«æ—¥å¿—è®°å½•é”™è¯¯ã€‚

---

### [Auto Sync] Update test_deterministic.py (20260124) (#17665)
**SHA**: `0834f9a` | ğŸ”— [æŸ¥çœ‹æäº¤](https://github.com/sgl-project/sglang/commit/0834f9afebfe343e4021e4120fd2c70892436ee3)

**ğŸ¯ å˜æ›´ç±»å‹**ï¼šæµ‹è¯•ä¿®æ”¹  
**âš¡ é‡è¦ç¨‹åº¦**ï¼šğŸŸ¢ä½  
**ğŸ“‹ æ‘˜è¦**ï¼š`test_deterministic.py` ä¸­æ”¹è¿›æ—¥å¿—è¾“å‡ºï¼Œæ”¹ä¸ºæ˜¾ç¤ºæœ«å°¾10ä¸ª logprobã€å·®å¼‚ç­‰ï¼›å°†éšæœºå‰ç¼€é•¿åº¦ä» 64 æ”¹ä¸º 100ï¼Œç”Ÿæˆ token æ•°ä» 2 æ”¹ä¸ºå¯é…ç½®çš„ 2ï¼Œå¹¶ç›¸åº”æ›´æ–°å‰ç¼€/ç¼“å­˜è¯´æ˜çš„æ‰“å°ä¿¡æ¯ã€‚æ•´ä½“ä¸ºæå‡å¯è¯»æ€§å’Œæµ‹è¯•çµæ´»æ€§ã€‚

---

### [JIT Kernel]Add Some CUDA Runtime API Wrapper for JIT Kernel Header (#17588)
**SHA**: `4c512a7` | ğŸ”— [æŸ¥çœ‹æäº¤](https://github.com/sgl-project/sglang/commit/4c512a7d1d56c68f9e1cada4936a7f9048e6b2b6)

**ğŸ¯ å˜æ›´ç±»å‹**ï¼šä»£ç é‡æ„  
**âš¡ é‡è¦ç¨‹åº¦**ï¼šğŸŸ¢ä½  
**ğŸ“‹ æ‘˜è¦**ï¼šä¸º JIT Kernel æ·»åŠ  CUDA Runtime API åŒ…è£…å‡½æ•°ï¼Œæ–°å¢è·å– SM æ•°é‡ã€è®¡ç®—èƒ½åŠ›ä¸»ç‰ˆæœ¬ã€è¿è¡Œæ—¶ç‰ˆæœ¬åŠåŠ¨æ€å…±äº«å†…å­˜ä¸Šé™çš„æ¥å£ã€‚

---

### [Docker] Install cudnn==9.16 for cuda 13 image to avoid check error (#17668)
**SHA**: `0dfe46d` | ğŸ”— [æŸ¥çœ‹æäº¤](https://github.com/sgl-project/sglang/commit/0dfe46dafbe04e2148d83ca235e8dd5b4e4be79f)

**ğŸ¯ å˜æ›´ç±»å‹**ï¼šé…ç½®è°ƒæ•´  
**âš¡ é‡è¦ç¨‹åº¦**ï¼šğŸŸ¢ä½  
**ğŸ“‹ æ‘˜è¦**ï¼šåœ¨ `docker/Dockerfile` ä¸­ä¸º CUDAâ€¯13 é•œåƒæ–°å¢ `nvidia-cudnn-cu13==9.16.0.29` çš„å®‰è£…å‘½ä»¤ï¼Œé¿å…æ£€æŸ¥é”™è¯¯ã€‚

---

### [Auto Sync] Update logits_processor.py, test_logprobs.py (20260124) (#17664)
**SHA**: `bc6f0b5` | ğŸ”— [æŸ¥çœ‹æäº¤](https://github.com/sgl-project/sglang/commit/bc6f0b5ce791dd198df94f6817a4c3d0222ab975)

**ğŸ¯ å˜æ›´ç±»å‹**ï¼šä»£ç é‡æ„  
**âš¡ é‡è¦ç¨‹åº¦**ï¼šğŸŸ¢ä½  
**ğŸ“‹ æ‘˜è¦**ï¼šåœ¨ `logits_processor.py` ä¸­åŠ å…¥å¯¹ç‰¹å¾å¼€å…³çš„æ£€æŸ¥ï¼Œé¿å…åœ¨ GPU ä¸Šå¯¹é perâ€‘token å¼ é‡è¿›è¡Œè¶Šç•Œç´¢å¼•ï¼›åŒæ—¶åœ¨ `test_logprobs.py` ä¸­è®©æ¯ä¸ªé…ç½®å¯è‡ªå®šä¹‰æŠ½æ ·æ•°é‡ã€‚

---

### Add yeahdongcn to CI permissions (#17667)
**SHA**: `e1833c4` | ğŸ”— [æŸ¥çœ‹æäº¤](https://github.com/sgl-project/sglang/commit/e1833c4f5a66ad139c73231244077bd8452681ac)

**ğŸ¯ å˜æ›´ç±»å‹**ï¼šé…ç½®è°ƒæ•´  
**âš¡ é‡è¦ç¨‹åº¦**ï¼šğŸŸ¢ä½  
**ğŸ“‹ æ‘˜è¦**ï¼šåœ¨ `.github/CI_PERMISSIONS.json` ä¸­æ–°å¢ `yeahdongcn` çš„ CI æƒé™ï¼Œå…è®¸æ ‡è®°è¿è¡Œ CIã€é‡æ–°è¿è¡Œå¤±è´¥ CI å’Œé˜¶æ®µï¼Œå†·å´æ—¶é—´è®¾ä¸º 0ã€‚

---

### fix post_residual_addition more generally (#17286)
**SHA**: `ad05782` | ğŸ”— [æŸ¥çœ‹æäº¤](https://github.com/sgl-project/sglang/commit/ad05782160a931307fad1ea90b03139375b9af95)

**ğŸ¯ å˜æ›´ç±»å‹**ï¼šä»£ç é‡æ„  
**âš¡ é‡è¦ç¨‹åº¦**ï¼šğŸŸ¢ ä½  
**ğŸ“‹ æ‘˜è¦**ï¼šåœ¨å¤šç§ LayerNorm å‰å‘å®ç°ä¸­ç»Ÿä¸€åŠ å…¥ `post_residual_addition` æ”¯æŒï¼Œç¡®ä¿åœ¨æ®‹å·®å­˜åœ¨æ—¶å…ˆåŠ ä¸Šè¯¥å¼ é‡åå†è¿›è¡Œåç»­èåˆ/å½’ä¸€åŒ–ã€‚

---

### [DLLM] Remove cuda graph batch size limitation (#17458)
**SHA**: `5438cd2` | ğŸ”— [æŸ¥çœ‹æäº¤](https://github.com/sgl-project/sglang/commit/5438cd20ce9ff4bf21bef998a88c6cc9b125d0de)

**ğŸ¯ å˜æ›´ç±»å‹**ï¼šä»£ç é‡æ„  
**âš¡ é‡è¦ç¨‹åº¦**ï¼šğŸŸ¢ä½  
**ğŸ“‹ æ‘˜è¦**ï¼šåˆ é™¤äº†åœ¨ Diffusionâ€‘LLM æ¨ç†æ—¶å¼ºåˆ¶å°† `cuda_graph_bs` è®¾ä¸º `[1]` çš„é™åˆ¶åŠç›¸å…³è­¦å‘Šï¼Œä½¿ CUDA å›¾æ‰¹å¤§å°ä¸å†è¢«ç¡¬æ€§å›ºå®šã€‚

---

