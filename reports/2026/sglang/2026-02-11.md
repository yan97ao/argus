# 每日更新报告（2026-02-11）

## sgl-project/sglang

| 提交时间 | 作者 | 提交信息 |
|----------|------|----------|
| 2026-02-11 23:19:40 | Vedant V Jhaveri | add support to enable lora with embedding models (#17780) |
| 2026-02-11 20:14:35 | Baizhou Zhang | [V3.2] Change default CP token split method to `--round-robin-split` (#18613) |
| 2026-02-11 15:34:53 | McZyWu | [NPU] support model skywork-reward-gemma2-2-27B-v0.2 (#16947) |
| 2026-02-11 15:26:37 | sky | Register cp-atten-allgather buffers with symm memory (#17756) |
| 2026-02-11 15:23:48 | Thomas Wang | Fp8 prefill attn kernel integration (#18528) |
| 2026-02-11 14:39:01 | BourneSun0527 | Fix Bug on dsv3.2 (#18553)<br>This PR affects only the NPU. If any issues arise, please contact iforgetmyname. |
| 2026-02-11 14:33:13 | Michael | [AMD] Fix Janus-Pro crash and add Kimi-K2.5 nightly test  (#18269) |
| 2026-02-11 13:27:41 | Liangsheng Yin | Add cache hit rate UT (#18566) |
| 2026-02-11 13:07:53 | Liangsheng Yin | Tiny fix regex warning (#18592) |
| 2026-02-11 12:47:41 | cutetocute | chore: fix some typos (#18577) |
| 2026-02-11 12:20:45 | 赵晨阳 | Enhance SMG guide with RL rollout systems benefits (#18588) |
| 2026-02-11 10:31:28 | AlexZhao | [Doc] Comprehensive Guide: Navigating DP, DPA, and SMG Best Practices (#18096) |
| 2026-02-11 07:54:03 | Liangsheng Yin | Fix wrong prefill log. (#18570) |
| 2026-02-11 06:08:34 | Yi-Chia Chen | Fix radix cache key to include generated tokens in multi-turn (regression) (#16521) |
| 2026-02-11 01:53:26 | Thomas Wang | Tilelang sparse decode fwd for dsv32 mi355 (#18488) |
| 2026-02-11 01:17:40 | Baizhou Zhang | Revert "[sgl-kernel] upgrade deepgemm" (#18562) |
| 2026-02-11 01:03:28 | husf | [NPU][docs]fix bug about hyperlink for best practice for ascend npu (#18561) |
| 2026-02-11 00:20:06 | Zheng Li | fix(config): Support setting Mamba state dtype via config file (#18532) |

### 📊 统计摘要
> 本日共 18 个提交 | 🔴高 1 | 🟡中 8 | 🟢低 9
## 📋 目录

- [sgl-project/sglang](#sgl-project-sglang)
  - [📊 统计摘要](#-统计摘要)
  - [🔴 高重要度变更 (1)](#-🔴-高重要度变更-1)
    - [fix(config): Support setting Mamba state dtype via config...](#4460376)
  - [🟡 中重要度变更 (8)](#-🟡-中重要度变更-8)
    - [add support to enable lora with embedding models (#17780)](#98b5013)
    - [[NPU] support model skywork-reward-gemma2-2-27B-v0.2 (#16...](#4f7422f)
    - [Fp8 prefill attn kernel integration (#18528)](#a8eef53)
    - [[AMD] Fix Janus-Pro crash and add Kimi-K2.5 nightly test ...](#d84d206)
    - [Add cache hit rate UT (#18566)](#cd90346)
    - [[Doc] Comprehensive Guide: Navigating DP, DPA, and SMG Be...](#3167bcc)
    - [Fix wrong prefill log. (#18570)](#93fca0b)
    - [Tilelang sparse decode fwd for dsv32 mi355 (#18488)](#4262f52)
  - [🟢 低重要度变更 (9)](#-🟢-低重要度变更-9)
    - [[V3.2] Change default CP token split method to `--round-r...](#947927b)
    - [Register cp-atten-allgather buffers with symm memory (#17...](#72c1526)
    - [Fix Bug on dsv3.2 (#18553)](#2cc235e)
    - [Tiny fix regex warning (#18592)](#50f7428)
    - [chore: fix some typos (#18577)](#8d28923)
    - [Enhance SMG guide with RL rollout systems benefits (#18588)](#a2c38f7)
    - [Fix radix cache key to include generated tokens in multi-...](#2bfab1b)
    - [Revert "[sgl-kernel] upgrade deepgemm" (#18562)](#2d38b8a)
    - [[NPU][docs]fix bug about hyperlink for best practice for ...](#573ff55)
#### 🔴 高重要度变更 (1)

### fix(config): Support setting Mamba state dtype via config file (#18532)
**SHA**: `4460376` | 🔗 [查看提交](https://github.com/sgl-project/sglang/commit/44603764d65e79d2406eab8d1928dfdec9290138)

**🎯 变更类型**：Bug修复 / 功能增强  

**⚡ 重要程度**：🔴 高  

**📋 变更摘要**：  
- 为 Mamba2（用于 FalconH1、NemotronH、JetNemotron、LFM2、Qwen3Next 等模型）的状态缓存加入了可通过模型配置文件自行指定 `mamba_ssm_dtype`（SSM 状态数据类型）的功能。  
- 通过 `sglang/srt/configs/mamba_utils.py` 新增 `mamba2_state_dtype(config=None)`，优先读取环境变量 `SGLANG_MAMBA_SSM_DTYPE`，随后读取模型配置字段 `mamba_ssm_dtype`（或 `text_config.mamba_ssm_dtype`），默认回退 `float32`。  
- 相应的各模型配置文件在构造 `Mamba2CacheParams` 时传入 `dtype=mamba2_state_dtype(self)`，并在 `ServerArgs` 与 CLI 中加入对应的可选参数，使用户能够在启动时覆盖或保留模型自带的 dtype。  

**🎯 影响范围**：  
- `python/sglang/srt/configs/*`（FalconH1、JetNemotron、LFM2、NemotronH、Qwen3Next）以及公共 `mamba_utils.py`。  
- `sglang/srt/environ.py` 环境变量定义。  
- `sglang/srt/server_args.py` 与命令行接口 `add_cli_args`。  
- 运行时涉及 Mamba2 状态缓存的所有推理/训练服务。  

**🔍 技术洞察**  

- **架构影响**  
  - **配置层统一**：引入统一的 `mamba2_state_dtype` 读取逻辑，将 dtype 决策从硬编码转移至配置/环境层，提升了框架的可组合性。  
  - **向后兼容**：在未显式设置时仍保持原有默认 (`float32` 或 `bfloat16` 取决于 `SGLANG_MAMBA_CONV_DTYPE`) ，不影响已有部署。  
  - **模块耦合度降低**：各模型配置不再手动硬编码 dtype，统一通过公共工具函数实现，后续新增模型只需在配置中声明 `mamba_ssm_dtype` 即可。  

- **性能影响**  
  - **显存占用**：`float16`/`bfloat16` 可以显著降低 Mamba2 状态缓存的显存占用，提升大模型推理的可装载规模。  
  - **计算精度**：若误选 `float16` 可能导致数值精度下降，尤其在长序列或梯度累积场景。新机制通过默认 `float32` 降低误用风险。  
  - **启动开销**：新增的配置读取和日志打印开销极低（仅在进程启动阶段），对运行时吞吐几乎无影响。  

- **安全考虑**  
  - **环境变量注入**：`SGLANG_MAMBA_SSM_DTYPE` 仍然可被外部环境覆盖，若服务器对环境变量未加限制，潜在的误配风险与原先相同。  
  - **类型校验**：加入了对配置或 env 中非法值的警告日志，避免因不可识别的 dtype 导致运行时异常（如 `torch.dtype` 不匹配）。  

**⚠️ 潜在风险**  
1. **配置错误**：用户在模型配置文件中写入拼写错误或不支持的 dtype（如 `float64`），会触发警告并回退为默认 `float32`，但可能导致显存使用意外增大。  
2. **环境变量优先级**：在多节点分布式部署时，若节点间环境变量不统一，可能出现不同节点使用不同 dtype，导致缓存不兼容或性能不一致。  
3. **兼容性**：旧版模型配置文件未提供 `mamba_ssm_dtype` 字段，仍依赖默认 `float32`。若用户希望统一使用 `bfloat16`，需确保 `SGLANG_MAMBA_SSM_DTYPE` 已设置，否则仍是 `float32`。  

**💡 关注建议**  
- **文档与示例**：在官方文档中明确说明 `mamba_ssm_dtype` 的配置位置、可选值以及推荐使用场景（显存受限时使用 `float16`/`bfloat16`）。  
- **CI 检查**：加入模型配置文件的 lint 检查，确保 `mamba_ssm_dtype` 字段的合法性，防止拼写错误。  
- **统一环境**：在分布式部署脚本或容器镜像中统一设置 `SGLANG_MAMBA_SSM_DTYPE`，或在启动脚本中显式传递 `--mamba-ssm-dtype` 参数，以避免节点间不一致。  
- **监控与日志**：在服务启动日志中输出最终解析得到的 `conv_dtype` 与 `ssm_dtype`，便于运维快速定位显存占用异常。  
- **回退策略**：如果用户强制使用不支持的 dtype，考虑在 `mamba2_state_dtype` 中抛出异常而非仅警告，以防生产环境意外使用低精度导致模型质量回退。  

通过上述改动，sglang 在 Mamba2 状态缓存的 dtype 管理上实现了更灵活、可配置的设计，为显存优化提供了可靠的入口，同时保持了向后兼容性。建议在正式生产环境使用前进行一次完整的推理基准测试，以验证选用的 dtype 对吞吐和精度的实际影响。

---

#### 🟡 中重要度变更 (8)

### add support to enable lora with embedding models (#17780)
**SHA**: `98b5013` | 🔗 [查看提交](https://github.com/sgl-project/sglang/commit/98b5013d59b42a54f556440afc4e14f22e049102)

**🎯 变更类型**：功能增强  
**⚡ 重要程度**：🟡 中  
**📋 变更摘要**：为 Embedding 接口引入 LoRA 支持。`engine.encode`/`async_encode`、OpenAI 协议、内部请求结构 `EmbeddingReqInput` 均新增 `lora_path`（可为单路径或列表）和 `lora_id` 字段；在请求转化、调度、分词管理等环节完成路径解析、合法性校验并向下游传播。新增单元测试验证批处理、长度匹配及与 HF + LoRA 的向量相似度。  

**🎯 影响范围**  
- `python/sglang/srt/entrypoints/engine.py`  
- `.../openai/protocol.py`、`serving_embedding.py`  
- `.../managers/io_struct.py`、`scheduler.py`、`tokenizer_manager.py`  
- 新增 `test/registered/lora/test_embedding_lora_support.py`  

**💡 关注建议**  
1. **向后兼容**：旧版调用不传 `lora_path` 应保持行为不变，文档需标明新增可选参数。  
2. **参数校验**：`lora_path` 列表长度必须等于 batch‑size，已在 `EmbeddingReqInput._normalize_lora_paths` 中检查，建议在高层 API 也给出友好错误提示。  
3. **LoRA 启用检测**：`_validate_lora_enabled` 只在首次适配时触发，确认对应后端（如 Triton）已正确配置。  
4. **资源管理**：加载 LoRA 会占用额外显存，建议在多卡或大模型场景下监控显存使用，并在 `SRTRunner` 启动参数中提供 `lora_paths`。  
5. **测试覆盖**：新加入的单元测试覆盖结构化处理，后续如增加跨模态 Embedding（图像、音频）时，同步完善 LoRA 相关路径和 ID 的传播逻辑。  

整体来看，此次改动为 Embedding 场景带来了灵活的微调能力，影响范围主要在请求包装与调度层，保持了原有功能的兼容性。开发者在使用时请确保 LoRA 文件可达并与模型匹配，必要时更新部署脚本和文档。

---

### [NPU] support model skywork-reward-gemma2-2-27B-v0.2 (#16947)
**SHA**: `4f7422f` | 🔗 [查看提交](https://github.com/sgl-project/sglang/commit/4f7422f7bada1f1d83b2cadc3ae3e609820f0e41)

**🎯 变更类型**：功能增强（NPU 对 Skywork‑Reward‑Gemma2‑2‑27B‑v0.2 的专属适配）  
**⚡ 重要程度**：🟡 中  

**📋 变更摘要**  
1. 在 `model_config.is_generation_model` 中加入 `Gemma2ForSequenceClassification` 判定，以防误将奖励模型识别为生成模型。  
2. 新增两项 NPU 环境变量 `SGLANG_NPU_FORWARD_NATIVE_GELUTANH`、`SGLANG_NPU_FORWARD_NATIVE_GEMMA_RMS_NORM`，用于在 NPU 上强制走原生 Gelu‑Tanh 与 Gemma‑RMS‑Norm 实现。  
3. `AscendBackend` 在检测到 Gemma2‑For‑SequenceClassification 时默认开启 `use_native_sdpa`，避免精度异常。  
4. `layers.activation`、`layers.layernorm` 的 NPU 前向分别加入对上述 env 的分支，透明切换原生实现。  
5. `models/gemma2.py` 针对 NPU 加入 dtype‑float32 的 Rotary Embedding 与关闭 logits‑softcapping，以消除数值漂移。  
6. 新增 NPU CI 测例 `test_ascend_gemma_2_27b_v0_2.py`，对奖励分数进行 0.04 的容差校验。  

**🎯 影响范围**  
- `sglang/srt/configs/model_config.py`  
- `sglang/srt/environ.py`  
- `sglang/srt/hardware_backend/npu/attention/ascend_backend.py`  
- `sglang/srt/layers/activation.py`、`sglang/srt/layers/layernorm.py`  
- `sglang/srt/models/gemma2.py`  
- NPU CI 测试目录  

**💡 关注建议**  
- **部署**：在 NPU 环境下使用该模型时，请务必在启动脚本或环境中显式设置 `SGLANG_NPU_FORWARD_NATIVE_GELUTANH=1` 与 `SGLANG_NPU_FORWARD_NATIVE_GEMMA_RMS_NORM=1`，否则仍会走原实现，可能出现精度偏差。  
- **兼容性**：新增的 `"Gemma2ForSequenceClassification"` 判定仅在奖励模型场景使用，如有其他自定义 Gemma2 变体，请确认其 `architectures` 字段不被误拦截。  
- **性能**：开启原生实现会牺牲部分加速（尤其是在多流模式下），但对数值稳定性有显著提升；建议在对精度要求高的推理场景下开启。  
- **回归**：运行新增的 NPU 测例或全链路 CI，确认在不同 `tp_size`、`torch_dtype`（目前仅 bf16）下分数误差 ≤ 0.04。  
- **文档**：在使用手册或部署脚本中补充上述环境变量的说明，避免用户因默认关闭而遇到“结果不一致”问题。  

总体而言，此次改动为特定奖励模型在 Ascend NPU 上提供了数值安全网，影响范围局限于模型判定、后端注意力、激活及归一化层，风险可控，只要在生产环境中按指引打开对应 env 即可。

---

### Fp8 prefill attn kernel integration (#18528)
**SHA**: `a8eef53` | 🔗 [查看提交](https://github.com/sgl-project/sglang/commit/a8eef53dc419f6575ca4aece11065d3ff7f463b9)

**🎯 变更类型**：功能增强（fp8‑prefill 注意力内核集成）  
**⚡ 重要程度**：🟡 中  
**📋 变更摘要**  
在 `sglang/srt/layers/attention/aiter_backend.py` 中新增了对 AMD gfx95 GPU 的 fp8 prefill 注意力实现。通过环境变量 `SGLANG_AITER_FP8_PREFILL_ATTN` 控制，默认在 gfx95 上开启。实现了元数据 buffer 的创建、元数据填充以及调用新 ASM‑kernel `mla_prefill_ps_asm_fwd` 与 `mla_reduce_v1` 的逻辑，兼容原有的 flash‑attn 分支。

**🎯 影响范围**  
- `sglang.srt.layers.attention.aiter_backend.AIterAttentionBackend`（前向元数据、`forward_extend`）  
- `sglang.srt.utils.is_gfx95_supported`（检测硬件）  
- 新增的 `get_ps_metadata_info_v1` / `get_ps_metadata_v1`（元数据接口）  
- 依赖的 triton/aiter kernel：`mla_prefill_ps_asm_fwd`、`mla_reduce_v1`  

**💡 关注建议**  

1. **兼容性**  
   - `is_gfx95_supported()` 只在 gfx95 上返回 true，其他 GPU 会自动回退到原 flash‑attn 分支，确保不会因缺失 kernel 导致崩溃。请在 CI 中加入非‑gfx95 环境的验证。  
2. **环境变量**  
   - 文档应说明 `SGLANG_AITER_FP8_PREFILL_ATTN` 的默认行为以及如何显式关闭，以防在不支持的硬件上意外启用。  
3. **数据类型**  
   - 代码将在 fp8 数据类型 (`fp8_dtype`) 与 float32 之间进行强制转换，注意 `self.input_dtype` 与 `fp8_dtype` 的一致性，防止精度回退或 overflow。  
4. **性能基准**  
   - 新增路径涉及多次 GPU‑to‑CPU copy（元数据 CPU‑side 填充），在大 batch 时可能成为瓶颈。建议在提交的 PR 中提供相同模型、不同 Q‑len 的吞吐量对比。  
5. **错误处理**  
   - 当前路径在创建元数据 buffer 时直接 `torch.empty`，若显存不足会抛出 RuntimeError，建议捕获并回退到 flash‑attn，实现“安全降级”。  
6. **单元测试**  
   - 添加针对 `make_mla_prefill_ps_meta_data_buffer`、`make_mla_prefill_ps_meta_data` 的功能测试，覆盖不同 `batch_size`、`max_qlen`、`qlen_granularity` 的组合。  

总体来看，此次提交为 fp8‑prefill 提供了显著的加速潜力，核心改动集中在元数据准备和 kernel 调用层，风险主要在硬件适配与显存需求上。做好回退机制和测试即可平稳上线。

---

### [AMD] Fix Janus-Pro crash and add Kimi-K2.5 nightly test  (#18269)
**SHA**: `d84d206` | 🔗 [查看提交](https://github.com/sgl-project/sglang/commit/d84d2063d32a881842843bc0e991c01e725445b3)

**🎯 变更类型**：功能增强 / CI 稳定性提升  
**⚡ 重要程度**：🟡 中  

**📋 变更摘要**  
1. 在 AMD CI 工作流中新增 Kimi‑K2.5（8‑GPU）准确性测试，分别覆盖 MI325 与 MI35x 两类硬件；对应 workflow `.github/workflows/nightly-test-amd.yml` 中的 job、suite、触发条件全部更新。  
2. `deepseek_janus_pro.py` 中 `LogitsProcessor` 的实例化参数从 `config` 改为 `language_config`，修复 Janus‑Pro 在 AMD 环境下因参数不匹配导致的崩溃。  
3. 新增两套 AMD 准确性评估测试 (`test_kimi_k25_eval_amd.py`、`test_kimi_k25_eval_mi35x.py`)，使用 GSM8K few‑shot 基准，阈值 0.92，计入 nightly‑amd‑accuracy 套件。  

**🎯 影响范围**  
- CI 运行时：AMD‑GPU（MI325、MI35x）夜间测试流程将执行 Kimi‑K2.5 准确性验证，可能延长 CI 时长。  
- 代码层面：`LogitsProcessor` 调用签名变化，只影响 `deepseek_janus_pro` 以及可能的自定义子类；若其他位置仍使用旧签名会导致运行错误。  
- 文档/维护：新增的 suite 名称需在相关 CI 注册表、README 或模型列表中同步更新。  

**💡 关注建议**  
1. **本地验证**：在 AMD 环境（或对应 docker 镜像）手动跑一次 `nightly‑amd‑accuracy‑8‑gpu‑kimi‑k25`，确认模型能成功加载、服务器启动、评估脚本不报错。  
2. **参数兼容**：检查项目中是否还有对 `LogitsProcessor` 的其他实例化（如自定义插件），确保统一使用 `language_config`。若有兼容需求，可在 `LogitsProcessor` 构造函数中加旧参数的兼容层。  
3. **CI 资源**：新增 job 将消耗额外 GPU‑hour，建议在 CI 配额紧张时评估是否需要将 K2.5 设为可选或降低并行度。  
4. **阈值监控**：accuracy 阈值 0.92 较高，首次跑可能出现轻微波动。建议在 CI 报告中记录历史趋势，防止因随机波动导致不必要的回滚。  
5. **文档同步**：在 `README.md`、模型列表或 CI 手册中加入 “Kimi‑K2.5 (AMD) Nightly Accuracy Test” 的说明，便于贡献者了解新增的测试入口。  

总体而言，此次提交为 AMD 平台引入新的模型基准并修复了一处导致 Janus‑Pro 崩溃的参数错误，风险主要集中在 CI 资源占用和潜在的参数不兼容上，按上述建议验证后即可安全合并。

---

### Add cache hit rate UT (#18566)
**SHA**: `cd90346` | 🔗 [查看提交](https://github.com/sgl-project/sglang/commit/cd90346a2ba465d0806f65748666f67b49a64c24)

**变更类型**：功能增强（新增缓存命中率检测工具及对应单元测试）  
**重要程度**：🟡 中  

**核心改动**  
1. **benchmark/hicache**  
   - `bench_long_context.py` 直接使用 `tokenizer.encode` 取 `input_ids`，避免多余的 `gen_payload` 包装，提高可读性。  
   - `bench_multiturn.py` 大幅重构：去掉冗余 `aiohttp` 请求实现，改为统一使用 `sglang.test.kits.cache_hit_kit` 中的 `async_request_sglang_generate` 与 `gen_payload`（基于 `input_ids`）。  
   - 调整历史记录、子问题、响应处理逻辑，全部改为 **token id 列表** 而非文本，保证缓存命中统计的准确性。  

2. **sglang/bench_serving.py**  
   - `compute_random_lens` 返回 `List[int]`，确保后续 JSON 序列化安全。  
   - `sample_random_requests` 在返回 token‑ids 时显式转为 Python `int`，并统一 `prompt_len`/`output_len` 类型。  

3. **新增 `cache_hit_kit.py`**  
   - 提供异步请求、payload 生成（使用 `input_ids`）以及多轮并发发送的通用工具。  
   - 实现缓存命中率验证逻辑：通过页面大小、miss_tolerance 计算期望命中并断言 `cached_tokens >= expected`.  

4. **新增单元测试 `test_radix_cache/test_radix_cache_hit.py`**  
   - 启动小模型服务器，执行 6 轮、8 客户端的多轮对话负载，验证缓存命中率符合预期。  

**影响范围**  
- `benchmark/hicache`、`sglang/bench_serving`、`sglang/test/kits` 以及相关依赖的 `tokenizer`、`ReadyQueue`。  
- 任何直接使用 `bench_multiturn` 的脚本或 CI 流程将受新接口（返回 token ids）影响，需要同步更新。  

**关注建议**  
1. **向后兼容**：保留旧的 `text`‑based `gen_payload`（或提供包装），避免破坏已有 benchmark。  
2. **类型安全**：在 `sample_random_requests` 中已转为 `int`，建议在所有生成 `payload` 前统一检查 `List[int]`。  
3. **异常处理**：`async_request_sglang_generate` 捕获异常后仅打印，最好在 CI 中加入重试或更明确的错误报告。  
4. **性能基准**：新实现使用 `aiohttp` 并发，建议在不同机器上跑基准，以确认对吞吐量没有负面影响。  

总体而言，此次改动为缓存命中率提供了可靠的检测手段，代码结构更清晰，唯一需要关注的是保持对旧 benchmark 接口的向后兼容并强化异常报告。

---

### [Doc] Comprehensive Guide: Navigating DP, DPA, and SMG Best Practices (#18096)
**SHA**: `3167bcc` | 🔗 [查看提交](https://github.com/sgl-project/sglang/commit/3167bcc01c3074d5739e8086757cd8c66077d508)

**变更类型**：文档完善  
**重要程度**：🟡 中  
**变更摘要**：新增《DP、DPA 与 SMG 最佳实践指南》，系统梳理了数据并行（DP）、注意力并行（DPA）以及基于 Rust 的 SGLang Model Gateway（SMG）的使用方式、参数要求和性能对比，并在索引中加入该文档。  

**影响范围**  
- `docs/advanced_features/`：新增 `dp_dpa_smg_guide.md`，对已有的并行和专家并行文档形成补充。  
- `docs/index.rst`：索引更新，使该指南在文档树中可见。  
- 运行时参数（`--dp-size`、`--enable-dp-attention`、`sglang_router` 启动入口）在文档层面得到明确说明，可能影响用户的部署脚本。  

**关注建议**  
1. **文档一致性**：检查其他章节（如 `expert_parallelism.md`、`sgl_model_gateway.md`）中涉及的参数名、默认值与本指南保持同步，避免出现冲突或解释不一致。  
2. **示例命令**：确保示例中使用的模型路径、GPU 数量等与 CI 测试环境兼容，防止新手复制后因资源不足报错。  
3. **链接有效性**：文中外部链接（PR #6121、博客）以及内部交叉引用（`expert_parallelism.md`、`sgl_model_gateway.md`）需在合并后重新验证。  
4. **索引更新**：在发布脚本或自动化文档生成流程中加入新文件的路径，保证搜索索引和侧边栏能够正确渲染。  
5. **平台适配**：若将来增加 Windows/CPU‑only部署，文档中涉及的 GPU 参数检查逻辑应提前预留说明。  

总体而言，此次提交为用户提供了完整的并行部署指南，提升了可用性和可维护性，只需在后续更新中保持跨文档的一致性即可。

---

### Fix wrong prefill log. (#18570)
**SHA**: `93fca0b` | 🔗 [查看提交](https://github.com/sgl-project/sglang/commit/93fca0bbc3135f473441611fc900c90a2f09fe20)

**🎯 变更类型**：Bug 修复 / 代码抽象化（修正错误的 prefill 日志并提升日志结构）  
**⚡ 重要程度**：🟡 中  

**📋 变更摘要**  
1. 新增 `PrefillStats` dataclass，用于统一保存 Prefill 阶段的统计信息（输入/命中 token、比例、当前 batch 大小、新增序列数）。  
2. 在 `ScheduleBatch` 中添加 `prefill_stats` 成员，并在调度器生成新 Prefill 批时填充该对象。  
3. `SchedulerMetricsMixin.log_prefill_stats` 的签名改为接受 `PrefillStats`，并使用其中的数据替代原来直接传入的 `PrefillAdder` 与其它散列参数，避免日志信息与实际统计不一致。  
4. 相应的调用者（`scheduler_output_processor_mixin.py`）同步改为传 `batch.prefill_stats`。  

**🎯 影响范围**  
- `python/sglang/srt/managers/schedule_batch.py`、`scheduler.py`、`scheduler_metrics_mixin.py`、`scheduler_output_processor_mixin.py` 四个核心调度模块。  
- 任何依赖旧 `log_prefill_stats` 参数签名（如自定义插件或外部监控）需要同步修改。  

**💡 关注建议**  
- **开发者**：确认所有内部或第三方代码已更新为 `log_prefill_stats(prefill_stats=…)` 的新调用方式；若仍使用旧 `adder` 参数会导致运行时异常。  
- **用户**：该改动仅影响日志与指标展示，不会改变模型推理结果或性能。可通过 `SGLANG_ENABLE_METRICS` 环境变量检查日志是否如预期输出。  
- **后续**：建议在文档中补充 `PrefillStats` 的字段说明，并在单元测试中加入对 `prefill_stats` 为空或异常值的容错验证，防止再次出现统计不匹配的 bug。

---

### Tilelang sparse decode fwd for dsv32 mi355 (#18488)
**SHA**: `4262f52` | 🔗 [查看提交](https://github.com/sgl-project/sglang/commit/4262f5259b94c5c08779efff5017c0a6235bcb5f)

**🎯 变更类型**：功能增强  
**⚡ 重要程度**：🟡 中  

**📋 变更摘要**  
- 在 `tilelang_kernel.py` 中新增两段 TileLang JIT kernel：`sparse_mla_fwd_decode_partial`（分块解码计算）和 `sparse_mla_fwd_decode_combine`（分块结果合并）。  
- `tilelang_sparse_fwd` 入口函数加入判定 `q.shape[0] <= 64`，在满足时走解码路径，调用上述两个 kernel 完成稀疏注意力的前向计算；否则保持原有 prefill 路径不变。

**🎯 影响范围**  
- 核心模块：`python/sglang/srt/layers/attention/nsa/tilelang_kernel.py`（新 kernel 实现、入口函数分支）。  
- 可能波及：调用 `tilelang_sparse_fwd` 的上层模型推理逻辑、单元测试、CI 中的性能基准。

**💡 关注建议**  
1. **功能正确性**：  
   - 只在 `is_causal=True`、`kv_group=1`、`topk%block_I==0` 的前提下实现，确保调用方在解码阶段满足这些前置条件。  
   - `mask` 采用 `Indices >= 0` 判断，若外部产生负索引会导致错误，需要在数据准备阶段显式填充合法值。  
   - `sumexp_i==0` 分支使用 `-(2**30)` 作为 “无效” log‑prob，合并阶段的 `lse_max` 也使用同样的下限，保持一致性。  

2. **数值一致性**：  
   - 建议加入对比测试（与原 prefill kernel 或 PyTorch 实现）在 `batch=1, seq_len≤64` 场景下的输出 L2 差异，验证 `sm_scale`、`log2`、`exp2` 计算路径的等价性。  

3. **性能验证**：  
   - 目前硬编码 `head_per_block=4`（可在 `sparse_mla_fwd_decode_combine` 参数中调节），在不同 GPU（MI300X、MI250）上跑 benchmark，确认相较于原实现的加速幅度。  
   - 注意 `block_I=64, threads=256` 与实际硬件的 warp/CTA 大小匹配，否则可能出现低利用率。  

4. **异常路径**：  
   - 当 `q.shape[0] > 64`（即不走解码路径），仍会走原 `sparse_attention_fwd_kernel_v1`，确保两条路径的输入/输出 shape 完全一致，避免隐藏的维度 mismatch。  

5. **代码维护**：  
   - 新增的两个 kernel 与已有 `sparse_attention_fwd_kernel_v1` 在参数、返回值上保持统一，便于后续统一抽象。建议在文件头部添加简要注释，说明 decode 与 prefill 的区别及使用场景。  

**结论**：此提交为稀疏注意力在解码阶段提供了专用的 TileLang 实现，若配套的测试和基准验证通过，可提升推理吞吐。请重点关注数值精度、mask 边界以及硬件适配的验证。

---

#### 🟢 低重要度变更 (9)

### [V3.2] Change default CP token split method to `--round-robin-split` (#18613)
**SHA**: `947927b` | 🔗 [查看提交](https://github.com/sgl-project/sglang/commit/947927bdb55ae45469be7ea0e44541a940c78ec3)

**🎯 变更类型**：代码重构  
**⚡ 重要程度**：🟢低  
**📋 摘要**：将 DeepSeek‑V3.2 上下文并行预填阶段的默认 token 分割方式从 `in-seq-split` 改为 `round-robin-split`，同步更新了文档说明及 CLI 参数默认值。

---

### Register cp-atten-allgather buffers with symm memory (#17756)
**SHA**: `72c1526` | 🔗 [查看提交](https://github.com/sgl-project/sglang/commit/72c152665790d14075473f1021dd94848d3d1b06)

**🎯 变更类型**：代码重构  
**⚡ 重要程度**：🟢低  
**📋 摘要**：在 `utils.py` 中为跨卡注意力全量收集引入对称内存分配，使用 `use_symmetric_memory` 包装张量创建，使其在对称分配开启时使用对称内存。

---

### Fix Bug on dsv3.2 (#18553)
**SHA**: `2cc235e` | 🔗 [查看提交](https://github.com/sgl-project/sglang/commit/2cc235e7952e6565a06ac2e179e0e1dffdd9a2c9)

**🎯 变更类型**：代码重构/Bug 修复  
**⚡ 重要程度**：🟢低  
**📋 摘要**：在 `nsa_indexer.py` 中新增对 `SGLANG_NPU_USE_MULTI_STREAM` 环境变量的判断，以在 NPU 上支持多流执行并正确同步；同时在 `overlap_utils.py` 中加入 NPU 检测，使其在 NPU 环境下禁用 `torch.compile`。这两个改动解决了 NPU 场景下的运行错误。

---

### Tiny fix regex warning (#18592)
**SHA**: `50f7428` | 🔗 [查看提交](https://github.com/sgl-project/sglang/commit/50f74285e9ae17901788892cc03597187b3d4388)

**🎯 变更类型**：测试修改  
**⚡ 重要程度**：🟢低  
**📋 摘要**：在 `test/registered/distributed/test_pp_single_node.py` 中，将 `response_answer_regex` 前加 `r` 前缀，使用原始字符串避免正则转义警告。

---

### chore: fix some typos (#18577)
**SHA**: `8d28923` | 🔗 [查看提交](https://github.com/sgl-project/sglang/commit/8d2892330c05e4a0d0ee3085b25c035bfed07dcf)

**🎯 变更类型**：代码重构  
**⚡ 重要程度**：🟢低  
**📋 摘要**：统一并修正了多个文件中的拼写错误、变量/函数命名（如 `sparse_decode_thresold` → `sparse_decode_threshold`、`is_threed` → `is_3d`），并相应更新了注释和测试用例的文字描述，未影响功能逻辑。

---

### Enhance SMG guide with RL rollout systems benefits (#18588)
**SHA**: `a2c38f7` | 🔗 [查看提交](https://github.com/sgl-project/sglang/commit/a2c38f7796fd723a28091a85f1072b1e6a234398)

**🎯 变更类型**：文档更新  
**⚡ 重要程度**：🟢低  
**📋 摘要**：在 SMG 使用指南中新增对强化学习 rollout 系统的优势说明，添加四点关键原因的引用链接。

---

### Fix radix cache key to include generated tokens in multi-turn (regression) (#16521)
**SHA**: `2bfab1b` | 🔗 [查看提交](https://github.com/sgl-project/sglang/commit/2bfab1bb67460af8b125d94ca4c5ab0040c12cd2)

**🎯 变更类型**：代码重构 / bug 修复  
**⚡ 重要程度**：🟢低  
**📋 摘要**：修复 radix 缓存键在多轮对话中未包含生成 token 的回归问题，将 `req.fill_ids` 替换为实际使用的 `token_ids`，确保在 EAGLE 模式下正确生成 bigram 键。

---

### Revert "[sgl-kernel] upgrade deepgemm" (#18562)
**SHA**: `2d38b8a` | 🔗 [查看提交](https://github.com/sgl-project/sglang/commit/2d38b8aca016a1702eef7e6fbd4c201937abda8a)

**🎯 变更类型**：代码重构  
**⚡ 重要程度**：🟢低  
**📋 摘要**：回滚 DeepGEMM 升级，恢复原 GIT_TAG；改用 `USE_SABI` 构建 Python 扩展并简化链接；移除 build.sh 中的 `USE_CCACHE` 参数；删除无用注释。

---

### [NPU][docs]fix bug about hyperlink for best practice for ascend npu (#18561)
**SHA**: `573ff55` | 🔗 [查看提交](https://github.com/sgl-project/sglang/commit/573ff558142281b4a0e5ec37e66db73ff8873ab5)

**🎯 变更类型**：文档更新  
**⚡ 重要程度**：🟢低  
**📋 摘要**：修正 Ascend NPU 最佳实践文档中表格与标题的超链接、数据集标识（如 “6K+1.6K”）格式错误，统一为正确的锚点和命名，确保跳转准确。

---

