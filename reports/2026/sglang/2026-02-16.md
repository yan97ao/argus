# 每日更新报告（2026-02-16）

## sgl-project/sglang

| 提交时间 | 作者 | 提交信息 |
|----------|------|----------|
| 2026-02-16 23:03:51 | Tamir Baydasov | [2/N] Quantization Refactor: Compressed tensors MoE schemes (#17503) |
| 2026-02-16 22:27:02 | Estrella-xx | refactor FAKE transfer backend and remove --disaggregation-decode-enable-fake-auto parameter (#18345) |
| 2026-02-16 21:57:58 | Ratish P | [diffusion][Wan]: fix sparse attention backends being applied to cross-attention (#17596) |
| 2026-02-16 19:47:09 | Mohammad Miadh Angkad | [Perf] ~9.5x faster Blackwell MXFP4 MoE weight loading (#18858) |
| 2026-02-16 19:44:41 | Shivam jindal | [Model] Add Qwen3ForRewardModel and fix Qwen3ForSequenceClassification (#17992) |
| 2026-02-16 18:00:58 | Mick | Revert "[diffusion]: Improve layerwise offload buffer reuse and shared-storage handling" (#18866) |
| 2026-02-16 16:44:37 | Mick | [diffusion] logging: improve peak vram logging (#18865) |
| 2026-02-16 16:07:24 | Yi Zhong | [JIT kernel] hd=512,1024 in JIT QK norm (cta based) (#17515) |
| 2026-02-16 16:02:31 | Alison Shao | Fix GLM-4V processor registration when glm_ocr is unavailable (#18885) |
| 2026-02-16 15:39:45 | Changyi Yang | [diffusion] fix: fix LoRA weight snapshot aliasing in unmerge logic (#18883) |
| 2026-02-16 15:24:27 | RAY | Update ascend_npu_qwen3_5_examples.md (#18888) |
| 2026-02-16 14:35:06 | Alison Shao | Fix test_lora_qwen3 nightly failure: replace adapter with added_tokens (#18884) |
| 2026-02-16 14:09:00 | Douglas Yang | fix: adding performance logging for nightly diffusion (#18023) |
| 2026-02-16 14:05:55 | Douglas Yang | fix: unifying docker image build pipeline (#18814) |
| 2026-02-16 13:34:06 | fzyzcjy | Support dumping gradients, parameters, lazy values (#18881) |
| 2026-02-16 13:31:19 | fzyzcjy | Collect upper level metadata to dump output (#18880) |
| 2026-02-16 13:30:47 | fzyzcjy | Change dump output format to dict with value and metadata (#18879) |
| 2026-02-16 13:29:32 | fzyzcjy | Flip dumper to disable by default and refactor environment handling (#18878) |
| 2026-02-16 12:59:39 | Duyi-Wang | [AMD] MORI-EP inter kernel type switch (#18437) |
| 2026-02-16 12:47:29 | Johnsonms | [Diff]: support SGLANG_TORCH_PROFILER_DIR environment variable for profiler log directory (#18454) |
| 2026-02-16 11:49:06 | Mick | [diffusion] refactor: refactor server_args adjust and validate logics (#18863) |
| 2026-02-16 11:48:28 | Mick | [diffusion] fix: avoid saving output for warmup requests (#18867) |
| 2026-02-16 11:19:44 | Yuan Luo | [VLM] Optimize Ernie4.5-VL rotary embedding with fused triton kernel (#18856) |
| 2026-02-16 10:57:37 | Douglas Yang | fix: nightly whl dev date suffix (#18873) |
| 2026-02-16 09:29:54 | Rain Jiang | Nsa trtllm mla sparse fp8 support with Deepseek v3.2 NVFP4 (#18389) |
| 2026-02-16 09:24:11 | Mohammad Miadh Angkad | [CI] Remove `--mem-fraction-static 0.93` from gpt-oss test (#18869) |
| 2026-02-16 07:14:03 | Xiaoyu Zhang | Add claude skills for sgl-kernel and jit-kernel (#18855) |
| 2026-02-16 01:41:38 | chenxu214 | Update ascend_npu_support.rst (#18868) |
| 2026-02-16 01:15:20 | chenxu214 | Create ascend_npu_qwen3_5_examples.md  (#18864) |
| 2026-02-16 00:44:47 | blake-snc | fix(sgl-kernel): use >= 120 for SM12x CUDA kernel dispatch (#18750) |
| 2026-02-16 00:43:04 | blake-snc | fix(sgl-kernel): support CUDA 13 runtime preloading for DGX Spark (#18747) |
| 2026-02-16 00:37:50 | Mike Qiu | Fix libnuma.so does not exsit (#15355) |
| 2026-02-16 00:36:01 | akhilg-nv | Improve profiler options for bench_serving (#16991) |
| 2026-02-16 00:33:24 | Blake Ledden | feat: expose consistent_hashing policy in Python router CLI args (#17972) |
| 2026-02-16 00:32:47 | Chanh Nguyen | Use ephemeral nccl port via get_free_port() (#18009) |
| 2026-02-16 00:31:42 | tjp_zju | fix_get_quant_method_in_fused_moe_condition (#18459) |
| 2026-02-16 00:29:37 | Zack Yu | test: add test for Modelopt FP8 on SM90 (#18463) |
| 2026-02-16 00:26:58 | WiwilZ | fix: add SM110 (Jetson AGX Thor) to Blackwell capability check (#18787) |
| 2026-02-16 00:23:51 | blake-snc | fix: update Blackwell log/error messages to include SM12x (#18751) |
| 2026-02-16 00:18:31 | SoluMilken | update pre-commit config (#18860) |
| 2026-02-16 00:02:30 | Alison Shao | Enable DeepGemm fast warmup in CI to prevent cold-cache timeouts (#18823) |

### 📊 统计摘要
> 本日共 41 个提交 | 🔴高 6 | 🟡中 20 | 🟢低 15
## 📋 目录

- [sgl-project/sglang](#sgl-project-sglang)
  - [📊 统计摘要](#-统计摘要)
  - [🔴 高重要度变更 (6)](#-🔴-高重要度变更-6)
    - [[2/N] Quantization Refactor: Compressed tensors MoE schem...](#eba6af3)
    - [fix: adding performance logging for nightly diffusion (#1...](#f1efb46)
    - [fix: unifying docker image build pipeline (#18814)](#2050875)
    - [Nsa trtllm mla sparse fp8 support with Deepseek v3.2 NVFP...](#0ffd0a3)
    - [fix(sgl-kernel): use >= 120 for SM12x CUDA kernel dispatc...](#0d30896)
    - [feat: expose consistent_hashing policy in Python router C...](#f759960)
  - [🟡 中重要度变更 (20)](#-🟡-中重要度变更-20)
    - [refactor FAKE transfer backend and remove --disaggregatio...](#1b3513a)
    - [[diffusion][Wan]: fix sparse attention backends being app...](#c1d1337)
    - [[Perf] ~9.5x faster Blackwell MXFP4 MoE weight loading (#...](#b86c649)
    - [[Model] Add Qwen3ForRewardModel and fix Qwen3ForSequenceC...](#4f0409f)
    - [[diffusion] logging: improve peak vram logging (#18865)](#d0c94e1)
    - [[JIT kernel] hd=512,1024 in JIT QK norm (cta based) (#17515)](#ed22720)
    - [Support dumping gradients, parameters, lazy values (#18881)](#f554b3c)
    - [Collect upper level metadata to dump output (#18880)](#9a7d8d5)
    - [Change dump output format to dict with value and metadata...](#949792d)
    - [Flip dumper to disable by default and refactor environmen...](#02816ab)
    - [[AMD] MORI-EP inter kernel type switch (#18437)](#5ddc84e)
    - [[diffusion] refactor: refactor server_args adjust and val...](#0af9dcc)
    - [[VLM] Optimize Ernie4.5-VL rotary embedding with fused tr...](#8a82c70)
    - [fix: nightly whl dev date suffix (#18873)](#45715af)
    - [fix(sgl-kernel): support CUDA 13 runtime preloading for D...](#5fc3284)
    - [Use ephemeral nccl port via get_free_port() (#18009)](#597d17d)
    - [test: add test for Modelopt FP8 on SM90 (#18463)](#536ed31)
    - [fix: add SM110 (Jetson AGX Thor) to Blackwell capability ...](#b2f74d6)
    - [fix: update Blackwell log/error messages to include SM12x...](#57f7e06)
    - [update pre-commit config (#18860)](#07a24f1)
  - [🟢 低重要度变更 (15)](#-🟢-低重要度变更-15)
    - [Revert "[diffusion]: Improve layerwise offload buffer reu...](#de833f9)
    - [Fix GLM-4V processor registration when glm_ocr is unavail...](#206accd)
    - [[diffusion] fix: fix LoRA weight snapshot aliasing in unm...](#61da34a)
    - [Update ascend_npu_qwen3_5_examples.md (#18888)](#d85884c)
    - [Fix test_lora_qwen3 nightly failure: replace adapter with...](#86c181e)
    - [[Diff]: support SGLANG_TORCH_PROFILER_DIR environment var...](#bc79a64)
    - [[diffusion] fix: avoid saving output for warmup requests ...](#78b4c9e)
    - [[CI] Remove `--mem-fraction-static 0.93` from gpt-oss tes...](#8290171)
    - [Add claude skills for sgl-kernel and jit-kernel (#18855)](#d3bae71)
    - [Update ascend_npu_support.rst (#18868)](#fd5a45d)
    - [Create ascend_npu_qwen3_5_examples.md  (#18864)](#f2d7286)
    - [Fix libnuma.so does not exsit (#15355)](#b79808b)
    - [Improve profiler options for bench_serving (#16991)](#48eac1b)
    - [fix_get_quant_method_in_fused_moe_condition (#18459)](#7a607c4)
    - [Enable DeepGemm fast warmup in CI to prevent cold-cache t...](#f760320)
#### 🔴 高重要度变更 (6)

### [2/N] Quantization Refactor: Compressed tensors MoE schemes (#17503)
**SHA**: `eba6af3` | 🔗 [查看提交](https://github.com/sgl-project/sglang/commit/eba6af385d17a3fe72719e14f70fe6230026c4f8)

**🎯 变更类型**：架构变更 / 重构（Quantization Refactor：引入统一 Scheme 抽象，拆分 MoE 量化实现）

**⚡ 重要程度**：🔴高  

**📋 变更摘要**  
1. 将原有的 `compressed_tensors_moe.py`（约 2 KB）彻底移除，拆分为一套 **Scheme** 抽象（`BaseLinearScheme`、`BaseMoEScheme`）与对应实现。  
2. 新增 `base_scheme.py`、`schemes/__init__.py`、`schemes/compressed_tensors_scheme.py`，并在 `compressed_tensors.py` 中统一通过 `QuantizationConfig.get_quant_method` 动态创建 **Linear** 或 **MoE** Scheme。  
3. 所有原来直接实例化 `CompressedTensors*Method` 的位置改为 `CompressedTensors*Scheme`（例如 `CompressedTensorsW4A4Fp4` → `CompressedTensorsW4A4Fp4` 继承 `CompressedTensorsLinearScheme`），并在 MoE 层统一使用 `layer.scheme` 来调用 `create_weights / process_weights_after_loading / apply_weights`。  
4. 新增多种 MoE‑专属 Scheme（MxInt4、Nvfp4、W4A8Int8、W8A8Int8、W8A8Fp8、WNA16 等）以及对应的 NPU/ROCm 实现。  

---

### 🎯 影响范围
- **核心量化框架**：`sglang.srt.layers.quantization.*`（所有 Linear 与 Fused MoE 量化路径）  
- **MoE 相关层**：`sglang.srt.layers.moe.ep_moe.layer`、`sglang.srt.layers.moe.fused_moe_triton.layer`、`sglang.srt.layers.moe.kt_ep_wrapper`  
- **模型加载/权重初始化**：`CompressedTensorsConfig.get_quant_method`、`CompressedTensorsFusedMoEMethod`  
- **硬件后端适配**：CUDA、NPU、HIP（ROCm）以及 FlashInfer‑TRTLLM，均涉及新的 Scheme 判断逻辑。  

---

### 🔍 技术洞察

| 维度 | 影响描述 |
|------|----------|
| **架构影响** | - 引入 **Scheme 抽象层**，实现 **Linear 与 MoE 量化解耦**，以后添加新量化方式只需实现对应 Scheme 而无需改动 `QuantizationConfig`。<br>- `layer.scheme` 成为每个 MoE 层的统一入口，统一了 `create_weights`、`process_weights_after_loading`、`apply_weights` 的调用路径。<br>- `CompressedTensorsFusedMoEMethod` 只负责 delegating，极大降低了原有 *MoE Method* 类的职责耦合度。<br>- 删除 `compressed_tensors_moe.py`（2190 行）后，代码体积下降，维护成本降低，且潜在的 **代码膨胀** 与 **重复实现** 被清除。 |
| **性能影响** | - **正面**：<br>1. 各 Scheme 采用专用 kernel（Marlin、FlashInfer、AIter、TRITON）并在 `process_weights_after_loading` 中一次性完成 weight 转换，运行时直接使用已经优化好的布局，减少额外的 transpose / pack 步骤。<br>2. 对 NPU/ROCm 的动态 int4/int8 方案（`NPUCompressedTensors*DynamicMoE`）在运行时直接调用硬件专属 kernel，降低量化/反量化开销。<br>- **潜在负面**：<br>1. 为每层增加 `layer.scheme` 属性与多次 `isinstance` 检查，可能带来微小的 Python 运行时开销（在极大模型中累计）。<br>2. Scheme 选择逻辑在 `get_quant_method` 中加入了多层条件分支，首次加载时会略微增加 CPU 侧的初始化时间。 |
| **安全考虑** | - 该改动 **不涉及网络、文件系统或外部依赖**，安全风险本质上是 **配置误用**：<br>1. 若 `QuantizationConfig` 与实际模型层名不匹配，`layer.scheme` 会为 `None` → 抛异常，导致模型加载失败（可视为 **安全失效**，避免错误量化）。<br>2. 新增的 `Base*Scheme` 抽象若未正确限制 `apply_weights` 的输入/输出类型，可能在恶意构造的 `dispatch_output` 上触发未检查的数值异常（但仍在受控的内部代码路径中）。<br>- 删除巨大的旧文件 `compressed_tensors_moe.py` 同时 **减小了攻击面**，因为其中包含大量直接操作 `torch` 参数的低层实现。 |
| **可维护性** | - **模块化**：每种量化实现独立文件，易于定位问题与增删方案。<br>- **统一接口**：所有 Scheme 必须实现同一套抽象方法，IDE/类型检查可提前发现实现遗漏。<br>- **文档/兼容性挑战**：原有 `CompressedTensors*Method` 名称已在外部脚本、demo、第三方插件中出现，需要同步文档与兼容层（如保留旧别名或提供迁移指南）。 |
| **兼容性** | - **向后兼容**：`QuantizationConfig.get_quant_method` 仍返回 `LinearMethodBase` 或 `FusedMoEMethodBase` 的子类，只是内部实现改为 Scheme。<br>- 已有模型 checkpoint（使用旧 `compressed_tensors_moe` 权重）在 **权重加载阶段** 通过 `process_weights_after_loading` 完成同样的转换，理论上兼容。<br>- 需要确保 `torch` 版本、`compressed_tensors` 包的 API 与新 Scheme 中使用的函数保持一致（尤其是 `CompressionFormat.pack_quantized` 常量）。 |

---

### ⚠️ 潜在风险
1. **加载阶段回滚问题**  
   - `CompressedTensorsWNA16MoE` 在 `process_weights_after_loading` 中会 **改变参数形状**（Marlin 重排），若后续需要再次加载权重（如 `torch.nn.Module.load_state_dict` 的 `strict=False` 重新加载），可能出现形状不匹配。  
2. **Scheme 名称不匹配**  
   - `QuantizationConfig` 依赖正则匹配层名 → 任何层名改动或自定义层会导致 `scheme = None`，进而触发 `ValueError`（模型启动失败）。  
3. **硬件分支差异**  
   - 新增的 HIP（ROCm）分支依赖 `is_hip` 与 `use_aiter` 环境变量。未在 CI 中覆盖的硬件路径可能出现 **未注册 kernel**、`ImportError` 等。  
4. **环境变量导致路径隐蔽**  
   - `SGLANG_USE_AITER` 会切换到 AIter kernel；如果在没有 AIter 编译好的环境下开启，运行时将报错。  
5. **多实例共享状态**  
   - `CompressedTensorsFusedMoEMethod` 通过 `layer.scheme` 持有实例，若同一 `layer` 被多次复用（例如在模型剪枝后重建）可能出现 **残留属性**（如 `is_marlin_converted`、`is_triton_converted`）导致不一致行为。  

---

### 💡 关注建议
| 建议 | 说明 |
|------|------|
| **完整回归测试** | 在 CUDA、NPU、ROCm 三

---

### fix: adding performance logging for nightly diffusion (#18023)
**SHA**: `f1efb46` | 🔗 [查看提交](https://github.com/sgl-project/sglang/commit/f1efb46bdd1b1b082ea3f32f416000018b30f83c)

**🎯 变更类型**：功能增强 / 性能优化 / 重构  

**⚡ 重要程度**：🔴高  

**📋 变更摘要**  
本次提交为 SGLang 项目新增 Diffusion 模型的性能采集与可视化能力。核心改动包括：  
1. 在 GitHub Actions nightly 工作流中添加 Diffusion 性能指标收集、保存为 JSON 并上传为 Artifact。  
2. 扩展 Web 仪表盘（`performance_dashboard/app.js`）以支持 Diffusion 相关指标（e2e、denoise 等）并实现文本/扩散数据的动态切换。  
3. 重构 pytest 测试基础设施：通过 `conftest.py` 使用 StashKey 统一收集 Diffusion 性能结果，生成 Markdown 报告、写入 GitHub Step Summary 并输出 JSON。  
4. 新增 CI 脚本 `save_diffusion_metrics.py` 将 Diffusion JSON 结果转化为仪表盘统一格式；`merge_metrics.py` 支持两类 metric 文件的统一合并。  

预期效果是实现 nightly CI 对 Diffusion 任务的自动化性能监控，并在统一的 Performance Dashboard 上展示，与现有文本/VLM 基准保持一致。

---

**🎯 影响范围**  
- CI 工作流：`.github/workflows/nightly-test-nvidia.yml`（1‑GPU、2‑GPU 两套 Diffusion 测试）  
- 性能仪表盘前端：`docs/performance_dashboard/app.js`  
- 测试层：`python/sglang/multimodal_gen/test/server/conftest.py`、`test_server_common.py`  
- CI 脚本：`scripts/ci/save_diffusion_metrics.py`、`scripts/ci/merge_metrics.py`  

---

**🔍 技术洞察**  

| 维度 | 影响分析 |
|------|----------|
| **架构影响** | - 引入 **pytest StashKey** 机制，将跨模块的 Diffusion 性能结果统一存放在 `config.stash`，避免全局变量导致的模块双加载问题。<br>- 新增 **performance dashboard** 前端数据模型，区分 `text` 与 `diffusion` 两类 metric，并在切换过滤器时动态生成对应的 tab 与图表。<br>- CI 端通过 `save_diffusion_metrics.py` 将 Diffusion 结果重新组织为与已有 `metrics-*.json` 相同的结构，保证后端 `merge_metrics.py` 能一次性合并所有指标。 |
| **性能影响** | - CI 增加了两步：运行 `save_diffusion_metrics.py` 与上传 Artifact，预计额外耗时 **< 2 min**（主要是 JSON 序列化与网络上传），对整体 nightly 时长影响有限。<br>- 前端在渲染 Diffusion 数据时，采用 **按测试名分组**（而非批大小），数据量通常远小于文本的 batch‑size 维度，渲染开销可忽略。 |
| **安全考虑** | - 仅使用环境变量 `GPU_CONFIG`、`GITHUB_STEP_SUMMARY`、`SGLANG_DIFFUSION_SLACK_TOKEN`（已在原工作流中使用），无新增敏感信息泄露风险。<br>- 脚本读取本地 JSON 并写入 CI Artifact，未涉及外部网络请求，安全风险极低。 |
| **可维护性** | - 将 Diffusion 与 Text/VLM 逻辑通过 `type` 字段区分，使后续新增其他模型类型时可直接在 `metricTypes` 中扩展。<br>- `conftest.py` 中的 StashKey 只在本仓库内部使用，避免了模块级全局变量导致的测试并发冲突。<br>- 新增的脚本与修改均带有丰富的日志打印，便于调试。 |
| **兼容性** | - 通过 `detectCurrentDataType()` 在前端动态判断数据类型，保持原有 Text/VLM 仪表盘功能不受影响。<br>- `merge_metrics.py` 兼容旧的 `metrics-*.json` 与新产生的 `diffusion-metrics-*.json`，不会破坏现有合并逻辑。 |

---

**⚠️ 潜在风险**  

1. **结果文件缺失或格式不匹配**  
   - `save_diffusion_metrics.py` 依赖 `diffusion-results.json`。若前置测试未成功写入该文件，后续步骤会生成空的 metric 文件，导致仪表盘出现 “无数据”。  
   - 建议在 CI 中加入对 `diffusion-results.json` 是否存在的显式检查，若缺失则 `fail-fast` 或给出警告。  

2. **Artifact 大小与保留期限**  
   - 每次 nightly 将上传两套 Diffusion JSON，若结果数据快速增长（例如加入更多测试），可能触发 GitHub Artifact 存储上限。建议在 `save_diffusion_metrics.py` 中压缩（`gzip`）或在 CI 中定期清理旧 Artifact。  

3. **StashKey 跨进程/并发问题**  
   - 虽然 StashKey 本身是进程内安全的，但在并发运行多个 pytest worker（`-n`）时，可能出现结果写入竞争。当前实现为 `list` 的 `extend`，在单进程下安全；若未来开启并行测试，需要改为线程/进程安全的合并方式（例如使用 `multiprocessing.Manager().list()` 或文件锁）。  

4. **前端数据切换 Bug**  
   - `detectCurrentDataType()` 通过 `result.test_suite` 判断 Diffusion，若未来出现非 Diffusion 测试但 `test_suite` 为空，可能误判。可以在判断时同时检查指标字段是否包含 `e2e_ms` 等 Diffusion 专有字段。  

5. **回滚与兼容**  
   - 旧的仪表盘用户若未升级前端代码，仍会请求 `metrics-*.json`，因此新增 Diffusion 文件不影响已有用户。但若在 `merge_metrics.py` 中出现异常导致整体 `metrics.json` 生成失败，所有仪表盘都将失效。建议在合并脚本中加入异常捕获并保留已有成功部分。

---

**💡 关注建议**  

1. **CI 稳健性**  
   - 在 `nightly-test-multimodal-server-*` 作业的 `run` 步骤后加入 `if: failure()` 检查，若 Diffusion 测试因资源不足失败，则在后续步骤中明确标记为 “No diffusion metrics”。  
   - 为防止空文件产生，可在 `save_diffusion_metrics.py` 中加入 `if not raw_results: exit(0)` 并在 workflow 打印提示。  

2. **数据验证**  
   - 为 `diffusion-metrics-*.json` 添加 JSON Schema 校验（在 CI 步骤中执行），确保字段完整性（`e2e_ms`、`avg_denoise_ms` 等必须为数值），提前捕捉结构性错误。  

3. **前端优化**  
   - 将 `metricTypes` 中的 `type` 改为枚举常量，避免硬编码字符串导致后续新增类型时遗漏。  
   - 考虑在仪表盘增加 “数据类型切换” 下拉框，允许用户手动强制选择 `text` 或 `diffusion`，提升可操作性。  

4. **文档同步**  
   - 更新项目的 **Performance Dashboard** 使用说明，明确新增的 Diffusion 指标意义、单位及解读方式。  
   - 在 CI README 中注明 `diffusion-results.json` 的生成位置以及 `save_diffusion_metrics.py` 的调用方式，帮助新贡献者快速定位。  

5. **长远规划**  
   - 若计划继续加入 **Video**、**Audio** 等多模态任务，建议抽象出统一的 **MetricProvider** 接口，前端通过插件化方式注册新的 `type`，后端统一通过 `merge_metrics.py` 合并。  

--- 

**结论**  
此次提交为 SGLang 引入了 Diffusion 模型的全链路性能监控，涉及 CI、测试、前端三大块的协同改造。整体实现思路清晰，兼容性良好，但需关注结果文件完整性

---

### fix: unifying docker image build pipeline (#18814)
**SHA**: `2050875` | 🔗 [查看提交](https://github.com/sgl-project/sglang/commit/2050875424b780aea83fa724b72f0f2e441e680c)

**🎯 变更类型**：重构 / 架构变更  
**⚡ 重要程度**：🔴高  
**📋 变更摘要**：  
统一了 Docker 镜像的构建与发布工作流，合并原先的 CUDA‑13、PR‑专用以及普通开发镜像流水线到 `release-docker-dev.yml`。新增 `pr_number`、`tag` 两个手动触发参数，实现自定义标签、PR 镜像以及 Nightly 构建的统一管理；同时保留并改进了 Nightly 镜像清理逻辑。

**🎯 影响范围**：  
- CI/CD 工作流 `.github/workflows/release-docker-dev.yml`（核心构建、推送、manifest 合并、旧标签清理）  
- 删除的旧工作流 `release-docker-cu13.yml`、`release-docker-dev-pr.yml`（不再单独维护）  
- Docker Hub 上的镜像标签策略（`dev-x86…`、`dev-arm64…`、`dev‑cu13…`、自定义/PR 标签）  

**🔍 技术洞察**  

- **架构影响**  
  - **CI 流水线统一**：原本分散在 3 份 workflow（CUDA‑13、普通 dev、PR‑dev）的构建逻辑被合并，矩阵 (`matrix.arch_tag`) 同时驱动 CUDA 12 与 CUDA 13。  
  - **标签生成逻辑抽象**：通过 `inputs.tag`、`inputs.pr_number` 统一生成 `dev-{arch}{-suffix}`，并在 `manifest` 步骤中统一创建多架构镜像。  
  - **构建来源切换**：Nightly（`schedule` 触发）使用 `USE_LATEST_SGLANG=1` 拉取最新发布；手动或 PR 构建使用 `BRANCH_TYPE=local`，保证构建基于当前源码。  
  - **并发控制**：`concurrency` 按 tag / PR 编号分组，防止相同 tag 的并行构建相互取消。  

- **性能影响**  
  - **构建时间**：矩阵条目从 2（x86/arm64）提升至 4（额外 CUDA‑13 两个平台），单次 CI 时长会略增约 30‑40%。  
  - **磁盘空间**：保留 `free-disk-space` 步骤，仍可在 GitHub runners 上回收大部分无用缓存，避免因额外构建导致磁盘不足。  
  - **缓存**：`--no-cache` 仍然开启，保持镜像可重复、无残留缓存，未引入额外的构建缓存层。  

- **安全考虑**  
  - **凭证使用**：仍通过 `secrets.DOCKERHUB_USERNAME/TOKEN` 登录 Docker Hub，未泄露。  
  - **Tag 删除脚本**：通过 `jq` 过滤匹配 `^nightly-${base}-[0-9]` 的标签，删除除最新 14 条之外的 Nightly 标签。正则过滤防止误删非 Nightly 标签，但若自定义 `tag` 与 Nightly 前缀意外重合，仍有误删风险。  
  - **输入处理**：`inputs.tag`、`inputs.pr_number` 直接拼接到 tag 名称，未进行额外字符过滤。若恶意用户在 fork 中提交 PR，可以尝试注入特殊字符，导致镜像 tag 不符合规范或 Docker Hub 拒绝。建议在 CI 中对输入做白名单校验（仅允许字母、数字、`-`、`_`）。  

**⚠️ 潜在风险**  

1. **标签冲突**  
   - 自定义 `tag` 与已有 Nightly/PR 前缀相同会导致同一镜像被多次覆盖或误删。  
2. **误删 Nightly 镜像**  
   - 正则 `test("^nightly-${{ matrix.variant.base }}-[0-9]")` 只匹配数字开头的日期部分；若后续引入诸如 `nightly-dev-rc-2024...`，可能不被保留。  
3. **构建失败的回滚**  
   - 统一工作流在同一次运行中同时构建 CUDA 12 与 13，任一平台失败会导致整个 workflow 失败，进而阻塞所有标签的发布。需要在后续考虑 `continue-on-error` 或分段构建。  
4. **并发取消**  
   - `concurrency` 使用 `${{ inputs.tag || inputs.pr_number || 'nightly' }}`，若多个手动触发使用相同自定义 tag，会互相取消，导致偶发构建缺失。  
5. **权限泄露风险**  
   - `curl` 调用 Docker Hub 登录接口的请求体中直接引用 secret，虽然在 GitHub Actions 中安全，但日志泄露风险仍需关注（默认不会打印 secret）。  

**💡 关注建议**  

1. **输入校验**  
   - 在 workflow 开头使用 `if`/`run` 步骤检验 `inputs.tag`、`inputs.pr_number` 是否只包含安全字符（`^[a-zA-Z0-9_-]+$`），若不符合则 `exit 1`。  

2. **分离构建阶段**  
   - 将 CUDA‑12 与 CUDA‑13 的构建分成两个独立 job，利用 `needs` 关系让 Nightly manifest 只在对应平台成功后执行，防止单个平台故障影响全部标签。  

3. **增强 Nightly 清理**  
   - 将保留数量做为可配置变量（如 `retain: 14`），并在正则中明确匹配完整的日期格式 `nightly-${base}-[0-9]{8}-[a-f0-9]{8}`，避免误删。  

4. **日志审计**  
   - 为 `docker login` 与 `curl` 步骤添加 `mask` 以确保敏感 token 不会意外打印到日志。  

5. **监控构建时长**  
   - 在 `workflow_run` 后添加通知（如 Slack）报告各平台构建耗时，帮助判断是否需要进一步的并行优化或缓存策略。  

6. **文档同步**  
   - 更新项目 README 与 Docker 镜像使用说明，明确新标签命名规则（`dev-x86`, `dev-arm64`, `dev-x86-cu13`, `dev-arm64-cu13`, `dev-pr-<num>`, `dev-<custom>`），并提醒用户使用 `docker pull lmsysorg/sglang:<tag>`。  

通过上述审查，可确保统一的 Docker 镜像构建流水线在提升维护效率的同时，降低因标签冲突或误删导致的生产风险。

---

### Nsa trtllm mla sparse fp8 support with Deepseek v3.2 NVFP4 (#18389)
**SHA**: `0ffd0a3` | 🔗 [查看提交](https://github.com/sgl-project/sglang/commit/0ffd0a3995e537c2ec6f450cbb7d4b4db44550aa)

**🎯 变更类型**：功能增强 / 性能优化  
**⚡ 重要程度**：🔴 高  

**📋 变更摘要**  
本次提交为 SGLang 添加了对 **TRT‑LLM MLA（稀疏）+ FP8** 的完整支持，并在 DeepSeek‑V3.2 上实现了 3‑5× 的吞吐提升（以牺牲少量精度为代价）。为此新增了 `--nsa-prefill-backend` / `--nsa-decode-backend` 的可选值 `trtllm`，实现了 FP8 量化‑RoPE 融合、KV‑Cache 布局重构、内存池维度覆盖等一系列底层改动，同时同步更新了文档、示例及单元测试。

---

### 🎯 影响范围
- **核心注意力层**：`sglang/srt/layers/attention/nsa_backend.py`、`trtllm_mla_backend.py`、`utils.py`  
- **模型运行时**：`model_runner_kv_cache_mixin.py`（KV‑Cache 大小计算）  
- **内存池**：`srt/mem_cache/memory_pool.py`（FP8 KV‑Cache 维度覆盖）  
- **DeepSeek‑V3.2 示例文档** 与 **服务器启动参数文档**  
- **单元测试**（`test_nsa_pool_host_unit.py`、`test_nsa_indexer.py`）  

---

### 🔍 技术洞察

| 维度 | 说明 |
|------|------|
| **架构影响** | • 引入 **TRT‑LLM MLA** 作为新的 NSA 后端；<br>• 为 FP8 路径增加 **量化 + RoPE 融合** (`mla_quantize_and_rope_for_fp8`)；<br>• KV‑Cache 维度在 FP8 场景下通过 `override_kv_cache_dim` 动态计算，避免原有 `kv_lora_rank + qk_rope_head_dim` 布局的额外存储开销；<br>• `ModelRunner` 在初始化 MemoryPool 时会传入计算后的 kv 缓存维度；<br>• `SpeculativeBackend` 循环次数由 `speculative_num_steps` → `speculative_num_steps‑1` 修正，确保后端数组不越界。 |
| **性能影响** | • **TRT‑LLM MLA + FP8** 在 Blackwell (SM100) GPU 上可直接使用 `trtllm-mla` 稀疏 kernel，配合 FP8 KV‑Cache，可实现 **3–5×** 的推理加速（文档已注明精度略有下降）。<br>• 通过一次 fused kernel 完成 **RoPE + FP8 量化**，显著降低 kernel launch 开销与显存搬移。<br>• `use_mha` 判定逻辑采用 `mha_max_kv_len`，在 prefill 使用 TRT‑LLM 时能够正确切换 MHA 与稀疏路径。 |
| **安全考虑** | • 该改动不涉及网络、文件系统或权限，仅在内部算子层面加入新 kernel。<br>• 需要确认 **FlashInfer** 与 **TRT‑LLM** 代码路径在不同 CUDA/cuDNN 组合下的安全性（防止异常崩溃）。<br>• FP8 量化路径对数值范围更敏感，若未严格校验 `pos_ids`、`cos_sin_cache` 的 dtype 与 shape，可能导致 **数值溢出** 或 **精度异常**。 |
| **可维护性** | • 将原先 `_concat_mla_absorb_q_general` 从 `nsa_backend.py` 抽离到 `utils.py`，统一实现并加入 CUDA 判定，降低重复代码。<br>• 新增 `mla_quantize_and_rope_for_fp8`，逻辑集中在一个函数，便于后续独立单元测试。<br>• 通过 `ModelRunner.calculate_mla_kv_cache_dim` 将 KV‑Cache 大小计算封装，降低内存池构造时的硬编码风险。 |

---

### ⚠️ 潜在风险

1. **精度回退**  
   - 使用 FP8 KV‑Cache 与 `trtllm` 后端会导致 **数值精度下降**，尤其在梯度敏感的任务（如对数几率校准）可能出现显著误差。需要在产品层提供 **显式警告** 并建议用户开启/关闭该模式。

2. **硬件兼容性**  
   - `trtllm-mla` 仅在 **Blackwell (SM100) / Hopper (SM90)** GPU 上可用。若用户在其他 GPU（如 Turing、Ampere）上误选 `trtllm`，会在运行时触发 `assert` 或未知行为。建议在 CLI 参数解析时加入 **硬件检测** 并给出友好错误信息。

3. **FP8 量化路径**  
   - `mla_quantize_and_rope_for_fp8` 依赖 `flashinfer.rope.mla_rope_quantize_fp8`。若 FlashInfer 版本不匹配或未编译相应 kernel，可能导致 **运行时异常**。需要在入口检测 `is_flashinfer_available()` 并校验所需函数是否存在。

4. **内存布局变化**  
   - `override_kv_cache_dim` 现在必须在 **非‑trtllm** FP8 场景下提供。若外部代码仍使用旧的 `MemoryPool` 构造签名（未传递 `kv_cache_dim`），将触发 `TypeError`。所有自定义 MemoryPool 调用需同步更新。

5. **Speculative Backend 循环修正**  
   - 将 `speculative_num_steps` 循环范围改为 `-1`，若外部插件仍假设原有循环计数（例如自定义 backend 列表长度），可能出现 **索引缺失**。建议在插件侧使用 `ModelRunner.speculative_num_steps` 读取实际循环次数。

---

### 💡 关注建议

| 对象 | 建议 |
|------|------|
| **开发者** | 1. 在 `launch_server` 参数校验中加入 **GPU SM 版本检测**，若选择 `trtllm` 并硬件不满足，直接报错并提示可选后端。<br>2. 为 FP8 量化路径编写 **单元测试**（随机输入 vs FP8‑后端输出对比），确保 `mla_quantize_and_rope_for_fp8` 与 FlashInfer kernel 行为一致。<br>3. 更新 CI 环境，确保 **FlashInfer ≥ 0.5**（含 `mla_rope_quantize_fp8`）已安装。 |
| **用户** | 1. 在 Blackwell 平台使用 `--nsa-prefill-backend trtllm --nsa-decode-backend trtllm --kv-cache-dtype fp8_e4m3fn` 可获得最大加速，注意阅读文档中 **“accuracy impact”** 部分。<br>2. 若对精度要求严格，建议保留原有 `flashmla_*` 后端或显式关闭 FP8（`--kv-cache-dtype bf16`）。<br>3. 使用 `--disable-flashinfer-autotune` 可避免自动切换到不兼容的后端。 |
| **维护者** | 1. 将 `kv_cache_dim` 参数统一写入 **`ModelConfig`**，避免在多个类构造函数中重复计算。<br>2. 考虑在 `utils.concat_mla_absorb_q_general` 中加入 **shape 检查**（如 `q_nope.shape[-1]` 与 `q_rope.shape[-1]`），提前捕获不匹配错误。<br>3

---

### fix(sgl-kernel): use >= 120 for SM12x CUDA kernel dispatch (#18750)
**SHA**: `0d30896` | 🔗 [查看提交](https://github.com/sgl-project/sglang/commit/0d3089601547dd99412dd51427733c304ab2084a)

**🎯 变更类型**：Bug修复  
**⚡ 重要程度**：🔴高  
**📋 变更摘要**：将原本仅在 SM 12.0（`sm_version == 120`）上的 CUDA kernel 调度条件改为 `sm_version >= 120`，使得 SM 12.1、12.2 等更高版本的 GPU 也能走相同的 FP8 / FP4/ MoE 调度路径，防止在这些硬件上回退到不支持的旧实现导致错误或性能退化。  

**🎯 影响范围**：  
- `sgl-kernel/csrc/gemm/fp8_blockwise_gemm_kernel.cu`（FP8 Blockwise GEMM）  
- `sgl-kernel/csrc/gemm/nvfp4_scaled_mm_kernels.cu`（FP4 Scaled MM）  
- `sgl-kernel/csrc/moe/nvfp4_blockwise_moe.cu`（MoE 中的 FP4 Blockwise GEMM）  

**🔍 技术洞察**  
- **架构影响**：原来代码只针对 SM 12.0（即 CUDA 12.0/12.1 的 Ampere‑X）做特化；现在扩大到所有 SM 12.x（包括后续的 12.1、12.2、12.3 等），保证在最新的 NVIDIA Hopper、Ada Lovelace 等硬件上仍使用最优实现，提升兼容性。  
- **性能影响**：调度逻辑本身未改动，仅放宽了版本判断。实际运行在更高 SM 时仍会走针对 SM12x 优化的 kernel，避免回退到旧的、可能较慢的实现，因而在新 GPU 上可获得预期的最高性能。对已有 SM12.0 硬件的性能保持不变。  
- **安全考虑**：变更仅涉及版本检查，无引入新库、系统调用或内存访问模式，安全风险极低。  

**⚠️ 潜在风险**  
1. **未来 SM 版本兼容性**：`>= 120` 暗含假设所有后续 SM12x 均兼容当前 SM12实现。若未来某个 SM12x 取消或修改了相关指令集，仍会错误地使用该实现，导致运行时错误或数值不一致。  
2. **编译器/宏定义不一致**：代码仍使用 `CUTLASS_ARCH_MMA_SM120A_SUPPORTED` 等宏判断，若编译环境未正确识别更高 SM 版本，可能出现宏未定义而走不到该分支的情况。  
3. **测试覆盖不足**：目前仓库的 CI 可能仍只覆盖 SM12.0 实例，缺少对 SM12.1/12.2 等硬件的回归测试。  

**💡 关注建议**  
- **新增硬件验证**：在 CI 中加入针对 Ada/Hopper（SM12.1/12.2）GPU 的单元/集成测试，确保数值正确性和性能不退化。  
- **防御性检查**：如有可能，添加运行时日志或断言，确认 `sm_version` 实际支持的指令集（例如检查 `cutlass::arch::Sm80` 等），在未来 SM 版本变更时更易定位问题。  
- **文档更新**：在 README/CHANGELOG 中注明此更改，使 downstream 开发者了解对 SM12x 系列的兼容扩展。  
- **长期维护**：考虑在未来将判断抽象为 “SM >= SM12x && 支持对应的 CUTLASS 特性”，以免硬编码 `120` 带来的维护负担。  

---  

---

### feat: expose consistent_hashing policy in Python router CLI args (#17972)
**SHA**: `f759960` | 🔗 [查看提交](https://github.com/sgl-project/sglang/commit/f759960ac23badbaa21e16bd3dbbac29f8223b2f)

**🎯 变更类型**：功能增强  

**⚡ 重要程度**：🔴高  

**📋 变更摘要**：  
- 在 Python 侧路由器 CLI 参数 `router_args.py` 中新增 `consistent_hashing` 与 `prefix_hash` 两种负载均衡策略的选项。  
- 这些选项同时在全局 `--policy`、前缀预填 `--prefill-policy` 与解码 `--decode-policy` 中可选，用以在 PD（prefill‑decode）模式下细粒度控制节点选择。  
- 目标是让用户能够在 Python 接口上直接使用已有的哈希类路由算法，提升路由行为的可配置性与可预测性。  

**🎯 影响范围**：  
- `sgl-model-gateway/bindings/python/src/sglang_router/router_args.py`（CLI 参数解析）  
- 与路由策略对应的底层实现（可能在 Rust/C++）  
- 使用 Python Router CLI 的所有部署脚本、CI 与文档  

**🔍 技术洞察**：  
- **架构影响**：  
  - 仅在 Python 包层面扩展了参数枚举，不涉及核心路由逻辑的代码改动。  
  - 若底层实现已经支持这两种策略，则本次改动是一次“暴露层”。若实现尚未完备，会导致前端‑后端不匹配的情况，需要在后端同步实现或在 Python 包中加入兼容性检查。  
- **性能影响**：  
  - `consistent_hashing` 与 `prefix_hash` 都基于哈希计算，额外的 CPU 开销极低（一次哈希一次路由决策），相较于随机或轮询几乎可以忽略。  
  - 在高并发预填/解码场景下，哈希分配可提升缓存命中率，潜在降低跨节点通信开销，对整体吞吐有正面作用。  
- **安全考虑**：  
  - 参数本身不涉及安全敏感操作。  
  - 需要注意：哈希算法若被恶意操控（例如提供特制请求前缀），可能导致请求集中到少数节点，形成 DoS（服务拒绝）风险。建议使用稳健的散列函数并在后端做请求速率限制。  

**⚠️ 潜在风险**：  
1. **不匹配风险**：如果底层路由器未实现 `consistent_hashing` / `prefix_hash`，用户在 CLI 传入这些值会触发运行时异常或回退至默认策略，导致部署不可预期。  
2. **默认值冲突**：新增选项未修改默认值，仍使用 `RouterArgs.policy`（可能是 `random`），但文档若未同步，使用者可能误以为新策略是默认开启。  
3. **兼容性**：老版本的 Python 包或旧的部署脚本仍会使用 `--policy` 但未包含新选项，若强制升级 CLI 解析而后端未同步，可能出现 “未知策略” 错误。  
4. **参数组合错误**：`--policy` 与 `--prefill-policy`、`--decode-policy` 的组合若出现不兼容（如全局使用 `consistent_hashing` 而子策略仍为 `random`），可能导致路由行为不一致，增加调试成本。  

**💡 关注建议**：  
- **文档与示例**：在官方 README 与 CLI 手册中补充 `consistent_hashing` 与 `prefix_hash` 的使用说明、适用场景以及对底层实现的前提。提供示例命令行。  
- **后端支持校验**：在 Python 包启动时，检测底层路由模块是否实际支持新策略，若不支持则给出明确错误信息并建议回退。  
- **单元/集成测试**：新增针对这两种策略的端到端测试，涵盖 PD 模式下的前置/解码路由路径，验证负载均衡的分布与缓存命中率。  
- **回滚机制**：保持 `--policy` 的默认值不变，确保升级不影响已有生产环境；如需默认启用新策略，务必通过版本号提升或显式的迁移指南。  
- **安全防护**：在后端实现中使用抗冲突的散列函数（如 SipHash、xxHash），并在路由入口加入请求速率/负载监控，防止哈希攻击导致节点热点。  

通过上述措施，可将新策略快速、安全地交付给用户，同时降低因暴露层不匹配而产生的运行时风险。

---

#### 🟡 中重要度变更 (20)

### refactor FAKE transfer backend and remove --disaggregation-decode-enable-fake-auto parameter (#18345)
**SHA**: `1b3513a` | 🔗 [查看提交](https://github.com/sgl-project/sglang/commit/1b3513a7e49f0182ffe1762bd72442879608b3ae)

**变更类型**：重构 / 功能增强  
**重要程度**：🟡 中  

**变更摘要**  
1. 删除 `--disaggregation-decode-enable-fake-auto` 参数，改为统一使用 `disaggregation_transfer_backend="fake"` 来开启 FAKE 传输模式。  
2. 重构 FAKE 后端实现：新增 `FakeKVManager`，统一在 `get_kv_class` 中注册；相应地在 `conn.py`、`transfer_engine.py`、`decode.py`、`data_parallel_controller.py` 等文件中改为判断 `server_args.disaggregation_transfer_backend == "fake"`。  
3. 文档和 CLI 参数同步删除该 flag，相关初始化参数也随之去除。  

**影响范围**  
- `sglang/srt/server_args.py`、CLI 参数解析  
- `sglang/srt/disaggregation/*`（FAKE 连接、engine、utils）  
- `sglang/srt/disaggregation/fake/conn.py`（新增 Manager）  
- `sglang/srt/disaggregation/decode.py`、`data_parallel_controller.py`（逻辑分支）  
- 文档 `server_arguments.md`  

**关注建议**  
1. **兼容性**：删除 flag 可能导致旧脚本仍尝试使用 `--disaggregation-decode-enable-fake-auto`，建议在入口层加入兼容警告或自动映射到新参数，以免用户启动失败。  
2. **测试覆盖**：确认所有使用 FAKE 模式的单元/集成测试已更新为 `--disaggregation-transfer-backend fake`，尤其是 warm‑up、bootstrap‑host 为 `FAKE_BOOTSTRAP_HOST` 的路径。  
3. **文档同步**：检查其它文档或 README 中是否仍出现旧参数描述，全部统一为新参数。  
4. **异常处理**：在 `AscendTransferEngine.initialize` 中已去掉 fake‑mode的早退出逻辑，确保在 fake 模式下不会错误调用真实后端的初始化接口。  
5. **日志与监控**：FAKE 模式启动时仍应有清晰的 INFO 日志（如 “FAKE transfer backend enabled”），便于运维排查。  

总体来说，此次重构简化了 FAKE 模式的打开方式，消除了冗余 flag，提升了代码一致性。开发者在升级时注意参数迁移和相应测试即可。

---

### [diffusion][Wan]: fix sparse attention backends being applied to cross-attention (#17596)
**SHA**: `c1d1337` | 🔗 [查看提交](https://github.com/sgl-project/sglang/commit/c1d1337afc52e17f6f724fb7294dc8997e9ea0d1)

**🎯 变更类型**：Bug 修复  
**⚡ 重要程度**：🟡 中  
**📋 变更摘要**：修正了稀疏注意力后端被错误地用于跨模态（cross‑attention）路径的情况。为 `AttentionBackendEnum` 增加 `is_sparse` 属性，并在 `WanVideo` 与 `CausalWanVideo` 初始化时显式过滤掉所有稀疏后端，只保留密集后端供 cross‑attention 使用，去除了之前硬编码删除 `VIDEO_SPARSE_ATTN` 的逻辑。  

**🎯 影响范围**  
- `python/sglang/multimodal_gen/runtime/models/dits/wanvideo.py`  
- `python/sglang/multimodal_gen/runtime/models/dits/causal_wanvideo.py`  
- `python/sglang/multimodal_gen/runtime/platforms/interface.py`（新增 `is_sparse` 判定）  

**💡 关注建议**  
1. **后端兼容性**：自定义注意力后端若属于稀疏实现，需要在 `AttentionBackendEnum` 中加入对应成员，`is_sparse` 判定会自动排除其用于 cross‑attention。  
2. **单元测试**：建议补充对 `WanI2VCrossAttention` / `WanT2VCrossAttention` 在仅保留密集后端时的行为测试，确保不再触发稀疏实现的异常。  
3. **文档更新**：在平台/后端说明中明确 “稀疏后端仅适用于自注意力，跨注意力始终使用密集实现”。  
4. **性能验证**：在 CUDA 环境下跑一次完整的 T2V / I2V 流程，确认跨注意力计算仍保持预期的吞吐与数值稳定性。  

整体来看，此次修改通过统一的稀疏判定属性，避免了之前散落的硬编码过滤，提升了代码可维护性和后端扩展的鲁棒性。开发者在添加新后端时只需关注 `is_sparse` 标记即可，无需修改业务层逻辑。  

---

### [Perf] ~9.5x faster Blackwell MXFP4 MoE weight loading (#18858)
**SHA**: `b86c649` | 🔗 [查看提交](https://github.com/sgl-project/sglang/commit/b86c6491fa7080ccea00630935c9c88f9407b847)

**🎯 变更类型**：性能优化  
**⚡ 重要程度**：🟡 中  

**📋 变更摘要**  
本次提交对 **FlashInfer MXFP4 MoE** 权重加载路径进行重构，使用 **索引直接置换** 替代原有的 `shuffle_matrix_*` 实现，并在 `flashinfer.fused_moe.core` 中引入 `get_w2_permute_indices_with_cache`，为不同形状/设备缓存置换索引。整体改动约 89 行新增、19 行删除，去掉了日志输出，显著提升权重加载约 9.5 倍。

**🎯 影响范围**  
- `python/sglang/srt/layers/quantization/mxfp4.py`（核心权重加载、shuffle 替换）  
- 依赖 `flashinfer` 的 MoE 代码路径（`flashinfer.fused_moe.core`）  
- 可能间接受到 `sglang.srt.layers.moe` 与模型初始化流程的影响  

**💡 关注建议**  
1. **缓存管理**：新增的两层缓存 (`_flashinfer_mxfp4_permute_indices_cache`、`_flashinfer_mxfp4_permute_indices_device_cache`) 会随不同张量形状/设备不断增长，建议在模型卸载或进程结束时显式清理，或限制缓存大小防止 OOM。  
2. **兼容性**：`get_w2_permute_indices_with_cache` 属于 `flashinfer` 的内部 API，若 flashinfer 版本升级可能导致签名变更，请在 `requirements.txt` 中锁定对应版本或加入兼容层。  
3. **日志信息**：原先的 `log_info_on_rank0` 被移除，导致在权重 shuffle 前不再提示耗时，建议在关键路径添加适度的可选日志（例如通过环境变量控制）以便排查异常。  
4. **设备索引处理**：对 `x.device.index` 为 `None`（CPU 或未显式指定 GPU）时使用 `-1`，确认这在所有使用场景下都是合理的，特别是多进程/分布式环境。  
5. **单元测试**：加入针对不同 `epilogue_tile_m`、`num_elts_per_sf` 参数的正确性测试，确保置换后权重与原实现数值一致。  

总体而言，此次改动大幅提升 MXFP4 MoE 权重加载性能，风险主要集中在缓存增长和对内部 API 的依赖上，建议在正式发布前进行长期运行和多卡/不同 GPU 架构的回归验证。

---

### [Model] Add Qwen3ForRewardModel and fix Qwen3ForSequenceClassification (#17992)
**SHA**: `4f0409f` | 🔗 [查看提交](https://github.com/sgl-project/sglang/commit/4f0409f8aa59baa26892712d5ad65fc6a4e1fc13)

**🎯 变更类型**：功能增强  
**⚡ 重要程度**：🟡 中  

**📋 变更摘要**  
1. 在 `model_config.py` 中识别 `"Qwen3ForRewardModel"` 为生成类模型。  
2. 新增 `Qwen3ForPooledOutput` 基类并把原 `Qwen3ForSequenceClassification` 迁移为其子类，统一池化、分数层的实现逻辑。  
3. 实现更健壮的 `load_weights`：支持 QKV、gate‑up 参数的拆分与分片加载，过滤无关张量并给出缺失参数警告。  
4. 新增 `Qwen3ForRewardModel`（2‑层 MLP + Pooler），用于 RLHF/Best‑of‑N 场景。  
5. 相应测试 `test_reward_models.py` 增加 Qwen3‑Reward 示例。  

**🎯 影响范围**  
- `sglang/srt/models/qwen3_classification.py`（权重加载、模型结构）  
- `sglang/srt/models/qwen3_rm.py`（新 RewardModel）  
- `sglang/srt/configs/model_config.py`（模型类别判断）  
- 测试套件 `test/registered/models/`  

**💡 关注建议**  
- **权重兼容性**：对比官方 Qwen‑3 checkpoints，确认 `load_weights` 能正确映射所有 shard（尤其 `qkv_proj`、`gate_up_proj`）。如出现 “Parameter … not found” 警告，需检查命名或模型版本。  
- **量化/LoRA**：在使用 `QuantizationConfig` 或 LoRA 时，确保 `weight_loader` 仍被正确调用；可在 CI 中加入量化路径的覆盖测试。  
- **接口一致性**：`Qwen3ForPooledOutput` 只接受 `get_embedding=True`，调用方需更新文档或加入显式错误提示，防止误用。  
- **性能回归**：由于额外的权重过滤与循环，建议在大模型（>30B）上跑一次基准，确认启动时间和显存占用未明显上升。  
- **文档/注册**：在模型注册表 (`EntryClass`) 中加入 `Qwen3ForRewardModel`，并在 README/模型列表中标注 “RewardModel”。  

整体来看，此次改动为 Qwen‑3 系列提供了分类与奖励两大下游能力，结构上更清晰、权重加载更健全，但需在多种量化/分片配置下做一次完整验证。

---

### [diffusion] logging: improve peak vram logging (#18865)
**SHA**: `d0c94e1` | 🔗 [查看提交](https://github.com/sgl-project/sglang/commit/d0c94e136af60f28c5d9d9b7e22dcbe828a85603)

**🎯 变更类型**：功能增强（VRAM 峰值与内存池占用的日志记录）

**⚡ 重要程度**：🟡 中  
（新增日志字段、类名重构，对外行为变化有限，但涉及多个核心模块，需要注意兼容性）

**📋 变更摘要**  
1. 引入 `MemorySnapshot` 与 `RequestMetrics`，在 `perf_logger` 中统一管理时间与内存信息。  
2. 在 GPU 工作进程 (`gpu_worker.py`) 中：
   - 通过 `capture_memory_snapshot` 在 forward 前后、mem‑analysis 阶段捕获内存基线与峰值，并把快照写入 `RequestMetrics.memory_snapshots`。  
   - 记录 `reserved`、`allocated` 两类显存以及二者差值（内存池开销），并在日志中展示。  
3. CLI、调度层等入口改为使用 `RequestMetrics`，并在日志恢复时重新构造 `MemorySnapshot`。  
4. `StageProfiler` 新增 `capture_memory` 参数，支持在任意阶段自动记录内存快照。  
5. `PerformanceLogger.dump_benchmark_report` 与 `log_request_summary` 增加 `memory_checkpoints` 字段，便于离线分析。

**🎯 影响范围**  
- `python/sglang/multimodal_gen/runtime/utils/perf_logger.py`（核心数据结构、序列化）  
- `python/sglang/multimodal_gen/runtime/managers/gpu_worker.py`（显存采样、日志）  
- `python/sglang/multimodal_gen/runtime/pipelines_core/schedule_batch.py`（请求对象）  
- `python/sglang/multimodal_gen/runtime/entrypoints/cli/generate.py`（CLI 读取/恢复）  
- 可能的其他直接引用 `RequestTimings` 的模块（搜索全库需确认）。

**💡 关注建议**  

1. **兼容性检查**  
   - 项目中仍有 `from …perf_logger import RequestTimings` 的残留会导致 `ImportError`。建议在 `perf_logger.py` 中保留一个向后兼容的别名：  
     ```python
     RequestTimings = RequestMetrics   # 仅为兼容，后续逐步淘汰
     ```  
   - 与外部工具（如性能分析脚本）交互的 JSON 文件现在多了 `memory_checkpoints`，若已有解析逻辑，需要同步更新或容错处理。

2. **性能影响**  
   - `torch.cuda.memory_*` 查询在每个阶段都执行，开销极小（几微秒），但在大量小 batch 场景下会略微抬高整体 latency。可通过 `env SGLANG_DIFFUSION_STAGE_LOGGING=0` 或在 `StageProfiler` 中关闭 `capture_memory` 来关闭。

3. **日志与监控**  
   - 新增的 “Memory pool overhead” 直接帮助定位显存碎片化问题。建议在监控平台展示 `reserved`、`allocated` 与 `overhead%` 三条曲线。  
   - `peak_reserved_gb` 成为官方的 “Peak GPU memory” 指标，旧的 `peak_memory_gb` 已被废弃，文档和示例需同步更新。

4. **测试与验证**  
   - 添加或更新单元测试，验证：  
     - `RequestMetrics.to_dict()` 包含 `memory_snapshots` 并能被 `PerformanceLogger.dump_benchmark_report` 正确写入。  
     - `gpu_worker.do_mem_analysis` 在无 GPU 环境下仍能安全运行（返回全 0 快照）。  
   - 在 CI 中加入至少一次显卡（CUDA）跑通的集成测试，确保快照记录不会触发 `RuntimeError: CUDA out of memory`。

5. **文档与使用说明**  
   - 在 README / docstring 中说明新增的 `--perf-dump-path` 输出结构（`memory_checkpoints`），并给出常见的 “内存池开销” 解释。  
   - 如有自定义的性能分析脚本，需要增加对 `memory_checkpoints` 的解析示例。

**总结**  
本次改动把显存峰值信息从单纯的数值提升为完整的快照结构，极大提升了对 GPU 资源利用的可观测性。只要注意跨模块的类名更新与 JSON 兼容性，整体风险较低，可在下一个发布周期内平滑推广。

---

### [JIT kernel] hd=512,1024 in JIT QK norm (cta based) (#17515)
**SHA**: `ed22720` | 🔗 [查看提交](https://github.com/sgl-project/sglang/commit/ed22720c07b12b9d577d2c02d21618b2081e84b5)

**🎯 变更类型**：功能增强  
**⚡ 重要程度**：🟡 中  

**📋 变更摘要**  
1. 为 Q‑K 归一化（qknorm）引入了对 head‑dim = 512、1024 的 CTA‑级别实现，原先仅支持 ≤ 256 的 warp‑level kernel。  
2. 在 Python 基准脚本中加入 `HEAD_DIM_RANGE`，让 benchmark 能覆盖新 head‑dim；对应的测试用例也扩展到 512、1024。  

**🎯 影响范围**  
- **python/sglang/jit_kernel/benchmark/bench_qknorm.py** – 参数维度扩展、配置组合改变。  
- **python/sglang/jit_kernel/tests/test_qknorm.py** – 测试维度扩大。  
- **python/sglang/jit_kernel/csrc/elementwise/qknorm.cuh** – 新增 `fused_qknorm_cta`，新增 `QKNormKernelCTA` 与统一调度 `QKNormKernel`，对 `QKNormKernelWarp` 进行重命名。  

**💡 关注建议**  
1. **性能验证**：CTA 实现使用持久化 kernel，建议在不同 GPU 型号（sm 80/90）上跑完整基准，确认 512/1024 时相较于 warp‑level 真的有提升，并检查占用的共享内存是否接近上限。  
2. **兼容性检查**：`host::norm::should_use_cta` 的判断依赖 FP16/BF16 与 head‑dim，确保在 float32（若未来加入）或其他 dtype 时仍能正确分发。  
3. **代码维护**：新加入的 `QKNormKernelCTA` 与 `QKNormKernelWarp` 结构体几乎复制了原有逻辑，建议抽取公共部分（参数校验、LaunchKernel 代码）到模板基类，防止后续修改不一致。  
4. **测试覆盖**：当前单元测试仅检查正确性，建议补充性能回归测试，尤其是 `head_dim=512/1024` 与不同 batch、GQA 组合的执行时间。  
5. **文档更新**：README/benchmark 说明里加入对 head‑dim > 256 的新实现及使用限制（仅 FP16/BF16），避免用户误用。  

整体来看，此次提交为 Q‑K 归一化扩展了大 head‑dim 场景，提升了模型（如 LLaMA‑2‑70B）在高维度注意力中的可用性，只要做好性能回归和代码抽象，即可平滑上线。

---

### Support dumping gradients, parameters, lazy values (#18881)
**SHA**: `f554b3c` | 🔗 [查看提交](https://github.com/sgl-project/sglang/commit/f554b3c27bb96a9a238d8c4d6506d4a356676336)

**🎯 变更类型**：功能增强  
**⚡ 重要程度**：🟡 中  

**📋 变更摘要**  
1. 为 `sglang.srt.debug_utils.dumper._Dumper` 新增 `enable_value/enable_grad/enable_model_value/enable_model_grad` 四个开关，并通过环境变量 `SGLANG_DUMPER_*` 暴露。  
2. 实现 `dump_model` 接口，可一次性记录模型参数及其梯度；在普通 `dump` 中加入对 **lazy（可调用）值** 的 materialize 支持。  
3. 通过 `register_hook` 为需要的张量在反向传播时自动捕获梯度，并把前向 `forward_pass_id` 写入文件名，实现“未来梯度”收集。  
4. 新增 `_materialize_value` 辅助函数及相应单元测试，覆盖可调用值、梯度捕获、过滤、模型参数的各类组合场景。  

**🎯 影响范围**  
- `python/sglang/srt/debug_utils/dumper.py`（核心调试/dump 逻辑）  
- 相关测试 `test/registered/debug_utils/test_dumper.py`（新增大量测试）  
- 环境变量配置入口 `from_env`  

**💡 关注建议**  
- **开发者**：`register_hook` 会在每次 `dump` 时为张量创建一次钩子，请确保在高频调用场景（如训练循环中频繁 `dump` 同一张量）不会导致钩子累积而泄漏内存；如有需求可在 `dump` 前检查已有 hook 或提供取消接口。  
- **用户**：若仅关心前向值，关闭 `SGLANG_DUMPER_ENABLE_GRAD` 以避免额外的 hook 开销；若希望捕获梯度，请在 `dump` 前确保张量已 `requires_grad=True`，且在后续的反向传播中仍保持引用。  
- **部署**：新增的环境变量默认已开启值的 dump、关闭梯度 dump，使用前请通过 `SGLANG_DUMPER_ENABLE_GRAD=1`、`SGLANG_DUMPER_ENABLE_MODEL_GRAD=1` 等显式打开，防止意外产生大量文件。  
- **调试**：`dump_model` 会遍历 `named_parameters()`，因此仅适用于 `torch.nn.Module`；若模型内部还有自定义缓冲区（`register_buffer`），需要自行调用 `dump`。  

整体来看，此次改动大幅提升了 SGLang 调试的可视化能力，注意合理开启梯度捕获以免产生性能和存储负担。

---

### Collect upper level metadata to dump output (#18880)
**SHA**: `9a7d8d5` | 🔗 [查看提交](https://github.com/sgl-project/sglang/commit/9a7d8d5eb025d4686f284815ee835cfaf73207eb)

**🎯 变更类型**：功能增强  
**⚡ 重要程度**：🟡 中  

**📋 变更摘要**  
1. 在 `sglang/srt/debug_utils/dumper.py` 中新增 `_static_meta`（使用 `cached_property`），在每次 `dump` 时把全局/并行信息（world rank‑size、sglang 与 Megatron 的并行配置）写入 `meta`。  
2. 为获取 `world_size` 新增 `_get_world_size`，并实现 `_compute_static_meta`、`_collect_sglang_parallel_info`、`_collect_megatron_parallel_info` 三套收集函数。  
3. 测试用例同步扩展，验证 `meta` 中的静态字段、缓存行为以及异常情况下的容错。  

**🎯 影响范围**  
- **核心模块**：`sglang/srt/debug_utils/dumper.py`（元数据构造、`dump` 输出结构）  
- **测试**：`test/registered/debug_utils/test_dumper.py`（新增单元测试）  
- **分布式依赖**：涉及 `torch.distributed`、sglang 与 Megatron 的并行状态查询。  

**💡 关注建议**  

| 关注点 | 建议 |
|--------|------|
| **可选导入 & 容错** | 目前采用 `try/except (ImportError, AttributeError, AssertionError)` 捕获并返回 `{…_error: True}`，已基本安全。建议在返回的字典加上 `source: "sglang"` / `"megatron"`，方便排查。 |
| **缓存实现** | `cached_property` 只在 Python 3.8+ 可用，确认项目最低支持版本；若在低版本运行会报 `AttributeError`。可提供后备实现或显式限制 Python 版本。 |
| **元数据覆盖** | `output_data["meta"] = dict(**full_kwargs, **self._static_meta)` 会让用户自行传入的键被 **静态元数据** 覆盖（如用户提供 `world_rank`）。建议先合并 `self._static_meta`，再 `update(full_kwargs)`，或在文档中声明键冲突的行为。 |
| **性能影响** | `_compute_static_meta` 在首次访问时会调用多次分布式查询，开销可接受且已缓存。若在高频 `dump` 场景中多次创建 `Dumper` 实例，仍会重复计算，建议在进程启动时就实例化一次 `Dumper`（如已是现状）。 |
| **序列化大小** | 新增的并行信息会显著增大每个 `.pt` 文件（尤其是 Megatron 全套状态），在大规模实验中请确认磁盘/网络 IO 能够承受。可考虑加入开关 `include_parallel_meta=False`。 |
| **测试覆盖** | 新增的测试使用 `Path("/tmp")`，在 CI 环境可能产生残留文件。建议使用 `tmp_path`（已在其他用例中）统一管理临时目录，防止权限或并发问题。 |
| **文档 & API 稳定性** | `_static_meta`、收集函数为私有实现，但已在测试中直接引用。若未来计划公开此信息，建议在 `Dumper` 类的文档中说明 `meta` 的完整结构及可自定义字段。 |

总体来看，此次改动为调试/可视化提供了更完整的运行时上下文，提升了问题定位效率，风险主要在兼容性和键覆盖上。按上述建议进行微调后即可安全合并。

---

### Change dump output format to dict with value and metadata (#18879)
**SHA**: `949792d` | 🔗 [查看提交](https://github.com/sgl-project/sglang/commit/949792d0c658323249afc503e5b5655cdfdbab2d)

**🎯 变更类型**：功能增强（dump 输出结构从纯 Tensor 改为带元数据的 dict）  
**⚡ 重要程度**：🟡 中  

**📋 变更摘要**  
1. `Dumper.dump` 现在把要保存的对象包装成 `{"value": ..., "meta": {...}}`，其中 `meta` 包含全部关键字参数以及内部生成的上下文信息。  
2. `DumpLoader` 与 `dump_comparator` 在读取时检查返回对象是否为上述 dict，若是则自动取出 `value` 再继续使用。  
3. 相应单元测试改为验证 dict 结构及元数据的完整性，并新增对上下文信息的覆盖测试。  

**🎯 影响范围**  
- `python/sglang/srt/debug_utils/dumper.py`（核心 dump 实现）  
- `python/sglang/srt/debug_utils/dump_loader.py`、`dump_comparator.py`（读取兼容）  
- 依赖 dump 文件的内部工具或用户脚本（例如自定义分析 pipeline）  
- 测试模块 `test/registered/debug_utils/test_dumper.py`  

**💡 关注建议**  
1. **向后兼容**：当前代码在读取时已兼容旧的仅 Tensor 文件，但如果用户自行 `torch.load` 并直接使用返回值，仍会得到 dict。建议在文档或代码中加入 **deprecation warning**，提醒用户访问 `obj["value"]`。  
2. **元数据完整性**：`meta` 中会保存全部 `kwargs`，包括可能非常大的对象（如大张量的引用）。请确认不会无意中把不需要的对象序列化进文件，导致磁盘占用激增。  
3. **性能影响**：包装为 dict 增加一次对象创建与一次额外的元数据序列化，耗时和体积提升在可接受范围（< 5 %），但在高频 dump 场景下可通过 `enable_write_file=False` 或专门的 “raw” 模式规避。  
4. **参数检查**：`dump` 中对 `torch.nn.Parameter` 的处理改为 `value.data`，但仍保持 `meta` 中的原始 `value` 类型。若外部代码依赖 Parameter 的梯度信息，读取后应自行恢复。  
5. **测试覆盖**：新增 `TestDumpDictFormat` 已覆盖结构、上下文、业务自定义键等，建议继续在 CI 中保留对旧格式文件的回归测试，以防误删兼容层。  

总体来看，此次改动提升了调试可观测性，影响范围局限在 debug_utils 子模块，兼容层已实现，若在生产流程中直接使用 dump 文件，请留意上述兼容与性能细节。

---

### Flip dumper to disable by default and refactor environment handling (#18878)
**SHA**: `02816ab` | 🔗 [查看提交](https://github.com/sgl-project/sglang/commit/02816abc0d1712284bcc47c7163593675cc751a2)

**🎯 变更类型**：功能增强 / 重构  
**⚡ 重要程度**：🟡 中  
**📋 变更摘要**：  
1. 将 `sglang` 的调试 `dumper` 默认改为关闭，启动时需要显式打开或通过 HTTP 接口动态开启。  
2. 把 dumper 的配置全部抽象为构造函数参数，并提供 `from_env()` 工厂函数，由环境变量统一读取；同时新增布尔/整数/字符串环境变量解析工具。  
3. `environ.temp_set_env` 加入 `allow_sglang` 参数，避免误用 SGLANG 前缀的 env vars，并在测试中统一使用该方法设置 dumper 相关变量。

**🎯 影响范围**  
- `python/sglang/srt/debug_utils/dumper.py`（核心逻辑、默认行为、HTTP 服务器控制）  
- `python/sglang/srt/environ.py`（环境变量上下文管理）  
- 单元测试 `test/registered/debug_utils/test_dumper.py`（全部改为使用 `temp_set_env` 并显式开启 dumper）  

**💡 关注建议**  
- **开发者**：新的 `Dumper` 构造签名已变更，内部调用仍通过 `dumper = _Dumper.from_env()`，但如果在代码中手动实例化，需要提供完整参数。注意 `enable_http_server` 现在默认开启，若不需要可在 env `SGLANG_ENABLE_DUMPER_HTTP_SERVER=0`。  
- **用户**：默认关闭 dumper，若仍想保留旧行为请在启动时显式设置 `SGLANG_DUMPER_ENABLE=1`，或者通过 `curl -X POST http://localhost:40000/dumper -d '{"enable": true}'` 动态打开。  
- **测试/CI**：使用 `temp_set_env(allow_sglang=True, ...)` 替代直接修改 `os.environ`，确保在多进程分布式测试中环境恢复正确。  
- **后续**：若还有其它模块依赖原来的 `SGLANG_DUMPER_ENABLE` 默认值为 1，需检查并在相应启动脚本或文档中同步更新说明。

---

### [AMD] MORI-EP inter kernel type switch (#18437)
**SHA**: `5ddc84e` | 🔗 [查看提交](https://github.com/sgl-project/sglang/commit/5ddc84e33e64c7891597ecb9a4346a13c94e94c0)

**变更类型**：功能增强 / 轻量级重构  
**重要程度**：🟡 中  

**变更摘要**  
1. 将 Docker 镜像中 MORI‑EP 的源码提交哈希由 `b0dce4b…` 替换为 `20920706…`，同步上游改动。  
2. 在文档中新增环境变量 `SGLANG_MORI_DISPATCH_INTER_KERNEL_SWITCH_THRESHOLD`，用于控制 InterNode 调度 kernel 的自动切换。  
3. `python/sglang/srt/layers/moe/token_dispatcher/moriep.py`：  
   - `get_ep_dispatch_configs` 改为接收 `num_max_dispatch_tokens_per_rank` 参数，并根据上述阈值选择 `InterNodeV1LL`（低 token 场景）或 `InterNodeV1`（高 token 场景）。  
   - `init_mori_op` 将 `num_max_dispatch_tokens_per_rank` 透传给 `get_ep_dispatch_configs`。  

**影响范围**  
- **Docker 构建**：所有基于 `docker/rocm*.Dockerfile` 的镜像将拉取新的 MORI 代码。  
- **运行时调度**：`sglang/srt/layers/moe/token_dispatcher/moriep.py` 的调度配置逻辑改变，进而影响 **MORI‑EP** 的跨节点通信性能。  
- **文档**：`docs/references/environment_variables.md` 增加新 env 变量说明。  

**关注建议**  
1. **兼容性**：确认项目中是否还有其他调用 `get_ep_dispatch_configs()` 的位置（例如单元测试、示例脚本），若有应补充默认实参或统一改为 `get_ep_dispatch_configs(num_max_dispatch_tokens_per_rank)`.  
2. **性能验证**：在不同 `SGLANG_MORI_NUM_MAX_DISPATCH_TOKENS_PER_RANK`（如 128、512）和阈值设置下跑基准，确保切换到 `InterNodeV1LL` 能带来预期的低延迟或更好吞吐。  
3. **环境变量传播**：确保容器或集群启动脚本能够正确设置 `SGLANG_MORI_DISPATCH_INTER_KERNEL_SWITCH_THRESHOLD`，避免因未设置而默认回退到旧行为。  
4. **CI 更新**：将 Docker 镜像的构建脚本及 CI 流程同步到新的 `MORI_COMMIT`，并在 CI 中加入对新 env 变量的覆盖测试。  
5. **回滚准备**：若新 MORI 代码在特定硬件上出现兼容性问题，保留旧提交哈希以便快速回滚。  

总体而言，此次改动为 MORI‑EP 引入了更加细粒度的 kernel 选择策略，提升了在不同 token 规模下的性能弹性。开发者应重点验证新阈值在真实工作负载中的效果，并确保所有调用路径已适配新增参数。

---

### [diffusion] refactor: refactor server_args adjust and validate logics (#18863)
**SHA**: `0af9dcc` | 🔗 [查看提交](https://github.com/sgl-project/sglang/commit/0af9dcc407fd5a0363a08dad40c536d6ebc90b3d)

**变更类型**：重构 / 功能增强  
**重要程度**：🟡 中  

### 变更概览
1. **`wanvideo.py`**：将原来在跨注意力不支持时的 `logger.warning_once` 改为 `logger.debug`，降低不必要的警告噪声。  
2. **`server_args.py`**：对服务器启动参数的“调整‑校验”流程进行彻底拆分与重构：  
   - 将原来的散乱逻辑拆分成 `_adjust_*` 系列（并行、离线、量化、暖启动、端口、注意力后端、平台特性、autocast）以及对应的 `_validate_*` 系列（pipeline、offload、parallelism、cfg‑parallel）。  
   - 参数默认值改为 `None`（如 `tp_size`, `sp_degree`, `hsdp_shard_dim`），在 `_adjust_parallelism` 中统一填充默认 1 或推导值。  
   - 引入更严格的合法性检查：GPU 与 TP/SP/HS‑DP 之间的除余关系、`sp_degree` 必须等于 `ring_degree * ulysses_degree`、CFG 并行在单 GPU 场景下报错等。  
   - 自动推断 `attention_backend`、`attention_backend_config`、`ulysses_degree`、`ring_degree` 等，提升“零配置”启动体验。  
   - 对 `disable_autocast`、`dit_layerwise_offload`、`dit_offload_prefetch_size` 等细节进行更明确的默认与冲突检查。  

### 影响范围
- **启动入口**：`ServerArgs.__post_init__`、`add_cli_args`、`check_server_args` 均被重新组织，对所有使用 `sglang` 启动脚本的用户均有影响。  
- **并行配置**：`tp_size`、`sp_degree`、`hsdp_shard_dim` 等默认从 `-1` 变为 `None`，旧版通过 `-1` 表示“自动”将不再生效，可能导致启动时报错或行为变化。  
- **平台适配**：在 MPS、ROCM 等平台上自动关闭/开启相关特性，保持兼容性。  
- **日志**：跨注意力不支持的提示从 warning 降为 debug，降低启动时的噪声。  

### 开发者建议
- **参数兼容**：若仍希望使用 `-1` 形式的 “自动” 参数，请在代码层面恢复或在调用时显式传 `None`。  
- **单元测试**：补充针对 `_adjust_parallelism` 与 `_validate_parallelism` 的边界测试（如 `num_gpus` 与 `sp_degree` 不整除、CFG 并行单卡等），防止回归。  
- **文档更新**：更新 CLI 使用说明，说明 `--tp-size`、`--sp-degree`、`--hsdp-shard-dim` 默认为 `None` 并会自动推导。  

### 用户建议
- **检查配置**：升级后请重新执行一次 `sglang` 启动命令，确认日志中没有因参数不匹配抛出的 `ValueError`。  
- **显式指定**：如对并行度有特殊需求，建议在命令行中显式提供 `--tp-size`、`--sp-degree` 等，避免自动推导产生意外的并行布局。  
- **关注警告**：原先的跨注意力不支持警告已被降级为 debug，若需要关注该信息请打开调试日志。

---

### [VLM] Optimize Ernie4.5-VL rotary embedding with fused triton kernel (#18856)
**SHA**: `8a82c70` | 🔗 [查看提交](https://github.com/sgl-project/sglang/commit/8a82c70297fdf1a24c4e32d9111f0299d389d9c0)

**📝 变更概览**  
本次提交为 Ernie4.5‑VL 的 3‑D 旋转位置编码实现了 **triton 融合 kernel**，在 `forward_cuda` 中直接对 Q/K 进行原位旋转，避免了两次显存拷贝与 Python 循环。新增 `_triton_ernie45_rope_qk_fused`、`triton_ernie45_rope_fused_inplace`，并在 `Ernie4_5_VLRotaryEmbedding` 中加入 `torch.compile` 包装的 `_apply_rotary_emb`（备份原生实现），以及对 `positions` 为二维 `[3, N]` 的特殊路径。

**⚡ 关键影响范围**  
- `python/sglang/srt/layers/rotary_embedding.py`（核心实现）  
- 可能牵涉到使用该层的全部上层模型（如多模态视觉语言模型）  
- 依赖 `triton`、CUDA 环境；在没有 triton 的机器上仍会回退到原实现。

**🔍 中等深度审查要点**  

| 关注点 | 说明 | 建议 |
|--------|------|------|
| **Kernel 功能完整性** | 代码对 Neox‑style 与 GPT‑J‑style 两种 head 组织均实现了旋转，并依据 `section_hw` 选择对应的 (h,w) 或 t 轴。 | 添加单元测试覆盖：①全 0/全 1 位置；②`section_h!=section_w`、`section_h+section_w+section_t!=rd//2` 抛异常；③不同 `head_size/rotary_dim` 组合，尤其非 2ⁿ 的情况。 |
| **边界 & 对齐** | 使用 `triton.next_power_of_2` 进行 padding，`num_warps` 取 4/8 的经验值；未显式控制 block‑size（默认 1），可能出现 **num_tokens > 2³¹‑1** 的 overflow（极端情况下）或 **warp idle**。 | 明确注释 block‑size，若未来有大 batch 建议加入 `tl.program_id(0) < num_tokens` 的 mask。 |
| **数据类型 & 设备** | 在入口强制 `q/k/positions/cos_sin_cache` 为 CUDA、contiguous，并在必要时 `cos_sin_cache.to(q.dtype, q.device)`。但 `positions` 仍需是 `int32`（未检查），若是 `int64` 会触发隐式转换。 | 在函数开头加 `assert positions.dtype in (torch.int32, torch.int64)`，统一转为 `int32`。 |
| **fallback 路径** | 当 `positions.ndim==1` 且 `apply_rope_with_cos_sin_cache_inplace` 不可用时会回到 `forward_native`。但 `forward_native` 仍使用原生 `_apply_rotary_emb`（未编译），可能在同一进程中出现两套实现的性能差异。 | 将 `torch.compile` 包装的函数统一用于 `forward_native`，或在类初始化时决定是否使用 triton。 |
| **torch.compile 使用** | `self._apply_rotary_emb_wrapped = torch.compile(dynamic=True)(_apply_rotary_emb)` 在每次实例化时编译一次，可能导致 **多次 JIT**（启动慢、内存泄漏）。 | 建议把编译结果设为类属性或模块级缓存，避免重复编译。 |
| **异常信息** | 对 `section_h==section_w`、`section_h+section_w+section_t == rd//2` 的断言信息简短，调试时不易定位。 | 改为 `raise ValueError(f"Invalid mrope_section={self.mrope_section}, expected h==w and sum=={rd//2}")`。 |
| **兼容性** | 新增 `triton` 依赖，在没有 triton 的环境下会报 `ImportError`，而不是优雅回退。 | 在模块顶部使用 `try: import triton; HAVE_TRITON=True`，并在不可用时禁用 fused kernel，确保 `pip install sglang` 在 CPU 环境下仍可运行。 |
| **文档/注释** | 代码中缺少对 `section_hw`、`is_neox_style` 含义的解释，阅读者难以快速理解。 | 在函数签名和关键步骤添加简要 docstring，说明每个常量的来源（Ernie4.5‑VL 设计文档）。 |

**🚀 建议的后续工作**  
1. **单元/集成测试**：覆盖多种 `head_size`、`rotary_dim`、`mrope_section` 组合，确认数值与原生实现完全一致（误差 < 1e‑6）。  
2. **性能基准**：在不同 `num_tokens`（1K‑64K）和不同 `head_size`（64、128）下对比原生 vs. triton 版本，记录显存占用与吞吐。  
3. **容错改进**：在 `triton_ernie45_rope_fused_inplace` 中加入 `grid = (num_tokens,)` 前的 `assert num_tokens > 0`，防止空张量调用导致 kernel launch 失败。  
4. **代码整洁**：将 triton 相关实现抽离到 `srt/kernels/` 子目录，保持核心层的可读性。  

总体而言，此次改动显著提升 Ernie4.5‑VL 在 CUDA 环境下的旋转位置编码速度，但在兼容性、异常信息以及编译成本方面仍有可提升之处。通过上述建议可进一步稳固功能、避免潜在回归。

---

### fix: nightly whl dev date suffix (#18873)
**SHA**: `45715af` | 🔗 [查看提交](https://github.com/sgl-project/sglang/commit/45715af50cc4312037ab62fda0ae0bd9bb6060a2)

**🎯 变更类型**：Bug 修复  
**⚡ 重要程度**：🟡 中  

**📋 变更摘要**  
在 `release-pypi-nightly.yml` 中，原先通过 `git describe` 判断是否为 tag‑0 提交来生成 `*.dev0+<hash>` 的 nightly 版本号。该实现会在同一天多次构建时产生相同的版本号，导致 PyPI 上的轮子无法按时间顺序排序。新的实现改为：  
1. 始终取最近的 tag，解析出主·次·修补号。  
2. 将修补号加一作为 nightly 基准版本。  
3. 采用当前 UTC 日期（`%Y%m%d`）作为 dev 编号，再拼接 Git 短 hash，形成 `X.Y.Z.dev<YYYYMMDD>+g<hash>`。  
4. 通过 `SETUPTOOLS_SCM_PRETEND_VERSION` 强制该版本用于 `python -m build`。

**🎯 影响范围**  
- **CI/CD**：nightly 发布流程全链路（`jobs.release-nighly`）受此脚本影响。  
- **版本体系**：所有通过 nightly 包发布的 Python wheel 都会获得新的日期后缀版本号。  
- **下游用户**：通过 `pip install --pre` 获取 nightly 的用户会看到更细粒度的、可排序的版本号，避免因相同 `dev0` 而出现覆盖或降级。  
- **文档/依赖**：没有直接代码变动，仅是构建元数据，故对运行时行为无影响。

**💡 关注建议**  
1. **CI 兼容性**：确认工作流的 `date -u` 命令在所有 GitHub runner 镜像上均可用（默认 Linux/Windows/macOS 都支持）。  
2. **版本回退**：若后续需要回滚至旧 nightly，确保 `NEXT_PATCH` 的递增逻辑不会因手动补丁而产生跳号。  
3. **依赖解析**：检查项目在 `requirements.txt` 或 `pyproject.toml` 中是否有锁定 `>=X.Y.Z.dev0` 的约束，升级为兼容 `dev<date>` 的范围（如 `>=0.5.9.dev20260214`）。  
4. **测试验证**：在 PR 合并前跑一次完整的 nightly 构建，确认生成的 wheel 名称符合预期（如 `sglang-0.5.9.dev20260215+g4cf4f08-py3-none-any.whl`），并通过 `pip install` 验证版本可被解析。  

总体来看，此改动提升了 nightly 包的唯一性和时间序列可比性，对运行时代码无影响，风险主要在 CI 环境和版本约束的兼容性上。建议合并后尽快在正式的 nightly pipeline 中验证一次。

---

### fix(sgl-kernel): support CUDA 13 runtime preloading for DGX Spark (#18747)
**SHA**: `5fc3284` | 🔗 [查看提交](https://github.com/sgl-project/sglang/commit/5fc328465ac7be8ef953fd3200951b56c92f0b4e)

**🎯 变更类型**：Bug 修复 / 功能增强  
**⚡ 重要程度**：🟡 中  

**📋 变更摘要**  
- 为 `sgl-kernel` 增加 CUDA 13 运行时的预加载逻辑，解决在 DGX Spark（CUDA 13）上出现 “libcudart.so.12 not found” 的错误。  
- 当检测到 CUDA 13 时，提供专门的 pip 安装提示（`cu130` 轮子）。  
- 错误信息中加入 CUDA 版本展示，提升排障信息可读性。  

**🎯 影响范围**  
- `sgl-kernel/python/sgl_kernel/load_utils.py`（加载与预加载 CUDA 库的核心实现）。  
- 受影响的调用链：`sgl_kernel._load_architecture_specific_ops` → `_preload_cuda_library` → `ctypes.CDLL`。  

**💡 关注建议**  
1. **兼容性检查**：`torch.version.cuda` 可能为 `None`（如仅使用 CPU），目前代码已做空值保护，但后续若改动 `torch` 导入顺序可能导致 `NameError`。建议在模块顶层统一获取并缓存 `CUDA_VERSION`，或使用 `getattr(torch.version, "cuda", None)`。  
2. **库版本优先级**：`lib_versions` 通过 `dict.fromkeys([cuda_major, "13", "12"])` 生成去重顺序，若 `cuda_major` 为 `"12"`，仍会尝试 `"13"` 再 `"12"`，在 CUDA 12 环境里多走一次查找。可考虑把 `cuda_major` 放在最前，其余仅在 `cuda_major != "13"` 时加入 `"13"`，避免无意义的查找。  
3. **异常日志**：当前仅 `debug` 级别记录加载失败，若用户在生产环境开启 `INFO`，可能看不到根因。建议在找不到任何库时输出 `warning`，提醒用户检查 CUDA 安装路径。  
4. **测试覆盖**：新增单元测试模拟不同 `torch.version.cuda`（`"13.0"、"12.1"、None`）以及不同文件系统布局，确保：
   - 正确挑选 `libcudart.so.{version}`；
   - `install_hint` 在 CUDA 13 场景下指向 `cu130` 镜像仓库；
   - 未找到库时返回统一错误信息。  
5. **文档同步**：README/安装章节需补充 “CUDA 13 支持” 说明及对应 wheel 链接，防止用户仍使用旧的 `pip install sgl-kernel` 命令导致缺少库。  

总体来看，此次修改解决了 DGX Spark 上的致命加载问题，改动范围局限在加载工具函数，风险较低。只要在 CI 中加入上述兼容性与路径查找的测试，即可稳定发布。

---

### Use ephemeral nccl port via get_free_port() (#18009)
**SHA**: `597d17d` | 🔗 [查看提交](https://github.com/sgl-project/sglang/commit/597d17dd18af037ec697a784494a6e5bfff58fa2)

**🎯 变更类型**：功能增强（使用临时 NCCL 端口）  
**⚡ 重要程度**：🟡 中  

**📋 变更摘要**  
1. 在 `sglang/srt/server_args.py` 中，原先通过 `is_port_available` 循环随机挑选 NCCL 端口的逻辑被简化为直接调用新工具函数 `get_free_port()`，实现一次性获取空闲端口。  
2. 同时对多处日志字符串做了从 f‑string → 纯字符串的微调，去除冗余的 `f` 前缀。  
3. 测试文件 `test/registered/core/test_server_args.py` 相应改为 mock `get_free_port`，并去除对 `is_port_available` 的依赖，新增对 `get_free_port` 被调用的断言。  

**🎯 影响范围**  
- `sglang/srt/server_args.py`（端口分配核心逻辑）  
- `sglang/srt/utils`（若 `get_free_port` 实现在该目录）  
- 单元测试 `test/registered/core/test_server_args.py`  

**💡 关注建议**  

*开发者*  
- 确认 `get_free_port` 在所有目标平台（Linux、macOS、Windows）上均能可靠返回未被占用的端口，尤其在容器/多节点环境下的并发调用。  
- 检查是否仍需要保留 `is_port_available`（已在多数路径中删除），避免死代码或未导出的符号导致 lint/CI 警告。  
- 更新文档或帮助信息，说明 `--nccl-port` 为 `None` 时会自动使用临时端口，避免用户误以为仍需手动指定。  

*用户*  
- 在使用分布式推理时，可不再手动设置 `--nccl-port`；若自行指定，请确保端口未被占用，否则仍会触发运行时错误。  
- 运行单元测试时，确保测试环境中的 `get_free_port` 被正确 mock，以免实际占用系统端口导致 flaky 测试。  

总体而言，此改动简化了 NCCL 端口分配流程，降低了端口冲突的概率，但需验证 `get_free_port` 的跨平台可靠性并同步更新相应文档。

---

### test: add test for Modelopt FP8 on SM90 (#18463)
**SHA**: `536ed31` | 🔗 [查看提交](https://github.com/sgl-project/sglang/commit/536ed3143b1cb53befdba3b4aff7472f857762c6)

**🎯 变更类型**：功能增强（新增测试）  
**⚡ 重要程度**：🟡 中  

**📋 变更摘要**  
本次提交在 `test/registered/quant/` 目录下新增 `test_modelopt_fp8.py`，通过 CI 注册 CUDA 环境，启动带 `--quantization modelopt_fp8` 参数的服务器，运行 GSM8K Few‑Shot 评测，并断言模型在 SM90 GPU 上的准确率必须超过 0.70。  

**🎯 影响范围**  
- **测试框架**：`sglang.test.*`、`sglang.srt.utils.kill_process_tree`、`sglang.test.ci.ci_register`  
- **服务器启动逻辑**：`popen_launch_server` 的参数传递与进程管理  
- **CI/CD**：CUDA CI 注册与执行时长（约 120 s）  

**💡 关注建议**  
1. **环境要求**：确保 CI 机器配备支持 FP8 的 NVIDIA SM90 GPU、对应的 CUDA/cuDNN 版本，以及已缓存模型 `nvidia/Llama-3.1-8B-Instruct-FP8`。  
2. **超时与资源**：测试并行度设为 200，若机器资源不足可能导致超时或 OOM，建议在本地先跑小批量 (`num_questions`、`parallel`) 验证。  
3. **进程清理**：`kill_process_tree` 已在 `tearDownClass` 中调用，确认在异常情况下仍能可靠结束子进程，防止残留占用端口。  
4. **模型可达性**：首次运行会从 HuggingFace 拉取大模型，建议在 CI 前缓存或使用镜像，以免因网络波动导致测试失败。  
5. **后续改进**：若模型或硬件不满足条件，可在测试入口添加提前跳过（`unittest.skipIf`）的判断，避免影响整体 CI 通过率。  

整体风险低，仅为新增验证用例；请在更新 CI 配置后跑一遍全链路，确认服务器启动、评测以及清理步骤均能顺利完成。

---

### fix: add SM110 (Jetson AGX Thor) to Blackwell capability check (#18787)
**SHA**: `b2f74d6` | 🔗 [查看提交](https://github.com/sgl-project/sglang/commit/b2f74d660ad9a3acf639986813281f652f8392cb)

**🎯 变更类型**：Bug修复（兼容性完善）  
**⚡ 重要程度**：🟡 中  
**📋 变更摘要**：在 `python/sglang/srt/utils/common.py` 中，将 Blackwell 计算能力检查从 `[10, 12]` 扩展为 `[10, 11, 12]`，从而把 Jetson AGX Thor（SM 11.0）加入支持范围。  
**🎯 影响范围**：`sglang.srt.utils.common._check_cuda_device_version` 以及所有依赖该缓存函数判断是否为 Blackwell GPU 的模块（模型调度、GPU 适配层等）。  

**💡 关注建议**  

1. **硬件兼容性验证**：Blackwell 代码路径现在会在 SM 11.0 设备上被触发。请在 Jetson AGX Thor 实机或模拟环境跑完整的推理/训练测试，确保没有因算子、内存或驱动差异导致崩溃。  
2. **CUDA 版本校验**：函数仍要求 `cuda_version >= (12, 8)`，而 Jetson AGX Thor 常配 CUDA 12.x。确认该版本在目标平台上可用，或在文档中说明最低 CUDA 要求。  
3. **缓存行为**：`is_blackwell_supported` 使用 `lru_cache(maxsize=1)`，首次调用后结果将被缓存。若后续在同进程中更换 GPU（例如多卡混合），需要显式清除缓存或重新启动进程，以避免误判。  
4. **单元测试与 CI**：新增对 `device_capability_majors` 包含 11 的测试用例，覆盖 `is_blackwell_supported(False)` 与 `True` 两种路径，并在 CI 中加入对 Jetson 架构的模拟（如使用 `torch.cuda.get_device_capability` mock）。  
5. **文档更新**：在《硬件兼容性》章节补充“Jetson AGX Thor（SM 11.0）已支持 Blackwell”，并提示用户在使用时检查 CUDA 版本。  

总体而言，此次改动提升了对 Jetson AGX Thor 的支持，但需确保其他依赖 Blackwell 判决的代码已经兼容 SM 11.0，避免在新硬件上出现隐藏的运行时错误。

---

### fix: update Blackwell log/error messages to include SM12x (#18751)
**SHA**: `57f7e06` | 🔗 [查看提交](https://github.com/sgl-project/sglang/commit/57f7e06cb97fa46cd3dd8ace3a8321c413ee1ea5)

**🎯 变更类型**：Bug 修复 / 文案改进  
**⚡ 重要程度**：🟡 中  
**📋 变更摘要**：将若干与 Blackwell GPU（SM100/SM12x）相关的日志与错误提示从硬编码的 “SM100” 改为更通用的 “Blackwell”/“SM100/SM12x”，以免在新一代 Blackwell（SM12x）上出现误导信息。  
**🎯 影响范围**：  
- `python/sglang/srt/server_args.py`（模型调度与后端选择）  
- 相关的 GPU 能力检测函数 `is_blackwell_supported()`（未改动但被引用）  

**💡 关注建议**：  
1. **文案一致性**：确认所有涉及 Blackwell 的提示、异常和文档均已同步更新，防止出现 “SM100” 与 “SM12x” 不匹配的情况。  
2. **兼容性测试**：在 Blackwell（SM12x）实际硬件或模拟环境下跑完整套启动、模型加载、prefill、MOE 以及 TRTLLM MLA 流程，确保新提示不影响逻辑分支。  
3. **日志等级**：这些信息仍使用 `logger.warning`，如果后续需要细化为 `info` 或 `debug`，可酌情调整，以免在生产环境中误报。  
4. **异常信息**：`ValueError` 中加入 “SM12x” 已保留原有语义，但要检查上层捕获是否依赖严格的字符串匹配，必要时改为更宽松的检查。  

总体来看，此次修改仅是文字层面的修正，不会影响代码执行路径，风险较低。建议在 CI 中加入对 `is_blackwell_supported()` 返回 True 时日志内容的检测，以防以后再次遗漏。

---

### update pre-commit config (#18860)
**SHA**: `07a24f1` | 🔗 [查看提交](https://github.com/sgl-project/sglang/commit/07a24f1a3846c4186e82ffc2bc43990ba6c0babc)

**🎯 变更类型**：功能增强 / 代码风格统一（更新 pre‑commit 配置、CI clang‑format 版本；大量格式化与小幅语法调整）  
**⚡ 重要程度**：🟡 中  

**📋 变更摘要**  
1. `.pre-commit-config.yaml` 中全部第三方 hook 版本升级：  
   - `pre‑commit‑hooks` → v6.0.0  
   - `isort` → 7.0.0  
   - `ruff` → v0.15.1  
   - `black` → 26.1.0  
   - `clang‑format` → v20.1.7  
   - `nbstripout` → 0.9.0  
2. CI 工作流 `lint.yml` 将 clang‑format 动作升级至 `v0.20`，并把默认 clang 版本从 18 提升到 20。  
3. 其余 200+ 项文件仅做了 **PEP‑8/clang‑format** 级别的细节修正（去除多余括号、统一 import 换行、简化字符串拼接、对齐赋值等），不涉及业务逻辑。

**🎯 影响范围**  
- **CI/Lint**：所有受 pre‑commit 管理的 Python、Jupyter Notebook、C/C++/CUDA、Markdown 等文件。  
- **代码库**：几乎所有模块都会重新通过更严格的 isort、ruff、black、clang‑format 检查。  
- **本地开发**：需要使用对应新版工具（`pip install pre‑commit && pre‑commit install`），否则 `git commit` 可能被阻止。  
- **文档/示例 notebook**：更新了多处多行字符串的写法，运行时行为保持不变，只是省去多余的换行/括号。

**💡 关注建议**  
1. **本地验证**：在提交前跑 `pre-commit run -a`，确认所有文件均能通过新版 hook，避免 CI 因格式错误回滚。  
2. **CI 缓存**：CI 中的 pre‑commit 缓存可能仍残留旧版本，建议在 `.github/workflows/lint.yml` 中加 `pre-commit clean` 或更新缓存键，以免出现“已通过但实际使用旧版本” 的误判。  
3. **clang‑format 兼容性**：升级到 clang‑format 20 可能导致已有 C++/CUDA 文件出现细微排版变化，检查 `sgl‑kernel` 目录下的 `.cu/.cuh` 是否仍能成功编译（尤其是宏展开、对齐注释）。  
4. **依赖冲突**：isort 7 与 Python 3.8+ 完全兼容，但若仓库仍在使用旧的 Python 3.7 环境，需要确保 CI 镜像已更新。  
5. **文档 Notebook**：部分 notebook 中的 `launch_server_cmd("""...""")` 改为单行字符串，确保在 CI 中的 ipynb‑diff 不产生意外的空格/换行；建议在 notebooks 运行一次，确认启动脚本仍能正常解析。  

总体来看，此次提交属于**非功能性、全局风格升级**，风险极低。只要开发者在本地同步更新 pre‑commit 环境并通过一次全库检查，就可以平滑过渡到更严格的代码规范。

---

#### 🟢 低重要度变更 (15)

### Revert "[diffusion]: Improve layerwise offload buffer reuse and shared-storage handling" (#18866)
**SHA**: `de833f9` | 🔗 [查看提交](https://github.com/sgl-project/sglang/commit/de833f9e8e9353d83a3ba06738861ee45f034bf0)

**🎯 变更类型**：代码重构  
**⚡ 重要程度**：🟢低  
**📋 摘要**：撤销了层级离线缓冲区复用的实现，删除了 GPU 缓冲池相关逻辑，改为直接 `torch.empty` 创建临时张量，并简化 `release_layer` 接口。整体代码量缩减，功能回退。

---

### Fix GLM-4V processor registration when glm_ocr is unavailable (#18885)
**SHA**: `206accd` | 🔗 [查看提交](https://github.com/sgl-project/sglang/commit/206accd15de341e10be68ae6139a3cdfb610eac3)

在 `glm4v` 处理器中加入 `try/except` 可选导入 `GlmOcrForConditionalGeneration`，并在 `models` 列表中筛除 `None`，防止在未安装 `glm_ocr` 时出现导入错误。

---

### [diffusion] fix: fix LoRA weight snapshot aliasing in unmerge logic (#18883)
**SHA**: `61da34a` | 🔗 [查看提交](https://github.com/sgl-project/sglang/commit/61da34ad0b8a0f9b844ea123b1f206fad419c793)

**🎯 变更类型**：代码重构  
**⚡ 重要程度**：🟢 低  
**📋 摘要**：在 LoRA 线性层中，将 `cpu_weight = base_layer.weight.to("cpu")` 改为 `base_layer.weight.detach().to("cpu").clone()`，防止 CPU 权重快照与原始张量别名共享，避免合并/取消合并时意外修改基线权重。

---

### Update ascend_npu_qwen3_5_examples.md (#18888)
**SHA**: `d85884c` | 🔗 [查看提交](https://github.com/sgl-project/sglang/commit/d85884ca5759feebe7164b4d6884746776582218)

**🎯 变更类型**：文档更新  
**⚡ 重要程度**：🟢低  
**📋 摘要**：修正 `ascend_npu_qwen3_5_examples.md` 中的 Docker 镜像标签（`qwen35` → `qwen3.5`）及设备映射指令的拼写错误（`---device=` → `--device=`）。

---

### Fix test_lora_qwen3 nightly failure: replace adapter with added_tokens (#18884)
**SHA**: `86c181e` | 🔗 [查看提交](https://github.com/sgl-project/sglang/commit/86c181e33597952a8a483134ca05db6d6699d32e)

**🎯 变更类型**：测试修改  
**⚡ 重要程度**：🟢 低  
**📋 摘要**：在 `test/lora_utils.py` 中将 LoRA 适配器名称从 `y9760210/Qwen3-4B-lora_model` 替换为 `TanXS/Qwen3-4B-LoRA-ZH-WebNovelty-v0.0`，修复 nightly 测试 `test_lora_qwen3` 的失败。

---

### [Diff]: support SGLANG_TORCH_PROFILER_DIR environment variable for profiler log directory (#18454)
**SHA**: `bc79a64` | 🔗 [查看提交](https://github.com/sgl-project/sglang/commit/bc79a64d3a81b1540c15d376b967dd436503d926)

**🎯 变更类型**：代码重构  
**⚡ 重要程度**：🟢 低  
**📋 摘要**：在 `profiler.py` 中将 `log_dir` 参数改为可选，并新增对环境变量 `SGLANG_TORCH_PROFILER_DIR` 的读取，默认日志目录仍为 `./logs`。这样可通过环境变量灵活配置 Torch Profiler 的日志保存路径。

---

### [diffusion] fix: avoid saving output for warmup requests (#18867)
**SHA**: `78b4c9e` | 🔗 [查看提交](https://github.com/sgl-project/sglang/commit/78b4c9e248b8fe1f1bf3126d0eb00d345b5f6920)

**🎯 变更类型**：代码重构  
**⚡ 重要程度**：🟢 低  
**📋 摘要**：在 `scheduler.py` 中将热身请求标记统一为 `set_as_warmup()`，并在 `Req` 类的 `set_as_warmup` 方法里关闭输出保存、日志抑制，并将推理步数设为 1，以避免在热身阶段产生多余的输出文件。

---

### [CI] Remove `--mem-fraction-static 0.93` from gpt-oss test (#18869)
**SHA**: `8290171` | 🔗 [查看提交](https://github.com/sgl-project/sglang/commit/8290171f5247061d48ca6545d2e298599db0359c)

**🎯 变更类型**：测试修改  
**⚡ 重要程度**：🟢低  
**📋 摘要**：在 `test_gpt_oss_4gpu.py` 中删除了 `--mem-fraction-static 0.93` 参数，简化了 CI 测试命令。

---

### Add claude skills for sgl-kernel and jit-kernel (#18855)
**SHA**: `d3bae71` | 🔗 [查看提交](https://github.com/sgl-project/sglang/commit/d3bae71e3f1fd983853cae4f95591d4a8545325f)

**变更类型**：文档更新  
**重要程度**：🟢 低  
**摘要**：新增两篇 `.claude/skills` 文档，分别详细说明在 `jit_kernel` 与 `sgl‑kernel` 中添加新 CUDA/C++ kernel 的实现、测试与基准步骤。

---

### Update ascend_npu_support.rst (#18868)
**SHA**: `fd5a45d` | 🔗 [查看提交](https://github.com/sgl-project/sglang/commit/fd5a45d5cf2f035c7a169b3c6a7f02dd56eb2cd3)

**🎯 变更类型**：文档更新  
**⚡ 重要程度**：🟢低  
**📋 摘要**：在 `docs/platforms/ascend_npu_support.rst` 中新增两份文档链接，分别为 Ascend NPU Qwen3.5 示例和 GLM5 示例。

---

### Create ascend_npu_qwen3_5_examples.md  (#18864)
**SHA**: `f2d7286` | 🔗 [查看提交](https://github.com/sgl-project/sglang/commit/f2d72866e9e9e56413c41807d63a20e88cb72af1)

**🎯 变更类型**：文档更新  
**⚡ 重要程度**：🟢低  
**📋 摘要**：新增 `docs/platforms/ascend_npu_qwen3_5_examples.md`，提供 Qwen3.5 在 Atlas NPU 上的 Docker 镜像拉取、容器启动、单机部署及运行参数示例。

---

### Fix libnuma.so does not exsit (#15355)
**SHA**: `b79808b` | 🔗 [查看提交](https://github.com/sgl-project/sglang/commit/b79808bee235180111d0501a71ee7c2a8c123978)

**🎯 变更类型**：代码重构  
**⚡ 重要程度**：🟢低  
**📋 摘要**：新增 `get_libnuma`，在加载 `libnuma.so` 时兼容不同名称并捕获缺失错误；相关 NUMA 绑定、节点计数等函数改用该包装并在库不可用时安全跳过或返回默认值。

---

### Improve profiler options for bench_serving (#16991)
**SHA**: `48eac1b` | 🔗 [查看提交](https://github.com/sgl-project/sglang/commit/48eac1b62d32c6fdad7d53edc68734b19a155cc8)

**🎯 变更类型**：代码重构  
**⚡ 重要程度**：🟢 低  
**📋 摘要**：为 bench_serving 增加了 `--profile-output-dir` 与 `--profile-prefix` 参数，在调用 `/start_profile` 时自动生成输出目录并设默认步数，`/stop_profile` 请求改为不携带参数。

---

### fix_get_quant_method_in_fused_moe_condition (#18459)
**SHA**: `7a607c4` | 🔗 [查看提交](https://github.com/sgl-project/sglang/commit/7a607c49009de956b6dd8c0e3055825ae8efb4a6)

**🎯 变更类型**：代码重构  
**⚡ 重要程度**：🟢低  
**📋 摘要**：在 `moe_wna16.py` 中引入 `UnquantizedFusedMoEMethod`，并在 `get_quant_method` 判断 `FusedMoE` 时返回该方法，修复混合专家层的量化获取逻辑。

---

### Enable DeepGemm fast warmup in CI to prevent cold-cache timeouts (#18823)
**SHA**: `f760320` | 🔗 [查看提交](https://github.com/sgl-project/sglang/commit/f7603203b044318fb0ec7879d88c2955c96b78a1)

**🎯 变更类型**：配置调整  
**⚡ 重要程度**：🟢低  
**📋 摘要**：在 CI workflow 中新增 `SGLANG_JIT_DEEPGEMM_FAST_WARMUP=true` 环境变量，以加速 DeepGemm 热身，防止冷缓存导致的超时。

---

