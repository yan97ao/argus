# 每日更新报告（2026-01-24）

## ai-dynamo/dynamo

| 提交时间 | 作者 | 提交信息 |
|----------|------|----------|
| 2026-01-24 10:47:00 | Biswa Panda | feat: event plane apis and nats implementation (#5624) |
| 2026-01-24 10:07:34 | milesial | fix: incremental build for dynamo-llm (#5601) |
| 2026-01-24 09:23:30 | Alec | refactor: add explicit non-leader node handling in vLLM (#5597) |
| 2026-01-24 09:19:06 | Alec | chore(deps): bump vLLM to 0.14.0 (#5593) |
| 2026-01-24 09:17:17 | Yan Ru Pei | chore: remove some clones in Indexer (#5612) |
| 2026-01-24 08:46:51 | Tushar Sharma | ci: add filters for frontend image workflow (#5585) |
| 2026-01-24 08:43:46 | Abhishek Gupta | docs: add NIXL backend configuration and fix multiple typos (#5564) |
| 2026-01-24 08:28:41 | Schwinn Saereesitthipitak | refactor: move GMS to standalone component (#5616) |
| 2026-01-24 07:10:32 | Kris Hung | fix: Fix race condition in TP>1 when ImmediateTransferResult arrives before CreateSlot (#5393) |
| 2026-01-24 05:59:43 | Biswa Panda | feat: add event plane discovery (#5614) |
| 2026-01-24 05:12:22 | Abhishek Gupta | fix: correct typos in help text and add missing docstrings (#5607) |
| 2026-01-24 04:44:03 | Abhishek Gupta | feat: add __all__ exports and __repr__ methods for better debugging (#5606) |
| 2026-01-24 02:06:06 | Keiven C | refactor: reduce Python API to only Prometheus Exposition Format callback (#5594) |
| 2026-01-24 01:10:13 | Yan Ru Pei | chore: simplify RadixTree assuming consistent hashing across workers (#5605) |
| 2026-01-24 00:26:01 | Yan Ru Pei | chore: nuke ForwardPassMetrics (#5531) |

### 📊 统计摘要
> 本日共 15 个提交 | 🔴高 7 | 🟡中 4 | 🟢低 4
## 📋 目录

- [ai-dynamo/dynamo](#ai-dynamo-dynamo)
  - [📊 统计摘要](#-统计摘要)
  - [🔴 高重要度变更 (7)](#-🔴-高重要度变更-7)
    - [feat: event plane apis and nats implementation (#5624)](#ebde0f6)
    - [refactor: move GMS to standalone component (#5616)](#92ecd30)
    - [fix: Fix race condition in TP>1 when ImmediateTransferRes...](#7fe89c7)
    - [feat: add event plane discovery (#5614)](#3ee9892)
    - [fix: correct typos in help text and add missing docstring...](#491a210)
    - [feat: add __all__ exports and __repr__ methods for better...](#7de8096)
    - [refactor: reduce Python API to only Prometheus Exposition...](#7361de4)
  - [🟡 中重要度变更 (4)](#-🟡-中重要度变更-4)
    - [fix: incremental build for dynamo-llm (#5601)](#e6ad5bc)
    - [refactor: add explicit non-leader node handling in vLLM (...](#2da403e)
    - [chore(deps): bump vLLM to 0.14.0 (#5593)](#50f1e0e)
    - [chore: nuke ForwardPassMetrics (#5531)](#feb6d27)
  - [🟢 低重要度变更 (4)](#-🟢-低重要度变更-4)
    - [chore: remove some clones in Indexer (#5612)](#67c868e)
    - [ci: add filters for frontend image workflow (#5585)](#d4fbf9d)
    - [docs: add NIXL backend configuration and fix multiple typ...](#912a4d4)
    - [chore: simplify RadixTree assuming consistent hashing acr...](#b273eda)
#### 🔴 高重要度变更 (7)

### feat: event plane apis and nats implementation (#5624)
**SHA**: `ebde0f6` | 🔗 [查看提交](https://github.com/ai-dynamo/dynamo/commit/ebde0f662ca789686611a2a3c635cda2e24879eb)

**🎯 变更类型**：功能增强  
**⚡ 重要程度**：🔴高  
**📋 变更摘要**：在 `runtime` 模块中新增 “Event Plane” 子系统，提供一套与底层传输解耦的 Pub/Sub API。核心实现包括 MessagePack 编解码器、二进制帧协议、统一的 Transport/Stream trait，以及针对 NATS 的具体实现。对外通过 `transports.rs` 暴露 `event_plane` 模块，使得上层业务可以在不感知底层协议的前提下发布/订阅事件。

**🎯 影响范围**：  
- `lib/runtime/src/transports.rs`（新增 `event_plane` 导出）  
- 全新 `lib/runtime/src/transports/event_plane/` 目录（codec、frame、traits、transport、nats_transport、mod）  
- 依赖 `DistributedRuntime` 中的 NATS KV‑router接口  
- 可能影响后续在 `runtime` 中使用的调度、发现、监控等模块（因为它们将能够基于 Event Plane 进行事件传播）

**🔍 技术洞察**  
- **架构影响**  
  - 引入 **Transport‑agnostic 事件层**，把 Pub/Sub 逻辑抽象到 `EventTransportTx` / `EventTransportRx` 两个 async trait 中。  
  - 通过 `EventEnvelope` 与 `MsgpackCodec` 统一序列化格式，保证不同后端（目前是 NATS，未来可扩展到 ZMQ、Redis、Kafka 等）在语义上保持一致。  
  - `Frame` 结构提供固定 5‑byte 头部 + 可变长度载荷的二进制帧，实现 **边界检测** 与 **协议版本** 控制，为以后协议演进预留空间。  
  - 新模块的引入不会破坏已有 `etcd`、`tcp` 传输代码，保持向后兼容，只是对外暴露了更多可选传输实现。

- **性能影响**  
  - **序列化**：使用 `rmp_serde`（MessagePack）相较于 JSON 更紧凑，序列化/反序列化开销在毫秒级以下，适合高吞吐场景。  
  - **帧处理**：`Frame::encode` 通过 `BytesMut` 预分配完整帧大小，单次拷贝完成，CPU 开销低。  
  - **网络层**：NATS 本身提供低延迟、自动负载均衡；`publish` 与 `subscribe` 直接转发 `Bytes`，避免额外的拷贝。  
  - **潜在瓶颈**：`MsgpackCodec::encode_payload` 会在序列化完成后再包装成 `Bytes`，产生一次 heap 分配；在极端高频事件（>10k/s）时可能导致 GC（内存分配）压力。可考虑使用 `bytes::BytesMut` 的零拷贝写入或对象池优化。

- **安全考虑**  
  - **序列化安全**：MessagePack 本身不执行代码执行，只是二进制数据，风险低。但若解码的结构体包含 `DeserializeOwned` 的自定义类型，需要确保来源可信，防止结构体层面的逻辑错误。  
  - **传输安全**：NATS 端需自行配置 TLS / 授权（本代码未涉及）。建议在生产环境开启 NATS 的加密与认证，防止中间人篡改 `EventEnvelope`。  
  - **帧边界**：`FrameError::IncompleteHeader`、`IncompletePayload`、`UnsupportedVersion` 已经覆盖基本的协议错误，避免恶意构造的非法帧导致缓冲区溢出。仍建议在 `Frame::decode` 里加入 **最大帧长度** 检查（`FrameTooLarge` 已预留）来防止 DoS。

**⚠️ 潜在风险**  
1. **后端依赖耦合**：`NatsTransport` 直接使用 `DistributedRuntime` 的内部 NATS 接口，如果这些接口的实现发生变更，`event_plane` 需要同步更新。  
2. **序列化兼容性**：`MsgpackCodec::encode_envelope` 使用 `to_vec_named`，若未来在 `EventEnvelope` 添加字段且未提供默认值，旧版消费者在解码时会失败。  
3. **背压 & 流控**：`WireStream` 直接映射为 `Box<Pin<Stream<Item = Result<Bytes>>>`，在高并发下如果下游处理慢，NATS 客户端的内部缓冲区可能被填满导致异常。  
4. **错误传播**：当前 `NatsTransport::subscribe` 把 NATS 消息包装成 `Result<Bytes>`，但未对 `NATS` 断连、重连等错误进行统一处理，可能导致上层无限等待。  
5. **资源泄露**：`EventTransportTx` 与 `EventTransportRx` 没有提供显式的 `close`/`shutdown` 接口，长期运行时可能残留未关闭的 NATS 订阅句柄。

**💡 关注建议**  
- **接口稳固**：为 `EventTransportTx` / `EventTransportRx` 增加 `shutdown(&self) -> Result<()>`，在 `DistributedRuntime` 停止时统一释放底层资源。  
- **帧大小限制**：实现 `FrameError::FrameTooLarge` 检查（例如上限 10 MiB），并在 `NatsTransport::publish` 前对 `payload_len` 做校验，防止单条事件被滥用。  
- **序列化向后兼容**：使用 `#[serde(default)]` 为新字段提供默认值，或在 `MsgpackCodec` 中提供 `decode_envelope_with_version` 之类的兼容层。  
- **监控与告警**：在 `NatsTransport` 的 `publish`/`subscribe` 包装错误时加入统一的日志标签（如 `event_plane::nats::publish_error`），方便 Prometheus/Grafana 报警。  
- **性能基准**：在 CI 中加入基准测试（如 100 k events / s）来评估序列化、帧编码以及 NATS 端吞吐，确保在实际集群规模下不出现瓶颈。  
- **安全加固**：文档中明确要求在生产环境启用 NATS TLS + JWT/用户名密码，或在 `EventTransportTx` 中加入可选的签名/校验插件，以防篡改。  

通过上述措施，**Event Plane** 将为 Dynamo Runtime 带来更灵活、可扩展的事件传播能力，同时保持高性能和安全可控。

---

### refactor: move GMS to standalone component (#5616)
**SHA**: `92ecd30` | 🔗 [查看提交](https://github.com/ai-dynamo/dynamo/commit/92ecd308fd7b92796ab9479ce6639195930b0cec)

**🎯 变更类型**：重构  

**⚡ 重要程度**：🔴 高  

**📋 变更摘要**：  
1. 将 GPU Memory Service (GMS) 从 Dynamo 代码库的 `components/src/dynamo/gpu_memory_service` 包迁移为独立的 `gpu_memory_service` 包，去除原有的包装层。  
2. 为 GMS 新增独立的 CLI 子模块 `gpu_memory_service/cli`，并在 `pyproject.toml` 中声明 `gpu-memory-service` 脚本入口。  
3. 更新入口点、日志名称、文档字符串以及 import 路径，使其不再依赖 `dynamo` 命名空间。  

**🎯 影响范围**：  
- **核心组件**：`components/src/dynamo/gpu_memory_service`（已删除）  
- **新组件**：`lib/gpu_memory_service`（包括 `cli/` 子目录）  
- **入口点**：`python -m gpu_memory_service` 取代 `python -m dynamo.gpu_memory_service`  
- **依赖方**：所有在代码或文档中直接 `import dynamo.gpu_memory_service.*` 的位置（包括内部 Dynamo 子模块、外部插件、示例脚本、CI 配置等）  

**🔍 技术洞察**  

- **架构影响**  
  - **解耦**：GMS 现在是一个独立的可发布库，能够单独版本管理、单独测试、单独发布 wheel，降低了 Dynamo 对 GPU 内存管理实现的耦合度。  
  - **模块边界**：删除 `components/src/dynamo/gpu_memory_service/__init__.py` 使得 Dynamo 不再充当 GMS 的“代理”。这强化了“单一职责”原则，未来可以在不影响 Dynamo 主体的情况下对 GMS 进行重写或替换。  
  - **向后兼容**：直接删除包装层意味着旧的 `dynamo.gpu_memory_service` 导入会立即失效，若没有提供兼容 shim，将导致 ImportError。  

- **性能影响**  
  - 代码路径未变更（核心逻辑仍在 `gpu_memory_service` 包），因此运行时性能基本保持不变。  
  - 唯一可能的微小差异在于日志名称从 `dynamo.gpu_memory_service` 变为 `gpu_memory_service`，若用户在日志过滤上依据名称做细粒度控制，需相应调整。  

- **安全考虑**  
  - 未引入新的网络或文件系统交互，仅是包装层的移除和入口点的重命名，安全风险极低。  
  - 需要确认 `gpu_memory_service` 包的 `pyproject.toml` 中的脚本入口不被意外暴露给不受信任的用户（比如通过 `sudo pip install`），但这与原有实现相同。  

**⚠️ 潜在风险**  

1. **破坏兼容性**  
   - 所有仍使用 `import dynamo.gpu_memory_service` 的代码会抛出 `ImportError`，导致运行时崩溃。  
2. **文档/示例不同步**  
   - 官方文档、README、示例脚本、CI 配置等可能仍指向旧路径，用户在升级后会受到混淆。  
3. **打包/发布流程**  
   - 需要在 `dynamo` 的发布流程中移除对已删除目录的打包声明，并在 `gpu_memory_service` 的独立 wheel 中确保依赖完整（尤其是 `torch` 扩展）。  
4. **日志/监控脚本**  
   - 监控系统如果基于 logger 名称或旧的进程启动命令进行过滤，需要相应更新。  
5. **Extension 导入**  
   - 原包装层尝试导入 `gpu_memory_service.client.torch.extensions._allocator_ext`，新结构仍保留，但入口路径改变后如果用户自行捕获异常进行 fallback，需检查是否仍兼容。  

**💡 关注建议**  

1. **提供兼容层**  
   - 在 `dynamo/gpu_memory_service/__init__.py` 中保留一个轻量的 shim（仅 `import gpu_memory_service as _gms; globals().update(_gms.__dict__)`），并在文件头部加入 `DeprecationWarning`，以平滑迁移并避免突发性崩溃。  
2. **文档同步**  
   - 更新所有 README、使用手册、示例以及 CI 脚本中的 import 路径和启动命令。  
3. **发布说明**  
   - 在本次发布的 changelog 中明确标记 “Breaking Change: GPU Memory Service moved to standalone package, import path changed”.  
4. **测试覆盖**  
   - 增加针对 `gpu_memory_service.cli.runner` 的集成测试，确保 `gpu-memory-service` 脚本能够成功启动并接受连接。  
5. **日志/监控迁移**  
   - 在迁移指南中提示用户将日志过滤规则从 `dynamo.gpu_memory_service` 改为 `gpu_memory_service`。  
6. **版本策略**  
   - 由于破坏性改动，建议将 Dynamo 主库的次要版本号提升（例如 `0.x.y → 0.(x+1).0`），并在 `gpu_memory_service` 发布独立的 `0.1.0`（或更高）版本。  

通过上述措施，可最大程度降低迁移风险，充分发挥 GMS 独立组件化带来的可维护性和可演进性优势。

---

### fix: Fix race condition in TP>1 when ImmediateTransferResult arrives before CreateSlot (#5393)
**SHA**: `7fe89c7` | 🔗 [查看提交](https://github.com/ai-dynamo/dynamo/commit/7fe89c74267d39585854ca39230f589d7cf3e9fb)

**🎯 变更类型**：Bug修复 / 性能优化  
**⚡ 重要程度**：🔴高  
**📋 变更摘要**：  
- 修复了在多节点（TP > 1）环境下，`ImmediateTransferResult` 可能在对应 `CreateSlot` 之前到达导致的竞态错误。  
- 引入 `NewSlotInfo`（携带 `expected_immediate_ops`），在创建槽位时声明该槽位应收到的即时操作数量。  
- 调整 Leader、Worker、Scheduler 等关键路径，使其在接收 `ImmediateTransferResult` 前能够缓存并在所有工作节点的槽位创建成功后统一计数，从而保证完成检测的正确性。  

**🎯 影响范围**：  
- `lib/bindings/kvbm/src/block_manager/vllm/connector/*`（metadata、leader、worker）  
- `lib/llm/src/block_manager/connector/scheduler.rs`（调度器槽位创建、未处理即时结果的缓存逻辑）  
- 所有使用 KV‑BM 连接器的 VLLM/TP‑LLM 运行时（包括 TRT‑LLM、VLLM 本体）  

---

### 🔍 技术洞察  

| 维度 | 影响说明 |
|------|----------|
| **架构影响** | - 在 **ConnectorMetadata** 中从 `Vec<String>` 更改为 `Vec<NewSlotInfo>`，导致元数据在网络/序列化层面发生结构变更。<br>- 新增 `create_slot(request_id, expected_immediate_ops)` 接口，所有创建槽位的代码路径必须使用该接口，否则会回退到默认 `0`，可能再次触发竞态。<br>- Scheduler 现在在 `add_slot` 时**不再删除** `unprocessed_immediate_results`，而是保留至 `remove_slot`，确保 TP > 1 场景下每个 worker 都能收到缓存的即时结果。<br>- 引入 `expected_immediate_ops` 参数后，**每个 worker 必须保持该计数一致**，否则 `is_complete` 可能永远为 `false`（导致请求卡死）。 |
| **性能影响** | - 额外的计数与过滤（`pending_ops.iter().filter(|op| op.request_type == Immediate)`）在创建槽位时执行，开销极小（线性于待处理操作数）。<br>- 对 `unprocessed_immediate_results` 的 `HashMap` 保持时间延长（从 “创建槽位时即删除” 变为 “请求完成后才删除”），在极端高并发的 TP > 1 场景下会略增内存占用，但仍在可接受范围。 |
| **安全考虑** | - 变更仅涉及内部状态管理和元数据结构，无外部 I/O、权限或加密相关改动。<br>- 使用 `serde::{Serialize, Deserialize}` 自动派生，需确保向后兼容序列化（新增字段默认缺省为 `0`，保持老版本解析成功）。 |
| **可维护性** | - 新增 `NewSlotInfo` 与 `create_slot_with_immediate_ops` 明确了 **“创建槽位时必须声明预期即时操作数”** 的业务约束，提升代码可自解释性。<br>- `Scheduler::add_slot` 中的注释解释了 TP > 1 的特殊处理，降低未来维护者误删缓存的风险。 |

---

### ⚠️ 潜在风险  

1. **向后兼容性**  
   - 旧版节点（未同步此 PR）仍使用原始 `create_slot(String)` 接口，若混合部署，可能出现 `expected_immediate_ops = 0` 导致同样的竞态。需要在发布说明中强制要求所有节点同步升级。  
2. **计数不匹配**  
   - `expected_immediate_ops` 必须等于该请求在所有 worker 中产生的 `ImmediateTransferResult` 总数。若业务层误算（如漏计一次），`is_complete` 将永远返回 `false`，请求卡住。  
3. **内存泄漏**  
   - 在极端异常情况下（如请求被提前 abort 而未走 `remove_slot`），`unprocessed_immediate_results` 可能残留，导致内存增长。建议在异常路径（如 request 被取消）加入清理逻辑。  
4. **序列化兼容**  
   - `NewSlotInfo` 新增字段在跨进程/跨语言通信时需要对应的序列化实现。若有非 Rust 客户端（如 Python）未更新结构，会导致解码错误。  

---

### 💡 关注建议  

1. **升级流程**  
   - 确保所有参与同一 TP 集群的节点在同一版本发布，避免混用老旧 `create_slot` 接口。提供升级脚本或兼容层（在旧接口内部调用新接口并默认 `expected_immediate_ops = 0`）。  

2. **增加验证**  
   - 在 `WorkerSchedulerClientSlot::make_scheduler_slot_request` 中加入断言：`expected_immediate_ops >= pending_immediate_ops_count`（在调试模式下），帮助快速捕获计数不匹配的问题。  

3. **异常清理**  
   - 为 `Scheduler::remove_slot` 增加处理 “request aborted” 场景的路径，确保 `unprocessed_immediate_results` 在任何异常退出时都能被清除。  

4. **监控/指标**  
   - 导出 `scheduler.unprocessed_immediate_results.len()`、`slot.expected_immediate_ops`、`slot.completed` 等指标，以便在生产环境监控是否出现异常卡死的情况。  

5. **文档与测试**  
   - 在项目文档中明确 **“在 TP>1 环境下必须使用 `create_slot_with_immediate_ops` 并提供正确的即时操作计数”**。  
   - 增加跨节点（多 worker）集成测试，模拟 `ImmediateTransferResult` 先于 `CreateSlot` 到达的场景，确保所有 worker 最终都能正确完成。  

---

---

### feat: add event plane discovery (#5614)
**SHA**: `3ee9892` | 🔗 [查看提交](https://github.com/ai-dynamo/dynamo/commit/3ee989252c229d24d878dbab2807a12e9c32beba)

**🎯 变更类型**：功能增强  
**⚡ 重要程度**：🔴高  
**📋 变更摘要**：  
- 在 discovery 平面新增 **Event Plane** 支持，提供统一的 **event channel** 注册、查询和注销能力。  
- 引入 `EventTransportKind / EventCodecKind / EventTransport` 配置模型，支持 NATS 与 ZMQ 两种传输方式并通过环境变量 `DYN_EVENT_PLANE` / `DYN_EVENT_PLANE_CODEC` 自动选择。  
- 为 KV‑Store、metadata、mock、watcher 等核心模块实现对 `EventChannel` 实例的完整生命周期管理，扩展查询枚举 `DiscoveryQuery::EventChannels` 与注册规范 `DiscoverySpec::EventChannel`。  
- 同步更新文档、测试以及错误日志，以兼容旧有模型/端点注册流程。

---

## 🎯 影响范围
- **核心 discovery 体系**：`lib/runtime/src/discovery/*`（`kv_store.rs、metadata.rs、mod.rs、mock.rs、watcher.rs`）  
- **配置模块**：`lib/runtime/src/config/environment_names.rs`（新增 env var 文档）  
- **模型实例标识**：`DiscoveryInstanceId`、`EventChannelInstanceId`（统一路径序列化）  
- **运行时元数据快照**：`MetadataSnapshot` 现在会返回事件通道集合  
- **单元测试**：覆盖 event channel 注册、过滤、注销等路径

---

## 🔍 技术洞察

### 架构影响
| 维度 | 影响 |
|------|------|
| **平面划分** | 将 **request plane**（现有 `TransportType`）与 **event plane** 明确分离，防止两者在配置/序列化上相互污染。 |
| **统一 discovery API** | `DiscoverySpec::EventChannel` 与 `DiscoveryQuery::EventChannels` 与已有 `Endpoint/Model` 保持同一接口，保持向后兼容。 |
| **元数据结构** | `DiscoveryMetadata` 增添 `event_channels` 哈希表；`get_all` 现在会合并三类实例。 |
| **KV‑Store 结构** | 新增 bucket `v1/event_channels`，相当于原 `instances` 与 `models` 的平行层级，保持数据组织一致性。 |
| **环境变量配置** | `DYN_EVENT_PLANE`、`DYN_EVENT_PLANE_CODEC` 通过 `EventTransportKind::from_env_or_default` 自动落地，简化部署。 |
| **监听/注销逻辑** | `ModelWatcher` 现在在 `Removal` 分支同时接受 `DiscoveryInstanceId::EventChannel`，避免误报错误日志。 |

### 性能影响
- **KV‑Store 读写**：新增一次 bucket 写入/删除（与模型/端点同级），CPU/网络开销与现有路径相当，整体吞吐量下降可忽略 (<0.5% 额外 IO)。  
- **查询**：`KVStoreDiscovery::list_and_watch` 在遍历键值时多了一个分支判断 (`EVENT_CHANNELS_BUCKET`)；匹配前缀的成本同样 O(N)。  
- **日志**：大批量 `info!`、`debug!` 记录在注册/注销阶段，生产环境可通过日志级别控制，避免性能冲击。  
- **内存**：`DiscoveryMetadata` 额外持有 `event_channels` 哈希表，若事件通道数量显著增长（如数千），内存占用随之线性增加。建议在生产环境监控 `metadata.event_channels.len()`。

### 安全考虑
- **环境变量注入**：`DYN_EVENT_PLANE` 与 `DYN_EVENT_PLANE_CODEC` 若被恶意修改，可能导致服务切换到不期望的传输（如打开未加密的 ZMQ）。建议在容器/Pod 中显式声明，或在启动脚本中做白名单校验。  
- **NATS / ZMQ 认证**：本次改动仅提供 **transport 选择**，未涉及凭证/TLS 配置；若实际部署使用 NATS、ZMQ，需要在上层仍保持原有安全机制（如 NATS token、ZMQ CurveZMQ）。  
- **路径序列化**：`EventChannelInstanceId::to_path` 与 `from_path` 采用十六进制实例 ID，防止路径冲突；仍需确认实例 ID 随机性足够，避免预测导致的资源抢占。  
- **日志泄露**：`info!` 中打印完整 `instance_id` 与 `topic`，在多租户环境可能泄露内部命名空间信息，建议在生产环境脱敏或降低日志级别。

---

## ⚠️ 潜在风险

| 风险 | 说明 | 严重度 |
|------|------|--------|
| **向后兼容性** | 新增 `DiscoveryInstanceId::EventChannel` 可能导致旧版代码在模式匹配时出现 `unreachable!` 或 `match` 未覆盖的情况。 | 中 |
| **配置默认差异** | 若未显式设置 `DYN_EVENT_PLANE`，默认走 NATS；但部分部署仍依赖旧版默认（无事件平面），可能产生不必要的 NATS 连接。 | 低 |
| **资源泄漏** | `KVStoreDiscovery::register`/`unregister` 对同一 `instance_id` 的幂等性未显式保障，重复注册/注销可能导致 KV store 中残留旧键。 | 中 |
| **日志噪声** | 新增大量 `info!`、`debug!` 日志，若未在 `RUST_LOG` 中调低，会导致磁盘 I/O 增大。 | 低 |
| **测试覆盖不足** | 目前仅在单元测试中覆盖了基本注册/过滤，缺少 **跨进程、真实 NATS/ZMQ** 的集成测试，可能在生产环境出现序列化不匹配或网络错误未捕获。 | 中 |
| **并发争用** | `DiscoveryMetadata` 的 `HashMap` 在多线程环境通过 `Mutex` 包装（在其它位置），若并发度提升，可能出现锁竞争。 | 低 |

---

## 💡 关注建议

1. **文档与示例**  
   - 在项目 README / docs 中补充 **Event Plane** 配置说明，包括 `DYN_EVENT_PLANE`、`DYN_EVENT_PLANE_CODEC` 示例。  
   - 给出 **NATS** 与 **ZMQ** 的最佳实践（如 TLS、认证、主题命名规范）。

2. **兼容层**  
   - 为旧代码提供一个 `#[allow(dead_code)]` 的 **compat shim**：`DiscoveryInstanceId::from_old_id`，将未知 variant 映射为 `Endpoint`（或报错），防止编译失败。  
   - 在 `match` 分支中使用 `_ => {}` 统一捕获未实现的 variant，记录 `warn!` 而非 `error!`。

3. **幂等保证**  
   - 在 `KVStoreDiscovery::register`/`unregister` 前先检查键是否已存在/不存在，防止重复写入/删除导致的 KV 目录膨胀。  
   - 若底层 KV store 已提供 **CAS**，可利用实现乐观锁。

4. **安全加固**  
   - 在 `EventTransport::from_env_or_default` 中加入 **白名单校验**（仅 `nats`、`zmq`），并在启动时打印选中方式供运维审计。  
   - 对 `EventTransport::Nats { subject_prefix }` 进行合法性检查（禁止通配符、非法字符），防止订阅冲突。

5. **日志治理**  
   - 将 **注册/注销** 的 `info!` 改为 `debug!`，只在调试模式下输出；保留 `warn!` 用于异常路径。  
   - 为关键错误（如 `Failed to parse instance_id hex`）保持 `error!`。

6. **性能监控

---

### fix: correct typos in help text and add missing docstrings (#5607)
**SHA**: `491a210` | 🔗 [查看提交](https://github.com/ai-dynamo/dynamo/commit/491a21093f0e05bc4522ded98bc5e04fa61031c7)

**🎯 变更类型**：Bug修复 / 文档改进  
**⚡ 重要程度**：🔵低  
**📋 变更摘要**：本次提交主要纠正了多个组件的帮助信息中的拼写错误（`ETCD_ENPOINTS` → `ETCD_ENDPOINTS`）、统一了模型路径示例、以及为若干关键函数补全了 docstring。除此之外，在 `trtllm_utils.py` 中为 `parse_endpoint` 增加了输入格式校验并在格式错误时抛出 `ValueError`，提升了错误可发现性。  

**🎯 影响范围**：  
- `components/src/dynamo/frontend/main.py`  
- `components/src/dynamo/mocker/args.py`  
- `components/src/dynamo/sglang/args.py`  
- `components/src/dynamo/trtllm/utils/trtllm_utils.py`  
- `components/src/dynamo/vllm/args.py`  
- `launch/dynamo-run/src/flags.rs`  

**🔍 技术洞察**：  
- **架构影响**：仅属于文档层面的改动，不影响系统架构或模块交互。`parse_endpoint` 的异常抛出属于输入校验的细粒度改进，对整体组件解耦无影响。  
- **性能影响**：新增的 docstring 在运行时几乎无开销；`parse_endpoint` 额外的格式检查仅在调用时多一次字符串分割与长度判断，成本极低。  
- **安全考虑**：纠正环境变量说明避免用户因拼写错误而误配置 Etcd 连接，更可靠的 `parse_endpoint` 校验可以阻止非法或错误格式的 endpoint 进入后续业务逻辑，降低因异常字符串导致的未定义行为风险。  

**⚠️ 潜在风险**：  
1. **异常传播**：`parse_endpoint` 现在在格式不符合 `namespace.component.endpoint` 时抛出 `ValueError`，如果上层调用未捕获该异常，可能导致进程意外退出。  
2. **文档同步**：帮助信息的文字修改可能需要同步到外部文档或 CI 脚本的预期输出（如 `--help` 检查），否则可能出现测试不一致。  

**💡 关注建议**：  
- **异常处理**：检查所有调用 `parse_endpoint` 的路径，确保在必要时捕获 `ValueError` 并给出友好的错误提示。  
- **兼容性测试**：在本地和 CI 环境中运行一次完整的启动脚本，验证 `--help` 输出是否仍满足既有文档/脚本的期望。  
- **文档更新**：同步 README、部署手册以及任何 CI 检查脚本中的帮助文本，防止因拼写差异导致的误导。  
- **回归验证**：因为改动仅为文档和轻量校验，建议跑一次全套单元/集成测试，以确认未意外引入运行时异常。  

---

### feat: add __all__ exports and __repr__ methods for better debugging (#5606)
**SHA**: `7de8096` | 🔗 [查看提交](https://github.com/ai-dynamo/dynamo/commit/7de80960dc5980165b3f63ef7c66d20c9bd8f760)

**🎯 变更类型**：功能增强  
**⚡ 重要程度**：🔴高  
**📋 变更摘要**：在 Python 绑定层新增 `__all__` 列表以显式导出异常类和健康检查相关对象，并为多个异常类以及 `HealthCheckPayload` 实现 `__repr__` 方法，以提升调试可读性和交互式使用体验。  
**🎯 影响范围**：`components/src/dynamo/planner/utils/exceptions.py`、`lib/bindings/python/src/dynamo/health_check.py`（Python 绑定层）；对外部使用 `dynamo` Python SDK 的用户代码。  

**🔍 技术洞察**  
- **架构影响**：  
  - 仅限于 Python 包的公开接口，未触及底层 Rust 核心实现，属于 **向后兼容的包装层改动**。  
  - 引入 `__all__` 明确了 `from dynamo.planner.utils.exceptions import *` 的导出集合，防止未显式列出的内部符号意外泄露。  
  - `__repr__` 实现遵循标准 `repr` 约定，返回可直接 `eval` 的表达式（除非字段包含不可序列化对象），有助于 REPL、日志和错误追踪。  

- **性能影响**：  
  - `__repr__` 仅在显式调用（如调试打印、日志）时执行，字符串拼接的开销极小，对正常运行时的 CPU/内存影响可以忽略。  
  - `__all__` 的解析在模块导入时进行一次，成本与常规模块导入相同。  

- **安全考虑**：  
  - `__repr__` 会把异常实例的属性（如 `deployment_name`、`namespace`、`model_name`、`service_names`）完整展示。若这些字段可能包含租户敏感信息，误将 `repr(e)` 写入公开日志或错误监控平台可能导致信息泄露。  
  - `HealthCheckPayload.__repr__` 会完整打印健康检查的 payload，payload 中若包含内部密钥或 token（虽然常规情况下不应在健康检查中暴露），同样需要注意。  

**⚠️ 潜在风险**  
1. **信息泄露风险**：`repr` 输出未做过滤，调试或异常日志在生产环境中可能被收集，进而泄露部署名称、命名空间、模型名称等业务信息。  
2. **向后兼容性**：新增 `__all__` 可能导致此前使用 `import *` 隐式获取的符号不再可见；若用户依赖了未列入 `__all__` 的内部类，将出现 `ImportError`。  
3. **误用 `repr`**：开发者可能在业务代码中直接使用 `repr(e)` 作为错误信息返回给客户端，导致内部实现细节外泄。  

**💡 关注建议**  
- **安全审计**：对异常属性和健康检查 payload 进行敏感度评估，若有潜在机密信息，可在 `__repr__` 中做脱敏处理（如 `***`）或仅返回关键标识。  
- **文档更新**：在 SDK 文档中明确说明新增的 `__all__` 导出列表以及推荐的调试/日志实践，以防用户误用 `import *`。  
- **日志策略**：建议在生产环境的日志配置中限制 `repr` 的使用，或在捕获异常后只记录 `e.__class__.__name__` 与通用错误信息。  
- **回归测试**：添加单元测试验证 `repr` 的输出格式以及 `__all__` 导出的完整性，确保未来改动不会意外移除或新增导出符号。  
- **兼容性检查**：对已有用户的 CI/CD 流水线运行一次 `python -c "from dynamo.planner.utils.exceptions import *; print(dir())"`，确认未出现意外 `ImportError`。  

总体来看，此次提交提升了开发者调试体验，风险主要集中在信息泄露与向后兼容性，合理的日志治理与文档指引即可将风险降至可接受范围。

---

### refactor: reduce Python API to only Prometheus Exposition Format callback (#5594)
**SHA**: `7361de4` | 🔗 [查看提交](https://github.com/ai-dynamo/dynamo/commit/7361de420863ae54b9587b4fe9fa1579f99804cc)

**🎯 变更类型**：重构 / 架构变更  
**⚡ 重要程度**：🔴高  

**📋 变更摘要**  
此次提交把 Python 端的 Prometheus Metrics API 大幅裁剪，只保留 **回调注册** 功能（`register_prometheus_expfmt_callback`），删除所有 `create_*` 方法以及对应的 metric 类型包装类。文档、类型存根、示例、以及 `Component`/`Namespace` 的 `metrics` 属性也一并下沉至 `Endpoint`。核心 Rust 代码相应移除大量包装实现，仅保留 `RuntimeMetrics` 的回调注册逻辑。

**🎯 影响范围**  
- **Python 绑定层**：`lib/bindings/python/*`（核心模块、类型存根、示例、文档）  
- **Rust 绑定层**：`lib/bindings/python/rust/prometheus_metrics.rs`、`lib/bindings/python/rust/lib.rs`  
- **依赖**：`Cargo.lock` 新增 `anyhow`、`bincode`（用于回调序列化/错误包装）  
- **测试套件**：删除 `test_metrics_registry.py`（原有的 metric‑creation/操作单元测试）  

---

### 🔍 技术洞察

| 维度 | 影响说明 |
|------|-----------|
| **架构** | - **API 表面简化**：只保留 endpoint‑level 回调，去除对 `Component` / `Namespace` 的直接 metrics 创建入口。<br>- **统一入口**：所有外部 Prometheus 数据必须通过回调返回完整 exposition 文本，统一了数据注入路径。<br>- **移除 wrapper**：原本为满足 PyO3 的新型包装（`Counter`, `Gauge` 等）被全部删除，减少了 Rust↔Python 的跨语言边界。 |
| **性能** | - **绑定体积下降**：删除 900+ 行的 wrapper 与方法实现，编译时间和二进制体积均有略微下降。<br>- **运行时开销**：回调执行仍在 `add_update_callback` 中通过 `Python::with_gil` 调用，性能与之前相当；但不再有 `register_callback`（仅更新已有 metric），所以少了一层 Python‑to‑Rust‑to‑Prometheus 的桥接，整体略有提升。 |
| **安全** | - **攻击面收窄**：去除了大量暴露的 metric 实例方法，降低了误用或恶意调用导致的资源泄露风险。<br>- **异常处理**：回调错误通过 `tracing::error!` 记录，未抛出给 Prometheus endpoint，避免服务崩溃。<br>- **新增依赖**：`anyhow`、`bincode` 本身是成熟库，未引入新安全问题。 |
| **可维护性** | - **代码量大幅削减**（约 1 k 行删除），代码审查、bug定位成本下降。<br>- **文档同步**：原来的 metrics API 文档被删除，防止误导。<br>- **兼容性风险**：对已有 Python 使用者是 **破坏性改动**，需要迁移；但对内部维护者来说，维护负担明显降低。 |
| **生态** | - **示例/文档**：两个示例脚本被删，社区学习资源暂时缺失。<br>- **类型存根**：`prometheus_metrics.pyi` 只保留 `RuntimeMetrics`，防止 IDE 报错，确保新 API 的类型检查正常。 |
| **测试** | - 原有 `test_metrics_registry.py`（覆盖所有 metric 类型创建、操作、 introspection）被删除，导致 Python 侧的单元测试覆盖率下降。若没有其他回归测试，可能在未来引入隐藏 bug。 |

---

### ⚠️ 潜在风险

1. **向后兼容性破坏**  
   - 所有依赖 `endpoint.metrics.create_*`、`component.metrics`、`namespace.metrics` 的 Python 代码将在运行时抛 `AttributeError`。  
   - `import dynamo.prometheus_metrics` 现在是空模块，旧的 `from dynamo.prometheus_metrics import Counter` 等导入会失败。

2. **迁移成本**  
   - 使用者必须改写为：自己在 Rust 侧创建 metric，或通过回调返回完整 Prometheus exposition 文本。  
   - 需要在项目内部提供迁移指南（示例、文档）。

3. **测试缺失**  
   - 删除的 Python 单元测试可能隐藏回调注册的边界情况（例如异常回调、并发回调）。  
   - 若未来新增 metric 类型或回调机制，缺少回归基线。

4. **运行时错误可见性**  
   - 回调执行异常仅记录日志，不会显式返回给调用方，运维可能错过关键错误。需要保证日志监控能够捕获 `Metrics callback failed`。

5. **潜在的依赖冲突**  
   - 新增的 `anyhow`、`bincode` 可能与项目中已有相同库的不同版本冲突，需检查 Cargo.lock 的一致性。

---

### 💡 关注建议

| 对象 | 建议 |
|------|------|
| **库维护者** | 1. 在 `README`/`docs` 中明确标注 “Python metrics API 已简化，仅支持回调”。<br>2. 提供迁移示例：<br>   ```python\nmetrics = endpoint.metrics\nmetrics.register_prometheus_expfmt_callback(lambda: external_system.collect())\n```<br>3. 保留（或新建）针对回调的单元测试，验证异常处理、并发调用、返回文本的合法性。 |
| **使用者** | 1. 检查代码中是否还有 `create_*` 调用；改为使用 Rust 侧 metrics 或回调方式。<br>2. 若需要在 Python 中维护指标状态，建议自行实现内部计数器并在回调中渲染 Prometheus exposition（参考 `prometheus_client` Python 包）。 |
| **CI/测试** | - 添加针对 `RuntimeMetrics.register_prometheus_expfmt_callback` 的集成测试，确保回调返回的文本最终出现在 `/metrics` 响应里。<br>- 确保在多进程/多线程环境下回调不导致 GIL 死锁或性能瓶颈。 |
| **安全/运维** | - 在 `tracing` 日志中加入回调名称或上下文，以便快速定位错误。<br>- 监控 `/metrics` 响应体大小，防止回调产生异常大的 exposition 文本导致网络或磁盘压力。 |
| **未来扩展** | 若需要恢复部分创建能力，建议 **分层**：保留 `RuntimeMetrics` 的回调入口，同时在 Rust 中提供 `MetricsFactory`，让 Python 只能获取已注册好的 metric 对象（只读），这样既保持简洁，又不完全失去创建能力。 |

--- 

**结论**：此次提交通过大幅削减 Python Prometheus Metrics API，显著降低了绑定层的复杂度与安全风险，但对现有 Python 使用者是一次 **破坏性** 更改。为避免生产事故，请在升级前完成迁移并补充针对回调的测试用例。 🚀

---

#### 🟡 中重要度变更 (4)

### fix: incremental build for dynamo-llm (#5601)
**SHA**: `e6ad5bc` | 🔗 [查看提交](https://github.com/ai-dynamo/dynamo/commit/e6ad5bc5a3d950f97115d2af9d1c213ec8aa99a9)

**🎯 变更类型**：Bug 修复  
**⚡ 重要程度**：🟡 中  

**📋 变更摘要**：  
- `lib/llm/build.rs` 中的 `compile_protos` 调用了错误的相对路径，仅传入文件名 `kserve.proto`，导致在增量编译（`cargo check` / `cargo watch`）时找不到文件并触发完整重新编译。  
- 修正为使用完整相对路径 `src/grpc/protos/kserve.proto`，保持搜索根目录不变，从而让 Cargo 正确识别文件依赖，实现增量构建。

**🎯 影响范围**：  
- `dynamo-llm` 子模块的构建脚本；  
- 依赖该子模块的 CI/CD 流程和本地增量编译（`cargo watch`、`cargo check`）。  

**💡 关注建议**：  
1. 本地运行 `cargo check` 与 `cargo watch`，确认不再出现 “file not found” 导致的全量重新编译。  
2. 运行项目全部测试，确保生成的 gRPC 代码仍兼容（尤其是序列化派生属性）。  
3. 若仓库中还有其他 `compile_protos` 调用，也检查路径是否同样需要使用完整相对路径，以避免类似增量构建回退。  
4. 在贡献指南或 CI 文档中加入说明：**proto 文件路径必须使用相对根目录的完整路径**，防止未来误用导致构建性能下降。  

此修复不影响运行时行为，只提升了开发体验和 CI 构建效率。

---

### refactor: add explicit non-leader node handling in vLLM (#5597)
**SHA**: `2da403e` | 🔗 [查看提交](https://github.com/ai-dynamo/dynamo/commit/2da403e39858a0138e767569e554203bb2319802)

**🎯 变更类型**：功能增强（多节点部署细化）  
**⚡ 重要程度**：🟡 中  

**📋 变更摘要**  
1. CI 工作流将 vLLM 构建超时从 90 min 提升至 240 min，以防止大模型/多卡构建被误杀。  
2. 在 `components/src/dynamo/vllm/main.py` 中新增 `_handle_non_leader_node`，当 `data_parallel_rank >= 1` 时，节点仅启动 vLLM worker 并 **不** 注册 Dynamo HTTP/GRPC 端点，而是通过 `await asyncio.Event().wait()` 持续阻塞，直至外部信号终止。  
3. 对 `init_prefill` 与 `init` 两个入口函数做相同的非主节点检测与提前返回，并相应地简化了原先的 `if not data_parallel_rank` 条件。  

**🎯 影响范围**  
- `components/src/dynamo/vllm/*`（vLLM 运行时初始化、模型注册）  
- CI/CD pipeline（pr.yaml 超时调高）  

**💡 关注建议**  
1. **Graceful shutdown**：当前非主节点通过 `await asyncio.Event().wait()` 无限阻塞，依赖外部 signal 终止。建议在 `graceful_shutdown` 中显式触发该 Event，或在进程退出前调用 `cancel()`，避免出现僵尸进程。  
2. **日志可观测性**：非主节点仅打印一次 “Skipping endpoint serving”。可考虑在退出前记录 shutdown 原因，便于排查。  
3. **配置兼容性**：`data_parallel_rank` 为 `0`、`None`、或正整数的分支已合并，确保文档中说明 “仅在 rank=0 时提供 API”。  
4. **测试覆盖**：新增单元/集成测试模拟 `data_parallel_rank>0` 场景，验证进程不会意外注册路由且能够被信号终止。  
5. **CI 超时**：240 min 对大多数 PR 已足够，但若后续引入更大模型，建议将 timeout 调整为变量或通过 matrix 动态计算，以免不必要的资源占用。  

总体来说，此次重构提升了多节点部署的行为一致性，避免非主节点暴露不必要的 Dynamo 服务；但需确保非主节点的生命周期管理可靠，防止因无限阻塞导致资源泄漏。

---

### chore(deps): bump vLLM to 0.14.0 (#5593)
**SHA**: `50f1e0e` | 🔗 [查看提交](https://github.com/ai-dynamo/dynamo/commit/50f1e0e17aebadbe5de9e337c6aaa5262f8559f2)

**变更类型**：功能增强 / 依赖升级  
**重要程度**：🟡 中  

**核心改动**  
1. 将 vLLM 依赖从 0.13.0 升级到 0.14.0，并同步更新 Dockerfile、`install_vllm.sh`、`pyproject.toml` 与支持矩阵文档。  
2. 在 Rust 代码 (`publisher.rs`, `subscriber.rs`) 中为 `BlockStored` 增加 `lora_name` 字段，并在反序列化 visitor 中处理该新字段，保持向后兼容。  
3. `kvbm/vllm_integration/connector_leader.py` 适配 vLLM 0.14.0 中 `resumed_req_ids` 的改变。  
4. 新增 Python 单元测试 `test_vllm_kv_events_api.py`，直接验证 vLLM 的 MsgSpec 结构、字段顺序、`array_like` 与 `tag` 配置以及序列化结果，防止未来 API 变动导致 Rust 反序列化错误。  
5. E2E 测试启动脚本增加 `terminate_existing=False`，避免在同一进程中误杀已启动的 NATS/etcd。  

**影响范围**  
- `lib/llm/src/kv_router`、`kv_consolidator` 以及 Python‑Rust 互操作层。  
- 使用 vLLM KV 事件的所有组件，包括 KV‑BM、调度器和后端集成。  

**建议**  
- 在 CI 中加入 `test_vllm_kv_events_api.py`，确保每次 vLLM 升级都能及早捕获结构变更。  
- 保持 `lora_name` 为 `Option<String>` 并在业务侧继续使用 `lora_id`，以兼容旧模型；必要时在文档中说明两者的对应关系。  
- 检查其他依赖（如 flashinfer、runai）是否需要同步升级，以免出现运行时缺失库的情况。  
- 考虑在 `pubspec` 中锁定 `vllm` 的次要版本范围（`>=0.14,<0.15`），防止未来次要升级突兀破坏序列化约定。  

总体来看，本次升级实现了对 vLLM 0.14.0 新增字段的安全适配，并通过专门的兼容性测试提高了代码稳健性。后续关注 vLLM 结构变化以及相应的序列化兼容即可。

---

### chore: nuke ForwardPassMetrics (#5531)
**SHA**: `feb6d27` | 🔗 [查看提交](https://github.com/ai-dynamo/dynamo/commit/feb6d272ac7dc392bdbd4a759c69f310bb3a78ba)

**🛠️ 变更类型**  
重构 / 功能削减（删除 `ForwardPassMetrics` 以及相关结构体，改为仅发布 **dp_rank + 活跃 KV Block 数**）

**⚡ 重要程度**  
🟡 中 —— 破坏性强（API 彻底改动），但对运行时行为影响有限（只简化了监控数据）。

---

## 1️⃣ 变更概览

| 模块 | 关键改动 |
|------|----------|
| **Python publishers** (`components/src/dynamo/*/publisher.py`) | 去掉 `ForwardPassMetrics`、`KvStats`、`WorkerStats`、`SpecDecodeStats`，改为 `self.metrics_publisher.publish(dp_rank, kv_active_blocks)`。`create_endpoint` 从同步改为 **异步**，在 `setup_*_metrics` 中显式 `await`。 |
| **示例代码** (`examples/multimodal/*`, `vllm/*`) | 同上，删除了 `request_total_slots` / `set_num_request_total_slots`，只保留 `num_gpu_block`（用于计算 `active_decode_blocks`）。 |
| **Rust bindings** (`lib/bindings/python/*`) | 移除对四个结构体的 `#[pyclass]` 暴露，`WorkerMetricsPublisher.publish` 参数改为 `(dp_rank: Option<u32>, active_decode_blocks: u64)`，并在 `pyo3` 方法签名中同步更新。 |
| **内部协议** (`lib/llm/src/kv_router/protocols.rs`) | 删除 `ForwardPassMetrics、WorkerStats、KvStats、SpecDecodeStats` 以及 `LoadMetrics` 中的旧实现，只保留 `ActiveLoad`（仅 `active_decode_blocks`）。 |
| **Metrics 发布器** (`lib/llm/src/kv_router/publisher.rs`) | `WorkerMetricsPublisher` 只在内部维护 `WorkerMetrics {dp_rank, active_decode_blocks}`，去掉 **Prometheus KvStats** 相关 gauge 注册与更新。发布前的“变更检测”逻辑只比较 `active_decode_blocks`。 |
| **Mock 调度器** (`lib/llm/src/mocker/*`) | 同样改为使用 `MockerMetrics {dp_rank, active_decode_blocks}`，`publish` 调用相应简化。 |
| **Prometheus 名称** (`lib/runtime/src/metrics/prometheus_names.rs`) | 删除整个 `kvstats` 模块及其常量，保留 `kvbm`（对象存储统计）以及 `kvrouter`。|
| **文档 & 测试** | 更新 `router/kv_cache_routing.md` 中的描述（从 “publish `ForwardPassMetrics`” 改为 “publish load metrics”），以及 `tests/utils/payloads.py` 中对指标数量的阈值调整。|
| **其它** | 去除 Python 包 `dynamo.llm` 中对已删除结构体的导出，关闭相应的 `pyo3` 类型注册。|

> **核心思路**：从“完整的前向传递快照（Worker + KV + 规格化解码）” → “仅上报 **DP‑rank** 与 **当前活跃 KV block 数**”。因此监控、路由只依赖 **active_decode_blocks** 这一个负载维度。

---

## 2️⃣ 受影响范围

| 受影响层次 | 具体文件/目录 |
|------------|----------------|
| **Python API** | `dynamo.llm`（`ForwardPassMetrics`、`WorkerStats`、`KvStats`、`SpecDecodeMetrics`）<br>所有使用 `WorkerMetricsPublisher.publish` 的组件（sglang、trtllm、vllm、multimodal） |
| **Rust 绑定** | `lib/bindings/python/rust/llm/kv.rs`、`lib/bindings/python/_core.pyi` |
| **内部协议** | `lib/llm/src/kv_router/protocols.rs`、`publisher.rs`、`mocker/*` |
| **Prometheus** | `lib/runtime/src/metrics/prometheus_names.rs`（删除 `kvstats`）<br>任何自定义监控仪表板/告警仍然依赖 `kvstats_*` 将失效 |
| **文档/示例** | `docs/router/kv_cache_routing.md`、`examples/*`、`components/*/publisher.py` |
| **测试** | `tests/*`（尤其是依赖 `ForwardPassMetrics` 的集成测试、Prometheus gauge 验证） |

---

## 3️⃣ 潜在风险与注意事项

1. **向后兼容性**  
   - 所有外部用户（包括内部子项目、第三方插件）若仍使用 `ForwardPassMetrics`、`WorkerStats`、`KvStats`、`SpecDecodeStats` 的 Python 类型或 `publish(metrics)` 接口，将立即报错。需要在升级指南中提供迁移示例（仅 `publish(dp_rank, active_blocks)`）。  
   - 已经在生产中部署的 Prometheus 报警/仪表板仍引用 `kvstats_*` 这些 metric 名称，需要手动改为新监控（目前只保留 `active_decode_blocks` 通过 `kvrouter` 的 `active_decode_blocks` 字段，外部可自行映射为相应的 metric）。

2. **异步端点创建**  
   - `WorkerMetricsPublisher.create_endpoint` 变为 **async**。若有遗漏的 `await`（比如在某些自定义脚本或未更新的测试里），会导致端点未创建、后续发布失败。已在 `setup_sgl_metrics`、`examples` 中添加 `await`，但请全局搜索 `create_endpoint(` 确认没有同步调用残留。

3. **Prometheus Gauge 删除**  
   - 原来的四个 KV‑stats gauge（`kvstats_active_blocks`、`kvstats_total_blocks`、`kvstats_gpu_cache_usage_percent`、`kvstats_gpu_prefix_cache_hit_rate`）已彻底移除。若有监控系统直接查询这些 gauge，会得到 “no such metric”。建议在迁移期通过 `kvrouter_active_decode_blocks`（或自行定义新 gauge）补齐监控需求。

4. **测试覆盖**  
   - 相关单元/集成测试已更新（如 `test_integration_publisher`），但仍保留了被 `#[ignore]` 标记的 Prometheus‑gauge 测试。若计划恢复，需要重新实现对应的 gauge 注册路径（已经删除）。  
   - `tests/utils/payloads.py` 中对指标数量的阈值已下调，确保 CI 不因缺失 `kvstats` 而报错。

5. **代码路径冗余**  
   - 删除了大量 `*_record*`、`*_record_values*` 辅助函数，这些函数在历史代码里被调用的地方已经全部替换，但仍需确认没有遗漏的内部调用（搜索 `record_values`、`_record`）。  
   - `examples/multimodal/components/worker.py` 中的 `set_num_request_total_slots` 已删除；如果外部仍通过 env 或 CLI 传递该值，可能导致运行时 `AttributeError`。

6. **文档一致性**  
   - 路由文档已更新为 “publish load metrics”。仍有可能出现旧文档（README、博客等）提到 `ForwardPassMetrics`，需同步更新，以免误导新

---

#### 🟢 低重要度变更 (4)

### chore: remove some clones in Indexer (#5612)
**SHA**: `67c868e` | 🔗 [查看提交](https://github.com/ai-dynamo/dynamo/commit/67c868e7b787c5ce4f7f9f118285ee38e92e2013)

**🎯 变更类型**：代码重构  
**⚡ 重要程度**：🟢 低  
**📋 摘要**：删除了 `KvRouter` 与 `KvIndexer` 中不必要的 `clone`，改为条件克隆，仅在需要时才复制事件，从而降低内存开销并提升性能。

---

### ci: add filters for frontend image workflow (#5585)
**SHA**: `d4fbf9d` | 🔗 [查看提交](https://github.com/ai-dynamo/dynamo/commit/d4fbf9d39f60b4bc769c02fdf61d791b60b0caf2)

**🎯 变更类型**：配置调整  
**⚡ 重要程度**：🟢低  
**📋 摘要**：为前端镜像工作流新增 `frontend` 过滤器，扩展 `.github/actions/changed-files` 输出，更新 `filters.yaml` 规则，并在 `build-frontend-image.yaml` 中仅在前端文件变更时构建镜像，加入状态检查步骤。

---

### docs: add NIXL backend configuration and fix multiple typos (#5564)
**SHA**: `912a4d4` | 🔗 [查看提交](https://github.com/ai-dynamo/dynamo/commit/912a4d4b7ef39eda11b93c11f74b32e8eaf1906a)

**🎯 变更类型**：文档更新  
**⚡ 重要程度**：🟢低  
**📋 摘要**：新增 NIXL 后端配置说明；修正多个拼写/语法错误（Python 参数说明、Markdown 文档、Rust 注释）。

---

### chore: simplify RadixTree assuming consistent hashing across workers (#5605)
**SHA**: `b273eda` | 🔗 [查看提交](https://github.com/ai-dynamo/dynamo/commit/b273eda2f456643ef5e18dbe95ae55b53473c057)

**🎯 变更类型**：代码重构  
**⚡ 重要程度**：🟢低  
**📋 摘要**：RadixTree 统一假设跨 worker 的块哈希相同，改用 `HashSet` 记录拥有该块的 workers，新增 `block_hash` 字段并使用 per‑worker 查找表，简化插入、遍历、删除逻辑，更新相应测试。

---

