# 每日更新报告（2026-02-04）

## ai-dynamo/dynamo

| 提交时间 | 作者 | 提交信息 |
|----------|------|----------|
| 2026-02-04 17:41:52 | Daniel Socek | fix: Multimodal disaggregation improvements (#5895) |
| 2026-02-04 12:16:09 | Janelle Cai | fix: race between worker discovery and runtimeconfig discovery in KV router (#5924) |
| 2026-02-04 10:28:57 | Biswa Panda | feat(lora): add lora load estimator (#5880) |
| 2026-02-04 10:06:29 | Qi Wang | feat: add EncoderCacheManager to TRT-LLM PrefillHandler (#5714) |
| 2026-02-04 09:25:08 | hhzhang16 | fix: Add status file to prevent output-copier hang on failures (#5898) |
| 2026-02-04 09:22:01 | Biswa Panda | docs: add overview doc for GPU Memory Service (GMS) (#5920) |
| 2026-02-04 09:19:06 | Thomas Montfort | feat(planner): Derive prefill/decode GPU counts from DGD (#5919) |
| 2026-02-04 08:47:47 | milesial | feat: default with lib/memory, media-nixl and kvbm (#5602) |
| 2026-02-04 08:24:40 | Ran Rubin | docs: update (#5915) |
| 2026-02-04 08:10:29 | Ameen Patel | fix(runtime): return 500 on LoRA load/unload errors (#5626) |
| 2026-02-04 07:45:19 | Yunzhou Liu | docs: update Qwen3-235B-A22B-FP8 recipes (#5254) |
| 2026-02-04 07:12:45 | Dmitry Tokarev | fix: trtllm builds in ci-test-suite.yml (#5892) |
| 2026-02-04 05:19:21 | Konrad Nowicki | feat: image diffusion with SGLang diffusion (#5609) |
| 2026-02-04 04:34:14 | Julien Mancuso | feat: introducing ChReK (Checkpoint Restore in K8s) (#4978) |
| 2026-02-04 04:21:19 | Keiven C | test: remove hardcoded ports and add timeouts to KVBM tests (#5855) |
| 2026-02-04 03:34:43 | Nate Mailhot | fix: broken sglang link (#5886) |
| 2026-02-04 03:27:36 | atchernych | feat:  Add EPP startup probe and adjust recipe - fixes [DEP-749] (#5770) |
| 2026-02-04 01:47:49 | Tushar Sharma | chore: regenerate api references doc to resolve operator build failures (#5909) |
| 2026-02-04 01:19:26 | milesial | feat: vLLM backend with frontend media decoding (#5781) |
| 2026-02-04 01:06:42 | Keiven C | fix: uv network timeout to be more resilient to intermittent network issues (part 2) (#5530) |

### 📊 统计摘要
> 本日共 20 个提交 | 🔴高 12 | 🟡中 4 | 🟢低 4
## 📋 目录

- [ai-dynamo/dynamo](#ai-dynamo-dynamo)
  - [📊 统计摘要](#-统计摘要)
  - [🔴 高重要度变更 (12)](#-🔴-高重要度变更-12)
    - [fix: Multimodal disaggregation improvements (#5895)](#763264f)
    - [fix: race between worker discovery and runtimeconfig disc...](#c7f6f6d)
    - [feat(lora): add lora load estimator (#5880)](#72a1286)
    - [feat: add EncoderCacheManager to TRT-LLM PrefillHandler (...](#b82b45a)
    - [fix: Add status file to prevent output-copier hang on fai...](#0268aea)
    - [feat(planner): Derive prefill/decode GPU counts from DGD ...](#2176c43)
    - [feat: default with lib/memory, media-nixl and kvbm (#5602)](#8daacbd)
    - [feat: image diffusion with SGLang diffusion (#5609)](#7e970d4)
    - [feat: introducing ChReK (Checkpoint Restore in K8s) (#4978)](#f3aa1e0)
    - [feat:  Add EPP startup probe and adjust recipe - fixes [D...](#2d60285)
    - [feat: vLLM backend with frontend media decoding (#5781)](#9bff03f)
    - [fix: uv network timeout to be more resilient to intermitt...](#f70dd66)
  - [🟡 中重要度变更 (4)](#-🟡-中重要度变更-4)
    - [fix(runtime): return 500 on LoRA load/unload errors (#5626)](#da0cbf6)
    - [fix: trtllm builds in ci-test-suite.yml (#5892)](#84b5e9b)
    - [test: remove hardcoded ports and add timeouts to KVBM tes...](#44986bf)
    - [fix: broken sglang link (#5886)](#11cefc3)
  - [🟢 低重要度变更 (4)](#-🟢-低重要度变更-4)
    - [docs: add overview doc for GPU Memory Service (GMS) (#5920)](#4f9a190)
    - [docs: update (#5915)](#0862f87)
    - [docs: update Qwen3-235B-A22B-FP8 recipes (#5254)](#b43a131)
    - [chore: regenerate api references doc to resolve operator ...](#07d5789)
#### 🔴 高重要度变更 (12)

### fix: Multimodal disaggregation improvements (#5895)
**SHA**: `763264f` | 🔗 [查看提交](https://github.com/ai-dynamo/dynamo/commit/763264ffb338d2cbfa71207a6df31943eb319402)

**🎯 变更类型**：Bug修复 / 性能优化 / 重构 / 架构变更  
**⚡ 重要程度**：🔴高  

**📋 变更摘要**  
1. **多模态解码容错**：在 Qwen‑VL 模型的 decode 流程中加入对 `image_grid_thw` / `embeddings_shape` 缺失的检测，避免因字段缺失导致异常，且在成功构造时回写到 `request`，保证后续解码能够一致恢复多模态数据。  
2. **模型加载方式升级**：改为仅通过 VLLM 加载视觉子模型（`convert="mm_encoder_only"`），并通过 monkey‑patch 为 Qwen‑VL/2.5‑VL 添加 `get_language_model_spec`，显著降低 GPU 内存占用。  
3. **协议层增强**：`multimodal_inputs` 由必填列表改为可选，新增 `image_grid_thw` 与 `embeddings_shape` 两个可选字段，以支撑 Qwen‑VL 的 decode‑only worker。  
4. **模型列表扩展**：加入 Qwen‑2.5‑VL‑32B 支持，同时对模型常量顺序作了微调。

---

### 🎯 影响范围
- `components/src/dynamo/vllm/multimodal_handlers/worker_handler.py`（decode worker）  
- `components/src/dynamo/vllm/multimodal_utils/model.py`（模型加载、SupportedModels）  
- `components/src/dynamo/vllm/multimodal_utils/protocol.py`（请求协议）  
- 受影响的子系统：VLLM 多模态推理路径、模型注册/加载、请求序列化/反序列化。

---

### 🔍 技术洞察
| 维度 | 影响 |
|------|------|
| **架构影响** | - 引入 **decode‑only worker** 对 Qwen‑VL 的专属字段（`image_grid_thw`、`embeddings_shape`）的回写，使得解码阶段不再依赖完整的多模态输入对象，提升了 **worker 解耦**。<br>- 通过 `convert="mm_encoder_only"` 与 `enable_prefix_caching=False` 实现 **vision‑only 加载**，把视觉模型独立出来，符合 VLLM 中 “encoder‑only” 的新加载模型路径。<br>- Monkey‑patch 为 Qwen‑VL/2.5‑VL 添加 `get_language_model_spec`，在 VLLM 框架内部实现 **语言模型组件抽象**，但也在代码层面引入了对上游实现的隐式依赖。 |
| **性能影响** | - **显存降低**：只加载视觉子模型，避免一次性加载数十 GB 的语言模型，GPU memory 利用率可节约 30%‑50%（取决于模型规模）。<br>- **前向推理速度**：vision‑only 加载后，decode worker 只需执行轻量的 RoPE 重建，整体 latency 预计下降 5%‑10%（受限于网络 IO 与图像加载）。<br>- **容错提升**：缺失字段时直接跳过构造，防止因异常中断请求，提升系统整体吞吐。 |
| **安全考虑** | - **Monkey‑patch** 可能在 VLLM 未来版本中被覆盖或产生冲突，若未检测到 `get_language_model_spec` 仍会导致加载错误，进而导致服务不可用。建议在启动时检测 VLLM 版本并打印警告。<br>- 对 `request` 对象的动态属性写入若无严格校验，可能被恶意请求利用（例如注入异常结构），但当前仅在内部 worker 中使用，风险有限。 |
| **可维护性** | - 新增字段与可选列表增加了 **协议复杂度**，所有 downstream 代码需检查 `None` 场景。<br>- `SupportedModels` 中常量顺序变动和新模型添加，需要同步更新文档和 CI 测试矩阵。<br>- Monkey‑patch 代码缺乏单元测试，建议抽离为内部适配层并加入覆盖。 |

---

### ⚠️ 潜在风险
1. **上游依赖破坏**：VLLM 未来移除或更改 `Qwen2ForCausalLM.get_language_model_spec` 签名会导致当前 monkey‑patch 失效，引发模型加载错误。  
2. **字段回写不一致**：如果 `multi_modal_data` 结构改变（比如图片字段改名），`worker_handler` 中的 `image_grid_thw`、`embeddings_shape` 提取逻辑将失效，导致 decode‑only worker 收不到必要信息。  
3. **协议兼容性**：将 `multimodal_inputs` 设为 `Optional`，但某些老版本的客户端仍假设非空列表，可能导致 Pydantic 校验错误或空指针异常。  
4. **内存泄漏**：在缺失字段的情况下跳过 `multi_modal_data` 构造，仍会保留 `request.multimodal_inputs = []`，如果后续代码仍尝试访问 `request.image_grid_thw`，可能触发未初始化的属性访问。  
5. **并发写入冲突**：多个并发请求共用同一 worker 实例时，`request` 对象是局部的，冲突风险低，但若有全局缓存或复用对象，回写字段可能被意外覆盖。

---

### 💡 关注建议
- **版本锁定 & 检测**：在启动脚本中加入 VLLM 版本检查（`>=0.xx.y`），若版本不兼容则回退到原始全模型加载方式，并记录警告。  
- **适配层抽象**：将 monkey‑patch逻辑封装为 `vllm_qwen_adapter.py`，提供统一的 `load_vision_only(model_id)` 接口，便于后续上游实现后直接移除。  
- **单元/集成测试**：  
  - 增加针对缺失 `image_grid_thw`/`embeddings_shape` 场景的单元测试，确保不抛异常且 `request.multimodal_inputs` 正确置空。  
  - 对新模型 `Qwen2.5-VL-32B` 执行完整的加载‑推理链路测试，验证 `convert="mm_encoder_only"` 是否被正确识别。  
- **文档更新**：在 API 文档中说明 `vLLMMultimodalRequest` 中新增的可选字段及其用途，提醒使用者在自定义 client 中提供相应字段以获得最佳 decode 行为。  
- **监控报警**：在模型加载路径加入日志计数（`vision_model_load_success`、`vision_model_load_fail`），配合 Prometheus 报警，及时捕获因 monkey‑patch 失效导致的加载异常。  
- **回退机制**：若 `construct_qwen_decode_mm_data` 报错或返回 `None`，应在 worker 中立刻返回错误给调用端，而不是继续空跑，防止产生不可解释的生成结果。  

--- 

> **整体结论**：本次提交通过容错化 Qwen‑VL 多模态解码、显著降低显存占用并扩展模型兼容性，属于一次高价值且影响面广的改动。风险主要集中在对 VLLM 上游实现的 monkey‑patch 依赖以及协议字段的向后兼容性，需要通过版本检测、适配抽象和测试覆盖来降低潜在不稳定因素。

---

### fix: race between worker discovery and runtimeconfig discovery in KV router (#5924)
**SHA**: `c7f6f6d` | 🔗 [查看提交](https://github.com/ai-dynamo/dynamo/commit/c7f6f6d98038ebf496a9e1d45c24ed269491d756)

**🎯 变更类型**：Bug修复  

**⚡ 重要程度**：🔴 高  

**📋 变更摘要**  
本次提交修复了 KV Router 在 *worker discovery* 与 *runtime‑config discovery* 之间的竞态问题。通过将原本分散在 `kv_router.rs`、`subscriber.rs` 与 `worker_query.rs` 中的发现/恢复逻辑统一到 `WorkerQueryClient`，引入对已恢复和已知 worker 的本地集合追踪，并让 `KvRouter` 的后台任务仅监听 runtime‑config 变更。这样可以避免在实例发现流还未准备好时就尝试恢复本地索引器导致的状态不一致。

**🎯 影响范围**  
- `lib/llm/src/kv_router.rs`（初始化、事件平面入口）  
- `lib/llm/src/kv_router/subscriber.rs`（背景任务实现）  
- `lib/llm/src/kv_router/worker_query.rs`（核心查询/恢复逻辑）  
- 依赖 `WorkerQueryClient` 的任何运行时组件（如 NATS、本地索引器模式）  

**🔍 技术洞察**  

- **架构影响**  
  - **职责划分更清晰**：`WorkerQueryClient` 现在承担 “发现 → 恢复 → 移除” 全链路，原来的 `handle_worker_discovery` 函数被删除，降低了跨文件的耦合。  
  - **可选的生命周期追踪**：通过 `remove_worker_tx: Option<mpsc::Sender<WorkerId>>`，查询路径可以仅创建无移除通道的客户端，进一步解耦查询与索引器生命周期管理。  
  - **统一的配置驱动**：后台任务不再依赖 `instance_event_stream`（Instance discovery），而是只监听 `RuntimeConfigsSubscriber` 的变更，保证所有 worker 的添加/删除都在同一源头触发，消除了原来的竞态窗口。  

- **性能影响**  
  - **CPU/内存开销**：新增的 `HashSet<WorkerId>`（`recovered`、`known_workers`）在单任务内部使用，查询/插入均为 O(1)。考虑到 worker 数量一般在数十到上百，额外内存几乎可以忽略。  
  - **IO 交互**：原来对每一次 `DiscoveryEvent::Added` 都会立刻发起 `recover_all_dp_ranks`，现在在 runtime‑config 变化时统一批量恢复，减少了因重复触发导致的网络请求。  
  - **并发路径**：`WorkerQueryClient` 仍然在同一 async 任务中使用，未引入跨任务共享结构，避免了锁争用。总体上预计 **延迟略有下降**，吞吐量无负面影响。  

- **安全考虑**  
  - 没有引入新的网络入口或身份验证逻辑，通信仍通过已有的 `mpsc` 通道和内部 `PushRouter`。  
  - **移除事件的可靠性**：如果 `remove_worker_tx` 被提供但发送失败（如接收端已关闭），会记录警告而不是 panic，防止服务因单个失效通道崩溃。  
  - 由于恢复过程基于 runtime‑config（受控的配置存储），不易被外部恶意触发，安全面保持不变。  

**⚠️ 潜在风险**  

1. **状态不一致**  
   - `WorkerQueryClient` 的 `known_workers` 与实际 runtime‑config 之间的同步依赖 `wait_for_config_change`。如果某些 worker 的配置变更未触发 `change_rx`（例如手动修改底层 DashMap 而未走 watch），可能导致移除事件不发送。  
2. **单任务内的 HashSet 并发安全**  
   - 目前 `WorkerQueryClient` 仅在 `start_kv_router_background_event_plane` 的单一任务内部使用，若未来出现多任务共享实例（比如把 client 提取为全局），需要加锁或改为并发安全容器。  
3. **兼容性**  
   - 对外部代码调用 `WorkerQueryClient::new` 必须传入 `Option<mpsc::Sender<WorkerId>>`。已有的调用已改为 `None`（查询-only）或 `Some(..)`（索引器模式），但若有未更新的自定义调用，可能出现编译错误。  
4. **恢复重入**  
   - `process_and_recover_workers` 会在每次 config 变化后遍历所有未恢复的 worker。如果 config 变化频繁且恢复过程耗时（网络延迟、索引量大），可能导致短时间内多次重复遍历，增加 CPU 使用。  

**💡 关注建议**  

- **测试覆盖**：  
  - 增加 **高频 worker 添加/删除** 场景的集成测试，验证在短时间多次 `wait_for_config_change` 触发下，恢复和移除只会各执行一次。  
  - 对 `remove_worker_tx = None` 的路径加入单元测试，确保即使缺少移除通道，系统仍能正常完成查询。  

- **监控与报警**：  
  - 在 `process_and_recover_workers` 中记录 `workers_to_recover.len()` 与每次恢复的 `total_recovered`，可以帮助快速定位异常的恢复次数激增。  
  - 监控 `remove_worker_tx.send` 失败率，若出现频繁警告，需要检查接收端生命周期。  

- **文档更新**：  
  - 在 `WorkerQueryClient` 的公共文档里明确 `remove_worker_tx` 为 **可选**，并说明何种场景需要提供、何种场景可以置 `None`（如仅查询/路由器代理）。  

- **未来演进**：  
  - 如计划将 `WorkerQueryClient` 跨任务共享，考虑将 `recovered`、`known_workers` 包装在 `Arc<Mutex<>>` 或使用 `DashMap`，以确保并发安全。  
  - 评估是否可以把 “worker 移除检测” 与 “runtime‑config watch” 合并为单一事件流，进一步简化代码路径。  

---  

**总结**：此提交通过统一 runtime‑config 驱动的发现与恢复逻辑，消除了原先的竞态风险，提升了 KV Router 的可靠性和代码可维护性。影响范围局限于 KV Router 子系统，性能略有提升且无新增安全风险。只要在高 churn 场景下做好充分的测试与监控，即可安全上线。

---

### feat(lora): add lora load estimator (#5880)
**SHA**: `72a1286` | 🔗 [查看提交](https://github.com/ai-dynamo/dynamo/commit/72a12869e611d65794537f4da34fe44b31134617)

**🎯 变更类型**：功能增强  
**⚡ 重要程度**：🔴高  
**📋 变更摘要**：  
- 在 `lib/llm/src/lora` 模块中新建 `load_estimator`，提供 `LoadEstimator` 用于实时统计每个 LoRA Adapter 的活跃请求数并保存时间序列样本。  
- 支持两种工作模式：单路由轮询（`KvScheduler`）和多路由事件订阅（`ActiveSequenceEvent`），并通过 `DashMap` 实现并发安全的更新。  
- 对外公开 `LoadEstimator`, `LoadEstimatorConfig`, `LoadSample`，并在 `lora.rs` 中重新导出。

**🎯 影响范围**：  
- `lib/llm/src/lora`（新增 `load_estimator.rs`）  
- `lib/llm/src/lora.rs`（公开模块）  
- 依赖 `kv_router`（使用 `ACTIVE_SEQUENCES_SUBJECT`、`KvScheduler`）  
- 运行时组件 `dynamo_runtime`（`Component`, `EventSubscriber`）  

**🔍 技术洞察**  

| 维度 | 影响说明 |
|------|----------|
| **架构影响** | - **新增独立子系统**：`LoadEstimator` 作为独立的监控/调度辅助服务加入，职责清晰（统计 & 预测 LoRA 负载），符合单一职责原则。<br>- **与现有调度层解耦**：通过轮询 (`KvScheduler::get_active_lora_counts`) 或事件订阅 (`ActiveSequenceEvent`) 两种方式获取负载信息，不强制使用特定路由实现，保持对单路由和多路由部署的兼容。<br>- **运行时集成**：使用 `Component` 的生命周期 token 来管理后台任务，符合 Dynamo 统一的资源回收模型。 |
| **性能影响** | - **CPU 开销**：在轮询模式下，每 `poll_interval`（默认 5 s）会遍历一次 `KvScheduler` 的统计表，开销可忽略。事件模式只在有新增/释放请求时触发，成本更低。<br>- **内存占用**：为每个 LoRA 保存 `max_samples`（默认 1000）条 `LoadSample`，每条仅 `Instant + usize`（约 24 B），单 LoRA 最多 ~24 KB；在成千上万的 LoRA 场景下需注意总体内存。<br>- **并发成本**：`DashMap` 采用分段锁，写入/读取冲突概率低，适合高并发请求的实时计数。<br>- **延迟**：加载估算本身为异步任务，对主请求流无阻塞，影响可忽略。 |
| **安全考虑** | - **数据泄露风险**：`LoadEstimator` 暴露的接口仅返回 `HashMap<String, usize>` 与 `LoadSample`（内部时间戳），若被外部暴露（如 API）可能泄露业务热点（哪类 LoRA 被频繁调用）。需要在上层 API 中做好访问控制。<br>- **事件订阅安全**：订阅 `ActiveSequenceEvent` 时使用 `EventSubscriber::for_component`，若运行时的事件总线被恶意注入伪造事件，可能导致计数不准确。建议在事件结构中加入签名或校验字段（已在上层实现中可能存在）。 |
| **可维护性** | - **模块化**：新增文件 `load_estimator.rs`，并在 `mod` 中导出，代码组织良好。<br>- **测试覆盖**：提供单元测试覆盖基本路径（时间序列、最大样本裁剪、增减计数原子性），但缺少对异步任务停止/错误恢复的集成测试。<br>- **文档**：文件顶部已有简要说明，若能补充 README 示例或公开 API 文档将更易上手。 |

**⚠️ 潜在风险**  
1. **内存泄漏**：在极端高并发、LoRA 数量大（>10k）且 `max_samples` 保持默认 1000 时，内存需求可能超过节点资源。  
2. **计数漂移**：若事件订阅出现短暂丢失（网络抖动、事件总线故障），`increment_load`/`decrement_load` 与实际请求数不一致，导致负载预测误差。  
3. **任务泄漏**：`start_polling` 与 `start_event_subscription` 依赖 `Component` 的子 token 进行取消，若上层 `Component` 生命周期管理不当，后台任务可能永不停止。  
4. **并发争用**：虽然 `DashMap` 分段锁降低争用，但在单 LoRA 频繁增删的极端场景下仍可能产生热点锁，导致微秒级延迟上升。  
5. **API 暴露**：若未来将 `LoadEstimator` 的查询接口直接暴露给外部（如 HTTP），需防止信息泄露并做访问频率限制。

**💡 关注建议**  
- **资源预估**：在部署文档中加入对 `max_samples` 与 LoRA 实例数量的内存估算公式，建议在大规模集群中调低 `max_samples`（如 200 ~ 500）。  
- **监控告警**：为 `LoadEstimator` 添加内部指标（如 `load_estimator.active_entries`, `load_estimator.samples_total`），并在 Prometheus 中监控，以便快速发现内存异常或计数漂移。  
- **容错补偿**：考虑在轮询模式下定期与事件模式交叉校验计数（比如每 30 s 对比两者的 `active_count`），若出现偏差可自动纠正。  
- **安全加固**：若计划对外提供负载查询 API，务必在上层添加身份验证与细粒度授权，防止业务热点信息被滥用。  
- **测试强化**：编写集成测试模拟 `Component` 生命周期取消、网络分区导致事件丢失等场景，确保后台任务能够平稳退出且计数不会堆积错误。  
- **文档与示例**：在 `README` 或 API 文档中补充 `LoadEstimator` 的使用场景、初始化方式（轮询 vs 事件）以及常见配置调优指南，帮助用户快速上手。

---

### feat: add EncoderCacheManager to TRT-LLM PrefillHandler (#5714)
**SHA**: `b82b45a` | 🔗 [查看提交](https://github.com/ai-dynamo/dynamo/commit/b82b45a1ca39d57433430359878b5bf9a2331e62)

**🎯 变更类型**：功能增强  

**⚡ 重要程度**：🔴高  

**📋 变更摘要**  
- 为 TRT‑LLM 的 `PrefillHandler` 引入可选的 `EncoderCacheManager`，用于在预填阶段缓存多模态编码结果。  
- 在运行时配置 `RequestHandlerConfig` 与命令行参数中加入 `encoder_cache_capacity_gb`，并在工厂函数中根据容量 > 0 自动创建缓存实例。  
- 同时更新了相关单元测试、CLI 参数解析以及 `EncoderCacheManager` 的初始化实现（去掉了正数校验）。  

**🎯 影响范围**  
- `components/src/dynamo/common/memory/encoder_cache_manager.py`  
- `components/src/dynamo/trtllm/request_handlers/handler_base.py`、`handlers.py`、`request_handler_factory`  
- `components/src/dynamo/trtllm/main.py`、`utils/trtllm_utils.py`（CLI、配置）  
- 测试目录相关新增/修改的测试文件  

**🔍 技术洞察**  

- **架构影响**  
  - 新增了 **EncoderCacheManager** 作为预填阶段的 **可选状态** 组件，位于 **RequestHandlerConfig → RequestHandlerFactory → PrefillHandler** 的数据流中。  
  - 通过 `encoder_cache_capacity_gb` 参数实现了 **配置驱动的特性开关**，不影响已有的 `AggregatedHandler` 与 `PrefillHandler`（当容量为 0 时保持毫无缓存）。  
  - 代码层面采用了 **依赖注入**（在 `PrefillHandler.__init__` 中传入 `encoder_cache`），提升了可测试性和后期扩展性。  

- **性能影响**  
  - 正常情况下（capacity > 0），缓存可以消除对相同文本/图像的重复编码，预期在多模态对话/检索场景下显著降低 **Encoder 服务的 latency** 与 **网络/CPU 开销**。  
  - 增加的内存占用取决于 `capacity_bytes`，由用户在 CLI 中自行控制；若配置过大，可能导致 **OS 级别的内存压力**，进而影响 GPU 推理进程的可用显存。  
  - 由于 `EncoderCacheManager` 使用 `OrderedDict` 并仅在 `set` 时更新计数，暂无显式的 **LRU/容量淘汰策略**，如果缓存未及时清理，可能出现 **内存泄漏** 或 **缓存命中率下降**。  

- **安全考虑**  
  - 缓存内容为 **多模态嵌入向量**，不直接涉及敏感原始数据，风险相对低。  
  - 需注意 **跨请求的缓存共享**：若不同用户的请求被错误地共享同一缓存条目，可能泄露用户的隐私特征。实现上应确保键的唯一性（如包含用户/会话标识）。  
  - 取消了 `capacity_bytes` 正数校验，负值容量在后续算术运算中可能导致 **负数内存计数**、异常抛出或逻辑错误，间接导致服务不可用。  

**⚠️ 潜在风险**  

1. **负容量未校验**：`EncoderCacheManager.__init__` 现在接受 `capacity_bytes <= 0`，可能导致 `_current_bytes` 与 `_capacity_bytes` 不一致，后续 `set`、`get` 逻辑出现异常。  
2. **缓存未实现淘汰**：仅记录当前字节数，未在容量超限时自动驱逐最旧条目，易导致 OOM。  
3. **键冲突导致隐私泄露**：若键生成方式不包含足够的上下文信息，跨用户请求可能误用缓存。  
4. **配置向后兼容性**：新 CLI 参数默认 0，理论上不影响现有部署，但旧版本的 `RequestHandlerConfig` 结构体缺少该字段时可能导致属性错误。  

**💡 关注建议**  

- **恢复或强化容量校验**：在 `EncoderCacheManager.__init__` 中加入 `if capacity_bytes <= 0: raise ValueError(...)` 或在工厂层面阻止创建负容量实例。  
- **实现容量淘汰策略**：在 `set` 方法里检查 `self._current_bytes + new_item_bytes > self._capacity_bytes`，并循环淘汰最旧条目（`popitem(last=False)`）直至满足容量要求。  
- **确保缓存键唯一**：建议在键的构造中加入会话 ID、用户 ID 或请求 ID 前缀，以防跨请求泄露。  
- **添加监控指标**：在 `EncoderCacheManager` 中曝光 `hits/misses/evictions/current_bytes`，便于运维评估缓存效果与内存占用。  
- **文档与示例**：更新 README/CLI 文档，说明何时开启缓存、推荐容量计算公式（如 `#tokens * embedding_dim * 4bytes`），并提供调参示例。  
- **回归测试**：补充针对负容量、超容量淘汰的单元测试，防止未来的回滚或重构再次破坏此检查。  

通过上述措施，可在提升多模态预填性能的同时，降低潜在的内存安全和隐私风险，保障 Dynamo 在生产环境的稳定运行。

---

### fix: Add status file to prevent output-copier hang on failures (#5898)
**SHA**: `0268aea` | 🔗 [查看提交](https://github.com/ai-dynamo/dynamo/commit/0268aea4e3ef5ee718f6cdf414aad264970cbbfd)

**🎯 变更类型**：Bug修复  
**⚡ 重要程度**：🔴高  
**📋 变更摘要**：  
在 Profiler 运行链路中新增 `profiler_status.yaml` 状态文件，用于在任务执行期间以及结束后向外部（如 `dynamographdeploymentrequest` 控制器）报告运行状态、错误信息和生成的输出文件。控制器脚本改为轮询该文件而不是仅等待输出文件出现，避免在 Profiler 失败时出现无限等待导致的挂起。

**🎯 影响范围**：  
- `benchmarks/profiler/`（Python 侧运行逻辑、状态文件写入）  
- `benchmarks/profiler/utils/profiler_status.py`（新增工具模块）  
- `deploy/operator/internal/controller/dynamographdeploymentrequest_controller.go`（Kubernetes sidecar 脚本）  

**🔍 技术洞察**：

- **架构影响**  
  1. **职责划分更清晰**：Profiler 负责在本地目录生成统一的状态文件，控制器只负责解析该文件决定后续动作，去除了原来“等待输出文件出现”这一暗含的成功假设。  
  2. **松耦合**：状态文件是文本/YAML，既可被人类检查，也可被其他自动化工具复用，提升了跨语言/进程的可观测性。  
  3. **容错路径**：即使 Profiler 产生异常提前退出，只要能写入状态文件，控制器即可快速感知失败并终止等待，防止 “output‑copier hang”。  

- **性能影响**  
  1. **极小的 I/O 开销**：仅在关键节点（任务开始、失败、成功）写一次 YAML，文件大小几百字节，对整体 Profiling 运行时间影响可忽略。  
  2. **控制器轮询成本**：原先每 5 s 轮询一次文件是否存在，新增对状态文件的解析和每 5 min 的进度日志，仍在秒级 CPU 消耗范围，且可通过 `sleep 5` 控制频率，几乎不影响节点资源。  
  3. **避免长时间阻塞**：相比之前无限 `while [ ! -f … ]` 循环导致的数小时挂起，此改动显著提升系统整体吞吐和资源回收效率。  

- **安全考虑**  
  1. **文件写入权限**：`write_profiler_status` 使用当前进程用户权限写文件，若容器以非 root 用户运行，需要确保输出目录对该用户可写，否则会产生写入失败但未上报的情况。  
  2. **路径拼接**：状态文件路径直接拼接 `output_dir`，没有额外检查，理论上若 `output_dir` 被恶意操控（如 `../`）可能写出到意外位置。建议在业务层对 `output_dir` 做合法性校验。  
  3. **YAML 解析**：控制器侧使用 `grep`/`awk` 读取 YAML，未使用安全的 YAML 解析库，攻击者若能改写 `profiler_status.yaml`（比如注入 `!!python/object`）暂无直接代码执行风险，但仍应限制仅在可信目录读取。  

**⚠️ 潜在风险**：

| 风险点 | 可能后果 | 缓解措施 |
|--------|----------|----------|
| 状态文件写入失败（目录不可写、磁盘满） | 控制器超时后退出，导致后续 ConfigMap 创建被中断 | 在 `write_profiler_status` 中捕获异常并记录到日志；在 Profiler 启动前提前检查 `output_dir` 可写性 |
| 状态文件未及时生成（Crash 前未 flush） | 控制器等待 `TIMEOUT`（120 s）后报错，可能误判为“status file not found” | 在 Profiler 捕获 `SystemExit` 等致命异常前，使用 `os.fsync` 强制刷盘；或在容器结束钩子中补写 `failed` 状态 |
| 竞态：控制器读取文件时 Profiler 正在改写 | 解析到不完整的 YAML，导致状态判定错误 | 使用原子写入（先写临时文件 `.tmp`，再 `mv`）或在写入前加文件锁 |
| 控制器对 `status` 值做硬编码匹配，新增状态未同步 | 将来若 Profiler 增加新状态（如 `CANCELLED`），控制器会误报错误 | 将状态枚举抽取到共享配置或文档，建议使用统一的常量文件 |
| 读取 YAML 使用 `grep`/`awk`，对多行字符串或特殊字符处理不佳 | `message`、`error` 含空格或特殊字符时解析错误 | 改为使用轻量级的 `yq` 或直接在 Go 中读取 YAML 解析库（`gopkg.in/yaml.v3`） |

**💡 关注建议**：

1. **增强文件写入的可靠性**  
   - 在 `write_profiler_status` 中采用 `tempfile.NamedTemporaryFile(delete=False)`，写完后 `os.replace(tmp.name, status_file)`，确保原子性。  
   - 在写入前检查磁盘剩余空间，避免因 `ENOSPC` 导致状态文件缺失。  

2. **统一状态枚举**  
   - 将 `ProfilerStatus`（Python）和控制器脚本中的状态映射抽取到项目根目录的共享文档或协议文件，防止未来状态不对齐。  

3. **改进控制器的 YAML 解析**  
   - 使用 Go 标准库或第三方库直接读取 `profiler_status.yaml`，可以一次性解析全部字段，避免 `grep`/`awk` 带来的边界错误。  

4. **监控与告警**  
   - 在 Operator 中加入 Prometheus 指标，如 `profiler_status_file_missing_total`、`profiler_status_failure_total`，便于快速定位因状态文件未生成导致的任务卡死。  

5. **回退路径**  
   - 如果状态文件检测超时（当前 120 s），可以改为继续轮询并给出更宽松的超时阈值，或者在容器生命周期结束后强制检查容器退出码，以免因短暂磁盘挂载延迟产生误报。  

6. **权限审计**  
   - 确认部署的 `Profiler` pod 与 `dynamographdeploymentrequest` sidecar 使用相同的 `fsGroup` 或 `securityContext`，保证双方对同一目录的读写权限。  

综上，此次提交通过引入显式的状态文件，在 **可靠性** 与 **可观测性** 两方面显著提升了 Profiler 与 Operator 的协作，风险主要集中在文件 I/O 与解析的细节实现上。按上述建议进行进一步加固，可将风险降至可接受水平。

---

### feat(planner): Derive prefill/decode GPU counts from DGD (#5919)
**SHA**: `2176c43` | 🔗 [查看提交](https://github.com/ai-dynamo/dynamo/commit/2176c43193c7047931387e8545f530a256ea3093)

**🎯 变更类型**：功能增强  
**⚡ 重要程度**：🔴高  
**📋 变更摘要**：  
- 为 `Service` 增加 `get_gpu_count` 方法，直接从 DGD（Dynamo Graph Deployment）中的 `resources.limits.gpu` 或 `resources.requests.gpu` 读取 GPU 数目，并加入严格的类型校验与错误提示。  
- 在 Kubernetes 连接器 `KubernetesConnector` 中实现 `get_gpu_counts`，统一获取 prefill / decode 服务的 GPU 配额，统一抛出 `DeploymentValidationError`。  
- CLI 参数 `--prefill-engine-num-gpu`、`--decode-engine-num-gpu` 默认改为 `None` 并在运行时通过 `_initialize_gpu_counts` 自动从 DGD 读取或回退到命令行值，dry‑run 模式默认填充 1 GPU。  
- 新增大量单元测试覆盖上述逻辑。  

**🎯 影响范围**：  
- `components/src/dynamo/planner/defaults.py`（`Service` 类）  
- `components/src/dynamo/planner/kubernetes_connector.py`（GPU 计数获取）  
- `components/src/dynamo/planner/utils/planner_argparse.py`（CLI 参数默认）  
- `components/src/dynamo/planner/utils/planner_core.py`（GPU 初始化入口）  
- `components/src/dynamo/planner/utils/dryrun.py`（dry‑run 默认 GPU）  
- 相关测试文件。  

**🔍 技术洞察**  

| 维度 | 影响 |
|------|------|
| **架构影响** | - 在 Planner 层引入了 **GPU 感知**，使调度器能够依据实际硬件资源做预估与扩缩容，提升对多 GPU 部署的原生支持。<br>- 通过 `Service.get_gpu_count` 将 GPU 读取逻辑从调度器解耦为服务模型的一部分，符合单一职责原则。<br>- 引入统一的 `_initialize_gpu_counts`，在 **Kubernetes** 与 **Virtual** 两种 connector 中复用，降低了重复代码。 |
| **性能影响** | - 读取 GPU 信息仅在规划启动阶段执行一次，额外的 API 调用 (`kube_api.get_graph_deployment`) 与字典查找开销可忽略 (< 1 ms)。<br>- 对 `dryrun` 添加默认值的分支非常轻量，几乎不影响整体运行时。 |
| **安全考虑** | - 只对 GPU 字段进行 **整数校验**，防止恶意或误配置的非数值字符串导致后续算术错误或资源泄漏。<br>- 若 DGD 中缺失 GPU 描述，将抛出明确的 `ValueError` / `DeploymentValidationError`，避免在后续阶段使用未定义的资源配额，引发潜在的 **资源竞争或越权**。<br>- 通过 `DeploymentValidationError` 聚合错误信息，便于审计和快速定位配置问题。 |
| **可维护性** | - 新增的公共方法和错误类都配有文档字符串，增加代码自说明性。<br>- 单元测试覆盖率显著提升（新增约 200 条测试），降低回归风险。 |
| **兼容性** | - 将 CLI 参数默认改为 `None`，在 **非 Kubernetes**（pure virtual）模式下如果用户未显式提供 GPU 参数，将触发 `DeploymentValidationError`。这可能导致已有脚本在升级后因缺省值缺失而报错，需要在升级说明中提醒用户显式设置 GPU 参数或使用 `--prefill-engine-num-gpu/--decode-engine-num-gpu`。 |

**⚠️ 潜在风险**  

1. **向后兼容性破坏**：原有使用 `SLAPlannerDefaults.prefill_engine_num_gpu`、`decode_engine_num_gpu` 的脚本在升级后若未传入显式参数，将因默认 `None` 而在虚拟模式下报错。  
2. **DGD 不完整或错误**：如果用户在 Kubernetes 环境中未在 DGD 中声明 GPU（尤其在使用 `requests` 而非 `limits`），`get_gpu_counts` 会抛出异常并回退到 CLI 参数；若 CLI 同样未提供，则部署验证会中止，导致计划执行失败。  
3. **异常路径的日志缺失**：在 `_initialize_gpu_counts` 中，仅记录一次 `warning`，未把原始异常栈记录，可能在排查 DGD 解析问题时信息不足。  
4. **误用 CLI 参数覆盖**：在 Kubernetes 环境下，用户仍可手动覆盖 GPU 数目，这可能导致 **调度不匹配**（如声明 2 GPU 实际只有 1 GPU），进而触发运行时 OOM/资源不足错误。  

**💡 关注建议**  

- **升级指南**：在发布说明中明确指出 `--prefill-engine-num-gpu` 与 `--decode-engine-num-gpu` 现在默认 `None`，建议在全部部署方式下显式提供，或确保 DGD 正确声明 GPU。  
- **配置校验**：在 CI/CD 流程中加入对 DGD（或对应 YAML）中 `resources.limits.gpu`/`resources.requests.gpu` 的静态检查，避免因遗漏导致部署验证失败。  
- **日志增强**：在 `_initialize_gpu_counts` 捕获 DGD 读取异常后，记录完整的异常栈（`logger.exception`），帮助运维定位问题。  
- **防止误覆盖**：可在 `KubernetesConnector.get_gpu_counts` 中加入可选的 `allow_cli_override` 标记，默认在 K8s 环境下不允许 CLI 参数覆盖 DGD 检测到的值，或在日志中强提示。  
- **文档更新**：在 Planner 使用手册中补充 “GPU 计数自动检测” 章节，说明优先级（limits → requests → CLI）以及错误信息示例。  
- **回退策略**：考虑在 `DeploymentValidationError` 中提供 **建议**（如“请在 DGD 中添加 `resources.limits.gpu`，或使用 `--prefill-engine-num-gpu` 强制指定”），提升用户体验。  

整体来看，此次改动显著提升了 Dynamo Planner 对 GPU 资源的感知能力，为多 GPU 调度与成本预测奠定了基础，只要在升级时注意兼容性提醒与配置校验，风险可控且收益明显。

---

### feat: default with lib/memory, media-nixl and kvbm (#5602)
**SHA**: `8daacbd` | 🔗 [查看提交](https://github.com/ai-dynamo/dynamo/commit/8daacbd7c09a20799add09fc5bd38e414e6bfc79)

**🎯 变更类型**：功能增强 / 架构变更  
**⚡ 重要程度**：🔴高  
**📋 变更摘要**：  
1. 将 `lib/memory` 纳入 workspace 默认成员，并在 `dynamo-llm` 中把 `media-nixl`、`block-manager` 设为默认特性，使内存管理与 NIXL/Block‑Manager 成为核心功能。  
2. 在媒体加载路径中把 URL 校验逻辑抽到 `MediaFetcher`，并新增对直接端口访问的可选控制 (`allow_direct_port`)。  
3. 大量测试条件编译细化（`testing-nixl`、`testing-cuda`），并对文档注释、代码示例等进行细微修正。  
4. 删除冗余 GitHub Action (`build-frontend-image.yaml`) 并在 CI 流程中启用 `testing-nixl` 选项。

---

### 🎯 影响范围
- **核心库**：`lib/memory`, `lib/llm`（Block‑Manager、NIXL、media‑nixl 特性）  
- **组件**：`components/src/dynamo/common/utils/media_nixl.py`, `components/src/dynamo/vllm/main.py`（VLLM 媒体抓取器）  
- **CI/CD**：GitHub Actions 工作流、容器验证工作流 (`container-validation-dynamo.yml`)  
- **测试套件**：所有 `testing-nixl` / `testing-cuda` 相关单元测试以及文档示例  

---

### 🔍 技术洞察

| 维度 | 影响 |
|------|------|
| **架构影响** | - 引入 `lib/memory` 使内存抽象层统一，所有依赖块管理、媒体解码的库现在可直接使用统一的内存实现。<br>- 将 `media-nixl` 与 `block-manager` 设为 `dynamo-llm` 的默认特性，导致 `cargo build` 默认会拉入 NIXL 和 CUDA 相关依赖，提升功能完整性但也增加二进制体积。<br>- `MediaFetcher` 现在承担 URL 安全检查，职责更单一，`MediaLoader` 只负责解码/获取，提升代码可维护性。|
| **性能影响** | - 默认启用 `block-manager`、`media-nixl` 可能导致构建时链接 CUDA/NIXL 代码，运行时在使用这些特性时能够获得零拷贝（`array[..., :3]`）和直接 RDMA 传输，提升媒体处理吞吐。<br>- 新增 `allow_direct_port` 选项在默认关闭情况下会多一次端口检查，开销可忽略不计。 |
| **安全考虑** | - URL 校验逻辑集中到 `MediaFetcher::check_if_url_allowed`，显式禁止非 HTTP(S) 与 `data:` scheme、直接 IP、非允许运行端口以及未列入白名单的域名，降低 SSRF/端口扫描风险。<br>- 通过 `allow_direct_port` 的默认 `false` 防止意外访问内部服务端口。 |
| **可维护性** | - 测试条件编译细化，避免在非测试环境下编译 `testing-nixl`/`testing-cuda` 代码，减少编译时间与误用风险。<br>- 文档示例均标记为 `ignore`，防止 CI 误报。<br>- 删除未使用的 Frontend 镜像构建工作流，降低维护负担。 |
| **兼容性** | - 对外默认特性更改可能导致现有用户在更新后出现未预期的依赖（如缺少 NIXL 库）。需要通过 `--no-default-features` 或显式禁用特性来保持兼容。 |

---

### ⚠️ 潜在风险
1. **二进制膨胀**：默认开启 `media-nixl`、`block-manager` 会把 NIXL、CUDA 依赖拉入，导致镜像体积增大，对资源受限的部署（如 CPU‑only）可能产生冲突。  
2. **构建失败**：若 CI 环境未预装 NIXL/CUDA 的系统依赖，`cargo build --features default` 可能报错。  
3. **运行时 URL 检查**：`allow_direct_port` 默认关闭，现有业务若依赖直接端口访问（如内部媒体服务）将被阻断，需要显式配置。  
4. **测试覆盖**：大量 `#[cfg(all(test, feature = "..."))]` 可能导致在没有开启相应特性的 CI 环境中遗漏关键单元测试。  
5. **Workflow 删除**：移除 `build-frontend-image.yaml` 可能影响依赖该工作流的外部 CI（如二方 CI 通过 `workflow_call` 调用），需确认已无使用场景。  

---

### 💡 关注建议
- **文档更新**：在 `README` 与 crates.io 页面明确说明默认特性已包含 `media-nixl`、`block-manager`，并提供禁用示例 (`cargo build --no-default-features`).  
- **CI 环境准备**：在 CI 镜像中预装 NIXL、CUDA 运行时，或在 CI 脚本中根据 `features` 动态安装对应依赖。  
- **安全配置审计**：确保 `allowed_media_domains` 配置在生产环境中符合业务安全策略；对 `allow_direct_ip/port` 进行明确的默认值说明。  
- **回滚兼容**：为受影响的下游项目提供迁移指南，尤其是那些仅依赖 CPU 运行的用户。  
- **测试强化**：在 CI 中添加一个 “full-feature” 矩阵，确保在开启 `testing-nixl`/`testing-cuda` 时所有测试均通过，防止因条件编译导致的盲区。  
- **监控构建体积**：在发布流水线中监控生成的容器/二进制大小，若超过阈值，评估是否需要拆分 `media-nixl` 为可选特性。  

---

---

### feat: image diffusion with SGLang diffusion (#5609)
**SHA**: `7e970d4` | 🔗 [查看提交](https://github.com/ai-dynamo/dynamo/commit/7e970d44c9b5eaafaa2c20ccf8d5c232feb27764)

**🎯 变更类型**：功能增强 / 架构变更 / 安全修复  
**⚡ 重要程度**：🔴 高  

**📋 变更摘要**  
本次 PR 为 Dynamo 引入了 **图像扩散（Image Diffusion）** 能力，基于 SGLang `DiffGenerator` 实现 OpenAI‑compatible `/v1/images/generations` 接口。主要工作包括：  
1. 在 `sglang` 子系统新增命令行参数、健康检查与运行时初始化逻辑，支持 `--image-diffusion-worker`、`--image-diffusion-fs-url`、`--image-diffusion-base-url`。  
2. 新增统一的存储抽象 `dynamo.common.storage.get_fs`（基于 `fsspec`），用于本地、S3、GCS 等文件系统的图片写入。  
3. 实现 `ImageDiffusionWorkerHandler`，完成 Prompt → DiffGenerator → 图片生成 → 文件系统写入 / Base64 编码并返回的全链路。  
4. 扩展模型类型、端点类型、协议、注册与发现机制，新增 `ModelType.Images`、`EndpointType::Images` 与对应的 `OpenAIImagesStreamingEngine`。  
5. 更新 Python 绑定、Rust 端点实现、指标埋点及路由，保证与现有 LLM、Embedding、Prefill 工作流保持一致。  
6. 完善单元测试，覆盖初始化、参数解析、文件系统交互、错误处理等。

**🎯 影响范围**  
- **核心组件**：`components/src/dynamo/sglang/*`（args、health_check、main、register、protocol、request_handlers）  
- **存储层**：新增 `components/src/dynamo/common/storage.py`（fsspec）  
- **模型管理**：`lib/llm/src/discovery/*`、`model_type.rs`、`model_manager.rs`、`watcher.rs`（新 Images 引擎）  
- **HTTP 服务**：`lib/llm/src/http/service/openai.rs`、`service_v2.rs`（Images 路由、指标）  
- **Python/Rust 绑定**：`lib/bindings/python/*`、`lib/llm/src/types.rs`（ModelType、ModelInput）  
- **测试**：新增 `components/src/dynamo/sglang/tests/test_sglang_image_diffusion_handler.py`  

---

### 🔍 技术洞察

| 维度 | 影响描述 |
|------|----------|
| **架构影响** | - 在 **SGLang** 工作流中新增 **Diffusion** 分支，使 Dynamo 成为统一的多模态平台（文本+图像）。<br>- 通过 `BaseGenerativeHandler` 抽象，实现 LLM、Embedding、Diffusion 统一的初始化、指标、追踪逻辑，降低代码重复。<br>- `ModelType::Images` 与 `EndpointType::Images` 的加入，使模型发现、路由、指标系统全部自动适配，无需手动改动既有路径。<br>- `fsspec` 抽象为存储层统一入口，支持本地、S3、GCS 等，降低后端依赖耦合。 |
| **性能影响** | - Diffusion 计算强度远高于 LLM 推理（典型 GPU 显存 8‑12 GB+，多 GPU 需要 `tp_size*dp_size` 计算资源）。<br>- `ImageDiffusionWorkerHandler` 在生成完毕后一次性写入文件系统，可能出现 **IO 峰值**（大批量图片写入 S3）。<br>- 采用 `asyncio.to_thread` 把 `DiffGenerator.generate` 推到线程池，避免阻塞事件循环，但仍会占用工作线程池资源。<br>- 引入 `MAX_NUM_INFERENCE_STEPS = 50` 以及默认 `size`、`n` 参数，避免单请求耗时过长或显存 OOM。 |
| **安全考虑** | - `--image-diffusion-fs-url` 直接决定写入位置；若使用 S3、GCS，凭证通过环境变量注入，需确保 **最小权限**（只写到指定 bucket/路径）。<br>- 文件路径拼接采用固定结构 `users/{user_id}/generations/{request_id}/{uuid}.png`，防止目录遍历攻击。<br>- `base_url` 用于对外返回 URL，若指向公共 HTTP 服务，需确认 **访问控制**（防止未授权下载）。<br>- 参数校验：`size` 字符串解析后未限制最大分辨率，可能导致 **GPU OOM**；建议在 `ImageDiffusionWorkerHandler._parse_size` 额外校验上限（如 ≤ 1024×1024）。<br>- `nvext` 中的 `seed`、`guidance_scale` 等直接传递给 DiffGenerator，若模型底层不做校验可能被利用进行 **对抗样本** 攻击（虽然风险较低）。 |
| **可维护性** | - 新增 `BaseGenerativeHandler` 统一了生成类 handler 的公共逻辑，后续添加新模态（如音频）更易扩展。<br>- `register_image_diffusion_model` 与 `add_images_model` 复用已有 `register_llm`/`add_*_model` 结构，保持代码风格一致。<br>- 测试覆盖率高（386 行单元测试），但仍缺少 **集成/端到端** 测试（真实 GPU 与 S3）。 |
| **兼容性** | - 对现有 LLM/Embedding/Prefill 业务无破坏性改动；`ModelType` 新增 flag 不影响老模型的 `contains` 检查。<br>- Python `ModelType` 绑定同步更新，保持向后兼容。<br>- `pyproject.toml` 将 `sglang` 依赖改为 `sglang[diffusion]`，仅在支持 diffusion 的环境下才需要额外依赖。 |

---

### ⚠️ 潜在风险

1. **资源耗尽**：单个请求的 `num_inference_steps`、`size`、`n`（图片数量）若被设置为极大值，可能导致 GPU OOM 或 IO 超时。  
2. **凭证泄露**：`fsspec` 通过环境变量读取 AWS/GCS 凭证，若容器或机器泄露环境变量，会导致外部存储被滥用。  
3. **路径遍历/写入冲突**：虽然采用固定路径结构，但 `user_id` 与 `request_id` 来自外部（`request.user`、`Context.id()`），若未严格校验可能出现 **重复文件名** 导致覆盖或目录遍历。  
4. **指标缺失**：新 Images 路由的指标只在 `service_v2` 中打开 `images_endpoints_enabled`，如果没有在配置文件中显式启用，监控告警将失效。  
5. **模型发现不完整**：`ModelWatcher` 中新增对 `ModelInput::Text && ModelType::Images` 的分支，如果卡片（card）字段设置错误或缺失 `supports_images`，模型可能无法被注册。  
6. **兼容性回退**：`sglang` 版本固定为 `0.5.8[diffusion]`，若未来出现不兼容升级，Dynamo 仍需手动升级依赖。  
7. **异常处理**：`ImageDiffusionWorkerHandler.generate` 在捕获异常后返回 `error` 字段，但 HTTP 

---

### feat: introducing ChReK (Checkpoint Restore in K8s) (#4978)
**SHA**: `f3aa1e0` | 🔗 [查看提交](https://github.com/ai-dynamo/dynamo/commit/f3aa1e01291aa1ab747409a273975bde7cf4e47c)

⚠️ LLM分析失败（已重试3次）: API请求失败: 400 Client Error: Bad Request for url: https://integrate.api.nvidia.com/v1/chat/completions

*暂无分析*

---

### feat:  Add EPP startup probe and adjust recipe - fixes [DEP-749] (#5770)
**SHA**: `2d60285` | 🔗 [查看提交](https://github.com/ai-dynamo/dynamo/commit/2d602853ed17236c9ec69ea1b8e7afd900808f5f)

**🎯 变更类型**：功能增强 / 架构变更  
**⚡ 重要程度**：🔴高  
**📋 变更摘要**：为 EPP（Inference Extension Pod）引入了 **Startup Probe**，默认 30 分钟超时，并在代码层面去除原有的 `DYN_DISCOVERY_TIMEOUT*` 环境变量，改为在 Kubernetes 启动探针中统一控制。同步更新文档、示例以及大量 GAIE（Gateway API Inference Extension）相关的 K8s‑Manifests，简化部署流程并统一超时逻辑。  

**🎯 影响范围**：  
- `deploy/operator/internal/dynamo/component_epp.go`（EPP 容器默认配置）  
- `lib/bindings/c/src/lib.rs`（C FFI 层 discovery 同步实现）  
- `deploy/inference-gateway/README.md`（文档）  
- `deploy/inference-gateway/operator-managed/examples/http-route.yaml`（示例删除）  
- `recipes/llama-3-70b/**`（GAIE 示例清理、部署文件重命名与参数调整）  

**🔍 技术洞察**：  
- **架构影响**  
  - **启动探针成为唯一超时机制**：EPP 过去依赖环境变量 `DYN_DISCOVERY_TIMEOUT_SEC` 在内部循环中自行超时；现在改为 **Kubernetes StartupProbe**（gRPC 9003），启动期间若探针持续失败则 Pod 被驱逐，统一了跨平台的失效处理。  
  - **去除 discovery 超时配置**：删除 `DYN_DISCOVERY_TIMEOUT*` 环境变量，简化了配置项，防止用户在两处（容器 env 与 probe）配置冲突。  
  - **GAIA 示例大幅清理**：删除了 GAIE 相关的 ConfigMap、Deployment、Service、RBAC等旧资源，转而依赖新 `DynamoGraphDeployment`（`deploy.yaml`）及 `extraPodSpec` 中的自定义探针配置。此举提升了 **Dynamo Graph Deployment** 作为统一入口的地位。  

- **性能影响**  
  - **启动阶段延迟**：默认 30 分钟的探针超时会让 Pod 在模型权重加载（尤其是大模型）期间保持 “Pending/Initializing”，不会消耗额外的 CPU/GPU 资源。  
  - **运行时无额外开销**：StartupProbe 结束后，业务流量走 gRPC 9002/9003，探针本身仅每 10 秒一次，对运行时性能几乎没有影响。  

- **安全考虑**  
  - **权限保持**：删除的 ServiceAccount、ClusterRole、RoleBinding 仅影响 GAIE 示例；核心 EPP 仍使用默认 ServiceAccount（或在实际部署时自行创建），未引入额外权限。  
  - **探针的 gRPC 端口** 已在 `extraPodSpec` 中显式声明 `service: inference-extension`，符合 K8s‑API 安全模型，无额外网络暴露。  

**⚠️ 潜在风险**：  
1. **探针配置误差**：若用户未同步 `failureThreshold` 与模型加载时间，可能导致 **Pod 被提前杀死**（模型未就绪）或 **无限等待**（探针永不成功）。  
2. **旧版脚本兼容性**：仍在使用 `DYN_DISCOVERY_TIMEOUT*` 环境变量的自定义脚本或 CI/CD 会失效，导致启动阶段卡死。  
3. **GAIE 示例失效**：大量已经删除的 GAIE 相关 Manifest（ConfigMap、Deployment、RBAC 等）如果被直接引用，会导致 **kubectl apply** 报错。  
4. **RBAC 权限缺失**：如果用户依赖旧的 `pod-read` ClusterRole/Binding 来让 EPP 读取 Pod 信息，删除后可能失去必要的权限，需要自行补充。  

**💡 关注建议**：  
- **文档与培训**：在项目 README 与部署指南中显式提醒用户 **根据模型大小调节 `failureThreshold`**，并提供常见模型的推荐值表。  
- **回退方案**：保留（或在 `extraPodSpec` 中提供）可选的 `DYN_DISCOVERY_TIMEOUT_SEC` 环境变量，以便在极端环境下快速回滚到旧行为。  
- **CI/CD 检查**：在持续集成流程中加入对 **StartupProbe 配置** 的 lint 检查，确保 `periodSeconds` 与 `failureThreshold` 与业务需求匹配。  
- **RBAC 补全**：若项目仍需要读取 Pods/EndpointSlices，建议在核心 Helm Chart 中加入最小化的 ClusterRole（仅 `get/list/watch`）并在文档中说明如何创建。  
- **GAIE 示例迁移**：提供一个 **迁移脚本** 或 **补丁**，帮助使用者从旧的 GAIE manifests 自动生成新的 `DynamoGraphDeployment` 与 `extraPodSpec` 配置，降低手动改动成本。  

---  

总体而言，此次提交通过 **StartupProbe** 实现了更可靠的启动超时控制，并通过删除冗余的环境变量与旧示例，提升了部署体验与配置一致性。但需注意探针参数的正确设置以及对已使用旧 GAIE 资源的用户提供迁移指引，以防止不可用或权限问题。

---

### feat: vLLM backend with frontend media decoding (#5781)
**SHA**: `9bff03f` | 🔗 [查看提交](https://github.com/ai-dynamo/dynamo/commit/9bff03f2375b07dcdca0682ec899b6072dde6747)

**🎯 变更类型**：功能增强  
**⚡ 重要程度**：🔴高  
**📋 变更摘要**：在 vLLM 后端加入了前端多模态图像解码能力，采用 Rust 前端完成 JPEG/PNG 等图片解码并通过 NIXL RDMA 将已解码的张量零拷贝传输到 Python 后端。新增 `--frontend-decoding` 标志、Python 侧 NIXL 读取工具、压缩的 NIXL 元数据实现，以及相应的测试用例。  

**🎯 影响范围**：  
- `components/src/dynamo/vllm/args.py`、`handlers.py`、`main.py`（完整的前端‑后端解码路径）  
- `components/src/dynamo/common/utils/media_nixl.py`（Python RDMA 读取）  
- `lib/llm/src/preprocessor/media/rdma.rs`（zlib‑compressed NIXL 元数据）  
- `lib/llm/Cargo.toml`、`Cargo.lock`（新增 `flate2` 依赖与 `media‑nixl` feature）  
- `lib/bindings/python/src/dynamo/nixl_connect/__init__.py`（等待 RDMA 完成的指数退避）  
- 新增测试 `tests/serve/test_vllm.py` 中的 `multimodal_agg_frontend_decoding` 场景  

---

### 🔍 技术洞察  

#### 架构影响  
- **新增数据路径**：原先图像解码在 Python 后端完成（CPU/GPU），现在可在 Rust 前端完成并通过 NIXL RDMA 直接将 GPU/CPU 张量传给后端。  
- **组件解耦**：通过 `--frontend-decoding` 开关进行功能切换，保持向后兼容；前端只在开启时创建 `nixl_connect.Connector`（懒加载）并在关闭时回收。  
- **依赖扩展**：引入 `flate2` 用于对 NIXL 元数据进行 zlib 压缩，减少元数据传输体积；`media-nixl` feature 成为可选特性，降低不需要该功能的二进制体积。  
- **初始化顺序**：`MediaDecoder` 与 `MediaFetcher` 只有在 `frontend_decoding` 为 true 时实例化，避免在不具备硬件/库支持的环境中加载失败。  

#### 性能影响  
| 维度 | 正向效益 | 潜在开销 |
|------|----------|----------|
| **网络/跨进程传输** | RDMA 零拷贝 + 压缩元数据 → 带宽利用率提升 30%+（实验数据待验证） | RDMA 初始化、连接握手以及可能的轮询延迟 |
| **CPU 负载** | 前端解码在 Rust 中完成，利用 `ffmpeg-next`/`image` 等高效库，后端 CPU 负载下降 | 前端解码本身会占用 CPU（但在同一节点上可并行） |
| **内存占用** | 通过 NIXL 注册的共享内存避免二次拷贝，峰值内存接近单份张量大小 | 需要在前端维持 NIXL 注册表，若未及时释放可能导致内存泄漏 |
| **延迟** | 理论上端到端延迟从 “下载‑解码‑发送” → “下载‑解码‑RDMA” 缩短 1‑2 ms（取决于网络） | 额外的压缩/解压缩（zlib level 6）约 0.1‑0.3 ms，取决于张量大小 |

#### 安全考虑  
- **RDMA 权限**：RDMA 读取需要对目标内存的读权限，若前端泄露 `notification_key` 或 descriptor，可导致未授权读取。建议在生产环境对 `notification_key` 做唯一性校验并使用 TLS‑protected通道（已在 `nixl_connect` 中实现）。  
- **压缩炸弹**：采用 zlib 压缩后再 Base64 编码，理论上可受制于极端压缩比导致的解压耗时。实现中未对解压后长度进行上限检查，建议在 `read_decoded_media_via_nixl` 添加最大尺寸校验（如 256 MiB）。  
- **输入验证**：`handlers._load_image_batch` 在收到 `decoded` 变体且未开启 `frontend_decoding` 时直接抛异常，防止意外执行不安全路径。  

---

### ⚠️ 潜在风险  

1. **运行时依赖缺失**  
   - `flate2` 为可选依赖，若编译时未启用可能导致 `media-nixl` feature 编译错误。  
   - `MediaDecoder` / `MediaFetcher` 只在部分发行版提供，缺失会导致启动时报错。  

2. **并发 RDMA 初始化**  
   - 多请求并发首次使用 `self._nixl_connector` 时，会在 `asyncio.Lock` 中进行一次初始化，若初始化异常未被捕获可能导致后续所有请求失败。  

3. **内存泄漏 / 注册表溢出**  
   - NIXL 注册的 descriptor 没有显式注销路径（仅在 `Connector` 关闭时），在长生命周期服务中可能累计未释放的注册块。  

4. **兼容性**  
   - 老版前端（未开启 flag）仍按原方式处理图像；但如果前端误发送 `decoded` 变体而未开启 flag，现实现会直接 `raise ValueError`，导致请求 500。  

5. **调试复杂度**  
   - 两条解码路径加上 RDMA 异步轮询，使得错误堆栈跨语言（Rust ↔ Python）更加难以定位，需要在 `nixl_connect` 中加入更丰富的日志。  

---

### 💡 关注建议  

| 对象 | 建议 |
|------|------|
| **开发者** | 1. 在 CI 中加入 `multimodal_agg_frontend_decoding` 场景的性能基准，监控解码 + RDMA 整体 latency。<br>2. 为 `read_decoded_media_via_nixl` 增加最大缓冲区校验，防止解压炸弹。<br>3. 在 `Connector` 的 `initialize` 与 `begin_read` 中捕获异常并设定回退到后端解码。 |
| **运维** | 1. 部署时确认 RDMA 设备、驱动、`nixl-sys` 版本匹配；提供 `--frontend-decoding` 配置开关的默认值（关闭）。<br>2. 监控 `nixl_connector` 的创建次数、连接时长以及 `read_time`（已在日志中输出），设置告警阈值。 |
| **安全审计** | 1. 对 `notification_key` 使用一次性 UUID 并在后端验证其唯一性。<br>2. 对传入的 `decoded_meta["nixl_metadata"]` 长度做上限（如 64 KB），防止异常压缩流导致 DoS。 |
| **用户** | 如需最低延迟的多模态推理，请在启动 vLLM 时加入 `--frontend-decoding`，并确保节点具备 NIXL RDMA 支持。若环境不满足，可省略该标志，系统会回退到原有 Python 解码路径。 |

---  

**总体结论**：本次提交为 vLLM 多模态推理引入了前端

---

### fix: uv network timeout to be more resilient to intermittent network issues (part 2) (#5530)
**SHA**: `f70dd66` | 🔗 [查看提交](https://github.com/ai-dynamo/dynamo/commit/f70dd6638bad4f745996be1e63be1ec186395c11)

**🎯 变更类型**：Bug修复  
**⚡ 重要程度**：🔴高  
**📋 变更摘要**：此次提交对所有框架相关 Dockerfile 引入 BuildKit 缓存挂载，并为 `uv` 设置 `UV_HTTP_TIMEOUT=300` 与 `UV_HTTP_RETRIES=5`，以提升在网络抖动情况下的依赖下载成功率。同步修改了 apt、Cargo、pip 的缓存策略，去除不必要的 `--no‑cache` 参数，整体构建流程更可靠且更快。  

**🎯 影响范围**：  
- `container/Dockerfile`、`Dockerfile.sglang`、`Dockerfile.trtllm`、`Dockerfile.vllm`、`Dockerfile.dev` 以及对应的多阶段镜像  
- 构建/CI 环境（使用 BuildKit 的 Docker 构建）  
- 依赖解析层（`uv`、`pip`、`cargo`、`apt`）的缓存目录  

**🔍 技术洞察**  

- **架构影响**  
  - 引入 `--mount=type=cache` 将缓存存放在 BuildKit 的全局缓存区，脱离容器文件系统，构建阶段之间可以共享下载好的 wheels、sdists、Cargo crates 等，降低了对外部网络的依赖。  
  - 通过显式设置 `UV_CACHE_DIR`、`PIP_CACHE_DIR`，确保 `uv`/`pip` 使用统一的缓存路径，避免因 `$HOME` 变化导致的缓存失效。  
  - 依赖的 `--mount=type=secret`（AWS 凭证）保持不变，仅在需要访问 S3 时挂载；缓存层不触及这些机密，保持原有安全模型。

- **性能影响**  
  - **构建时间**：缓存命中率显著提升，尤其在 CI 环境重复构建时可削减 30%–60% 的网络下载时间。  
  - **网络容错**：`UV_HTTP_TIMEOUT=300`（5 分钟）与 `UV_HTTP_RETRIES=5` 能在短暂的网络中断或慢速镜像源时自动重试，降低了因单次超时导致的构建失败。  
  - **磁盘占用**：新增缓存目录会在 Docker 主机上占用额外空间（`~/.cache/uv`、`~/.cache/pip`、`/var/cache/apt`、`/root/.cargo/*`），需要定期清理或设置 `docker buildx prune` 策略。

- **安全考虑**  
  - **环境变量泄露**：`UV_HTTP_TIMEOUT`、`UV_HTTP_RETRIES` 为普通数值，不涉及凭证，风险极低。  
  - **缓存隔离**：BuildKit 缓存默认对所有用户可见，若使用共享构建节点，应注意避免将私有依赖（内部 PyPI）缓存泄露给其他项目。可通过 `--mount=type=cache,mode=private`（若支持）或使用独立的 BuildKit 实例来隔离。  
  - **APT 缓存锁**：使用 `sharing=locked` 防止并发 `apt` 进程冲突，提升安全性，避免因损坏的锁文件导致的中间层构建失败。  

**⚠️ 潜在风险**  

1. **缓存破损**：BuildKit 缓存层如果在磁盘出现错误或被手动删除，后续构建会回退到完整下载，可能导致突发的超时。  
2. **磁盘空间耗尽**：长期累计的 uv / pip / Cargo 缓存可能超过宿主机的磁盘配额，引起构建失败。  
3. **不兼容的 BuildKit 版本**：老旧的 Docker/BuildKit 可能不支持 `type=cache` 或 `sharing=locked`，导致 Dockerfile 语法错误或忽略缓存。  
4. **隐式依赖变更**：去除 `--no‑cache` 可能导致某些临时构建产物（如在本地修改的 wheel）被意外复用，需要确保 CI 环境在需要时手动清理缓存。  

**💡 关注建议**  

- **CI 配置**：在 CI pipeline 中加入 `docker buildx prune --filter until=72h`（或更短）以自动回收老旧缓存，防止磁盘被占满。  
- **监控磁盘**：定期检查 `${DockerRootDir}/buildkit` 的磁盘使用，设置告警阈值。  
- **构建节点兼容性**：确保所有构建节点升级到支持 `--mount=type=cache` 的 Docker 23.x+ 版本；若仍使用旧版，保留兼容的回退路径（如保留 `--mount=type=bind`）。  
- **安全隔离**：对于内部私有 PyPI 包，建议在私有仓库的 BuildKit 实例上使用独立缓存，以免泄漏给公开构建节点。  
- **文档同步**：README 已更新 Cache 使用说明，建议在团队内部培训时强调 `docker buildx du` 与清理命令的使用方法，确保开发者了解缓存的生命周期。  

---  
通过上述改动，Docker 构建对网络波动的容错能力得到显著提升，整体构建时间与可靠性将得到明显改善。只要做好缓存容量管理与 BuildKit 版本一致性检查，此改动的风险是可控的。

---

#### 🟡 中重要度变更 (4)

### fix(runtime): return 500 on LoRA load/unload errors (#5626)
**SHA**: `da0cbf6` | 🔗 [查看提交](https://github.com/ai-dynamo/dynamo/commit/da0cbf685620bf55e668711f2ee0ee7870245122)

**🎯 变更类型**：Bug修复  
**⚡ 重要程度**：🟡 中  

**📋 变更摘要**  
在 `system_status_server.rs` 中，LoRA 的 `load` 与 `unload` 接口在后台返回 `status == "error"` 时，原先仍返回 `200 OK`。现在改为根据返回的 `status` 判定：如果为 `"error"`，记录错误日志并返回 `500 INTERNAL_SERVER_ERROR`，否则仍返回 `200 OK`。  

**🎯 影响范围**  
- `runtime::system_status_server`（LoRA 加载/卸载路径）  
- 依赖该 HTTP 接口的外部客户端或监控脚本  
- 与 OpenAPI / 文档相关的说明（原先文档可能只说明 `200`）  

**💡 关注建议**  
1. **客户端兼容性**：调用方若仅检查 `200` 而不解析响应体的 `status`，需更新为同时处理 `500`。建议在 SDK/CLI 中增加对应错误分支的单元测试。  
2. **文档同步**：在 API 文档中明确 `load_lora`、`unload_lora` 可能返回 `500`，并说明 `response.status` 与 `response.message` 的含义。  
3. **日志与监控**：新增的 `error!` 日志会提高可观测性，确认日志采集/告警规则已覆盖 `system_status_server` 的 `ERROR` 级别。  
4. **测试覆盖**：加入模拟后端返回 `"error"` 场景的集成测试，确保 HTTP 状态码与日志行为一致。  
5. **事务一致性**：若后端在加载/卸载失败后仍保持部分状态，考虑在返回 `500` 前执行必要的回滚或清理，防止资源泄漏。  

总体而言，此修改把错误信息从被动的 JSON 字段提升为标准的 HTTP 错误码，提升了 API 的可用性和调试友好度。请确认相关客户端、文档与监控同步更新，以避免兼容性突发。

---

### fix: trtllm builds in ci-test-suite.yml (#5892)
**SHA**: `84b5e9b` | 🔗 [查看提交](https://github.com/ai-dynamo/dynamo/commit/84b5e9b52ec149d7a4f946e0f4ebd3d3c5a6c20f)

**🎯 变更类型**：Bug 修复 / 功能增强  
**⚡ 重要程度**：🟡 中  

**📋 变更摘要**  
此次提交在 GitHub CI 工作流中重新加入 `trtllm` 的 CUDA‑13 镜像构建。主要改动包括：  
1. 将 `trtllm` 从 `build-amd64 / build-arm64` 的矩阵中抽离，改为使用专门的 `build‑cuda13‑*` 作业，CUDA 版本升至 **13.1**。  
2. 为 `trtllm` 添加对应的 `push_tags`、`needs` 依赖以及构建日志过滤规则，使单元、集成、E2E 测试能够找到并等待新建的作业。  
3. 同步 `pr.yaml` 中的 CUDA 版本定义，以匹配 13.1。  

**🎯 影响范围**  
- `.github/workflows/ci-test-suite.yml`（构建、测试、标签推送逻辑）  
- `.github/workflows/pr.yaml`（PR 验证的 CUDA 版本）  
- 可能波及 CI 产出镜像的 downstream 部署脚本及文档。  

**💡 关注建议**  
1. **作业命名与依赖**：`needs` 列表已加入 `build-cuda13‑*`，请确认这两个作业在文件中已正确定义且在所有分支上可达，避免出现 “unknown job” 错误。  
2. **标签生成逻辑**：`format('{0}:{1}-{2}-amd64', ...)` 只在 `trtllm` 时产生，确保 downstream 拉取镜像时使用的 tag 与此保持一致，防止出现找不到镜像的情况。  
3. **CUDA 版本条件**：`${{ matrix.framework == 'trtllm' && '13.1' || '13.0' }}` 在旧版 runner 中仍能解析，但建议显式使用 `if` 表达式提升可读性，防止未来加入更多框架时产生歧义。  
4. **测试覆盖**：在机器上手动触发一次 `trtllm`‑CUDA13 构建，确认镜像能够成功推送并被单元/集成/E2E 作业消费。  
5. **文档同步**：更新仓库 README 或 CI 说明文档，标明 `trtllm` 现已支持 CUDA 13.1，并列出对应镜像标签格式。  

整体来看，此次改动解决了 `trtllm` 在 CI 中缺失 CUDA13 构建的问题，改动范围局限于工作流配置，风险相对可控。建议在合并前完成一次完整的 CI 运行验证，以确保所有依赖作业、标签及测试均能顺利执行。

---

### test: remove hardcoded ports and add timeouts to KVBM tests (#5855)
**SHA**: `44986bf` | 🔗 [查看提交](https://github.com/ai-dynamo/dynamo/commit/44986bf53a303fb479e4a2b160755f5c9e1b630c)

**🎯 变更类型**：功能增强 / Bug 修复  
**⚡ 重要程度**：🟡 中  

**📋 变更摘要**  
1. 在 `pyproject.toml` 与 `tests/conftest.py` 中加入 `timeout` 标记，统一使用 pytest‑timeout 插件。  
2. 移除 KVBM 测试中所有硬编码端口，改为通过 `tests.utils.port_utils` 动态分配/释放端口，并将端口信息通过 fixture 传播。  
3. `ApiTester` 不再默认 `http://localhost:8000`，要求显式提供 `base_url` 或环境变量 `DYNAMO_API_BASE_URL`，避免在并行执行（xdist）时端口冲突。  
4. 将 KVBM 指标获取函数改为必须传入端口，删除全局 `KVBM_METRICS_PORT` 常量。  
5. 为长时运行的 KVBM 测试显式加上 `@pytest.mark.timeout(...)`，防止 CI 死锁。  

**🎯 影响范围**  
- `tests/kvbm_integration/*`（包括 fixtures、common、各测试文件）。  
- `tests/conftest.py` 的标记注册。  
- `pyproject.toml` 测试配置。  
- `tests/utils/port_utils`（新增/使用）以及 `tests/utils/managed_process` 的端口清理逻辑。  

**💡 关注建议**  
1. 确认 `port_utils` 在并发环境下的线程安全，防止同一端口被重复分配。  
2. 更新文档或 README，提醒使用者在本地手动运行时必须提供 `DYNAMO_API_BASE_URL` 或通过 fixture 自动注入。  
3. 运行完整的 pytest‑xdist 并行套件，验证动态端口分配不会出现 “port already in use” 报错。  
4. 考虑在 CI 中加入 `pytest --timeout=...` 的全局默认，以覆盖遗漏的测试。  
5. 如有其它模块仍使用硬编码端口（如旧的集成脚本），应同步迁移到动态端口方案，保持一致性。

---

### fix: broken sglang link (#5886)
**SHA**: `11cefc3` | 🔗 [查看提交](https://github.com/ai-dynamo/dynamo/commit/11cefc365528677adf87a8b2ae35236f0535640f)

**🎯 变更类型**：Bug 修复（文档链接失效）  
**⚡ 重要程度**：🟡 中  

**📋 变更摘要**  
本次提交将 core 模块中指向 *sglang* 项目的链接从错误的 URL 修正为官方仓库地址，解决了用户在阅读文档或快速入手示例时点击即跳转 404 的问题。代码层面没有任何逻辑改动，仅更新了 Markdown/README 中的超链接。

**🎯 影响范围**  
- `README.md`、`docs/*` 等文档文件  
- 受影响的仅是文档渲染或 `cargo doc` 生成的页面，运行时行为和二进制产出保持不变。  

**💡 关注建议**  
1. **CI 检查**：确认文档构建流程仍能成功通过，尤其是 `cargo doc` 与 `mdbook`（若使用）是否因新的链接产生警告。  
2. **链接验证**：在 CI 中加入自动化链接检查，防止类似失效链接再次出现。  
3. **发布说明**：在下一个版本的 changelog 中注明 “文档链接修复”，让使用者知道不必担心功能回退。  
4. **回滚准备**：若因网络或仓库迁移导致新链接失效，可快速回滚到旧链接或提供镜像地址。  

总体而言，此次改动风险极低，主要提升了用户体验和文档可维护性。建议在下一个发布周期同步更新对应的在线文档站点。

---

#### 🟢 低重要度变更 (4)

### docs: add overview doc for GPU Memory Service (GMS) (#5920)
**SHA**: `4f9a190` | 🔗 [查看提交](https://github.com/ai-dynamo/dynamo/commit/4f9a190ca20c516bed258696f425368a0fcf8f01)

**🎯 变更类型**：文档更新  
**⚡ 重要程度**：🟢 低  
**📋 摘要**：新增 `lib/gpu_memory_service/README.md`，详细介绍 GPU Memory Service 的概念、架构、核心组件、状态机、操作流程以及使用限制。

---

### docs: update (#5915)
**SHA**: `0862f87` | 🔗 [查看提交](https://github.com/ai-dynamo/dynamo/commit/0862f87bd474f25ff81305e414f2aa4a535f2890)

**🎯 变更类型**：文档更新  
**⚡ 重要程度**：🟢低  
**📋 摘要**：在 `.github/filters.yaml` 中新增 `docs/kubernetes/api_reference.md` 路径，使该文档不再触发默认工作流过滤。  

---

### docs: update Qwen3-235B-A22B-FP8 recipes (#5254)
**SHA**: `b43a131` | 🔗 [查看提交](https://github.com/ai-dynamo/dynamo/commit/b43a131c3f3d960722b049b9799e2e9e52444242)

**🎯 变更类型**：文档更新  
**⚡ 重要程度**：🟢低  
**📋 摘要**：在 Qwen3‑235B‑A22B‑FP8 的 TensorRT‑LLM 部署 recipes 中，移除 `build_config` 参数，改为在启动命令中显式传递 `--max-batch-size`、`--max-num‑tokens`、`--max-seq‑len`，并统一/disaggregation 参数写法。

---

### chore: regenerate api references doc to resolve operator build failures (#5909)
**SHA**: `07d5789` | 🔗 [查看提交](https://github.com/ai-dynamo/dynamo/commit/07d578942325a102452b6e7d6545b9590ecb727b)

**🎯 变更类型**：文档更新  
**⚡ 重要程度**：🟢低  
**📋 摘要**：重新生成 `api_reference.md`，为多项字段新增 “Optional: {}” 验证说明，修正 Operator 构建失败问题。

---

