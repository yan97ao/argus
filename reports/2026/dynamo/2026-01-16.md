# 每日更新报告（2026-01-16）

## ai-dynamo/dynamo

| 提交时间 | 作者 | 提交信息 |
|----------|------|----------|
| 2026-01-16 16:36:10 | KrishnanPrash | feat: SGLang aggregated multimodal support (#5450) |
| 2026-01-16 14:29:32 | Yan Ru Pei | fix: include missing reqs in benchmark (#5477) |
| 2026-01-16 14:25:17 | Yan Ru Pei | chore: make precentile plots in router benchmark (#5476) |
| 2026-01-16 09:45:26 | Pavithra Vijayakrishnan | build: Install NVIDIA packages based on CUDA version (#5461) |
| 2026-01-16 04:34:40 | GuanLuo | fix: [vLLM multimodel] launch image loading in parallel (#5444) |
| 2026-01-16 03:59:33 | Biswa Panda | feat: [router] serve worker KV query over dynamo endpoint  instead of nats (#5451) |
| 2026-01-16 03:54:34 | Neelay Shah | fix: apply labels to Kubernetes Service objects in operator (#5459) |
| 2026-01-16 03:31:39 | dagil-nvidia | fix: consolidate return statement in get_engine_runtime_config (#5442) |
| 2026-01-16 03:01:12 | dagil-nvidia | fix: use correct argument name max_isl in synthesize_requests (#5441) |
| 2026-01-16 00:19:09 | jh-nv | fix: rename test file to skip vllm specific tests (#5438) |

### 📊 统计摘要
> 本日共 10 个提交 | 🔴高 3 | 🟡中 5 | 🟢低 2
## 📋 目录

- [ai-dynamo/dynamo](#ai-dynamo-dynamo)
  - [📊 统计摘要](#-统计摘要)
  - [🔴 高重要度变更 (3)](#-🔴-高重要度变更-3)
    - [feat: SGLang aggregated multimodal support (#5450)](#ddee21c)
    - [fix: [vLLM multimodel] launch image loading in parallel (...](#0b7e127)
    - [feat: [router] serve worker KV query over dynamo endpoint...](#7ebd5f8)
  - [🟡 中重要度变更 (5)](#-🟡-中重要度变更-5)
    - [fix: include missing reqs in benchmark (#5477)](#abe9d12)
    - [fix: apply labels to Kubernetes Service objects in operat...](#283b20c)
    - [fix: consolidate return statement in get_engine_runtime_c...](#d154562)
    - [fix: use correct argument name max_isl in synthesize_requ...](#ef09f71)
    - [fix: rename test file to skip vllm specific tests (#5438)](#d02619b)
  - [🟢 低重要度变更 (2)](#-🟢-低重要度变更-2)
    - [chore: make precentile plots in router benchmark (#5476)](#d83ab66)
    - [build: Install NVIDIA packages based on CUDA version (#5461)](#34c4882)
#### 🔴 高重要度变更 (3)

### feat: SGLang aggregated multimodal support (#5450)
**SHA**: `ddee21c` | 🔗 [查看提交](https://github.com/ai-dynamo/dynamo/commit/ddee21cbe1e28522297171e6f40f4d4b695d1d86)

**🎯 变更类型**：功能增强  
**⚡ 重要程度**：🔴高  
**📋 变更摘要**：在 SGLang 后端的 `DecodeWorkerHandler` 中新增对多模态（图像 URL）请求的解析，将 `image_url` 列表提取为 `image_data` 并透传给 SGLang 引擎，实现 **EPD（Simple Aggregated）** 模式的单进程多模态推理。文档、启动脚本以及测试套件同步更新以覆盖该模式。  

**🎯 影响范围**：  
- `components/src/dynamo/sglang/request_handlers/llm/decode_handler.py`（核心请求处理）  
- `docs/multimodal/sglang.md`（使用文档）  
- `examples/backends/sglang/launch/`（新增/重命名脚本 `agg.sh`、`multimodal_epd.sh`）  
- `tests/serve/test_sglang.py`（新增 EPD 与聚合多模态测试用例）  

**🔍 技术洞察**  

- **架构影响**  
  - **引入 EPD（Simple Aggregated）模式**：原先只支持 **E/PD** 与 **E/P/D**（需独立编码 worker），现在在单个 DecodeWorker 中完成文本解码、视觉编码与前缀填充，实现 *内部* 视觉编码。  
  - **请求路径变化**：`request["multi_modal_data"]["image_url"]` → `image_data` → 直接交给 SGLang 引擎的 `mm_data_processor`，去除跨 worker 的 RDMA 传输，简化了部署拓扑。  
  - **向后兼容**：仅在 `multi_modal_data` 存在且包含 `image_url` 时才注入 `image_data`，不影响纯文本请求。  

- **性能影响**  
  - **正面**：消除跨进程/跨机器的 Tensor RDMA 传输开销，网络延迟及序列化成本降低，尤其在单机单卡（GPU 0）场景下可获得显著的端到端加速。  
  - **负面**：视觉模型的加载与推理与语言模型共享同一进程/同一 GPU 资源，可能导致 **GPU 竞争**，在高并发或大图情况下出现 **吞吐下降** 与 **延迟抖动**。  
  - **资源占用**：图片下载、解码、预处理会占用额外的 CPU、内存与网络 IO，需要监控峰值，建议在生产环境中设定 **图片大小上限** 与 **并发下载数**。  

- **安全考虑**  
  - **外部 URL 下载**：引入对任意 HTTP(s) URL 的拉取，潜在 **SSRF**、**恶意文件**（如 payload 注入、内存炸弹）风险。  
  - **建议**：  
    - 对 URL 进行白名单/域名校验（或在内部网络开启白名单）。  
    - 限制下载超时、最大响应体大小（例如 5 MiB）。  
    - 对下载内容进行 MIME 类型检查，仅接受图片格式（jpeg/png/webp）。  
    - 在异常捕获中返回友好错误，避免堆栈泄露。  

**⚠️ 潜在风险**  
1. **GPU 资源争用**：在 EPD 模式下，单进程同时承担视觉编码与语言解码，可能导致 GPU OOM 或因显存碎片化降低性能。  
2. **网络依赖不稳定**：图片 URL 拉取失败会导致整个请求失败，影响服务可用性。  
3. **向后兼容性**：如果其它后端（如 vLLM、VLLM）未实现 `image_data` 参数，调用统一的 `async_generate` 可能抛出未定义参数错误。  
4. **错误处理缺失**：当前代码仅在 `isinstance(item, dict) and "Url" in item` 时取值，未捕获不规范字段或下载异常，可能导致隐式 `None` 传入，引擎内部错误。  

**💡 关注建议**  
- **实现层面**  
  - 在 `decode_handler` 中加入 **异常捕获** 与**日志**，显示下载/解析失败的具体原因。  
  - 为 `image_data` 添加 **参数校验**（非空、合法 URL），并在 `engine.async_generate` 前做 **提前返回**（如返回 400 Bad Request）。  
  - 考虑在配置项中提供 **`max_image_size`、`download_timeout`、`allowed_domains`** 等可调参数。  

- **运维层面**  
  - 监控 **GPU 显存使用率** 与 **CPU 网络 I/O**，在高并发场景下预警。  
  - 为 EPD 模式准备 **GPU 分区/资源配额**（如使用 CUDA 多进程或 MPS），防止单进程独占导致其他服务被挤压。  
  - 在生产部署文档中标明 **EPD 适用于低并发、单机部署** 场景，若业务对吞吐量有更高要求仍建议使用 **E/PD** 或 **E/P/D**。  

- **安全层面**  
  - 在入口层（如 HTTP API 网关）对 `image_url` 做 **白名单** 与 **大小限制** 检查。  
  - 通过 **容器网络策略** 限制后端对外部网络的访问，仅放通可信图片仓库。  

通过上述措施，可充分利用新增的 **聚合多模态** 能力，同时降低因资源竞争和外部依赖带来的风险，实现更稳定、安全的 Dynamo‑SGLang 多模态服务。

---

### fix: [vLLM multimodel] launch image loading in parallel (#5444)
**SHA**: `0b7e127` | 🔗 [查看提交](https://github.com/ai-dynamo/dynamo/commit/0b7e12715d39eaf154b32ce28d0aab89d1ac6e41)

**🎯 变更类型**：功能增强 / 性能优化  
**⚡ 重要程度**：🔴高  
**📋 变更摘要**：在 `vllm` 多模态处理器中新增 `_load_image_batch` 异步批量加载函数，使用 `asyncio.gather` 并行下载图片并统一报告异常；原来的逐条 `await` 循环被替换为一次性并行调度，从而显著降低多图请求的响应延迟。  

**🎯 影响范围**：  
- `components/src/dynamo/vllm/handlers.py`（图像加载与多模态数据抽取）  
- 依赖 `ImageLoader` 的所有 `vLLM` 多模态推理路径  
- 相关单元测试与集成测试（涉及图片 URL 处理的用例）  

**🔍 技术洞察**  

- **架构影响**  
  - 将图片加载抽象为独立的内部异步方法，提升代码可读性与可复用性。  
  - 通过 `asyncio.gather(..., return_exceptions=True)` 实现并行调度，使图片下载不再阻塞后续处理，符合微服务式的“任务分离”思路。  
  - 异常聚合逻辑改变了错误向上传递的方式：现在会在批次结束后统一抛出聚合异常，而不是在第一条失败时立即中止，这可能影响上层对错误的快速定位。  

- **性能影响**  
  - **延迟**：并行 I/O 可将 N 张图片的下载时间从≈ Σ t_i 降至 ≈ max (t_i)（受网络带宽与并发限制），对多图请求（如 4‑8 张）预期降幅在 2‑5 倍左右。  
  - **资源占用**：并发下载会瞬间打开多个网络连接并在内存中保持未压缩的图像数据，若批次规模过大或单张图片体积大，可能导致 CPU、带宽或内存峰值上升。  
  - **吞吐**：在高并发请求场景下，整体系统吞吐有望提升，但需关注共享 `ImageLoader` 的缓存命中率和后端存储压力。  

- **安全考虑**  
  - 加载路径仍然依赖 `ImageLoader` 对 URL 的校验与缓存机制，未引入新的安全漏洞。  
  - 并行请求可能放大对外部 URL 的访问频率，需防止 **SSRF**、**恶意域名** 或 **大文件下载** 攻击；建议在 `ImageLoader` 层继续执行域名白名单、文件大小上限、速率限制等防护。  
  - 异常聚合后抛出统一 `Exception`，若未对异常类型进行细分，可能在日志审计时失去部分堆栈信息，需确保 `collective_exceptions` 中保留完整错误描述。  

**⚠️ 潜在风险**  

1. **内存峰值**：大量并行加载大图片可能触发 OOM，尤其在 GPU‑bound 推理节点上。  
2. **异常处理变更**：上层可能依赖单张图片加载失败立即抛异常的行为，改为批次结束后统一抛异常后，需要确认调用方的错误恢复逻辑是否兼容。  
3. **并发限制缺失**：当前实现对并发数量没有上限，若一次请求包含数十张图片，可能对网络或后端存储造成突发压垮。  
4. **日志噪声**：`logger.debug` 只截取 URL 前 80 字符，若 URL 长度接近 80 仍可能泄露敏感路径；在生产环境建议使用脱敏或哈希后打印。  

**💡 关注建议**  

- **引入并发上限**：在 `_load_image_batch` 外层或 `ImageLoader` 中使用 `asyncio.Semaphore` 限制并发下载（如 4‑8 并发），兼顾性能与资源安全。  
- **内存与大小防护**：在 `ImageLoader` 前检查图片的 Content‑Length，超过阈值直接拒绝或分块下载。  
- **异常细化**：考虑将聚合异常包装为自定义 `BatchImageLoadError`，并在 `collective_exceptions` 中保留每张图片的原始异常类型，以便上层做更细粒度的容错。  
- **监控与告警**：在关键指标（并发下载数、平均下载时延、失败率、内存占用）上添加 Prometheus/StatsD 监控，及时捕获异常峰值。  
- **回归测试**：补充以下测试场景：  
  1. 多图成功并行加载，验证返回顺序与输入对应。  
  2. 部分图像下载失败，确保聚合异常包含所有错误信息且成功图像仍被返回。  
  3. 大批量（>10）图像请求的内存占用与响应时延。  
- **文档更新**：在 `handlers.py` 或项目文档中说明“并行图片加载已默认启用，推荐在高并发环境下使用并发上限”。  

通过上述措施，可在保持新功能带来显著性能提升的同时，降低资源超载和错误传播的风险，提升系统的鲁棒性与可运维性。

---

### feat: [router] serve worker KV query over dynamo endpoint  instead of nats (#5451)
**SHA**: `7ebd5f8` | 🔗 [查看提交](https://github.com/ai-dynamo/dynamo/commit/7ebd5f8266ccf091641148ba87e49da794a13dda)

**🎯 变更类型**：功能增强  
**⚡ 重要程度**：🔴高  
**📋 变更摘要**：将原先通过 NATS 实现的 Worker KV Indexer 查询路径迁移到 Dynamo 的请求平面（endpoint）上，新增错误统一处理（`MaybeError`），并在 Router 与 Worker 之间使用统一的 `PushRouter` 进行请求/响应。实现了端点注册、错误包装、以及相应的测试用例。  

**🎯 影响范围**：  
- `kv_router`（publisher、subscriber、worker_query、indexer）  
- `kv_router::worker_query` 中的请求路由逻辑  
- 相关示例脚本 `examples/backends/vllm/launch/agg_router_replicas.sh`（演示新端点使用）  

**🔍 技术洞察**  

- **架构影响**  
  - **从 NATS → 请求平面端点**：原先的 `worker_kv_indexer_query` 通过 NATS 主题进行 request/reply，现改为在 Runtime 中注册 `worker_kv_indexer_query` endpoint，由 `PushRouter` 按 `RoundRobin` 方式调度。  
  - **统一错误模型**：实现 `MaybeError` trait，使 `WorkerKvQueryResponse::Error(String)` 能够在协议层统一转化为 `anyhow::Error`，降低了各层手动错误包装的重复代码。  
  - **解耦组件**：Router 不再依赖 NATS 子系统来查询本地 KV 索引，使用 Runtime 的“请求平面”可以让该功能在不同 transport（如 gRPC、HTTP）上更容易迁移。  

- **性能影响**  
  - **降低网络跳数**：NATS 需要额外的 publish/subscribe 过程以及主题匹配，改为直接点对点的 endpoint 调用可以减少一次消息路由，理论上降低 10‑30% 的延迟。  
  - **序列化开销相近**：仍然使用 JSON (`serde_json`) 编码，序列化成本未变。  
  - **并发调度**：`PushRouter` 采用 `RoundRobin`，在多 worker 场景下能够更均匀地分配查询请求，改善热点 worker 的压力。  

- **安全考虑**  
  - **传输层安全**：请求平面端点目前仍走内部 Runtime 通道，未加入额外的身份认证或加密。若在跨机器部署且开启外部访问，需要在 Runtime 配置层面补充 TLS/鉴权。  
  - **错误信息泄露**：`WorkerKvQueryResponse::Error(String)` 直接将内部错误字符串返回给 Router，若错误信息包含敏感上下文，可能被上层日志泄露。建议在生产环境对错误信息做脱敏或统一错误码包装。  

**⚠️ 潜在风险**  

1. **兼容性**  
   - 老版 Worker（仍使用 NATS 主题）将在新 Router 上无法响应查询，导致 “Worker not reachable” 错误。部署升级需同步更新所有 Worker。  

2. **端点命名冲突**  
   - `WORKER_KV_INDEXER_QUERY_ENDPOINT` 常量值为 `"worker_kv_indexer_query"`，若用户自行注册了同名端点可能产生覆盖或意外路由。  

3. **错误处理路径**  
   - `WorkerKvQueryResponse::Error` 通过 `MaybeError` 转成 `anyhow::Error`，但在 `subscriber::recover_from_worker` 中仅 `anyhow::bail!`，会将错误传播为 Router 的失败路径，可能触发重试/回退逻辑。若错误是不可恢复的（例如序列化失败），频繁重试会造成资源浪费。  

4. **回退逻辑**  
   - `calculate_backoff_ms` 仍保留，用于 NATS 错误的指数退避。迁移后若 endpoint 暂时不可用，仍可能触发该退避，但代码未显式调用。需要确认在失败后仍会触发退避机制。  

**💡 关注建议**  

- **升级指南**：在发布此功能的同时提供清晰的滚动升级文档，确保所有 Worker 在应用新版本时已注册 `worker_kv_indexer_query` endpoint。  
- **安全加固**：如果部署跨网络边界，建议在 Runtime 层开启 TLS 并在 endpoint 上配置基于 token/mtls 的鉴权，防止未授权查询本地 KV。  
- **错误脱敏**：在 `WorkerKvQueryResponse::Error` 生成处（`WorkerKvQueryEngine::generate`）对错误信息进行统一格式化，只返回错误码或通用描述，防止内部实现细节泄露。  
- **监控 & 告警**：新增 Prometheus 指标（如 `kvrouter_worker_query_failure_total`）来监控 endpoint 查询错误率，并与原有 NATS 监控保持对齐，以便快速定位迁移后可能出现的异常。  
- **回退兼容**：保留一个隐藏的 NATS‑based查询实现（可通过环境变量开启），在出现不可预期的 endpoint 故障时自动切回，以提升系统的容错性。  
- **负载测试**：在多 worker 大规模（>100）场景下进行基准测试，比较 NATS 与 endpoint 两种实现的延迟、吞吐和 CPU/内存占用，确保新实现满足实际业务需求。  

---  

此次改动在架构清晰度、查询延迟和可扩展性方面提供了显著提升，但也引入了端点注册和错误统一处理的新风险。建议在正式发布前完成兼容性验证、异常监控布控以及安全加固，以确保平滑迁移。

---

#### 🟡 中重要度变更 (5)

### fix: include missing reqs in benchmark (#5477)
**SHA**: `abe9d12` | 🔗 [查看提交](https://github.com/ai-dynamo/dynamo/commit/abe9d127dfd416154787c640c338eb2ced249351)

**🎯 变更类型**：Bug 修复  
**⚡ 重要程度**：🟡 中  

**📋 变更摘要**  
此次提交在 `benchmarks/pyproject.toml` 中补全了基准测试所需的依赖，新增了 `aiperf`（指定 commit）、`matplotlib`、`numpy` 三个库，并保持了已有的 `networkx`、`pandas`、`pydantic`、`tabulate` 等依赖。目的是解决运行基准脚本时因缺失包导致的 import 错误，使 CI 与本地 benchmark 能顺利执行。

**🎯 影响范围**  
- `benchmarks` 目录下的所有基准测试脚本（尤其是涉及性能度量和绘图的部分）  
- 依赖解析阶段：`pip install -e .[bench]` 或 `poetry install` 时会拉取额外的 `aiperf`、`matplotlib`、`numpy`，可能会触发编译（尤其是 `numpy`）  
- CI/CD 环境：需要保证构建镜像中已包含相应的编译工具链（如 `gcc`, `gfortran`）以编译 `numpy`  

**💡 关注建议**  
1. **CI 镜像检查**：确认 CI 使用的基础镜像已装好 `build-essential`、`python-dev` 等编译依赖，防止 `numpy` 编译超时或失败。  
2. **锁定版本**：`aiperf` 通过 commit 引用可以保证一致性，但 `matplotlib`、`numpy` 未指定版本，建议在 `pyproject.toml` 中加上上游兼容的版本范围，以避免未来的破坏性升级。  
3. **文档同步**：在 `README` 或 benchmark 说明文档中标明 `bench` 可选依赖，提醒用户执行 `pip install -e .[bench]` 或 `poetry install --extras bench`。  
4. **本地验证**：在多个平台（Linux/macOS/Windows）跑一遍 `benchmarks/run.py`，确保新增依赖不会产生跨平台问题。  

此改动主要影响基准测试环境，对业务代码本身没有直接影响，但需留意依赖的编译成本和文档同步，以保持开发者体验一致。

---

### fix: apply labels to Kubernetes Service objects in operator (#5459)
**SHA**: `283b20c` | 🔗 [查看提交](https://github.com/ai-dynamo/dynamo/commit/283b20c9619fdc492d94bd0ec8d67691c7a96c95)

**🎯 变更类型**：Bug 修复  
**⚡ 重要程度**：🟡 中  
**📋 变更摘要**：在 `GenerateComponentService` 中改进 Service 标签的生成逻辑。原先仅在启用 K8s Discovery 时硬写两条标签，导致用户在 `Component.Labels` 中声明的标签被丢弃。现在先复制用户标签，再在需要时追加（或覆盖）Discovery 相关标签，使两者能够共存且 Discovery 标签拥有最高优先级。  

**🎯 影响范围**：  
- `deploy/operator/internal/dynamo/graph.go`（Service 对象的 `ObjectMeta.Labels`）  
- 依赖该函数的 Operator 部署流程和任何基于 Service 标签做过滤或监控的外部工具。  

**💡 关注建议**  
1. **兼容性**：Discovery 标签会覆盖同名的用户标签，这与旧实现保持一致；但其他用户标签现在会被保留下来，需确认下游系统（如 Prometheus 自动发现、Ingress 控制器）不会因意外标签冲突产生副作用。  
2. **空指针安全**：`component.Labels` 为 `nil` 时遍历仍安全，代码已使用 `make` 初始化本地 `labels`，无需额外检查。  
3. **测试**：添加单元测试验证以下场景：  
   - `component.Labels` 为空/不存在，仅产生 Discovery 标签。  
   - 同时存在用户标签且 Discovery 未开启，仅保留用户标签。  
   - 两者都开启，确保 Discovery 标签覆盖同名用户标签。  
4. **文档/注释**：建议在函数前补充说明“用户标签 → Discovery 标签（覆盖）”，帮助后续维护者快速理解标签合并策略。  
5. **性能**：标签合并仅在内存中一次拷贝，开销可忽略。  

总体而言，此次修改恢复了用户对 Service 的自定义标签能力，行为更符合期望，影响局限于 Service 生成阶段，风险可通过以上测试与文档补充得到有效控制。

---

### fix: consolidate return statement in get_engine_runtime_config (#5442)
**SHA**: `d154562` | 🔗 [查看提交](https://github.com/ai-dynamo/dynamo/commit/d1545621102a10ae70cd45ec9e644544858e59b1)

**🎯 变更类型**：Bug修复  
**⚡ 重要程度**：🟡 中  
**📋 变更摘要**：在 `components/src/dynamo/trtllm/main.py` 中合并了 `get_engine_runtime_config` 的返回路径，去掉了异常分支中重复的 `return runtime_config`，并把注释改为 “保持默认/None 值”。  

**🎯 影响范围**：  
- `dynamo` 的 TRT‑LLM 组件（runtime 配置获取逻辑）  
- 依赖 `get_engine_runtime_config` 的异步工作流 `worker`  

**💡 关注建议**：  
1. **语义保持**：合并返回后，函数在正常和异常路径都会在最后统一返回同一个 `runtime_config`，行为保持不变；但务必确认异常捕获块里不再需要提前返回，以免遗漏对日志的后续处理。  
2. **日志完整性**：异常分支仍然记录错误日志，建议在 `except` 中添加 `logging.debug` 打印堆栈信息，以便排查隐藏的 TensorRT‑LLM 调用失败。  
3. **单元测试**：新增或更新一个异常路径的单元测试，验证当引擎返回错误时 `runtime_config` 仍然保持默认/None，且函数不抛异常。  
4. **代码风格**：合并返回提升了可读性，但请保持函数体的缩进一致，避免出现多余空行导致 pylint/flake8 警告。  

总体来看，此次修改只是简化返回逻辑，对功能没有实质影响，风险极低。若项目中已有对 `get_engine_runtime_config` 的异常返回进行特殊处理，请检查并相应更新调用方的容错逻辑。

---

### fix: use correct argument name max_isl in synthesize_requests (#5441)
**SHA**: `ef09f71` | 🔗 [查看提交](https://github.com/ai-dynamo/dynamo/commit/ef09f718e3bd455afc8435630ca48d6c99b0422c)

**🎯 变更类型**：Bug 修复  
**⚡ 重要程度**：🟡 中  

**📋 变更摘要**  
在 `benchmarks/prefix_data_generator/example.py` 中，调用 `synthesizer.synthesize_requests` 时错误地使用了参数名 `input_len_filter`。本次提交将其改为正确的 `max_isl`（max input sequence length），并顺手修正了注释中的拼写错误 “outpputs → outputs”。  

**🎯 影响范围**  
- `benchmarks/prefix_data_generator` 示例脚本  
- 与该脚本相关的文档或 README（若引用了旧参数名）  
- 受影响的 CI/示例测试（如果有）  

**💡 关注建议**  
1. **验证 API 一致性**：确认 `Synthesizer.synthesize_requests` 的签名中仍然使用 `max_isl`，并在项目文档中统一说明该参数含义。  
2. **更新示例及文档**：搜索仓库中所有对 `input_len_filter` 的引用，及时替换为 `max_isl`，避免用户在使用示例时出现参数未识别的错误。  
3. **回归测试**：运行或新增针对 `synthesize_requests` 的单元测试，确保在传入 `max_isl` 时行为如预期，且旧参数名不再被接受。  
4. **保持注释准确**：已修正的拼写错误虽小，但提升了代码可读性，建议在其他示例或注释中同样进行细致检查。  

总体而言，此次修改仅影响示例层面的调用，不会对核心库逻辑产生副作用。完成上述检查后即可安全合并。

---

### fix: rename test file to skip vllm specific tests (#5438)
**SHA**: `d02619b` | 🔗 [查看提交](https://github.com/ai-dynamo/dynamo/commit/d02619b8ee6079c7468936999176dae2076f327c)

**🎯 变更类型**：Bug 修复  
**⚡ 重要程度**：🟡 中  

**📋 变更摘要**  
本次提交将 `components/src/dynamo/vllm/tests/test_vllm_chat_message_utils.py` 重命名，以使其在默认测试流水线中被跳过。目的是避免在不具备 VLLM 环境的 CI 中因缺少依赖或资源消耗过大而导致测试失败。

**🎯 影响范围**  
- **vllm 组件**：仅涉及 `components/src/dynamo/vllm` 目录下的单元测试文件。  
- **测试框架**：改动可能影响 pytest/ nose 的文件匹配规则或 CI 中的自定义跳过逻辑。  
- **文档/CI 配置**：若有硬编码的测试路径或过滤规则，需要同步更新。

**💡 关注建议**  
1. **确认跳过逻辑**：检查项目的 `pytest.ini`、`cargo test` 脚本或 GitHub Actions 配置，确保新的文件名（如加上 `.skip` 前缀或后缀）能够被正确识别为需跳过的测试。  
2. **避免导入错误**：如果其他测试或示例代码显式引用了该文件的模块路径，需同步更新 import 语句或删除不再需要的引用。  
3. **保持版本一致性**：在发布新版本前，确保发布说明中提及该测试已被标记为可选，以免用户误以为功能有变动。  
4. **后续清理计划**：建议在 VLLM 依赖完整的环境准备好后，重新启用或迁移该测试，以防止功能回归未被检测。  

总体来看，此次改动对生产代码无任何影响，仅限于测试层面，风险极低。只要 CI 配置同步更新即可保持测试稳定性。

---

#### 🟢 低重要度变更 (2)

### chore: make precentile plots in router benchmark (#5476)
**SHA**: `d83ab66` | 🔗 [查看提交](https://github.com/ai-dynamo/dynamo/commit/d83ab662f7403da290c1d9cb855c77c20a468e3b)

**🎯 变更类型**：代码重构  
**⚡ 重要程度**：🟢低  
**📋 摘要**：在 `router` 基准测试中添加对 TTFT 与 ITL 的 p25、p50、p75 分位数统计与可视化，并支持数据抽样策略 `shuffle`。删除旧的平均值聚合逻辑，更新 JSON 输出结构。

---

### build: Install NVIDIA packages based on CUDA version (#5461)
**SHA**: `34c4882` | 🔗 [查看提交](https://github.com/ai-dynamo/dynamo/commit/34c4882d8c774205255ae3264d1e3dc66791b2cb)

**🎯 变更类型**：代码重构（Dockerfile 构建脚本）  
**⚡ 重要程度**：🟢低  
**📋 摘要**：在 `Dockerfile.sglang` 中根据检测到的 CUDA 主版本号动态安装对应的 NVIDIA 包，新增对 CUDA 13 的 CuDNN、NCCl、cublas 等依赖的支持。

---

