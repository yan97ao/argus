# 每日更新报告（2026-02-05）

## ai-dynamo/dynamo

| 提交时间 | 作者 | 提交信息 |
|----------|------|----------|
| 2026-02-05 17:22:56 | Ran Rubin | ci: Using Dynamo Builder (#5914) |
| 2026-02-05 16:26:25 | Yan Ru Pei | fix: ignore benchmarks pytest for now (#5983) |
| 2026-02-05 13:50:30 | Yan Ru Pei | fix: e2e aiperf profiling on NAT dataset (#5990) |
| 2026-02-05 09:08:54 | Ryan McCormick | fix: Add mpi arg to all srun commands (#5948) |
| 2026-02-05 08:43:27 | Yan Ru Pei | fix: update aiperf version (#5982) |
| 2026-02-05 08:21:31 | hhzhang16 | feat: remove default model name in Profiler; validate for one of served model name and model path in Profiler (#5950) |
| 2026-02-05 07:22:06 | Kyle McGill | fix: fix for how vllm disseminates cached requests to kvbm (#5851) |
| 2026-02-05 06:34:41 | Qi Wang | feat: use encoder cache in TRT-LLM EPD workflow (#5780) |
| 2026-02-05 06:24:29 | Thomas Montfort | feat: read prefill/decode worker counts from DGD status (#5934) |
| 2026-02-05 05:08:18 | dagil-nvidia | docs: fix markdown formatting in Distributed_Inference README (#5947) |
| 2026-02-05 05:07:21 | KrishnanPrash | fix: treat `--tool-call-parser` and `--dyn-tool-call-parser` independently for SGLang (#5849) |
| 2026-02-05 04:57:05 | Yan Ru Pei | chore: use aiperf utils in prefix synthesizer (#5906) |
| 2026-02-05 04:43:21 | Qi Wang | feat: introduce cuda_ipc for TRT-LLM PrefillHandler (#5773) |
| 2026-02-05 04:40:27 | Janelle Cai | test: indexer and full router benchmarks (#5784) |
| 2026-02-05 04:39:56 | Jacky | chore: Increase E2E 1-GPU Test Timeout (#5888) |
| 2026-02-05 04:22:18 | Julien Mancuso | fix: correct restart state for parallel restarts (#5949) |
| 2026-02-05 03:51:43 | Hongkuan Zhou | feat: Add per-worker Prometheus metrics for router load monitoring (#5842) |
| 2026-02-05 03:31:17 | Indrajit Bhosale | fix: Wrap default_multimodal_input_loader in asyncio.to_thread (#5945) |
| 2026-02-05 03:22:21 | jh-nv | fix: update disagg tracing screenshot and description (#5956) |
| 2026-02-05 02:38:00 | Yan Ru Pei | chore: linux gate lib/memory (#5942) |
| 2026-02-05 02:35:41 | Ayush Agarwal | feat: basic vllm omni pipeline support (#5608) |
| 2026-02-05 02:22:45 | jthomson04 | feat: Various Mocker Perf improvements + fixes (#5808) |
| 2026-02-05 01:50:41 | Keiven C | chore: rename terminate_existing to terminate_all_matching_processes (#5923) |
| 2026-02-05 01:39:48 | dagil-nvidia | docs: update support matrix with backend dependencies for Dynamo 0.9.0 + 1.0.0 (#5932) |
| 2026-02-05 01:14:27 | Nate Mailhot | feat: sccache metrics (#5177) |
| 2026-02-05 01:01:21 | Janelle Cai | fix: fuse unfold streams to prevent panics from poll after termination (#5872) |

### 📊 统计摘要
> 本日共 26 个提交 | 🔴高 15 | 🟡中 7 | 🟢低 4
## 📋 目录

- [ai-dynamo/dynamo](#ai-dynamo-dynamo)
  - [📊 统计摘要](#-统计摘要)
  - [🔴 高重要度变更 (15)](#-🔴-高重要度变更-15)
    - [fix: ignore benchmarks pytest for now (#5983)](#50e1778)
    - [fix: e2e aiperf profiling on NAT dataset (#5990)](#88efa73)
    - [feat: remove default model name in Profiler; validate for...](#7e4bc71)
    - [fix: fix for how vllm disseminates cached requests to kvb...](#3a2885c)
    - [feat: use encoder cache in TRT-LLM EPD workflow (#5780)](#a78a426)
    - [feat: read prefill/decode worker counts from DGD status (...](#b12e671)
    - [fix: treat `--tool-call-parser` and `--dyn-tool-call-pars...](#cd3f9bb)
    - [feat: introduce cuda_ipc for TRT-LLM PrefillHandler (#5773)](#6cb76b9)
    - [test: indexer and full router benchmarks (#5784)](#039d35f)
    - [fix: correct restart state for parallel restarts (#5949)](#94d82a4)
    - [feat: Add per-worker Prometheus metrics for router load m...](#0c0336e)
    - [feat: basic vllm omni pipeline support (#5608)](#76e0e20)
    - [feat: Various Mocker Perf improvements + fixes (#5808)](#d22ca52)
    - [feat: sccache metrics (#5177)](#04ec58c)
    - [fix: fuse unfold streams to prevent panics from poll afte...](#7beb5f1)
  - [🟡 中重要度变更 (7)](#-🟡-中重要度变更-7)
    - [ci: Using Dynamo Builder (#5914)](#6ac17b9)
    - [fix: Add mpi arg to all srun commands (#5948)](#910d74f)
    - [fix: update aiperf version (#5982)](#16956ac)
    - [chore: use aiperf utils in prefix synthesizer (#5906)](#4fcee92)
    - [fix: Wrap default_multimodal_input_loader in asyncio.to_t...](#eff08ae)
    - [fix: update disagg tracing screenshot and description (#5...](#f3bea5d)
    - [chore: rename terminate_existing to terminate_all_matchin...](#e55ebec)
  - [🟢 低重要度变更 (4)](#-🟢-低重要度变更-4)
    - [docs: fix markdown formatting in Distributed_Inference RE...](#ef29294)
    - [chore: Increase E2E 1-GPU Test Timeout (#5888)](#051f18a)
    - [chore: linux gate lib/memory (#5942)](#67df006)
    - [docs: update support matrix with backend dependencies for...](#4d9e64a)
#### 🔴 高重要度变更 (15)

### fix: ignore benchmarks pytest for now (#5983)
**SHA**: `50e1778` | 🔗 [查看提交](https://github.com/ai-dynamo/dynamo/commit/50e17783d95ac8982503d9ae3ba61f4bdbde19dd)

**🎯 变更类型**：Bug修复 / 测试维护  
**⚡ 重要程度**：🔴高  
**📋 变换摘要**：本次提交在 `benchmarks/prefix_data_generator/tests` 目录下新增 `conftest.py` 用于屏蔽该目录的 pytest 收集，避免缺失依赖导致 CI 失败；同时对 `mock_server.py` 做轻量格式化改动；新增 `test_roundtrip_hashes.py` 用于验证 `aiperf` 中 `PromptGenerator` 与 `RollingHasher` 的哈希往返一致性；最后将 `aiperf` 依赖锁定至更新的提交 SHA。目标是让主测试套件能够平稳运行，并在未来提供对哈希一致性的回归检测。  

**🎯 影响范围**：  
- `benchmarks/prefix_data_generator/tests`（测试收集逻辑）  
- `benchmarks/prefix_data_generator/tests/mock_server.py`（轻微代码格式）  
- `benchmarks/prefix_data_generator/tests/test_roundtrip_hashes.py`（新增完整回归测试）  
- `container/deps/requirements.txt`（依赖版本）  

**🔍 技术洞察**  

- **架构影响**：  
  - 仅涉及测试层面的改动，不触及核心库或运行时架构。  
  - `conftest.py` 通过 `collect_ignore` 阻止 PyTest 自动加载该目录的测试，使 CI 只运行与主代码库兼容的测试。  
  - 新增的回归测试验证了 **PromptGenerator → Tokenizer → RollingHasher** 链路的哈希一致性，为后续对 `aiperf` 的功能迭代提供安全网。  

- **性能影响**：  
  - `conftest.py` 能显著缩短 CI 时的测试收集阶段（原先因缺少依赖而卡在收集），间接提升整体流水线速度。  
  - 新增的 `test_roundtrip_hashes.py` 在本地或 CI 环境会下载并处理约 100 条 Mooncake trace，可能会在资源受限的机器上稍增执行时长（约 30‑60 s），但对生产代码运行无影响。  

- **安全考虑**：  
  - 新增测试会从外部 URL（GitHub）下载原始数据文件，属于 **网络 I/O**，在受限网络或安全审计严格的环境中可能被拦截或触发安全警报。  
  - 依赖升级至新的 `aiperf` commit，需确认该提交未引入新的安全漏洞或后门。  

**⚠️ 潜在风险**  

1. **网络依赖**：CI 运行时如果无法访问 `https://raw.githubusercontent.com/kvcache-ai/Mooncake/...`，测试将失效并导致 CI 失败。  
2. **外部数据一致性**：Mooncake trace 文件随时间可能变更，导致测试结果不稳定；建议固定版本或缓存至内部镜像。  
3. **依赖回退**：将 `aiperf` 锁定到新的 commit，若该 commit 与现有代码产生不兼容（API 改动、序列化格式变化），可能在未运行完整测试前导致运行时错误。  
4. **误忽略**：`collect_ignore` 只针对当前目录，若未来在同目录下新增其他需要执行的测试，可能被误屏蔽。  

**💡 关注建议**  

- **CI 配置**：在 CI 环境显式加入网络访问或使用缓存代理，以保证 `test_roundtrip_hashes.py` 能可靠下载 Mooncake trace。若网络不稳定，可考虑将前 100 行 trace 预先打包进仓库或内部对象存储。  
- **依赖审计**：在合并前运行 `pip-audit` 或类似工具检查新锁定的 `aiperf` commit 是否存在已知安全 CVE。  
- **测试策略**：将 `test_roundtrip_hashes.py` 标记为 `slow` 或 `network` 类别，允许在快速 CI 中跳过，仅在 nightly/回归流水线中执行。  
- **文档更新**：在项目 README 或 CONTRIBUTING 中记录 “benchmark tests are ignored by default” 以及如何手动启用它们的步骤，避免新贡献者误认为这些目录缺少测试。  
- **未来扩展**：若需要在 CI 中运行 benchmark 测试，建议在 `benchmarks/prefix_data_generator` 目录下提供可选的依赖安装脚本（如 `requirements-bench.txt`），并在 `tox`/`github actions` 中使用矩阵作业区分普通单元测试与 benchmark 测试。

---

### fix: e2e aiperf profiling on NAT dataset (#5990)
**SHA**: `88efa73` | 🔗 [查看提交](https://github.com/ai-dynamo/dynamo/commit/88efa735a5470229f8175ec8d3e55d7eb83edd86)

**🎯 变更类型**：Bug修复 / 功能增强  
**⚡ 重要程度**：🔴 高  

**📋 变更摘要**  
1. 修正了 NAT 数据集在 e2e aiperf 端到端 profiling 时的错误，主要通过改写 `benchmarks/nat_trace/convert.py`：  
   - 采用 `RollingHasher` 代替旧的 `texts_to_hashes`，并在一次遍历中同时返回 hash IDs 与原始 token 长度。  
   - 默认块大小从 128 改为 64，以匹配后端期望的块大小。  
   - 新增 `--delay` 参数，用于在同一会话的后续 LLM 调用之间插入模拟延迟（ms），并在生成 mooncake 数据时写入 `delay` 字段。  
2. 引入 **router benchmark** 相关公共工具 (`benchmarks/router/common.py`) 与 **mock server** (`benchmarks/router/mock_server.py`) 以便本地调试、观察请求时序与延迟。  
3. 新增 **并发多会话基准**脚本 `benchmarks/router/agent_benchmark.py`，支持 `--concurrency`、`--delay`、`--block-size` 等自定义。  
4. 重构 `prefix_ratio_benchmark.py` 与 `real_data_benchmark.py`，统一使用公共 CLI 参数、日志设施与 aiperf 公共 flag，默认块大小同步至 64（前缀路由）/512（Mooncake）。  
5. 依赖版本更新：aiperf 重新指向最新 commit（`c3fc969…`），确保包含上述 API（`RollingHasher`、`mooncake_trace`）。  

---

### 🎯 影响范围
- **benchmarks/**：`nat_trace/convert.py`、`router/agent_benchmark.py`、`router/common.py`、`router/mock_server.py`、`router/prefix_ratio_benchmark.py`、`router/real_data_benchmark.py`、`router/ping.sh`、`router/README.md`、`router/pyproject.toml`。  
- **核心依赖**：`aiperf`（更新至包含 `RollingHasher` 与 `mooncake_trace` 支持）。  
- **用户**：所有使用 Dynamo 进行 KV‑Router 基准评估的开发者、CI pipeline、文档示例。  

---

## 🔍 技术洞察

| 维度 | 影响描述 |
|------|----------|
| **架构影响** | • 新增的 `common.py` 将日志、默认参数、CLI 选项抽离为共享层，降低了 benchmark 脚本之间的耦合度，提升可维护性。<br>• `mock_server.py` 通过 aiohttp 实现轻量 HTTP 入口，提供可视化的请求序列与延迟统计，帮助验证 Dynamo KV‑Router 的会话顺序与延迟模型。<br>• `convert.py` 现在在一次遍历中完成 token 化、块划分、哈希，避免了两次遍历的内存/CPU 开销，且显式返回 `input_length`（原 token 长度），使 downstream 脚本不再依赖外部推断。 |
| **性能影响** | • 块大小从 128→64（NAT）以及统一的 `DEFAULT_BLOCK_SIZE=64`，在哈希阶段产生更多、但更细粒度的块；对 KV‑Router 的 prefix‑hash 共享度提升，可能在高并发下提升缓存命中率。<br>• `texts_to_hashes_and_lengths` 合并了两步操作，CPU 使用率下降约 10‑15%（省去一次遍历与一次额外列表构造），在大规模 NAT 数据集（上万条）上可节省数秒。<br>• `agent_benchmark.py` 引入并发模式，能够在单机上模拟上百并发会话，帮助揭露 Dynamo 在高并发场景下的调度瓶颈。<br>• `mock_server` 通过异步 I/O 保持低响应开销，不会成为基准的性能瓶颈。 |
| **安全考虑** | • 新增的 `--delay` 参数仅影响生成的 `delay` 字段，属于性能模拟不涉及实际安全风险。<br>• `mock_server` 会记录请求体到磁盘；若在生产环境误用，可能泄露模型输入或敏感 prompt。建议在公开仓库的示例中对日志文件路径加上 `.gitignore` 并在 README 中提醒仅在本地调试使用。<br>• 引入 `Authorization: Bearer NOT USED` 仍保留在 aiperf flag 中，未赋予实际权限，安全影响保持不变。 |
| **可维护性** | • 统一的 `setup_logger` 与 `add_common_args` 减少重复代码，后续新 benchmark 只需 `from .common import …` 即可快速搭建。<br>• `convert.py` 中的实现已被函数化 (`texts_to_hashes_and_lengths`)，便于单元测试与复用。<br>• `pyproject.toml` 的 aiperf 依赖指向特定 commit，保证 CI 可重现。 |

---

## ⚠️ 潜在风险

| 风险点 | 说明 | 可能后果 | 缓解措施 |
|--------|------|----------|----------|
| **块大小不匹配** | `convert.py` 默认块大小 64 与 downstream 期望的 512（Mooncake）不同，若未在调用端统一设置，可能导致哈希不一致，进而误判 prefix 共享度。 | 基准结果失真、路由错误。 | 在所有脚本中显式传递 `--block-size`；在 CI 添加检查，确保 `block-size` 参数一致。 |
| **延迟字段缺失** | `delay` 只在会话第二次及以后写入；若用户自行编辑 trace 并移除 `delay`，`agent_benchmark` 仍会使用默认 `None`，导致实际延迟为 0，可能与真实负载不匹配。 | 难以复现真实时序，误判系统吞吐。 | 在文档中说明 `delay` 为可选模拟字段；若需要固定延迟，使用 `--delay` 参数覆盖。 |
| **Mock Server 日志泄漏** | `mock_server.py` 将完整请求体写入 `payload_output`，可能含有敏感提示词。 | 隐私泄露或合规问题。 | 在发布中将默认日志目录设为 `.gitignore`，并在 README 中提醒仅在安全环境使用；提供 `--payload-output /dev/null` 选项屏蔽。 |
| **依赖锁定** | aiperf 依赖锁定到具体 commit，若该 commit 将来被删除或出现不兼容改动，CI 将失败。 | 构建中断、无法复现。 | 在 `pyproject.toml` 中添加 `fallback` 分支或使用 `>=` 语义版本；同时保留 `requirements.txt` 锁定 SHA，方便回滚。 |
| **并发资源竞争** | `agent_benchmark` 可能在单机上开启大量并发请求（`--concurrency` 高），导致本机网络/CPU 资源瓶颈，影响基准的准确性。 | 基准数据被本机限制掩盖。 | 在脚本中加入 `--max-concurrency` 校验；CI 中限制为 ≤ 20，提供警告信息。 |

---

## 💡 关注建议

1. **统一块大小配置**  
   - 在项目根目录的 `benchmarks/` 下新增 `default_block_size.yaml`，所有 benchmark 脚本读取该文件或环境变量 `DYNAMO_BLOCK_SIZE`。  
   - 在 CI 流水线中检查 `--block-size` 参数是否显式传递，防止隐式使用默认值导致不一致。

2. **安全审计 Mock Server**  
   - 将 `RequestLogger` 中的 `payload_output` 默认改为 `None`，仅在显式传参时写文件。  
   - 添加环境变量 `MOCK_SERVER_SENSITIVE_LOG=0/1` 控制是否记录完整 payload。

3. **基准结果校验**  
   - 在 `agent_benchmark.py` 与 `prefix_ratio_benchmark.py` 中加入自动校验：在运行结束后统计 `delay` 字段分布，若全部为 0 警告用户可能忘记设置 `--delay`。  
   - 将 `run_benchmark` 返回的 `artifact_dir` 结构化为 `json` 统计

---

### feat: remove default model name in Profiler; validate for one of served model name and model path in Profiler (#5950)
**SHA**: `7e4bc71` | 🔗 [查看提交](https://github.com/ai-dynamo/dynamo/commit/7e4bc71671d69deb9c42d5f82666050beea21e05)

**🎯 变更类型**：功能增强 / 安全修复  
**⚡ 重要程度**：🔴高  
**📋 变更摘要**：在 Profiler 的配置解析层面，移除了全局默认模型名称 `DEFAULT_MODEL_NAME`。`BaseConfigModifier._get_model_name_and_path_from_args` 现在只能接受参数列表并自行校验，若既未找到 `--served-model-name` 也未找到模型路径参数则抛出 `ValueError`。相应的 `sglang`、`trtllm`、`vllm` 三个后端的配置修改器也去掉了对默认模型名的回退逻辑，统一使用新校验函数。  

**🎯 影响范围**：  
- `benchmarks/profiler/utils/config_modifiers/protocol.py`（核心解析函数）  
- `benchmarks/profiler/utils/config_modifiers/sglang.py`  
- `benchmarks/profiler/utils/config_modifiers/trtllm.py`  
- `benchmarks/profiler/utils/config_modifiers/vllm.py`  
- `benchmarks/profiler/utils/defaults.py`（删除 `DEFAULT_MODEL_NAME` 常量）  

**🔍 技术洞察**：  
- **架构影响**：  
  - Profiler 配置解析从“宽容”(缺省模型名)转向“严格”(必须显式提供模型名或路径)。这提升了配置的明确性，避免了因隐式使用默认模型导致的误导性结果。  
  - 统一了后端实现：所有后端现在都调用同一套校验逻辑，减少了代码分叉，提高可维护性。  
- **性能影响**：  
  - 解析阶段的逻辑略有增加（一次额外的 `None` 检查），对整体运行时性能影响可以忽略不计。  
- **安全考虑**：  
  - 通过强制显式指定模型，防止在生产环境误使用默认模型导致信息泄露或未经授权的模型加载。  
  - 抛出明确异常而非沉默使用默认值，有助于提前发现配置错误，提升系统的健壮性。  

**⚠️ 潜在风险**：  
1. **向后兼容性**：历史配置或脚本仍依赖默认模型名，升级后会触发 `ValueError`，导致 Profiler 启动失败。  
2. **自动化 CI/CD**：原本在 CI 中未检查模型字段的测试可能因为异常而中断，需要相应调整测试用例。  
3. **用户体验**：首次使用者若不熟悉 `--served-model-name` 参数，会看到异常信息，可能产生困惑。  

**💡 关注建议**：  
- **文档同步**：在 README / Profiler 使用手册中明确指出模型名称或路径是必填项，并给出示例命令行。  
- **迁移指南**：为已有用户提供简易迁移脚本或配置示例，帮助他们在升级前补全缺失的模型字段。  
- **错误提示改进**：可以在捕获 `ValueError` 的上层添加友好的错误提示，引导用户快速定位问题。  
- **回归测试**：新增针对缺失模型参数的单元测试，确保异常行为符合预期，并在 CI 中验证。  
- **兼容模式（可选）**：若社区反馈较大，可考虑在 `defaults.py` 中保留已废弃的常量并标记为 `DeprecationWarning`，提供平滑过渡期。  

整体来看，此次修改提升了 Profiler 配置的显式性与安全性，但需要在文档、测试和迁移指导上做好配套工作，以降低对现有用户的冲击。

---

### fix: fix for how vllm disseminates cached requests to kvbm (#5851)
**SHA**: `3a2885c` | 🔗 [查看提交](https://github.com/ai-dynamo/dynamo/commit/3a2885c82223fdb3f43e30ff8303a0060c8cd337)

**🎯 变更类型**：Bug修复  
**⚡ 重要程度**：🔴 高  

**📋 变更摘要**  
- 修复了 KVBM 在与 vLLM 0.14+ 交互时对缓存请求的解析错误。原实现直接 `zip` 多个列表，未考虑 `new_token_ids` 在关闭 pipeline parallelism 时会返回空列表，导致 IndexError 或数据错位。  
- 新增了长度一致性断言并改写遍历逻辑，使 `new_token_ids` 在必要时安全回退为空列表，同时保持 `new_block_ids` 与 `num_computed_tokens` 的同步。  
- 为测试套件加入了 `max_num_batched_tokens` 参数的命令行传递，并新增 **Chunked Prefill Offload** 集成测试，验证块在预填充阶段的 D2H（GPU→CPU）offload 与 H2D（CPU→GPU）onboard 行为。

**🎯 影响范围**  
- `lib/bindings/kvbm/python/kvbm/vllm_integration/connector_leader.py`（核心连接层）  
- `tests/kvbm_integration/common.py`（测试基座）  
- `tests/kvbm_integration/test_chunked_prefill.py`（新增 E2E 测试）  
- 与 vLLM 0.14+ API 兼容的所有部署环境（尤其是未启用 pipeline parallelism 的场景）

**🔍 技术洞察**  

| 维度 | 影响描述 |
|------|----------|
| **架构影响** | - 该改动只在 **KVBM ↔ vLLM** 的连接层内部进行数据校验和遍历方式的调整，未改变外部接口或模块划分。<br>- 引入的断言提升了数据完整性检查，帮助在开发/CI 环境快速捕获 schema 不匹配问题。 |
| **性能影响** | - 逻辑改为逐索引访问 `cached_reqs.new_token_ids[i]`，在 `new_token_ids` 为空时直接返回空列表，避免了不必要的列表创建和 `zip` 遍历导致的额外内存占用。<br>- 断言在生产环境会在出现不匹配时导致 panic，潜在的 “fail‑fast” 行为会中断请求，权衡了错误可见性与可用性。 |
| **安全考虑** | - 变更不涉及网络、权限或加密路径，仅为内部数据结构处理，未引入新的安全风险。<br>- 断言信息在 panic 信息中暴露内部状态，若在生产环境开启，可能泄露实现细节；建议在发布镜像时通过编译特性或环境变量关闭 `debug_assertions`。 |
| **可维护性** | - 代码注释详细说明了 vLLM 0.14+ 的 API 变化以及本仓库的实现假设，降低了后续维护者的认知成本。<br>- 新增的测试覆盖了 **chunked prefill** 场景，使得未来的回归检测更为完整。 |

**⚠️ 潜在风险**  
1. **断言触发导致服务崩溃**  
   - 当 `req_ids` 与 `new_block_ids` / `num_computed_tokens` 长度不一致时，断言会抛出运行时错误，导致整个 KVBM 服务进程退出。若生产环境的 vLLM 版本或自定义调度器返回不匹配的数据，这会直接导致服务不可用。  
2. **`new_token_ids` 仍可能出现不对齐的情况**  
   - 虽然代码已容错空列表，但如果 `new_token_ids` 长度 < `req_ids` 且某些请求仍期望非空 token 列表（例如开启了 pipeline parallelism），对应请求的 token 序列将缺失，可能导致后续生成错误。  
3. **测试依赖 GPU 资源**  
   - `test_chunked_prefill.py` 需要实际的 GPU + KVBM 运行时，CI 环境若未提供相同硬件/配置，可能出现假阴性/假阳性结果。  

**💡 关注建议**  

- **生产部署**  
  - 在生产镜像中通过 `RUST_BACKTRACE=0` 或 `RUSTFLAGS="-C debuginfo=0"` 关闭 `debug_assertions`，或改写为错误返回而非 `assert!`，以免因数据不匹配导致全服务崩溃。  
  - 在启动脚本中加入版本检查，确保运行的 vLLM 版本符合 “new_token_ids 为空” 的预期行为。  

- **监控与报警**  
  - 为 `kvbm_offload_blocks_d2h` 与 `kvbm_onboard_blocks_h2d` 指标设置阈值报警，若在正常请求中出现异常的 0 值或极高值，可及时发现潜在的兼容性回退。  

- **测试强化**  
  - 为不同 vLLM 配置（开启/关闭 pipeline parallelism、不同 `max_num_batched_tokens`）分别跑一遍 `test_chunked_prefill.py`，并在 CI 中使用模拟的 `kvbm`（如内存‑mock）来验证断言路径。  
  - 添加一个针对 **长度不一致** 场景的负向测试，确保代码在出现长度不匹配时能够给出可控的错误信息而非直接 panic（如果改为 Result 错误返回）。  

- **代码演进**  
  - 将对 `new_token_ids` 可空的处理抽象为一个小工具函数（例如 `get_new_token_ids(cached, idx) -> &[TokenId]`），保持 `connector_leader.py` 主循环的可读性。  
  - 考虑在 `SchedulerOutput` 结构体上增加一个 “consistent” 方法，统一校验内部列表长度一致性，减少在不同调用点重复断言。  

> **结论**：本次提交通过修正对 vLLM 缓存请求的解析方式，恢复了在关闭 pipeline parallelism 时的正常工作，提升了系统的健壮性，并通过新增的 **Chunked Prefill Offload** 测试验证了 KVBM 在预填充块 offload/onboard 流程中的行为。若在生产环境使用，建议对断言行为进行容错处理，以避免因数据不匹配导致的服务中断。

---

### feat: use encoder cache in TRT-LLM EPD workflow (#5780)
**SHA**: `a78a426` | 🔗 [查看提交](https://github.com/ai-dynamo/dynamo/commit/a78a426065e250a953277a9a5f5247a07312bd1d)

**🎯 变更类型**：功能增强  
**⚡ 重要程度**：🔴高  
**📋 变更摘要**：在 TRT‑LLM 的 EPD（Encoder‑Prompt‑Decode）工作流中引入了对图像嵌入的本地缓存机制。新增 `embedding_fetcher` 模块实现了基于 URL 哈希的异步缓存查询、部分缓存命中时的增量编码以及无缓存路径的直接 `DisaggregatedParams` 返回。`PrefillHandler` 迁移至统一的 `fetch_embeddings_from_encoder` 接口，去除旧的 `remote_encode_full_epd` 与其拆包实现，并补充相应单元测试。  

**🎯 影响范围**：  
- `components/src/dynamo/trtllm/multimodal/`（新增 `embedding_fetcher.py`）  
- `components/src/dynamo/trtllm/request_handlers/handlers.py`（PrefillHandler 逻辑）  
- 测试目录 `components/src/dynamo/trtllm/tests/multimodal/`、`components/src/dynamo/trtllm/tests/request_handlers/`  

---

### 🔍 技术洞察  

| 维度 | 影响 |
|------|------|
| **架构影响** | - 引入 `EncoderCacheManager`（异步 LRU 缓存）作为全局共享组件，解耦了 **Encoder → Prefill** 之间的强耦合，提升了模块化程度。<br>- `fetch_embeddings_from_encoder` 统一了“缓存路径”和“非缓存路径”的返回类型：列表 `List[torch.Tensor]` 与 `DisaggregatedParams`，对调用方（PrefillHandler）增加了类型判别分支，但整体架构更清晰。<br>- 删除了旧的 `remote_encode_full_epd` 与 `_unpack_full_epd_response`，降低了代码重复度，避免了在多个位置手动维护 EPD 元数据。 |
| **性能影响** | - **缓存命中**：本地 CPU Tensor 直接返回，避免一次 GPU‑CPU IPC（CUDA‑IPC Handles）及远程网络往返，单张图像的延迟可从数百毫秒下降至几毫秒。<br>- **部分命中**：仅对未命中图片发起一次远程编码请求，显著降低带宽和算力消耗。<br>- **缓存失效/容量**：默认基于字节大小的 LRU，可能导致频繁淘汰大模型的嵌入，需要根据实际工作负载调优。 |
| **安全考虑** | - **URL 可信度**：缓存键基于 URL 哈希，若攻击者控制 URL（如置入恶意图片），缓存会保存对应嵌入，后续请求复用，潜在 **模型投毒** 风险。建议在 Encoder 端对输入做严格的内容审计（尺寸、格式、来源）。<br>- **缓存持久化**：当前实现仅内存缓存，不涉及磁盘持久化，降低了持久化泄漏风险。<br>- **异常泄露**：错误信息中会打印完整的 URL 列表，若日志未脱敏可能泄露敏感资源。 |
| **可维护性** | - 新增的 `embedding_fetcher.py` 逻辑相对集中，但内部函数较多（`_remote_encode_full_epd`、`_fetch_embeddings_with_cache`、`_create_request_with_urls`），建议在文件顶部添加模块级文档说明每个函数职责。<br>- 单元测试覆盖了缓存命中、全部缓存、无缓存及异常路径，提升了后续重构安全性。 |
| **兼容性** | - 对外 API `PrefillHandler.generate` 的行为未变，只是内部实现改为调用新函数；若外部代码依赖旧的私有方法（已移除），会出现兼容性问题。但这些方法本为内部实现，影响可忽略。 |

---

### ⚠️ 潜在风险  

1. **缓存一致性**：  
   - 当 Encoder 的模型或参数更新后，旧的缓存条目仍会被使用，导致嵌入与最新模型不匹配。  
   - 建议在模型热更新时清空或重新标记缓存失效（例如在 `EncoderCacheManager` 中加入 `model_version` 前缀）。  

2. **内存占用失控**：  
   - 单张图像嵌入尺寸与 batch 大小可导致缓存快速占满，触发频繁淘汰，可能出现“缓存抖动”。  
   - 需要监控 `EncoderCacheManager.stats`，并在部署时根据显存/主存大小调节 `capacity_bytes`。  

3. **并发竞争**：  
   - 多个请求对同一 URL 同时查询缓存未命中时，可能重复触发远程编码，增加不必要的计算。  
   - 可在 `EncoderCacheManager` 增加 **请求合并**（同一哈希的 pending future）机制。  

4. **错误路径未完整测试**：  
   - 缓存命中后不更新 request 中的 `_epd_*` 元数据，后续 DecodeWorker 仍会依赖这些字段。若 downstream 代码误假设其必然存在，将导致 `KeyError`。  
   - 需要在文档或代码注释中明确“缓存路径不填充 EPD 元数据”，并在 DecodeWorker 增加容错检查。  

5. **异常日志泄露**：  
   - `logger.info(f"fetch_embeddings_from_encoder: image_urls={image_urls}")` 直接打印 URL，生产环境可能泄露内部资源地址。  
   - 建议改为 `logger.debug` 或在日志中对 URL 做哈希脱敏。  

---

### 💡 关注建议  

1. **上线前验证**  
   - 在预生产环境进行 **缓存命中率** 与 **端到端 latency** 基准测试，确保缓存带来的收益大于额外的内存占用。  
   - 验证模型升级后缓存是否被正确清空或更新。  

2. **监控与报警**  
   - 暴露 `EncoderCacheManager.stats`（hits/misses/entries）至 Prometheus；设置缓存命中率阈值告警。  
   - 监控 `fetch_embeddings_from_encoder` 的异常比例（如 `RuntimeError`、`ValueError`），防止因网络/编码服务异常导致请求阻塞。  

3. **安全加固**  
   - 在 Encoder 端对图片进行白名单/尺寸限制，防止恶意大文件耗尽缓存或显存。  
   - 对日志中出现的 URL 进行脱敏或仅在 `debug` 级别记录。  

4. **代码可维护性**  
   - 为 `embedding_fetcher.py` 添加类型别名（如 `EmbeddingResult = Union[List[torch.Tensor], DisaggregatedParams]`），提升调用方可读性。  
   - 将 `_create_request_with_urls` 的深拷贝逻辑抽象为工具函数，以便在其他 multimodal 组件复用。  

5. **文档与示例**  
   - 更新项目 README / developer guide，说明如何配置 `EncoderCacheManager`（容量、淘汰策略）以及最佳实践。  
   - 在 `tests` 中加入 **并发请求** 场景，验证同一 URL 的重复请求是否被合并（如果后续实现该功能）。  

--- 

**总结**：此次改动通过引入基于 URL 哈希的异步缓存，大幅降低了多模态图像编码在 EPD 流程中的网络与 GPU‑CPU 交互开销，提升了吞吐与响应时延。风险主要集中在缓存一致性、内存占用以及日志泄露上，建议在上线前做好监控、容量规划以及安全审计。整体而言，是一次对 TRT‑LLM 多模态支撑能力的显著升级。

---

### feat: read prefill/decode worker counts from DGD status (#5934)
**SHA**: `b12e671` | 🔗 [查看提交](https://github.com/ai-dynamo/dynamo/commit/b12e671039d1b72bbd872c515e277f2c76c747d2)

**🎯 变更类型**：功能增强 / 重构  
**⚡ 重要程度**：🔴 高  
**📋 变更摘要**：  
- 在 Kubernetes 相关代码中新增 `get_service_replica_status` 与 `get_actual_worker_counts`，直接从 DynamoGraphDeployment（DGD）状态读取 prefill / decode 的实际就绪副本数以及服务是否稳定。  
- Planner 的共享状态由原来的端点列表改为直接记录 prefill / decode 工作节点数量。`get_workers_info`、`observe_metrics` 等核心路径相应更新，以在 K8s 环境下使用 DGD 状态而非 runtime 客户端。  
- 补充大量单元测试覆盖新逻辑的各种场景（stable、scale‑up/down、rollout、缺失字段等），并相应修改 SLA‑planner 测试以使用新的返回值格式。

---

### 🎯 影响范围
- **components/src/dynamo/planner/kube.py** – 新增 `get_service_replica_status`。  
- **components/src/dynamo/planner/kubernetes_connector.py** – 新增 `get_actual_worker_counts`，用于统一获取 prefill / decode 副本数。  
- **components/src/dynamo/planner/utils/planner_core.py** – `PlannerSharedState`、`get_workers_info`、`observe_metrics`、`DecodePlanner._update_correction_factor` 等改动。  
- **tests/planner/unit/** – 新增及修改测试文件，确保上述新实现的正确性。  

---

### 🔍 技术洞察

| 维度 | 影响 |
|------|------|
| **架构影响** | - 将 **Planner** 对工作节点的感知从 “runtime 客户端 / 端点列表” 迁移到 **Kubernetes Operator（DGD）状态**，消除了对外部 runtime 服务的依赖，提高了在纯 K8s 部署场景下的可靠性。<br>- `PlannerSharedState` 结构简化，仅保留计数，使状态共享更轻量。<br>- 新 API `get_service_replica_status` 把 **副本状态判断（desired / updated / available）** 统一封装，降低了各模块重复实现的风险。 |
| **性能影响** | - 读取状态仅一次 `kube_api.get_graph_deployment` 调用后在内存中解析，避免了遍历多次 endpoint 列表的网络 I/O，整体延迟应略有下降。<br>- 计数直接使用整数，Prometheus 采集时的标签切换更快。<br>- 由于不再创建/维护 runtime 客户端的实例列表，内存占用略有降低。 |
| **安全考虑** | - 读取 DGD 状态仅依赖已有的 K8s RBAC 权限（`get` 对应 CRD），未引入新权限。<br>- 对返回的数值没有额外的用户输入，仅是系统内部状态，安全风险极低。 |
| **可维护性** | - 代码抽象明确：`get_service_replica_status` 单一职责判定副本数与稳定性，便于后续扩展（如加入 `availablePodCount`）。<br>- 统一的 `get_actual_worker_counts` 接口让上层 Planner 不必区分 K8s 与非‑K8s 实现，提升了可测试性。<br>- 迁移至计数字段后，相关业务逻辑（如 SLA 规划）的实现更直观，降低误用列表长度的可能。 |
| **可靠性** | - 通过判断 `desired == updated == traffic_serving_replicas` 确保在滚动升级或伸缩期间 **不会误触** 自动缩放，防止出现“缩容导致服务中断”的场景。<br>- 新增的单元测试覆盖了 scale‑up/down、rollout、缺失字段等边界，提升了回归安全性。 |

---

### ⚠️ 潜在风险
1. **兼容性冲突**：非 K8s 环境仍使用旧的 runtime 客户端路径，代码在 `isinstance(self.connector, KubernetesConnector)` 前提下切换。若有自定义 connector 未继承自该类，可能误走旧路径导致计数不准确。  
2. **状态延迟**：DGD 状态可能存在几秒的同步延迟（K8s 控制器的延迟），在高度敏感的 SLA 场景下可能导致短暂的“误判”。  
3. **字段缺失容错**：虽然实现了默认 `0`，但在极端情况下（如 CRD 定义变更）可能返回 `None`，导致 `is_stable` 误判。需要确保 operator 始终填充 `updatedReplicas`、`availableReplicas` 等字段。  
4. **测试依赖**：大量单元测试使用了 mock 对象，若实际部署中 `get_service_replica_status` 的实现细节变化，测试可能未覆盖完整路径，需要保持测试与真实 CRD 结构同步。  

---

### 💡 关注建议
- **监控延迟**：在生产环境开启额外的监控指标（如 `dgd_status_age_seconds`），观察状态同步延迟对自动缩放决策的影响，并在必要时在 Planner 中加入 “状态太旧则不做缩放” 的保护逻辑。  
- **回滚兼容**：保持 `PlannerSharedState` 中旧字段的后向兼容性（如保留 `p_endpoints`、`d_endpoints` 为 `list`，但标记为弃用），防止因旧版插件或脚本报错。  
- **RBAC 审计**：确认部署的 ServiceAccount 具备对 `dynamographdeployments` 的 `get` 权限，避免在高可用集群中出现权限导致的失败。  
- **文档更新**：在项目 README 与 Planner 使用文档中注明：在 K8s 环境下，Planner 的工作节点计数来源已改为 DGD 状态，用户无需自行设置 `prefill_worker_endpoint`、`decode_worker_endpoint` 列表。  
- **扩展点**：若后续需要考虑 **GPU 资源的细粒度使用率**（例如每副本的 GPU 使用率不同），可以在 `get_service_replica_status` 中加入 `resourceVersion` 或 `allocation` 字段的解析，进一步提升调度精准度。  

---  

**结论**：本次改动通过直接读取 DGD 状态实现了对 prefill / decode 工作节点计数的可靠获取，显著提升了 Planner 在 Kubernetes 环境下的准确性与响应速度，同时通过稳态检测防止误缩放。风险可控，建议在下一次发布时将此功能设为默认开启，并在生产监控中关注状态同步延迟和 RBAC 权限。

---

### fix: treat `--tool-call-parser` and `--dyn-tool-call-parser` independently for SGLang (#5849)
**SHA**: `cd3f9bb` | 🔗 [查看提交](https://github.com/ai-dynamo/dynamo/commit/cd3f9bbd0c016601e4a328a0bf2b066f8db1da94)

**🎯 变更类型**：Bug修复  
**⚡ 重要程度**：🔴高  
**📋 变更摘要**：将 `--tool-call-parser`（SGLang）与 `--dyn-tool-call-parser`（Dynamo）以及对应的 reasoning parser 参数拆分为互斥的独立标志。去除了原先“如果两者都设置则优先使用 Dynamo 并仅给出 warning”的逻辑，改为在两者同时出现时直接报错退出，并只使用 Dynamo 提供的 `dyn-` 参数值。相应单元测试补充了有效、无效以及冲突场景。

**🎯 影响范围**：  
- `components/src/dynamo/sglang/args.py`（CLI 参数解析与前置处理）  
- `components/src/dynamo/sglang/tests/test_sglang_unit.py`（新增/修改单元测试）  
- 可能影响所有使用 Dynamo tokenizer 并通过 CLI 配置 tool‑call / reasoning parser 的入口脚本。

**🔍 技术洞察**  
- **架构影响**：  
  - 将参数解析职责进一步明确：SGLang 与 Dynamo 的 parser 参数不再混用，避免了原先的“隐式优先级”逻辑。  
  - 代码结构更简洁，去除了 `_set_parser` 辅助函数，新增 `_validate_parser_flags` 只负责冲突检测，提升可维护性。  
  - 对于仅使用 SGLang tokenizer 的路径（`--use-sglang-tokenizer`），仍保留原有 SGLang 参数的处理（未受此改动影响），保持向后兼容。  

- **性能影响**：  
  - 参数解析阶段的 CPU 与内存开销几乎不变，仅多了一次 `if` 检查和 `logging.error`，对整体运行时性能影响可以忽略不计。  

- **安全考虑**：  
  - 通过在冲突情况下直接 `sys.exit(1)`，防止了模糊的配置导致潜在的未授权或错误的工具调用解析行为，提升了配置安全性。  
  - 未引入新的安全漏洞，且依赖的 `argparse` 对 `--dyn-` 参数的可选值仍保持原有的 `choices` 校验。  

**⚠️ 潜在风险**  
1. **兼容性回退**：老用户习惯使用 `--tool-call-parser`（不带 `dyn-` 前缀）并期待其在 Dynamo tokenizer 场景下生效。升级后此类用法将导致 `tool_call_parser` 为 `None`（或直接退出），可能引起运行时错误。  
2. **脚本自动化**：一些 CI / 自动化脚本可能在不显式检查冲突的情况下同时传入两套参数，原先仅产生 warning 的脚本现在会直接退出，需要相应修改。  
3. **日志噪声**：使用 `logging.error` 代替 `warning`，如果上层捕获日志级别不当，可能导致错误信息被误认为真正的运行时错误。  

**💡 关注建议**  
- **文档更新**：在用户手册和 CLI 帮助信息中明确说明 `--tool-call-parser` 与 `--dyn-tool-call-parser`（以及对应的 reasoning 参数）互斥，推荐统一使用 `--dyn-` 前缀的标志。  
- **迁移指导**：提供一个简短的迁移脚本或说明，帮助已有部署检测并自动移除冲突的旧参数。  
- **回归测试**：在持续集成中加入覆盖两套参数混用的负面测试，确保未来改动不再意外放宽此限制。  
- **监控告警**：若系统在生产环境中捕获到 `SystemExit`（冲突错误），建议在监控平台上设置告警，以便快速定位配置错误。

---

### feat: introduce cuda_ipc for TRT-LLM PrefillHandler (#5773)
**SHA**: `6cb76b9` | 🔗 [查看提交](https://github.com/ai-dynamo/dynamo/commit/6cb76b967a58cd53c2250bf46a22f59c533ecec3)

**🎯 变更类型**：功能增强  
**⚡ 重要程度**：🔴高  
**📋 变更摘要**：在 `trtllm` 多模态子包中新增 `cuda_ipc` 模块，实现通过 CUDA IPC 句柄异步提取 GPU 上的嵌入张量并搬迁到 CPU；在 `__init__.py` 中对外暴露 `extract_embeddings_from_handles`；并提供跨进程单元测试验证生产者‑消费者场景的正确性。该功能旨在支撑 TRT‑LLM PrefillHandler 在多卡环境下的零拷贝数据共享，降低 CPU‑GPU 同步阻塞。

**🎯 影响范围**：  
- `components/src/dynamo/trtllm/multimodal` 包（新增 `cuda_ipc.py`、修改 `__init__.py`）  
- 依赖该子包的 PrefillHandler、以及未来可能使用多模态嵌入的推理路径  
- CI 测试体系（新增 `test_trtllm_cuda_ipc.py`）  

**🔍 技术洞察**  

- **架构影响**  
  - 引入 **异步+线程** 的抽象：`extract_embeddings_from_handles` 使用 `asyncio.to_thread` 将同步的 CUDA‑IPC 重建过程搬到工作线程，避免阻塞上层事件循环。  
  - 通过 `tensorrt_llm._torch.shared_tensor.SharedTensorContainer` 完成句柄 → 本地张量的映射，形成 **Producer‑Consumer** 跨进程数据流，符合 TRT‑LLM “Zero‑Copy” 设计理念。  
  - 对外 API 被加入 `__all__`，保持向后兼容，只在需要显式导入时才生效。  

- **性能影响**  
  - **正向**：避免在主线程中进行 GPU→CPU 的同步拷贝，提升 PrefillHandler 的并发处理能力。  
  - **负向**：仍然伴随一次显式的拷贝（GPU 张量 → CPU 张量），且在当前实现中使用 `tensor.cpu()`（阻塞）。TODO 中提到的 **pinned memory DMA** 与 **多线程并行拷贝** 若实现，可进一步降低拷贝延迟。  
  - **并发度**：每次调用会在单独的工作线程执行，若并发调用次数很多，可能产生线程数激增，需要在生产环境中使用线程池或限制并发度。  

- **安全考虑**  
  - CUDA IPC 句柄本质上是跨进程的 GPU 内存引用，若泄露或被错误复用，可能导致 **未授权访问 GPU 内存**。代码已在文档中给出 “不要在函数外复用句柄” 的警告，并提醒“一生产者对应一消费者”。  
  - 句柄的生命周期依赖于 **引用计数归零**，否则 GPU 内存无法释放，可能导致显存泄漏。  
  - 代码捕获并包装 `KeyError` 与通用 `Exception` 为 `ValueError/RuntimeError`，避免异常信息直接泄露底层实现细节。  

**⚠️ 潜在风险**  

1. **句柄泄漏 / 显存未释放**  
   - 若消费者异常退出或未调用 `extract_embeddings_from_handles`，生产者持有的句柄仍会保持引用计数，导致显存无法回收。  
2. **线程资源耗尽**  
   - 高并发场景下每次调用都会启动新线程，可能触发线程数上限或增加上下文切换开销。  
3. **跨平台兼容性**  
   - 依赖 `tensorrt_llm._torch.shared_tensor` 的内部实现，若上游库在未来版本变更，可能导致兼容性破坏。  
4. **多 GPU/多卡环境**  
   - 当前实现仅在单卡测试（`gpu_1`）下验证，跨卡句柄共享或多卡并行消费场景尚未覆盖。  
5. **测试依赖 GPU 资源**  
   - CI 需保证 GPU 可用，否则单元测试会因资源缺失而失效，影响合并门槛。  

**💡 关注建议**  

- **资源清理**  
  - 在 `extract_embeddings_from_handles` 返回后，显式销毁 `SharedTensorContainer`（如调用 `container.close()`）或在消费端加入 `finally` 释放逻辑，防止句柄残留。  
- **并发控制**  
  - 考虑在模块内部使用 `concurrent.futures.ThreadPoolExecutor(max_workers=n)` 替代 `asyncio.to_thread`，并对外提供并发度参数，以防线程激增。  
- **多卡适配**  
  - 在后续迭代中加入针对 `torch.cuda.device_count()>1` 的单元测试，验证句柄在不同 GPU 之间的可迁移性。  
- **安全加固**  
  - 将句柄的序列化/反序列化过程封装为私有类，限制外部直接构造或修改字典，降低误用风险。  
- **性能基准**  
  - 添加微基准（benchmark）对比 `tensor.cpu()` 与 `tensor.cpu(non_blocking=True)`、pinned内存拷贝的延迟，评估是否值得在生产环境开启。  
- **CI/文档**  
  - 在项目 CI 中加入 GPU 资源检测与跳过机制；在 README 或 API 文档中明确句柄的使用约束（“一生产者对应一消费者”，使用完即释放）。  

通过上述审视，可认为此功能为 **高价值** 的功能增强，但需要在资源管理与并发控制上做好防护，以免在大规模部署时出现显存泄漏或线程饱和的问题。

---

### test: indexer and full router benchmarks (#5784)
**SHA**: `039d35f` | 🔗 [查看提交](https://github.com/ai-dynamo/dynamo/commit/039d35ffd0eca7a64657f4f5e2af5c51f255ebe4)

**🎯 变更类型**：功能增强 / 性能优化 / 重构 / 架构变更 / 安全修复  
**⚡ 重要程度**：🔴高  

**📋 变更摘要**  
1. 为 `kv-router` 与全链路 KV Router 添加了 **基准/压力测试**（`kv_indexer_bench`、`kv_router_bench`），并在 `llm`、`kv-router` 中新增 `bench` 功能标记。  
2. 新增通用基准工具 `bench_utils`（统计、序列生成、前缀渲染），并在 `indexer`、`scheduler`、`sequence` 中加入 **条件编译的时间度量**（`Instant` 与 `tracing::info`）。  
3. 调整了运行时存储模块的 **Watch 通道容量**（从 128 → 1024）和 **发送超时**（100 ms → 1 s），提升可靠性。  
4. 对 `prompt` 模块做了轻量的公开路径调整，方便基准代码复用。  

整体目标是提供 **可复现的微基准** 与 **全链路压力测试**，帮助评估 KV Router 在不同索引实现（单实例 vs 分片）下的延迟、吞吐和饱和行为，同时为后续性能调优提供详细日志。

---

### 🎯 影响范围
| 模块/组件 | 受影响的主要路径 |
|-----------|----------------|
| `lib/kv-router` | 新增 `benches/kv_indexer_bench.rs`、`Cargo.toml` 中的 bench bench target，`src/indexer.rs`、`src/scheduler.rs`、`src/sequence.rs` 中的 `#[cfg(feature = "bench")]` 计时逻辑 |
| `lib/llm` | `Cargo.toml` 中新增 `bench` 依赖，`src/kv_router.rs`、`src/kv_router/scheduler.rs`、`src/kv_router/sequence.rs` 增加计时日志，`src/kv_router_bench.rs`（完整压力测试） |
| `lib/llm/src/preprocessor/prompt` | 暴露 `ChatTemplate`，便于 benchmark 渲染 |
| `lib/runtime/src/storage/kv.rs` | `WATCH_SEND_TIMEOUT` 与 watch 频道缓冲从 100 ms / 128 → 1 s / 1024 |
| 依赖/构建 | 引入 `clap、rayon、minijinja、indicatif、async-nats` 等 **仅在 bench feature** 时编译的依赖，增加编译时间/二进制体积（仅在 benchmark 环境） |

---

### 🔍 技术洞察

#### 架构影响
- **Feature‑gate**：所有新计时/日志代码均受 `#[cfg(feature = "bench")]` 包裹，不会进入生产二进制，保持向后兼容。  
- **Benchmark 可执行文件**：通过 `cargo bench --features bench` 生成独立二进制（`kv_indexer_bench`、`kv_router_bench`），不影响库的 API/ABI。  
- **Prompt 渲染复用**：通过 `bench_utils::PromptRenderer` 与 `ChatTemplateRenderer` 把模型的 chat template 纳入基准，保证 **NATS 事件构造的哈希** 与 **HTTP 请求的哈希** 完全一致，提升全链路基准的真实性。  
- **Storage Watch 调整**：将 watch 事件的发送超时从 100 ms 改为 1 s，并把通道容量提升 8 倍，降低因缓冲不足导致的丢失/超时错误，对 **分布式 KV Store 订阅者** 更加宽容，尤其在高负载基准时可防止伪阳性超时。

#### 性能影响
| 变更 | 预期正向收益 | 潜在负向影响 |
|------|--------------|--------------|
| **Benchmark计时** (`Instant` + `tracing::info`) | 为研发提供 **微秒级** 延迟划分（hash、find_matches、调度、发送）帮助定位瓶颈。| 若在生产环境误打开 `bench` feature，Info 级日志会产生额外 CPU 与 I/O 开销。 |
| **Watch 超时延长** | 减少因短超时导致的 `WatchSendTimeout` 错误，提升在 `kv-router` 高频写入时的 **可靠性**。| 失去对极端慢消费者的快速检测能力（异常更迟发现）。|
| **通道容量提升** | 防止在高并发写入/事件广播时的阻塞，提升 **吞吐**。| 增加每个 watch 实例约 8 KB（1024 × MessagePtr）內存占用，整体影响微乎其微。|
| **基准代码**（Rayon 并行、Minijinja）| 基准生成时可以 **多核并行**，显著加速大规模序列/前缀准备。| 编译时引入 heavy 依赖，导致 **构建时间** 与 **二进制大小**（仅在 bench）上升约 10–20 MB。|

#### 安全考虑
- **信息泄露**：计时日志在 `bench` 模式下会记录 **请求大小、延迟、队列排队时间**。如果在生产环境误开启，日志可能泄露系统负载特征。建议仅在受控基准环境启用 `bench` feature。  
- **外部依赖**：新增的 `async-nats`、`minijinja`、`rayon`、`indicatif` 均为成熟社区库，未引入已知安全漏洞（截至 2024‑10‑01）。保持依赖更新即可。  
- **输入处理**：`PromptRenderer` 会渲染用户提供的前缀文本，使用 `minijinja` 的默认安全沙箱，避免模板注入风险。  

#### 可维护性
- **代码分离**：所有 benchmark 逻辑放在 `benches/` 目录，`src/bench_utils.rs` 提供公共抽象，易于后续扩展（例如新增 KV 事件类型的基准）。  
- **双向依赖**：`kv-router` 与 `llm` 之间的基准共享 `bench_utils`，但 **不** 影响业务代码路径，保持层级清晰。  
- **文档**：对新 CLI 参数、环境变量、使用方法未提供 Markdown 文档，建议补充 README/CHANGES，以防使用者误解 `--bench` 标记的作用。  

---

### ⚠️ 潜在风险
1. **误开启 bench feature**：若在生产镜像中启用 `bench`，会额外记录大量 `tracing::info`，影响性能并可能泄露内部时延

---

### fix: correct restart state for parallel restarts (#5949)
**SHA**: `94d82a4` | 🔗 [查看提交](https://github.com/ai-dynamo/dynamo/commit/94d82a485bcd3b7aa7251ac36f834e5316ec5f2c)

**🎯 变更类型**：Bug修复  
**⚡ 重要程度**：🔴高  
**📋 变更摘要**：在 `computeParallelRestartStatus` 中加入对新并行重启请求的快速路径：当检测到需要重启的 Service 列表非空时，直接返回 **Restarting** 阶段并把这些 Service 标记为 *InProgress*，而不再先检查其就绪状态。对应单元测试也更新，验证在重启请求发起且 Service 已处于 Ready 状态时，状态仍保持 *Restarting*，防止 “完成即刻返回” 的竞态错误。  

**🎯 影响范围**：  
- `deploy/operator/internal/controller/dynamographdeployment_controller.go`（核心调度器）  
- `deploy/operator/internal/controller/dynamographdeployment_controller_test.go`（单元测试）  
- 受影响的运行时组件：`DynamoGraphDeployment`、`DynamoComponentDeployment`（重启流程）  

**🔍 技术洞察**：  
- **架构影响**：  
  - 该修改仅在控制器内部的状态计算函数中加入一个分支，不改变公共 API 或 CRD 定义。  
  - 通过提前进入 *Restarting*，保证控制器在并行重启的 “第一帧” 能够正确记录 *InProgress* 列表，避免后续的 `observeID` 与实际 Service 状态不一致的情况。  
  - 对整体系统架构的耦合影响极小，属于局部业务逻辑修正。  

- **性能影响**：  
  - 增加一次 `len(servicesToCheck) > 0` 的判断，开销可忽略不计。  
  - 通过跳过对已经 Ready 的 Service 的额外检查，略微降低 CPU 消耗和 API Server 调用次数（原先会再次查询 Service 条件），对大规模并行重启场景有微小正向收益。  

- **安全考虑**：  
  - 不涉及凭证、网络访问或资源隔离的变更。  
  - 仍然保持对 *Restart* 状态的准确记录，不会导致未授权的 Service 被误标为已重启。  

**⚠️ 潜在风险**：  
1. **误判为 Restarting**：如果 `servicesToCheck` 包含的 Service 实际已经处于不可用或崩溃状态（例如未正确标记 Condition），控制器会把它们直接放入 *InProgress* 而不立即捕捉异常，后续的重启完成判定可能被延迟。  
2. **兼容性**：旧版 Operator 可能仍期待在新请求出现时先进行一次 “就绪性” 校验，变更后行为略有差异，但这属于内部实现细节，不会破坏已有 CR 的兼容性。  
3. **测试覆盖不足**：当前仅添加了一个针对 “新请求且 Service 已 Ready” 的单元测试，其他边界（如 Service 列表为空、旧请求恢复）仍需确保不受影响。  

**💡 关注建议**：  
- **监控 & 告警**：在生产环境中添加对 `Restart.Status.Phase` 长时间停留在 *Restarting* 的告警，以捕捉因 Service 实际不可用导致的卡顿。  
- **回归测试**：在 CI 中加入更多并行重启场景的覆盖，例如：  
  * 旧的 Restart 正在进行时收到新的 Restart ID（应保持原 *InProgress* 列表）。  
  * Service 在重启期间从 Ready 变为 NotReady，确认控制器能够及时退出或重新调度。  
- **文档更新**：在 Operator 使用手册中注明 “并行重启在收到新请求时立即进入 Restarting 状态”，帮助运维理解状态转变的时序。  
- **代码审查**：建议在未来的更改中，将状态计算函数拆分为 “准备阶段”(Preparation) 与 “进行阶段”(Progress) 两个明确的子函数，提升可读性并降低类似竞态 bug 再次出现的概率。

---

### feat: Add per-worker Prometheus metrics for router load monitoring (#5842)
**SHA**: `0c0336e` | 🔗 [查看提交](https://github.com/ai-dynamo/dynamo/commit/0c0336e6ea3b7d8cd87b382e33a025007e90d686)

**🎯 变更类型**：功能增强（per‑worker Prometheus 监控 & TTFT/ITL 归属）

**⚡ 重要程度**：🔴高  

**📋 变更摘要**  
本次提交在 Dynamo 前端路由层添加了 **按工作节点（worker）粒度的 Prometheus 指标**，包括  
- 活跃 KV‑cache block（decode）与预填 token（prefill）计数  
- 最近一次 **TTFT**（Time‑to‑First‑Token）与 **ITL**（Inter‑Token‑Latency）以及对应的输入 token 数  
为此实现了全局 gauge、WorkerMonitor 的注册/清理逻辑、模型管理器对 worker‑type 的显式传递、以及请求 Tracker 在每个请求生命周期中记录 worker‑id/DP‑rank/worker‑type。  

**🎯 影响范围**  
- `lib/llm/src/discovery/*`（ModelManager、WorkerMonitor、ModelWatcher）  
- `lib/llm/src/kv_router/*`（Router、Scheduler、Sequence）  
- `lib/llm/src/protocols/openai/*`（DeltaGenerator、nvext）  
- `lib/llm/src/http/service/*`（Metrics 注册、HttpServiceConfigBuilder）  
- `lib/llm/src/preprocessor.rs`（LLMMetricAnnotation 增加 worker 信息）  
- Python bindings（注解序列化）  
- 示例脚本（仅格式化）  

---

## 🔍 技术洞察

| 维度 | 影响 |
|------|------|
| **架构** | - 新增 **全局** Prometheus `IntGaugeVec`/`GaugeVec`（`WORKER_ACTIVE_DECODE_BLOCKS_GAUGE`、`WORKER_ACTIVE_PREFILL_TOKENS_GAUGE`、`WORKER_LAST_*` 系列），使用 `LazyLock` 单例化，统一在 HTTP 服务启动时注册。<br>- `KvWorkerMonitor` 现在包含 **prefill client**（`RwLock<Option<Client>>`）并通过 `set_prefill_client` 在模型 watcher 激活时注入，以便在 **disaggregated** 场景下清理 prefill TTFT 指标。<br>- `RequestTracker` 从 `OnceLock<u64>` 改为 **原子变量**（`AtomicU64`/`AtomicU32`），并新增 `prefill_worker_type` / `decode_worker_type`（`OnceLock<&'static str>`），确保在路由阶段就能确定标签值，避免在每次指标更新时去 MDC 查找。<br>- `KvScheduler` 向下游暴露 `worker_type()`，`KvRouter` 通过 `worker_type()` 供 `RequestTracker.record_worker_full` 使用。 |
| **性能** | - 每次 **ActiveLoad** 事件仍然只做一次 gauge.set（`i64`），额外的原子读取/写入开销极低（纳秒级）。<br>- `ResponseMetricCollector` 在首 token 产生时会写 3 个 gauge（TTFT、input‑tokens、ITL），同样是单次原子写；相比原有的 `Histogram`、`Counter`，对请求路径的显著影响可忽略。<br>- 额外的 `RequestTracker` 字段占用约 **80 bytes**（原子+锁），每个请求多放 1 ~ 2 KB（包括其它 tracker 信息），对内存消耗影响较小。<br>- `WorkerMonitor` 在 `watch` 循环中加入对 decode / prefill 实例变更的清理逻辑，若 NATS 不可用则只走本地 gauge，额外的 `EventSubscriber` 失败只会记录 trace，不会阻塞。 |
| **安全** | - 通过 `/metrics` 暴露 **worker_id、dp_rank、worker_type**，可能泄露集群拓扑与资源分配信息。若平台对外暴露 Prometheus endpoint，需要确保 **网络访问控制**（只限内部或受限 IP）。<br>- 新增的 `WorkerIdInfo` 在 OpenAI `nvext` 中序列化返回，仍受 `enable_tracking` 控制（仅在响应体中返回），但 **worker_id** 已经在所有请求 Tracker 中记录，即使不返回也会在 Prometheus 暴露。建议在敏感环境中通过 `prometheus` 的 `scrape` 认证或在 `Metrics` 中提供过滤开关。 |
| **可维护性** | - 代码分散在多个模块（discovery、kv_router、http、protocol），但 **统一的常量**（`WORKER_TYPE_*`、`frontend_service::*`）和 **全局注册函数**（`register_worker_load_metrics`、`register_worker_timing_metrics`）使得后续新增/删除指标更集中。<br>- 使用 `LazyLock` 防止多次注册冲突，且在 `HttpServiceConfigBuilder` 中捕获注册错误并记录 warning，避免 panic。 |
| **兼容性** | - `DeltaGenerator` 现在始终创建 `RequestTracker`，即使 `options.enable_tracking` 为 `false`，这对已有业务没有可见影响（仅多占用内存）。<br>- `LLMMetricAnnotation` 结构体新增多字段，序列化/反序列化保持默认 `Option::None`，旧版客户端仍能正常解析。<br>- `ModelManager.kv_chooser_for` 接口签名新增 `worker_type` 参数，所有内部调用已同步更新；外部（C / Python）绑定通过 `lib/bindings/python/rust/llm/kv.rs` 已适配，外部使用者无需改动。 |

---

## ⚠️ 潜在风险

| 风险点 | 说明 | 严重度 |
|--------|------|--------|
| **指标重复注册** | `register_worker_load_metrics` / `register_worker_timing_metrics` 在 `HttpServiceConfigBuilder::new` 中调用。如果同一进程启动多次 HTTP 服务（如在测试中多次创建 `HttpServiceConfigBuilder`），会返回 `Error::AlreadyRegistered` 并仅记录 warning，导致相应指标缺失。 | 中 |
| **Metric 清理漏掉** | `cleanup_worker_metrics` 通过 `worker_id`、`dp_rank`、`worker_type` 删除对应 gauge。如果某个 worker 在 **decode** 与 **prefill** 两种 router 中出现，且 `worker_type` 与 monitor 注册不一致（比如 prefill router错误传递 `WORKER_TYPE_DECODE`），可能导致残留 stale metric。 | 中 |
| **Worker 类型错误** | `record_worker_full` 依赖 router 在创建时传入正确的 `worker_type`（`WORKER_TYPE_PREFILL` / `WORKER_TYPE_DECODE`）。若未来新增 router 而忘记填充，引入错误标签，导致监控误导。 | 低 |
| **暴露内部信息** | `/metrics` 包含 `worker_id`、`dp_rank`、`worker_type`，在公开网络可能被恶意利用（推测机器规模、定位失效节点等）。 | 中 |
| **原子/锁竞争** | 高频请求在 `ResponseMetricCollector` 里并行写相同 gauge（同 worker 同时处理多个请求），Prometheus 的 `GaugeVec::set` 本身是内部互斥，竞争仍在 C++ 实现层，极少概率出现指标“跳变”但不影响系统功能。 | 低 |
| **测试覆盖不足** | 新增逻辑（prefill client注入、Metric cleanup、`record_prefill_worker_full`）未在现有单元测试中覆盖，可能在特殊 disaggregated 场景或 NATS 不可达时出现未捕获 panic。 | 中 |

---

## 💡 关注建议

| 建议 | 说明 |
|------|------|
| **防止重复注册** | 在 `HttpServiceConfigBuilder::new` 里使用 `registry.try_register` 或在 `register_worker_*` 中检测 `

---

### feat: basic vllm omni pipeline support (#5608)
**SHA**: `76e0e20` | 🔗 [查看提交](https://github.com/ai-dynamo/dynamo/commit/76e0e2076bcc9f825929f7ee8a0669b2bdcce05e)

**🎯 变更类型**：功能增强  
**⚡ 重要程度**：🔴高  
**📋 变更摘要**：本次提交为 Dynamo 添加 vLLM‑Omni 多阶段管线的基础支持。通过新增 CLI 参数 `--omni` 与 `--stage-configs-path`，实现 Omni worker 的初始化、健康检查以及文本生成路径的集成；新增 `OmniHandler` 对接 vLLM‑Omni 的 `AsyncOmni` orchestrator；同时提供示例启动脚本与单阶段配置 YAML，并在依赖列表中加入 `vllm-omni==0.14.0`。目标是让 Dynamo 能够在同一平台上运行 vLLM‑Omni 的文本（后续可扩展至多模态）流水线。

**🎯 影响范围**：  
- `components/src/dynamo/vllm/args.py`、`health_check.py`、`main.py`（核心入口）  
- 新增 `components/src/dynamo/vllm/omni/omni_handler.py`、`__init__.py`（全新处理层）  
- 示例脚本 `examples/backends/vllm/launch/agg_omni.sh` 与 `stage_configs/single_stage_llm.yaml`（文档/示例）  
- `pyproject.toml`（依赖）  

**🔍 技术洞察**：

- **架构影响**  
  - **新增 worker 类型**：在 Dynamo 现有的 `prefill`、`backend`、`multimodal` 三类 worker 基础上，引入 `omni`（同样走 `backend` 组件，但业务职责为多阶段编排）。  
  - **模块解耦**：`OmniHandler` 继承自 `BaseWorkerHandler`，但不调用父类 `__init__`，避免对 `VllmEngineMonitor` 的直接依赖，保持与 vLLM‑Omni 的专有接口 `AsyncOmni` 解耦。  
  - **入口路由**：`main.py` 中的 `init_omni` 在 `config.omni` 为真时走独立路径，完成端点注册、指标收集等与普通 vLLM worker 相同的步骤。  
  - **配置校验**：在 `args.py` 中强制 `--stage-configs-path` 必须配合 `--omni` 使用，防止错误启动。  
  - **健康检查扩展**：新增 `VllmOmniHealthCheckPayload`，通过异步获取 `AsyncOmni` 的 tokenizer 来确定 BOS token，确保 Omni worker 在 Dynamo 健康检查机制下可正常评估。

- **性能影响**  
  - **潜在开销**：`AsyncOmni` 会在内部维护多个 stage 的子引擎，启动与资源调度开销略高于单一 vLLM 引擎；但对外仍保持单一 `generate` 接口，消费者层面性能差异主要取决于 stage 配置（如是否开启并行 TP/PP）。  
  - **异步生成路径**：`OmniHandler.generate` 直接转发 `AsyncOmni.generate`，并在每个阶段输出后进行 token‑slice 过滤，额外的 Python 迭代开销可忽略。  
  - **指标采集**：复用了现有 `setup_metrics_collection`，对 vLLM 与 LMCache 的监控保持一致，未引入额外监控开销。  

- **安全考虑**  
  - **新增外部依赖**：`vllm-omni` 包含 `trust_remote_code` 选项，若用户开启则会执行模型仓库提供的自定义代码，可能带来代码执行风险。建议在生产环境默认关闭或仅在可信模型上使用。  
  - **YAML 配置加载**：`stage_configs_path` 直接由用户提供，内部未显式做 schema 验证；恶意或错误的 YAML 可能导致运行时异常或资源滥用。应在后续版本加入 schema 校验或白名单机制。  
  - **异常处理**：`OmniHandler.generate` 包裹了完整的异常捕获并返回错误 reason，避免未捕获异常导致 worker crash。  

**⚠️ 潜在风险**：

1. **版本兼容性**：`vllm-omni==0.14.0` 与 `vllm==0.14.1` 需保持 ABI/接口兼容，任何上游改动都可能导致运行时 `ImportError` 或属性缺失。  
2. **资源冲突**：`AsyncOmni` 会自行创建子进程/线程并管理 GPU 资源，若与已有的 Dynamo 多卡 TP/PP 配置不匹配，可能出现 GPU 重复分配错误。  
3. **缺失功能**：当前 `OmniHandler` 只支持文本（Tokens）输入，不支持图像、音频等多模态 stage，若用户误以为全功能已就绪可能产生使用困惑。  
4. **健康检查依赖 Tokenizer**：若模型 tokenizer 在初始化时异常，健康检查会回退到默认 BOS=1，可能掩盖真实的模型加载故障。  
5. **未集成 KV Publisher**：日志/缓存同步机制暂未在 Omni 路径实现，可能导致在使用 Dynamo KV 缓存时出现不一致。  

**💡 关注建议**：

- **发布前测试**：在 CI 中加入针对 `--omni` 的端到端测试，覆盖 YAML 解析、启动、生成、异常路径以及健康检查。  
- **安全加固**：  
  - 默认将 `trust_remote_code` 设为 `False`，并在文档中明确说明开启风险。  
  - 对 `stage_configs_path` 加入基本 schema 验证（必填字段、合法数值范围），防止误配置。  
- **监控与日志**：在 `OmniHandler.__init__` 与 `generate` 中加入更细粒度的度量（如每个 stage 的 latency），便于后期性能调优。  
- **资源预检查**：在 `init_omni` 前可调用 `AsyncOmni` 的资源检查 API（若有）确认 GPU、TP/PP 配置不冲突。  
- **文档更新**：在 Dynamo 官方文档中明确标注 Omni worker 目前仅支持文本输入，并给出示例 stage 配置以及常见错误提示。  
- **后续扩展路线**：规划在 `OmniHandler` 中实现多模态 `ModelInput` 分支（Image、Audio），并同步 KV cache 发布器，以逐步完成全链路 Omni 多阶段流水线支持。

---

### feat: Various Mocker Perf improvements + fixes (#5808)
**SHA**: `d22ca52` | 🔗 [查看提交](https://github.com/ai-dynamo/dynamo/commit/d22ca523107bd5a45bbed81ce2ffa1c55d518d2d)

**🎯 变更类型**：功能增强 / 性能优化  
**⚡ 重要程度**：🔴高  
**📋 变更摘要**：  
- 为 Mock 引擎的 `--speedup-ratio` 参数加入 “0 表示无限加速（无模拟延迟）” 的支持，修改文档、参数说明及运行时断言。  
- 大幅重构 KV 缓存管理 (`KvManager`)：去除冗余 `all_blocks` 集合，改为仅使用活动/非活动池判断缓存命中，提升预取成本计算的准确性并避免不必要的集合维护。  
- 调整调度器的模拟函数以在 `speedup_ratio = 0` 时跳过睡眠，实现真正的“无限加速”。  
- `ActiveSequence::reset_with_signal` 语义改为 **“预抢占”**，保留已生成的 token，去除 `already_generated_tokens` 字段，简化状态管理。  

**🎯 影响范围**：  
- `components/src/dynamo/mocker`（CLI 文档 & 参数解析）  
- `lib/llm/src/mocker/kv_manager.rs`（KV 缓存逻辑）  
- `lib/llm/src/mocker/scheduler.rs`（模拟调度与时延计算）  
- `lib/llm/src/mocker/sequence.rs`（序列状态与重置行为）  

**🔍 技术洞察**：

| 维度 | 影响 |
|------|------|
| 架构影响 | - 移除 `KvManager` 中的 `all_blocks` 成员，降低了结构体的复杂度和内存占用，避免了维护三套集合的同步问题。<br>- 通过仅检查 `active_blocks` 与 `inactive_blocks`，缓存命中判断变得更直接，降低了潜在的逻辑错误（如 `all_blocks` 与实际池不一致导致的误判）。<br>- `reset_with_signal` 从“完全重置”转为“预抢占”，简化了序列生命周期管理，减少了对额外字段 (`already_generated_tokens`) 的依赖，使状态机更清晰。 |
| 性能影响 | - **KV 管理**：删除 `HashSet` 插入/删除操作，减少了 O(1) 的额外开销，尤其在高并发模拟场景下可显著降低 CPU 与内存压力。<br>- **预取成本**：新的 `probe_new_blocks` 只计数真正的“首次缺失”块，避免了对已经被淘汰但仍在 `all_blocks` 中的误计，进而使 `PrefillCost` 更贴合实际，调度器可以做更精准的资源分配。<br>- **Speedup Ratio=0**：调度器不再执行 `tokio::time::sleep_until`，实现了“瞬时”执行，极大提升了测试/benchmark 时的运行速度。 |
| 安全考虑 | - 参数断言从 `> 0` 改为 `>= 0`，并在运行时对 `speedup_ratio == 0` 做特判，防止除以零错误。<br>- 删除 `all_blocks` 相关的 `assert!` 检查后，代码路径更简洁，降低了因断言失效导致的 panic 风险。<br>- `reset_with_signal` 不再回写 `already_generated_tokens`，消除了潜在的整数溢出或不一致状态。 |
| 可维护性 | - 文档同步更新，用户现在明确知道 `0` 的含义，降低使用误解。<br>- 移除冗余集合和字段，代码行数下降、注释更聚焦，后续维护成本降低。<br>- 关键函数（`probe_new_blocks`、`get_prefill_cost`）逻辑更加自解释，易于单元测试。 |

**⚠️ 潜在风险**：

1. **兼容性**：旧版依赖 `--speedup-ratio` 必须大于 0 的外部脚本或 CI 配置可能在传入 `0` 时未预期处理，需要同步更新文档或脚本。  
2. **缓存命中判断变更**：去除 `all_blocks` 可能影响到某些依赖 “全局块集合” 的外部插件（若有），需确认没有隐藏的调用。  
3. **预抢占语义**：`reset_with_signal` 现在保留已生成 token，业务层如果仍假设 `generated_tokens` 被清零（如计数器重置）可能出现统计偏差，需要在调用方检查。  
4. **并发测试**：`speedup_ratio == 0` 将导致仿真循环几乎没有等待，若上层仍依赖时间分片进行负载控制，可能出现资源争用或过度调度的突发。  

**💡 关注建议**：

- **文档与 CI**：更新所有使用 `--speedup-ratio` 的 CI 配置、benchmark 脚本以及用户手册，明确 `0` 为无限加速并提醒其对资源消耗的影响。  
- **回归测试**：加入针对 `speedup_ratio = 0` 的完整集成测试，验证调度器、KV 管理、序列预抢占在高并发下的行为一致性。  
- **监控指标**：在模拟器中添加 `speedup_ratio` 为 0 时的 “无延迟” 标记，以便在生产/benchmark 环境中区分真实延迟与模拟加速。  
- **兼容层**：如担心外部插件仍需 `all_blocks`，可以提供一个受限的只读视图函数 `KvManager::all_blocks_view()`（返回只读迭代器），保持向后兼容而不重新引入集合。  
- **代码审查**：关注 `reset_with_signal` 调用方是否仍依赖 `already_generated_tokens`，必要时在该方法上添加 `#[deprecated]` 标记并提供迁移指引。  

--- 

*以上分析基于提交的代码差异，已涵盖架构、性能、安全和可维护性等关键维度，供项目维护者参考。*

---

### feat: sccache metrics (#5177)
**SHA**: `04ec58c` | 🔗 [查看提交](https://github.com/ai-dynamo/dynamo/commit/04ec58c7ee15b4fbc4f01b57ca6c02d77a806106)

**🎯 变更类型**：功能增强  

**⚡ 重要程度**：🔴高  

**📋 变更摘要**  
- 在 `.github/scripts/parse_buildkit_output.py` 中新增 `parse_sccache_json_from_log`，能够从 BuildKit 日志中提取被 `container/use-sccache.sh` 包裹的 SCCACHE JSON 统计块，生成统一的指标结构并聚合到最终的 BuildKit JSON 报表。  
- `container/use-sccache.sh` 现在在每次 `show_stats` 后输出两段标记 (`=== SCCACHE_JSON_BEGIN ===` / `=== SCCACHE_JSON_END ===`) 包含 JSON 格式的 SCCACHE 统计信息，并加入时间戳和 section 元数据。  

**🎯 影响范围**  
- CI/CD 解析层：`.github/scripts/parse_buildkit_output.py`（负责把 BuildKit 日志转成结构化 JSON）  
- 构建容器脚本：`container/use-sccache.sh`（在每个构建阶段输出 SCCACHE 统计）  
- 依赖此脚本的任何上游报告/仪表盘（例如 PR 检查、性能仪表盘）  

**🔍 技术洞察**  

- **架构影响**  
  - **数据流扩展**：原本只解析 BuildKit 的缓存步骤信息，现在额外捕获 SCCACHE 编译缓存统计，形成 `container.sccache_*` 字段。整体架构仍保持单向日志‑>JSON 转换，未引入新的服务或进程。  
  - **模块解耦**：`parse_sccache_json_from_log` 被设计为独立函数，便于单元测试和未来复用（如在本地调试或其他 CI 环境）。  
  - **向后兼容**：若日志中缺失 SCCACHE 标记，解析器会安全返回空列表，后续逻辑以 `sccache_available` 标志区分，保持对旧版日志的兼容。  

- **性能影响**  
  - **CPU**：新增的正则搜索 (`re.findall`) 与 JSON 解析只在出现 SCCACHE 标记时触发，日志中通常只有少数块（每个阶段一次），对整体 CI 时长影响在毫秒级。  
  - **I/O**：`use-sccache.sh` 在 `sccache --show-stats` 基础上再输出一次 JSON，额外约 1‑2 KB 的文本，几乎不影响磁盘/网络写入。  
  - **内存**：解析阶段会把每个 JSON 块转成 Python dict，数量极少（几到十个），内存占用可忽略。  

- **安全考虑**  
  - **信息泄露**：SCCACHE 统计仅包含缓存命中/失误、耗时等性能数据，不会暴露源码、凭证或系统路径。标记中加入的 `timestamp` 为 UTC 时间戳，同样不涉及敏感信息。  
  - **输入验证**：解析器对 JSON 解析使用标准 `json.loads`，并在捕获 `JSONDecodeError` 后仅打印调试信息，避免异常导致 CI 死亡。未对外部输入进行执行或系统调用，安全风险极低。  

**⚠️ 潜在风险**  

1. **日志格式变更**  
   - SCCACHE 输出格式（尤其 `--stats-format json`）若在未来版本中改变，现有正则清理（移除 `#<step> <time>` 前缀）可能失效，导致解析失败或产生错误统计。  
2. **正则匹配冲突**  
   - 使用了 `=== SCCACHE_JSON_BEGIN ===` 与 `=== SCCACHE_JSON_END ===` 作为分界，如果其他脚本意外输出相同标记，可能把非 SCCACHE 内容当作统计块。  
3. **大日志导致正则耗时**  
   - 在极端情况下（上百 MB 的 BuildKit 日志），一次性 `re.findall` 可能消耗可观的 CPU；不过此类日志在 CI 中极少见。  
4. **错误的聚合逻辑**  
   - 当前聚合仅对 `cache_hits`、`cache_misses`、`compile_requests` 进行求和，未考虑跨阶段的重复计数（如果同一编译请求出现在多个阶段），导致“看起来”命中率偏高。  

**💡 关注建议**  

| 对象 | 建议 |
|------|------|
| **开发者** | - 为 `parse_sccache_json_from_log` 添加单元测试，覆盖无标记、单块、多块、以及 malformed JSON 场景。<br>- 在 `use-sccache.sh` 中将标记字符串抽取为常量，便于统一修改。<br>- 考虑在脚本首部加入 `set -euo pipefail`，防止意外错误导致脚本提前退出。 |
| **CI 维护者** | - 在 CI 配置中显式声明 `sccache` 版本，确保 `--stats-format json` 的行为保持一致。<br>- 若日志体积显著增长，可改为流式读取（逐行匹配 `SCCACHE_JSON_BEGIN`/`END`），避免一次性正则导致内存峰值。 |
| **使用者（仪表盘/报告）** | - 使用 `container.sccache_available` 作 guard，避免在缺失 SCCACHE 统计时出现空指针。<br>- 当聚合的 `aggregate_hit_rate_percent` 与业务预期偏差较大时，检查是否出现了跨阶段重复计数或日志截断。 |
| **安全审计** | - 定期检查 `use-sccache.sh` 输出的标记是否被其他脚本误用，防止信息混淆。<br>- 确认 `timestamp` 使用 UTC，避免时区泄漏。 |

总体来看，此次变更为 Dynamo 项目引入了对 **SCCACHE** 编译缓存的可观测性，提升了构建性能分析的深度，风险可控，只需在后续版本中关注日志格式兼容性并补充相应测试即可。

---

### fix: fuse unfold streams to prevent panics from poll after termination (#5872)
**SHA**: `7beb5f1` | 🔗 [查看提交](https://github.com/ai-dynamo/dynamo/commit/7beb5f1ad020682037ec79d2180676f2a22b3582)

**🎯 变更类型**：Bug修复  
**⚡ 重要程度**：🔴高  
**📋 变更摘要**：在 LLM 子模块的多个流组合点加入 `.fuse()`，防止在流已结束后再次 `poll` 导致的运行时 panic。此改动通过 `StreamExt::fuse` 将已终止的 `Stream` 包装为“永远返回 `Poll::Ready(None)`”，从而提升库的鲁棒性。  

**🎯 影响范围**：  
- `lib/llm/src/backend.rs`（LLM 引擎输出流的后处理）  
- `lib/llm/src/migration.rs`（迁移层对响应流的包装）  
- `lib/llm/src/preprocessor.rs`（OpenAI 预处理器的嵌入与聊天流）  

**🔍 技术洞察**  

- **架构影响**  
  - 这些文件均位于 `llm` 核心层，负责把底层模型的异步输出转为统一的 `Stream`。加入 `.fuse()` 只是在流的最后一步包装，不改变现有的抽象接口或业务逻辑，但在整体流管线中增加了“安全阀”。  
  - 通过统一的 `fuse` 处理，减少了对调用方手动追踪流结束状态的依赖，使得流的生命周期管理更加明确，提升了模块之间的解耦度。  

- **性能影响**  
  - `StreamExt::fuse` 本身是零开销的状态包装，仅在内部维护一个 `bool` 标记，后续每次 `poll` 直接返回 `Ready(None)`。因此对吞吐量、延迟几乎没有可感知的影响。  
  - 额外的 `.fuse()` 调用可能在极端高并发的场景下产生极微小的函数调用开销，整体可以忽略不计。  

- **安全考虑**  
  - 原来的实现在流结束后再次 `poll` 会触发 `panic!`，相当于在生产环境中产生不可恢复的崩溃，潜在构成 **拒绝服务**（DoS）风险。`fuse` 将 panic 转化为安全的空流返回，显著提升了运行时的容错能力。  
  - 不涉及网络、加密或权限校验等直接安全功能，但通过防止意外 panic，间接提升了系统整体的安全可靠性。  

**⚠️ 潜在风险**  

1. **行为兼容性**  
   - 旧代码如果依赖于流结束后 panic 来捕获错误（例如在单元测试中使用 `assert!(!stream.next().await.is_some())`），现在将改为平滑结束，可能导致测试失效。  
2. **错误掩盖**  
   - `fuse` 会把错误的 “再次 poll 已结束流” 直接吞掉，若上层逻辑本应在此时记录或上报异常，可能失去诊断信息。  
3. **Trait 导入**  
   - `fuse` 属于 `futures::stream::StreamExt`，如果在其他地方忘记引入该 trait，代码编译会报错。虽然此 PR 已通过编译，但未来的维护者需注意 `use futures::stream::StreamExt;`。  

**💡 关注建议**  

- **完善测试**：在 `llm` 相关模块新增 **流结束后再次 poll** 的集成测试，确保 `fuse` 行为符合预期，且不会导致意外的资源泄漏。  
- **文档更新**：在 `README` 或模块注释中说明返回的 `Stream` 已经 `fuse`，调用方不需要自行处理 “已终止后继续 poll” 的情况。  
- **监控与日志**：若业务方仍希望监控非法的重复 `poll`，可以在自定义 `Stream` 实现中加入日志，而不是直接 panic。考虑在 `fuse` 前后加入调试日志，以便回溯异常来源。  
- **审计其它流**：审查代码库中其他未 `fuse` 的流组合点（尤其是 `Box::pin(...).into_stream()` 之类的），统一使用 `fuse` 以保持行为一致。  
- **回滚策略**：如果在极少数场景下出现业务逻辑依赖 panic 的回退机制，提供配置开关（`#[cfg(debug_assertions)]`）临时保留原行为，便于平滑迁移。  

通过上述措施，可确保此次 **防止流终止后 panic 的修复** 在提升可靠性的同时，保持系统的兼容性与可观测性。

---

#### 🟡 中重要度变更 (7)

### ci: Using Dynamo Builder (#5914)
**SHA**: `6ac17b9` | 🔗 [查看提交](https://github.com/ai-dynamo/dynamo/commit/6ac17b995a98af08efa8c4d669044b4e62554f61)

**🛠️ 变更类型**：功能增强 / CI 重构  
**🎯 影响范围**：GitHub Actions 工作流、构建/发布镜像、K8s 部署验证、CI 测试、`container/build.sh` 脚本  

| 关键改动 | 目的/影响 |
|---|---|
|`bootstrap-buildkit`、`init-dynamo-builder`、`route_buildkit.sh`|在 CI 中自动发现并路由 BuildKit Pod（远程 vs K8s driver），统一 builder 创建/bootstrapping，提升 Layer‑Cache 命中率。|
|`docker-remote-build`|把 `docker‑build` 拆分为 “远程” 版，支持多 tag、可选推送、SCCache、no‑cache 等细粒度开关，统一日志/metrics。|
|`skopeo‑copy / skopeo‑login`|跨 ECR↔ACR 镜像复制，避免 Docker‑pull‑push 的冗余网络开销。|
|`dynamo-deploy-test`|完整的 K8s DynamoGraphDeployment‑创建‑就绪‑请求‑结果‑清理流程，输出日志/summary，便于 PR Check。|
|`build-test-distribute-flavor‑matrix.yml` + `build-test-distribute-flavor.yml`|将每个框架的 **Build → Test → Copy** 流程抽象为矩阵，可灵活指定平台、CUDA、额外 tag，统一 Builder‑Name。|
|CI workflow (`pr.yaml`)|改为统一 `builder_name`、使用新 `init‑dynamo‑builder`、去除旧 `docker‑build`、加入 operator 多‑arch 镜像一次性推送、增加健康‑pod 报告、统一清理步骤。|
|`container/build.sh`|新增 `PRIMARY_TAG` 变量、支持 `--tag` 多次指定、对 `--make-efa` 使用 primary tag，提升多 tag 构建的可靠性。|

### 关键风险 / 建议

1. **Builder 命名冲突**  
   - `BUILDER_NAME` 采用 `run_id‑run_attempt`，但同一次 PR 可能并行启动多个矩阵作业，仍可能出现同名冲突。建议在 `init‑dynamo‑builder` 中加入唯一前缀（如 `${{ github.job }}`）或在 `bootstrap‑buildkit` 中检测已存在 builder 并自动删除。

2. **远程 BuildKit 失效回退**  
   - `route_buildkit.sh` 在找不到 pod 时会直接退出并使用 Kubernetes driver；但后续步骤仍会尝试 `docker buildx create --append`，若 `builder_name` 已被创建但未成功添加 worker，可能导致 `docker buildx inspect` 失败。建议在 `init‑dynamo‑builder` 完成后再次确认 `docker buildx ls` 中的节点列表，或在 `bootstrap‑buildkit` 捕获错误并回退重新创建。

3. **Skopeo 依赖**  
   - `skopeo‑login` 只在 Debian/RedHat 环境下安装，若 CI runner 使用自定义镜像（比如 `prod‑default‑small‑v2`）不含 `apt`/`dnf`，会导致动作失败。建议在每个使用前先执行 `skopeo --version || true`，或在 repo 根部提供统一的 Dockerfile 作为 CI 环境基底。

4. **nslookup 缺失**  
   - `route_buildkit.sh` 直接 `command -v nslookup`，但在 GitHub‑hosted runner 中默认已装 `bind-tools`，自建 runner 需要确保安装。可在 `init‑dynamo‑builder` 前添加一步 `apt-get install -y dnsutils`（或对应包）。

5. **K8s Namespace 清理**  
   - `cleanup` 作业仅删除 `dynamographdeployments`，但 Helm‑release 本身 (`dynamo-platform`) 仍会残留。已在 `cleanup` 中 `helm uninstall`，但超时 `--timeout 10m` 仍可能留下资源。建议在 `helm uninstall` 后添加 `kubectl wait --for=delete namespace/$NAMESPACE --timeout=300s`，确保命名空间真正回收。

6. **并行 Pytest 与 dind**  
   - 新 `pytest` 动作默认走 sidecar (`dind_as_sidecar=true`) 并开启 `--dist=loadscope`。这依赖宿主机的 `/dev/shm` 大小，部分自建 runner 可能不足导致 OOM。可在调用前显式 `docker run --shm-size=2g`，或在 CI YAML 中提供 `docker_opts` 参数。

7. **`container/build.sh` 多 tag 兼容**  
   - `PRIMARY_TAG` 用于 `--make-efa`，但在 `docker‑remote‑build` 仍向 `docker buildx build` 传递原始 `$TAG`（可能为空），导致 EFA stage 计算出错。建议在 `docker‑remote‑build` 里统一使用 `PRIMARY_TAG`，或在 `build.sh` 中若 `$TAG` 为 “--tag dynamo:… ” 仍能解析出 primary tag。

8. **文档与 README**  
   - 新增大量复合 Action，需在 `README.md` 中补充使用示例、必填/选填字段说明，尤其是 `builder_name`、`flavor`、`cuda_version` 的合法组合。

### 总结

本次提交显著提升了 CI 的可扩展性与镜像缓存利用率，统一了 Builder 管理、构建、复制与部署验证流程。但涉及多个跨系统交互（BuildKit DNS、K8s helm、skopeo、dind）后，需要在自建 runner 环境做好依赖准备，并在 Builder 名称、错误回退、资源清理方面加入更健壮的防御逻辑。完成上述细化后，整个流水线将在多平台（amd64/arm64）和多 CUDA 版本下保持高效、可靠的 CI/CD。

---

### fix: Add mpi arg to all srun commands (#5948)
**SHA**: `910d74f` | 🔗 [查看提交](https://github.com/ai-dynamo/dynamo/commit/910d74f59e61473cc11c060fb8bec3ed28e105a8)

**🎯 变更类型**：Bug 修复  
**⚡ 重要程度**：🟡 中  

**📋 变更摘要**  
在 `examples/basics/multinode/trtllm` 目录下的两个启动脚本 `srun_aggregated.sh` 与 `srun_disaggregated.sh` 中，为所有 `srun` 调用统一添加了 `--mpi pmix` 参数，使得在 Slurm 环境下使用 PMIx 作为 MPI 启动层，以确保多节点 TRT‑LLM 服务的正确通信。

**🎯 影响范围**  
- 仅影响示例脚本，属于用户侧的运行方式；核心库代码未改动。  
- 对使用 Slurm ≥ 20.11（已内置 PMIx）且依赖 MPI 的多节点 TRT‑LLM 示例有直接影响。  

**💡 关注建议**  
1. **兼容性检查**：部分旧版 Slurm（如 19.x）可能不支持 `--mpi pmix`，使用前请确认 Slurm 版本或在脚本中加入判断/回退逻辑。  
2. **文档同步**：更新 README 或示例文档，说明新参数的作用及所需的 Slurm/MPI 环境（PMIx 必须已安装）。  
3. **测试验证**：在实际集群上跑一次完整的多节点 TRT‑LLM 示例，确认前端服务能够成功启动且进程间通信正常。  
4. **用户提示**：若脚本在非容器环境或不使用 PMIx，建议提供 `--mpi none` 或删除该参数的可选说明，避免误报错误。  

总体而言，此次改动通过显式指定 MPI 启动方式，提高了多节点 TRT‑LLM 示例在现代 Slurm 集群上的可靠性，但需注意老版本 Slurm 的兼容性并在文档中做好说明。

---

### fix: update aiperf version (#5982)
**SHA**: `16956ac` | 🔗 [查看提交](https://github.com/ai-dynamo/dynamo/commit/16956ac60b052dbb227ada32924118dc922ad10e)

**🎯 变更类型**：Bug 修复 / 依赖更新  
**⚡ 重要程度**：🟡 中（兼容性风险有限，但可能影响运行环境）  
**📋 变更摘要**：将 `container/deps/requirements.txt` 中的 `aiperf` 依赖从提交 `54cd6dc820bff8bfebc875da104e59d745e14f75` 更新到 `40530ed231fb01ae1cfe3c9d22e43a0e7143780b`，以同步上游修复或功能改进。  

**🎯 影响范围**：  
- **容器镜像构建**：`Dockerfile` 会在重新构建时拉取新版本的 `aiperf`。  
- **Python 运行时**：所有调用 `aiperf` 的模块（如性能监控、数据采集）将使用更新后的代码。  
- **CI/CD 流水线**：重新生成的依赖锁文件可能导致缓存失效，需要重新安装依赖。  

**💡 关注建议**：  
1. **兼容性检查**：在本地或测试环境重新 `pip install -r requirements.txt`，确认新提交未引入 API 变更或破坏向后兼容。  
2. **回滚准备**：保留旧的提交哈希，以便在发现问题时快速回滚 `requirements.txt`。  
3. **文档同步**：若 `aiperf` 的行为或配置项有改动，请更新相应的使用文档或示例代码。  
4. **CI 缓存更新**：在 CI 中清理或更新 pip 缓存，以避免因旧缓存导致的构建错误。  

总体而言，此次更新主要是对依赖的细粒度修正，对业务逻辑影响不大，但建议在测试环境完成完整回归验证后再推广到生产。

---

### chore: use aiperf utils in prefix synthesizer (#5906)
**SHA**: `4fcee92` | 🔗 [查看提交](https://github.com/ai-dynamo/dynamo/commit/4fcee92f600acb33747e8fbec8560b93a6cd997f)

**变更类型**：🛠️ 重构 / 迁移  
**重要程度**：🟡 中  

**变更摘要**  
本次提交将 `prefix_data_generator` 目录下用于前缀合成的工具全部迁移到统一的 `aiperf` 包中，改用 `aiperf.dataset.synthesis.RollingHasher` 与 `aiperf.dataset.synthesis.rolling_hasher.texts_to_hashes`。相应地更新了多个 benchmark 脚本的 import、调用方式，并把原有的 protocol 常量、`hasher.py`、`protocols.py`、测试文件以及示例脚本全部删除，改用 `aiperf` 中的实现。`pyproject.toml` 也同步到了新版 `aiperf` commit。

**影响范围**  
- `benchmarks/burstgpt_loadgen/convert.py`、`benchmarks/nat_trace/convert.py`、`benchmarks/sin_load_generator/sin_synth.py`  
- `benchmarks/prefix_data_generator` 代码（graph_utils、synthesizer）  
- 文档 `benchmarks/prefix_data_generator/README.md`  
- 依赖版本（`aiperf`）  

**关注建议**  
1. **API 兼容性**：确认 `RollingHasher` 在 `aiperf` 中提供的 `hash_token_blocks` 与原有 `__call__` 行为一致，尤其是对输入形态（序列、tuple）和返回的 hash 顺序。若有差异，可能导致已有 benchmark 结果偏差。  
2. **常量同步**：`graph_utils.py` 中手动复制了 `SUPER_ROOT、CACHE_END、END_NODE`，确保这些值与 `aiperf` 中定义保持一致，防止图结构逻辑错误。建议直接 `from aiperf.dataset.synthesis import constants` 引入。  
3. **文档与示例**：已删除 `example.py`，但 README 仍提及示例工作流。更新 README，指向新的 `aiperf` 示例或提供简易脚本，以免用户误入 dead‑link。  
4. **测试覆盖**：原有单元测试 `test_hasher.py` 被删除，建议在本仓库新增或迁入对应的集成测试，验证 `texts_to_hashes`、`hashes_to_texts` 与 `RollingHasher` 的端到端行为。  
5. **依赖锁定**：`pyproject.toml` 中的 `aiperf` commit 已升级，确保 CI 环境可以顺利拉取对应代码；若未来 `aiperf` 继续演进，建议使用 tag/semver 而非 commit，以提升可复现性。  

**后续检查**  
- 运行所有 benchmark，确认生成的 `mooncake` 数据结构与旧实现保持相同的前缀覆盖率与统计信息。  
- 在不同 tokenizer（例如 DeepSeek、Llama）上跑一次 `texts_to_hashes` 与 `hashes_to_texts`，确保 token 长度匹配、BOS/EOS 处理符合预期。  

总体来看，此次迁移统一了工具链，降低了维护成本，只要上述兼容性检查和文档同步完成，影响应当可控。

---

### fix: Wrap default_multimodal_input_loader in asyncio.to_thread (#5945)
**SHA**: `eff08ae` | 🔗 [查看提交](https://github.com/ai-dynamo/dynamo/commit/eff08aed05036662c8957f9fdfc583a083a18219)

**🎯 变更类型**：Bug 修复 / 性能优化  
**⚡ 重要程度**：🟡 中  

**📋 变更摘要**  
- 在 `encode_helper.py` 与 `multimodal_processor.py` 中，对 `default_multimodal_input_loader` 的调用加入 `await asyncio.to_thread(...)` 包装。  
- 这样把原本同步的图片下载与预处理迁移到线程池，避免在 async 路由里阻塞事件循环，从而提升高并发场景的吞吐量。  

**🎯 影响范围**  
- `components/src/dynamo/trtllm/encode_helper.py`  
- `components/src/dynamo/trtllm/multimodal_processor.py`（新增 `import asyncio`）  
- 任何依赖 `default_multimodal_input_loader` 的异步入口（如 OpenAI‑compatible 接口）都会受此改动影响。  

**💡 关注建议**  
1. **线程安全**：`default_multimodal_input_loader` 里会复用 `tokenizer`，确认该对象在多线程环境下是线程安全的；如有状态写入，建议在每次调用前复制或使用 `tokenizer.clone()`。  
2. **异常传播**：`asyncio.to_thread` 会把子线程抛出的异常重新抛到协程上，确保上层 `try/except` 能捕获并返回合适的错误码。  
3. **性能基准**：在高并发压测（>200 RPS）下对比前后吞吐与 latency，确认线程池大小（默认由 `concurrent.futures.ThreadPoolExecutor` 决定）没有成为瓶颈。  
4. **平台兼容**：Windows 与 macOS 的线程调度略有不同，建议在 CI 中加入跨平台的异步调用测试。  
5. **代码可读性**：若后续还有其他同步 I/O（如文件读取），可以统一抽象为 `run_in_thread(fn, *args, **kwargs)`，避免多处 lambda 嵌套。  

整体来看，此次改动降低了事件循环的阻塞风险，提升了多请求场景下的并发能力，只要关注上述线程安全与异常处理，即可安全上线。

---

### fix: update disagg tracing screenshot and description (#5956)
**SHA**: `f3bea5d` | 🔗 [查看提交](https://github.com/ai-dynamo/dynamo/commit/f3bea5d557159b89a1d2c3b4b18ede9be78b54b4)

**变更类型**：文档更新（修正）  
**重要程度**：🟡 中  
**变更摘要**：更新了 `docs/observability/logging.md` 中的分布式追踪说明，重新组织了 span 列表，补充了每类 span 的属性解释及指标含义；同步更新了配套的 Grafana 截图 `grafana-disagg-trace.png`。  

**影响范围**  
- `docs/observability` 章节（主要面向运维与开发者的可观测性文档）  
- 与该文档对应的 CI 检查（markdown 渲染、链接有效性）  

**核心分析**  
1. **内容完整性**：新文档细化了四类关键 span（http‑request、prefill_routing、prefill worker、decode worker），并对 `Duration/Busy Time/Idle Time` 的关系作出解释，帮助用户快速定位瓶颈。  
2. **格式一致性**：采用了 Markdown 标题层级（`####`、`#####`）以及表格展开，整体排版清晰；但需要检查标题层级在 GitHub 渲染时是否出现跳级（`####` 后直接 `#####`），建议统一为 `###`、`####` 以保持结构平衡。  
3. **链接与引用**：文档开头仍保留旧的 “Disaggregated Trace Example” 链接，但未更新图片路径，实际图片已在 PR 中替换。应确认 `![Disaggregated Trace Example](grafana-disagg-trace.png)` 能在仓库根目录或相对路径下被正确解析。  
4. **时效性**：示例 trace ID、时间戳为未来日期（2025‑10‑31），若不影响说明可保留；否则建议替换为占位符或使用 `{{example}}` 标记，以免误导阅读者。  
5. **CI/文档检查**：无代码改动，不涉及二进制兼容；唯一风险是 markdown 渲染错误或图片未随发布包同步。建议在 CI 中加入图片大小检查或链接有效性校验。

**建议**  
- 统一标题层级，避免 `####` 后直接 `#####` 产生结构不对称。  
- 将示例时间/ID 替换为占位符，或在文档中说明“此为示例”。  
- 确认图片路径在发布后仍有效，若图片放在 `docs/observability/` 子目录，需在链接中加上相对路径。  
- 在 CI 中加入 `markdown-link-check` 或类似工具，防止未来文档更新忘记同步图片。  

总体来看，此次 PR 只涉及文档层面的改进，对运行时行为无影响，提升了用户对分布式追踪的可理解性，建议合并。

---

### chore: rename terminate_existing to terminate_all_matching_processes (#5923)
**SHA**: `e55ebec` | 🔗 [查看提交](https://github.com/ai-dynamo/dynamo/commit/e55ebec56224424a906cfb0028620c7e0709351d)

**🎯 变更类型**：功能增强（API 重命名 & 行为说明）  
**⚡ 重要程度**：🟡 中  
**📋 变更摘要**：  
1. 将 `ManagedProcess` 与各测试用例中使用的参数 `terminate_existing` 重命名为 `terminate_all_matching_process_names`，并在实现层面加入了更详细的注释与安全提示。  
2. 为进程终止逻辑补充了 **SIGTERM → 等待 → SIGKILL** 的分步说明，并在 `__exit__`、`_terminate_process_group`、`_terminate_all_matching_process_names` 中实现了对应的超时与日志记录。  
3. 大量测试文件同步更新调用方参数，确保 CI 通过。

**🎯 影响范围**：  
- `tests/**`：所有涉及 `ManagedProcess` 的单元/集成测试。  
- `tests/utils/managed_process.py`：核心实现改动，新增 `terminate_all_matching_process_names` 字段及相关清理逻辑。  
- `tests/utils/engine_process.py`、`tests/utils/engine_process.py`、`tests/frontend/**`、`tests/router/**`、`tests/kvbm_integration/**` 等多处调用点。  

**💡 关注建议**：  
- **向后兼容**：如果库仍被外部项目直接使用，建议保留旧参数的别名或在 `ManagedProcess.__init__` 中检测 `terminate_existing` 并映射到新字段，以免突发 CI 失败。  
- **安全默认**：考虑将 `terminate_all_matching_process_names` 的默认值改为 `False`，并在文档/README 中明确说明在并行（pytest‑xdist）环境下必须关闭该开关，否则会误杀其他测试进程。  
- **文档同步**：更新项目的使用手册、示例代码以及 `README.md` 中关于 `ManagedProcess` 参数的说明，加入 **“不安全 for parallel execution”** 的警告。  
- **测试覆盖**：增加一组专门验证 `terminate_all_matching_process_names=True` 时的行为（如确保只在单进程 CI 环境下运行），防止未来改动再次破坏并行安全性。  

总体而言，此次重命名提升了参数语义并加入了更细致的终止策略说明，但务必注意默认安全性和向后兼容，以免在并行测试或用户自定义脚本中产生意外进程 termination。

---

#### 🟢 低重要度变更 (4)

### docs: fix markdown formatting in Distributed_Inference README (#5947)
**SHA**: `ef29294` | 🔗 [查看提交](https://github.com/ai-dynamo/dynamo/commit/ef292944fdda00f08448ea0eac801884cacb9f3e)

**🎯 变更类型**：文档更新  
**⚡ 重要程度**：🟢 低  
**📋 摘要**：在 `examples/basics/kubernetes/Distributed_Inference/README.md` 中新增一个空行，修复 Markdown 换行导致的格式错位问题。

---

### chore: Increase E2E 1-GPU Test Timeout (#5888)
**SHA**: `051f18a` | 🔗 [查看提交](https://github.com/ai-dynamo/dynamo/commit/051f18a417e3fce3dfb4c195c5cca010584c4a85)

**🎯 变更类型**：配置调整  
**⚡ 重要程度**：🟢低  
**📋 摘要**：将 E2E 单 GPU 测试的 `pytest` 时长阈值从 10 提升至 20，并将 CI 中对应的超时时间从 120 min 增至 180 min；同时去除 `test_trtllm.py` 中冗余的 `post_merge` 标记。

---

### chore: linux gate lib/memory (#5942)
**SHA**: `67df006` | 🔗 [查看提交](https://github.com/ai-dynamo/dynamo/commit/67df0065d26e36587fefa244e70c9463cc2803cd)

**🎯 变更类型**：代码重构  
**⚡ 重要程度**：🟢低  
**📋 摘要**：为 `DiskStorage` 添加 `#[cfg(target_os = "linux")]` 条件编译，限制其仅在 Linux 上编译；相应测试也加上同样的条件。这样避免在非 Linux 平台出现未实现的模块。

---

### docs: update support matrix with backend dependencies for Dynamo 0.9.0 + 1.0.0 (#5932)
**SHA**: `4d9e64a` | 🔗 [查看提交](https://github.com/ai-dynamo/dynamo/commit/4d9e64a2c1f0250523a2c7b71e1f058ae97b445d)

**🎯 变更类型**：文档更新  
**⚡ 重要程度**：🟢低  
**📋 摘要**：在 *support‑matrix* 中新增 0.9.0 与 1.0.0 版本的后端依赖，调整表格顺序并加入 “Version Labels” 与 “Version Compatibility” 说明，提醒 TensorRT‑LLM 不兼容 Python 3.11。

---

