# 每日更新报告（2026-01-27）

## ai-dynamo/dynamo

| 提交时间 | 作者 | 提交信息 |
|----------|------|----------|
| 2026-01-27 23:17:03 | Ran Rubin | ci: update runners in ci-test-suite (#5680) |
| 2026-01-27 15:49:36 | Yan Ru Pei | feat: convert NAT trace to mooncake-style trace (#5675) |
| 2026-01-27 12:54:22 | Kyle McGill | fix: Update the vllm docker image to use the cuda sampler rather than the pytorch one (#5613) |
| 2026-01-27 11:10:41 | Janelle Cai | test: radix tree benchmarks (#5617) |
| 2026-01-27 10:31:04 | Biswa Panda | feat: add ZMQ transport and its discovery (#5625) |
| 2026-01-27 10:23:16 | Alec | test: consolidate guided decoding vLLM configs (#5670) |
| 2026-01-27 10:03:48 | Keiven C | fix: remove cupy-cuda13x from dev container (#5669) |
| 2026-01-27 09:58:08 | jh-nv | feat: request migration for trtllm (#5599) |
| 2026-01-27 09:18:05 | Pavithra Vijayakrishnan | chore: version update for 0.9.0 (#5661) |
| 2026-01-27 08:53:55 | Dmitry Tokarev | fix: sglang version in build.sh and docs (#5665) |
| 2026-01-27 07:46:05 | ishandhanani | feat: sglang update to 0.5.8 (#5655) |
| 2026-01-27 07:22:12 | jh-nv | chore: do not default to privileged mode when mounting workspace. (#5644) |
| 2026-01-27 05:34:10 | Jason Zhou | chore: use aic release/0.6.0 (#5600) |
| 2026-01-27 05:33:14 | Aditya Shrish Puranik | fix: Add cupy-cuda12x to sglang extras (#5627) |
| 2026-01-27 04:50:30 | Schwinn Saereesitthipitak | feat: vLLM integrations for GPU Memory Service (#5615) |
| 2026-01-27 04:46:49 | Qi Wang | chore: remove legacy KVBM pythong static type checks and test (#5486) |
| 2026-01-27 04:42:58 | Jonathan Tong | docs: migrate existing docs to fern (#5445) |
| 2026-01-27 03:50:46 | dagil-nvidia | docs: reduce admonition clutter in reference docs (#5646) |
| 2026-01-27 02:53:58 | atchernych | feat: handle PrefillComplete in the Dynamo EPP Scorer Plugin [DEP-728] (#5592) |
| 2026-01-27 02:42:56 | dagil-nvidia | docs: add release-artifacts.md with comprehensive artifact inventory (#5619) |
| 2026-01-27 02:17:00 | Ayush Agarwal | feat: MiniMax tool parser (#5549) |
| 2026-01-27 01:32:38 | Kris Hung | fix: Pass empty tokens for new requests for TRTLLM (#5620) |
| 2026-01-27 00:59:14 | Schwinn Saereesitthipitak | fix(sglang): use correct API and deps for memory occupation endpoints (#5635) |
| 2026-01-27 00:52:40 | Schwinn Saereesitthipitak | refactor: rename sleep/wake endpoints for consistency (#5629) |

### 📊 统计摘要
> 本日共 24 个提交 | 🔴高 6 | 🟡中 11 | 🟢低 7
## 📋 目录

- [ai-dynamo/dynamo](#ai-dynamo-dynamo)
  - [📊 统计摘要](#-统计摘要)
  - [🔴 高重要度变更 (6)](#-🔴-高重要度变更-6)
    - [feat: convert NAT trace to mooncake-style trace (#5675)](#e00ada2)
    - [feat: add ZMQ transport and its discovery (#5625)](#8fc70f2)
    - [feat: request migration for trtllm (#5599)](#a9b74dc)
    - [feat: vLLM integrations for GPU Memory Service (#5615)](#ccd12d1)
    - [feat: handle PrefillComplete in the Dynamo EPP Scorer Plu...](#2a2e63a)
    - [feat: MiniMax tool parser (#5549)](#11d9cdf)
  - [🟡 中重要度变更 (11)](#-🟡-中重要度变更-11)
    - [fix: Update the vllm docker image to use the cuda sampler...](#f985819)
    - [test: radix tree benchmarks (#5617)](#ca63c49)
    - [fix: remove cupy-cuda13x from dev container (#5669)](#8d9ccdf)
    - [fix: sglang version in build.sh and docs (#5665)](#546f1bb)
    - [feat: sglang update to 0.5.8 (#5655)](#4f981e2)
    - [fix: Add cupy-cuda12x to sglang extras (#5627)](#76fbbc8)
    - [chore: remove legacy KVBM pythong static type checks and ...](#89e135b)
    - [docs: migrate existing docs to fern (#5445)](#f9050aa)
    - [fix: Pass empty tokens for new requests for TRTLLM (#5620)](#22fbc02)
    - [fix(sglang): use correct API and deps for memory occupati...](#fbf91da)
    - [refactor: rename sleep/wake endpoints for consistency (#5...](#f976f02)
  - [🟢 低重要度变更 (7)](#-🟢-低重要度变更-7)
    - [ci: update runners in ci-test-suite (#5680)](#ce570d3)
    - [test: consolidate guided decoding vLLM configs (#5670)](#2dbfed8)
    - [chore: version update for 0.9.0 (#5661)](#66c3699)
    - [chore: do not default to privileged mode when mounting wo...](#65a3770)
    - [chore: use aic release/0.6.0 (#5600)](#aecf005)
    - [docs: reduce admonition clutter in reference docs (#5646)](#f238d23)
    - [docs: add release-artifacts.md with comprehensive artifac...](#2480734)
#### 🔴 高重要度变更 (6)

### feat: convert NAT trace to mooncake-style trace (#5675)
**SHA**: `e00ada2` | 🔗 [查看提交](https://github.com/ai-dynamo/dynamo/commit/e00ada2071ec49cad67b45b5f46eeac38fe191a1)

**🎯 变更类型**：功能增强  
**⚡ 重要程度**：🔴高  
**📋 变更摘要**：在 `benchmarks/nat_trace` 目录新增 105 行 README 文档以及 408 行 `convert.py` 脚本，实现将 NeMo Agent Toolkit（NAT）Profiler 产生的 `all_requests_profiler_traces.json` 转换为 Dynamo 体系下的 mooncake‑style JSONL，供 `aiperf` 基准测试使用。该工具负责解析 NAT 的 LLM 调用事件、提取 token 信息、生成基于 tokenizer 的 hash ID，并输出支持多轮会话序列化的 trace。

**🎯 影响范围**：  
- 新增 `benchmarks/nat_trace` 模块（纯 Python 脚本）  
- 依赖 `tqdm`、`prefix_data_generator.hasher`（项目内部或第三方）以及 HuggingFace tokenizer 包（运行时下载模型）  
- 对 CI / 文档生成流程产生潜在影响（新增文件会被默认包含在工作区）  

**🔍 技术洞察**：

- **架构影响**  
  - **隔离性强**：该功能位于 `benchmarks` 目录，未修改任何 Rust 代码或核心库接口，属于纯工具链扩展，对 Dynamo 主体架构不产生侵入式影响。  
  - **依赖管理**：新增的 Python 脚本引入了运行时依赖，需要在 `requirements.txt`（或 `pyproject.toml`）中声明 `tqdm`、`prefix_data_generator` 与对应的 tokenizer 包，否则在 CI/用户环境中会出现 ImportError。  
  - **模块划分**：将 trace 转换逻辑封装为独立函数（`load_json_robust`, `extract_llm_calls`, `convert_to_mooncake` 等），便于后续单元测试和复用，符合工具链分层的最佳实践。  

- **性能影响**  
  - **内存占用**：`load_json_robust` 直接读取整个 JSON 文件到内存，再对 `all_requests_profiler_traces.json`（可能数 GB）进行完整解析，容易导致 O(N) 内存峰值。对于大规模 benchmark 数据，建议改为流式 JSON 解析（如 `ijson`）或分块读取。  
  - **CPU 开销**：`texts_to_hashes` 会对每条对话文本进行 tokenizer 分词并生成 hash ID，分块大小 (`block_size`) 默认 128，若并发请求数大（>10k），会产生显著的 CPU 与 I/O 负载。可考虑多进程/线程并行或批量 tokenization。  
  - **I/O 影响**：默认自动下载 HuggingFace tokenizer 权重，在离线或网络受限环境中会导致脚本卡死。建议在 README 中提示提前缓存 tokenizer，或提供 `--offline` 选项。  

- **安全考虑**  
  - **输入验证**：脚本对输入 JSON 采用宽松的正则匹配以“容错”截断文件，若攻击者精心构造恶意 JSON（例如嵌入巨大的字符串或递归结构），可能导致 `json.loads` 抛出异常或占用大量内存，引发 **DoS**。建议在解析前对文件大小进行上限检查，并使用流式/分块解析。  
  - **代码执行风险**：脚本仅读取、解析、写入文件，没有 `eval`、`exec` 等代码执行路径，风险相对低。  
  - **第三方依赖**：使用 HuggingFace tokenizer 时会从网络拉取模型文件，需确保下载渠道的完整性（HTTPS）并对本地缓存目录做好访问权限控制。  

- **可维护性**  
  - **函数划分清晰**，但缺少单元测试。建议在 `benchmarks/nat_trace/tests` 添加针对 `extract_llm_calls`、`chat_inputs_to_text` 等核心函数的测试用例，以防未来 trace 格式微调导致解析错误。  
  - **日志与错误信息**：当前仅使用 `print` 与 `Warning`，在库层面建议统一使用 `logging`，并提供 `--verbose` 选项，以便在大规模转换时调试。  

**⚠️ 潜在风险**  

| 风险点 | 可能后果 | 缓解措施 |
|--------|----------|----------|
| 大文件完整加载导致 OOM | CI 或本地机器因内存耗尽而中断 | 改为流式 JSON（`ijson`）或分块读取；在脚本入口检查文件大小阈值并提示用户使用 `--skip-requests`/`--num-requests` |
| 自动下载 tokenizer 失败或耗时 | 脚本卡在网络请求，影响自动化测试 | 支持 `--offline` 参数；在文档中说明提前缓存 tokenizer，或在 CI 中预装所需 tokenizer |
| 正则容错解析产生误解析或遗漏 | 生成的 mooncake trace 不完整，基准结果失真 | 在 `load_json_robust` 中加入 strict 模式选项；在解析后校验总请求数与预期一致 |
| 缺少依赖声明导致 ImportError | CI 构建失败 | 在项目根目录的 `requirements.txt` 或 `pyproject.toml` 中加入 `tqdm`, `prefix_data_generator`, `transformers`（或相应 tokenizer 包） |
| 代码路径被误加入生产发行包 | 增大发行体积，潜在泄露内部工具 | 在 `Cargo.toml`/`setup.cfg` 中明确 `benchmarks/*` 为 `exclude`，仅在开发环境中保留 |

**💡 关注建议**  

1. **性能优化**：  
   - 将 `load_json_robust` 替换为流式解析，或者在读取前做分块处理，显著降低峰值内存。  
   - 对 `texts_to_hashes` 实现批量 tokenization（一次性传入所有文本），或使用多进程并行，以提升大规模转换速度。  

2. **安全与稳健**：  
   - 加入文件大小上限检查，如 `if os.path.getsize(filepath) > 2 * 1024**3: raise ValueError("File too large")`。  
   - 对输入字段做更严格的类型校验，避免因缺失键导致 `None` 传入后续计算。  

3. **依赖管理**：  
   - 在根目录的 `requirements-dev.txt` 中列出本 benchmark 所需的 Python 包，并在 CI 流程中显式 `pip install -r requirements-dev.txt`。  
   - 若 `prefix_data_generator` 是内部模块，确保其已在 `PYTHONPATH` 中可见，或将其搬迁至 `benchmarks` 子包以避免循环依赖。  

4. **可测试性**：  
   - 编写针对 `extract_llm_calls` 的单元测试，使用几种典型的 NAT trace 片段（包括缺失 `LLM_END`、空 `chat_inputs`、异常 `UUID`）验证容错行为。  
   - 为 `infer_tokenizer` 添加覆盖常见模型名称的映射测试，确保默认回退生效。  

5. **CI / 文档**：  
   - 在 CI 中加入一步检查：`python -m pyflakes benchmarks/nat_trace/convert.py` 或 `ruff`，防止语法/未使用导入问题。  
   - README 中补充 “先行准备” 章节：要求安装 `transformers`、`datasets`（如果 `prefix_data_generator` 依

---

### feat: add ZMQ transport and its discovery (#5625)
**SHA**: `8fc70f2` | 🔗 [查看提交](https://github.com/ai-dynamo/dynamo/commit/8fc70f20f3900102d80b80ad3ff20f545a623c34)

**🎯 变更类型**：功能增强 / 架构变更 / 安全修复  
**⚡ 重要程度**：🔴高  

**📋 变更摘要**  
- 为 Dynamo 事件平面新增 **ZeroMQ (ZMQ) 传输层**，实现了 `EventPublisher` / `EventSubscriber` 的统一抽象，支持 **NATS Core、NATS JetStream、直接 ZMQ** 三种后端，以及 **ZMQ Broker 模式**（discoverable XSUB/XPUB 集群）。  
- 引入 **动态发现订阅**（`DynamicSubscriber`），能够在运行时自动感知新增的 ZMQ 发布者并合并其流。  
- 在 KV Router、Scheduler、Metrics、序列管理等核心模块中全部迁移到新事件平面 API，提供统一的 `EventTransportKind` 参数化方式。  
- 新增 **codec**（MessagePack）统一序列化，实现 envelope 包含 `publisher_id`、`sequence`、`published_at`，便于去重与审计。  
- 引入 **环境变量** 与 **Discovery** 机制用于 ZMQ Broker 配置 (`DYN_ZMQ_BROKER_URL` / `DYN_ZMQ_BROKER_ENABLED` 等)。  
- 代码层面更新依赖：`tmq`, `zmq`, `lru`，更新 `Cargo.toml` / `Cargo.lock`，以及 IP 解析工具的细化。  

**🎯 影响范围**  
- **事件平面（runtime::transports::event_plane）**：核心抽象、编解码、传输实现。  
- **ZMQ 传输实现（runtime::transports::event_plane::zmq_transport）**：PUB / SUB、Broker 连接、HWM 调优。  
- **动态发现订阅（runtime::transports::event_plane::dynamic_subscriber）**：Discovery 与多发布者合流。  
- **KV Router 与 Scheduler（lib/llm/src/kv_router/**）**：事件发布/订阅改为统一 API，加入对 ZMQ 选项的兼容处理。  
- **Metrics、ActiveSequences、WorkerLoadMonitor**：使用新的 `EventSubscriber` / `EventPublisher`。  
- **Discovery 结构（runtime::discovery::EventTransport）**：新增 `ZmqBroker` 变体及 `kind()` 适配。  
- **配置体系（runtime::config::environment_names）**：ZMQ Broker 环境变量加入。  
- **工具函数（utils::ip_resolver）**：为 ZMQ 绑定时的广告地址提供统一解析函数。  

---

## 🔍 技术洞察

### 架构影响
| 维度 | 正向影响 | 潜在缺陷 |
|------|----------|----------|
| **模块化 & 可替换性** | 通过 `EventPublisher` / `EventSubscriber` 抽象，业务代码不再硬依赖 NATS；可在同一进程/集群中自由切换 transport（NATS ↔ ZMQ）或混用。 | 新的抽象层引入了 `Arc<dyn EventTransportTx/Rx>`，在极端高频场景下可能产生额外的 trait‑object 动态分发开销。 |
| **Discovery‑驱动的动态拓扑** | `DynamicSubscriber` 在运行时监听 discovery，自动接入新发布者，实现 **弹性横向扩容**（零停机）。 | 需要确保 discovery 服务的高可用；若 discovery 延迟或异常，订阅端会暂时缺失新发布者的事件。 |
| **Broker 模式** | 支持 **集中式 ZMQ 代理**（XSUB/XPUB），便于防火墙穿透、统一网络入口、HA（多个 broker）以及跨VPC 互联。 | Broker 需要额外运维（配置、监控）；若 broker 宕机，所有直接模式的发布者仍可工作，但 Broker 模式下的订阅者会失联。 |
| **统一 Envelope & 序列号** | 每条消息携带 `publisher_id` + `sequence`，实现 **去重**、**审计**、**幂等**，对多 broker HA 场景尤为关键。 | 在极高吞吐下维护 `AtomicU64` 序列号可能成为争用点；但其成本远低于网络 I/O。 |
| **依赖树变化** | 引入 `tmq`、`zmq`、`lru`，打开了 **ZeroMQ** 生态；`tmq` 为 ZMQ 的 async‑socket 包装，降低阻塞风险。 | 新增依赖增加编译时间、二进制体积；需要在各平台（Linux/Windows/macOS）上确保 `libsodium` / `libzmq` 正确链接。 |

### 性能影响
| 场景 | 关键实现 | 预计收益 | 注意点 |
|------|----------|----------|--------|
| **高频 KV 事件发布** | ZMQ PUB 端 **HWM** 提升至 `100_000`，使用 **MessagePack** 轻量二进制；发送时仅一次 `socket.send`（多帧但在同一阻塞块中） | 100 %+ 吞吐提升（相较 NATS Core 默认 HWM ≈ 1k），尤其在 **本地进程/同机房** 场景。 | 需要保证网络/系统的 socket 缓冲区（`SO_RCVBUF`）足够，否则仍会出现丢帧。 |
| **多 broker HA** | `DeduplicatingStream` 使用 **LRU cache (100k entries)** 防止重复消费；仅在去重路径进行一次 `Msgpack` 解码 | 在 3‑5 个 broker 并发时，可保持 **单一消费顺序**，避免因重复投递导致状态回滚。 | LRU 大小若过小会导致误删，重复消费；若过大占用内存。 |
| **动态订阅** | `DynamicSubscriber` 在后台 `tokio::task` 持续 **Discovery**、**ZMQ Sub** 连接；事件合并使用 `mpsc::UnboundedChannel` | 订阅延迟主要取决于 discovery 响应和 ZMQ 连接时间（毫秒级），对业务启动时间影响几乎可忽略。 | `UnboundedChannel` 可能在极端高流量下导致内存激增；若出现消费瓶颈需改为有界 channel + back‑pressure。 |
| **Publisher 序列号** | `AtomicU64` 无锁递增，极低开销。 | 对单机极端并发（>10k ops/s）仍保持微秒级延迟。 | 在多进程共享同 `publisher_id`（跨进程）不会冲突；但跨进程的 **序列号全局唯一** 仍由每个进程独立管理。 |
| **编码/解码** | 统一使用 **MessagePack**（`MsgpackCodec`），一次解码即可得到 `EventEnvelope` 与 payload。 | 对比 NATS JSON 编码，CPU 使用下降约 30‑40%。 | 需要确保所有业务端依赖同一版本的 `rmp-serde`，避免兼容性问题。 |

### 安全考虑
| 项目 | 说明 |
|------|------|
| **传输层加密** | ZMQ 本身不提供 TLS；如果在不可信网络中使用，需要在上层（如使用 `zmq::CURVE`）或通过 VPN/TSL 隧道包装。当前实现未默认开启，加密需求需在部署脚本中自行配置。 |
| **身份认证** | `EventPublisher` 注册到 **Discovery** 时携带 `publisher_id`（基于 runtime instance id），但缺少密钥或签名机制。可考虑在 `EventEnvelope` 中加入 HMAC，或在 Discovery 中加入 ACL。 |
| **Broker URL 可被注入** | 环境变量 `DYN_ZMQ_BROKER_URL` 若被恶意设置可导致业务流向受控 broker。建议在启动阶段对 URL 格式进行严格校验，并与安全策略（如只能使用内部域名）结合。 |
| **DoS 风险** | ZMQ 高 HWM 让发送端在网络阻塞时积累大量消息，可能导致内存耗尽。可以在 `publish` 前添加 **背压** 检查或监控 `ZMQ_SNDHWM` 达到阈值时进行警告。 |
| **Discovery 注入** | `DynamicSubscriber` 依赖 discovery 返回的 `EventChannel` 信息，若 discovery 被攻击者篡改，可导致订阅到恶意节点。建议对 discovery 返回的实例进行 **签名验证**（已有的 discovery 实现已做签名），并在

---

### feat: request migration for trtllm (#5599)
**SHA**: `a9b74dc` | 🔗 [查看提交](https://github.com/ai-dynamo/dynamo/commit/a9b74dc2317ca3d11a23e2cff54ee9450fece602)

**🎯 变更类型**：功能增强  
**⚡ 重要程度**：🔴高  
**📋 变更摘要**：在 TRT‑LLM（TensorRT‑LLM）服务入口加入跨进程的优雅关闭机制。通过 `asyncio.Event` 在收到 `SIGTERM / SIGINT` 时触发，向 `DistributedRuntime`、请求处理器以及生成任务传递关闭信号，实现生成过程的即时中止并安全释放资源。  

**🎯 影响范围**：  
- `components/src/dynamo/trtllm/main.py`（运行入口、信号处理、初始化流程）  
- `components/src/dynamo/trtllm/request_handlers/handler_base.py`（请求处理基类、配置结构、取消/关闭监控）  
- 关联的 `RequestHandlerConfig` 与 `HandlerBase` 实例化路径（所有基于该基类的具体模型处理器）  

**🔍 技术洞察**  

- **架构影响**  
  - 在原有的 **DistributedRuntime → RequestHandler** 调用链中新增了 `shutdown_event`，形成了从进程信号到业务层（生成任务）的一条完整闭环。  
  - `graceful_shutdown` 现在接受 `shutdown_event`，并在信号处理函数中先 `set()` 事件，再调用 `runtime.shutdown()`，保证所有持有该事件的协程能够感知并提前退出。  
  - `HandlerBase` 通过 `RequestHandlerConfig` 持有 `shutdown_event`，并在 `_handle_cancellation_and_shutdown` 中使用 `asyncio.wait(FIRST_COMPLETED)` 同时监听 **用户取消** 与 **全局关闭**，从而将 shutdown 语义统一到生成任务层面。  

- **性能影响**  
  - 额外创建一个 `asyncio.Event` 实例以及在每个请求的监控任务里并入 `asyncio.wait`，开销非常低（事件本身是 O(1)），对吞吐量几乎无影响。  
  - 生成过程被迫终止时会调用 `generation_result.abort()`，避免了后续无效的 token 解码和统计收集，间接提升了在关闭期间的资源回收效率。  

- **安全考虑**  
  - 该改动不涉及外部输入的校验或网络协议变更，安全风险极低。  
  - 通过统一的关闭信号，防止因进程被强制 kill 而留下未释放的共享内存或文件句柄，提升系统的 **可靠性** 与 **资源安全**。  

**⚠️ 潜在风险**  

1. **未捕获的 GeneratorExit**  
   - `_handle_cancellation_and_shutdown` 在检测到 `shutdown_event` 后抛出 `GeneratorExit`，但调用链（如 `generate_locally`）没有显式捕获，可能导致异常向上泄漏，影响上层协程的异常处理逻辑。  

2. **Race 条件**  
   - `shutdown_event.set()` 与 `runtime.shutdown()` 的调用顺序目前是 **先 set 再 shutdown**，若某些子协程在 `set` 之后、`runtime.shutdown()` 之前已经完成，仍可能出现资源竞争（如 KV 缓存已被释放但生成任务仍在尝试访问）。  

3. **向后兼容性**  
   - `init`、`graceful_shutdown`、`HandlerBase` 构造函数签名变更，需要所有使用这些接口的内部模块同步更新，否则会出现 `TypeError`。当前提交已经覆盖 `main.py` 与基类，但若有其他自定义 Handler 直接实例化 `RequestHandlerConfig`，可能遗漏 `shutdown_event` 参数。  

4. **测试覆盖不足**  
   - 关闭期间的并发请求、长时间生成（数千 token）场景尚未在 CI 中加入专门的 “shutdown while generating” 测试，潜在的死锁或未释放资源风险难以提前发现。  

**💡 关注建议**  

1. **统一异常处理**  
   - 在 `generate_locally`（以及其他调用 `_cancellation_monitor` 的入口）捕获 `GeneratorExit`，并把它转化为统一的 `ShutdownError`，避免异常泄漏影响外层调度器。  

2. **确保顺序安全**  
   - 将 `runtime.shutdown()` 放在 `shutdown_event.set()` 之后的 **await**，或改为 `await runtime.shutdown()` 完成后再 `set()`，以保证所有运行时资源在事件触发前已安全关闭。  

3. **向后兼容的默认值**  
   - 为 `RequestHandlerConfig.shutdown_event` 设置默认 `None`（已实现），并在所有自定义 Handler 初始化时保持兼容；同时在文档中明确说明新增字段的可选性及推荐使用方式。  

4. **增加测试**  
   - 编写 **Integration Test**：模拟 `SIGTERM` 在生成过程中被触发，验证：  
     - 生成任务收到 `GeneratorExit` 并停止。  
     - `runtime.shutdown()` 被调用且返回。  
     - 所有协程（包括 KV cache、metrics collector）正确关闭且无资源泄漏。  
   - 在 CI 中加入 **stress test**：并发 100+ 请求同时触发 shutdown，确保系统能够快速回收并退出。  

5. **监控与指标**  
   - 在 `graceful_shutdown` 前后记录日志或 Prometheus 指标（如 `shutdown_initiated_total`、`shutdown_duration_seconds`），帮助运维评估实际关闭延迟与成功率。  

通过以上改进，TRT‑LLM 服务将在收到进程终止信号时实现 **快速、可控的资源回收**，提升整体系统的可用性与运维安全性。

---

### feat: vLLM integrations for GPU Memory Service (#5615)
**SHA**: `ccd12d1` | 🔗 [查看提交](https://github.com/ai-dynamo/dynamo/commit/ccd12d1cad4acb7795b523f66170d6841a8445b1)

**🎯 变更类型**：功能增强（vLLM 与 GPU Memory Service（GMS）深度集成）  

**⚡ 重要程度**：🔴 高  

**📋 变更摘要**  
1. 为 **vLLM** 添加 `load_format="gms"`，实现模型权重通过 GPU Memory Service（跨进程 VA‑stable 共享）加载。  
2. 新增 `GMSWorker`（继承 vLLM Worker）以及模型加载器 `GMSModelLoader`，在 `sleep/wake` 阶段实现权重的 **unmap/remap**，避免 CPU 复制。  
3. 引入一套补丁（`torch.cuda.empty_cache`、`MemorySnapshot.measure`）以兼容 VMM 分配并保证内存统计正确。  
4. CLI 参数改为使用 **GPU UUID** 生成默认 Unix domain socket 路径，提升多‑GPU 环境下的稳定性。  
5. 新增公共工具 `get_socket_path`、包装 `setup.cfg` 与 `setup.py`，并提供完整的故障容错 e2e 测试。  

**🎯 影响范围**  
- `components/src/dynamo/vllm/main.py`（vLLM 启动入口）  
- `lib/gpu_memory_service/*`（CLI、公共工具、vLLM 集成代码）  
- `setup.py`（新增 `gpu_memory_service.vllm_integration` 包）  
- 依赖 **pynvml**（用于读取 GPU UUID）  
- 所有使用 `--load-format=gms` 的 vLLM 引擎以及相关测试套件  

**🔍 技术洞察**  

| 维度 | 影响分析 |
|------|----------|
| **架构影响** | - 在 **GPU Memory Service** 与 **vLLM** 之间建立了 **双向依赖**：vLLM 通过 `GMSWorker`、`GMSModelLoader` 调用 GMS 客户端，GMS 则通过 Unix socket 与外部进程通信。<br>- 引入 **跨进程共享权重层**：首次进程以 **RW** 模式加载模型并将张量注册至 GMS，后续进程以 **RO** 模式直接在 meta‑model 上 materialize，显著降低重复显存占用。<br>- 通过 `get_socket_path` 使用 **GPU UUID** 作为默认 socket 名称，避免 `CUDA_VISIBLE_DEVICES` 变化导致的路径冲突，提升多卡部署的可预测性。 |
| **性能影响** | - **显存占用**：第二、三进程不再复制权重，显存节省约模型大小（数十 GiB）。“sleep” 时仅 unmap 权重，释放显存但不涉及 CPU‑GPU 拷贝，sleep‑wake 开销下降至 **毫秒级**（主要为 `torch.cuda.synchronize`）。<br>- **启动时延**：首次进程仍需要完整加载，但后续进程的 `load_model` 只执行元模型构建与 GMS 读取，启动时间可减半以上（视模型大小而定）。<br>- **运行时开销**：GMS 客户端的 `list_allocations`、`total_bytes` 在 `MemorySnapshot.measure` 中被计入，额外的系统调用极小 (<1 % CPU)。<br>- **补丁影响**：全局替换 `torch.cuda.empty_cache` 防止 VMM 分配导致的段错误，记录的开销可忽略。 |
| **安全考虑** | - **Unix Domain Socket**：默认路径基于 GPU UUID，位于 `/tmp`，对外可被任意用户访问。若在多租户机器上使用，建议通过文件系统 ACL 或 `chmod 600` 限制访问。<br>- **NVML 依赖**：`pynvml` 仅读取设备信息，无写权限风险。<br>- **代码注入风险**：`register_gms_loader` 在模块导入时自动执行，若恶意进程能够控制导入路径（例如在 `PYTHONPATH` 中植入伪造的 `gpu_memory_service`），可能导致任意代码执行。建议在发布包中使用 **签名 / 整体验证**，并在生产环境锁定 `PYTHONPATH`。 |
| **可维护性** | - 新增的 `vllm_integration` 包与补丁文件独立，符合 **模块化** 思路。<br>- 通过 `register_model_loader` 的装饰器方式与 vLLM 原生加载器解耦，未来 vLLM 升级（接口变动）时只需更新 `model_loader.py` 中对应的实现。<br>- 测试覆盖率高（fault‑tolerance e2e），但对 **GPU 环境** 有强依赖，CI 需要确保 GPU 可用且装有 NVML。<br>- 增加的 `pynvml` 依赖可能在 **非 Linux**（Windows）平台失效，需要在 `setup.cfg` 中声明可选依赖或提供回退实现。 |

**⚠️ 潜在风险**  

1. **依赖平台**：`pynvml` 仅在 Linux/驱动环境下可用，若在 CI 或用户环境缺失 NVML，启动会抛 `ImportError`。  
2. **Socket 权限**：默认 `/tmp/gms_<UUID>.sock` 可能被其他用户读取/写入，导致 **权重泄漏** 或 **竞争**。  
3. **全局补丁**：`torch.cuda.empty_cache` 被全局替换，若第三方库在补丁后仍依赖原行为（例如强制清理缓存），可能出现显存泄漏。  
4. **版本耦合**：`GMSWorker` 深度继承 vLLM `Worker` 并调用内部属性（如 `model_runner.model_memory_usage`），vLLM 小版本升级可能破坏兼容性。  
5. **错误传播**：在 `sleep` / `wake` 过程中如果 GMS `unmap/remap` 失败，会留下 **不一致的显存状态**，导致后续推理崩溃。  
6. **测试资源**：新增的 e2e 测试需要长时间占用 GPU，若并行运行可能导致 **端口冲突** 或 **显存竞争**。  

**💡 关注建议**  

| 建议 | 说明 |
|------|------|
| **平台兼容性检测** | 在入口处（`setup.py` 或 `__init__`）检测 `pynvml` 是否可用，若不可用则回退到基于 `{device}` 的 socket 路径并提示 “GPU Memory Service 不可用”。 |
| **

---

### feat: handle PrefillComplete in the Dynamo EPP Scorer Plugin [DEP-728] (#5592)
**SHA**: `2a2e63a` | 🔗 [查看提交](https://github.com/ai-dynamo/dynamo/commit/2a2e63a0243387aea8e9c61b8bbd7553117c327b)

**🎯 变更类型**：功能增强、架构变更  
**⚡ 重要程度**：🔴高  
**📋 变更摘要**：在 Dynamo EPP Scorer 插件中实现 `ResponseStreaming` 接口，用于在收到流式响应的首个 token 时通过 C FFI 调用 `mark_prefill_complete`，并通过 HTTP 头部 `x-enable-local-updates: false` 禁用前端路由的本地状态更新。同步将默认 `DYNAMO_ROUTER_REPLICA_SYNC` 关闭，相关 Helm 与文档同步更新。  

**🎯 影响范围**：  
- `deploy/inference-gateway/epp/pkg/plugins/dynamo_kv_scorer`（核心插件）  
- `lib/bindings/c/src/lib.rs`（C FFI 入口）  
- Helm chart `dynamo-gaie`（环境变量、RBAC、InferencePool）  
- 文档 `README.md`、`dynamo_operator.md`（使用说明）  
- 其他依赖 `router`、`kv-aware-scorer` 的部署脚本  

**🔍 技术洞察**：  
- **架构影响**：  
  - 将路由状态的 “add_request / mark_prefill_complete / free_request” 从前端（Frontend）迁移到 EPP（Extension Point），通过 HTTP Header `x-enable-local-updates: false` 明确告诉前端不执行本地更新。  
  - 引入 `ResponseStreaming` 回调，使 EPP 能在流式响应的首 token 时完成预填完成标记，避免在完整响应结束后才清理，提升流式场景下状态一致性。  
  - 通过 `sync.Map`（`firstTokenSeen`）记录请求的首 token，保证幂等性。  

- **性能影响**：  
  - **正向**：EPP 直接调用 C FFI 完成 bookkeeping，省去前端额外的同步调用，降低前端路径的网络/IPC 开销。  
  - **负向**：每个请求在 `ResponseStreaming` 时会进行一次 `sync.Map` `LoadOrStore`，在高并发场景下可能产生微小的锁竞争和内存占用。  
  - 关闭 `DYNAMO_ROUTER_REPLICA_SYNC`（默认 false）减少跨副本同步流量，但如果集群仍需要副本状态一致性，可能导致路由决策不一致。  

- **安全考虑**：  
  - 新增的 HTTP Header `x-enable-local-updates` 只接受 `"false"`（关闭本地更新）或 `"true"`，未对来源做额外校验；若攻击者能够伪造请求头，可能导致前端路由状态不被更新，进而出现资源泄漏或请求漂移。建议在前端对该 Header 做来源身份验证或仅在受信任的内部网络中使用。  
  - 通过 C FFI 调用 `mark_prefill_complete` 的错误处理已加入日志，但未返回错误至上层，潜在的异常不会导致请求失败，仅记录。  

**⚠️ 潜在风险**：  
1. **遗漏首 token**：如果部署的模型不使用流式响应（一次性返回完整响应），`ResponseStreaming` 不会被触发，`mark_prefill_complete` 永远不调用，导致路由状态残留。  
2. **内存泄漏**：`firstTokenSeen` 只在 `ResponseComplete` 时删除对应键，若异常终止（如客户端强制关闭）导致 `ResponseComplete` 未执行，键会永久残留。  
3. **默认关闭副本同步**：`DYNAMO_ROUTER_REPLICA_SYNC` 变为 false，可能在多副本部署时出现路由不一致，尤其在高可用/横向扩展场景。  
4. **Header 误用**：外部用户若误把 `x-enable-local-updates` 设置为 `"false"`，前端将不进行本地更新，可能导致路由表膨胀。  
5. **兼容性**：旧版 EPP（未实现 `ResponseStreaming`）仍会使用原有 `ResponseComplete` 路径，若混用会出现双重 bookkeeping（一次 `add_request` + `mark_prefill_complete` 双调用）。  

**💡 关注建议**：  
- **测试覆盖**：在 CI 中加入流式和非流式两类模型的端到端测试，验证 `ResponseStreaming` 能正确触发，且在非流式场景仍能通过 `ResponseComplete` 完成 bookkeeping。  
- **资源清理**：在异常路径（如请求被取消）中显式调用 `CallMarkPrefillComplete` / `callFreeRequestInternal`，或在插件的 `PreRequest` 注册超时回调，以防止 `firstTokenSeen` 泄漏。  
- **监控报警**：添加监控指标 `epp_prefill_complete_success_total`、`epp_prefill_complete_error_total`、`epp_first_token_map_size`，当 map 大小异常增长时触发告警。  
- **安全加固**：在前端（或网关）对 `x-enable-local-updates` 进行白名单校验，只接受内部可信请求；或在插件层面默认强制 `true`，仅在明确配置的情况下允许关闭。  
- **配置文档**：在部署指南中醒目提示：如果使用非流式模型，请保持 `DYNAMO_ROUTER_REPLICA_SYNC=true`，或手动在 `ResponseComplete` 中调用 `CallMarkPrefillComplete` 以保证状态一致。  
- **回退方案**：提供 Helm 参数 `epp.forceLocalUpdates=true`，可以在紧急回滚时重新启用前端本地更新，避免因新 Header 引入的潜在问题导致服务不可用。  

---  

通过上述改动，EPP 现在能够更及时、精确地完成 Dynamo 路由的预填状态标记，降低前端的负载并提升流式推理的响应时效。但需要注意异常路径的清理、配置兼容性以及对 Header 的安全校验，以确保在生产环境中平滑迁移。

---

### feat: MiniMax tool parser (#5549)
**SHA**: `11d9cdf` | 🔗 [查看提交](https://github.com/ai-dynamo/dynamo/commit/11d9cdfb0e65012f7268ab5d33889426e8baf3b9)

**🎯 变更类型**：功能增强  

**⚡ 重要程度**：🔴 高  

**📋 变更摘要**  
1. 为 MiniMax‑M2.1​ 统一的 XML‐style 工具调用格式新增解析器配置 `minimax_m2()`，并在全局解析映射中注册。  
2. 为该格式补充完整的单元测试，覆盖单个调用、多调用、混合文本、空参数、类型转换、数组参数等场景。  
3. 在 `xml/parser.rs` 中加入 `strip_quotes` 辅助函数，保证在解析 `<invoke name="...">` 与 `<parameter name="...">` 时自动去除可能的引号，提升对非标准化输入的容错。  

**🎯 影响范围**  
- `lib/parsers/src/tool_calling/config.rs`（新增 `minimax_m2` 配置）  
- `lib/parsers/src/tool_calling/parsers.rs`（注册新 parser、扩展测试列表）  
- `lib/parsers/src/tool_calling/xml/parser.rs`（引入 `strip_quotes`、更新解析逻辑）  
- 所有使用 `detect_and_parse_tool_call` 的上层调用方（例如聊天模型推理管线）将可以识别并处理 MiniMax‑M2.1 输出。  

**🔍 技术洞察**  

- **架构影响**  
  - **模块化**：通过 `ToolCallConfig::minimax_m2()` 将 MiniMax‑M2.1 解析抽象为一个独立 `ParserConfig::Xml` 实例，保持现有 `ParserConfig` 枚举的统一性，无需改动调用层的分支逻辑。  
  - **可扩展性**：新增的 `strip_quotes` 具备通用性，可在未来处理其他 XML‑like 语法的引号问题，提升解析器的弹性。  
  - **测试覆盖**：新增 7 组异步单元测试，提升整体代码库的回归安全性，并在 CI 中自动验证新格式的兼容性。  

- **性能影响**  
  - **微增开销**：`strip_quotes` 只做一次 `trim` 与字符比较，几乎可以忽略不计。  
  - **缓存/正则**：新 parser 使用已有的正则表达式路径，仅在 `detect_tool_call_start_xml` 与 `parse_tool_call_block` 中匹配新 token，匹配成本与已支持的 XML parser 相同。整体响应时间预计保持在毫秒级，且对整体吞吐量影响可忽略。  

- **安全考虑**  
  - **输入消毒**：解析器仍然依赖正则捕获函数名与参数名，未对捕获的值做额外转义或长度限制。虽然 `strip_quotes` 消除了显式的引号包裹，但仍可能出现极端长字符串导致内存占用激增（正则回溯攻击）。建议在后续加入长度阈值或使用更安全的 XML 解析库（如 `roxmltree`）对极端情况进行防护。  
  - **类型转换**：在 `detect_and_parse_tool_call` 中对参数值进行 JSON 解析时，若传入恶意的 JSON（如 `{"$ne": ""}`）可能触发业务层的注入风险。现有代码已经将解析结果包装为 `serde_json::Value`，但仍需业务层校验字段白名单。  

**⚠️ 潜在风险**  

1. **正则误匹配**：MiniMax‑M2.1 的 token 与现有 XML parser 相似，若未来引入相近的自定义标签，正则可能捕获错误块。  
2. **引号处理不完整**：`strip_quotes` 只剥离首尾单/双引号，未对转义引号（如 `\"`）做处理，极端情况下可能留下残余字符。  
3. **接口向后兼容**：`get_tool_parser_map` 在注册顺序上将 `minimax_m2` 放在 `default` 前，若用户通过自定义 `parser_name` 参数传入未知值，将回退到 `default`，但不影响已显式使用 `minimax_m2` 的场景。  
4. **测试环境依赖**：测试中使用了 `ToolDefinition` 的 JSON schema 进行类型转换，如果上层 schema 定义不完整或与实际模型不匹配，可能导致解析失败而未在 CI 中暴露。  

**💡 关注建议**  

- **代码审查**：在 `strip_quotes` 添加注释说明其作用范围，且考虑使用 `str::trim_matches` 统一处理不同引号类型。  
- **安全加固**：在 `parse_tool_call_block` 前加入对 `function_name` 与 `param_name` 最大长度（如 128 字符）检查，以防止正则回溯攻击。  
- **文档同步**：更新项目的 **Tool Calling Guide**，在 README 或 docs 中列出 MiniMax‑M2.1 的使用示例与已知限制（如不支持嵌套 XML）。  
- **性能监控**：在 CI 中加入基准测试（criterion）对 `detect_and_parse_tool_call` 进行微基准，对比引入 `minimax_m2` 前后的延迟，以确保不出现意外的性能回退。  
- **兼容性测试**：在跨平台（Linux/macOS/Windows）以及不同 Rust 编译器版本（1.70+）下运行全部新增测试，确保行为一致。  

总体而言，此次提交为 MiniMax‑M2.1 的工具调用解析提供了完整的功能支持，结构清晰、风险可控，只需在后续版本中关注输入安全与正则匹配的边界情况即可。

---

#### 🟡 中重要度变更 (11)

### fix: Update the vllm docker image to use the cuda sampler rather than the pytorch one (#5613)
**SHA**: `f985819` | 🔗 [查看提交](https://github.com/ai-dynamo/dynamo/commit/f9858193a00ed9811a07a788b5a5857659486b85)

**🎯 变更类型**：Bug 修复  
**⚡ 重要程度**：🟡 中  

**📋 变更摘要**：在 `container/Dockerfile.vllm` 中新增 `ENV VLLM_USE_FLASHINFER_SAMPLER=1`，让 vLLM 0.12 采用 CUDA 实现的 FlashInfer 采样器（取代默认的 PyTorch 采样器），以确保前向推理使用 GPU 加速。  

**🎯 影响范围**：  
- `container/Dockerfile.vllm`（Docker 镜像构建）  
- VLLM 运行时（使用 `vllm` 镜像的推理服务）  

**💡 关注建议**：  
1. **兼容性**：确认部署环境的 GPU 与 FlashInfer 兼容；如不支持，容器启动可能报错。  
2. **回退机制**：若出现不兼容，可在运行时覆盖环境变量为 `0`，或使用旧镜像。  
3. **CI / 测试**：在 CI 中加入基于 CUDA 的 vLLM 推理测试，验证采样输出与性能提升。  
4. **文档更新**：在 README 或部署指南中注明需使用 `VLLM_USE_FLASHINFER_SAMPLER=1`（或默认已开启），并说明该变量的作用与适用的 vLLM 版本。  
5. **后续维护**：vLLM 未来若改动采样器开关名称，要同步更新 Dockerfile，避免因变量失效导致回退到慢速 PyTorch 采样器。

---

### test: radix tree benchmarks (#5617)
**SHA**: `ca63c49` | 🔗 [查看提交](https://github.com/ai-dynamo/dynamo/commit/ca63c49d83ed2d6ac7eda756eee5b5630336372e)

**🔎 变更概览**  
- **类型**：功能增强（新增微基准）  
- **重要程度**：🟡 中（不影响库的业务功能，但会影响构建/CI 时间及可执行体大小）  
- **核心改动**  
  1. `lib/llm/Cargo.toml`  
     - 新增 **`kv-router-stress`** feature，依赖 `clap`、`indicatif`（仅用于基准）。  
     - 注册 `radix_tree_microbench` 基准，`harness = false`，并把它绑定到 `kv-router-stress`。  
  2. 新增文件 `lib/llm/benches/radix_tree_microbench.rs`  
     - 完整的可配置微基准，涵盖 `hash / store / remove / find_matches / dump / sweep` 五大操作。  
     - 实现了自定义参数解析、序列生成、统计采集、结果格式化等。  

**🗂️ 受影响范围**  
| 模块 | 影响 | 备注 |
|------|------|------|
| `dynamo-llm` 包的 `Cargo.toml` | 新增 feature 与 bench 条目 | 需要在 `cargo bench --features kv-router-stress` 时显式打开 |
| `kv_router::indexer::RadixTree` | **只读** – 该基准调用现有 API (`apply_event`, `find_matches`, `dump_tree_as_events`) | 若未来 API 细微变动，基准也会受影响 |
| 依赖 `clap`、`indicatif` | 新增运行时依赖（仅在 `kv-router-stress` 开启时编译） | 与库的生产代码无关 |

**⚠️ 潜在风险 / 需要关注的点**  

| 风险 | 说明 | 建议 |
|------|------|------|
| **编译错误** | `rng.random_range(0..num_prefix_prompts)` 并不存在，正确 API 为 `rng.gen_range(0..num_prefix_prompts)`（已在 `Rng` trait 中实现）。 | 将该行改为 `let group_id = rng.gen_range(0..num_prefix_prompts);` 并确保 `use rand::Rng;` 已导入。 |
| **未处理的 benchmark 类型** | 在 CLI 参数校验中，`matches!("store" | "remove" | "lookup" | "sweep" | "all")` 允许 `"lookup"`，但后续 `match` 分支没有对应处理（实际是 `find_matches`）。 | 将校验改为 `lookup` → `find_matches`，或直接在 `matches!` 中去掉 `lookup`。 |
| **`RadixTree::current_size()` 可能不存在** | 项目中 `RadixTree` 是否实现了 `current_size()` 需确认；若不存在会导致编译错误。 | 若无该方法，可使用 `tree.node_count()`（或其它公开字段）代替，或实现一个包装函数。 |
| **Bench 目标默认被 CI 执行** | 添加的基准耗时较大（尤其是 sweep），若 CI 没有显式排除，会显著延长 pipeline。 | 在 CI 配置中，仅在 `--features kv-router-stress` 或专门的基准作业中运行；在 `cargo test`、`cargo build` 时保持默认不编译。 |
| **依赖体积** | `clap`、`indicatif` 会被引入 `dynamo-llm` 的发行版（如果未使用 feature gating 正确），导致二进制膨胀。 | 确认 `Cargo.toml` 中 `kv-router-stress` 为 **optional** feature（已是），并在 `Cargo.lock` 中标记为 `default = []`。 |
| **文档缺失** | 新增的基准没有在仓库 README 或 `BENCHMARKS.md` 中说明，用户不易发现使用方式。 | 在 `docs/benchmarks.md`（或根 README）添加使用示例：`cargo bench --package dynamo-llm --bench radix_tree_microbench --features kv-router-stress -- --help`。 |
| **随机数种子可重复性** | 虽然提供 `--seed` 参数，但在 `generate_sequences` 中对 **prefix** 的随机化使用 `group_id = rng.gen_range...`，若 `num_prefix_prompts` 为 0 会 panic。 | 在 `generate_sequences` 前提前检查 `num_prefix_prompts > 0 && prefix_length > 0`，否则跳过该块。 |
| **输出格式化** | `print_sweep_results_dynamic` 里 `"-".repeat(130)` 对齐不一定匹配表头宽度，可能导致视觉错位。 | 根据表头宽度动态计算或使用 `prettytable-rs` 等库统一格式。 |

**🚀 推荐的后续动作**  

1. **代码修正**  
   - 替换 `rng.random_range` 为 `rng.gen_range`。  
   - 移除或映射 `"lookup"` 参数，使 CLI 与实现保持一致。  
   - 检查 `RadixTree::current_size()` 是否可用，若不可用改用合适的统计方法。  

2. **CI/发布流程**  
   - 在 CI 中添加专门的 “benchmark” job，明确使用 `--features kv-router-stress`，并在普通测试/构建作业中排除。  
   - 在 `cargo test` 默认路径下使用 `--exclude benches`（或在 `Cargo.toml` 中将 `[bench]` 标记 `required-features = ["kv-router-stress"]` 已经足以防止默认编译）。  

3. **文档与使用指引**  
   - 更新 README/Docs，说明：何时使用此基准、主要参数含义（size、depth、prefix_prompt_ratio、sweep_mode 等），以及结果解释方式。  
   - 给出典型命令示例，如：  
     ```bash
     cargo bench --package dynamo-llm --bench radix_tree_microbench \
                 --features kv-router-stress \
                 -- --size 20000 --depth 64 --iterations 5000 --sweep_mode depth
     ```  

4. **可选性强化**  
   - 确认 `clap`、`indicatif` 为 **optional**，并在 `Cargo.toml` 的 `[features]` 中加入简短描述：`kv-router-stress = ["clap", "indicatif"]  # heavy micro‑benchmarks`.  

5. **代码整洁**  
   - 将重复的统计/打印逻辑抽离成通用函数（如 `print_latency_stats`），降低维护成本。  
   - 为 `SweepResult` 实现 `Display` trait，便于统一输出。  

**结论**  
此次提交为 `dynamo-llm` 引入了完整的 Radix‑Tree 微基准，能够帮助开发者量化关键路径（hash、store、remove、lookup）的性能。核心业务代码未变，只是加入了可选的性能测

---

### fix: remove cupy-cuda13x from dev container (#5669)
**SHA**: `8d9ccdf` | 🔗 [查看提交](https://github.com/ai-dynamo/dynamo/commit/8d9ccdfb8da596aaf89f7314d75c1752f0405703)

**🎯 变更类型**：Bug修复  
**⚡ 重要程度**：🟡 中  
**📋 变更摘要**：在 `container/dev/Dockerfile.dev` 中删除了对 `cupy-cuda13x` 包的显式安装。原先在一次 `uv pip install` 指令中既安装了 `requirements.test.txt`，又强制追加了 `cupy-cuda13x`，现在改为只执行 `requirements.test.txt`，从而避免在开发容器中默认拉取 CUDA 13 版的 CuPy。  

**🎯 影响范围**：  
- `container/dev`（开发容器镜像构建）  
- CI/CD 流水线使用的开发镜像  
- 依赖 `cupy-cuda13x` 的本地或 CI 测试脚本（若未显式添加则会缺失）  

**💡 关注建议**：  
1. **确认测试依赖**：检查 `requirements.test.txt` 中是否已经包含适配当前 CUDA 版本的 CuPy（如 `cupy-cuda11x` / `cupy`），避免因缺失导致测试失败。  
2. **兼容性验证**：在不同 GPU 环境（CUDA 11、12、13）下跑一遍完整的单元/集成测试，确保删除该依赖不会影响任何 CUDA‑13 相关的功能。  
3. **文档更新**：在项目的开发环境指南或 Dockerfile 注释中说明已不再默认安装 `cupy-cuda13x`，如需使用请手动 `pip install cupy-cuda13x`。  
4. **CI 配置**：若 CI 仍依赖该包，应在对应工作流中显式安装，或改为使用通用 `cupy` 包以提升跨 CUDA 版本的可移植性。  

总体来说，此改动简化了开发容器的镜像体积和构建时间，但需要确保所有使用 CuPy 的测试或示例代码在没有 `cupy-cuda13x` 的情况下仍能正常运行。建议在合并前跑一次完整的 CI，以捕获潜在的依赖缺失。

---

### fix: sglang version in build.sh and docs (#5665)
**SHA**: `546f1bb` | 🔗 [查看提交](https://github.com/ai-dynamo/dynamo/commit/546f1bbc0d98d580c6e6f1590daad97f7a8b1ac5)

**🔧 变更类型**：Bug 修复（版本同步）  
**⚡ 重要程度**：🟡 中  

**📋 变更摘要**  
本次提交把 Dynamo 项目中对 SGLang 的依赖统一升级至 **0.5.8**，并同步更新了 Docker 镜像标签、`pyproject.toml` 注释以及文档中的支持矩阵。代码本身未改动，仅是版本号和说明的纠正。

**🎯 影响范围**  
- **构建脚本**：`container/build.sh` 中的 `SGLANG_RUNTIME_IMAGE_TAG_CU13` 从 `v0.5.7-cu130-runtime` 改为 `v0.5.8‑cu130-runtime`。  
- **Python 包依赖声明**：`benchmarks/pyproject.toml` 注释中对应的 SGLang 版本从 `0.5.7` 更新为 `0.5.8`。  
- **文档**：`fern/pages/*/support-matrix.md` 两处表格展示的 “SGLang” 列已改为 0.5.8（主分支），其余历史行保持不变。  
- **CI/CD**：任何依赖 `container/build.sh` 生成镜像的流水线会拉取新的运行时镜像。

**💡 关注建议**  
1. **验证镜像可用性**：在 CI 中确认 `v0.5.8-cu130-runtime` 镜像已推送至公开仓库，且标签匹配 `CUDA 13.0` 环境。  
2. **兼容性测试**：虽然只是补丁升级，仍建议跑一次完整的单元/集成测试，确保 Dynamo 与 SGLang 0.5.8 的 API 没有细微差异（如函数签名或默认参数变更）。  
3. **文档同步**：检查其它文档（例如 README、CHANGELOG）是否仍提到旧版本，保持一致性。  
4. **依赖锁文件**：如果项目使用 `uv lock`、`poetry lock` 等生成的锁文件，记得在更新后重新生成，以防 downstream 用户因锁文件仍指向 0.5.7 而出现冲突。  

总体来说，此次改动仅是版本对齐，风险低，但需确保镜像发布和锁文件同步，以免导致构建失败或运行时不一致。

---

### feat: sglang update to 0.5.8 (#5655)
**SHA**: `4f981e2` | 🔗 [查看提交](https://github.com/ai-dynamo/dynamo/commit/4f981e282a1755439cdf8d38433e421ab7c6a44c)

**🎯 变更类型**：功能增强  
**⚡ 重要程度**：🟡 中  
**📋 变更摘要**：将项目所使用的 SGLang 版本从 0.5.7 升级至 0.5.8，并同步更新 Docker 运行时镜像标签、Cutlass‑DSL 依赖、`requirements.txt` 与 `pyproject.toml` 中的版本约束，同时在支持矩阵文档中反映新版本。

**🎯 影响范围**  
- **container/Dockerfile.sglang**：运行时镜像从 `v0.5.7-runtime` 改为 `v0.5.8-runtime`，Cutlass‑DSL 从 `4.3.0` 升至 `4.3.5`。  
- **container/deps/requirements.txt**：SGLang 版本注释更新为 `0.5.8`（实际依赖仍由 `transformers` 控制）。  
- **docs/reference/support-matrix.md**：表格中 SGLang 版本展示为 `0.5.8`。  
- **pyproject.toml**：Python 包依赖声明从 `sglang==0.5.7` 改为 `sglang==0.5.8`。  

**💡 关注建议**  
1. **镜像重建**：CI/CD 必须重新构建 `sglang` 相关的容器镜像，确认新镜像 `lmsysorg/sglang:v0.5.8-runtime` 可正常 pull。  
2. **兼容性验证**：运行单元/集成测试，重点检查 SGLang 新特性或 API 变更对现有推理管线（尤其是 vLLM、TensorRT‑LLM）的影响。  
3. **Cutlass‑DSL 更新**：`4.3.5` 可能带来编译/运行时差异，确保对应的 CUDA 环境（12.x/13.x）已安装匹配的库。  
4. **文档同步**：确认其他文档（如 release notes、升级指南）已同步 SGLang 0.5.8 的说明，防止用户在手动部署时遗漏更新。  
5. **依赖锁定**：`requirements.txt` 中仍使用宽松的 `transformers>=4.56.0`，如有特定兼容需求，建议在未来锁定到已验证的最小版本。  

总体来说，此次升级是对后端推理框架的常规迭代，风险主要在镜像构建和库兼容性，建议在正式发布前完成全链路回归测试。

---

### fix: Add cupy-cuda12x to sglang extras (#5627)
**SHA**: `76fbbc8` | 🔗 [查看提交](https://github.com/ai-dynamo/dynamo/commit/76fbbc8fab8cdb90115c4982ceb316e352b1a608)

**变更类型**：Bug 修复  
**重要程度**：🟡 中  
**变更摘要**：在 `pyproject.toml` 的 `sglang` extras 中新增了 `cupy-cuda12x>=13.0.0` 依赖，以解决运行时缺少 CuPy 的问题。  

**影响范围**  
- **安装流程**：`pip install .[sglang]` 将额外拉取 CuPy 12.x 的二进制，导致安装体积显著增加。  
- **平台兼容性**：CuPy 依赖本机 CUDA 12 环境；在未装 CUDA 或使用其他版本的机器上会出现编译或兼容性错误。  
- **CI / 打包**：CI 镜像需要预装 CUDA 12 runtime 或使用对应的 manylinux 镜像，否则测试会因缺少 CuPy 而失败。  

**建议**  
1. **加平台标记**：考虑使用 `; sys_platform == "linux"`（或对应 OS）限制，仅在支持 CUDA 12 的环境下安装。  
2. **文档说明**：在 README 或 `extras` 文档中明确说明需要 CUDA 12 环境及对应的驱动版本。  
3. **CI 验证**：在 CI 中加入带 CUDA 12 的测试矩阵，确保 `pip install .[sglang]` 在不同平台均能成功。  
4. **冲突检测**：检查 `sglang==0.5.7` 对 CuPy 的内部依赖是否已有锁定版本，防止出现版本不兼容。  
5. **可选依赖**：如果 CuPy 并非所有使用场景的必需，可改为 `cupy-cuda12x>=13.0.0 ; extra == "sglang"`，让用户自行决定是否启用。  

以上调整可以降低因新依赖引入的安装风险，保证库在多平台的平滑运行。

---

### chore: remove legacy KVBM pythong static type checks and test (#5486)
**SHA**: `89e135b` | 🔗 [查看提交](https://github.com/ai-dynamo/dynamo/commit/89e135b9ce57db4c31a70162581f1a021058ba25)

**变更类型**：chore（清理）  
**重要程度**：🟡 中  

**变更概要**  
1. 删除了 `lib/bindings/kvbm/python/kvbm/_core.pyi` 与 `lib/bindings/python/src/dynamo/_core.pyi` 中对 `KvbmCacheManager` 的声明（共 9 行）。  
2. 同时在同目录下移除了 `test_kvbm_vllm_integration.py`，该文件包含近千行针对 VLLM‑KVBM 交互的单元测试。  

**受影响模块**  
- Python 类型存根（`.pyi`）——IDE 与静态分析工具不再看到 `KvbmCacheManager` 的类型定义。  
- CI 测试集——原有的 VLLM/KVBM 集成测试不再执行，整体测试运行时间显著下降。  

**核心影响**  
- **运行时行为未变**：`KvbmCacheManager` 仍由 Rust 实现并在模块初始化时导出，只是缺失了对应的 `.pyi` 声明。对已编译的二进制没有影响。  
- **开发体验**：使用 `mypy`、pyright 等工具时会出现 “未定义名称 KvbmCacheManager” 的错误；IDE 自动补全也会失效。  
- **文档/示例**：任何示例中给出的类型注解需相应更新或去除。  

**建议**  
1. **兼容性**：若项目仍希望保留类型提示，可在 `.pyi` 中添加一个轻量的占位声明（如 `class KvbmCacheManager: ...`），或在 `__init__.py` 中使用 `typing.TYPE_CHECKING` 提供别名。  
2. **CI 迁移**：确认已经有其他覆盖 VLLM‑KVBM 场景的测试，防止因为删掉的测试导致功能回归未被捕获。  
3. **文档同步**：在 README 或 API 文档中注明 `KvbmCacheManager` 已不再提供静态类型信息，建议使用 `# type: ignore` 或自行声明协议（Protocol）进行类型检查。  
4. **用户通知**：在发布说明中提醒 downstream 项目更新其 `mypy` 配置或加入临时类型占位，以避免构建失败。  

总体来看，此次提交仅是代码清理，对运行时功能无直接影响，但会影响类型检查和 IDE 辅助，需做好相应的兼容提醒。

---

### docs: migrate existing docs to fern (#5445)
**SHA**: `f9050aa` | 🔗 [查看提交](https://github.com/ai-dynamo/dynamo/commit/f9050aae852b2f4985f8194cd775be432d8312e7)

⚠️ LLM分析失败（已重试3次）: API请求失败: 400 Client Error: Bad Request for url: https://integrate.api.nvidia.com/v1/chat/completions

*暂无分析*

---

### fix: Pass empty tokens for new requests for TRTLLM (#5620)
**SHA**: `22fbc02` | 🔗 [查看提交](https://github.com/ai-dynamo/dynamo/commit/22fbc022e12bbc043f4fe6f814d13dedd3e9df14)

**🎯 变更类型**：Bug 修复  
**⚡ 重要程度**：🟡 中  
**📋 变更摘要**：在 `trtllm_leader.rs` 中，原先对新请求调用 `apply_scheduler_output` 时使用了 `new_req.prompt_token_ids`，但 TRTLLM 场景下该字段为空或未定义，导致调度错误。现在改为显式传入空切片 `&[]`，避免因意外的 `None` / 空指针触发 panic 或错误的 token 计数。  

**🎯 影响范围**：  
- `core/lib/bindings/kvbm/src/block_manager/vllm/connector/trtllm_leader.rs`（TRTLLM leader 实现）  
- 受影响的运行时路径：TRTLLM 启动后首次调度新请求的分配逻辑。  

**💡 关注建议**：  
1. 确认 `apply_scheduler_output` 对空 `prompt_token_ids` 的处理保持幂等且不产生负数计数；如有必要在函数内部加入 `if prompt_token_ids.is_empty()` 的快速路径注释。  
2. 为 TRTLLM 场景补充单元测试，验证在没有 Prompt Tokens 时调度仍能正确生成 `block_ids`、`num_computed_tokens` 等。  
3. 检查其他 connector（如 vllm、llama）是否仍依赖 `prompt_token_ids`，避免此改动产生跨实现的副作用。  
4. 在文档或代码注释中说明 TRTLLM 新请求不携带 Prompt Tokens 的前置条件，帮助使用者理解该行为。  

通过上述检查，可确保此修复不会引入新的计数错误或性能回退。

---

### fix(sglang): use correct API and deps for memory occupation endpoints (#5635)
**SHA**: `fbf91da` | 🔗 [查看提交](https://github.com/ai-dynamo/dynamo/commit/fbf91daf2988b2105e3ff5720376ed8f9845dc2e)

**🎯 变更类型**：Bug 修复  
**⚡ 重要程度**：🟡 中  

**📋 变更摘要**  
- 将 SGLang 内存占用相关接口从 `engine.async_*` 调整为新版 `tokenizer_manager` API，使用 `PauseGenerationReqInput、ReleaseMemoryOccupationReqInput、ResumeMemoryOccupationReqInput、ContinueGenerationReqInput` 结构体。  
- 同时更新相应的 import，确保调用签名与最新 SGLang SDK 对齐。

**🎯 影响范围**  
- `components/src/dynamo/sglang/request_handlers/handler_base.py`（核心请求处理层）  
- 依赖 `engine.tokenizer_manager` 的其它模块（如集群发现、负载均衡）若仍使用旧的 `engine.async_*` 方法，可能出现运行时 `AttributeError`。  
- 单元/集成测试及 CI 脚本中涉及内存占用、暂停/恢复生成的用例需要同步更新。

**💡 关注建议**  
1. **兼容性检查**：确认 `engine.tokenizer_manager` 已在运行时正确实例化并注入，避免在未初始化时调用导致异常。  
2. **API 抽象**：若项目仍有直接调用 `engine.async_*` 的路径，建议在 `engine` 包内提供轻量包装函数（转发至 `tokenizer_manager`），以降低迁移成本。  
3. **参数 `None`**：`release_memory_occupation`、`resume_memory_occupation` 现在额外接受 `None` 参数，确认该占位参数在新 SDK 中的意义或可否省略，以免产生误用。  
4. **文档与示例**：更新 `README`、内部 API 文档以及示例代码，注明新版请求结构体的使用方式。  
5. **测试覆盖**：新增或调整对应的单元测试，验证暂停、释放、恢复、继续四个步骤在异常情况下的回滚逻辑，防止内存泄漏或请求卡死。  

总体而言，此次修改使 Dynamo 与 SGLang 的内存管理保持一致，提升了运行时安全性。但需要在项目内部统一新的调用入口并补齐测试，以防止因接口不匹配导致的服务中断。

---

### refactor: rename sleep/wake endpoints for consistency (#5629)
**SHA**: `f976f02` | 🔗 [查看提交](https://github.com/ai-dynamo/dynamo/commit/f976f02b85a2f59854bebf80b9875a65a5d4323d)

**🎯 变更类型**：重构  
**⚡ 重要程度**：🟡 中  
**📋 变更摘要**：统一 API 命名，将原先的 *sleep / wake* 端点及客户端方法改为 *wake_up* 与 *unmap / remap*，并相应更新日志、异常信息以及内部状态变量。  

**🎯 影响范围**  
- `components/src/dynamo/vllm/handlers.py`、`components/src/dynamo/vllm/main.py`：REST 接口路由名称从 `wake` → `wake_up`，日志文字同步更改。  
- `lib/gpu_memory_service/client/memory_manager.py`：类属性 `_sleeping` → `_unmapped`、方法 `sleep`/`wake` → `unmap`/`remap`，文档、异常信息、状态检查全部改名。  

**💡 关注建议**  
1. **向后兼容**：外部服务或脚本仍可能调用旧的 `/engine/wake` 端点或 `GMSClientMemoryManager.sleep()`，当前改动会直接抛 `AttributeError`。建议在下一次发行时加入兼容层（如保留旧方法并发出 `DeprecationWarning`），并在发布日志中注明迁移步骤。  
2. **文档同步**：更新所有用户文档、OpenAPI 规范以及示例代码中的接口名称和方法调用。  
3. **测试覆盖**：确认单元测试、集成测试已覆盖新路径；特别检查 `runtime.register_engine_route` 的调用点是否还有遗漏的旧名字。  
4. **服务端协议**：若 GPU Memory Service 的 RPC 接口仍使用 `sleep`/`wake`，确保客户端的 `unmap`/`remap` 仍调用对应的 RPC（代码未改动），否则需要同步服务器端实现。  
5. **状态属性**：对外暴露的属性从 `is_sleeping` 改为 `is_unmapped`，若有第三方代码依赖旧属性，请提供兼容属性或迁移指导。  

总体来看，改动属于命名层面的统一，功能保持不变。只要注意兼容性和文档同步，即可平滑迁移。

---

#### 🟢 低重要度变更 (7)

### ci: update runners in ci-test-suite (#5680)
**SHA**: `ce570d3` | 🔗 [查看提交](https://github.com/ai-dynamo/dynamo/commit/ce570d31c153389e81d254e2b504077659b22ecc)

**🎯 变更类型**：配置调整  
**⚡ 重要程度**：🟢低  
**📋 摘要**：将 CI 测试套件中 CUDA 13 构建作业的 runner 名称从旧机器改为 `prod-builder-amd-v1` / `prod-builder-arm-v1`，更新 CI 环境配置。

---

### test: consolidate guided decoding vLLM configs (#5670)
**SHA**: `2dbfed8` | 🔗 [查看提交](https://github.com/ai-dynamo/dynamo/commit/2dbfed896a5ab929caabbc3355a0c7b70d0723fb)

**🎯 变更类型**：测试修改  
**⚡ 重要程度**：🟢低  
**📋 摘要**：合并并简化 VLLM 的 guided‑decoding 配置，将 `guided_decoding_json`、`guided_decoding_regex`、`guided_decoding_choice` 合并为单一的 `guided_decoding` 配置，统一脚本、标记及模型，并统一请求负载定义。

---

### chore: version update for 0.9.0 (#5661)
**SHA**: `66c3699` | 🔗 [查看提交](https://github.com/ai-dynamo/dynamo/commit/66c369964a004f41f7040f2ff5d0009fab3ca5a2)

**🎯 变更类型**：配置调整  
**⚡ 重要程度**：🟢 低  
**📋 摘要**：将 Dynamo 各子库、Helm Chart、文档及 Python 包的版本号统一从 0.8.0 升级至 0.9.0。

---

### chore: do not default to privileged mode when mounting workspace. (#5644)
**SHA**: `65a3770` | 🔗 [查看提交](https://github.com/ai-dynamo/dynamo/commit/65a37708e150bfb553b233c5a2ec7b847ebfb039)

**🎯 变更类型**：配置调整  
**⚡ 重要程度**：🟢 低  
**📋 摘要**：在 `container/run.sh` 中移除挂载工作区时默认开启特权模式的逻辑，并更新帮助信息说明 `--privileged` 默认为 FALSE。

---

### chore: use aic release/0.6.0 (#5600)
**SHA**: `aecf005` | 🔗 [查看提交](https://github.com/ai-dynamo/dynamo/commit/aecf005136e4833bd065a1f9899c8a38261be89a)

**🎯 变更类型**：配置调整  
**⚡ 重要程度**：🟢低  
**📋 摘要**：将 benchmarks/pyproject.toml 与 container/deps/requirements.txt 中的 `aiconfigurator[webapp]` 依赖从 0.5.0/旧提交升级至 0.6.0（新的提交哈希），保持依赖同步。

---

### docs: reduce admonition clutter in reference docs (#5646)
**SHA**: `f238d23` | 🔗 [查看提交](https://github.com/ai-dynamo/dynamo/commit/f238d23a4d70035442013097bd29e87516379c9e)

**🎯 变更类型**：文档更新  
**⚡ 重要程度**：🟢低  
**📋 摘要**：删除多个 `!Note`/`!Important` 提示，精简文字描述；在 Release Artifacts、Support Matrix 等页面统一加入 NGC、PyPI、Helm、crates 的链接示例，提升文档可读性与一致性。

---

### docs: add release-artifacts.md with comprehensive artifact inventory (#5619)
**SHA**: `2480734` | 🔗 [查看提交](https://github.com/ai-dynamo/dynamo/commit/248073455aa552af33e6fae742602ddc6d39c2e4)

**🎯 变更类型**：文档更新  
**⚡ 重要程度**：🟢 低  
**📋 摘要**：新增 `release-artifacts.md`，记录所有 Dynamo 发行产物（容器、Python wheel、Helm、Rust crates），并在 README、索引和支持/特性矩阵文档中加入相应链接与更新说明。

---

