# 每日更新报告（2026-02-21）

## ai-dynamo/dynamo

| 提交时间 | 作者 | 提交信息 |
|----------|------|----------|
| 2026-02-21 22:59:54 | William Zhang | fix: Multimodal flag was ignored for TRTLLM (#6468)<br>* Why?<br>Commit `5a67b246d` refactored configs for the TRTLLM backend, breaking<br>`--modality multimodal`.<br>* What?<br>This commit fixes this bug, and adds a unit test verified to fail<br>without it. |
| 2026-02-21 13:01:13 | Tzu-Ling Kan | feat: Remove public uses of CancellationToken (#6405) |
| 2026-02-21 09:31:32 | Schwinn Saereesitthipitak | feat(chrek): external restore, signal-based IPC, and package refactor (#6286) |
| 2026-02-21 06:38:43 | Dmitry Tokarev | Run Fault Tolerance test jobs only in Nightly pipeline (not in post-m… (#6462) |
| 2026-02-21 06:38:34 | knarangN | test: add TensorRT-LLM multimodal EPD test for nightly CI (#6193) |
| 2026-02-21 06:37:26 | Graham King | feat(frontend): Reduce Python-side overhead in the vLLM chat path (#6437) |
| 2026-02-21 05:33:15 | Julien Mancuso | fix: reintroduce helm docs autogeneration (#6459) |
| 2026-02-21 03:49:04 | William Zhang | fix: Fix dev container build (#6455)<br>There were 2 bugs prior to this commit when building a TRTLLM dev<br>container:<br>- template rendering bug<br>- CUDA compatibility layer<br>The `nvidia_entrypoint.sh` script should render the second completely<br>unnecessary. |
| 2026-02-21 03:32:01 | Dmitry Tokarev | fix: Docker push retries (#6456) |
| 2026-02-21 03:11:52 | Ryan Olson | chore: cargo machete - remove unused dependencies (#6453) |
| 2026-02-21 02:47:59 | Yongming Ding | refactor(mocker): modularize into common/scheduler/kv_manager/cache (#6440) |
| 2026-02-21 02:36:18 | Jacky | feat: Configurable Request Cancellation abort passage to TRT-LLM  (#6445) |
| 2026-02-21 02:33:02 | MatejKosec | feat: interleaved thinking support in reasoning parser (#6422) |
| 2026-02-21 01:48:21 | Ayush Agarwal | fix: vllm omni image perf fix (#6451) |
| 2026-02-21 01:16:04 | mwieczorek | fix(recipes): change componentType from "main" to "worker" for TRT-LL… (#5788) |
| 2026-02-21 01:08:15 | Dmitry Tokarev | fix: use diff temp dir for pytest (#6449) |
| 2026-02-21 01:07:37 | Dmitry Tokarev | fix: increase lychee timeouts and retries (#6444) |
| 2026-02-21 00:53:10 | Julien Mancuso | chore: remove mechanism to disable webhooks (#6441) |
| 2026-02-21 00:27:44 | Qi Wang | feat: add embedding cache to pd worker (#6061) |

### 📊 统计摘要
> 本日共 19 个提交 | 🔴高 8 | 🟡中 9 | 🟢低 2
## 📋 目录

- [ai-dynamo/dynamo](#ai-dynamo-dynamo)
  - [📊 统计摘要](#-统计摘要)
  - [🔴 高重要度变更 (8)](#-🔴-高重要度变更-8)
    - [feat: Remove public uses of CancellationToken (#6405)](#42d6980)
    - [feat(chrek): external restore, signal-based IPC, and pack...](#bb8fc8a)
    - [feat(frontend): Reduce Python-side overhead in the vLLM c...](#f91b42b)
    - [fix: reintroduce helm docs autogeneration (#6459)](#fd839b8)
    - [refactor(mocker): modularize into common/scheduler/kv_man...](#9b2e8f3)
    - [feat: Configurable Request Cancellation abort passage to ...](#41d7d54)
    - [feat: interleaved thinking support in reasoning parser (#...](#d82b005)
    - [feat: add embedding cache to pd worker (#6061)](#c82fe88)
  - [🟡 中重要度变更 (9)](#-🟡-中重要度变更-9)
    - [fix: Multimodal flag was ignored for TRTLLM (#6468)](#8d30cd4)
    - [fix: Fix dev container build (#6455)](#a798e08)
    - [fix: Docker push retries (#6456)](#6c698b8)
    - [chore: cargo machete - remove unused dependencies (#6453)](#7a6283e)
    - [fix: vllm omni image perf fix (#6451)](#7409bd3)
    - [fix(recipes): change componentType from "main" to "worker...](#edc0d4b)
    - [fix: use diff temp dir for pytest (#6449)](#2baafc2)
    - [fix: increase lychee timeouts and retries (#6444)](#16cec71)
    - [chore: remove mechanism to disable webhooks (#6441)](#f385661)
  - [🟢 低重要度变更 (2)](#-🟢-低重要度变更-2)
    - [Run Fault Tolerance test jobs only in Nightly pipeline (n...](#c8423b5)
    - [test: add TensorRT-LLM multimodal EPD test for nightly CI...](#da7d3e9)
#### 🔴 高重要度变更 (8)

### feat: Remove public uses of CancellationToken (#6405)
**SHA**: `42d6980` | 🔗 [查看提交](https://github.com/ai-dynamo/dynamo/commit/42d698054665965edb5659f6617aac1ca591cf03)

**🎯 变更类型**：功能增强 / 架构变更  
**⚡ 重要程度**：🔴 高  
**📋 变更摘要**：  
- 将 Python 端服务（`HttpService`、`KserveGrpcService`）的 `run` 接口从接受外部 `CancellationToken` 改为直接接受 `DistributedRuntime`，内部自行创建并管理子 token。  
- 为两类服务新增 `shutdown()` 方法，实现对内部 token 的安全取消。  
- 移除 `CancellationToken` 在 Python 绑定层的公开导出及其相关 API，统一由 `DistributedRuntime` 完成 token 管理，更新示例、测试以及 `.pyi` 类型定义。  

**🎯 影响范围**：  
- `lib/bindings/python/rust/http.rs`、`kserve_grpc.rs`（核心服务实现）  
- `lib/bindings/python/rust/lib.rs`（删除公开的 `CancellationToken` 类）  
- Python 示例 `examples/kserve_grpc_service/server.py`、`examples/openai_service/server.py`  
- 测试 `tests/test_http_server.py`、`tests/test_kserve_grpc.py`  
- 类型存根 `dynamo/_core.pyi`（API 文档同步）  

**🔍 技术洞察**：

- **架构影响**  
  - **封装性提升**：取消了 `CancellationToken` 的公开暴露，防止用户对运行时内部 token 进行不当操作，降低 API 表面复杂度。  
  - **责任归属明确**：`DistributedRuntime` 统一负责 token 的创建和生命周期管理，服务仅需在 `run` 时获取子 token，`shutdown` 时自行取消，符合“一致的资源拥有者”原则。  
  - **实现细节**：使用 `Arc<OnceLock<CancellationToken>>` 替代原先的 `Mutex<Option<CancellationToken>>`，保证 **一次性初始化** 且无锁竞争，消除潜在的双重初始化 race condition。  

- **性能影响**  
  - **锁消除**：`OnceLock` 的原子一次性写入在多数情况下比 `Mutex` 更轻量，尤其在高并发的服务启动路径上可略微降低延迟。  
  - **运行时开销**：额外的 `Arc` 包装及一次性检查对整体性能影响可以忽略不计。  

- **安全考虑**  
  - **线程安全**：`CancellationToken.cancel()` 本身已是线程安全的，`OnceLock` 再次保证写入的唯一性；无需额外同步，避免了因锁错用导致的死锁或竞争。  
  - **错误检测**：在 `run` 中检测重复调用并抛出 `RuntimeError`，防止同一实例被多次启动导致未定义行为。  
  - **向后兼容**：直接删除公开 `CancellationToken` 属于非兼容变更，若用户仍持有旧 token，可能出现 “已取消但服务未关闭” 的资源泄漏风险，需在迁移文档中明确提醒。  

**⚠️ 潜在风险**：

1. **破坏向后兼容**  
   - 任何依赖 `CancellationToken`（如自定义退出逻辑或外部监控） 的用户代码在升级后会编译/运行错误。  
2. **迁移遗漏**  
   - 示例、文档或第三方库仍可能调用已删除的 `runtime.child_token()`，导致运行时异常。  
3. **单例初始化竞争**  
   - 虽然 `OnceLock` 抛出错误时已返回明确 `RuntimeError`，但若在极端的多线程环境下两次几乎同时调用 `run`，仍可能触发错误路径，需要用户捕获并处理。  
4. **测试/CI 脚本未同步**  
   - 部分内部 CI 仍可能使用旧 token，可能产生假阴性或假阳性测试结果。  

**💡 关注建议**：

- **文档与迁移指南**  
  - 在发布说明中明确标记为 **破坏性变更**，提供 `runtime.child_token()` → `service.run(runtime)` + `service.shutdown()` 的迁移示例。  
  - 更新所有官方文档、示例和 `README` 中的 API 描述。  

- **版本号策略**  
  - 由于是公开 API 删除，建议将主版本号升级（例如从 `0.x` 到 `1.0`，或 `0.10` → `0.11` 视项目约定），并在 `CHANGELOG` 中突出此变更。  

- **向后兼容层（可选）**  
  - 若社区需要平滑过渡，可在下一次小版本中提供一个 **废弃的** `CancellationToken` 包装类，内部仅转发到 `DistributedRuntime.child_token()`，并在文档中给出 `DeprecationWarning`。  

- **测试覆盖**  
  - 确保所有服务的 `run`/`shutdown` 流程都有单元与集成测试，特别是异常路径（重复 `run`，未调用 `shutdown`）。  
  - 在 CI 中加入对旧 API 的编译检查，以防误用。  

- **监控与日志**  
  - 在 `shutdown()` 中加入日志（`info!("HttpService shutdown via token")`），帮助运维快速定位服务终止原因。  

- **代码审查要点**  
  - 检查所有 `DistributedRuntime` 的实例在传递给服务前已完成初始化（`inner()` 已可用）。  
  - 确认 `Arc<OnceLock<_>>` 的使用没有泄露 `Arc`，即服务对象在 `drop` 前仍持有唯一引用，避免因循环引用导致内存泄漏。  

通过上述改动，项目的 API 更加简洁、内部资源管理更安全，并为未来的扩展（如多服务协同关闭）奠定了更坚实的基础。祝迁移顺利！

---

### feat(chrek): external restore, signal-based IPC, and package refactor (#6286)
**SHA**: `bb8fc8a` | 🔗 [查看提交](https://github.com/ai-dynamo/dynamo/commit/bb8fc8a4a969357000caf57c79af47df6b2e2113)

⚠️ LLM分析失败（已重试3次）: API请求失败: 400 Client Error: Bad Request for url: https://integrate.api.nvidia.com/v1/chat/completions

*暂无分析*

---

### feat(frontend): Reduce Python-side overhead in the vLLM chat path (#6437)
**SHA**: `f91b42b` | 🔗 [查看提交](https://github.com/ai-dynamo/dynamo/commit/f91b42b909352794bed874295803b063bef85db3)

**🎯 变更类型**：功能增强  
**⚡ 重要程度**：🔴高  

**📋 变更摘要**  
本次提交为 Dynamo 前端引入了可选的性能调试开关（`--dyn-debug-perf`）以及可配置的预处理工作进程池（`--dyn-preprocess-workers`），通过在 Python 侧并行化 tokenization、模板渲染等 CPU‑bound 步骤，显著降低了 vLLM 聊天路径的同步阻塞开销。同时新增了性能计数器、同步/异步预处理函数以及相应的配置、日志与测试支撑。

**🎯 影响范围**  
- `components/src/dynamo/frontend/frontend_args.py`（新增 CLI 参数）  
- `components/src/dynamo/frontend/main.py`（将 `debug_perf` 传递给工厂）  
- `components/src/dynamo/frontend/perf_instrumentation.py`（性能计数实现）  
- `components/src/dynamo/frontend/prepost.py`（引入 `AsyncMicrobatchTokenizer`、请求准备拆分、同步版本 `preprocess_chat_request_sync`、快速路径优化）  
- `components/src/dynamo/frontend/vllm_processor.py`（核心改造：工作进程池、调度改写、日志埋点、异常包装）  
- `components/src/dynamo/frontend/vllm_processor.py` 中的 `EngineFactory`（创建 `ProcessPoolExecutor`、热身、异常处理）  
- `components/src/dynamo/mocker/main.py`（代码格式细微调整）  
- 测试 `components/src/dynamo/vllm/tests/test_vllm_renderer_api.py`（验证 `PreprocessWorkerResult` 可 pickle）  

**🔍 技术洞察**  

- **架构影响**  
  - **解耦前处理**：将原有的同步 `preprocess_chat_request` 拆分为可在子进程中执行的 `preprocess_chat_request_sync`，通过 `ProcessPoolExecutor` 实现“阶段 A → B → C” 的流水线化，降低主事件循环的阻塞时间。  
  - **可选并行层**：在 `VllmProcessor` 中引入 `preprocess_pool` 与信号量控制，以实现 “工作进程数 × 并行请求” 的可配置并发，保持向后兼容（`preprocess_workers=0` 时保持单进程行为）。  
  - **性能监控层**：`perf_instrumentation` 通过简单的全局计数实现并发请求数峰值监控，配合日志输出，方便在生产环境快速定位瓶颈。  
  - **模块化配置**：新增 `debug_perf` 与 `preprocess_workers` 两个 config 字段，统一由 CLI/Env 解析，保持配置路径一致性。  

- **性能影响**  
  - **CPU‑bound 步骤并行化**：tokenizer、模板渲染等操作在子进程拥有独立 GIL，可实现线性加速（理论上 N 工作进程≈N 倍提升），特别在高并发、长 prompt 场景下显著降低平均响应 latency。  
  - **异步 tokenization**：`AsyncMicrobatchTokenizer` 采用 vLLM 提供的 async 微批机制，进一步减少 I/O 与 CPU 切换开销。  
  - **调试开关开销**：`--dyn-debug-perf` 在每个 generator 生命周期记录进入/退出计数及时延，除去日志写入本身，对正常路径影响可忽略（<1 ms）。  
  - **内存占用**：每个子进程会复制 tokenizer、模型配置等对象，可能导致额外几百 MB 的驻留内存，需在资源受限的部署环境中酌情设置 `preprocess_workers`。  

- **安全考虑**  
  - **子进程隔离**：使用 `ProcessPoolExecutor` 天然提供了进程级别的内存隔离，安全性不低于原实现。  
  - **异常包装**：`_PreprocessError` 将用户可见错误包装为结构化 dict，避免异常信息泄漏。  
  - **环境变量**：新增 `DYN_VLLM_SKIP_REQUEST_VALIDATION`、`DYN_VLLM_STREAM_INTERVAL` 等 env 变量均为可选且默认安全，未做额外安全校验。  
  - **日志**：调试日志中会输出 active_requests、timings，若在生产环境开启可能泄露请求并发信息，建议仅在调试阶段打开。  

**⚠️ 潜在风险**  
1. **进程启动与资源消耗**：在容器或受限资源的节点上，启动多个子进程可能导致 OOM 或启动延迟。  
2. **跨平台兼容性**：`ProcessPoolExecutor` 在 Windows 需要 `if __main__` guard；当前代码未做显式兼容处理，可能导致在 Windows 环境下运行失败。  
3. **Pickle 依赖**：返回的 `PreprocessWorkerResult` 必须全部可 pickle；若未来加入非 pickle‑friendly对象（如自定义 C 扩展），会导致整体流程失效。  
4. **GIL 争用与锁**：虽然计数器在 GIL 下是原子操作，但在高并发时会产生热点，可能轻微抑制并行度。  
5. **调试开关泄露**：开启 `--dyn-debug-perf` 后日志会记录请求 ID 与活跃请求数，若日志未加脱敏处理，可能被外部窃取请求并发情况。  
6. **错误传播**：子进程抛出的 `_PreprocessError` 会被捕获并直接返回错误 dict，若错误信息格式不符合 OpenAI 错误规范，前端客户端可能出现解析异常。  

**💡 关注建议**  

- **资源规划**：在生产部署时，根据模型大小与机器内存，显式设置 `--dyn-preprocess-workers`（如 1~2），并监控内存峰值。  
- **平台适配**：若计划在 Windows 环境使用，添加 `if __name__ == "__main__":` 防护或使用 `multiprocessing.set_start_method("spawn")`。  
- **安全审计**：在生产环境关闭 `--dyn-debug-perf`，或将 logger 级别调至 `WARNING`，防止敏感并发信息泄漏。  
- **回退路径**：保持 `preprocess_workers=0` 作为快速回退选项，以便在子进程出现异常时不影响整体服务可用性。  
- **测试覆盖**：针对不同 `preprocess_workers` 配置进行压力测试，验证在高并发下的 latency、吞吐与内存占用；在 CI 中加入 Windows 子进程启动的兼容性检查。  
- **文档更新**：在用户手册中明确说明 `--dyn-preprocess-workers` 只在 `--dyn-chat-processor vllm` 场景下生效，以及调试开关的日志级别与环境变量。  

---  
通过以上改动，Dynamo 前端在保持功能完整的前提下，显著降低了 Python 侧的同步阻塞，提供了可选的性能调试与预处理并行化能力。但在实际部署时需慎重评估资源、平台兼容性以及日志泄露风险，确保新特性带来的收益能够被安全、可靠地兑现。

---

### fix: reintroduce helm docs autogeneration (#6459)
**SHA**: `fd839b8` | 🔗 [查看提交](https://github.com/ai-dynamo/dynamo/commit/fd839b8d575826ac702d66ab4baf3e56b4fae6ba)

**🎯 变更类型**：Bug修复 / 功能增强（恢复 Helm 文档自动生成）  
**⚡ 重要程度**：🔴高  
**📋 变更摘要**：本次提交在 `deploy/helm/charts/platform` 目录新增 Makefile，用于本地下载 `helm-docs` 并基于 `values.yaml` 与模板自动生成 Helm Chart 的 `README.md`。同时在 `deploy/operator/Makefile` 中把文档生成步骤加入 `check` 流程，并更新 `.helmignore` 以排除生成的 `bin/` 与 Makefile。目标是确保每次提交或 CI 检查前 Helm 文档保持最新，防止因手动编辑导致的文档漂移。

**🎯 影响范围**：  
- `deploy/helm/charts/platform`（Helm Chart 包含的文档生成）  
- `deploy/operator/Makefile`（CI 检查、代码生成）  
- CI/CD 流水线（新增下载二进制、执行 Make 目标）  

**🔍 技术洞察**：  
- **架构影响**：仅在构建/发布阶段增加一个独立的文档生成子模块，不会影响运行时二进制或服务架构。通过 `Makefile` 把 Helm 文档生成与 Operator 的验证流程解耦，提升可维护性。  
- **性能影响**：CI 运行时会多一次网络下载（`helm-docs`）和一次文档渲染，耗时预计在 5–10 秒左右，对生产性能无任何影响。  
- **安全考虑**：`helm-docs` 通过 HTTP GET 从 GitHub Release 拉取二进制，未做校验和或签名验证，存在供应链攻击风险。若构建环境被劫持，恶意二进制可能被执行。建议在受信任网络或使用哈希校验来降低风险。  

**⚠️ 潜在风险**：  
1. **网络不通或 GitHub Rate‑Limit** 导致 `helm-docs` 下载失败，使 CI 检查卡死。  
2. **二进制兼容性**：新版本 `helm-docs` 可能改变模板渲染行为，导致生成的 `README.md` 与预期不符。  
3. **.helmignore** 误将实际需要的文件排除（如误加入 `bin/`），导致 Helm 包发布时缺失文件。  

**💡 关注建议**：  
- 为 `helm-docs` 下载添加 SHA256 校验或使用官方提供的 `checksums.txt`，确保二进制完整性。  
- 在 CI 中为下载步骤加入重试机制或缓存（如使用 `actions/cache`），避免因网络波动导致构建失败。  
- 将 `helm-docs` 版本锁定在 `Makefile` 中，并在升级前通过本地回归测试验证文档输出。  
- 定期审查 `.helmignore`，确保仅排除生成过程产生的临时文件，不影响真实的 Helm 资源。  

---  

此改动提升了 Helm Chart 文档的一致性与自动化程度，风险主要集中在构建阶段的外部二进制获取上，适当的校验与缓存即可将风险降至可接受水平。

---

### refactor(mocker): modularize into common/scheduler/kv_manager/cache (#6440)
**SHA**: `9b2e8f3` | 🔗 [查看提交](https://github.com/ai-dynamo/dynamo/commit/9b2e8f3dd5a4c77ded47e84b396797d3f5c0ced8)

**🎯 变更类型**：重构 / 架构变更  
**⚡ 重要程度**：🔴 高  

**📋 变更摘要**  
本次提交对 `dynamo-mocker` 进行大幅度模块化，拆分出 `common`、`scheduler`、`kv_manager`、`cache` 四个子包，并在 `kv_manager` 中引入全新的 `HashCache` 实现，用统一的 O(1) 哈希表 + LRU 失活池替代原先散落在多个文件中的 `HashMap` + `LRUEvictor` 组合。与此同时，所有对外公开的路径统一迁移到 `dynamo_mocker::common::*`，并通过 `pub use` 保留了一定的向后兼容。

**🎯 影响范围**  
- `lib/mocker/src/*`（核心实现）  
- `lib/kv-router/benches/*`（基准测试）  
- 依赖 `dynamo-mocker` 的外部 crates（导入路径必须更新）  
- KV 缓存相关的业务逻辑（如 `KvManager`、调度器 `Scheduler`）  

**🔍 技术洞察**  

- **架构影响**  
  - **模块边界清晰**：`common` 汇聚所有与业务无关的通用工具（bootstrap、evictor、perf_model、protocols、running_mean、sequence），`kv_manager` 只关注 KV 块管理，`scheduler` 专责调度实现，`cache` 负责缓存抽象。此结构提升了代码可读性、可维护性，并为未来多后端（如 vLLM、FastChat）提供了插拔点。  
  - **公共 API 调整**：原来的 `dynamo_mocker::{BootstrapServer, DirectRequest, KvCacheEventSink, ...}` 已迁移至 `dynamo_mocker::common::*`，且 `Scheduler` 被重新导出自 `dynamo_mocker::scheduler::vllm`. 对外使用者若未更新 import 将编译失败。  
  - **内部耦合度降低**：`KvManager` 只依赖 `cache::HashCache` 与 `common::protocols`，不再直接使用 `evictor`、`sequence` 等实现细节，便于单元测试和模块替换。  

- **性能影响**  
  - **缓存结构统一为 O(1) 哈希查找**：`HashCache` 将活跃块和失活块分别存放在 `HashMap` 与 `LRUEvictor`，对 `contains`、`insert`、`remove` 均保持常数时间，理论上与旧实现相当，但代码路径更短，避免了重复遍历两个独立容器。  
  - **引用计数管理更集中**：通过 `increment_ref` / `decrement_ref` 方法，避免了手动对 `HashMap` 的多次 `get_mut`，降低 cache‑miss 的概率。  
  - **添加的包装层（Cache struct）引入极小的运行时开销（一次结构体解引用），在高并发场景下可以通过 `Arc<Mutex<>>` 等方式外部包装，暂无性能回退风险。  

- **安全考虑**  
  - **未引入新的外部依赖**，仅做内部抽象。  
  - **引用计数边界检查**：`deactivate`、`reactivate` 中加入 `debug_assert!`，在 debug 编译时可捕获不一致的状态，提升安全性。  
  - **公共路径变更** 可能导致误用旧路径而编译报错，属于兼容性问题而非安全漏洞。  

**⚠️ 潜在风险**  
1. **向后兼容性**：外部项目若仍然 `use dynamo_mocker::{DirectRequest, Scheduler}`，在当前版本会编译失败，需迁移到 `dynamo_mocker::common::protocols::DirectRequest` 与 `dynamo_mocker::scheduler::Scheduler`。  
2. **引用计数逻辑微调**：`MoveBlock::Dereference` 现在先读取计数再决定是否 `deactivate`，若 `get_active_ref_count` 返回 `None`（块已被移到 inactive）将触发 panic，需确保所有路径在块被移动到 inactive 前已完成对应的引用计数更新。  
3. **测试覆盖不足**：新 `HashCache` 的边界（如在 `max_capacity` 达到后连续 evict、reactivate、deactivate 循环）需要更细粒度的单元测试，防止出现隐藏的泄漏或错误的 LRU 顺序。  
4. **多线程使用**：`HashCache` 本身是单线程结构体，若未来在调度器中加入并发访问（如跨线程的 KV 管理），需要外部加锁或使用并发容器，否则会出现数据竞争。  

**💡 关注建议**  
- **迁移指引**：在项目文档或发布说明中明确列出旧路径 → 新路径的映射表，提供示例代码以降低用户迁移成本。  
- **兼容层**：考虑在 `dynamo_mocker` 根目录保留少量兼容 shim（如 `pub use common::protocols::*;`），在下一大版本再正式移除，以平滑升级。  
- **完善测试**：新增对 `HashCache` 的压力测试，覆盖 `is_at_capacity`、连续 `deactivate`/`reactivate`、以及 `evict_inactive` 的 LRU 正确性。  
- **并发规划**：若调度器未来需要跨线程共享 `KvManager`，提前评估是否在 `cache::HashCache` 内部引入 `RwLock` 或者在外层提供 `Arc<Mutex<>>` 包装，避免后期大规模改动。  
- **监控和日志**：保持 `KV_CACHE_TRACE_ENABLED` 的日志输出，同时可以在 `HashCache` 中加入 `debug_assert!` 检查 `active_blocks.len() + inactive_blocks.len() <= max_capacity`，帮助快速定位容量越界问题。  

总体来看，此次重构提升了项目的模块化程度和代码可维护性，性能保持并有望在后续迭代中进一步优化。唯一需要重点关注的是向后兼容路径的迁移以及对新缓存实现的全面测试。

---

### feat: Configurable Request Cancellation abort passage to TRT-LLM  (#6445)
**SHA**: `41d7d54` | 🔗 [查看提交](https://github.com/ai-dynamo/dynamo/commit/41d7d5490fc8e723fa1ef88ec946d9c7f4ec89b4)

**🎯 变更类型**：功能增强  

**⚡ 重要程度**：🔴高  

**📋 变更摘要**  
在 TRT‑LLM 引擎的请求取消路径中加入 `--disable-request-abort` 配置开关，默认关闭（即不调用 `abort()`），以规避在大量并发取消时可能出现的卡死问题。该开关从 CLI/环境变量一路透传到 `HandlerBase` 与工作进程配置，并补充对应单元测试，确保在开启/关闭两种模式下的行为符合预期。

**🎯 影响范围**  
- `components/src/dynamo/trtllm/backend_args.py` – CLI 参数与 `DynamoTrtllmConfig`。  
- `components/src/dynamo/trtllm/request_handlers/handler_base.py` – 取消处理逻辑以及配置结构。  
- `components/src/dynamo/trtllm/workers/llm_worker.py` – 生成 `HandlerBase` 时传递新字段。  
- 相关测试文件（`trtllm_handler_base.py`, `fault_tolerance/cancellation/test_trtllm.py`, `fault_tolerance/migration/test_trtllm.py`）。  

**🔍 技术洞察**  

- **架构影响**  
  - **配置链路扩展**：在 `backend_args` → `DynamoTrtllmConfig` → `RequestHandlerConfig` → `HandlerBase` → `LLMWorker` 中新增字段，保持了现有的配置传播模式，无需改动核心运行时逻辑。  
  - **行为分支**：`HandlerBase._handle_cancellation` 根据 `disable_request_abort` 决定是否调用 `generation_result.abort()`，实现了对底层 TRT‑LLM 引擎取消行为的可控切换。  

- **性能影响**  
  - **关闭 abort**（默认）可避免在高并发取消场景下因 `abort()` 阻塞导致的 worker 卡死，从而提升系统整体可用性与吞吐。  
  - **开启 abort** 时，取消请求会及时释放 GPU KV 缓存，降低残留内存占用，提升后续请求的资源利用率。两者在不同负载下各有优势，提供了调优空间。  

- **安全考虑**  
  - 此改动不涉及网络、权限或数据泄露，仅影响内部资源回收。唯一需关注的是：若在高并发环境误将 `disable_request_abort` 设置为 **false**，且 TRT‑LLM 的 abort 实现仍有潜在死锁风险，可能导致服务不可用，属于可用性层面的安全（服务可用性）问题。  

**⚠️ 潜在风险**  

1. **资源泄漏风险**  
   - 当 `disable_request_abort=true`（默认）时，已取消的请求的 KV 缓存不会被主动清理，若大量取消持续发生，可能导致 GPU 内存占满、OOM 或请求排队延迟。  

2. **配置误用**  
   - 参数名为 `--disable-request-abort`，默认 `True`，语义上是“禁用 abort”。新手开发者可能误解为“启用 abort”，导致意向相反的配置。  

3. **兼容性回归**  
   - 某些外部监控或治理工具可能依赖 `abort()` 的调用来记录取消事件，关闭 abort 可能导致日志或指标缺失。  

4. **测试覆盖局限**  
   - 单元测试使用 `MagicMock` 验证 `abort()` 是否被调用，未覆盖真实 TRT‑LLM 引擎在高并发取消下的行为，仍需在集成环境中验证。  

**💡 关注建议**  

- **文档与示例**：在 README / CLI 手册中明确说明 `--disable-request-abort` 的默认行为、取值意义以及何时建议开启（例如在资源紧张且取消频率低的场景）。  
- **监控指标**：新增 `request_abort_invoked` 指标，帮助运维快速判断当前是否在使用 abort，以及其成功率。  
- **安全阈值**：考虑在配置中加入可选的 “强制 abort” 超时阈值，或在检测到 GPU 内存占用异常时自动切换 `disable_request_abort`。  
- **回滚策略**：若在生产环境开启 abort 后出现卡死，提供快速方式（环境变量或 runtime 重新加载）切换回禁用模式，降低故障恢复时间。  
- **更完善的集成测试**：在真实 TRT‑LLM 环境下跑并发取消压力测试，验证两种模式下的内存占用、响应延迟以及潜在死锁情况。  

通过上述措施，可确保新开关在提供灵活调优能力的同时，避免因误用导致的资源泄漏或可用性回退。

---

### feat: interleaved thinking support in reasoning parser (#6422)
**SHA**: `d82b005` | 🔗 [查看提交](https://github.com/ai-dynamo/dynamo/commit/d82b0050f91f68db3bd3b0142252865c05f5341e)

**🎯 变更类型**：功能增强 / 重构  
**⚡ 重要程度**：🔴高  
**📋 变更摘要**：  
在 `BasicReasoningParser` 中加入对 **交叉式思考（interleaved thinking）** 的完整支持。实现了：  
1. 通过 `overlap()` 检测跨块的部分 `<think>` / `</think>` 标记，实现流式增量解析的无缝衔接。  
2. 改进了 `detect_and_parse_reasoning` 与 `parse_reasoning_streaming_incremental` 的内部状态机，使单次调用即可遍历 **多个** `<think>...</think>` 块，支持 `force_reasoning` 与 `stream_reasoning` 两种模式。  
3. 更新了解析器注册表，新增 `glm45`（以及 `nemotron_nano`）对 `<think>` 的默认映射。  
4. 大量新增单元测试覆盖多块、跨块、部分标签、强制推理等边界情况。  

**🎯 影响范围**：  
- `core` 模块下的推理结果解析器（`ReasoningParser` 实现）  
- 所有基于该解析器的模型适配层（GLM‑4.5/4.7、Qwen‑3、DeepSeek‑R1 等）  
- 相关单元测试和 `parsers::mod` 中的 parser‑type 映射  

**🔍 技术洞察**  

| 维度 | 影响描述 |
|------|----------|
| **架构影响** | - 引入了 **状态机循环**（在 `parse_reasoning_streaming_incremental` 中循环处理 `self._buffer`），把原本“一次只能处理一个块” 的设计升级为 **可递归消费**，提升了解析器的表达能力。<br>- 新增 `overlap()` 工具函数，提供通用的前后缀匹配逻辑，便于后续其他标签（如工具调用）复用。<br>- `force_reasoning` 与 `stream_reasoning` 参数解耦，使同一解析器实例可在不同模型的“思考标签是否显式” 与 “是否实时输出” 场景下复用。 |
| **性能影响** | - 额外的循环遍历与 `String::find`、`String::ends_with` 检查在最坏情况下会在 **O(n·k)**（k 为标签长度）上略有提升，但标签本身极短，实际影响可忽略。<br>- `overlap()` 在每次跨块检测时最多遍历 `delim.len()`（≈7）次，开销极低。<br>- 通过一次调用消费全部块，减少了后续调用的次数，对高频 SSE 流式输出的整体延时有轻微正向提升。 |
| **安全考虑** | - 解析器仍然是**纯文本**处理，没有执行或评估用户生成的内容，未引入新的代码注入面向。<br>- 增加的状态机若在异常输入（如无限循环的未闭合 `<think>`）下持续保持 `self._in_reasoning = true`，可能导致后续正常文本被错误归入推理文本，进而影响工具调用解析；但不会导致系统崩溃或资源泄露。 |
| **可维护性** | - 代码结构更加模块化：`overlap()`、循环状态机、注释解释清晰。<br>- 单元测试覆盖率显著提升（包括跨块、部分标签、强制推理等 30+ 场景），降低回归风险。<br>- `parse_reasoning_streaming_incremental` 的实现现在**不再修改** `self._in_reasoning` 在 `detect_and_parse_reasoning` 中的注释已明确，避免误用。 |
| **兼容性** | - 旧行为（只处理单个块、在 `detect_and_parse_reasoning` 中自动清空 `_in_reasoning`）被保留：如果同时使用 `detect_and_parse_reasoning` 与 `parse_reasoning_streaming_incremental` 同一实例，会得到文档中已说明的 “reset/忽略内部流式状态”。<br>- 新增的 `glm45` 映射仅影响 **配置文件中使用 `glm45` 的模型**，对已有模型无副作用。 |

**⚠️ 潜在风险**  
1. **状态泄漏**：在长时间流式会话中，如果出现未闭合的 `<think>`（例如模型输出错误），`_in_reasoning` 将保持 `true`，导致后续所有普通文本被误归为推理文本，进而阻塞工具调用的检测。  
2. **误判部分标签**：`overlap()` 的阈值设为 `>=2`，防止单字符 `<` 被缓冲。但在极端情况下（如自定义标签 `<th>`），可能仍产生误判，需要在文档中明确“不建议使用与 `<think>` 前缀冲突的自定义标签”。  
3. **并发使用**：解析器内部持有可变状态 (`_buffer`, `_in_reasoning` 等)，若同一实例被多线程共享会产生竞争。当前库大多数使用场景是 **单实例/单线程**，但增加了 `loop` 处理后对并发安全的检查更为重要。  
4. **回退兼容**：老代码如果仍依赖 `detect_and_parse_reasoning` **后** 调用 `parse_reasoning_streaming_incremental`（期待 `_in_reasoning` 被清零），可能遇到不一致行为。虽已在注释中提醒，但实际使用中仍有潜在破坏。  

**💡 关注建议**  
- **文档强化**：在 `ReasoningParser` trait 文档中明确说明两种入口函数的互斥使用场景，以及 `force_reasoning` 与 `stream_reasoning` 的语义。  
- **异常恢复**：在 `parse_reasoning_streaming_incremental` 中加入对 **超时未闭合** 的检测（如累计字符数超过阈值仍未出现 `</think>`），可以主动将状态重置并在 `ParserResult` 中返回残余文本，以防止长链卡死。  
- **并发安全**：若未来计划在多线程环境下复用解析器实例，考虑将内部状态封装为 `RefCell`/`Mutex` 或提供 `clone` 能力，使每条流拥有独立状态。  
- **日志/度量**：在跨块 `overlap` 检测与状态转移处加入 **debug 级别日志**，便于调试模型出现异常标签时快速定位。  
- **回归测试**：加入 **模糊测试**（随机切分 `<think>` 与 `</think>` 的位置）确保 `overlap` 与循环逻辑在极端切分下仍保持语义正确。  
- **配置灵活性**：考虑把 `overlap` 阈值（目前硬编码 `>=2`）抽象为可配置项，以便在特殊模型使用不同分割策略时调优。  

总体来看，此次改动极大提升了 Dynamo 对 **交叉式思考** 场景的兼容性，解决了过去在流式 SSE 中工具调用丢失的问题。只要在使用时遵守文档约定、注意异常闭合情况，风险可控，收益显著。

---

### feat: add embedding cache to pd worker (#6061)
**SHA**: `c82fe88` | 🔗 [查看提交](https://github.com/ai-dynamo/dynamo/commit/c82fe888470187a7ad74bde16951a0b9dbc7d123)

**🎯 变更类型**：功能增强 / 重构  
**⚡ 重要程度**：🔴 高  

**📋 变更摘要**  
1. 在 `multimodal_embedding_cache_manager` 中引入 `CachedEmbedding` NamedTuple，使缓存不仅存储张量，还携带 `image_grid_thw`（图像分块元信息），并相应更新了缓存的增删查逻辑、统计与单元测试。  
2. `embedding_fetcher` 与 VLLM 的 `multimodal_pd_worker_handler`、`prefill_worker_utils` 重新设计，以 **缓存‑先查‑后取‑再写** 的流程统一管理多模态嵌入，加入 NIXL RDMA 缓冲区的延迟释放机制。  
3. 对外导出 API 统一为 `load_multimodal_embeddings`，去除了原先散落在多个文件的 `fetch_embeddings_from_encode_workers`、`accumulate_embeddings`、`load_embeddings` 等旧实现。  
4. 相关单元测试、示例脚本以及 `conftest` 中的图片加载做了兼容处理（Git‑LFS 指针回退到最小 PNG），并在 VLLM 多模态端到端测试中切换至新脚本 `disagg_multimodal_e_pd.sh`。  

**🎯 影响范围**  
- `components/src/dynamo/common/memory/multimodal_embedding_cache_manager.py`  
- `components/src/dynamo/trtllm/multimodal/embedding_fetcher.py`  
- `components/src/dynamo/vllm/multimodal_utils/*`（`prefill_worker_utils.py`、`protocol.py`、`__init__.py`）  
- `components/src/dynamo/vllm/multimodal_handlers/multimodal_pd_worker_handler.py`  
- 所有伴随的单元测试、示例脚本与 CI 配置  

**🔍 技术洞察**  

| 维度 | 影响分析 |
|------|----------|
| **架构影响** | • 引入 **统一的缓存层**，在 PD Worker 与 Encode Worker 之间建立 *读‑写‑缓存* 的闭环，降低重复编码请求的网络/计算成本。<br>• 将原先的 `fetch_embeddings_from_encode_workers → accumulate_embeddings → load_embeddings` 链路压缩成单一的 `load_multimodal_embeddings`，实现 **职责分离**：<br> - `_parse_frontend_request` 只负责解析前端 JSON，<br> - `_load_multimodal_data` 只负责调用缓存/远程获取并返回 `multi_modal_data`，<br> - `_finalize_request_metadata` 负责模型‑特定的元信息注入。<br>• 新增 `_PendingRelease` 类用于 **NIXL RDMA 缓冲区的延迟释放**，防止在 `torch.cat` 前提前释放导致数据 corruption。 |
| **性能影响** | • **缓存命中** 时直接返回张量（及可选的 `image_grid_thw`），可省去跨进程的网络通信、GPU 编码算子及 RDMA 传输，显著降低 **热点图片** 的请求 latency（理论上可降低 30%‑70%）。<br>• LRU 机制基于 **字节容量**，在高并发时仍保持 O(1)（OrderedDict）查询/插入，整体开销可忽略。<br>• 对 **单图** 场景，需要在缓存命中后进行 `tensor.clone()`（在 `_ensure_owned_tensors` 中），会产生一次复制，成本约为 1‑2 ms（取决于张量大小）。<br>• 当 `TRANSFER_LOCAL=0`（使用 NIXL）时，缓存仍使用 **零拷贝视图**，但在单图路径必须在释放前 clone，避免后续 `release_tensor` 把视图数据清零。 |
| **安全考虑** | • 缓存键采用 `MultimodalHasher.hash_bytes(url.encode())`（SHA256），冲突概率极低，无直接安全风险。<br>• 通过 `assert tensor.is_contiguous()` 保证缓存的张量可安全用于 NIXL RDMA，防止不连续张量导致未定义行为。<br>• 代码未引入外部 I/O，仅在 `load_multimodal_embeddings` 中访问网络一次（Encode Worker），不增加攻击面。 |
| **可维护性** | • 将缓存抽象为 `CachedEmbedding` + `MultimodalEmbeddingCacheManager`，后续若需在缓存中加入更多元数据（如时间戳、来源信息）只需扩展 NamedTuple。<br>• 采用 **async/await** 完全异步化的实现，统一错误传播，提升代码可读性。<br>• 大量旧的导入与函数已被剔除，`__init__.py` 只暴露 `load_multimodal_embeddings`，避免用户误用已废弃 API。 |
| **兼容性** | • 原有直接 `cache.set(key, tensor)` 的调用已全部改为 `CachedEmbedding(tensor, grid)`. 旧代码在本次 PR 中已迁移，向后兼容性 **已断裂**，但仅限内部组件（已同步）。<br>• 对外暴露的 `MultimodalEmbeddingCacheManager` 接口保持不变（`get`, `set`, `stats`），仅返回值类型变化。用户代码需适配 `entry.tensor`。 |
| **测试覆盖** | • 新增 `test_vllm_prefill_worker_utils.py` 对 `load_multimodal_embeddings` 的 **全缓存 / 部分缓存 / 无缓存** 场景进行覆盖。<br>• 现有缓存单元测试更新为处理 `CachedEmbedding`。<br>• `conftest` 通过最小 PNG fallback 保证在未拉取 LFS 对象的 CI 环境仍能运行。 |

**⚠️ 潜在风险**  

1. **线程安全**：`MultimodalEmbeddingCacheManager` 使用 `OrderedDict`，在多协程并发 `set/get` 时没有显式锁。若同一 PD worker在多个请求的异步路径上共享同一缓存实例，可能出现竞争条件（读‑写交叉导致计数不准或键错误）。  
2. **内存泄漏**：`_PendingRelease.release_all()` 只在 **单图** 场景手动 clone 后调用，若忘记调用或异常提前退出，NIXL 缓冲区可能未被释放，导致长期占用显存。  
3. **缓存容量误配置**：`capacity_bytes` 由 `--multimodal-embedding-cache-capacity-gb` 参数控制，若配置过小（低于单张图像大小），所有请求都会“缓存未命中”，并且因为 `set` 会直接返回 `False

---

#### 🟡 中重要度变更 (9)

### fix: Multimodal flag was ignored for TRTLLM (#6468)
**SHA**: `8d30cd4` | 🔗 [查看提交](https://github.com/ai-dynamo/dynamo/commit/8d30cd45879d20ffde29f597351d2e9439cf5bec)

**🎯 变更类型**：Bug 修复  
**⚡ 重要程度**：🟡 中  
**📋 变更摘要**：  
1. 先前在 `trtllm` 后端将 `--modality multimodal` 参数的判定硬写为字符串，导致在配置重构后该标志被忽略。  
2. 将判定改为使用统一的 `Modality` 枚举 (`Modality.MULTIMODAL`) 并相应更新导入。  
3. 新增单元测试 `test_init_llm_worker_creates_multimodal_processor`，通过 mock 验证在多模态模式下 `MultimodalRequestProcessor` 会被实例化。

**🎯 影响范围**：  
- `components/src/dynamo/trtllm/args.py`（解析 `modality` 为 `Modality` 枚举）  
- `components/src/dynamo/trtllm/workers/llm_worker.py`（初始化时依据枚举决定是否创建 `MultimodalRequestProcessor`）  
- 测试目录 `components/src/dynamo/trtllm/tests/`（新增 `asyncio`/`mock` 单元测试）  

**💡 关注建议**：  
1. **向后兼容**：确认 CLI 仍能接受旧的 `"multimodal"` 字符串输入并自动转换为 `Modality.MULTIMODAL`，避免已有脚本报错。  
2. **文档同步**：在用户手册和 `--help` 文本中明确说明 `modality` 参数现在基于 `Modality` 枚举，列出可选值。  
3. **全局审查**：项目其他位置（如 `runtime`、`engine`）若仍以字符串比较 `modality`，需统一改为枚举，以免出现隐藏的逻辑分支不匹配。  
4. **测试覆盖**：运行完整的 CI，确保所有后端（包括非 TRTLLM）在多模态标志下仍保持原有行为；对 `Modality` 枚举新增边界值测试（如非法值）。  
5. **性能影响**：修改仅涉及条件分支，无额外开销；但在 `init_llm_worker` 中强制 `skip_tokenizer_init=False`，应确认不会导致不必要的模型加载延迟。  

总体来看，此次改动精准定位并修复了多模态标志失效的问题，并通过单元测试提供了回归保障，风险有限。后续关注枚举在全项目的统一使用即可。

---

### fix: Fix dev container build (#6455)
**SHA**: `a798e08` | 🔗 [查看提交](https://github.com/ai-dynamo/dynamo/commit/a798e08c8157b91b67010f6650eb7df3f8676c04)

**🎯 变更类型**：Bug 修复  
**⚡ 重要程度**：🟡 中  

**📋 变更摘要**  
本次提交修复了 TRT‑LLM 开发容器构建时的两个问题：  
1. Dockerfile 模板渲染错误导致多余的 `-` 符号被保留；  
2. 移除了 `nvidia_entrypoint.sh` 中不再需要的 CUDA 兼容层路径 `/usr/local/cuda/compat/lib.real`，避免在容器运行时出现 LD_LIBRARY_PATH 冲突。  

**🎯 影响范围**  
- `container/templates/dev.Dockerfile`（环境变量拼接）  
- `container/templates/trtllm_framework.Dockerfile`（模板闭合符号）  
- 受影响的仅是构建开发容器的 CI/CD 与本地 `devcontainer`，不影响运行时库或业务代码。  

**💡 关注建议**  
- **构建验证**：在本地和 CI 中重新构建 `trtllm` 开发容器，确认 Docker 镜像能够成功生成且启动入口脚本不再报找不到 `lib.real`。  
- **回归测试**：运行已有的容器相关单元／集成测试，确保环境变量（尤其 `LD_LIBRARY_PATH`）的顺序和内容保持预期。  
- **文档同步**：若有文档或 README 中提及 `compat/lib.real`，及时更新说明，避免误导使用者。  
- **后续监控**：关注后续的 CUDA 升级或 NGC 基础镜像变更，确保移除的路径不会在新镜像中再次出现导致缺失。  

整体而言，此次改动对业务逻辑无直接影响，但对开发者的容器体验有显著提升，建议在下一个发布周期前完成验证并合并。

---

### fix: Docker push retries (#6456)
**SHA**: `6c698b8` | 🔗 [查看提交](https://github.com/ai-dynamo/dynamo/commit/6c698b8b5006a0647251629e00a8f5f8d56b4cba)

**🎯 变更类型**：Bug 修复（提高 Docker 推送的可靠性）  
**⚡ 重要程度**：🟡 中  

**📋 变更摘要**  
- 新增 `retry_push.sh`，在 Docker 镜像推送失败时进行最多 3 次指数退避重试。  
- `docker-tag-push` Action 中的 ECR、ACR 推送逻辑改为调用 `retry_push`，并对条件判断使用 `-n`/`[[ … ]]` 防止空值。  
- `skopeo-copy` Action 增加 `--retry-times 3` 参数，统一重试策略。  
- 工作流 `build-test-distribute-flavor.yml` 将复制 ACR 步骤的默认超时从 5 min 提升至 10 min，给重试留出更宽裕时间。  

**🎯 影响范围**  
- `.github/actions/docker-tag-push`（ECR/ACR 推送）  
- `.github/actions/skopeo-copy`  
- `.github/workflows/build-test-distribute-flavor.yml`  

**💡 关注建议**  
1. 确认 `retry_push.sh` 已加入执行权限，否则 `source` 可能因缺少可执行位导致报错。  
2. 由于工作流开启了 `set -euo pipefail`，`retry_push` 通过 `if docker push …; then return 0; fi` 方式安全退出，仍建议在脚本头部加入 `set -e` 以防意外退出。  
3. 若后续需要自定义重试次数或等待上限，可将 `max_attempts`、`wait_seconds` 参数化为 Action 输入。  
4. 运行环境的 `bash` 需支持算术扩展 `(( … ))`；若在 `sh` 下执行需保持兼容。  
5. 验证在高并发 CI 中多次重试不会触发配额限制或导致长时间占用 runners。  

总体来看，此次修改显著提升了镜像推送的鲁棒性，影响范围限于 CI/CD 步骤，风险较低，只需确保脚本可执行并在 CI 环境中跑通即可。

---

### chore: cargo machete - remove unused dependencies (#6453)
**SHA**: `7a6283e` | 🔗 [查看提交](https://github.com/ai-dynamo/dynamo/commit/7a6283e92742f75d0e4e98d584b1a4b3b42e2140)

**🛠️ 本次提交概览**  
- 通过 `cargo machete` 大幅清理 **未使用的传递依赖**，涉及 `addr2line`, `backtrace`, `gimli`, `inotify`, `candle‑core`, `gemm`, `safetensors`, `toktrie` 等上百个 crate。  
- 同时在若干子库（`bindings/c`, `bindings/kvbm`, `bindings/python`, `runtime/examples/*`）的 **Cargo.toml** 中删掉了 `async‑stream`, `async‑trait`, `futures`, `uuid`, `tracing‑subscriber`, `prometheus` 等依赖，及相应的 `dev‑dependencies`（`rstest`, `tokio‑test` 等）。  
- 伴随锁文件的更新，出现 **版本升级**：`anyhow` → 1.0.102、`clap` → 4.5.60、`bumpalo` → 3.20.2、`syn` → 2.0.117、`tokio` → 1.48.0 等。  

**⚡ 影响范围**  
| 模块 | 主要删除项 | 潜在影响 |
|------|-----------|----------|
| `bindings/*`（C、KVBM、Python） | `async‑stream`, `async‑trait`, `futures`, `uuid`, `tracing‑subscriber`, `prometheus`, `dlpark`, `cudarc`，以及对应的 feature 标记 | 可能破坏用户自定义的 **feature‑gate**（如开启 GPU、Prometheus 导出、UUID 序列化）或 Python 扩展的异步运行时。 |
| `kv-router`、`kvbm-logical`、`runtime` | 删除 `dashmap`, `tokio‑util`, `tokio‑util`, `futures` 等 | 编译仍通过说明已不再在代码里直接使用这些 API；若外部项目依赖这些内部实现细节，将失效。 |
| `llm` | 移除 `candle‑core`, `gemm`, `float8`, `safetensors`, `toktrie` 系列，删除 `hyper`, `hyper‑util`, `tower`, `regex` 等 | 对 **GPU/量化**、**安全推理**（safetensors）以及 **HTTP/2** 功能的可选特性失效；需检查 Cargo.toml 中的 `features` 是否同步删减。 |
| `runtime` | 删除 `tmq`, `inotify`, `nid`, `nix 0.29`，以及对应的 dev‑deps | Linux 文件系统监控、进程 ID 生成等高级功能不再可用；若生产环境依赖这些特性，需要手动重新加回。 |
| `parsers`, `runtime/examples/*` | 删除 `lazy_static`, `rstest`, `tokio‑test` 等 | 测试与示例代码的编译/运行可能受影响。 |

**🔎 核心风险**  
1. **Feature‑gate 不一致**  
   - 例如 `kvbm` 原本的 `dlpark`、`cudarc`、`prometheus` 都是 **可选**，但 `Cargo.toml` 中的 `[features]` 部分未同步更新。开启这些特性后会因缺失依赖导致编译错误。  
2. **间接依赖被误删**  
   - `regex`、`hyper`、`tower` 曾被 `llm` 使用于 **统一请求、HTTP2 服务**。如果代码中仍有 `#[cfg(feature = "http-service")]` 等条件编译分支未清理，运行时会出现 “unresolved import” 错误。  
3. **锁文件版本跳变**  
   - 大量 crate 版本升级（尤其是 `syn`、`clap`）可能触发 **宏展开或 API 兼容性** 的微小差异，需在 CI 中跑完整的 **编译 + 测试**，防止隐藏的破坏。  
4. **示例/测试依赖缺失**  
   - 示例 `service_metrics`、`system_metrics` 的 `serde`、`serde_json`、`tokio` 被删，导致示例无法直接 `cargo run`；若这些示例在 CI 中被执行，将报错。  

**🛡️ 建议**  
- **跑完整工作空间的 CI**（`cargo test --all-features --workspace`），确保在开启所有可选特性时仍能成功编译。  
- **审查并同步 Feature 列表**：在每个 `Cargo.toml` 的 `[features]` 区块删除已不再提供的依赖名称，避免用户误以为可以打开相应功能。  
- **更新文档**：在项目 README 与 crate 文档中标注已删除的可选特性（GPU、Prometheus、Inotify 等），并提供迁移指引。  
- **锁文件清理**：虽然 `Cargo.lock` 已被压缩，但仍建议在提交前执行 `cargo check` 并 `cargo tree` 确认没有残余的 “unused” 条目。  
- **保留最小测试**：若不再使用 `rstest`、`tokio-test` 等测试框架，考虑删掉对应的测试文件或改写为 `#[tokio::test]`，防止 CI 误报缺少依赖。  

**结论**：本次清理显著降低了编译时间与二进制体积，属于积极的维护工作。但因涉及大量 **可选特性** 与 **示例/测试**，务必通过全特性编译和完整测试验证，防止意外断裂对下游使用者造成兼容性问题。 🚀

---

### fix: vllm omni image perf fix (#6451)
**SHA**: `7409bd3` | 🔗 [查看提交](https://github.com/ai-dynamo/dynamo/commit/7409bd3a36dd6e0d66f71391120ea1f391d01323)

**🎯 变更类型**：Bug 修复  
**⚡ 重要程度**：🟡 中  
**📋 变更摘要**：在 `components/src/dynamo/vllm/omni/omni_handler.py` 中，针对 Image 与 Video 请求的 `OmniTextPrompt`，将 `negative_prompt` 的默认值从原来的空字符串 (`""`) 改为 `None`（仅在 `nvext` 存在且其 `negative_prompt` 非空时返回实际值），避免在没有负向提示时向后端传递冗余空字符串，从而提升 VLLM Omni 的推理性能。  

**🎯 影响范围**：  
- `omni_handler.py` 的 `_engine_inputs_from_image` 与 `_engine_inputs_from_video` 两个路径。  
- 任何依赖 `OmniTextPrompt.negative_prompt` 为字符串的上层逻辑（如序列化、模板拼接）可能需要兼容 `None`。  

**💡 关注建议**：  
1. **代码兼容**：检查 downstream 代码（尤其是 JSON 序列化、Prompt 拼装）是否假设 `negative_prompt` 为字符串，必要时改为 `if negative_prompt is not None`。  
2. **文档同步**：在 API 文档中明确 `negative_prompt` 为可选字段，默认 `null` 而非空串。  
3. **回归测试**：新增或更新单元测试，覆盖无 `negative_prompt`、仅有正向提示、以及同时提供正负提示的三种情况，确保行为一致且不抛异常。  
4. **性能监控**：在生产环境打开相应指标，比较修改前后 Image/Video 推理的延迟与显存占用，以验证优化效果。  

此改动对功能影响有限，但可显著降低不必要的数据传输与计算开销，建议在下一个发布周期正式合并。

---

### fix(recipes): change componentType from "main" to "worker" for TRT-LL… (#5788)
**SHA**: `edc0d4b` | 🔗 [查看提交](https://github.com/ai-dynamo/dynamo/commit/edc0d4b69ed17bd5ce2ace6055d4e0e62aea1d6a)

**🎯 变更类型**：Bug 修复  
**⚡ 重要程度**：🟡 中  
**📋 变更摘要**：在三个 TensorRT‑LLM（TRT‑LLM）模型的聚合部署 YAML 中，将 `TrtllmWorker` 的 `componentType` 从 `"main"` 调整为 `"worker"`，统一与组件模型约定。  

**🎯 影响范围**：  
- `recipes/gpt-oss-120b/trtllm/agg/deploy.yaml`  
- `recipes/qwen3-235b-a22b-fp8/trtllm/agg/deploy.yaml`  
- `recipes/qwen3-32b-fp8/trtllm/agg/deploy.yaml`  

**💡 关注建议**：  
1. **兼容性**：确认调度系统或监控平台对 `componentType: worker` 已有相应处理，避免因类型不匹配导致服务未能正常启动。  
2. **回归测试**：在本地或 CI 环境执行完整的部署‑启动‑推理链路，验证模型加载、推理吞吐与之前 `main` 类型的行为一致。  
3. **文档同步**：更新相应的 recipes 文档或示例说明，避免新手仍按旧写法提交错误的 `componentType`。  
4. **监控报警**：部署后观察 `TrtllmWorker` 的健康检查和日志，确保更改未引入隐蔽的资源配额或调度问题。  

总体而言，此改动是一次定位明确的配置修正，风险有限，只要通过上述验证即可安全合入。

---

### fix: use diff temp dir for pytest (#6449)
**SHA**: `2baafc2` | 🔗 [查看提交](https://github.com/ai-dynamo/dynamo/commit/2baafc2a757402dc6ecc78fc2cd7944f45979d5c)

**变更类型**：Bug 修复  
**重要程度**：🟡 中  
**变更摘要**：将 GitHub Actions 中的 pytest 执行命令的 `--basetemp` 参数，从直指 `/tmp` 改为 `/tmp/pytest_temp`，避免与其他进程共用同一临时目录，降低并发冲突风险。  

**影响范围**：  
- `.github/actions/pytest` 工作流（CI 环境）  
- 依赖 `PYTEST_CMD` 生成的临时文件路径的任何后置脚本或缓存逻辑  

**关注建议**：  
1. 确认 `/tmp/pytest_temp` 在每次 CI 运行时已创建（如未自动创建，建议在脚本前加 `mkdir -p /tmp/pytest_temp`）。  
2. 检查是否有其他步骤（如自定义插件、后处理脚本）硬编码了 `/tmp` 作为 pytest 临时目录，必要时同步更新。  
3. 考虑使用 GitHub‑runner 提供的专属临时目录（`$RUNNER_TEMP` 或 `${{ runner.temp }}`）而非固定的 `/tmp`，提升跨平台兼容性。  
4. 若在本地开发或其他 CI 环境使用相同 action，验证该路径的写权限和清理机制，防止残留文件占满磁盘。  

整体来看，此改动提升了 CI 并发执行的可靠性，影响范围局限于测试工作流，只要做好目录创建与清理即可安全合并。

---

### fix: increase lychee timeouts and retries (#6444)
**SHA**: `16cec71` | 🔗 [查看提交](https://github.com/ai-dynamo/dynamo/commit/16cec71399fa840228f4ac49cd21e2af38816515)

**🎯 变更类型**：Bug修复  
**⚡ 重要程度**：🟡 中  
**📋 变更摘要**：在 `docs-link-check.yml` 工作流中，将 Lychee 链接检查的重试次数、重试间隔以及单次请求超时时间分别提升为 4 次、3 秒和 30 秒，以降低因网络抖动或临时不可达导致的检查失败。  
**🎯 影响范围**：CI/CD（GitHub Actions）→ 文档链接校验步骤；间接影响 PR 合并审核流程。  

**💡 关注建议**  
1. **CI 时长**：超时从 20 s→30 s、重试次数加倍，整体耗时可能上升 10–20 %。如果工作流执行时间成为瓶颈，可考虑在非关键分支上使用更短的超时或通过缓存降低网络请求次数。  
2. **误报率**：增加重试有助于抑制因瞬时网络问题产生的误报，但仍应监控 CI 结果，防止“永不失败”导致真实失效链接被忽略。建议在成功率提升明显后，逐步回调到更保守的阈值。  
3. **文档维护**：若后续文档链接结构或外部资源频繁变动（如新加入的 API 文档），仍可能触发超时。可在 workflow 中加入分支过滤或按路径分块检查，以避免不必要的全量扫描。  
4. **回滚方案**：如 CI 稳定性未得到改善，可快速将 `--max-retries`、`--retry-wait-time`、`--timeout` 恢复至原值，提交一次回滚 PR。  

总体而言，此次调参提升了链接检查的鲁棒性，对功能无直接影响，仅在 CI 环境下延长执行时间，需关注整体流水线时长与成功率的平衡。

---

### chore: remove mechanism to disable webhooks (#6441)
**SHA**: `f385661` | 🔗 [查看提交](https://github.com/ai-dynamo/dynamo/commit/f385661ae0e3957b96f9086feca6fb3b3dbec151)

**变更概览**  
本次提交将 `webhook.enabled` 配置彻底移除，Admission Webhooks 成为 Dynamo Operator 的强制组件。对应的 Helm 参数、模板及 Operator 启动标志均被删减，控制器不再在 `Config.WebhooksEnabled` 为 false 时执行自检，所有校验均依赖 Webhook（包括默认化、CRD Conversion）。同时在文档、README 与 Chart 示例中加入 “Webhooks 必须” 的升级说明，并补充了 GPU‑Discovery、checkpoint 等细节。

**核心影响**  
1. **Helm Chart** – `webhook.enabled` 参数被删除，相关的条件渲染 (`if .Values.webhook.enabled`) 均改为无条件或仅依据证书管理方式。部署时默认会走 Helm‑hook 自动生成 TLS，或使用 cert‑manager/外部 secret。  
2. **Operator 代码** – 启动参数 `--enable-webhooks` 与对应 flag 被去除；`Config.WebhooksEnabled` 字段与防御性验证路径全部删除，控制器只保留 Webhook 注册与默认化逻辑。  
3. **文档** – 说明 Webhook 为必装组件，并提供升级检查表（端口 9443 可达、TLS 证书准备、删除旧 `webhook.enabled` 配置）。  
4. **其他** – 新增 `gpuDiscovery`、checkpoint 细化字段，对现有功能无直接冲突。

**风险与注意事项**  
- **网络连通**：API Server 必须能够访问 Operator Pod 的 9443 端口；已有 NetworkPolicy 或防火墙需放通。  
- **TLS 管理**：若之前使用 `webhook.enabled: false` 并自行管理证书，升级前必须确保 `webhook.certificateSecret` 已存在或切换到 cert‑manager。  
- **旧值残留**：自定义 `values.yaml` 中仍保留 `webhook.enabled` 会被 Helm 忽略但易引起混淆，建议清理。  
- **回滚困难**：禁用 Webhook 不再受支持，若遇到兼容性问题只能通过 `failurePolicy: Ignore` 或临时删除 ValidatingWebhookConfiguration 来绕过。

**建议**  
- **运维**：在升级前执行 `kubectl get validatingwebhookconfiguration` 检查是否已创建；确认 `kubectl get service -n <ns> -l control-plane=controller-manager` 的 9443 端口可达。  
- **开发**：本地调试时可使用 `kubectl delete validatingwebhookconfiguration` 暂时绕过，或在 Chart 中将 `webhook.certificateSecret.external:true` 并自行提供证书。  
- **CI/CD**：更新 Helm 变量模板，移除 `webhook.enabled` 相关渲染，确保 CI 流水线不再向 Helm 传递该键。  

整体来看，此改动统一了验证入口，简化了配置，但要求集群必须满足 Webhook 基础设施（网络、TLS）才能正常部署。请按上述检查表完成升级，以避免不可用的 Operator 实例。

---

#### 🟢 低重要度变更 (2)

### Run Fault Tolerance test jobs only in Nightly pipeline (not in post-m… (#6462)
**SHA**: `c8423b5` | 🔗 [查看提交](https://github.com/ai-dynamo/dynamo/commit/c8423b5748533f997774dd1a143d1b74b2f2db2d)

**🎯 变更类型**：配置调整  
**⚡ 重要程度**：🟢 低  
**📋 摘要**：在 CI 工作流中，将 Fault Tolerance 测试作业的执行条件限制为仅在 `nightly` 流水线运行，避免在常规流水线中执行。

---

### test: add TensorRT-LLM multimodal EPD test for nightly CI (#6193)
**SHA**: `da7d3e9` | 🔗 [查看提交](https://github.com/ai-dynamo/dynamo/commit/da7d3e9e2a0539fd10c8be6b27fd8cddf94bf440)

**🎯 变更类型**：测试修改  
**⚡ 重要程度**：🟢低  
**📋 摘要**：在 `tests/serve/test_trtllm.py` 中新增 TensorRT‑LLM EPD 多模态 nightly CI 测试，改名为 `epd_multimodal`，使用 llava 模型，调整脚本、GPU 标记、请求 payload 与环境变量以适配 2 GPU 场景。

---

