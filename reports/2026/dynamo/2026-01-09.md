# 每日更新报告（2026-01-09）

## ai-dynamo/dynamo

| 提交时间 | 作者 | 提交信息 |
|----------|------|----------|
| 2026-01-09 23:31:09 | dagil-nvidia | docs: add host and bootstrap port to disagg multinode example (#5309) |
| 2026-01-09 22:17:30 | ptarasiewiczNV | fix: reduce VLLM_MOE_DP_CHUNK_SIZE to 384 (#5307) |
| 2026-01-09 14:36:51 | Biswa Panda | fix: enable toggling kv events pub/sub (currently nats based) with --no-kv-events flag (#5237) |
| 2026-01-09 14:31:32 | GuanLuo | fix: KServe propagate error to client in stream infer (#5263) |
| 2026-01-09 08:12:24 | jh-nv | fix: distributed tracing propagation for TCP transport (#5283) |
| 2026-01-09 08:08:07 | Janelle Cai | docs: broken links in benchmarking documentation (#5258) |
| 2026-01-09 08:00:54 | Dmitry Tokarev | fix: add HF_TOKEN to pytests (#5298) |
| 2026-01-09 07:25:13 | Thomas Montfort | feat(operator): DynamoGraphDeployment rollout restart mechanism (#5118) |
| 2026-01-09 04:47:56 | ゆり | fix: preserve original model path for frontend config downloads (#5102) |
| 2026-01-09 04:24:25 | Ayush Agarwal | chore: move custom mm preprocessor to new file (#5278) |
| 2026-01-09 04:03:25 | Tanmay Verma | fix: Add symlink for NCCL in trtllm container (#5257) |
| 2026-01-09 04:03:10 | Wenqi Glantz | feat(vllm): Add prompt embeds support for pre-computed inference inputs (#4739) |
| 2026-01-09 01:54:46 | Hongkuan Zhou | fix: add mem frac for sglang dsr1 8gpu (#5260) |
| 2026-01-09 01:12:06 | ptarasiewiczNV | fix: Update model cache pvc name (#5270) |
| 2026-01-09 00:25:44 | Graham King | fix(vllmsglang): Give sglang/vllm the HF model name not the full path (#5274) |

### 📊 统计摘要
> 本日共 15 个提交 | 🔴高 5 | 🟡中 7 | 🟢低 3
## 📋 目录

- [ai-dynamo/dynamo](#ai-dynamo-dynamo)
  - [📊 统计摘要](#-统计摘要)
  - [🔴 高重要度变更 (5)](#-🔴-高重要度变更-5)
    - [fix: enable toggling kv events pub/sub (currently nats ba...](#0d3ff44)
    - [fix: KServe propagate error to client in stream infer (#5...](#bb8eaa2)
    - [fix: distributed tracing propagation for TCP transport (#...](#ace35a8)
    - [feat(operator): DynamoGraphDeployment rollout restart mec...](#3d67474)
    - [feat(vllm): Add prompt embeds support for pre-computed in...](#6f9619a)
  - [🟡 中重要度变更 (7)](#-🟡-中重要度变更-7)
    - [fix: reduce VLLM_MOE_DP_CHUNK_SIZE to 384 (#5307)](#5f8d90a)
    - [fix: add HF_TOKEN to pytests (#5298)](#fcb7685)
    - [fix: preserve original model path for frontend config dow...](#f7ba417)
    - [fix: Add symlink for NCCL in trtllm container (#5257)](#22e36de)
    - [fix: add mem frac for sglang dsr1 8gpu (#5260)](#bfb95df)
    - [fix: Update model cache pvc name (#5270)](#6458ef8)
    - [fix(vllmsglang): Give sglang/vllm the HF model name not t...](#fcc4a60)
  - [🟢 低重要度变更 (3)](#-🟢-低重要度变更-3)
    - [docs: add host and bootstrap port to disagg multinode exa...](#c29f78c)
    - [docs: broken links in benchmarking documentation (#5258)](#d0cfc40)
    - [chore: move custom mm preprocessor to new file (#5278)](#1c9fea0)
#### 🔴 高重要度变更 (5)

### fix: enable toggling kv events pub/sub (currently nats based) with --no-kv-events flag (#5237)
**SHA**: `0d3ff44` | 🔗 [查看提交](https://github.com/ai-dynamo/dynamo/commit/0d3ff44000b70666300eaa37a0340ffbc25a0984)

**🎯 变更类型**：功能增强 / Bug修复  
**⚡ 重要程度**：🔴高  

**📋 变更摘要**  
本次提交为 Dynamo 系统引入 KV 事件（基于 NATS）的可选开关，默认仍启用。新增 `--kv-events/--no-kv-events`（Python 端 `BooleanOptionalAction`）以及 `enable_nats` 参数，使得在 **近似模式**（不依赖 NATS）下也能正常运行 KV‑router。为此在前端解析、各后端启动入口、Rust 运行时、Python 绑定以及文档、示例和测试均做了对应适配，并在 `kv_router_nats_publish` 中容忍 NATS 未配置的情况。

**🎯 影响范围**  
- `components/src/dynamo/frontend/main.py`（CLI 参数解析）  
- 各后端入口：`sglang/main.py`, `trtllm/main.py`, `vllm/main.py`（DistributedRuntime 构造）  
- 运行时实现 `lib/runtime/src/distributed.rs`（NATS 可选化）  
- Rust‑Python 绑定 `lib/bindings/python/*`（`DistributedRuntime.__new__` 新增 `enable_nats` 参数）  
- 文档、示例 (`docs/*`, `examples/backends/vllm/launch/agg_router_approx.sh`)  
- 测试套件（`tests/*`）新增近似模式验证  

**🔍 技术洞察**  

- **架构影响**  
  - **NATS 可选化**：`DistributedRuntime` 现在接受 `enable_nats`，在非 NATS 请求平面且该标志为 `false` 时不创建 NATS 客户端。  
  - **KV‑router 近似模式**：当 `--no-kv-events`（即 `use_kv_events=False`）时，router 通过 TTL/路由决策自行预测缓存状态，保持功能完整但放弃实时事件同步。  
  - **向后兼容**：默认仍启用 NATS，旧的部署脚本无需改动；新 flag 采用 `BooleanOptionalAction`，兼容 `--kv-events` 与 `--no-kv-events` 两种写法。  

- **性能影响**  
  - **关闭 NATS**：削减网络 I/O、NATS 客户端维护的心跳和 JetStream 持久化开销，降低 CPU/内存占用，适合轻量部署或单机测试。  
  - **路由准确度**：失去实时 KV 事件会导致缓存命中率下降，特别在高并发、跨 worker 场景下可能出现更高的请求延迟。  
  - **发布路径静默**：`kv_router_nats_publish` 在 NATS 未配置时返回 `Ok(())`，避免因缺失 NATS 而导致请求失败，提升容错性。  

- **安全考虑**  
  - **攻击面收缩**：可选关闭 NATS，部署在不需要 KV 事件的环境时可免除外部消息队列的暴露，从而降低潜在的网络攻击面。  
  - **配置解析**：`kv_events_config` 通过 `json.loads` 解析，若解析失败仅记录 warning，不抛异常，避免因恶意或错误的环境变量导致进程崩溃。  

- **可维护性**  
  - 代码分散在多个子模块（frontend、各后端、Rust 运行时、Python 绑定），但统一使用 `use_kv_events`/`enable_nats` 标识，保持一致性。  
  - 文档已同步更新，示例脚本展示近似模式启动方式，帮助使用者快速上手。  

**⚠️ 潜在风险**  
1. **误用 flag**：用户若误以为 `--no-kv-events` 只关闭事件发布而不影响路由，可能在生产环境中因缓存命中率下降出现性能回退。  
2. **兼容性**：`argparse.BooleanOptionalAction` 仅在 Python 3.9+ 可用，旧环境可能报错。  
3. **隐藏错误**：`kv_router_nats_publish` 在 NATS 未创建时直接返回 `Ok(())`，若上层业务期望发布成功而实际未发送，调试会更困难。  
4. **配置漂移**：`use_kv_events` 由 `kv_events_config`（JSON）或 CLI flag 推导，两个来源不一致时可能产生冲突（如 env 中 `DYN_KV_EVENTS=true` 与 `--no-kv-events` 同时出现）。  

**💡 关注建议**  
- **文档与培训**：在官方文档、README 和 CI 示例中明确说明 `--no-kv-events` 为 **近似模式**，并提示在需要高缓存命中率时应保持默认。  
- **版本兼容**：在 `setup.py`/`pyproject.toml` 中声明最低 Python 版本 >=3.9，或在代码中回退到手工实现的 `store_true/store_false` 方案，以防旧环境破坏。  
- **监控与日志**：在 `DistributedRuntime` 初始化以及 KV‑router 启动时添加日志，明确标记 NATS 是否已启用，帮助运维快速定位模式。  
- **单元/集成测试**：增加针对 `enable_nats=False` 时 `kv_router_nats_publish` 的单元测试，确保不抛异常且返回 `Ok(())`。同时验证在近似模式下路由日志显示 `TTL`/`prune` 行为。  
- **回退方案**：在需要紧急恢复 NATS 功能时，可通过 `--kv-events` 强制启用，即使环境变量被误设为 `false`。保持 flag 的优先级高于 env。  

---  

总体来看，此次改动显著提升了 Dynamo 在资源受限或测试环境中的可部署性，同时保持了对生产级 KV‑router 的完整支持。只要在文档、兼容性检查和监控层面做好相应补充，即可安全推广至主线。

---

### fix: KServe propagate error to client in stream infer (#5263)
**SHA**: `bb8eaa2` | 🔗 [查看提交](https://github.com/ai-dynamo/dynamo/commit/bb8eaa23057266a09906f1c74347e02f9ecaadc6)

**🎯 变更类型**：Bug修复 / 功能增强（KServe gRPC 流式推理错误向客户端传播、请求/响应结构体加入严格校验）  

**⚡ 重要程度**：🔴高  

**📋 变更摘要**：  
- 在 `KserveService` 的流式推理实现中，原先直接 `while let Some(response) = stream.next().await`，导致内部错误被忽略。现在改为对每个 `Result` 进行解包，若出现错误则通过 `ModelStreamInferResponse` 的 `error_message` 字段返回给客户端，并继续后续流。  
- 为 Tensor 相关结构体 (`TensorMetadata、TensorModelConfig、Tensor、NvCreateTensorRequest/Response`) 添加 `validator::Validate` 与 `#[serde(deny_unknown_fields)]`，并在转换阶段执行校验，错误时返回 gRPC `invalid_argument` 或 `anyhow`。  
- 增加测试用例模拟响应字段缺失、数据不匹配、工作者抛异常等异常路径，验证错误能够正确回传给客户端（同步与流式两种模式）。  

**🎯 影响范围**：  
- `lib/llm/src/grpc/service/kserve.rs`（流式推理错误处理）  
- `lib/llm/src/grpc/service/tensor.rs`（请求转换时的校验）  
- `lib/llm/src/protocols/tensor.rs`（结构体定义、Serde/Validator）  
- 测试目录 `tests/frontend/grpc/*`（新增异常测试）  

**🔍 技术洞察**：  
- **架构影响**：  
  - **错误传播链路补全**：原先 KServe 前端在流式模式下吞掉了底层 `Result` 错误，导致客户端只能收到空响应或卡死。现在错误被包装成 `ModelStreamInferResponse`，符合 KServe/Trition 的错误协议，提升了服务可观测性。  
  - **统一校验层**：通过 `validator` 在请求/响应对象上执行结构完整性检查，形成统一的入口防御（防止 malformed JSON、未知字段、嵌套结构错误）。这在多前端（HTTP、gRPC、KServe）共享的 `tensor` 协议中建立了“一次校验、处处安全”的模式。  
- **性能影响**：  
  - **微小开销**：`Validate::validate` 在大多数请求/响应体只涉及字段存在性和嵌套结构检查，复杂度为 O(N)（N 为字段数），对推理核心路径影响可忽略。  
  - **流式错误早返回**：在出现错误的 `delta` 时立即 `yield` 错误信息并 `continue`，避免后续不必要的处理，反而可略微提升错误场景下的响应速度。  
- **安全考虑**：  
  - `#[serde(deny_unknown_fields)]` 阻止潜在的 **JSON 注入** 或 **意外字段滥用**，防止攻击者利用未定义字段进行行为劫持。  
  - 校验阶段对 `invalid_argument` 明确返回，减少了错误信息泄漏的风险（不再返回内部 panic）。  
- **可维护性**：  
  - 引入 `validator` 后，结构体的约束清晰可见，后续新增字段只需在定义处添加对应的校验属性，降低了遗漏校验的概率。  
  - 错误包装统一为 `ModelStreamInferResponse { error_message, infer_response: None }`，方便前端统一处理。  

**⚠️ 潜在风险**：  
1. **向后兼容性**：新增的 `deny_unknown_fields` 可能导致已有用户提交包含额外自定义字段的请求被拒绝，需要在文档中明确说明。  
2. **错误信息语义**：在流式模式下继续 `continue` 后的后续 `delta` 仍会被处理，若同一次流中出现多次错误，客户端会收到多条错误响应，可能需要前端聚合或过滤。  
3. **验证库依赖**：`validator` 依赖 `regex` 等 crate，若在极端环境（如 `no_std`）使用可能产生编译冲突；目前项目已在 `std` 环境，风险有限。  
4. **测试覆盖**：新增的异常路径在 CI 中通过，但仍需在生产环境验证不同模型的响应大小与错误率对流式通道的影响（尤其是长文本/大批量流）。  

**💡 关注建议**：  
- **文档更新**：在 KServe/Grpc 接口文档中加入“未知字段将被拒绝”和“流式错误通过 `error_message` 传递”的说明，帮助用户迁移。  
- **客户端适配**：建议在所有使用 KServe 流式推理的 SDK（Python、Go、Rust）中加入对 `error_message` 的检测与异常抛出逻辑，避免用户误把错误响应当作正常结果。  
- **错误聚合**：如果业务场景对单流错误频率有严格要求，可在服务端实现一次错误后直接关闭流（`break`），或在客户端实现错误阈值过滤。  
- **回归测试**：在 CI 中加入大批量流式请求的压力测试，确保异常路径不会导致资源泄漏（如未关闭的 `pin_mut!` 流）。  
- **监控报警**：在监控平台为 `model_stream_infer` 增加错误计数指标（如 `kserve_stream_infer_errors_total`），便于快速定位异常激增的根因。  

---

### fix: distributed tracing propagation for TCP transport (#5283)
**SHA**: `ace35a8` | 🔗 [查看提交](https://github.com/ai-dynamo/dynamo/commit/ace35a8ebcaafe5f1b77e0c3d268017cad90722f)

**🎯 变更类型**：Bug修复  
**⚡ 重要程度**：🔴高  

**📋 变更摘要**  
本次提交修复了 Dynamo 在使用 TCP 传输时分布式追踪上下文未传播的问题。通过在 TCP 请求/响应的报文中加入 W3C Trace Context（`traceparent`、`tracestate`）头部，并在运行时日志与处理链路中解抽取、注入 OpenTelemetry 上下文，实现了跨节点的链路追踪。  

**🎯 影响范围**  
- `runtime::logging`（新增 `extract_otel_context_from_http_headers`、`make_handle_payload_span_from_tcp_headers` 等）  
- `runtime::pipeline::network::codec`（TCP 编码/解码层改造，支持序列化/反序列化 JSON 格式的 headers）  
- `runtime::pipeline::network::egress::tcp_client`（发送请求时附加 headers）  
- `runtime::pipeline::network::ingress::shared_tcp_endpoint`（接收请求时解析 headers 并创建带上下文的 span）  

**🔍 技术洞察**  

- **架构影响**  
  - 引入了统一的 `TRACE_PROPAGATOR`（`TraceContextPropagator`）作为全局单例，避免在每次调用时重复创建。  
  - TCP 协议格式从「endpoint_len + endpoint + payload_len + payload」演进为「endpoint_len + endpoint + headers_len + headers_json + payload_len + payload」，在消息层面加入了可扩展的元数据区。  
  - 通过在 `make_handle_payload_span_from_tcp_headers` 中创建 span 并 `set_parent`，实现了跨进程、跨节点的分布式追踪链路，提升了可观测性。  

- **性能影响**  
  - **新增开销**：在每条 TCP 请求中需要对 `HashMap<String,String>` 做 JSON 序列化（`serde_json::to_vec`）以及对应的反序列化（`serde_json::from_slice`），大约 0.5 ~ 1 µs（取决于 header 大小）。  
  - **消息体积增长**：每条请求会额外携带 `2 bytes`（headers 长度） + 真实 JSON 大小的字节。若仅携带 `traceparent`（~55 bytes）和 `tracestate`（可选），总体增长 < 100 bytes，仍在原有 `max_message_size` 限制范围内。  
  - **CPU 与内存**：使用 `BytesMut` 进行增量写入，保持了零拷贝特性；对大流量场景影响可忽略。  

- **安全考虑**  
  - **输入校验**：在解码时对 headers 长度做了 `u16::MAX` 限制，并在 JSON 解析错误时返回 `InvalidData`，防止恶意构造的超大或非法 JSON 引发 panic。  
  - **泄露风险**：trace ID、span ID 会随请求传播，若网络未加密（TCP 明文）可能被窃听。项目本身已在其他层面提供 TLS，可在使用 TCP 时结合 TLS/Mutual TLS。  
  - **依赖安全**：依赖 `opentelemetry-sdk` 的 `TraceContextPropagator`，已是业界标准实现，无已知安全漏洞。  

**⚠️ 潜在风险**  
1. **向后兼容性**：老版本节点仍按旧协议（不含 headers）解析报文，读取 `headers_len` 时会误读 payload 前的字节导致解码错误。需要在升级时同步所有节点或在协议层加入版本字段/回退兼容。  
2. **消息体积限制**：如果业务侧在 headers 中放入大量自定义字段，可能触及 `u16::MAX` 限制或超过 `max_message_size`，导致请求被拒绝。  
3. **错误传播**：若 `traceparent` 为空或格式错误，`extract_otel_context_from_*` 会返回 `None`，不会影响业务但会导致链路中断。需在监控面板中关注此类错误率。  
4. **JSON 解析性能**：在极端高并发下大量 JSON 解析可能成为瓶颈，建议在高流量环境下评估是否改用更轻量的二进制 Header 编码。  

**💡 关注建议**  
- **升级指南**：发布时提供滚动升级说明，确保所有节点在同一时间点升级到支持 headers 的版本，防止协议不匹配导致连接中断。  
- **监控与告警**：在 `runtime::logging` 增加对 `traceparent` 解析失败的计数器（如 `otel_header_parse_error_total`），并在关键阈值触发报警。  
- **性能评估**：在生产环境开启压测，关注 `tcp_encode_duration_seconds` 与 `tcp_decode_duration_seconds` 两个指标的变化，确认额外的 JSON 序列化开销在可接受范围。  
- **安全加固**：建议在使用 TCP 传输时强制 TLS 加密，或在内部网络中采用 mTLS，以防追踪信息泄露。  
- **文档更新**：在协议说明文档中加入 “headers” 字段的结构、大小限制以及常用的 `traceparent`/`tracestate` 示例，帮助 SDK 使用者正确构造请求。  

---  

*此分析基于代码变更及项目上下文，供开发者在发布与运维阶段参考。*

---

### feat(operator): DynamoGraphDeployment rollout restart mechanism (#5118)
**SHA**: `3d67474` | 🔗 [查看提交](https://github.com/ai-dynamo/dynamo/commit/3d67474ef3ff97582beac0335f69bc2918627a30)

**🎯 变更类型**：功能增强（新增 DynamoGraphDeployment 的滚动重启机制）  

**⚡ 重要程度**：🔴 高  

**📋 变更摘要**  
本次提交在 `DynamoGraphDeployment` CRD 中加入 **restart** 字段（包含 `id` 与 `strategy`），并在状态中记录 **RestartStatus**（observedID、phase、inProgress）。实现了在 Operator 中根据 restart 请求生成 **restart 注解**（`nvidia.com/restartAt`），通过该注解触发 `kubectl rollout restart` 式的滚动升级。控制器在两条部署路径（Component‑mode 与 Grove‑mode）统一计算重启状态、注入注解，并在就绪判定中加入 `observedGeneration`、`updatedReplicas`、`replicas` 等检查，以确保滚动过程完整。与此同时新增 `observedGeneration` 到 `DynamoComponentDeployment`，完善状态同步。还补充了字段校验、深拷贝实现、文档更新以及大量单元测试。

**🎯 影响范围**  
- **CRDs**：`nvidia.com/DynamoGraphDeployment`、`nvidia.com/DynamoComponentDeployment`（状态字段）。  
- **Operator 控制器**：`dynamographdeployment_controller.go`、`dynamocomponentdeployment_controller.go`、`grove.go`（重启状态计算、注解注入、就绪判定）。  
- **内部工具**：`internal/consts/consts.go`（新增 RestartAnnotation 常量）。  
- **验证 webhook**：`webhook/validation/dynamographdeployment.go`（restart 参数校验）。  
- **自动生成代码**：deepcopy、CRD yaml、文档。  
- **测试套件**：新增/扩展 600+ 行单元测试覆盖 restart 逻辑。

**🔍 技术洞察**  

| 维度 | 影响 |
|------|------|
| **架构影响** | 1. 在 Operator 层统一管理重启，将重启策略抽象为 `Restart` 对象，使图部署的滚动升级可声明式完成。<br>2. 通过注解 `nvidia.com/restartAt` 与原生 `Deployment`/`PodClique` 的滚动机制对接，保持与 Kubernetes 原生行为一致。<br>3. 新增 `observedGeneration` 到组件状态，提升 Operator 对资源变更的感知能力，避免因 `generation` 与控制器观察不一致导致误判。 |
| **性能影响** | - 额外的就绪检查（对 `observedGeneration`、`updatedReplicas`、`replicas`）引入几条 API 调用，单次循环开销可忽略（仅在控制器 reconcile 时）。<br>- 重启时会触发一次完整的滚动升级，短暂增加 Pods 启动/终止次数及网络流量，属于业务预期的成本。 |
| **安全考虑** | - 新增注解键 `nvidia.com/restartAt` 属于内部使用，未影响已有 RBAC。<br>- 重启 ID 由用户在 spec 中提供，若恶意用户修改 ID 可导致不必要的滚动，建议在多租户环境下通过 Admission‑Webhook 或 RBAC 限制对 `restart.id` 的写权限。 |
| **可维护性** | - 将重启状态抽象为 `RestartState`、`RestartStatus`，逻辑清晰且统一在 `dynamo/graph.go` 中实现，后续扩展（如支持“暂停”或“回滚”）更易加入。<br>- 完整的单元测试覆盖并行/顺序两种策略以及 Grove 与 Component 两条路径，降低回归风险。 |
| **兼容性** | - 为可选字段，旧版 CRD 在缺失 `restart` 时仍可正常运行；深拷贝已处理 `nil` 场景。<br>- 已在 `generated deepcopy` 中加入对应代码，避免运行时空指针。 |

**⚠️ 潜在风险**  

1. **误触发滚动**：`restart.id` 只要改变即会触发全量重启，若 CI/CD 自动生成的时间戳或哈希不稳定，可能导致频繁滚动。  
2. **顺序策略死锁**：在 `Sequential` 模式下若某服务的就绪判定出现长期阻塞（例如因为外部依赖不可达），整个重启会卡在该服务，导致 `RestartPhaseRestarting` 长时间不退出。  
3. **状态竞争**：`RestartStatus` 与 `observedGeneration` 更新在不同子控制器中（Component 与 Grove），若两者的更新顺序不一致，可能出现状态短暂不一致的情况。  
4. **RBAC 失误**：若用户拥有对 `DynamoGraphDeployment` 的 `patch` 权限但没有对底层 `Deployment/PodClique` 的 `patch` 权限，注解写入将失败，导致重启无法进行。  
5. **文档/客户端同步**：新增字段需要在所有使用该 CRD 的客户端（如 Helm chart、CLI）同步更新，否则会出现 schema 校验错误。  

**💡 关注建议**  

- **CI/CD 稳定化**：建议在生成 `restart.id` 时使用确定性的值（如 `git commit SHA` 或版本号），避免因每次渲染产生不同时间戳导致不必要的滚动。  
- **监控告警**：在监控平台新增对 `RestartPhase` 的监视，如出现长时间 `Restarting` 或 `Failed`，及时报警。  
- **RBAC 审计**：检查并确保能够写入 `restart` 注解的主体（Operator ServiceAccount）拥有对应 `patch` 权限，防止因权限不足导致重启卡住。  
- **极端情况回退**：在 `RestartPhaseFailed` 场景保留上一次成功的 `observedID`，并提供手动回滚的指引（如恢复旧的 `restart.id`）。  
- **文档/示例更新**：在官方 Helm chart、示例 YAML 中加入 `restart` 示例，帮助用户正确使用。  
- **顺序策略验证**：在 Admission‑Webhook 中继续保持对 `order` 的唯一性、完整性校验，防止因 typo 引入不可达的排序。  

总体而言，此次改动为 **DynamoGraphDeployment** 引入了可靠且可声明式的滚动重启能力，提升运维灵活性和系统自愈性，风险主要集中在误触发和顺序策略的阻塞上，可通过上面的建议进行有效管控。

---

### feat(vllm): Add prompt embeds support for pre-computed inference inputs (#4739)
**SHA**: `6f9619a` | 🔗 [查看提交](https://github.com/ai-dynamo/dynamo/commit/6f9619a2106e9a03cf2038234a80b351b7b69f9f)

**🎯 变更类型**：功能增强  
**⚡ 重要程度**：🔴 高  
**📋 变更摘要**：为 vLLM 后端新增对 **prompt embeddings**（预计算提示向量）的全链路支持。实现了在前端 (Rust) 与后端 (Python) 的请求解析、base64‑PyTorch Tensor 解码、Prompt 对象创建、使用序列长度统计生成 usage、以及日志与 LoRA 上下文统一。对应部署、文档及测试均同步更新，且对 NATS 最大 payload 做了 15 MB 调整以容纳 base64 编码后约 13 MB 的嵌入数据。

**🎯 影响范围**  
- `components/src/dynamo/vllm/handlers.py`（核心后端处理）  
- Rust 前端协议结构 `lib/async-openai/src/types/completion.rs`、`lib/llm/src/preprocessor.rs`、`protocols/common/preprocessor.rs`（请求解析、ISL 计算）  
- 验证逻辑 `lib/llm/src/protocols/openai/validate.rs`（prompt / prompt_embeds 校验）  
- Usage 统计 `protocols/openai/completions.rs`、`.../delta.rs`（把 worker 端返回的 prompt_tokens 透传）  
- 部署脚本 `docker-compose.yml`、Helm `values.yaml`（NATS payload）  
- 文档、示例、隐藏 TOC 更新  
- 新增单元、集成、前端 E2E 测试（约 30+ 条）  

---

### 🔍 技术洞察

| 维度 | 影响 |
|------|------|
| **架构影响** | - 在 **前端** 添加 `prompt_embeds` 字段；**后端** 新增 `_decode_prompt_embeds`、`_create_prompt_from_embeddings`、`_build_prompt_from_request` 等方法，形成 **Prompt Embeds → EmbedsPrompt → vLLM Engine** 的全新数据通路。<br>- 现有 **TokensPrompt** 路径保持不变，二者在 `generate_tokens` 参数 `embedding_sequence_length` 上做分支，确保不干扰已有流程。<br>- LoRA 日志抽象为统一私有 `_log_with_lora_context`，提升可读性并降低重复代码。 |
| **性能影响** | - **解码成本**：`torch.load` 在 Python 端完成，解码一次（一次请求）大约 1‑2 ms（取决于 tensor 大小），对整体生成时延影响可忽略。<br>- **网络负载**：通过 NATS 传输 base64 编码后约 1.33×膨胀，最大 13 MB（10 MB 解码），已通过 `max_payload=15 MB` 保障不被截断。<br>- **缓存/KV**：使用嵌入时仍走 KV 迁移路径，未产生额外 KV 开销。 |
| **安全考虑** | - **数据泄露风险降低**：用户在客户端完成隐私敏感信息的 tokenization → embeddings，服务端仅接收不可逆的张量，符合“数据不落地”安全模型。<br>- **输入验证**：统一在 Rust（size ≥100 B）和 Python（base64 → torch Tensor 类型）两层校验，防止恶意构造的非 Tensor 数据导致代码执行或资源耗尽。<br>- **配置门禁**：默认关闭 `--enable-prompt-embeds`，要求显式开启，防止误用。 |
| **可维护性** | - 代码分层清晰：解码、Prompt 构造、请求构建分离；单元测试覆盖解码、大小、形状、错误路径，Rust 验证测试覆盖字段组合与大小。<br>- 新增的 `prompt_embeds` 字段在所有协议层采用 `Option<String>` 与 `skip_serializing_if`，不影响已有序列化/反序列化。<br>- 文档完整，示例、helm、docker 统一更新，降低学习成本。 |
| **兼容性** | - **向后兼容**：旧请求仍走 token 化路径，未启用 flag 时若出现 `prompt_embeds` 将返回 `ValueError`，明确错误信息。<br>- **前向兼容**：在新版本中 `prompt_embeds` 与 `prompt` 可以共存，后端优先使用嵌入，保持对已有业务的最小侵入。 |

---

### ⚠️ 潜在风险

1. **Payload 超限**  
   - 如用户自行拼接超过 15 MB 的 base64 数据（例如 12 MB 解码），NATS 将截断导致请求失败。需在前端给出友好错误（目前会抛出 NATS 连接错误）。  
2. **解码 DoS**  
   - 虽然大小被限制在 10 MB，仍可能出现大量并发大尺寸请求，占用 CPU 与内存。建议在前端或入口层（gateway）对 `prompt_embeds` 进行速率限制。  
3. **Tensor 兼容性**  
   - 只支持 **PyTorch** 序列化格式；若用户尝试 NumPy、ONNX、或不同 `torch.save` 版本的文件，解码会报错。文档已有说明，但仍可能产生使用误解。  
4. **LoRA 与嵌入共存**  
   - 当前日志对 LoRA 与嵌入的组合未显式标记，若调用方同时使用 LoRA 与 `prompt_embeds`，日志仍显示 “with LoRA”，可考虑在日志中加入 `embeds` 标记，便于排障。  
5. **ISL（Inference Sequence Length）计数**  
   - 在 `preprocessor.rs` 中只在 `prompt_embeds.is_none()` 时更新 ISL，若后续出现自动调度依据 ISL 的路径，可能需要确保使用嵌入时仍能获得正确的 ISL（已通过 `embedding_sequence_length` 传递给 worker，但 downstream 可能仍依赖 `request.tracker.isl`）。  

---

### 💡 关注建议

| 对象 | 建议 |
|------|------|
| **开发者** | - 在调用前确保 `--enable-prompt-embeds` 已开启；如果未开启但仍发送 `prompt_embeds`，系统会返回明确的 `ValueError`。<br>- 对大规模嵌入（>5 MB）可预先在客户端压缩或分片，避免一次性传输导致 NATS 超时。 |
| **运维** | - 监控 NATS `max_payload` 使用率，若业务增长建议适当提升 `max_payload`（保持安全上限 < 20 MB）。<br>- 配置 rate‑limit/ACL 防止单 IP 大批量发送 10 MB 嵌入造成 CPU 瓶颈。 |
| **安全审计** | - 确认仅可信的前端服务拥有 `--enable-prompt-embeds` 启动权限，防止外部用户通过未授权渠道直接利用嵌入路径。<br>- 定期审计 `torch.load` 依赖的安全性（避免加载恶意自定义类），当前使用 `weights_only=True` 已降低风险。 |
| **代码维护** | - 将 `_log_with_lora_context` 的 `level` 参数改为枚举或统一使用 `logger.log(level, ...)`，便于以后扩展其它上下文（如 `embedding`）。<br>- 为 `BaseWorkerHandler._decode_prompt_embeds` 添加 `@staticmethod` 注解（已是实例方法但不依赖 `self`），提升可测试性。 |
| **文档/示例** | - 在 README 示例中显式演示 **fallback**：如果未开启 flag，返回的错误信息示例。<br>- 增加 “常见错误” 小节，列出 “payload 超限”、“非 PyTorch 格式”、“tensor shape 与模型不匹配”。 |

--- 

**结论**：此次 PR 为 Dynamo 引入了 **Prompt Embeddings** 的完整链路，极大提升了 **隐私保护** 与 **前端灵活性**，对系统核心架构影响有限且已提供回滚路径。只要在生产环境中做好 **payload 大小监控** 与 **开启标识** 的管理，风险可控，收益显著。建议在正式发布前进行 **压力测试**（并发大体积嵌入）以及 **安全审计**（torch.load 复审），随后即可在生产环境推广。

---

#### 🟡 中重要度变更 (7)

### fix: reduce VLLM_MOE_DP_CHUNK_SIZE to 384 (#5307)
**SHA**: `5f8d90a` | 🔗 [查看提交](https://github.com/ai-dynamo/dynamo/commit/5f8d90a35348b3463e5b2e8f407aa9276994b575)

**🎯 变更类型**：Bug 修复  
**⚡ 重要程度**：🟡 中  

**📋 变更摘要**  
此次提交将 DeepSeek‑R1 VLLM Disagg 部署中 `VLLM_MOE_DP_CHUNK_SIZE` 默认值由 **512** 调整为 **384**，并在 README 中说明该数值是能够在 16 块 H200 上成功部署的上限。同时删除了 `NVSHMEM_QP_DEPTH=1512` 环境变量的配置。  

**🎯 影响范围**  
- `recipes/deepseek-r1/vllm/disagg/deploy_hopper_16gpu.yaml`（两处 low‑throughput 与 high‑throughput 配置）  
- 同目录下的 README 文档  

**💡 关注建议**  
1. **性能回归检查**：`VLLM_MOE_DP_CHUNK_SIZE` 决定 MoE DP 的切分粒度，调小可能降低吞吐但提升可部署性。请在 16‑GPU Hopper 环境下跑一次完整的基准（如 `openai_chat_completions`）对比 512 与 384 的 latency/throughput。  
2. **并发安全**：文档已提示 “该值应大于 per‑rank concurrency”。开发者在自行调参时需确保 `VLLM_MAX_MODEL_LEN / VLLM_MOE_DP_CHUNK_SIZE` 等比例关系仍满足业务需求。  
3. **NVSHMEM 参数**：`NVSHMEM_QP_DEPTH` 被移除，若用户依赖该调优手段（例如极端网络拓扑），需自行在部署 YAML 中恢复或通过其它方式调节。建议在 README 中补充说明何时需要保留此变量。  
4. **文档同步**：确保所有示例脚本、CI 配置或其他部署模板（如 8‑GPU、单机）同步更新相同的默认值，避免出现 “部署成功后异常启动” 的情况。  
5. **回滚方案**：若生产环境出现显著性能回退，可快速恢复 `VLLM_MOE_DP_CHUNK_SIZE` 为 512，或在运行时通过环境变量覆盖。  

整体来看，此次改动仅涉及部署配置，风险有限，但建议在实际集群上进行一次端到端的验证后再推广到生产。

---

### fix: add HF_TOKEN to pytests (#5298)
**SHA**: `fcb7685` | 🔗 [查看提交](https://github.com/ai-dynamo/dynamo/commit/fcb76854a032ed0008c4eef45c7bb60e28795999)

**🎯 变更类型**：Bug 修复  

**⚡ 重要程度**：🟡 中  

**📋 变更摘要**  
此次提交在 GitHub Action 的 pytest 步骤中新增了对 HuggingFace 令牌（`HF_TOKEN`）的支持。通过在 `action.yml` 中声明 `hf_token` 输入并将其注入容器环境变量，在 CI 工作流 `container‑validation‑backends.yml` 中把 `secrets.HF_TOKEN` 传递进来，以便在需要访问私有模型或数据集的 pytest 用例中能够顺利认证。

**🎯 影响范围**  
- `.github/actions/pytest/action.yml`（新增输入 `hf_token`、环境变量映射）  
- `.github/workflows/container‑validation‑backends.yml`（在多个后端的预合并测试 job 中加入 `hf_token` 参数）  
- 受影响的 CI 环境：所有使用该 pytest Action 的工作流，尤其是涉及 HuggingFace 资源的后端（sglang、trtllm、等）。

**💡 关注建议**  
1. **安全性**：确保 `HF_TOKEN` 只在受限的 CI 机器上使用，且在仓库的 `Secrets` 中设置了相同名称的密钥。避免在日志中泄漏，已通过 `env` 注入而非明文打印。  
2. **向后兼容**：新增输入默认 `required: false`，不影响已有调用；若有内部脚本硬编码了 `HF_TOKEN`，请检查是否需要回退。  
3. **文档更新**：在项目的 CI 使用说明或贡献指南中补充 `hf_token` 参数的说明，提醒贡献者在需要访问私有 HuggingFace 资源时配置 `secrets.HF_TOKEN`。  
4. **测试验证**：在本地或临时 CI 环境中运行一次完整的 pytest，确认 `HF_TOKEN` 能被正确读取且不影响其他测试。若出现 “token not found” 的错误，请检查 Secrets 名称及权限。  
5. **未来扩展**：若后续需要在其他 Action（如 lint、build）中同样使用 HF 令牌，考虑统一在工作流层面设置 `HF_TOKEN` 环境变量，以免重复传递。  

---

### fix: preserve original model path for frontend config downloads (#5102)
**SHA**: `f7ba417` | 🔗 [查看提交](https://github.com/ai-dynamo/dynamo/commit/f7ba417e76b0154ace38fefefdbc909fefc82314)

**🎯 变更类型**：Bug 修复  
**⚡ 重要程度**：🟡 中  
**📋 变更摘要**：在 `ModelDeploymentCard` 中新增 `source_model` 字段，用于在用户通过 `--served-model-name`（或等价的前端配置）自定义 `display_name` 时，仍能保存原始 HuggingFace 仓库路径，以便后续下载模型文件。`set_name` 会在第一次改名时把原 `display_name` 迁入 `source_model`，而 `download` 逻辑随后优先使用 `source_model`。  

**🎯 影响范围**  
- `lib/llm/src/model_card.rs`（核心模型卡结构、序列化、下载实现）  
- 可能波及前端模型列表/配置 UI（需要展示或编辑 `source_model`）  
- 与模型持久化（JSON/YAML）相关的任何模块，因为新增字段使用 `#[serde(default, skip_serializing_if = "Option::is_none")]`，不会破坏旧数据。  

**💡 关注建议**  
1. **向后兼容**：新增字段的 serde 标记已确保旧的持久化文件仍可读，但在读取后 `source_model` 为 `None` 时会回退到 `display_name`，请在文档中说明此行为。  
2. **多次改名**：`set_name` 只在 `source_model` 为 `None` 时保存一次原始名称，防止覆盖。若业务允许二次改名，确认这仍符合预期。  
3. **前端同步**：如果前端在展示模型卡时仍使用 `display_name` 进行下载，需要改为 `source_model.unwrap_or(display_name)`，否则可能出现下载错误。  
4. **测试覆盖**：添加单元测试：① 自定义 `display_name` 后 `source_model` 被正确设置；② `download` 调用使用 `source_model`；③ 序列化/反序列化循环保留该字段。  
5. **文档与帮助信息**：在 CLI/SDK 文档中补充说明 `--served-model-name` 只影响注册名，不影响下载源，新增 `source_model` 仅内部使用。  

总体而言，此次修改解决了自定义模型名称导致的下载路径丢失问题，影响范围局限于模型卡核心实现，只要做好测试与文档同步，即可安全上线。

---

### fix: Add symlink for NCCL in trtllm container (#5257)
**SHA**: `22e36de` | 🔗 [查看提交](https://github.com/ai-dynamo/dynamo/commit/22e36dec7c8f3b24f3595e855bb67aa06963e62c)

**变更类型**：Bug 修复  
**重要程度**：🟡 中  

**变更摘要**：在 `container/Dockerfile.trtllm` 的镜像构建阶段新增一条命令，创建指向 `libnccl.so.2` 的 `libnccl.so` 符号链接，以满足 TensorRT‑LLM 对显式 `libnccl.so` 的加载需求。

**影响范围**  
- `Dockerfile.trtllm`（构建 TensorRT‑LLM 容器的镜像）  
- 运行时的 NCCL 动态链接路径（仅在容器内部）  

**关注建议**  
1. **路径与库版本**：确认基础镜像中 `/usr/lib/${ARCH_ALT}-linux-gnu/` 目录下始终包含 `libnccl.so.2`，否则链接会失效。建议在 `apt-get install` 后加入 `ls` 检查或 `dpkg -L libnccl2` 验证。  
2. **跨架构兼容**：`ARCH_ALT` 变量在 x86_64 与 ARM 等平台上可能不同，确保两者都能找到对应的库文件；如有必要，可在 Dockerfile 中添加条件分支或通用路径（`/usr/lib/x86_64-linux-gnu`、`/usr/lib/aarch64-linux-gnu`）。  
3. **缓存层**：该命令位于 `apt-get clean` 后，会导致 Docker 镜像层重新构建。若频繁修改，建议将 symlink 步骤单独放在独立的 `RUN` 行，以免影响前面已缓存的层。  
4. **后续升级**：若将来 NCCL 升级到 `libnccl.so.3`，需要同步更新此 symlink；可考虑使用 `ln -sf $(ldconfig -p | grep libnccl.so | head -n1 | awk '{print $4}') /usr/lib/.../libnccl.so` 的动态方式。  
5. **测试验证**：在 CI 中加入 `ldd` 检查 TensorRT‑LLM 可执行文件是否成功解析到 `libnccl.so`，并运行一次简单的 NCCL 通信测试，确保容器启动后不会因缺失符号而报错。  

总体来看，此改动解决了容器内 NCCL 链接缺失的问题，风险主要在库路径或版本变动上。通过上述验证步骤可降低因镜像基础包升级导致的回归风险。

---

### fix: add mem frac for sglang dsr1 8gpu (#5260)
**SHA**: `bfb95df` | 🔗 [查看提交](https://github.com/ai-dynamo/dynamo/commit/bfb95df77deda8cc3edb7008de055e6583da3125)

**🎯 变更类型**：Bug 修复  
**⚡ 重要程度**：🟡 中  

**📋 变更摘要**  
在 `recipes/deepseek-r1/sglang/disagg-8gpu/deploy.yaml` 中为 `decode` 与 `prefill` 两个容器的启动参数新增 `--mem-fraction-static "0.75"`，解决在 DeepSeek‑R1 8‑GPU DisAgg 环境下因内存分配不足导致的崩溃/性能退化问题。  

**🎯 影响范围**  
- `sglang` 的 Disaggregation 部署（8 GPU）  
- 依赖该 `deploy.yaml` 的 CI/CD 流水线与用户自建集群  
- 相关的 `deepseek-r1` 镜像启动脚本  

**💡 关注建议**  
1. **验证内存占用**：部署后监控容器的实际内存使用，确认 0.75 的静态比例不会导致其他进程 OOM。  
2. **兼容性检查**：若用户在不同硬件（如 4 GPU）上复用该配置，需要自行调整 `mem-fraction-static` 参数，以匹配实际显存。  
3. **文档同步**：更新对应的部署文档或 README，说明该参数的作用及调节建议。  
4. **回滚方案**：若出现异常，可删除新增参数回到原始配置，或将比例调低（如 0.6）再观察。  

该改动仅影响配置文件，不会引入代码层面的兼容性风险，建议在测试环境先行验证后再推向正式环境。

---

### fix: Update model cache pvc name (#5270)
**SHA**: `6458ef8` | 🔗 [查看提交](https://github.com/ai-dynamo/dynamo/commit/6458ef8094321fa30f7608b52c4f7c61ea228e51)

**🎯 变更类型**：Bug 修复  
**⚡ 重要程度**：🟡 中  
**📋 变更摘要**：将 DeepSeek‑R1 vLLM Disagg 示例中的模型缓存 PVC 名称从 `model-cache-pvc` 调整为 `model-cache`，并同步更新了前端 Service 的端口转发命令与相关的 `volumeMounts` 引用。  

**🎯 影响范围**  
- `recipes/deepseek-r1/vllm/disagg` 目录下的所有部署清单（`deploy_hopper_16gpu.yaml`）  
- README 中的本地调试指令  
- 任何基于该示例自行复制或修改的用户部署脚本  

**💡 关注建议**  
1. **确认 PVC 名称统一**：在实际集群中创建的 PVC 必须使用 `model-cache`（而非旧的 `model-cache-pvc`），否则 Pod 启动会因找不到卷而失败。  
2. **同步文档**：除本次修改的 README，还应检查项目根目录或其他文档里是否出现旧名称，避免误导用户。  
3. **回滚兼容**：若已有用户仍在使用旧名称的部署，请提供迁移指南（删除旧 PVC、重新创建或通过 `kubectl patch` 更新 `DynamoGraphDeployment`）。  
4. **CI/测试覆盖**：加入对 PVC 名称一致性的检查（如 kustomize/helm 渲染后搜索 `model-cache-pvc`），防止类似命名失误再次出现。  
5. **验证端口转发**：README 中的 `kubectl port-forward` 已改为 `svc/vllm-dsr1-frontend`，使用前请确认 Service 名称已随 `metadata.name` 更新。  

总体来说，此次改动只影响示例部署的命名一致性，风险较低。完成后建议在测试集群跑一次完整的部署‑启动‑推理链路，确保模型能够正常读取缓存。

---

### fix(vllmsglang): Give sglang/vllm the HF model name not the full path (#5274)
**SHA**: `fcc4a60` | 🔗 [查看提交](https://github.com/ai-dynamo/dynamo/commit/fcc4a60f6c570644ce48a415894f18dd9ea23654)

**🎯 变更类型**：Bug 修复  
**⚡ 重要程度**：🟡 中  
**📋 变更摘要**：将 sglang 与 vllm 启动时的模型标识由完整本地路径改为 Hugging‑Face（HF）模型名称，避免在分布式 worker 中因路径不一致导致二次下载。通过 `fetch_llm` 预先将模型拉到本地缓存，同时保留原始 HF 名称供后续进程使用。  

**🎯 影响范围**  
- `components/src/dynamo/sglang/args.py`：解析 CLI 参数时为 `served_model_name` 加默认值并在缺失本地文件时调用 `fetch_llm`（保持路径不变，仅触发下载）。  
- `components/src/dynamo/vllm/main.py`：启动入口同样为 `served_model_name` 设默认值，下载模型后不修改 `engine_args.model`，防止 Ray worker 看到错误的本地路径。  

**💡 关注建议**  
1. **异步下载安全**：`parse_args` 现在在解析阶段会执行 `await fetch_llm`，若多实例并发调用可能产生竞争。建议在上层（如 CLI 启动脚本）加锁或使用共享缓存目录。  
2. **分布式缓存一致性**：worker 仍会尝试下载，依赖 HF 缓存的可见性。确保所有节点挂载相同的 `~/.cache/huggingface`，或在 CI 中显式指定 `HF_HOME`。  
3. **非 HF 模型**：对于本地路径模型，仍会把路径原样传递。文档应明确说明：仅在 `model` 为 HF 名称时才会自动填充 `served_model_name`。  
4. **TODO 迁移**：代码中保留 “parse_args 不应下载模型” 的注释，后续可考虑将下载逻辑抽离至统一的启动前置步骤，以保持职责单一。  
5. **回归测试**：新增对 `sglang` 与 `vllm` 两条路径的单元/集成测试，验证 (a) HF 名称输入时 `served_model_name` 正确；(b) 本地路径输入时保持原路径且不误改写。  

总体来说，此次改动解决了模型名称在分布式环境下不一致导致的二次下载问题，但引入了在参数解析阶段进行网络 I/O 的副作用，后续可进一步抽象下载步骤，提升代码可维护性。

---

#### 🟢 低重要度变更 (3)

### docs: add host and bootstrap port to disagg multinode example (#5309)
**SHA**: `c29f78c` | 🔗 [查看提交](https://github.com/ai-dynamo/dynamo/commit/c29f78c19da656a0dc8a9da6d4a8b17e3e72806c)

**🎯 变更类型**：文档更新  
**⚡ 重要程度**：🟢低  
**📋 摘要**：在多节点示例文档中新增 host 与 disaggregation bootstrap 端口的说明及对应环境变量，指导用户正确配置跨节点通信。

---

### docs: broken links in benchmarking documentation (#5258)
**SHA**: `d0cfc40` | 🔗 [查看提交](https://github.com/ai-dynamo/dynamo/commit/d0cfc40a7d2d3bbed59c21cd68f6cf137a2fc931)

**🎯 变更类型**：文档更新  
**⚡ 重要程度**：🟢 低  
**📋 摘要**：将 Benchmarking 文档中失效的相对链接改为指向仓库的完整 GitHub 链接，确保文档可正常访问相关资源。

---

### chore: move custom mm preprocessor to new file (#5278)
**SHA**: `1c9fea0` | 🔗 [查看提交](https://github.com/ai-dynamo/dynamo/commit/1c9fea016810d3a4e050dbfdf66d10157dab72e7)

**🎯 变更类型**：代码重构  
**⚡ 重要程度**：🟢低  
**📋 摘要**：将自定义多模态预处理器迁移至新文件 `preprocessor_handler.py`，并在 `__init__.py` 中更新相应的导入路径。

---

