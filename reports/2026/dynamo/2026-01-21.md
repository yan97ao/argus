# 每日更新报告（2026-01-21）

## ai-dynamo/dynamo

| 提交时间 | 作者 | 提交信息 |
|----------|------|----------|
| 2026-01-21 23:41:53 | Anant Sharma | chore: update attributions for vllm cuda13 container (#5436) (#5488) |
| 2026-01-21 16:20:19 | Ayush Agarwal | fix: multi image bug for qwen ec connector (#5514) |
| 2026-01-21 15:12:00 | blarson-b10 | fix: add test for long context kv store events and fix drop issue (#5499) |
| 2026-01-21 14:32:01 | Janelle Cai | fix: restrict pod hash for worker/instance id to <2^53 (#5471) |
| 2026-01-21 07:55:55 | ishandhanani | fix: ipv6 support for sglang disaggregation (#5521) |
| 2026-01-21 06:51:33 | Schwinn Saereesitthipitak | refactor: clean up SGLang sleep/wake implementation (#5517) |
| 2026-01-21 06:47:00 | ishandhanani | fix(sglang): Fix YAML config parsing for store_true arguments (#5513) |
| 2026-01-21 06:19:18 | MatejKosec | feat(sglang): enforce stream_output=True for optimal streaming performance (#5510)<br>This ensures that only new tokens are returned by sglang which avoids the overhead from creating copies of the entire token sequences per each iteration. These copies can become a bottleneck particularly for long sequence lengths and large concurrency counts. |
| 2026-01-21 06:05:09 | Keiven C | fix: on a bad network day, uv timeout too easily when building dev/local-dev containers (#5511) |
| 2026-01-21 04:09:46 | jthomson04 | feat: Support Dynamo KVBM with TRTLLM Disagg (#3527) |
| 2026-01-21 01:55:43 | Schwinn Saereesitthipitak | feat: SGLang release/resume_memory_occupation endpoints (#5207) |
| 2026-01-21 01:17:16 | Schwinn Saereesitthipitak | feat: Sleep/wake endpoints for vLLM runtime (#5339) |

### 📊 统计摘要
> 本日共 12 个提交 | 🔴高 7 | 🟡中 4 | 🟢低 1
## 📋 目录

- [ai-dynamo/dynamo](#ai-dynamo-dynamo)
  - [📊 统计摘要](#-统计摘要)
  - [🔴 高重要度变更 (7)](#-🔴-高重要度变更-7)
    - [fix: multi image bug for qwen ec connector (#5514)](#6070089)
    - [fix: restrict pod hash for worker/instance id to <2^53 (#...](#ca023c0)
    - [fix: ipv6 support for sglang disaggregation (#5521)](#9b8b35a)
    - [feat(sglang): enforce stream_output=True for optimal stre...](#748fee6)
    - [feat: Support Dynamo KVBM with TRTLLM Disagg (#3527)](#bf19823)
    - [feat: SGLang release/resume_memory_occupation endpoints (...](#0e0d6c1)
    - [feat: Sleep/wake endpoints for vLLM runtime (#5339)](#e2a0a4b)
  - [🟡 中重要度变更 (4)](#-🟡-中重要度变更-4)
    - [fix: add test for long context kv store events and fix dr...](#fdd2d15)
    - [refactor: clean up SGLang sleep/wake implementation (#5517)](#2e8c444)
    - [fix(sglang): Fix YAML config parsing for store_true argum...](#04cecda)
    - [fix: on a bad network day, uv timeout too easily when bui...](#7b639e7)
  - [🟢 低重要度变更 (1)](#-🟢-低重要度变更-1)
    - [chore: update attributions for vllm cuda13 container (#54...](#8877c46)
#### 🔴 高重要度变更 (7)

### fix: multi image bug for qwen ec connector (#5514)
**SHA**: `6070089` | 🔗 [查看提交](https://github.com/ai-dynamo/dynamo/commit/607008992debc3841e030999cf8895cbb6e2f3c0)

**🎯 变更类型**：Bug修复  
**⚡ 重要程度**：🔴高  
**📋 变更摘要**：  
- 将多模态（主要是多图）输入的处理方式从“每张图片单独调用一次 vLLM 编码器”改为“一次性加载全部图片并一次性发起 vLLM 生成请求”。  
- 修正了 Qwen‑EC 连接器在处理多张图片时因多次 `generate` 调用导致的错误（之前每张图片都会产生独立的 `request_id`），并在后续为每张图片单独计算 `mm_hash` 并返回对应的响应。  

**🎯 影响范围**：  
- `components/src/dynamo/vllm/multimodal_handlers/encode_worker_handler.py`（核心编码工作线程）  
- 受影响的上层模块包括：`dynamo` 的多模态请求调度层、缓存层（依据 `mm_hash`）以及使用 Qwen‑EC 连接器的用户业务。  

**🔍 技术洞察**  

- **架构影响**  
  - **调用路径简化**：原本对每张图片都要生成一次 `engine_client.generate`，现在改为一次性发送所有图片的 `multi_modal_data`。这使得请求在 `EncodeWorkerHandler` 与 vLLM 引擎之间的交互更加紧凑，降低了调度层的并发创建请求数量。  
  - **请求 ID 语义统一**：仅保留原始 `request_id` 用于一次性编码，随后在内部生成 `item_request_id`（`{request_id}_mm_{idx}`）供后续缓存/PD worker 使用，保持向后兼容。  
  - **后向兼容性**：其它组件仍然通过 `VLLMNativeEncoderResponse` 获取 `mm_hash`，因此缓存逻辑无需变更。  

- **性能影响**  
  - **显著提升**：一次性向 vLLM 发送所有图片，省去多次网络/IPC 调度、上下文切换以及 VLLM 端的重复初始化开销。  
  - **资源占用**：一次性加载全部图片至内存（`media_list`），在图片数量或分辨率较高时可能导致峰值内存增长。  
  - **错误传播**：若任意一张图片加载失败或 VLLM 报错，整个批次将被中止，导致所有图片都返回错误，需权衡批量成功率与单张独立成功率。  

- **安全考虑**  
  - **外部资源加载**：仍然通过 `image_loader.load_image` 下载外部 URL，未改变安全模型。  
  - **异常处理**：对不支持的视频 URL 抛出 `NotImplementedError`，保持原有安全/功能边界。  
  - **Hash 计算**：在成功获取编码结果后才计算 `mm_hash`，与之前的顺序一致，无新泄露风险。  

**⚠️ 潜在风险**  

1. **批量失败风险**：单张图片的加载或哈希异常会导致整批请求失败，可能影响用户体验。  
2. **内存峰值**：大量或高分辨率图片一次性放入 `media_list`，在资源受限的部署环境（如容器/边缘）可能触发 OOM。  
3. **顺序依赖**：后续依赖 `item_request_id` 的组件（如 PD workers）的并发处理必须确保能够区分同一批次的子请求，否则可能出现缓存错乱。  
4. **后续功能扩展**：当前硬编码 `modality = "image"`，若未来加入 video/audio，需重新设计批处理逻辑，否则会再次出现 NotImplementedError。  

**💡 关注建议**  

- **增加批量容错**：在循环加载图片时捕获单张加载异常，记录失败的索引并继续处理其余图片；在最终返回时对成功/失败分别生成响应。  
- **内存保护**：在加载前检查累计图片大小或数量，超过阈值时采取分批上传或直接返回提示。  
- **单元/集成测试**：覆盖以下场景：*单图、多图、混合成功/失败、极大图片尺寸*，确保 `encode_worker_handler` 在异常情况下不会导致进程崩溃。  
- **文档更新**：在 README 或 API 文档中明确说明当前仅支持一次性 **多图** 编码，不支持视频/音频，且一次请求的图片数量/大小上限。  
- **监控指标**：新增 `encode_worker_batch_size`、`encode_worker_batch_failure_rate` 等监控指标，以便在生产环境快速定位批量失败或内存压力问题。  

通过上述措施，可在保持本次 bug 修复收益的同时，降低新代码带来的潜在风险，确保系统的可用性和可维护性。

---

### fix: restrict pod hash for worker/instance id to <2^53 (#5471)
**SHA**: `ca023c0` | 🔗 [查看提交](https://github.com/ai-dynamo/dynamo/commit/ca023c0c1f3b5509d9f38a71cdaa21f469c7ae51)

**🎯 变更类型**：Bug修复 / 性能优化（防止 JSON 序列化精度丢失）  
**⚡ 重要程度**：🔴高  
**📋 变更摘要**：  
1. 在 `hash_pod_name` 中对哈希结果进行掩码，强制生成的实例 ID 小于 2²⁵³，以确保在 IEEE‑754 `f64`（即 JSON 数字）中能够安全保留整数精度。  
2. 新增单元测试，验证哈希值经过 `serde_json` 序列化/反序列化后保持不变，并在结构体中嵌入时同样安全。  

**🎯 影响范围**：  
- `lib/runtime/src/discovery/kube/utils.rs`（Pod 名称 → 实例 ID 的核心函数）  
- 任何使用该函数生成 `instance_id` 并随后通过 JSON（或其它基于 `f64` 的数值）进行传输、存储或比较的模块，例如：  
  - 运行时的节点/工作者发现（discovery）机制  
  - 调度器、监控以及外部工具通过 HTTP/JSON 与 Dynamo 交互的入口  

**🔍 技术洞察**  

- **架构影响**  
  - `hash_pod_name` 是跨组件唯一标识生成的唯一入口，掩码限制将哈希空间从 2⁶⁴ 降至 2⁵³。该修改是向下兼容的（旧值若已在低 53 位，保持不变），但在极端规模集群中可能出现哈希碰撞，需要业务层做好去重或冲突处理。  
  - 通过对 `instance_id` 的范围做约束，避免了在 JSON（使用 IEEE‑754 双精度浮点）中出现精度截断导致的 “实例 ID 变成 0” 或 “变为相邻数值” 的错误，提升了跨语言/跨系统交互的可靠性。  

- **性能影响**  
  - 仅在返回前多了一次位掩码 `& INSTANCE_ID_MASK`，CPU 开销可以忽略不计。  
  - 新增的 52 行单元测试会在 CI 中略微延长执行时间，但不影响运行时性能。  

- **安全考虑**  
  - 该改动不引入新的安全风险，反而通过避免因数值精度丢失导致的身份混淆（如错误的实例 ID）降低了潜在的攻击面。  
  - 由于哈希空间仍然足够大（≈9×10¹⁵），不存在可预测性或暴力破解的风险。  

**⚠️ 潜在风险**  

1. **哈希碰撞概率提升**  
   - 将可用位数从 64 降至 53，理论上碰撞概率上升约 2¹¹（≈ 2048）倍。虽然在常规规模（几千至几万节点）仍可忽略，但在极大规模集群（>10⁸）可能出现冲突。  
2. **下游假设破坏**  
   - 若其他组件（自定义插件或外部监控）对 `instance_id` 的位宽有硬编码假设（例如取高位做位标记），则掩码会导致这些逻辑失效。  
3. **历史数据不兼容**  
   - 已存在的持久化记录若使用未掩码的 64 位值，升级后读取时可能出现不匹配，需要迁移或兼容处理。  

**💡 关注建议**  

- **监控碰撞**：在升级后监控 `instance_id` 的唯一性（例如在注册阶段记录冲突日志），若出现冲突可考虑在实例层面追加序列号或使用 UUID。  
- **文档更新**：在项目文档、API 说明以及 CHANGELOG 中明确指出 `instance_id` 现在受 53 位限制，避免第三方开发者使用超过此范围的位运算。  
- **兼容处理**：如果系统中已有持久化的实例 ID（如数据库/etcd），在迁移期间可以保留原值并在内部映射到新的掩码值，或提供向后兼容的转换脚本。  
- **审查下游依赖**：检查所有直接或间接使用 `instance_id` 进行位运算的代码路径，确保没有硬编码高位假设。  
- **性能回归测试**：虽然性能影响极小，仍建议在 CI 中保留基准测试，以防将来对 `hash_pod_name` 再次改动带来意外的性能回退。  

通过上述措施，可以确保本次修复在提升 JSON 序列化安全性的同时，平稳地在生产环境中推广。

---

### fix: ipv6 support for sglang disaggregation (#5521)
**SHA**: `9b8b35a` | 🔗 [查看提交](https://github.com/ai-dynamo/dynamo/commit/9b8b35a887bacfdd486f1d790e48c2bb7f5ac118)

**🎯 变更类型**：Bug修复  
**⚡ 重要程度**：🔴高  
**📋 变更摘要**：  
1. 为 SGLang 的 disaggregation 场景添加对 IPv6 地址的解析与自动检测，改进了 `register.py` 中的 bootstrap 主机获取逻辑。  
2. 在 Rust 层的 `ip_resolver.rs` 中，对本地 IP 的返回结果做了 IPv6 括号包装，以确保在拼接 `{host}:{port}` 时 URL 语法合法。  
3. 同时补充了相应的单元测试，验证 IPv6 地址是否被正确括号化以及 IPv4 地址保持不变。

**🎯 影响范围**：  
- `components/src/dynamo/sglang/register.py`（Python 端网络启动流程）  
- `lib/runtime/src/utils/ip_resolver.rs`（Rust 端 RPC 主机解析公用函数）  
- 依赖该函数构建 HTTP/RPC URL 的全部模块（如 RPC 客户端、监控、日志上报等）  

**🔍 技术洞察**：  
- **架构影响**：  
  - 仅在 IP 解析/包装层面做了增强，接口签名和返回值类型未变，属于向下兼容的功能补丁。  
  - 新增的 `AF_UNSPEC` 解析策略使得系统在同时拥有 IPv4 与 IPv6 时由 OS 决定首选协议，提升了跨平台部署的灵活性。  
- **性能影响**：  
  - Python 端额外调用 `socket.getaddrinfo`（一次）并做字符串处理，开销极低（毫秒级）。  
  - Rust 端仅在返回字符串前进行一次模式匹配与 `format!`，同样可忽略。整体性能基本不受影响。  
- **安全考虑**：  
  - 正确的 IPv6 括号包装防止了在 URL 拼接时出现 `:::`` 或 ``[::1]:port`` 解析错误，降低了潜在的 URL 注入或解析异常风险。  
  - `socket.getaddrinfo` 在解析失败时会记录警告并回退到原始主机名，避免因解析错误导致服务不可用。  

**⚠️ 潜在风险**：  
1. **已有代码假设主机字符串不含方括号**：如果下游模块在拼接 URL 前再次自行包装方括号，可能出现 `[[::1]]` 形式，导致请求失败。  
2. **`socket.getaddrinfo` 返回的首个记录不一定是期望的地址族**：在某些系统上，首条记录可能是 IPv4，即使 IPv6 可达，导致默认走 IPv4，可能不符合用户的“首选 IPv6”期待。  
3. **日志量增加**：在每次解析/自动检测时会输出 `info` 级别日志，在高并发场景下可能略微放大日志体积。  

**💡 关注建议**：  
- **代码层面**：检查所有使用 `bootstrap_host` 或 `get_http_rpc_host_with_resolver` 生成 URL 的位置，确保不再手动添加方括号；如有必要，可统一使用一个包装函数 `ensure_bracketed(host: &str) -> String`。  
- **部署文档**：在部署手册中说明：  
  - 环境变量 `SGLANG_HOST_IP` 若提供 IPv6，必须使用方括号形式（`[2001:db8::1]`）。  
  - 系统默认会自动检测并包装 IPv6，用户无需额外处理。  
- **监控**：关注启动日志中的 `Failed to resolve bootstrap host` 警告，确保在真实网络环境下解析成功。  
- **回归测试**：在 CI 中加入带有真实 IPv6 地址的集成测试（如在容器内启用 IPv6），验证 URL 拼接、网络连通性与错误恢复路径。  
- **性能/安全审计**：在高并发 RPC 场景下观察 `socket.getaddrinfo` 调用的延迟分布，确认不会成为瓶颈；同时确认日志级别符合生产环境的安全合规要求。

---

### feat(sglang): enforce stream_output=True for optimal streaming performance (#5510)
**SHA**: `748fee6` | 🔗 [查看提交](https://github.com/ai-dynamo/dynamo/commit/748fee6bcfe2070291cee9b2c069ee7a638a08ad)

**🎯 变更类型**：功能增强  

**⚡ 重要程度**：🔴高  

**📋 变更摘要**：  
- 在 `sglang` 的启动参数解析阶段强制开启 `stream_output=True`，确保 SGLang 只返回自上一次输出后的增量 token。  
- 相应地简化了 `decode_handler` 与 `multimodal/worker_handler` 中的流处理逻辑，直接转发增量 token，去除原先的累计计数与切片操作。  
- 目标是消除对完整 token 序列的重复拷贝，提升长序列及高并发场景下的流式输出性能。  

**🎯 影响范围**：  
- `components/src/dynamo/sglang/args.py`（启动参数解析）  
- `components/src/dynamo/sglang/request_handlers/llm/decode_handler.py`（LLM token 流处理）  
- `components/src/dynamo/sglang/request_handlers/multimodal/worker_handler.py`（多模态流处理）  

**🔍 技术洞察**：  
- **架构影响**  
  - 统一了 Dynamo 与 SGLang 之间的流式协议：Dynamo 现在只接受 *disjoint*（增量）token，后端不再需要维护累计计数。  
  - 简化了 `StreamProcessor` 与 `_process_token_stream` 的内部状态（去除 `num_output_tokens_so_far`），降低了代码耦合度。  
  - 强制 `stream_output=True` 可能与其他非 SGLang 后端冲突，需要在全局配置或文档中明确限定适用范围。  

- **性能影响**  
  - 通过避免每次迭代复制完整 token 序列，显著降低了 CPU 与内存开销，尤其在 `sequence_length ≥ 1k`、并发数 ≥ 10 时可减少数倍的内存拷贝。  
  - 直接转发增量 token 减少了内部数据结构的创建与 GC 负担，提升了整体吞吐量与响应时延。  
  - 对于 GPU 推理路径几乎无额外开销，因只影响 CPU 端的流式转发。  

- **安全考虑**  
  - 变更仅涉及内部数据流的组织方式，没有新增外部输入或权限检查，安全风险极低。  
  - 需关注因强制 `stream_output=True` 可能导致的兼容性问题：如果下游消费者仍假设 `output_ids` 为累计序列，可能出现意外的 token 拼接错误，从而导致生成内容错误或服务异常。  

**⚠️ 潜在风险**  
1. **兼容性回退**：已有用户或内部组件可能依赖累计 `output_ids`（例如日志、审计或自定义后处理），强制增量模式会导致这些逻辑失效。  
2. **配置硬编码**：`server_args.stream_output = True` 直接覆盖用户显式传入的值，限制了灵活性，若未来需要关闭此特性将需要改动代码。  
3. **错误传播**：如果 SGLang 在某些异常情况下仍返回累计 token（实现回退），Dynamo 将误认为是增量，导致 token 重复或丢失。  
4. **测试覆盖不足**：长序列、高并发以及多模态输入的边界情况需充分测试，防止隐藏的状态泄漏或 race condition。  

**💡 关注建议**  
- **可配置开关**：将 `force_stream_output` 设为可选参数，默认开启但允许通过 CLI/环境变量关闭，以兼容特殊场景。  
- **回退检测**：在流处理入口加入校验，若检测到 `output_ids` 长度明显小于累计预期（例如出现倒序或重复），记录警告并可选择回退到累计模式。  
- **完善测试**：新增单元/集成测试，覆盖：  
  - 超长序列（>4k token）在高并发（≥20）下的内存/时延表现。  
  - 多模态流（图片+文本）下的 token 切分正确性。  
  - 强制关闭 `stream_output` 时的行为保持向后兼容。  
- **文档更新**：在 Dynamo 使用手册中明确说明 `stream_output=True` 为强制要求，并说明对下游 consumers 的影响及兼容方案。  
- **监控指标**：部署后打开 `stream_output` 相关的性能指标（如每秒拷贝字节数、GC 暂停时间），确保改动带来的性能提升可量化。  

---

### feat: Support Dynamo KVBM with TRTLLM Disagg (#3527)
**SHA**: `bf19823` | 🔗 [查看提交](https://github.com/ai-dynamo/dynamo/commit/bf19823d08386366b61aea24edc1a3002800e95f)

**🎯 变更类型**：功能增强 / 架构变更  

**⚡ 重要程度**：🔴 高  

**📋 变更摘要**  
本次提交为 Dynamo 项目新增对 TensorRT‑LLM（TRT‑LLM）**KVBM（KV Block Manager）**的支持，兼容 TRT‑LLM **disaggregated serving**（prefill + decode 分离）。核心改动包括：  
1. 在 `dynamo.trtllm` 启动入口新增 `--connector` 参数并生成对应的 `KvCacheConnectorConfig`。  
2. 在运行时初始化时关闭 KV‑cache 的 `enable_partial_reuse` 并将 `kv_connector_config` 注入 LLM API。  
3. 在 Rust 端实现新的 `apply_scheduler_output` 接口，使用 `num_scheduled_tokens` 取代原先缺失的字段；同步更新 leader/slot 实现以及 KV‑BM 连接器的 Python wrapper。  
4. 文档、示例、测试均同步更新，以验证在 prefill / decode 分离模式下的确定性与性能。

**🎯 影响范围**  
- `components/src/dynamo/trtllm/*`（Python 启动脚本、参数解析、运行时初始化）  
- `lib/bindings/kvbm/*`（Python connector、Rust slot/leader 实现）  
- `docs/kvbm/*`（部署说明）  
- `tests/kvbm_integration/*`（新增 TRT‑LLM disagg 确定性测试）  
- 依赖版本：TRT‑LLM **≥ 1.2.0rc2**（旧版本将因缺少 `num_scheduled_tokens` 报错）

**🔍 技术洞察**  

- **架构影响**  
  - 引入了 **KV‑Connector** 的概念，使 Dynamo 能在 TRT‑LLM 的 **prefill worker** 与 **decode worker** 之间共享 KV‑cache 元数据。  
  - 通过 `KvCacheConnectorConfig` 将 connector 的模块、调度器类、工作者类注入 LLM API，形成 **插件化** 结构，降低了耦合度。  
  - 删除了原先在 `Slot` trait 中专门为 TRT‑LLM 编写的 `apply_scheduler_output_with_computed_position`，统一使用 `apply_scheduler_output`，简化了跨后端实现路径。  

- **性能影响**  
  - **关闭 `enable_partial_reuse`**：确保 KV‑cache 在预填阶段不进行局部复用，提升 **offloading cache hit** 的概率，符合 KVBM 的设计目标。  
  - 通过 `num_scheduled_tokens` 明确传递调度器实际产生的 token 数，避免了在 `Slot` 中对缺失字段的二次推断，降低了额外计算开销。  
  - 预填与解码分离后，每个 worker 只专注单一阶段，理论上可以取得更好的 **CPU↔GPU 并行度** 与 **GPU 内存占用**（因 KV‑BM 能更精细地管理块）。  

- **安全考虑**  
  - 新增的 `--connector` 参数受 `choices=["none","kvbm"]` 严格限制，避免任意模块加载。  
  - 对不支持的 TRT‑LLM 版本做了显式检查并 `sys.exit(1)`，防止运行时因缺失字段导致不可预期的内存错误。  
  - 代码路径未引入网络 I/O 或外部脚本执行，安全风险保持在原有范围内。  

**⚠️ 潜在风险**  

1. **版本兼容性**：部署环境如果使用 TRT‑LLM 低于 1.2.0rc2，会在 `kvbm_connector_leader.py` 抛出 `ValueError`，导致服务启动失败。  
2. **配置误用**：`config.connector` 默认为 `"none"`，但若在旧版文档或脚本中忘记显式指定 `"kvbm"`，可能导致 KV‑BM 未激活而出现性能回退。  
3. **内存回收**：关闭 `enable_partial_reuse` 会让预填阶段占用更多 GPU KV‑cache，若 GPU 内存本身紧张，可能触发 OOM。  
4. **代码分支差异**：原有的 `apply_scheduler_output_with_computed_position` 被删除，若后续有其他后端（如 vLLM）仍依赖该函数，可能导致编译冲突或运行时缺失实现。  

**💡 关注建议**  

- **版本检测**：在启动脚本或 CI 中加入对 TRT‑LLM 版本的前置检查，提前给出升级提示。  
- **配置模板**：提供官方推荐的 `kvbm_llm_api_config.yaml` 示例，明确 `enable_partial_reuse: false` 与 `max_tokens` 计算方式，防止用户手动配置错误。  
- **监控与报警**：在生产部署时开启 KV‑BM 相关指标（如 `cache_hits`, `offload_counts`），配合 `MetricsCollector` 监控 GPU KV‑cache 使用率。  
- **回退路径**：保持 `connector=none` 为默认选项，以便在不支持 KVBM 的环境快速回退至原有行为。  
- **文档同步**：确保 README 与部署脚本的 TRT‑LLM 版本要求保持一致，避免出现 “要求 1.2.0rc2” 与实际使用 1.1.0rc5 的冲突。  

通过上述措施，可最大化本次功能增强带来的性能收益，同时将兼容性与安全风险控制在可接受范围。

---

### feat: SGLang release/resume_memory_occupation endpoints (#5207)
**SHA**: `0e0d6c1` | 🔗 [查看提交](https://github.com/ai-dynamo/dynamo/commit/0e0d6c164d9a2928a083f08260d6e10431487a2b)

**🎯 变更类型**：功能增强  
**⚡ 重要程度**：🔴高  
**📋 变更摘要**：在 SGLang 工作节点中新增 `release_memory_occupation` 与 `resume_memory_occupation` 两个 REST 路由，实现 GPU 内存占用的动态释放与恢复，同时在服务发现层面实现端点的自动注销与重新注册，确保在内存回收期间不再接受新请求。  

**🎯 影响范围**：  
- `components/src/dynamo/sglang/main.py`（启动时注册新路由）  
- `components/src/dynamo/sglang/request_handlers/handler_base.py`（实现核心业务逻辑）  
- `components/src/dynamo/sglang/request_handlers/llm/decode_handler.py`、`prefill_handler.py`（构造函数签名扩展，传递 `generate_endpoint`）  

**🔍 技术洞察**  

- **架构影响**  
  - **服务发现耦合**：通过 `generate_endpoint.unregister_endpoint_instance()` / `register_endpoint_instance()` 将内存回收流程与 Dynamo 的服务发现（Discovery）绑定，使得节点在释放内存后自动从路由池剔除，恢复后重新加入。  
  - **统一入口注册**：在 `main.py` 中统一调用 `runtime.register_engine_route`，保持与其它 engine 路由相同的注册路径 (`/engine/<name>`) ，对外保持 API 稳定性。  
  - **Handler 基类扩展**：`BaseWorkerHandler` 增加 `generate_endpoint` 成员并实现两套异步流程，所有子类（Decode、Prefill）只需传递该对象，无需再在子类中重复实现。  

- **性能影响**  
  - **正向**：`release_memory_occupation` 能在不重启进程的情况下释放 KV‑cache、权重、CUDA‑graph 等显存资源，提升节点在多租户或弹性伸缩场景下的显存利用率。  
  - **潜在负载**：在 `release_memory_occupation` 调用期间，所有新请求会被阻断（因为端点已被注销），且当前正在执行的请求需等待 `engine.async_pause_generation()` 完成后才会被清空，短暂的停顿可能导致 99% 延迟峰值。  
  - **恢复成本**：`resume_memory_occupation` 需要重新加载权重等资源，取决于标签集合大小，可能出现几秒到十几秒的恢复窗口。  

- **安全考虑**  
  - **权限控制**：目前新增的两条 endpoint 没有显式的鉴权检查，若对外暴露可能被恶意调用导致服务不可用或显存被强行回收。建议在 `runtime.register_engine_route` 前加入 RBAC / token 校验。  
  - **异常泄露**：错误路径将原始异常信息直接返回给调用方（`message: str(e)`），可能泄露内部实现细节，建议统一错误码并脱敏。  

**⚠️ 潜在风险**  

| 风险点 | 描述 | 可能后果 | 缓解措施 |
|--------|------|----------|----------|
| **服务发现不一致** | `unregister_endpoint_instance` 成功但 `async_pause_generation` 失败，导致节点已从路由池但仍在生成请求。 | 请求丢失或超时，监控误报。 | 在异常回滚时重新 `register_endpoint_instance`，或者在 `pause_generation` 前做幂等检查。 |
| **内存恢复失败** | `async_resume_memory_occupation` 因显存碎片或权重加载错误抛异常，节点会重新注册但无法实际提供服务。 | 高错误率、CPU/GPU 资源浪费。 | 加入重试机制并在失败时降级为 “不可用” 状态，推送监控告警。 |
| **并发调用冲突** | 同时收到 `release` 与 `resume` 请求，可能出现状态竞态（已释放后再次释放或已恢复后再次恢复）。 | 状态不一致、重复资源释放导致崩溃。 | 在 handler 中使用 asyncio.Lock 或原子状态机 guard，确保一次只执行一种操作。 |
| **缺乏鉴权** | 任意客户端可调用这些接口。 | 服务被恶意 “Memory‑DoS”。 | 在路由注册时加入中间件进行 token / API‑key 验证。 |
| **日志噪声** | 每次释放/恢复都会记录多条 `info`，在高频调用场景下可能淹没关键日志。 | 难以排查其他问题。 | 采用结构化日志并控制日志级别，仅在调试模式下输出详细信息。 |

**💡 关注建议**  

1. **加入鉴权层**：在 `runtime.register_engine_route` 时包装一个统一的权限检查函数，确保只有内部控制平面或经过授权的管理员能触发内存回收/恢复。  
2. **幂等与状态机**：为每个 worker 增加 `memory_state`（`ACTIVE` / `PAUSED` / `RELEASED`）并在入口函数中检查当前状态，使用 `asyncio.Lock` 防止并发冲突。  
3. **监控 & 报警**：在 `release_memory_occupation`/`resume_memory_occupation` 完成后上报自定义指标（如 `memory_release_success_total`、`memory_resume_latency_seconds`），并在异常分支触发告警。  
4. **回滚策略**：若 `unregister_endpoint_instance` 成功但后续步骤失败，必须在 `except` 中尝试重新 `register_endpoint_instance`，避免节点永久失联。  
5. **文档与 SDK**：在 Dynamo 文档中补充这两个新 API 的使用示例、必需的 `tags` 参数以及推荐的调用时机（如节点缩容、GPU 资源紧张时）。  
6. **性能基准**：在不同显存占用比例下跑一次 `release` + `resume` 循环，记录暂停时间、恢复时间以及对整体 QPS 的影响，按需在调度系统中加入 “内存回收窗口” 的软限制。  

---  

总体而言，此次提交为 SGLang 引入了显存弹性管理能力，对提升集群资源利用率和支持动态伸缩极为关键，但也引入了服务发现同步、并发安全及授权控制等新风险。建议在正式上线前完成上述安全与幂等性强化，并通过压力测试验证暂停/恢复过程对整体吞吐的可接受性。

---

### feat: Sleep/wake endpoints for vLLM runtime (#5339)
**SHA**: `e2a0a4b` | 🔗 [查看提交](https://github.com/ai-dynamo/dynamo/commit/e2a0a4b5b92338a88f6de19d920b8494281dd2d7)

**🎯 变更类型**：功能增强  
**⚡ 重要程度**：🔴高  
**📋 变更摘要**：在 vLLM 运行时为引擎新增 `/engine/sleep` 与 `/engine/wake` 两个 HTTP 接口。`sleep` 用于在不接受新请求的情况下释放 GPU 内存并从服务发现中摘除实例，`wake` 用于重新恢复内存并重新注册实例以接受流量。注册流程已在 `init` 与 `init_prefill` 两处统一加入。  

**🎯 影响范围**：  
- `components/src/dynamo/vllm/handlers.py`（新增 `sleep`、`wake` 方法）  
- `components/src/dynamo/vllm/main.py`（运行时注册新路由）  
- vLLM 引擎客户端 (`engine_client.sleep` / `engine_client.wake_up`)  
- 服务发现/路由层（`generate_endpoint.unregister_endpoint_instance` / `register_endpoint_instance`）  
- 监控与日志系统（新增日志信息）  

**🔍 技术洞察**  

- **架构影响**  
  - **新增 API 层**：在运行时的 `EngineRouteRegistry` 中加入两条路由，使外部调度系统能够主动触发资源收缩/恢复。  
  - **状态机扩展**：引入“睡眠 → 唤醒”状态转换，需要确保在任意时刻只有一种状态有效，防止出现“已睡眠但仍被路由”的不一致。  
  - **发现服务耦合**：在 `sleep` 前先注销实例，确保在释放显存期间不会有新请求落到已睡眠的节点；`wake` 则相反，先恢复显存再重新注册。该顺序设计降低了竞争风险。  

- **性能影响**  
  - **正向**：空闲时通过 `sleep` 释放重量级显存（weights、kv 缓存等），可显著提升集群资源利用率，降低成本。  
  - **潜在**：唤醒时需要重新加载权重或缓存，可能导致请求延迟（冷启动）以及短暂的 CPU/GPU 峰值 IO。若 `tags` 过滤不当，可能出现不必要的全量加载，增加启动时间。  
  - **并发**：如果在 `sleep` 与 `wake` 之间仍有请求被路由，可能触发异常或资源竞争，需要依赖发现层的快速下线。  

- **安全考虑**  
  - **接口暴露**：`/engine/sleep`、`/engine/wake` 若未做身份校验，可被恶意用户随意触发，导致服务中断或资源浪费（频繁睡眠/唤醒导致 GPU 抖动）。  
  - **参数校验**：`level` 与 `tags` 直接传递给底层引擎，未做白名单校验可能导致非法值传入，引擎异常或未预期的内存释放。  
  - **审计**：现已有日志记录，但建议在审计系统中加入操作来源（token、IP）以便追溯。  

**⚠️ 潜在风险**  

1. **状态不一致**：若注销成功但 `engine_client.sleep` 失败，实例已不在发现中但仍占用显存，导致资源泄漏。  
2. **并发请求冲突**：在注销与实际睡眠之间的窗口期仍可能有请求路由到该实例，引发错误或部分请求失败。  
3. **异常恢复**：`wake` 过程中注册失败（网络、 discovery 服务不可用），会导致实例恢复显存却仍无法接受流量，形成“盲区”。  
4. **资源抖动**：频繁调用 `sleep`/`wake` 可能导致显存碎片化或 GPU 频率波动，影响长期性能。  
5. **安全滥用**：未加鉴权的开放接口可能被内部或外部脚本误用，引起服务不可用。  

**💡 关注建议**  

- **加固鉴权**：在 `runtime.register_engine_route` 前后统一加入 API 鉴权（OAuth、API‑Key 或 mTLS），仅限调度系统或运维账号调用。  
- **幂等与回滚**：将 `sleep` 与 `wake` 实现为幂等操作；在 `sleep` 失败后自动尝试撤销已完成的注销，或在 `wake` 出错时回滚显存加载。  
- **完善监控**：为新接口添加 Prometheus 指标（如 `engine_sleep_requests_total`, `engine_wake_latency_seconds`），并在 Grafana 中报警显存使用率异常或注册失败率。  
- **文档与限制**：在用户手册中明确 `level` 与 `tags` 的合法取值范围、预计恢复时长以及推荐的调用频率（例如每小时最多一次）。  
- **灰度验证**：先在单节点/测试集群开启，观察 sleep/wake 对吞吐、延迟、显存回收的实际效果，再逐步推广到生产。  
- **异常路径审计**：在 `except` 分支中记录更丰富的上下文（instance‑id、runtime‑id、请求来源）以便事后排查。  

通过上述措施，可最大化利用 GPU 资源、提升集群弹性，同时降低因接口误用或实现缺陷导致的服务中断风险。

---

#### 🟡 中重要度变更 (4)

### fix: add test for long context kv store events and fix drop issue (#5499)
**SHA**: `fdd2d15` | 🔗 [查看提交](https://github.com/ai-dynamo/dynamo/commit/fdd2d15e2ff4b3e467a2a91feefd1f6d6adb5b10)

**🎯 变更类型**：Bug 修复 / 性能优化  
**⚡ 重要程度**：🟡 中  

**📋 变更摘要**  
1. 为 `RadixTree` 实现自定义 `Drop`，采用显式栈迭代释放节点，防止深层递归导致的栈溢出。  
2. 新增 `test_radix_tree_large_stores`，在单元测试中构造深度递增的 KV‑store 序列，验证大规模存储的正确性及 drop 过程的安全性。  

**🎯 影响范围**  
- `lib/llm/src/kv_router/indexer.rs`（`RadixTree`、`RadixBlock`、`lookup` 结构）  
- 依赖 `RadixTree` 的 KV‑router 与事件处理模块（运行时内存管理）  

**💡 关注建议**  
- 检查 `Rc::try_unwrap` 失效时的 `drop(rc)` 是否会留下隐式循环引用，建议在文档中说明 `RadixTree` 不应出现环。  
- 该 Drop 实现对 `lookup` 中未被根节点引用的块也统一清理，确认所有路径均已覆盖，防止遗漏导致内存泄漏。  
- 运行完整测试套件，确保新加入的长序列测试在 CI 环境下不产生显著的执行时间或内存波动。  
- 考虑在未来加入基准测试，量化自定义 Drop 对极端深度树的性能提升。  

---

### refactor: clean up SGLang sleep/wake implementation (#5517)
**SHA**: `2e8c444` | 🔗 [查看提交](https://github.com/ai-dynamo/dynamo/commit/2e8c4447aefb1de06192582c577df9a1b8cef6c9)

**变更概览**  
本次重构将 SGLang 的 “sleep/wake”(release‑/resume‑memory) 与 profiling 路由的注册逻辑从 `main.py` 中抽离，统一搬到 `BaseWorkerHandler`（`handler_base.py`）。新增 `start_profile` / `stop_profile` 方法并在 `register_engine_routes` 中一次性注册四个路由，同时去除了 `logger = logging.getLogger(__name__)` 的冗余定义，改用直接的 `logging` 调用。

**核心影响**  
- **路由注册统一化**：所有 `DecodeWorkerHandler`、`PrefillWorkerHandler` 只需调用 `handler.register_engine_routes(runtime)` 即可完成 profiling 与 memory 管理路由的注册，避免了之前在 `main.py` 中的重复代码。  
- **日志行为变化**：原先在 `main.py` 的 `logging.info` 提示被移除，改为在 `BaseWorkerHandler` 中仅记录错误/警告，可能导致运行时观察不到路由成功注册的提示。  
- **兼容性**：外部插件或测试若直接依赖 `runtime.register_engine_route("start_profile", …)` 的显式调用仍能正常工作，因为路由仍然会被注册，只是注册时机晚于之前（在 handler 实例化后）。但若有代码在 `handler` 实例化前就尝试调用该路由，需确认运行顺序未受影响。

**建议**  
1. **测试覆盖**：重点跑通 profiling (`/engine/start_profile`、`/engine/stop_profile`) 与 memory 管理 (`release_memory_occupation`、`resume_memory_occupation`) 的端到端测试，确认路由仍能被发现并正常调用。  
2. **文档更新**：在 SGLang 开发手册中说明路由已统一在 `BaseWorkerHandler.register_engine_routes`，不再需要在业务入口手动注册。  
3. **日志监控**：如仍需在启动时看到路由注册信息，可在 `register_engine_routes` 中适当添加 `logging.info`，避免信息缺失导致运维困惑。  
4. **回退检查**：确认没有其他模块（如自定义 runtime 实现）在 `main.py` 之外再次手动注册同名路由，以防出现“重复注册”异常。  

总体来说，此次重构提升了代码可维护性，风险主要在路由注册时机和日志可观测性，两点验证后即可安全推广。

---

### fix(sglang): Fix YAML config parsing for store_true arguments (#5513)
**SHA**: `04cecda` | 🔗 [查看提交](https://github.com/ai-dynamo/dynamo/commit/04cecda7710164d55a9f2a2f9615dc5ec96c73d8)

**🎯 变更类型**：Bug 修复  
**⚡ 重要程度**：🟡 中  

**📋 变更摘要**：  
- 修复了在 SGLang 配置文件中使用 `store_true`/`store_false` 参数时，YAML 解析失效的问题。  
- 通过 runtime 检测 `ConfigArgumentMerger` 的构造函数签名，兼容旧版（v0.5.7）和新版（≥v0.5.7）API，避免硬编码版本号导致的兼容性错误。

**🎯 影响范围**：  
- `components/src/dynamo/sglang/args.py`（参数解析层）  
- 关联的 SGLang 依赖（`ConfigArgumentMerger`）  

**💡 关注建议**：  
1. **兼容性测试**：在 CI 中加入不同 SGLang 版本的矩阵测试，确保 `inspect.signature` 能正确识别两种构造函数签名。  
2. **异常安全**：`inspect.signature` 可能在极端环境（如 stripped 二进制）抛异常，建议捕获异常并回退到旧实现。  
3. **文档更新**：在项目 README/CHANGELOG 中注明此兼容实现，以免未来升级 SGLang 时误以为已统一使用新 API。  
4. **代码可读性**：将解析 `boolean_actions` 的逻辑抽离为私有函数，便于单元测试并提升可维护性。  

通过上述改动，解析 `store_true` 参数的可靠性提升，且对 SGLang 版本的硬依赖被消除，降低了后续升级风险。

---

### fix: on a bad network day, uv timeout too easily when building dev/local-dev containers (#5511)
**SHA**: `7b639e7` | 🔗 [查看提交](https://github.com/ai-dynamo/dynamo/commit/7b639e76e8cd755141532bbae6a38266c265c094)

**🔧 变更类型**：Bug 修复  
**⚡ 重要程度**：🟡 中  

**📋 变更摘要**  
在 `container/dev/Dockerfile.dev` 中，为 `uv pip install` 添加了缓存挂载，并将网络超时时间提升至 300 s、重试次数提升至 5 次（`UV_HTTP_TIMEOUT=300 UV_HTTP_RETRIES=5`），以防止在网络不佳时容器构建因超时而失败。

**🎯 影响范围**  
- `core` → Docker 镜像构建流程（dev / local‑dev 环境）  
- CI/CD 中使用该 Dockerfile 的构建步骤（如 GitHub Actions、内部流水线）  

**💡 关注建议**  
1. **缓存有效性**：`--mount=type=cache,target=/root/.cache/uv` 会复用下次构建的包缓存，需确保在依赖升级后手动清除或使用 `--no-cache` 进行强制刷新，防止出现“旧包”错误。  
2. **超时与重试**：提升的超时时间和重试次数对慢速网络友好，但也会延长真正的网络故障等待时间。建议在 CI 环境中通过变量（如 `UV_HTTP_TIMEOUT`）进行可配置化，以便在需要时快速调低。  
3. **兼容性验证**：在本地与 CI 两套环境分别执行一次完整的 `docker build`，确认构建时间、缓存命中率以及依赖解析结果均符合预期。  
4. **文档更新**：在项目的开发者指南或 Dockerfile 说明中加入新环境变量的解释及缓存目录的用途，帮助后续维护者了解该改动的目的。  

总体而言，此改动能显著降低因网络抖动导致的构建失败风险，但需关注缓存一致性和超时设置的灵活性，以免在网络异常时过度拖长构建时间。

---

#### 🟢 低重要度变更 (1)

### chore: update attributions for vllm cuda13 container (#5436) (#5488)
**SHA**: `8877c46` | 🔗 [查看提交](https://github.com/ai-dynamo/dynamo/commit/8877c46fb7908137b78c62e35f72ae381204c4d8)

**🎯 变更类型**：文档更新  
**⚡ 重要程度**：🟢 低  
**📋 摘要**：为 vllm CUDA 13 容器新增大量第三方组件的归属声明（ATTRIBUTIONS‑Python.md 与 ATTRIBUTIONS‑container‑vllm‑runtime.txt），包括 NVIDIA‑nvtx、nixl‑cu13、nccl、nvshmem、cudnn、cublas、cupti、cudart 等全部许可证及链接信息。  

（仅更新文档，不影响代码功能）

---

