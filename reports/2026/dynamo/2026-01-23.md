# 每日更新报告（2026-01-23）

## ai-dynamo/dynamo

| 提交时间 | 作者 | 提交信息 |
|----------|------|----------|
| 2026-01-23 17:50:09 | Schwinn Saereesitthipitak | feat: GPU Memory Service (#5286) |
| 2026-01-23 13:55:52 | Olga Andreeva | fix: enabling cuda mem pools for vectorized transfer in kvbm (#5475) |
| 2026-01-23 12:23:40 | jthomson04 | chore: Bump TRTLLM to 1.2.0rc6.post2 (#5580) |
| 2026-01-23 09:58:46 | dagil-nvidia | docs: update vLLM flag for local dev without NATS (#5587) |
| 2026-01-23 09:20:24 | Yan Ru Pei | chore: default python hash seed to zero always for the engines (#5583) |
| 2026-01-23 09:09:47 | Jacky | test: Rewrite Request Migration Tests and Add Disagg Scenarios (#5448) |
| 2026-01-23 08:43:32 | Alec | fix: add pre-commit cache dir and improve dockerignore (#5588) |
| 2026-01-23 07:49:19 | Indrajit Bhosale | feat: Standalone encoder in dynamo trtllm (#4668) |
| 2026-01-23 07:25:03 | Nate Mailhot | chore: update nixl to 0.9.0 (#5528) |
| 2026-01-23 07:22:40 | Jason Zhou | fix: TestProfileSlaAiconfigurator should use new framework versions (#5562) |
| 2026-01-23 06:59:59 | Ben Hamm | fix(recipes): address VDR feedback - fix bugs, improve docs, add READMEs (#5479) |
| 2026-01-23 06:48:28 | Julien Mancuso | feat: add dynamo operator observability (#5543) |
| 2026-01-23 06:21:19 | Ayush Agarwal | chore: added forced audit logging (#5552) |
| 2026-01-23 04:30:06 | dagil-nvidia | docs: quick fixes for README.md  (#5582) |
| 2026-01-23 04:15:56 | atchernych | feat: update GAIE to release version with hints in headers (#5503) |
| 2026-01-23 03:09:56 | Alec | ci: split vllm venv COPY into parallel layers for faster pulls (#5494) |
| 2026-01-23 02:42:11 | Yan Ru Pei | chore: use Rc in RadixTree BFS dumpt (#5574) |
| 2026-01-23 02:33:38 | Hongkuan Zhou | feat: add kalman filter as load predictor (#5554) |
| 2026-01-23 02:29:15 | atchernych | feat: Support the reading of routing hints from the headers  (#5502) |
| 2026-01-23 02:25:13 | Keiven C | fix: local-dev needs proper so files for sudo (#5556) |
| 2026-01-23 00:21:53 | dagil-nvidia | docs: improve the contributor experience of CONTRIBUTING.md (#5507) |

### 📊 统计摘要
> 本日共 21 个提交 | 🔴高 8 | 🟡中 5 | 🟢低 8
## 📋 目录

- [ai-dynamo/dynamo](#ai-dynamo-dynamo)
  - [📊 统计摘要](#-统计摘要)
  - [🔴 高重要度变更 (8)](#-🔴-高重要度变更-8)
    - [feat: GPU Memory Service (#5286)](#30c6228)
    - [fix: enabling cuda mem pools for vectorized transfer in k...](#cde3b2a)
    - [feat: Standalone encoder in dynamo trtllm (#4668)](#66963b7)
    - [fix(recipes): address VDR feedback - fix bugs, improve do...](#f366932)
    - [feat: add dynamo operator observability (#5543)](#53a609e)
    - [feat: update GAIE to release version with hints in header...](#4810ad3)
    - [feat: add kalman filter as load predictor (#5554)](#0d5c8df)
    - [feat: Support the reading of routing hints from the heade...](#cb352d9)
  - [🟡 中重要度变更 (5)](#-🟡-中重要度变更-5)
    - [test: Rewrite Request Migration Tests and Add Disagg Scen...](#cdcf6d0)
    - [fix: add pre-commit cache dir and improve dockerignore (#...](#edf847e)
    - [fix: TestProfileSlaAiconfigurator should use new framewor...](#e861f61)
    - [ci: split vllm venv COPY into parallel layers for faster ...](#b31b5b5)
    - [fix: local-dev needs proper so files for sudo (#5556)](#f438aee)
  - [🟢 低重要度变更 (8)](#-🟢-低重要度变更-8)
    - [chore: Bump TRTLLM to 1.2.0rc6.post2 (#5580)](#64ba7dd)
    - [docs: update vLLM flag for local dev without NATS (#5587)](#a7bc38d)
    - [chore: default python hash seed to zero always for the en...](#0316216)
    - [chore: update nixl to 0.9.0 (#5528)](#6dba119)
    - [chore: added forced audit logging (#5552)](#1032076)
    - [docs: quick fixes for README.md  (#5582)](#38fbb1d)
    - [chore: use Rc in RadixTree BFS dumpt (#5574)](#8f1ae2c)
    - [docs: improve the contributor experience of CONTRIBUTING....](#fb3a77b)
#### 🔴 高重要度变更 (8)

### feat: GPU Memory Service (#5286)
**SHA**: `30c6228` | 🔗 [查看提交](https://github.com/ai-dynamo/dynamo/commit/30c6228b822426f84b8adc85da20900087539c54)

**🎯 变更类型**：功能增强（新增 GPU Memory Service 组件）  
**⚡ 重要程度**：🔴高  
**📋 变更摘要**：向 Dynamo 项目中引入 **GPU Memory Service（GMS）**，实现基于 CUDA Virtual Memory Management (VMM) 的跨进程 GPU 内存分配与共享。新增 Python 包（含 C++ 扩展）、服务端 RPC、客户端管理器、PyTorch 集成以及完整的 Docker 镜像构建开关，使模型权重可在不同进程间零拷贝共享，并在写入、读取、sleep‑wake 场景下保持指针稳定。  
**🎯 影响范围**：  
- `components/src/dynamo/gpu_memory_service/**`（Python 包装层、CLI、服务器入口）  
- `lib/gpu_memory_service/**`（核心协议、服务器、客户端实现、C++ 扩展）  
- Dockerfile 系列（`container/Dockerfile*`）以及 `container/build.sh`（新增 `ENABLE_GPU_MEMORY_SERVICE` 开关）  
- `.devcontainer/post-create.sh`、`.dockerignore`、`.gitignore`、CI 过滤 (`.github/filters.yaml`)  
- `README.md`（安装指引）  
- 相关 Python 绑定、PyTorch 分配器、元数据管理、状态机与锁控制

---  

## 🔍 技术洞察

### 1. 架构影响
| 维度 | 具体变化 | 影响描述 |
|------|----------|----------|
| **模块划分** | 新增 `gpu_memory_service` 包、服务器（`GMSRPCServer`）与客户端（`GMSClientMemoryManager`）两套实现 | 形成 **服务‑客户端** 架构，原先的 `block-manager` 直接在进程内分配的模型权重被抽象为外部服务，解耦资源所有权 |
| **运行时模型** | 服务器只负责 **物理 GPU 内存分配**（不创建 CUDA 上下文），客户端负责 **VA 映射**、元数据读取并给 PyTorch 提供 `CUDAPluggableAllocator` | ① 服务器可在不含 CUDA 驱动的容器中运行（仅需 Python 头文件与 C++ 编译器） ② 客户端可在多进程框架（vLLM、SGLang）中共享同一块 GPU 内存，实现 **零拷贝** 与 **跨进程持久化** |
| **状态机** | `GlobalLockFSM` 通过 `RW/RO` 锁与 `COMMITTED` 状态显式管理写入/读取会话；支持 `rw_or_ro` 自动模式 | 防止写写竞争，确保 **写入后只能以 RO 方式读取**；在 `sleep()/wake()` 场景下保持 VA 不变，避免指针失效 |
| **构建系统** | Dockerfile 中加入 `ENABLE_GPU_MEMORY_SERVICE` 参数，默认仅在 VLLM/SGLang 镜像中打开；`setup.py` 提供 C++ 扩展编译 | 新增可选编译路径，降低对普通 Dynamo 镜像的侵入性；但需要 `g++` 与 Python 开发头文件，构建脚本对 CI 新增依赖检测需求 |
| **CLI & 配置** | `gpu_memory_service/args.py`、`gpu_memory_service/server.py` 提供 `--device`、`--socket-path`、`--verbose` 参数 | 与上层框架的 `--load-format gpu_memory_service`、`--model-loader-extra-config` 对接，统一配置入口 |

### 2. 性能影响
| 场景 | 潜在收益 | 潜在开销 |
|------|----------|----------|
| **跨进程模型加载** | 只复制一次权重，后续子进程通过 `export`/`import` 共享同一块 GPU 内存，显著降低 PCIe 传输与显存拷贝成本 | RPC（Unix domain socket）+ FD 传递的系统调用开销；每次 `import_allocation` 需要 `cuMemMap`/`cuMemSetAccess`，相对 `cudaMalloc` 有少量额外延迟 |
| **写入/发布** | `commit` 前统一 `torch.cuda.synchronize`，一次性切换权限，避免频繁的 `cuMemSetAccess` | `commit` 触发服务器关闭 RW 连接并计算全局哈希，可能导致短暂阻塞 |
| **sleep / wake** | 只解除物理映射保留 VA，恢复时无需重新分配，大幅加速 **RL 训练‑推理切换** | `unmap`/`remap` 仍需多次 `cuMemMap`/`cuMemUnmap`，在大量分配（如 KV‑Cache）时可能出现显著 CPU 开销 |
| **C++ allocator** | 通过 `CUDAPluggableAllocator` 直接调用 Python 回调实现 `malloc/free`，省去 `torch.cuda.memory` 的内部调度层 | 每次 malloc/free 需要跨语言回调（Python ↔ C++），在极端小 `malloc` 场景（大量小张量）会有函数调用开销 |

总体而言，**大模型部署**（权重一次性加载、推理多进程）受益显著；**高频小分配** 场景需关注回调开销与锁竞争。

### 3. 安全考虑
| 风险点 | 描述 | 缓解措施 |
|--------|------|----------|
| **Unix 域套接字文件** | 服务器通过 `socket_path` 暴露在文件系统，若路径权限过宽，恶意进程可抢占或注入 FD | 建议在启动时使用 `umask 077`，或在容器内部仅对 `dynamo` 用户可写；在 CI 中加入 `chmod 600` 检测 |
| **FD 传递** | `export_fd` 将 CUDA 内存句柄以 POSIX FD 形式发送，接收方若未正确关闭会导致句柄泄漏 | 在 Python 端使用 `with` / `finally` 确保 `os.close(fd)`；在服务器端 `export_fd` 后立即返回，不持有该 FD |
| **状态哈希泄露** | `GetStateHashResponse` 返回完整的哈希，理论上可被用作侧信道推断模型结构 | 哈希仅用于内部校验，若对外公开请在生产环境中关闭 `GET_STATE_HASH`（可通过环境变量或协议层过滤） |
| **未经验证的请求** | RPC 调用通过 `msgspec` 解码后直接映射到业务方法，若消息被篡改可触发异常路径 | 在 `RequestHandler` 中对所有字段做显式校验；在 `GMSRPCServer._dispatch` 前使用 `GlobalLockFSM.check_operation` 进行模式检查 |
| **C++ 扩展注入** | `_allocator_ext` 通过全局 Python 回调执行 `malloc`/`free`，若回调实现被恶意覆盖会执行任意 Python 代码 | 在 `extensions/__init__.py` 中对导入进行异常捕获；建议在正式部署时将回调函数固化在库内部，避免外部可替换 |

### 4. 潜在风险点
1. **资源泄露**：  
   - VMM 句柄 (`cuMemRelease`)、VA 预留 (`cuMemAddressFree`) 若未在异常路径彻底释放，会导致显存泄漏。  
   - 客户端 `GMSClientMemoryManager.free_mapping` 与 `close` 必须在异常捕获后保证调用。  


---

### fix: enabling cuda mem pools for vectorized transfer in kvbm (#5475)
**SHA**: `cde3b2a` | 🔗 [查看提交](https://github.com/ai-dynamo/dynamo/commit/cde3b2a5b464e27c837446626612e75e65fd9e86)

**🎯 变更类型**：功能增强 / 性能优化 / 重构  
**⚡ 重要程度**：🔴高  
**📋 变更摘要**：  
本次提交为 KV-BM（键值块管理）模块引入了基于 CUDA Memory Pool 的设备内存分配实现，取代原先的 pinned‑buffer 池。新增 `dynamo-memory` crate 与 `CudaMemPool`、`CudaMemPoolBuilder`，在 `TransferContext` 中创建并暴露该池，随后在块向量化拷贝路径 (`copy_blocks_with_customized_kernel`) 中使用流序列化的设备内存分配与释放，避免了每次拷贝的 `cudaMalloc/cudaFree` 与 pinned‑host 内存的频繁申请。相应的 Cargo 配置、错误处理与测试代码也同步更新，使得在高并发传输场景下能够充分利用 CUDA 11+ 的内存池特性提升吞吐与延迟。

---

### 🎯 影响范围
- **核心模块**：`lib/llm/src/block_manager/block/transfer/*`（TransferContext、kernel launch、拷贝逻辑）  
- **依赖层**：`lib/bindings/kvbm/Cargo.lock` 新增 `dynamo-memory` → 引入 `cudarc`、`nixl-sys`、`offset-allocator` 等。  
- **构建脚本**：`lib/llm/Cargo.toml` 中 `block-manager` feature 增加 `dep:dynamo-memory`。  
- **运行时**：KV‑BM worker、offload、distributed worker 在创建 `TransferContext` 时必须成功初始化 CUDA Memory Pool。  
- **测试套件**：`tests/kvbm_integration` 中的确定性测试已取消 `xfail`，并对请求参数做了细微调整以配合新实现。

---

### 🔍 技术洞察

| 维度 | 影响说明 |
|------|----------|
| **架构影响** | - 新增 `memory::pool::cuda` 子模块，实现 **安全、线程序列化** 的 CUDA Memory Pool 包装。<br>- `TransferContext` 现在持有 `Option<Arc<CudaMemPool>>`，并提供 `cuda_mem_pool()` 接口，供上层拷贝函数使用。<br>- 旧的 *Pinned Buffer Pool* 仍保留为 `Legacy` 标记，仅用于兼容早期路径，未来将移除。 |
| **性能影响** | - 通过 `cuMemAllocFromPoolAsync`/`cuMemFreeAsync`，一次性预热（reserve）数十 MB 设备内存，后续分配几乎为常数时间，显著降低每次向量化拷贝的 `cudaMalloc`/`cudaFree` 开销。<br>- 采用 **流序列化**（stream‑ordered）分配，避免主机端 pinned‑host 内存拷贝与同步点，提升并发传输的吞吐。<br>- 记录并同步 H2D 事件后再释放 host‑side 向量，防止数据竞争。整体预计在 `max_concurrent_transfers ≥ 8` 时可提升 30‑70% 的带宽利用率。 |
| **安全考虑** | - 所有 CUDA API 调用均包装为 `Result`，错误向上传递并在 `TransferContext::new` 中转换为 `anyhow::Error`，避免 panic。<br>- `CudaMemPool` 实现 `Drop`，在销毁时调用 `cuMemPoolDestroy`，确保内存回收。<br>- 对 `free_async_raw` 使用 `unsafe`，但已在安全层面限制仅接受由本池分配的指针，降低悬空释放风险。 |
| **可维护性** | - 代码结构更清晰：分配/释放逻辑集中在 `memory::pool::cuda`，拷贝路径只关心 *获取指针并使用*。<br>- `TransferResources`（旧的 pinned‑buffer 结构）仍在项目中，但已在 `TransferContext::new` 中明确标记为不再使用，未来可安全删除。<br>- 新增单元测试覆盖 pool 创建、预热、基本分配/释放流程。 |
| **兼容性** | - 依赖 CUDA 11.2+（`cuMemPool*` APIs），在旧驱动上会返回 `CUDA_ERROR_NOT_SUPPORTED`，导致 `TransferContext::new` 返回错误。调用方已在 `worker.rs`、`offload.rs` 中将错误升级为 `anyhow` 并打印，促使用户检查 GPU 环境。<br>- 仍然保留 `pinned buffer` 代码路径，以兼容不支持 memory‑pool 的环境。 |

---

### ⚠️ 潜在风险

1. **GPU 驱动/CUDA 版本不兼容**  
   - `cuMemPoolCreate` 在 CUDA 11.2 之前不可用。若用户在旧环境运行，`TransferContext::new` 会失败并导致整体 KV‑BM 启动中断。  
   - 建议在发布说明中明确最低 CUDA 版本要求，并在运行时检测 `cudarc::driver::has_mem_pool()`（或类似）提前报错。

2. **内存预热规模误估**  
   - `reserve_size` 按配置 `(max_concurrent_transfers * 2 + 2) * max_transfer_batch_size * num_outer_components * num_layers * sizeof(u64)` 计算，若配置异常大（如数百 GB），创建 pool 可能失败或导致 OOM。  
   - 需要在 `TransferContext::new` 对 `reserve_size` 设置上限（如 8 GB）并给出警告。

3. **多线程竞争与死锁**  
   - `CudaMemPool` 内部使用 `Mutex` 序列化 **分配** 调用；若高并发线程频繁进入 `alloc_async`，可能成为热点。当前实现为 `Mutex`，在极端负载下可能出现 contention。可考虑使用 `parking_lot::Mutex` 或细化锁粒度（如 per‑stream sub‑pool）进行优化。

4. **泄漏风险**  
   - `TransferContext::Drop` 未显式检查 `cuda_mem_pool` 中是否还有未释放的块。若上层忘记 `free_async`，GPU 端仍会在流完成后回收，但在 `Drop` 前的 `Arc` 持有可能导致 pool 未及时销毁。需要在 `TransferContext` 中加入调试统计（已分配/已释放计数）并在 `Drop` 时 assert 为 0（仅在 debug 编译）。

5. **错误传播**  
   - `TransferContext::new` 现在返回 `Result<Self, anyhow::Error>`. 若调用方未及时 `?` 处理（如在 `OffloadManager::offload_worker` 中），会导致隐式 panic 或未捕获的错误。代码已补全 `map_err`，但仍需审计所有 `TransferContext::new` 调用点。

6. **测试覆盖不足**  
   - 现有集成测试仅验证确定性行为，未针对高并发、大尺寸转移做压力测试。建议新增 benchmark（`block-manager-bench`）验证在 16‑64 并发流下的内存池利用率与延迟。

---

### 💡 关注建议

| 对象 | 建议 |
|------|------|
| **库维护者** | - 在 `README`/`CHANGELOG` 中加入 “最低 CUDA 11.2，需支持 `cuMemPool*`”。<br>- 提供运行时检查函数 `fn cuda_mem_pool_supported() -> bool`，在 `TransferContext::new` 前提前返回明确错误信息。 |
| **用户/部署者** | - 在升级前确认 GPU 驱动 ≥ 470.xx、CUDA Toolkit ≥ 11.2。<br>- 如使用旧驱动，可通过环境变量 `DYNAMO_DISABLE_CUDA_MEM_POOL=1` 强制回

---

### feat: Standalone encoder in dynamo trtllm (#4668)
**SHA**: `66963b7` | 🔗 [查看提交](https://github.com/ai-dynamo/dynamo/commit/66963b70402be0fa64129fd051098ac81f76ccc0)

**🎯 变更类型**：功能增强（Standalone encoder & 全链路 E/P/D 多模态推理）

**⚡ 重要程度**：🔴高  

**📋 变更摘要**  
- 在 **TRT‑LLM** 后端新增 **Encode** 工作进程，支持两条独立路径：  
  1️⃣ 通过 **NIXL** 读取用户提供的预计算嵌入文件（`.pt/.pth/.bin`），实现零拷贝 RDMA 传输；  
  2️⃣ 通过 **MultimodalEncoder.generate()** 直接对图像 URL（http/https/base64）进行视觉编码，返回 `disaggregated_params`（包含 `multimodal_embedding_handles`）供 Prefill 使用。  
- 新增 `DisaggregationMode` 枚举、 `TensorRTLLMEngine` 能在 `Encode` 模式下实例化 `MultimodalEncoder`，以及一套 **EncodeHelper / Handler** 实现协程‑安全的请求拆分、参数编码/解码、元数据缓存。  
- 文档、示例脚本、配置文件、Jinja 模板全线同步更新，并为 E/P/D（图像 URL 与预计算嵌入两种）提供完整的启动方式。  

---

## 🔍 技术洞察

| 维度 | 影响 |
|------|------|
| **架构影响** | - 将原本 **Prefill** 中的视觉编码职责抽离到 **Encode**，形成 **E → P → D** 三阶段流水线。<br>- `TensorRTLLMEngine` 现在接受 `disaggregation_mode` 参数，统一在 `engine` 初始化时决定实例化 `LLM` 还是 `MultimodalEncoder`（均实现 `BaseLLM` 接口，保持后续调用透明）。<br>- 新增 `constants.DisaggregationMode`，取代旧的内部 `Enum`，并在 `handler_base`、`main`、`launch` 脚本统一引用，提升可维护性。 |
| **性能影响** | - **并行化**：Encode、Prefill、Decode 可分别占用独立 GPU，视觉编码与语言模型 KV‑cache 计算不再竞争同一块显存，显著降低单请求的峰值显存占用，并提升吞吐量。<br>- **零拷贝**：Embedding‑path 通过 NIXL RDMA 直接把磁盘/网络的张量读入 Prefill，省去 CPU→GPU 拷贝和额外的序列化。<br>- **异步阻塞**：`EncodeHelper._process_full_epd_flow` 使用 `asyncio.to_thread` 将同步的 `MultimodalEncoder.generate` 移出事件循环，避免阻塞 Encode 工作进程的并发调度。<br>- **流式增量解码**：`MultimodalRequestProcessor.create_response_chunk` 改为基于 `previous_decoded_text` 计算增量，避免每次 `decode` 都重新 `tokenizer.decode` 整段文本，提升 Streaming 响应的 CPU 开销。 |
| **安全考虑** | - **远程媒体加载**：仍通过 `MultimodalProcessor.load_tensor_from_path_or_url` 读取用户提供的 URL。新增 `allowed_local_media_path` 与 `max_file_size_mb` 参数（在 `epd_multimodal_image_and_embeddings.sh` 中可配置），对本地文件路径与文件大小做了基本限制。<br>- **NIXL 元数据泄露**：`EncodeHelper._process_embedding_path_flow` 只返回 `metadata`（shape、dtype）和可选的辅助字段，未直接暴露原始张量；潜在风险在于 RDMA 读写权限仍由底层 NIXL 控制，需保证集群网络安全策略。<br>- **Base64 解码**：`utils.disagg_utils` 在 `decode`/`encode` 时对 `opaque_state` 进行显式 base64 编/解码，避免因误用 `bytes` → `str` 产生的潜在信息泄漏。 |
| **可维护性** | - 将 **DisaggregationMode** 抽离为公共常量，所有子系统（engine、handlers、launch 脚本、文档）使用同一枚举，降低拼写/硬编码错误。<br>- `EncodeHelper` 将两种路径的处理逻辑拆分为私有静态方法，代码结构清晰，单元测试更易定位。<br>- `HandlerBase._setup_disaggregated_params_for_mode` 集中处理 PREFILL/DECODE 对 `DisaggregatedParams` 的组装与解码，避免在各 handler 中重复实现。 |

---

## ⚠️ 潜在风险

| 类别 | 描述 | 风险等级 |
|------|------|----------|
| **并发状态混用** | `MultimodalRequestProcessor` 的 `previous_decoded_text` 作为实例属性在 Streaming 场景下跨请求共享。如果同一 `Encode/Prefill` 工作进程处理并发流式请求，后一个请求的 `previous_decoded_text` 可能被前一个请求覆盖，导致增量 `delta` 计算错误。 | 中 |
| **Encoder 初始化参数不匹配** | `TensorRTLLMEngine` 在 `Encode` 模式仅传递 `model` 与 `max_batch_size` 给 `MultimodalEncoder`。若用户的模型需要其它必填参数（如 `tokenizer_path`、`vision_encoder` 选项），会导致运行时 `TypeError`。 | 中 |
| **NIXL RDMA 依赖** | NIXL 仅在 `x86_64`、特定内核/驱动版本下受支持；在不兼容的机器上调用 `embedding_path` 流程会抛出 `RuntimeError`，并导致 Prefill 卡死。 | 中 |
| **远程媒体下载** | `MultimodalEncoder.generate` 会下载图像 URL，如果未对 URL 域名或文件大小进行限制，可能被用于 **SSRF** 或下载大文件耗尽内存/磁盘。 | 高 |
| **DisaggregatedParams 兼容性** | `DisaggregatedParamsCodec.encode`/`decode` 采用 `dataclasses.replace`，但如果后端 TRT‑LLM 在新版本中新增字段，旧 `Codec` 可能会丢失或未能正确序列化，导致 Prefill/Decode 报错 `KeyError`。 | 中 |
| **测试覆盖不足** | 目前仅新增了 EPD 流程的端到端集成测试；缺少对 **异常分支**（如 NIXL 失败、Encoder 生成空 `ep_disaggregated_params`、图像下载超时）的单元测试。 | 中 |
| **文档/脚本同步** | 多个 `launch/*.sh` 脚本已更新，但仍保留旧的 `epd_disagg.sh`（仅示例）未同步 `encode` 参数，易导致用户误用。 | 低 |

---

## 💡 关注建议

1. **并发安全**  
   - 将 `previous_decoded_text` 移入 **每次请求的局部上下文**（如放入 `Request` 对象或 `ThreadLocal`），或在 `create_response_chunk` 前先获取锁，防止跨请求交叉。  
2. **Encoder 参数校验**  
   - 在 `TensorRTLLMEngine.__init__` 中加入 **参数白名单校验**（`model`, `max_batch_size`, `vision_encoder_cfg` 等），若缺失则抛出明确的错误信息。  
3. **安全硬化**  
   - 为 `MultimodalProcessor.load_tensor_from_path_or_url` 添加 **白名单域名**、**最大下载时长**、**文件大小检查**（对 HTTP `Content‑Length` 预

---

### fix(recipes): address VDR feedback - fix bugs, improve docs, add READMEs (#5479)
**SHA**: `f366932` | 🔗 [查看提交](https://github.com/ai-dynamo/dynamo/commit/f366932aa057c3afec03f82814ff8526e424549e)

**🎯 变更类型**：功能增强 / Bug 修复 / 文档改进  
**⚡ 重要程度**：🔴 高  

**📋 变更摘要**  
本次提交在 `recipes` 目录中加入了多套全新部署示例（DeepSeek‑R1、Qwen3‑235B‑A22B、Qwen3‑32B‑FP8、Llama‑3‑70B 等），并对已有配方进行大量修正：统一镜像标签至 `0.8.0`、改用 HuggingFace 模型标识符、更新 GPU 数量与特性说明、补全 GAIE 集成列、完善下载、存储与环境变量文档。整体目标是提升配方的可用性、可维护性，并响应 VDR（Verification & Design Review）反馈。

---

### 🎯 影响范围
- `recipes/` 目录下所有模型配方（Llama‑3‑70B、Qwen3‑32B‑FP8、Qwen3‑235B‑A22B、DeepSeek‑R1、GPT‑OSS‑120B 等）  
- 相关的 K8s 部署清单（`deploy.yaml`、`gaie` manifest）  
- 文档文件 `README.md`（主目录及各模型子目录）  
- 镜像引用统一至 `nvcr.io/nvidia/ai-dynamo/*-runtime:0.8.0` 与前端 `frontend:0.8.0`  

---

### 🔍 技术洞察

| 维度 | 影响说明 |
|------|----------|
| **架构影响** | - 新增 **Multi‑Feature Recipe**，将 **Disaggregated Serving** 与 **KV‑aware Routing** 组合，提供更完整的 Dynamo 性能特性演示。<br>- 引入 GAIE（Gateway API Inference Extension）列，明确哪些配方已经集成 AI‑Inference Gateway，帮助使用者快速决定是否启用。<br>- 多模型 README 的统一结构提升了项目的可导航性与可扩展性。 |
| **性能影响** | - 多数 `deploy.yaml` 中的 `gpu-memory-utilization` 参数由 `0.95` 调整为 `0.90`，降低单卡显存占用，提升在共享集群上的部署成功率。<br>- 将模型路径从本地 PV 路径改为 HF 模型标识（如 `RedHatAI/Llama-3.3-70B-Instruct-FP8-dynamic`），配合最新 Runtime 镜像的模型加载逻辑，可利用内部的模型缓存与并行下载优化，提高启动速度。<br>- 新增 `HF_HOME` 环境变量统一模型缓存目录，避免跨容器的路径冲突。 |
| **安全考虑** | - 仅文档层面的更改，没有引入新代码执行路径。<br>- 所有镜像仍基于 NVIDIA 官方受信容器，安全性不受影响。<br>- 文档中强调 **HuggingFace token** 的创建方式，提醒用户在生产环境使用 Secret，避免明文泄露。 |
| **可维护性** | - 镜像版本统一为 `0.8.0`，消除 “`my-tag`” 占位符导致的部署错误。<br>- 通过模型标识符替代硬编码路径，降低后续模型迁移成本。<br>- 新增 `README.md` 为每个模型提供完整的前置条件、快速启动与硬件需求说明，降低新手上手门槛。 |

---

### ⚠️ 潜在风险
1. **镜像同步风险**：如果 `0.8.0` 镜像在容器仓库未同步或与本地构建的 Runtime 不兼容，部署会失败。  
2. **模型路径变更破坏**：已有用户可能仍在使用旧的本地路径（`/opt/models/hub/...`），升级后需手动迁移或回滚。  
3. **GPU 数量/配置误导**：部分配方的 GPU 计数（如从 `4x` 到 `2x`）已更正，但文档或 CI 仍可能引用旧值，导致资源预估错误。  
4. **GAIE 集成标记**：GAIE 列仅在文档层面标记，若实际 `gaie` 组件未部署，用户可能误以为已集成。  

---

### 💡 关注建议
- **镜像验证**：在 CI 中加入对 `nvcr.io/nvidia/ai-dynamo/*-runtime:0.8.0` 拉取成功与版本校验的步骤。  
- **回滚指南**：在每个 `README` 中注明若使用旧路径或旧镜像的回退方法（如保留 `my-tag` 占位符的旧配方）。  
- **自动化文档检查**：使用脚本对所有配方的 `GAIE` 列与实际 `gaie` 目录结构进行一致性检查。  
- **资源预估更新**：在项目根目录的硬件需求表中同步最新 GPU 数量与显存需求，避免误配。  
- **安全强化**：推荐在 `README` 中强调使用 `kubectl create secret` 时启用 `--dry-run=client -o yaml | kubectl apply -f -` 方式，以防 Token 暴露在 bash 历史记录。  

> 综合来看，此次提交显著提升了 Dynamo 配方的完整性与可用性，属于一次高价值的功能增强兼文档修复。项目团队应在下一个发布周期前完成镜像同步与回滚文档的细化，以确保平滑迁移。

---

### feat: add dynamo operator observability (#5543)
**SHA**: `53a609e` | 🔗 [查看提交](https://github.com/ai-dynamo/dynamo/commit/53a609e538fd787903de3172ccddd36e65017f44)

**🎯 变更类型**：功能增强（新增 Operator 可观测性：Prometheus 指标、Grafana 仪表盘、Metrics 端点包装器）  
**⚡ 重要程度**：🔴 高  

**📋 变更摘要**  
1. 为 Dynamo Operator 增加完整的可观测性套件：  
   - 新的 Prometheus 指标（reconcile、webhook、资源计数）。  
   - Helm Chart 自动创建 `ServiceMonitor`，并在 `values.yaml` 中默认开启 `metricsService.enabled:true`。  
   - 新增 Grafana 仪表盘 JSON（两份，一份用于 `deploy/observability/grafana_dashboards`，另一份用于 `ConfigMap` 供 kube‑prometheus‑stack 自动导入）。  
2. 在 Operator 代码层面实现 **观察包装器**：  
   - `observability/metrics.go` 定义并注册所有自定义度量。  
   - `observability/reconciler_wrapper.go` 为每个 controller 添加统一的 **reconcile** 时长、结果、错误统计。  
   - `observability/webhook_wrapper.go` 为所有 admission webhook 添加验证耗时、成功/拒绝计数。  
   - `observability/resource_counter.go` 每 30 s 基于缓存 client 统计 CRD 实例的 **状态**（ready / not_ready / unknown）并上报 gauge。  
3. 为所有 CRD（Model、ComponentDeployment、GraphDeployment、GraphDeploymentRequest、ScalingAdapter）实现 `GetState()` 与 `IsReady()` 辅助方法，统一状态标签。  
4. 在 `main.go` 中初始化度量、启动资源计数 goroutine；在每个 controller `SetupWithManager` 中使用 `observability.NewObservedReconciler` 包装实际 reconciler；在 webhook 注册时使用 `NewObservedValidator` 包装 lease‑aware validator。  
5. 通过 **constants** 统一资源种类与状态字符串，保证 metric label 的统一性。  

**🎯 影响范围**  
- `deploy/operator/internal/*`（controller、webhook、consts、main）  
- `deploy/operator/api/v1alpha1/*`（新增 `GetState` 方法）  
- Helm chart `deploy/helm/charts/platform/components/operator`（ServiceMonitor 模板、默认开启 metrics）  
- 新增 `deploy/observability/*`（Grafana 仪表盘、ConfigMap、内部 observability 包）  
- 文档 `docs/kubernetes/observability/*` 与根目录的可观测性章节。  

---

### 🔍 技术洞察  

| 维度 | 影响描述 |
|------|----------|
| **架构影响** | - 引入 **观测层**（metrics 包）作为跨‑controller、webhook 的横切关注点；不影响业务逻辑，保持单一职责。<br>- `ServiceMonitor` 替代原来的 `ClusterRole` RBAC（已删除），只需 `monitoring.coreos.com/v1` 支持，简化权限模型。<br>- 新增 `ResourceState` 常量与 `GetState()` 方法，使资源状态统一为 **ready / not_ready / unknown**，供 `resource_counter` 使用，兼容所有 CRD。 |
| **性能影响** | - 每次 **Reconcile** 额外记录一次 histogram + counters，开销极小（ns‑级）。<br>- `resource_counter` 每 30 s 从缓存 client 拉取全部 CRD 列表并遍历，CPU/内存消耗随资源规模线性，典型集群（< 10k CR）几毫秒完成。<br>- `webhook` 包装在验证路径上，仅在 Admission 请求时记录一次 histogram，导致的额外延迟在毫秒级以下。 |
| **安全考虑** | - 暴露 `/metrics` 端口（默认 8443），通过 `--ignore-paths=/metrics` 让 `kube‑rbac‑proxy` 仅对该路径放行；仍建议在集群网络层（NetworkPolicy）仅允许 Prometheus 抓取。<br>- 删除原先的 `ClusterRole`（rbac‑proxy）后不再授予广泛的 `get /metrics` 权限，降低潜在的 privilege escalation。<br>- `ServiceMonitor` 需要 `monitoring.coreos.com/v1` CRD，若集群未安装 kube‑prometheus‑stack，则 Helm 将自动不创建（guarded by `if .Capabilities.APIVersions.Has "monitoring.coreos.com/v1"`）。 |
| **可维护性** | - 所有度量注册集中在 `metrics.go`，统一管理 bucket、label，后续新增指标只需在此文件添加。<br>- 通过包装器 `ObservedReconciler`、`ObservedValidator`，所有 controller/webhook 自动获得统一的指标，无需在每个业务实现中重复代码。<br>- `GetState()` 实现与业务逻辑解耦，后续若增加更多状态（如 `degraded`）只需修改 const 与实现即可。 |
| **兼容性** | - 增加的 `GetState()` 方法为 **非破坏性**（只在内部调用），不影响现有 CRD 版本兼容。<br>- 默认开启 `metricsService.enabled:true`，但保留 `values.yaml` 开关，老用户可通过 `--set dynamo-operator.metricsService.enabled=false` 维持旧行为。<br>- 对于未安装 `ServiceMonitor` 的集群，Helm 将回退为仅创建 `ConfigMap`（不报错），保持安装成功。 |
| **文档/运维** | - 完整的 Operator Metrics Guide、Grafana Dashboard 配置、Troubleshooting 小节已加入，帮助运维快速验证。<br>- 更新了 `docs/_sections/k8s_observability.rst` 与根目录 README，确保可观测性入口统一。 |

**⚠️ 潜在风险**  

1. **Metrics 暴露误配置**  
   - 如果未通过 NetworkPolicy 限制 `/metrics` 访问，外部主体可读取内部状态。  
   - `--ignore-paths=/metrics` 只在 `kube‑rbac‑proxy` 中生效，若使用自定义 sidecar 可能失效。  

2. **ServiceMonitor 依赖缺失**  
   - 集群未安装 `monitoring.coreos.com/v1`（如未部署 kube‑prometheus‑stack）会导致 ServiceMonitor 资源无法创建，导致 Prometheus 抓不到 Operator 指标。  
   - Helm 检查 `Capabilities.APIVersions.Has`，但在 **升级** 过程中若先装 CRD 再升级，可能出现 “ServiceMonitor 已存在但未被监控” 的误报。

3. **资源计数误差**  
   - `resource_counter` 依赖缓存 client，如果 `ExcludedNamespaces` 实现不完整（如漏掉某些租约）可能导致 **双计数**（两个 operator 实例都统计同一命名空间的资源）。  
   - 计数间隔 30 s，短期瞬时变化不会即时反映；监控告警阈值需考虑该延迟。  

4. **二进制体积 & 启动时间**  
   - 引入 `prometheus/client_golang`、`observability` 包会增加约 1‑2 MB 的二进制体积，启动时间略增。  

5. **兼容旧版本**  
   - 旧版 Operator（未包含 `GetState`）若仍在集群中运行，与新部署的 `resource_counter` 共存会导致 **panic**（接口未实现）。应确保所有 Operator pod 统一升级。  

**💡 关注建议**  

| 建议 | 说明 |
|------|------|
| **验证 Metrics 可达性** | 在集群内部执行 `curl -k https://<operator-pod>:8443/metrics`，确认返回。随后在 Prometheus UI 检查 `dynamo_operator_reconcile_total` 是否被抓取。 |
| **NetworkPolicy 加固** | 为 `dynamo-operator` 命名空间添加只允许 `monitoring` 命名空间的 Prom

---

### feat: update GAIE to release version with hints in headers (#5503)
**SHA**: `4810ad3` | 🔗 [查看提交](https://github.com/ai-dynamo/dynamo/commit/4810ad349d864e679324da23dca790d992d536aa)

**🎯 变更类型**：功能增强 / 重构 / 架构变更  
**⚡ 重要程度**：🔴高  

**📋 变更摘要**  
- 引入 **Dynamo EPP**（自定义 Endpoint Picker Plugin）并基于 **KV‑aware scorer** 与 Dynamo 路由器的 FFI 进行深度集成。  
- 删除旧的 GAIE EPP Dockerfile 与构建脚本，新增专属 **Dockerfile**、**Makefile**、**go.mod**、插件代码以及 Helm Chart 配置，使 EPP 能直接加载 Dynamo 静态库 `libdynamo_llm_capi.a`。  
- 在请求处理流中通过 HTTP 头部 (`x-worker-instance-id`, `x-prefiller-host-port`, `x-dynamo-routing-mode`) 将路由决策注入后端，实现 **header‑only routing**。  
- 更新 CRDs、Helm Chart、README 与部署脚本，升级至 **GAIE v1.2.1**，并统一使用 `inference.networking.k8s.io` API。  

**🎯 影响范围**  
- `container/`（Dockerfile、build.sh）  
- `deploy/inference-gateway/`（README、Helm templates、install 脚本）  
- `pkg/epp/`（请求控制、调度插件、插件注册）  
- 新增 `deploy/inference-gateway/epp/`（独立 EPP 项目）  
- 相关配置文件：`epp-config-dynamo.yaml`、`values-dynamo-epp.yaml`、`epp-config-dynamo.yaml`（Helm）  
- 受影响的模块：EPP 二进制、外部处理服务器、Kubernetes InferenceGateway、Dynamo 路由器  

**🔍 技术洞察**  

| 维度 | 影响分析 |
|------|----------|
| **架构** | 1. **插件化**：在 GAIE 插件体系中注册 `kv-aware-scorer`、`dynamo-inject-workerid`，通过 `PluginState` 跨阶段（Score → PreRequest → ResponseComplete）共享路由信息。<br>2. **FFI 层**：使用 CGO 绑定 Rust 编写的 `libdynamo_llm_capi.a`，在 Go 端调用 `dynamo_query_worker_selection_and_annotate`、`dynamo_router_*` 系列函数，实现 **持久化 pipeline**（单例）以及 **运行时初始化/关闭**。<br>3. **新部署模型**：EPP 作为独立容器镜像构建，包含 Dynamo 静态库；Helm Chart 为 EPP 创建 ConfigMap、Deployment、Service，并在 InferencePool 中使用 `endpointPickerRef` 指向 EPP Service。<br>4. **API 更新**：从之前的 `inference.networking.x‑k8s.io` 迁移到 `inference.networking.k8s.io`（v1），统一资源名称，避免旧 CRD 冲突。 |
| **性能** | - **路由决策**：在 Score 阶段一次性调用 Dynamo Router，返回 `worker_id`、`prefill_worker_id` 与 token 列表，避免后端再次进行 KV‑lookup，理论可显著降低调度延迟。<br>- **FFI 开销**：CGO 调用跨语言边界带来 ~µs 级额外开销；若大量并发请求，C‑Go 调度器可能成为瓶颈，需要在 buildx 中匹配宿主架构（Makefile 已自动检测）。<br>- **容器镜像体积**：新增 `ubuntu:24.04`、C++ runtime、libstdc++，镜像大小约 200‑300 MB（比原 distroless 更大），但仍可在 CI 中使用 `docker buildx --load` 本地缓存。 |
| **安全** | - **CGO 与本地库**：引入本地二进制（Rust）后，需审计库的内存安全（避免未初始化指针、溢出、未释放的 `malloc`）。<br>- **环境变量泄露**：`DYNAMO_*`、`HF_TOKEN` 等敏感信息通过容器 env 暴露，推荐使用 `Secret` 并以 `valueFrom.secretKeyRef` 方式注入。<br>- **Header 注入**：`x-worker-instance-id`、`x-prefiller-host-port` 直接由路由器返回，若攻击者能够操纵请求体（例如通过 SSE 注入），可能导致错误路由或信息泄露，需要在 Lua filter层进行白名单校验。<br>- **权限**：Helm Chart 中的 RBAC 仍然仅为 `pod-read`，若 EPP 需要访问其他资源（如 ConfigMaps），请适当扩展 `ClusterRole`。 |
| **可维护性** | - **代码组织**：插件代码分离至 `deploy/inference-gateway/epp/pkg/plugins/...`，但仍与主仓库耦合；未来可考虑独立模块或子仓库。<br>- **Makefile**：提供 `all`、`all-push`、`all-kind` 目标，已封装 Dynamo lib 编译、镜像构建与加载，降低手动步骤。<br>- **文档**：README 与 Helm `values.yaml` 已同步说明，新增 `HF_TOKEN`、`DYNAMO_KV_BLOCK_SIZE` 必须设置的提示。<br>- **兼容性**：GAIE 升级至 v1.2.1，旧版插件 (`dynamo-inject-workerid`) 已重写为 `RequestBodyMutator`，需确认已有自定义插件是否兼容。 |

**⚠️ 潜在风险**  
1. **跨平台构建失败**：CGO 需要与宿主平台的 `libdynamo_llm_capi.a` 匹配；在 CI 中若未提前执行 `make dynamo-lib`，镜像会缺失库导致容器启动报错。  
2. **运行时初始化错误**：`DYNAMO_KV_BLOCK_SIZE`、`DYNAMO_NAMESPACE` 等环境变量缺失或非法会在 `initFFI` 中 `panic`，导致整个 EPP Pod CrashLoopBackOff。  
3. **内存泄漏 / 双释放**：FFI 里 `dynamo_free_worker_selection_result` 只释放 `token_ids` 与 `annotated_json`，若 Rust 端返回异常指针或未释放内部结构，可能导致容器 OOM。  
4. **竞争条件**：`pipelineMutex` 只保护 `pipeline` 句柄，但 `callAddRequest` 以及 `callFreeRequestInternal` 在高并发下仍可能出现并发写入错误（若底层 Rust API 非线程安全）。  
5. **安全泄露**：`token_data` 通过 Base64 编码写入 Header，若 token 包含敏感信息（例如用户输入的敏感词），可能被后端日志泄露。  
6. **RBAC 不完整**：EPP 若在 future 需要读取模型 ConfigMaps，现有 `ClusterRole` 权限不足，导致 Pod 权限错误。  

**💡 关注建议**  

| 建议 | 说明 |
|------|------|
| **CI/CD 完整性** | 在 CI 中强制运行 `make dynamo-lib`、`make all-kind`，并在镜像构建完成后执行 `docker run --rm <image> sh -c "test -f /workspace/pkg/plugins/dynamo_kv_scorer/lib/libdynamo_llm_capi.a"` 进行验证。 |
| **多架构验证** | 使用 `docker buildx` 同时构建 `linux/amd64` 与 `linux/arm64`，确保 `libdynamo_llm_capi.a` 编译的

---

### feat: add kalman filter as load predictor (#5554)
**SHA**: `0d5c8df` | 🔗 [查看提交](https://github.com/ai-dynamo/dynamo/commit/0d5c8dfc4ee3bca75dbaba25fe5dfaca58e6eb97)

**🎯 变更类型**：功能增强  
**⚡ 重要程度**：🔴高  

**📋 变更摘要**  
1. 为 SLA 规划器新增 **Kalman 预测器**（基于 `filterpy`），可在低延迟、在线场景中提供更平滑的短期负载预测。  
2. 扩展默认配置、命令行参数及文档，以支持 Kalman 以及对所有预测器统一的 `log1p` 选项。  
3. 调整预测器实现（ARIMA、Prophet）以统一使用 `argparse.Namespace` 参数对象，提升配置一致性。  

**🎯 影响范围**  
- `components/src/dynamo/planner/defaults.py`（默认值）  
- `components/src/dynamo/planner/utils/load_predictor.py`（预测器实现）  
- `components/src/dynamo/planner/utils/planner_argparse.py`（CLI 参数）  
- `components/src/dynamo/planner/utils/planner_core.py`（预测器实例化）  
- `container/deps/requirements.txt`（新增 `filterpy` 依赖）  
- 文档与测试脚本等辅助文件  

**🔍 技术洞察**  

| 维度 | 影响说明 |
|------|----------|
| **架构影响** | - **可插拔预测器模型**：通过 `LOAD_PREDICTORS` 字典统一管理，新增 Kalman 后无需修改上层调度逻辑。<br>- **统一参数入口**：所有预测器现在接受 `argparse.Namespace`，统一了配置路径，减少了不同预测器构造函数签名的不一致，提升可维护性。<br>- **默认配置扩展**：在 `SLAPlannerDefaults` 中加入 Kalman 参数，保持与其它预测器对称。 |
| **性能影响** | - **KalmanFilter**：计算量极低（O(1)）且仅涉及矩阵乘法，适合频繁调用的 “observe‑1 → predict‑1” 场景，预计对 CPU/内存占用影响可忽略。<br>- **ARIMA/Prophet**：保持原有实现，仅在初始化阶段会受 `log1p` 选项影响；引入 `log1p` 可能降低数值范围，提升模型收敛速度。<br>- **依赖增长**：新增 `numpy`（已经是项目依赖）和 `filterpy`，会略增容器镜像体积与启动时间。 |
| **安全考虑** | - **第三方库**：`filterpy` 属于成熟的 BSD‑3‑Clause 项目，攻击面小，但仍需在 CI 中执行安全扫描（比如 `safety`、`bandit`）以防止潜在的 CVE。<br>- **输入验证**：Kalman 参数 (`q_level`, `q_trend`, `r`) 直接来自 CLI，若提供负数或非数值会导致 `numpy` 报错或数值不稳定。建议在 argparse 中加入 `type=float` + `choices`/`range` 检查。 |
| **可维护性** | - 代码路径统一（`args` 传递），降低了未来新增预测器的改动成本。<br>- 文档同步更新，帮助用户快速了解新特性。<br>- 通过 `LOAD_PREDICTORS` 自动映射，新增预测器仅需在字典中注册，无需改动调度核心。 |
| **兼容性** | - 老版脚本仍然使用 `--load-prediction-window-size`（已在 argparse 中保留），但新预测器不再使用该参数。<br>- `ConstantPredictor` 与 `ARIMAPredictor` 的构造签名已从 `window_size` 变为 `args`，若项目内部有自行实例化的旧代码，可能出现 `TypeError`。需要在项目内部或第三方集成处同步更新。 |

**⚠️ 潜在风险**  
1. **向后兼容性**：直接调用预测器构造函数（如在测试或自定义插件）仍可能使用旧签名，导致运行时错误。  
2. **参数不合理**：`Kalman` 的噪声矩阵 `Q`、测量噪声 `R` 若设得过小或过大，过滤器可能发散或过度平滑，产生不准确的预测。  
3. **数值稳定性**：在 `log1p` 模式下，`KalmanPredictor` 使用 `math.log1p` 进行转换，但预测结果再 `expm1` 时若出现负值会被强制 `max(0.0, …)`，可能隐藏潜在的负偏差。  
4. **依赖链**：`filterpy` 依赖 `numpy`，若容器镜像中使用的 `numpy` 版本与 `filterpy` 编译的二进制不兼容（尤其在 AMD/ARM 环境），可能出现导入错误。  
5. **并发安全**：`KalmanPredictor` 的内部状态 (`self._kf`) 没有显式的线程锁，若同一实例在多线程环境下并发调用 `add_data_point`/`predict_next`，可能产生竞争条件。  

**💡 关注建议**  
- **回退兼容层**：在 `load_predictor.py` 为每个预测器保留旧的构造函数包装（接受 `window_size` 等），在内部转为 `Namespace`，避免外部代码破坏。  
- **参数校验**：在 `planner_argparse.py` 为 Kalman 参数添加合理范围检查（如 `q_level > 0`, `r > 0`），并在 `KalmanPredictor.__init__` 中抛出明确异常。  
- **单元/集成测试**：新增针对 Kalman 的预测精度、收敛速度以及 `log1p` 开关的测试，覆盖最小点数、预测缓存逻辑和异常路径。  
- **监控与告警**：在运行时记录 Kalman 预测的 `self._kf.P`（协方差）以及预警若协方差异常膨胀，提示模型参数需要调优。  
- **安全审计**：将 `filterpy` 加入依赖审计流水线，定期检查 CVE 报告；同时在容器镜像构建阶段使用 `--no-cache-dir` 防止旧版本残留。  
- **文档与示例**：在官方文档中加入 Kalman 参数调优的实践案例（如 “快速响应 VS 稳定平滑” 的取值建议），帮助用户快速上手。  

通过上述措施，可在保持当前功能完整性的前提下，安全、平滑地引入 Kalman 预测器，提升 SLA 规划器在突发流量场景下的响应速度和预测准确度。

---

### feat: Support the reading of routing hints from the headers  (#5502)
**SHA**: `cb352d9` | 🔗 [查看提交](https://github.com/ai-dynamo/dynamo/commit/cb352d95a87b720759d1c948461eb5d8fc3a0f45)

**🎯 变更类型**：功能增强  

**⚡ 重要程度**：🔴 高  

**📋 变更摘要**  
- 在 OpenAI 兼容的 HTTP 接口（`/v1/completions`、`/v1/chat/completions`、`/v1/responses`）中加入对自定义路由 Hint（`x-worker-instance-id`、`x-prefill-instance-id`）的读取与解析。  
- 通过新函数 `apply_header_routing_overrides` 将这些 Header 覆盖写入请求体的 `nvext` 字段，从而影响后端实例/worker 的调度。  
- 同时在 `nvext.rs` 中新增常量、实现覆盖逻辑以及单元测试，保证行为可验证。  

**🎯 影响范围**  
- **核心模块**：`lib/llm/src/http/service/openai.rs`（所有 OpenAI 路由的请求处理入口）  
- **协议层**：`lib/llm/src/protocols/openai/nvext.rs`（新增 Header 解析函数及相关常量）  
- **测试**：`nvext.rs` 中的单元测试  
- **构建**：`.gitignore` 轻微扩展（不影响功能）  

---

### 🔍 技术洞察  

| 维度 | 影响描述 |
|------|----------|
| **架构影响** | - 引入 **Header‑Driven 路由**，使调度层能够根据请求方显式指定 *backend_instance_id / decode_worker_id / prefill_worker_id*。<br>- 该逻辑位于 **服务入口（axum handler）**，在生成 `Context` 前即完成覆盖，保持了后续流水线（aggregator、router 等）不需要感知 Header。<br>- 对现有 `NvExtProvider` 接口无侵入，只是对已有 `nvext` 做一次可选的“覆盖”。 |
| **性能影响** | - 解析两个 Header 并尝试 `u64` 转换，开销极小（微秒级），对总体吞吐几乎无影响。<br>- 若 Header 存在并成功解析，会触发一次 `NvExt` `unwrap_or_default` 创建，仍在常数时间。<br>- 可能导致 **调度路径改变**（请求落到不同 worker），间接影响响应时延，但这属于业务层面而非代码性能瓶颈。 |
| **安全考虑** | - **信任边界**：如果服务面向公网或未做内部鉴权，恶意客户端可自行指定 worker ID，可能导致：<br> • 资源划分被绕过（请求被强行投递到高负载或受限的实例）。<br> • 信息泄露或侧信道攻击（通过观察特定 worker 的行为推断系统内部）。<br>- 当前实现 **不做校验**，仅在 Header 能解析为 `u64` 时直接写入 `nvext`。<br>- 对于 **内部调用**（如由 orchestrator、proxy）使用该 Header 是合理的，但需配合网络隔离或鉴权机制防止外部滥用。 |
| **可维护性** | - 新增的 `apply_header_routing_overrides` 被放在 `nvext.rs`，职责单一，易于单元测试和后续扩展。<br>- 通过 `unwrap_or_default` 保证在没有 Header 时保持原始 `nvext`，不会破坏向后兼容。<br>- 代码风格与项目现有的 Builder/Validate 体系保持一致。 |

---

**⚠️ 潜在风险**  

1. **未经授权的 Header 注入**：外部用户可能伪造 Header，强制请求落到特定 worker，导致负载不均或触发安全策略。  
2. **Header 解析错误导致隐藏异常**：当前在解析失败（非数字、溢出）时会直接 `None`，可能掩盖错误信息，调试时不易定位问题。  
3. **与现有调度策略冲突**：如果调度系统已有更复杂的路由规则（如负载感知、QoS），Header 覆盖可能绕过这些规则，引起不可预期的调度行为。  
4. **文档/客户端同步**：如果客户端未同步新增 Header（或误用），可能产生请求被错误路由的现象，需在文档中明确说明。  

---

**💡 关注建议**  

| 建议 | 说明 |
|------|------|
| **访问控制** | 在进入 `apply_header_routing_overrides` 前加入鉴权检查，仅对受信任的内部 IP/服务开放 Header 解析。 |
| **日志审计** | 为每次 Header 覆盖写入日志（包括请求 ID、原始 `nvext` 与覆盖后值），便于审计与排障。 |
| **阈值校验** | 对 `backend_instance_id`、`decode_worker_id`、`prefill_worker_id` 添加范围或存在性校验（例如只能是已注册的 worker ID），防止无效或恶意数值进入调度层。 |
| **监控指标** | 新增监控 “header_routing_override_applied_total” 计数器，观察实际使用情况与潜在异常激增。 |
| **文档更新** | 在 API 文档中明确 `x-worker-instance-id` 与 `x-prefill-instance-id` 的用途、适用场景、权限要求以及取值范围。 |
| **回退策略** | 若业务侧发现 Header 导致不稳定，可通过配置关闭 `apply_header_routing_overrides`（例如环境变量 `DYNAMO_DISABLE_HEADER_ROUTING=1`），保持向后兼容。 |
| **更严谨的错误处理** | 将 `parse::<u64>()` 失败的情况记录为 debug/trace 级别日志，帮助调试错误 Header。 |

---

**总体结论**  
此提交为 **功能增强**，提供了在 HTTP 层通过 Header 明确指定后端实例/worker 的能力，提升了调度灵活性，尤其适用于内部编排或实验性路由需求。实现简洁、对现有业务兼容性好，但在安全与运维层面需要配合鉴权、审计与监控，以防止 Header 被滥用导致资源失衡或潜在攻击。建议在生产环境开启前完成上述安全防护措施，并在文档中做好使用说明。

---

#### 🟡 中重要度变更 (5)

### test: Rewrite Request Migration Tests and Add Disagg Scenarios (#5448)
**SHA**: `cdcf6d0` | 🔗 [查看提交](https://github.com/ai-dynamo/dynamo/commit/cdcf6d0a532a0b0f44b4b3c6e440ef0e0d9bc108)

**🛠️ 变更类型**：功能增强 / 测试扩展  
**⚡ 重要程度**：🟡 中  

### 1. 核心改动概览
| 文件 | 主要改动 | 目的 |
|------|----------|------|
| `tests/fault_tolerance/migration/*` | ① 统一并重写 **SGLang、TRT‑LLM、vLLM** 三套迁移测试<br>② 引入 **聚合 (aggregated)**、**预填 (prefill)**、**KV‑transfer**、**解码 (decode)** 四种场景<br>③ 为所有测试加入 `migration_limit`、`immediate_kill`、`request_api`、`stream` 参数化，覆盖 **migration‑enabled/disabled**、**worker‑failure / graceful‑shutdown**、**chat‑vs‑completion**、**流式 vs 非流式** 四维组合 | 让迁移容错的覆盖面更完整，能够在 CI 中捕获更多边界错误 |
| `tests/fault_tolerance/migration/utils.py` | - 新增 **JSON SSE 解析**、**时间戳记录**、**统一的 `wait_for_response`/`validate_response`**<br>- `DynamoFrontendProcess` 支持 `--enforce-disagg` 参数<br>- `DynamoWorkerProcess` 重构：<br> • 支持 `disagg_mode`（`prefill` / `decode` / `None`）<br> • 动态分配 `system_port`、`disaggregation‑bootstrap-port`、`VLLM_NIXL_SIDE_CHANNEL_PORT` 等<br> • 根据模式自动添加相应 CLI 参数和环境变量<br>- 新增公共函数 **`run_migration_test`**，封装请求发送、worker 识别、kill 与验证的完整流程 | 为后面的四类场景提供统一实现，避免重复代码，同时把 **SSE 流式解析**抽离出来，提升可读性和可维护性 |
| 测试文件 (`test_sglang.py`, `test_trtllm.py`, `test_vllm.py`) | - 通过 `@pytest.mark.parametrize` 引入多维组合<br>- 对 **prefill**、**kv‑transfer**、**decode** 场景逐一实现（部分使用 `xfail`/`skip` 标记）<br>- 使用新的 `run_migration_test` 替代原来的手工步骤 | 让每个后端的迁移逻辑在不同运行模式下都得到验证 |

### 2. 影响范围
| 受影响模块 | 具体影响 |
|-----------|----------|
| **测试框架** | 大幅增加测试数量（原 4 项 → 12 项），单次 CI 运行时间约从 5 min 上升到 **≈12 min**（取决于是否开启 `stream`）。 |
| **`tests.utils.managed_process`** | 新增 `terminate_process_tree` 的直接调用，保留旧实现但已在 `utils.py` 中使用。 |
| **前端启动脚本** (`DynamoFrontendProcess`) | 接受 `--enforce-disagg`，如果 CI/本地脚本未传递此 flag，仍然可以正常工作（默认聚合模式）。 |
| **后端进程启动** (`DynamoWorkerProcess`) | 现在会根据 `disagg_mode` 自动追加 `--disaggregation‑mode`、`--host 0.0.0.0`、`--disaggregation‑transfer‑backend nixl` 等参数，且在 **prefill** 模式下强制 `migration_limit=0`。 |
| **日志/健康检查** | 每个 worker 只在需要时（decode/aggregated）添加模型 API 检查；prefill 只做系统端口健康检查。 |
| **公共工具函数** (`run_migration_test`, `start_*_completion_request`) | 产生的 `response_list` 已经是 **(content|Exception, timestamp)**，旧版直接使用 `requests.Response` 的代码已被全部替换。 |

### 3. 开发者/使用者建议
1. **CI 资源评估**  
   - 当前测试组合会显著放大资源消耗，建议在 CI 中 **分块执行**（如 `-m sglang`、`-m trtllm`、`-m vllm`），或通过 `pytest -k` 只跑感兴趣的子集。  
2. **保持向后兼容**  
   - 已有的外部脚本如果直接调用 `DynamoFrontendProcess(request)`，仍可运行（默认不强制 `enforce_disagg`）。若需要显式测试 `disagg`，请添加 `enforce_disagg=True`。  
3. **端口分配与清理**  
   - `DynamoWorkerProcess` 现在使用 `allocate_port(9100)` 自动分配，确保在并行测试时不会冲突；若出现 “端口被占用” 错误，请检查是否有残留的 `python3` 进程未正常退出。  
4. **日志验证**  
   - `verify_migration_occurred` 会在日志中搜索 `"Stream disconnected... recreating stream..."`，若日志输出被自定义的 log‑level 或 `DYN_LOG` 覆盖，可能导致误报。请保持 `debug` 级别或手动打开对应日志。  
5. **SSE 解析**  
   - 新的 SSE 解析函数对 `event: error` 和 `[DONE]` 做了显式过滤，理论上不会误判。若后端在 **非标准 SSE**（如自定义字段）上出现异常，请检查 `tests/fault_tolerance/migration/utils.py` 中的 `_parse_*_sse_content`，必要时补充字段处理。  
6. **迁移限制 (`migration_limit`)**  
   - 0 → **migration disabled**；正数 → **迁移可用**。在 **prefill** 场景中会自动覆盖为 0，防止 KV‑cache 迁移不被后端支持导致崩溃。若有其他后端（比如新加入的模型）需要支持预填迁移，请在 `DynamoWorkerProcess` 中移除该强制覆盖逻辑。  
7. **文档与示例**  
   - 建议在仓库根目录的 `docs/testing.md` 中添加一段 **“如何使用新迁移测试”**，列出常用的 `pytest -m` 标记组合以及 `--enforce-disagg` 参数的说明。  
8. **后续扩展**  
   - `run_migration_test` 已经将 **请求发送 → worker 选取 → kill → 验证** 统一，后续如果添加 **TensorRT‑LLM‑v2**、**Mistral‑V** 等后端，只需要实现对应的 `DynamoWorkerProcess` 参数即可复用。  

---  

**总结**：此次提交把原来的单一迁移测试（仅聚合、仅 worker‑failure）扩展为四种运行模式，加入了 **参数化**、**SSE 解析** 与 **统一验证函数**，大幅提升迁移容错的覆盖度。但随之带来了测试时长和资源需求的提升，请在 CI 中适当拆分或使用 `-k`/`-m` 过滤，以保持稳定的回归速度。若后续需要在其他后端启用 **prefill** 或 **KV‑transfer**，只要在 `DynamoWorkerProcess` 中添加对应 CLI 标记即可。祝调试顺利 🚀.

---

### fix: add pre-commit cache dir and improve dockerignore (#5588)
**SHA**: `edf847e` | 🔗 [查看提交](https://github.com/ai-dynamo/dynamo/commit/edf847e5e176eed72f284afff85af2102e20c8f8)

**🎯 变更类型**：Bug 修复 / 小幅功能增强  
**⚡ 重要程度**：🟡 中  

**📋 变更摘要**  
1. 在 `.dockerignore` 中加入 `**/__pycache__`、`**/*.pyc`，防止编译后的 Python 文件进入镜像构建上下文，进一步减小镜像体积。  
2. `container/dev/Dockerfile.dev` 为每个开发容器在用户主目录下创建 `~/.cache/pre-commit` 并赋予组写权限，避免首次运行 `pre‑commit` 时因缓存目录缺失导致的重复下载。  

**🎯 影响范围**  
- `Dockerfile.dev`（开发镜像的构建与运行）  
- `.dockerignore`（所有 Docker 构建会受益）  
- CI / 本地 `pre‑commit` 工作流（缓存位置已预置）  

**💡 关注建议**  
1. **权限**：仅 `chmod g+w`，若容器内运行用户不在同一组，可能仍缺写权限。建议在创建目录后使用 `chown $USERNAME:$USERNAME /home/$USERNAME/.cache/pre-commit`，或直接 `chmod 777`（视安全要求而定）。  
2. **缓存持久化**：当前仅在容器内部创建目录，若容器每次重新创建则缓存会失效。考虑在 `docker compose` 或 `docker run` 时挂载宿主机的缓存卷，以真正加速 `pre‑commit`。  
3. **`.dockerignore` 冲突**：已经在文件底部单独排除了 `__pycache__/` 与 `*.pyc`，新增的全局 `**/__pycache__`、`**/*.pyc` 可能导致重复条目或意外排除某些子模块的源码（如需要在运行时读取 `.pyc`）。建议统一保留一套全局规则，去除重复的局部规则。  
4. **构建验证**：请在 CI 中加入一次完整的 `docker build -f container/dev/Dockerfile.dev .`，确保新增目录权限正确、镜像构建成功且 `.dockerignore` 不会误删必需文件。  

总体来看，此次改动对开发体验提升明显，主要风险在权限与缓存持久化上，建议按上述检查后再合并。

---

### fix: TestProfileSlaAiconfigurator should use new framework versions (#5562)
**SHA**: `e861f61` | 🔗 [查看提交](https://github.com/ai-dynamo/dynamo/commit/e861f619586f8264ca2620305fbc7a3e3f68924a)

**🎯 变更类型**：Bug 修复  
**⚡ 重要程度**：🟡 中  

**📋 变更摘要**  
本次提交仅修改了 `tests/profiler/test_profile_sla_aiconfigurator.py` 中的参数化数据，将几个 AI 框架的版本号从旧版本（`0.20.0`、`0.11.0`、`0.5.1.post1`）更新为最新可用的版本（`1.2.0rc5`、`0.12.0`、`0.5.6.post2`），以保证测试用例能够在新版依赖上通过。

**🎯 影响范围**  
- **核心模块**：`profiler`（尤其是 `SlaAiconfigurator` 相关的版本检测逻辑）  
- **测试套件**：所有依赖该参数化组的单元测试  

**💡 关注建议**  
1. **版本解析兼容性**：确认 `SlaAiconfigurator` 在解析 `rc`、`post` 等后缀时能够正确比较版本，否则可能导致新版本仍被误判为不兼容。  
2. **依赖约束**：如果项目的 `pyproject.toml` 或 `requirements.txt` 中对这些框架设置了严格的版本上限，需要同步更新，以防 CI 环境因版本冲突而报错。  
3. **回归测试**：在本地和 CI 中运行全部测试，尤其是涉及 AI 框架选择的路径，确保新版本不会触发隐藏的兼容性问题。  
4. **文档同步**：若 README 或部署脚本中列举了受支持的框架版本，建议同步更新相应说明，避免使用者误认为旧版本仍受支持。  

总体来看，此次改动仅涉及测试数据的更新，对业务代码无直接影响，但需要留意版本比较实现的稳健性，以防后续升级时出现相同的检测失误。

---

### ci: split vllm venv COPY into parallel layers for faster pulls (#5494)
**SHA**: `b31b5b5` | 🔗 [查看提交](https://github.com/ai-dynamo/dynamo/commit/b31b5b5663f7712d07df656b0b01510f1f10fb55)

**🎯 变更类型**：功能增强（CI / Docker 镜像构建性能）  
**⚡ 重要程度**：🟡 中  

**📋 变更摘要**  
- 将 `container/Dockerfile.vllm` 中一次性复制完整 Python 虚拟环境的指令拆分为 6 条针对大体量包（nvidia、flashinfer_jit_cache、torch、vllm、triton、flashinfer_cubin）的独立 `COPY`，其余文件统一复制。  
- 新增 `ENV PYTHON_VERSION` 传递，使层路径可由构建参数决定。  
- `.dockerignore` 与 `container/dev` 脚本同步更新，排除常见的 IDE、构建、缓存等文件，提升本地 `docker build` 的上下文传输速度。  

**🎯 影响范围**  
- **Dockerfile.vllm**（镜像构建层）  
- **container/dev/50‑framework‑paths.sh**（运行时路径配置）  
- **container/dev/Dockerfile.dev**（开发镜像）  
- **.dockerignore**（构建上下文）  

**💡 关注建议**  
1. **层缓存有效性**：拆分后每个大包会单独形成缓存层，可并行拉取并在后续更新单独失效。确认 `SITE_PACKAGES` 计算的 `${VIRTUAL_ENV}` 在 `framework` 镜像中始终指向相同路径；若路径变化，将导致缓存失效。  
2. **PYTHON_VERSION 环境变量**：现在在 Dockerfile 中通过 `ENV` 暴露，外部 CI 必须显式传入 `--build-arg PYTHON_VERSION=3.12`（或对应版本），否则默认值会回退到 `dev` 脚本的警告逻辑。建议在 CI 脚本中统一声明该变量，避免隐式默认。  
3. **排除列表**：`.dockerignore` 新增了大量 IDE、缓存目录。若仓库中已有自定义忽略规则，需确认不产生重复或冲突；尤其是 `.venv-docs` 行保持在末尾，防止误删。  
4. **兼容性检查**：拆分复制后，`COPY --exclude` 中的通配符使用了 `lib/python*/site-packages/...`，确保在不同 Python 小版本（3.10/3.11）下仍匹配正确路径。建议在 CI 中加入一次性 `docker build --no-cache` 的完整构建测试。  
5. **文档更新**：README/CONTRIBUTING 中关于镜像构建的 `--build-arg PYTHON_VERSION` 说明需要同步更新，防止使用者遗漏。  

综上，此改动通过层拆分显著缩短镜像拉取与构建时间，对 CI 与本地开发均有正面效应。重点确保 `PYTHON_VERSION` 正确传递并验证 `COPY --exclude` 的通配匹配，以防意外遗漏关键包。

---

### fix: local-dev needs proper so files for sudo (#5556)
**SHA**: `f438aee` | 🔗 [查看提交](https://github.com/ai-dynamo/dynamo/commit/f438aee258aedff745c0a7939d51a254b0de6eb0)

**🎯 变更类型**：Bug 修复  
**⚡ 重要程度**：🟡 中  

**📋 变更摘要**  
本次提交在 `container/dev/Dockerfile.dev` 中新增一行 `COPY --from=dynamo_tools /usr/libexec/ /usr/libexec/`，修复本地开发镜像缺少 `libexec` 目录导致需要 `sudo` 执行的工具找不到的问题。

**🎯 影响范围**  
- `container/dev` 构建流程（本地开发镜像）  
- 运行 `docker-compose up` 时的工具链可用性（如 `sudo`、`lshw`、`iptables` 等依赖 `libexec` 的二进制）  

**💡 关注建议**  
1. **镜像体积**：`/usr/libexec` 可能包含大量辅助工具，建议在 CI 中检查生成镜像大小，防止不必要的膨胀。  
2. **权限检查**：复制后确认文件权限是否保持原有的 `root:root` 与可执行位，若有变更需在后续 `RUN chmod` 中恢复。  
3. **跨平台兼容**：若某些工具在 Alpine/Ubuntu 基础镜像中路径不同，考虑使用更通用的 `--chown` 或 `RUN rm -rf` 清理无用文件。  
4. **回归测试**：新增一个本地开发容器的 Smoke Test，验证 `sudo` 能正常调用而不提示 “command not found”。  
5. **文档更新**：在 `README` 或 `container/dev/README.md` 中说明已修复的 `sudo` 依赖问题，提醒新用户重新构建镜像。  

总体而言，此改动解决了本地开发环境的实际使用痛点，影响范围局限于开发镜像，风险较低，只需关注镜像体积与权限一致性。

---

#### 🟢 低重要度变更 (8)

### chore: Bump TRTLLM to 1.2.0rc6.post2 (#5580)
**SHA**: `64ba7dd` | 🔗 [查看提交](https://github.com/ai-dynamo/dynamo/commit/64ba7dd068a88f244eff5dd6578191447e7894e4)

**🎯 变更类型**：配置调整  
**⚡ 重要程度**：🟢低  
**📋 摘要**：将 TensorRT‑LLM 版本升级至 1.2.0rc6.post2，并同步更新 pyproject、Dockerfile、默认构建参数、依赖文件及文档中的对应引用。

---

### docs: update vLLM flag for local dev without NATS (#5587)
**SHA**: `a7bc38d` | 🔗 [查看提交](https://github.com/ai-dynamo/dynamo/commit/a7bc38d7c5e31807fab0bc45613bed9f83f2ea67)

**🎯 变更类型**：文档更新  
**⚡ 重要程度**：🟢低  
**📋 摘要**：将本地开发使用 vLLM 时的说明从关闭前缀缓存改为禁用 KV 事件发布（`--kv-events-config '{"enable_kv_cache_events": false}'`），并相应更新 CONTRIBUTING、README 与支持矩阵中的链接和表述。

---

### chore: default python hash seed to zero always for the engines (#5583)
**SHA**: `0316216` | 🔗 [查看提交](https://github.com/ai-dynamo/dynamo/commit/03162161e46fbb544e6020c9b252c6371bbed8b4)

**🎯 变更类型**：配置调整  
**⚡ 重要程度**：🟢 低  
**📋 摘要**：在多个 `__main__.py` 与示例 worker 脚本开头新增对 `PYTHONHASHSEED` 环境变量的默认设置，若未定义则统一设为 `"0"`，确保 Python 哈希行为一致。

---

### chore: update nixl to 0.9.0 (#5528)
**SHA**: `6dba119` | 🔗 [查看提交](https://github.com/ai-dynamo/dynamo/commit/6dba119d7a40e32e3c36c8dcf373fdc2a0e7ed77)

**🎯 变更类型**：配置调整  
**⚡ 重要程度**：🟢低  
**📋 摘要**：将 nixl 依赖升级至 0.9.0，更新 Cargo.lock、Cargo.toml、构建脚本、文档及相关版本约束。

---

### chore: added forced audit logging (#5552)
**SHA**: `1032076` | 🔗 [查看提交](https://github.com/ai-dynamo/dynamo/commit/1032076de5b244c1dd75164576da5b728a76fd15)

**🎯 变更类型**：配置调整  
**⚡ 重要程度**：🟢 低  
**📋 摘要**：新增 `DYN_AUDIT_FORCE_LOGGING` 环境变量并在 `AuditPolicy` 中加入 `force_logging` 字段；`create_handle` 逻辑改为在强制日志开启时忽略 `store` 标记；同时新增单元测试验证强制日志行为。

---

### docs: quick fixes for README.md  (#5582)
**SHA**: `38fbb1d` | 🔗 [查看提交](https://github.com/ai-dynamo/dynamo/commit/38fbb1db448926f3185b7c1b0f09bd786c040983)

**🎯 变更类型**：文档更新  
**⚡ 重要程度**：🟢低  
**📋 摘要**：对 README.md 进行排版、链接、图片和章节结构的整理，新增快速入门、贡献指南、部署与 benchmark 信息，更新徽章与链接，使文档更易读、内容更完整。

---

### chore: use Rc in RadixTree BFS dumpt (#5574)
**SHA**: `8f1ae2c` | 🔗 [查看提交](https://github.com/ai-dynamo/dynamo/commit/8f1ae2c592f163392592d8511b6c5cfe9e6b304e)

**🎯 变更类型**：代码重构  
**⚡ 重要程度**：🟢低  
**📋 摘要**：在 RadixTree 的 BFS dump 中使用 `Rc` 包装 `parent_hashes` `HashMap`，避免子节点入队时的重复克隆，降低内存开销并提升性能。

---

### docs: improve the contributor experience of CONTRIBUTING.md (#5507)
**SHA**: `fb3a77b` | 🔗 [查看提交](https://github.com/ai-dynamo/dynamo/commit/fb3a77b7b7642bc784cc8a7d6ac2aa7555f4117e)

**变更类型**：文档更新  
**重要程度**：🟢低  
**摘要**：更新 ISSUE_TEMPLATE 链接，全面重写 CONTRIBUTING.md，加入新手指南、流程图、社区统计等；在 README 添加贡献指引与社区徽章，提升新人上手和贡献体验。

---

