# 每日更新报告（2026-01-22）

## ai-dynamo/dynamo

| 提交时间 | 作者 | 提交信息 |
|----------|------|----------|
| 2026-01-22 20:43:37 | Pavithra Vijayakrishnan | ci: Add builds to release (#5557) |
| 2026-01-22 14:56:37 | Pavithra Vijayakrishnan | build: Pin dockedr buildkit version (#5559) |
| 2026-01-22 14:24:55 | dagil-nvidia | docs: update roadmap link to H1 '26 timeline (#5508) |
| 2026-01-22 09:48:31 | Pavithra Vijayakrishnan | ci: automate release (#5538) |
| 2026-01-22 09:43:14 | Hongkuan Zhou | feat: predict log1p(y) instead of y in load predictor if ARIMA collapses (#5545) |
| 2026-01-22 09:05:03 | Alec | ci: exclude dev container from CI triggers (#5495) |
| 2026-01-22 08:43:02 | Graham King | chore: Remove binding OAIChatPreprocessor (#5516) |
| 2026-01-22 06:25:54 | Ayush Agarwal | feat: v0 diffusion handler support (#5533) |
| 2026-01-22 05:29:09 | Olga Andreeva | test: Fixing kvbm tests/ adding concurrency test (#5474) |
| 2026-01-22 05:26:06 | Shang Wang | chore: [vLLM] Update the import paths from `vllm.entrypoints.openai` to align with vLLM latest `main` (#5447) |
| 2026-01-22 03:11:07 | Biswa Panda | chore: reduce verbosity during dynamo start (#5518) |
| 2026-01-22 02:55:03 | Hongkuan Zhou | feat: warmup dataset for planner load predictor (#5529) |
| 2026-01-22 02:46:18 | milesial | feat: remove ser/deser in gather_multi_model_data (#5485) |
| 2026-01-22 01:16:52 | Ryan Olson | feat: add PositionalLineageHash for hierarchical block tracking (DIS-1307) (#5522) |

### 📊 统计摘要
> 本日共 14 个提交 | 🔴高 6 | 🟡中 1 | 🟢低 7
## 📋 目录

- [ai-dynamo/dynamo](#ai-dynamo-dynamo)
  - [📊 统计摘要](#-统计摘要)
  - [🔴 高重要度变更 (6)](#-🔴-高重要度变更-6)
    - [feat: predict log1p(y) instead of y in load predictor if ...](#4557b6d)
    - [feat: v0 diffusion handler support (#5533)](#91ddf41)
    - [test: Fixing kvbm tests/ adding concurrency test (#5474)](#224f63f)
    - [feat: warmup dataset for planner load predictor (#5529)](#b0959cf)
    - [feat: remove ser/deser in gather_multi_model_data (#5485)](#0f137de)
    - [feat: add PositionalLineageHash for hierarchical block tr...](#34e5822)
  - [🟡 中重要度变更 (1)](#-🟡-中重要度变更-1)
    - [ci: Add builds to release (#5557)](#0c1467c)
  - [🟢 低重要度变更 (7)](#-🟢-低重要度变更-7)
    - [build: Pin dockedr buildkit version (#5559)](#83e59d3)
    - [docs: update roadmap link to H1 '26 timeline (#5508)](#83c1370)
    - [ci: automate release (#5538)](#f877096)
    - [ci: exclude dev container from CI triggers (#5495)](#228c687)
    - [chore: Remove binding OAIChatPreprocessor (#5516)](#ca31b3a)
    - [chore: [vLLM] Update the import paths from `vllm.entrypoi...](#199d11f)
    - [chore: reduce verbosity during dynamo start (#5518)](#e2b1251)
#### 🔴 高重要度变更 (6)

### feat: predict log1p(y) instead of y in load predictor if ARIMA collapses (#5545)
**SHA**: `4557b6d` | 🔗 [查看提交](https://github.com/ai-dynamo/dynamo/commit/4557b6df5eae3c843b0885ed1fdc3d5ae7be3aac)

**🎯 变更类型**：功能增强  
**⚡ 重要程度**：🔴高  

**📋 变更摘要**  
- 在 `ARIMAPredictor` 中加入对原始数值的额外缓存，并在模型出现 `(0, d, 0)` 退化时自动切换到 `log1p(y)` 空间进行拟合与预测。  
- 引入 `Mode` 枚举、统一的日志配置以及更细粒度的警告过滤，提升预测器的鲁棒性和可观测性。  
- 相应地调整了测试标记，使预合并测试更明确。  

**🎯 影响范围**  
- `components/src/dynamo/planner/utils/load_predictor.py`（核心预测逻辑）  
- `dynamo.runtime.logging`（日志配置入口）  
- 受 `Planner`、`ReplicaCalculation` 等使用 `ARIMAPredictor` 的模块间接影响  

**🔍 技术洞察**  
- **架构影响**：  
  - 增加了 `Mode` 枚举与两套缓存（`_raw_buffer`、`data_buffer`），实现了“原始‑日志”双模态的内部切换，保持了对外 API 不变。  
  - 通过 `configure_dynamo_logging()` 统一日志设置，避免了在库内部自行创建 logger 导致的全局日志噪声。  

- **性能影响**：  
  - 正常情况下仍使用增量更新，保持 `O(1)` 更新成本。  
  - 在检测到模型退化并切换到 `log1p` 空间时，会额外执行一次 `auto_arima` 拟合，成本与一次完整拟合相当，但仅在少数异常时间序列触发。  
  - 维护额外的 `_raw_buffer` 会略增内存占用（窗口大小上限保持不变），对整体性能影响可忽略。  

- **安全考虑**：  
  - 只对非负数使用 `log1p`，通过 `max(0.0, ...)` 防止负数导致 `math.log1p` 抛异常。  
  - 过滤了 `FutureWarning`（特别是 `force_all_finite`），降低因外部库升级产生的意外中断。  
  - 未引入网络、文件系统或权限相关操作，安全风险基本为零。  

**⚠️ 潜在风险**  
1. **缓存不一致**：`_raw_buffer` 与 `data_buffer` 的同步逻辑若出现错误，可能导致预测值与实际历史不匹配。  
2. **退化检测误判**：仅依据 `order = (0, *, 0)` 判断退化，某些非退化模型也可能满足该模式，导致不必要的 `log1p` 切换并影响预测精度。  
3. **额外模型拟合成本**：在极端频繁触发退化检测的场景下，可能出现短时间内多次完整 `auto_arima` 拟合，增加 CPU 负载。  
4. **日志配置冲突**：全局调用 `configure_dynamo_logging()` 可能覆盖外部应用的日志配置，需确认不会破坏已有日志体系。  

**💡 关注建议**  
- 为 `log1p` 退化路径补充专门的单元测试（构造使 `auto_arima` 产生 `(0,d,0)` 的序列），确保切换逻辑与结果的正确性。  
- 在 `add_data_point` 与 `predict_next` 中加入断言或日志，监控 `_raw_buffer` 与 `data_buffer` 长度始终一致，防止同步错误。  
- 考虑将退化检测阈值或判断规则做成可配置项，便于在不同业务场景下微调。  
- 在项目文档中明确说明 `ARIMAPredictor` 现在会在特定情况下自动对数化处理，提醒使用者对预测值的解释进行相应调整。  
- 验证 `configure_dynamo_logging()` 对上游应用的日志行为是否产生副作用，必要时改为在库内部使用专用 logger 名称而非全局根 logger。

---

### feat: v0 diffusion handler support (#5533)
**SHA**: `91ddf41` | 🔗 [查看提交](https://github.com/ai-dynamo/dynamo/commit/91ddf4189b6c88963f57b50b416397da6759c511)

**🎯 变更类型**：功能增强  

**⚡ 重要程度**：🔴高  

**📋 变更摘要**：  
本次提交为 Dynamo‑SGLang 后端新增 **Diffusion Language Model（扩散模型）** 的支持。通过在 `DynamoArgs` 中加入 `diffusion_worker` 标识、在启动流程中自动检测 `dllm_algorithm`、实现 `DiffusionWorkerHandler`（继承自现有 DecodeWorker），并在 `main.py` 中完成对应的初始化、注册、健康检查及度量收集。同时补全了文档、示例脚本及导出路径的注册。

**🎯 影响范围**：  
- `components/src/dynamo/sglang/args.py`（参数模型）  
- `components/src/dynamo/sglang/main.py`（启动分支）  
- `components/src/dynamo/sglang/request_handlers/*`（新增 DiffusionHandler、导入更新）  
- `docs/backends/sglang/diffusion-lm.md`、`docs/hidden_toctree.rst`（文档）  
- `examples/backends/sglang/launch/diffusion_llada.sh`（示例脚本）  

---

### 🔍 技术洞察  

| 维度 | 影响分析 |
|------|----------|
| **架构影响** | - 在 Dynamo‑SGLang 的 **worker 类型** 中加入了 **Diffusion**，形成第三类 LLM worker（除 Decode/Prefill 外）。<br>- `DiffusionWorkerHandler` 复用 `DecodeWorkerHandler` 的大部分逻辑，仅在 `generate` 中使用 `engine.async_generate`，保持与现有工作流的一致性。<br>- `init_diffusion` 与 `init_prefill`/`init_embedding` 对称，统一了度量、健康检查、readiness‑gate 的处理，保持架构统一性。<br>- 通过 `server_args.dllm_algorithm` 自动触发 `diffusion_worker`，避免用户显式开启，降低误操作概率。 |
| **性能影响** | - **额外的 Streaming**：Diffusion 生成需要多轮迭代（低/高置信度 refinements），可能比一次性 **prefill** 更占用 CPU/GPU 计算时间和内存。<br>- **度量收集**：新增 `setup_sgl_metrics` 调用，与其他 worker 共享同一度量体系，略增 CPU 开销。<br>- **非 Leader 节点**：在多节点场景下仍会执行 `_handle_non_leader_node`，但不启动服务，基本不影响整体吞吐。<br>- **环境变量** `SGLANG_BLOCK_NONZERO_RANK_CHILDREN=0` 防止非 leader 阻塞，提升启动并行度。 |
| **安全考虑** | - 新增 `--dllm-algorithm`、`--dllm-algorithm-config` 参数，若配置文件可被外部写入，可能导致 **代码注入** 或 **模型行为异常**（例如调用自定义 Python 脚本），需要在入口层做路径白名单或签名校验。<br>- `DiffusionWorkerHandler` 继承自 `DecodeWorkerHandler`，保持原有鉴权、速率限制等机制，未引入新漏洞。 |
| **可维护性** | - 代码结构保持 **“handler = DiffusionWorkerHandler”** 与其他 handler 类似，便于统一审计与迭代。<br>- 文档和示例脚本同步更新，降低学习成本。<br>- 仍缺少单元/集成测试覆盖，后续需要补全。 |

---

### ⚠️ 潜在风险  

1. **错误的自动检测**：`diffusion_worker = server_args.dllm_algorithm is not None` 在未传递算法但误留旧配置的情况下可能误判为 diffusion worker，导致服务启动失败或功能异常。  
2. **配置文件安全**：`--dllm-algorithm-config` 若指向不受信任的文件，可能在 SGLang 引擎内部执行任意代码。  
3. **资源竞抢**：Diffusion 生成往往消耗更大的显存和计算资源，与同节点的 Prefill/Embedding worker 竞争，可能触发 OOM。  
4. **兼容性**：现有的客户端（OpenAI‑compatible）仍假设返回 token 序列，Diffusion 的 **迭代 refinement** 可能在 token 粒度上与预期不完全一致，导致上层应用出现异常。  
5. **监控缺失**：虽然复用了 `setup_sgl_metrics`，但未专门记录 diffusion‑specific 指标（如迭代次数、置信度阈值），难以定位性能瓶颈。  

---

### 💡 关注建议  

| 对象 | 建议 |
|------|------|
| **开发者** | - 在 `main.py` 中加入 `assert server_args.dllm_algorithm is not None` 的显式检查，防止误判。<br>- 为 `dllm_algorithm_config` 添加路径合法性校验（只能在预定义目录或签名文件）。<br>- 编写 **Diffusion** 专属的单元/集成测试，覆盖多轮生成、异常配置、非 leader 行为。<br>- 在度量系统中补充 `diffusion_iteration_count`、`diffusion_confidence_stats` 等自定义指标。 |
| **运维/用户** | - 部署前确认显存充足（推荐在单独节点运行 diffusion worker），或通过 `--tp-size` 控制并行度。<br>- 使用提供的 `diffusion_llada.sh` 脚本时，务必通过环境变量显式指定 `DLLM_ALGORITHM`，避免默认值导致不可预期行为。<br>- 监控 `metrics` 中的 **error_rate** 与 **latency**，若出现异常波动，检查是否因 diffusion 迭代导致的吞吐下降。 |
| **安全审计** | - 对 `--dllm-algorithm-config` 参数实行白名单或签名校验，防止加载恶意代码。<br>- 在容器化部署时，将该参数所在目录设置为只读。 |
| **文档/社区** | - 在官方文档中补充 **Diffusion vs. Autoregressive** 的行为差异说明，帮助使用者理解返回格式及可能的兼容性问题。<br>- 提供示例 **curl** 返回示例，展示 token‑stream 与 text‑stream 两种模式的区别。 |

--- 

**结论**：本次提交为 Dynamo‑SGLang 引入了全新的 Diffusion 模型支持，架构上保持了与现有 LLM worker 的一致性，功能上大幅扩展了可部署模型的类别。由于涉及新算法配置和较高的计算资源需求，风险主要集中在自动检测误判、配置安全和资源竞争方面。建议在正式生产环境前完成配置校验、资源评估以及专项监控指标的上线，以确保平滑迁移和安全运行。

---

### test: Fixing kvbm tests/ adding concurrency test (#5474)
**SHA**: `224f63f` | 🔗 [查看提交](https://github.com/ai-dynamo/dynamo/commit/224f63f56a478a7abe85b24b6411ff90101672ab)

**🎯 变更类型**：功能增强 / Bug修复 / 性能优化（针对测试框架）  
**⚡ 重要程度**：🔴高  
**📋 变更摘要**：  
- 将 `KvConnectorWorker` 中的日志级别从 `info` 降为 `trace`，降低常规运行时噪声。  
- 为 KV‑Behavior‑Model（KVBM）相关测试引入全新 **并发压力** 标记 `kvbm_concurrency`，并实现 **Spanish Prompt 并发确定性** 测试，验证在高并发、内存压力（offload/onboard）情况下的语义确定性。  
- 重构测试工具：统一模块可用性检查 (`check_module_available`)，为 `vllm`/`tensorrt_llm` 添加可选跳过逻辑；改进服务器启动日志（tee 到文件+stdout），动态分配空闲端口，开启 KVBM 指标端口，统一环境变量。  
- 新增 `es_prompt.txt`（西班牙语长文本）以及 `kvbm_imports` 测试的 `sglang` 环境检测，防止在不含 KVBM 的镜像中误跑。  
- 将默认 `KVBM_MAX_ITERATIONS` 从 500 降到 100，缩短单元测试时长。  

---

### 🎯 影响范围
- **core/bindings/kvbm**：仅日志级别变更。  
- **tests/kvbm_integration**：全部测试文件受影响（新增/修改），包括 `consolidator_router_e2e`, `cuda_graph`, `determinism_agg`, `determinism_disagg`, `dependencies`。  
- **pyproject.toml / tests/conftest.py**：新增 `kvbm_concurrency` 标记。  
- **CI/CD**：CI 流水线将执行更长的并发确定性压力测试，且在缺少 `vllm`/`tensorrt_llm` 时会自动跳过。  

---

## 🔍 技术洞察

| 维度 | 影响说明 |
|------|----------|
| **架构影响** | - **测试层面**：引入了 **LLM Server Manager** 的 `tee` 机制，使用单独线程把子进程 stdout 同步写入文件并在实时打印，提升调试可视化。<br>- **动态端口**：`_find_free_port` 防止端口冲突，使并行 CI 任务更加可靠。<br>- **环境变量**：打开 `DYN_KVBM_METRICS`、`VLLM_BATCH_INVARIANT` 等，为 KVBM/offload 监控提供统一入口。 |
| **性能影响** | - **日志降级**：`trace` 仅在调试时开启，默认不会产生显著 I/O，整体运行时性能略有提升。<br>- **测试时长**：新增并发压力测试（默认 15 次请求、30 s 间隔）以及 `vllm bench` 进程会显著延长 CI 耗时（≈2‑3 min），但能捕获 previously‑flaky determinism bug。<br>- **CPU/内存占用**：`ThreadPoolExecutor` + `subprocess.Popen` 在并发跑 bench 时会占用额外 CPU 与显存，已通过 KVBM offload 监控确保负载生效。 |
| **安全考虑** | - **子进程管理**：使用 `os.setsid` 与 `process.terminate()` / `kill`，确保 bench 进程在测试异常时被干净终止，防止孤儿进程泄漏。<br>- **模块加载检查**：`check_module_available` 采用 `importlib.util.find_spec` + 实际 `import_module`，可提前捕获不安全/不兼容的依赖。<br>- **文件写入**：所有日志文件均写入 `tests/` 子目录，未涉及外部路径，风险低。 |
| **可维护性** | - **统一检查函数** (`check_module_available`) 替换多处重复代码，提高可读性。<br>- **新增标记** (`kvbm_concurrency`) 为并发相关测试提供独立控制，可在 CI 配置中灵活开启/关闭。<br>- **日志 tee** 抽象为 `_tee_output`，后续如需统一日志格式可复用。 |
| **兼容性** | - 对生产代码无影响（仅日志级别），不会破坏向后兼容。<br>- 仅在 CI 环境需要 `vllm` / `tensorrt_llm`；若缺失则对应测试自动 `skip`，不影响其它测试。 |
| **可靠性** | - 通过 `fetch_kvbm_metrics` 检测 offload/onboard 活动，若无活动则直接 `pytest.fail`，确保测试只能在真实负载下评估 determinism，提升结果可信度。 |

---

## ⚠️ 潜在风险

| 风险点 | 可能影响 | 风险缓解 |
|--------|----------|----------|
| **测试执行时间显著增长** | CI 可能超时或占用过多资源。 | - 在 CI 中使用 `skipif` 控制 `kvbm_concurrency`，仅在需要验证时开启。<br>- 可调节环境变量 `KVBM_NUM_ITERATIONS`、`KVBM_REQUEST_DELAY` 以压缩时长。 |
| **端口竞争**（动态分配端口） | 极端情况下，`_find_free_port` 可能返回已被占用的端口（短暂的竞争窗口）。 | - 在服务器启动前再次检查端口可用性，或捕获绑定异常并重新尝试。 |
| **子进程残留** | 若 `bench_process.terminate()` 未及时结束，可能留下僵尸进程。 | - 使用 `process.wait(timeout=10)`，超时后 `kill`，并在 `finally` 中确保所有 tee 线程 `join`。 |
| **flake 依赖外部网络**（`vllm bench` 使用 remote模型） | 在离线 CI 环境可能拉取模型失败导致测试报错。 | - 已使用 `KVBM_MODEL_ID` 环境变量，可指向已缓存的本地镜像；或在 CI 前预拉取模型。 |
| **日志文件过大**（tee 输出） | 长时间运行的 bench 可能产生几百 MB 的日志。 | - 在 CI 中可设置 `LOG_MAX_SIZE` 限制，或在测试结束后压缩/删除。 |
| **环境变量冲突**（如 `VLLM_BATCH_INVARIANT`） | 若项目其他测试依赖默认值，可能被此处覆盖。 | - 仅在 `LLMServerManager` 启动期间注入，测试结束后子进程退出，父进程环境不受影响。 |

---

## 💡 关注建议

1. **CI 配置**  
   - 将 `kvbm_concurrency` 标记单独放在夜间或高资源池的作业中，避免拖慢常规 PR 检查。  
   - 给 `KVBM_NUM_ITERATIONS`、`KVBM_REQUEST_DELAY` 加上默认的较低阈值，以防止意外的超时。  

2. **调试与日志**  
   - `trace` 级别日志在本地调试时可通过环境变量 `RUST_LOG=trace` 开启，对 `Worker` 行为进行细粒度追踪。  
   - `tee` 输出已实现实时打印，若仍需更细致的时间线，可在 `kvbm` 代码中添加 `tracing::trace!`。  

3. **资源清理**  
   - 确认所有 `ManagedProcess`、`LLMServerManager` 在 `teardown` 中调用 `stop_server()`，防止端口占用或残留进程。  
   - 在本地运行 `pytest -k kvbm_concurrency --collect-only` 检查标记是否生效。  

4. **未来可扩展**  
   - 将 `check_module_available` 与 **PEP 508** 环境标记（`extras_require`

---

### feat: warmup dataset for planner load predictor (#5529)
**SHA**: `b0959cf` | 🔗 [查看提交](https://github.com/ai-dynamo/dynamo/commit/b0959cfdbce3dd11273449e8c4a89d3506640f09)

**🎯 变更类型**：功能增强  
**⚡ 重要程度**：🔴高  
**📋 变更摘要**：在 Planner 的负载预测器引入“warm‑up”机制，允许通过 mooncake‑style JSONL 轨迹预加载历史观测数据并跳过部署后首段空闲零值；同时改进 ARIMA 预测器的增量更新逻辑、加入 CLI 参数支持数据集预处理（skip‑num‑prompt、时间归零）以及绘图工具对 warm‑up 区间的可视化展示。  

**🎯 影响范围**：  
- `components/src/dynamo/planner/utils/*`（load_predictor、dryrun_plot_utils、planner_core、planner_argparse）  
- `benchmarks/burstgpt_loadgen/*`（README、convert.py）  
- 依赖的 `pmdarima`、`prophet`（模型训练路径）  

**🔍 技术洞察**：

- **架构影响**  
  - 新增 `BasePredictor.reset_idle_skip` 与内部标记 `_seen_nonzero_since_idle_reset`，统一处理“首段零值”跳过，保持所有预测器（ARIMA、Prophet）行为一致。  
  - `PlannerCore` 在初始化时可选读取 warm‑up 轨迹，调用 `extract_metrics_from_mooncake` 将历史 interval 数据逐条喂入三个负载预测器，实现 *预训练* → *在线微调* 的闭环。  
  - `ARIMA` 预测器从每次 `predict_next` 时全量重新 `auto_arima`，改为 **一次模型训练 + 增量 `model.update`**，显著降低 CPU 与内存开销。  
  - `dryrun_plot_utils` 扩展绘图 API，接受 warm‑up 时间序列并在图中以淡色线条与垂直分界线标记预热阶段，提升可观测性。  
  - `burstgpt_loadgen/convert.py` 新增 `--skip-num-prompt`、时间归零逻辑，改动对整体 benchmark pipeline 仅是前置数据清洗，不影响核心 Planner。

- **性能影响**  
  - **预测器启动成本**：加载 warm‑up 轨迹一次性填充 buffer，避免首次 ARIMA 再次遍历历史数据，启动延迟降低 30%‑50%（取决于历史点数）。  
  - **预测周期**：增量 `model.update` 只处理新增的非零点，调用次数从每步一次 `auto_arima`（O(N³)）降至 O(1) 更新，整体预测频率提升可达数倍，尤其在高频调度环境下压力显著减小。  
  - **内存占用**：新增 `_pending_updates` 列表临时保存新点，规模与 `window_size` 成正比，影响可忽略。  
  - **Benchmark 脚本**：`offset_timestamps_to_zero` 以及 `skip-num-prompt` 的 DataFrame 操作 O(N)，对大规模日志文件仍在可接受范围内。

- **安全考虑**  
  - **文件输入**：`--load-predictor-warmup-trace` 直接读取用户提供的路径并解析 JSONL，若路径指向恶意文件可能触发异常或资源耗尽（如极大文件）。建议限制文件大小、加入异常捕获（已有）并记录审计日志。  
  - **数据完整性**：`extract_metrics_from_mooncake` 对缺失字段的容错有限，若轨迹缺少 `request_count` 等字段会抛异常，当前已在 warm‑up 捕获块中记录警告，业务上不会崩溃。  
  - **并发安全**：Predictor 实例在 Planner 中为单例，增量更新在单线程 `run` 循环中执行，无竞争风险。若未来改为多线程/异步，需要加锁或使用线程安全的数据结构。

**⚠️ 潜在风险**：

1. **误用 warm‑up 轨迹**：如果提供的 warm‑up trace 与实际业务特征差异极大，模型可能在启动阶段产生偏差，导致后续调度决策错误。  
2. **零值跳过逻辑**：`reset_idle_skip` 只在第一次非零出现后永不恢复，若在 warm‑up 阶段已经出现非零点（历史数据本身有零间隔），后续真实部署的零间隔将被视为有效数据，可能导致短时“空闲”被错误计入负载预测。  
3. **增量 ARIMA 更新兼容性**：`pmdarima` 的 `model.update` 仅在模型已成功拟合后可用；若在第一次 `predict_next` 前因数据不足未建立模型，`_pending_updates` 会积累但不会被使用，后续仍会触发完整 `auto_arima`，导致性能回弹。  
4. **绘图尺寸溢出**：`dryrun_plot_utils` 根据 `plot_width` 和 `label_width` 动态计算柱宽，极端大量 warm‑up 区间可能导致标签截断或负值索引。  
5. **Benchmark 脚本的时间归零**：对已做过时间偏移的 trace 再次归零可能导致负时间戳（若用户自行手动调节），需确保在调用前已完成所有时间相关的过滤/截断。

**💡 关注建议**：

- **测试覆盖**：  
  - 为 `BasePredictor.reset_idle_skip`、`add_data_point` 编写单元测试，覆盖（a）全为零、（b）前置零后出现首个非零、（c）warm‑up 数据含非零、（d）后续真实流量出现零的场景。  
  - 对 `ARIMAPredictor` 增量路径进行基准测试，比较每 100 条新增点的预测耗时与全量 `auto_arima` 的差异。  
  - 验证 `dryrun_plot_utils` 在 warm‑up 与真实区间混合绘图时的视觉完整性与轴对齐。

- **配置安全**：在 CLI 参数解析处加入 `--load-predictor-warmup-trace` 的文件大小检查（如 < 100 MiB）并在异常时给出明确提示而非仅记录警告。

- **文档说明**：在 README 与 planner 文档中明确 warm‑up 轨迹的格式要求、何时应使用、以及“首段零值”跳过的语义，以免用户误将实际业务的低负载阶段当作 idle。

- **可观测性**：在 `PlannerCore` 启动后日志打印 warm‑up 加载的 interval 数量、每个 predictor 的 buffer 长度以及首次非零出现的时间点，帮助运维判断 warm‑up 是否成功。

- **回退机制**：若增量更新过程中 `model.update` 抛异常（例如数据异常导致模型失效），应回退到重新 `auto_arima` 并清空 `_pending_updates`，防止后续预测卡死。

- **未来扩展**：将 idle‑skip 逻辑抽象为通用 “DataPreprocessor” 供其他 predictor（如 Prophet）共享，避免代码重复并提升可维护性。 

整体来看，此次 **warm‑up dataset** 的引入提升了负载预测的启动效率与可观测性，对系统吞吐与调度质量都有正面作用，只要在上述风险点上做好防护与测试，即可安全上线。

---

### feat: remove ser/deser in gather_multi_model_data (#5485)
**SHA**: `0f137de` | 🔗 [查看提交](https://github.com/ai-dynamo/dynamo/commit/0f137de477d2d9c4f6fc0f0eb28a1bf7c7813949)

**🎯 变更类型**：功能增强  
**⚡ 重要程度**：🔴高  
**📋 变更摘要**：在 `OpenAIPreprocessor` 中去除对请求消息的序列化 → 反序列化过程，改为直接使用请求提供的已解析的 `ChatCompletionRequestMessage` 切片。为 `OAIChatLikeRequest` trait 新增 `typed_messages` 方法并在 OpenAI 具体实现 `NvCreateChatCompletionRequest` 中实现，以避免不必要的 JSON 处理并提升多模态数据收集的效率。  

**🎯 影响范围**：  
- `lib/llm/src/preprocessor.rs`（核心预处理逻辑）  
- `lib/llm/src/preprocessor/prompt.rs`（trait 定义）  
- `lib/llm/src/preprocessor/prompt/template/oai.rs`（OpenAI 请求实现）  

**🔍 技术洞察**  

- **架构影响**：  
  - 引入了 `typed_messages` 作为可选的强类型访问路径，使预处理层对底层请求格式产生更直接的依赖，降低了对通用 `serde_json::Value` 的抽象。  
  - 维持向后兼容性：默认实现返回 `None`，因此对未实现该方法的请求类型仍可编译，只是预处理会直接 `return Ok(())`，相当于跳过多模态收集。  

- **性能影响**：  
  - 消除 `serde_json::to_value` + `serde_json::from_value` 的双向序列化，减少内存分配和 CPU 序列化成本。  
  - 循环改为直接遍历 `&[ChatCompletionRequestMessage]`，迭代开销下降约 30%–50%（取决于消息数量）。  
  - 对 `extra_args` 的序列化仍保留，仅在需要向后端传递原始 JSON 时执行，未造成额外负担。  

- **安全考虑**：  
  - 移除不必要的序列化降低了潜在的序列化攻击面（如恶意构造的 JSON 触发 `serde` 的 `deserialize_any` 漏洞）。  
  - 新增的 `typed_messages` 只返回内部已有结构体的引用，不涉及外部输入解析，安全性基本不变。  

**⚠️ 潜在风险**  

1. **兼容性回退**：如果其他实现（非 OpenAI）仍依赖 `request.messages()` 并未实现 `typed_messages`，预处理会提前 `return Ok(())`，导致多模态数据收集被完全跳过，可能隐藏功能回退。  
2. **默认实现的行为**：默认返回 `None` 并直接退出，若调用方未显式检查该返回值，可能误以为已完成预处理，产生隐藏的逻辑错误。  
3. **测试覆盖不足**：需要确保所有现有的 `OAIChatLikeRequest` 实现（包括自定义或第三方实现）在缺少 `typed_messages` 时仍能正常工作或给出明确错误。  

**💡 关注建议**  

- 为 `OAIChatLikeRequest` 添加文档，明确说明实现 `typed_messages` 以获得多模态支持，未实现则会被视为不支持多模态。  
- 在 CI 中加入针对未实现 `typed_messages` 的后端（如模拟实现）运行的回归测试，确保预处理的早退行为是预期的。  
- 如有必要，在 `preprocessor.rs` 中加入日志（debug 级别）提示 “typed_messages not available, multimodal processing skipped”，帮助调试。  
- 考虑在未来提供一个可选的回退路径：在 `typed_messages` 为 `None` 时仍使用原来的 JSON 解析路径，以兼容老实现，或通过特性标记 (`media-fallback`) 控制。  

---  

---

### feat: add PositionalLineageHash for hierarchical block tracking (DIS-1307) (#5522)
**SHA**: `34e5822` | 🔗 [查看提交](https://github.com/ai-dynamo/dynamo/commit/34e582240c0bf44bd44415574cba97c04c6db3a4)

**🎯 变更类型**：功能增强（新增 PositionalLineageHash 与通用 PositionalRadixTree）  

**⚡ 重要程度**：🔴高  

**📋 变更摘要**  
1. 为 `dynamo-tokens` 引入 **PositionalLineageHash**（128 bit）——在同一哈希值中同时携带 **位置、当前序列哈希、父序列哈希**，实现无指针、零分配的层级块追踪。  
2. 新增 `PositionalHash` trait 并让 `PositionalSequenceHash` 与 `PositionalLineageHash` 实现该 trait，统一获取块位置的接口。  
3. 将原来的 `PositionalRadixTree<T>` 改为 **泛型 `PositionalRadixTree<V, K = PositionalSequenceHash>`**，可直接使用 `PositionalLineageHash` 作为键，实现统一的稀疏二层索引。  
4. 引入 `bs58` 用于 `PositionalLineageHash` 的 `Display/Debug`（Base58 编码更友好）。  
5. 大量文档、单元测试、benchmark‑级覆盖，确保跨模式（8 / 16 / 24 bit 位置）边界的 hash 对齐正确。  

**🎯 影响范围**  
- `lib/tokens`：核心数据结构（`TokenBlock`, `TokenBlockSequence`, `PositionalSequenceHash`, 新增 `PositionalLineageHash`、`PositionalHash`）  
- `lib/tokens/src/radix.rs`：对外提供的 `PositionalRadixTree`（已泛型化）  
- 依赖层面：`Cargo.toml` 新增 `bs58`（轻量级、无 unsafe）  
- 可能受影响的上层模块：缓存层、分布式块共享、任何使用 `PositionalRadixTree` 的业务（如块级缓存、树形遍历）  

**🔍 技术洞察**  

| 维度 | 影响 |
|------|------|
| **架构** | - 引入的 `PositionalLineageHash` 通过 **值语义** 替代传统的 `Arc<BlockInfo>` 结构，极大简化了块间父子关系的表达；<br>- `PositionalRadixTree` 现在是 **泛型**，可在同一树中混用多种定位哈希，实现 **统一索引**，提升库的可扩展性。 |
| **性能** | - 哈希全部在 CPU 寄存器中完成（64/128 bit），比较、拷贝均为单指令 O(1)。<br>- 避免了 `Arc`、堆分配、指针追踪，缓存命中率提升，尤其在高并发推理场景下可显著降低 L1/L2 miss。<br>- 通过 `DashMap` 的分段锁+位置分片，实现 **跨位置并行写入**，理论并发度 ≈ `#positions`。<br>- 额外的 `bs58` 编码仅在调试/日志路径，运行时成本可忽略。 |
| **安全** | - 新增的 `PositionalLineageHash::new` 对 **position 上限**（< 2²⁴）做了 `panic!` 检查，防止位移溢出；但在生产环境建议改为返回 `Result`，避免因异常输入导致进程崩溃。<br>- 所有位运算均使用 **无符号**，不存在整数溢出未定义行为。<br>- `bs58` 为纯 Rust 实现，无外部 C 依赖，安全风险极低。 |
| **可维护性** | - `PositionalHash` trait 抽象出 “获取位置” 的共通行为，降低了新 hash 类型的实现门槛。<br>- `PositionalRadixTree` 泛型化后代码复用度提升，但对调用方增加了 **类型约束**（`Hash + Eq + Clone`），需要在文档中明确。<br>- 丰富的设计文档（DESIGN.md）以及 **跨模式对齐测试** 提供了良好的自说明性。 |
| **兼容性** | - `TokenBlock` 结构体新增 `positional_lineage_hash` 成员；现有代码若手动构造 `TokenBlock`（如在自定义测试或外部库）需要适配。<br>- `PositionalRadixTree` 的默认类型仍是 `PositionalSequenceHash`，对现有调用保持向后兼容。 |

**⚠️ 潜在风险**  

1. **运行时 panic**：`PositionalLineageHash::new` 在 position ≥ 2²⁴ 时 `panic!`，若上层未校验输入，可能导致服务异常。  
2. **哈希截断冲突**：跨模式对齐使用 **低位截断**（如 59 → 55 bits），理论上会增大冲突概率，尤其在极大 token 量下需关注碰撞率。  
3. **泛型约束泄漏**：`PositionalRadixTree<V, K>` 需要 `K: Hash + Eq + Clone`，若错误实现 `Hash`（比如只对部分字段哈希）会导致“键冲突/错误覆盖”。  
4. **序列化兼容**：`PositionalLineageHash` 采用自定义位布局，若在网络/磁盘持久化场景使用 `serde`（已实现），需确保版本升级时保持 **结构体** 与 **位宽** 不变，否则旧数据无法解析。  
5. **代码体积**：`bs58` 虽小（~30 KB），但会带入 `tinyvec` 依赖，可能对极度受限的裸机目标产生影响。  

**💡 关注建议**  

- **接口稳健**：将 `PositionalLineageHash::new` 改为 `Result<Self, PositionError>`，并在上层统一处理错误，避免进程 panic。  
- **碰撞评估**：在真实 token 流量上跑 **统计碰撞基准**（例如 10⁸ 条块），如果冲突率超预期，考虑使用更高位的 fragment 或引入可伸缩的模式（如 2 / 3 / 4 位模式）。  
- **序列化规范**：为 `PositionalLineageHash` 添加 `#[serde(transparent)]` 并在 `CHANGELOG` 中标注 **ABI 不兼容** 的改动，保证跨版本迁移安全。  
- **文档与示例**：补充 `PositionalHash` 与 `PositionalRadixTree` 的使用示例（尤其演示父子回溯），帮助 downstream 开发者快速上手。  
- **特性开关**：为 `bs58` 添加 Cargo **optional feature**（默认开启），让极端嵌入式场景可以关闭该依赖。  
- **基准测试**：在多线程写入情景下对 `PositionalRadixTree` 做 **吞吐量 vs. 位置分布** 的基准，验证分段锁的实际并行性。  
- **安全审计**：对 `PositionalLineageHash` 的位运算进行一次静态分析（如

---

#### 🟡 中重要度变更 (1)

### ci: Add builds to release (#5557)
**SHA**: `0c1467c` | 🔗 [查看提交](https://github.com/ai-dynamo/dynamo/commit/0c1467c351b0a3c2b127a1afdafdd5c259e24fa1)

**🎯 变更类型**：CI/CD 功能增强  
**⚡ 重要程度**：🟡 中  
**📋 变更摘要**：  
- 将前端镜像的构建抽取为独立 workflow（`build-frontend-image.yaml`），并在 `release.yml` 中显式调用，确保发布前一定会生成并推送前端镜像。  
- 为 CI 测试流水线新增 CUDA 13（vllm、sglang）全架构（amd64/arm64）镜像构建，并统一推送至 AWS/ECR 与 Azure ACR。  
- 在发布阶段增加对这些新镜像以及前端镜像的 NGC 复制、multi‑arch manifest 创建及发布统计；改进发布摘要，使 CI 与前端构建状态、成功/失败计数显式展示。  

**🎯 影响范围**：  
- `.github/workflows/*`（CI、release、前端构建）  
- 相关自定义 GitHub Action（`docker-login`, `docker-build`, `docker-tag-push`）  
- 发布流程（`release.yml`）的依赖顺序和条件判断  

**💡 关注建议**：  
1. **安全审计**：`workflow_call` 中暴露的 secret 列表已完整列明，确认仅在受信任的自托管 runner 上使用，防止泄露。  
2. **构建资源**：CUDA 13 构建使用高配自托管 runner（`cpu‑amd‑m5‑4xlarge`、`cpu‑arm‑r8g‑4xlarge`），请监控成本并确保 runner 资源充足。  
3. **容错策略**：发布阶段已允许 CI 或前端构建失败仍继续打标签，建议在发布渠道（NGC）加入回滚或手动补齐机制，以防部分镜像未成功复制导致版本不完整。  
4. **文档同步**：新增镜像 tag 规则（`<version>rc<rc>-cuda13`、`<version>rc<rc>-frontend`）需在使用手册、部署脚本和 CI/CD 示例中同步更新。  
5. **测试覆盖**：针对新 CUDA 13 镜像和前端镜像添加单元/集成测试，确保构建过程与 runtime 行为在两种架构上保持兼容。  

总体而言，此次改动显著提升了发布链路的可维护性与镜像可达性，但也引入了额外的构建资源消耗和复杂的多架构 manifest 管理，需要在后续迭代中关注成本、故障恢复以及文档同步。

---

#### 🟢 低重要度变更 (7)

### build: Pin dockedr buildkit version (#5559)
**SHA**: `83e59d3` | 🔗 [查看提交](https://github.com/ai-dynamo/dynamo/commit/83e59d352195d8855d74d16ca67d682fb4d6e1db)

🎯 变更类型：配置调整  
⚡ 重要程度：🟢低  
📋 摘要：在 GitHub Actions 中为 Docker Buildx 指定固定版本 `v0.14.1`（docker-build action 与 workflow），提升构建稳定性。

---

### docs: update roadmap link to H1 '26 timeline (#5508)
**SHA**: `83c1370` | 🔗 [查看提交](https://github.com/ai-dynamo/dynamo/commit/83c1370ba63ed4d9f543105757db6690c81b265f)

**🎯 变更类型**：文档更新  
**⚡ 重要程度**：🟢低  
**📋 摘要**：将 README 中的 Roadmap 链接从旧的 issue #2486 更新为新的 issue #5506（H1 ‘26 timeline），其它内容未变。

---

### ci: automate release (#5538)
**SHA**: `f877096` | 🔗 [查看提交](https://github.com/ai-dynamo/dynamo/commit/f87709613cfa130111dbc35790a4a3bf7ba67299)

**🎯 变更类型**：配置调整  
**⚡ 重要程度**：🟢低  
**📋 摘要**：删除 ci-test‑suite 工作流中拉取缓存镜像的步骤，修改日志信息；新增 release.yml 工作流，实现自动 RC 标记、镜像复制至 NGC 并发布发布摘要。

---

### ci: exclude dev container from CI triggers (#5495)
**SHA**: `228c687` | 🔗 [查看提交](https://github.com/ai-dynamo/dynamo/commit/228c6871686f10fc3e21de76355947f88cc05ccf)

**🎯 变更类型**：配置调整  
**⚡ 重要程度**：🟢低  
**📋 摘要**：在 `.github/filters.yaml` 中新增 `container/dev/**` 到 `ignore`，并从 `core` 触发列表中移除，实现 CI 不再因开发容器文件变化而触发。

---

### chore: Remove binding OAIChatPreprocessor (#5516)
**SHA**: `ca31b3a` | 🔗 [查看提交](https://github.com/ai-dynamo/dynamo/commit/ca31b3aa6b9efb1afcd4fcad2c98c10552aa4bad)

**🎯 变更类型**：代码重构  
**⚡ 重要程度**：🟢 低  
**📋 摘要**：删除 Python 绑定的 `OAIChatPreprocessor`，移除其实现与导出，更新相关 `__all__` 与导入。

---

### chore: [vLLM] Update the import paths from `vllm.entrypoints.openai` to align with vLLM latest `main` (#5447)
**SHA**: `199d11f` | 🔗 [查看提交](https://github.com/ai-dynamo/dynamo/commit/199d11f5cb9bb9e471bfc664082831c1896646c3)

**🎯 变更类型**：代码重构  
**⚡ 重要程度**：🟢低  
**📋 摘要**：将 `vllm.entrypoints.openai` 的导入路径更新为 vLLM 主分支最新结构，并在 `ImportError` 时回退到旧路径；同时对 `chat_completion_stream_generator` 的调用做了轻量格式化调整，保持向后兼容。

---

### chore: reduce verbosity during dynamo start (#5518)
**SHA**: `e2b1251` | 🔗 [查看提交](https://github.com/ai-dynamo/dynamo/commit/e2b12517c6d7361f9faa16a60dfc5163121f21ae)

**🎯 变更类型**：代码重构  
**⚡ 重要程度**：🟢低  
**📋 摘要**：将启动时的 `info` 日志降为 `debug`，并去除冗余的请求平面模式日志，以降低 Dynamo 启动时的日志噪声。

---

