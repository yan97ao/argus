# 每日更新报告（2026-01-30）

## ai-dynamo/dynamo

| 提交时间 | 作者 | 提交信息 |
|----------|------|----------|
| 2026-01-30 23:04:32 | ls-2018 | feat: remove useless branch condition (#4920) |
| 2026-01-30 11:03:09 | Yan Ru Pei | docs: update main router doc (#5812) |
| 2026-01-30 10:18:20 | Jacky | fix: Temporary disable cancellation at TRT-LLM decode worker (#5764) |
| 2026-01-30 09:52:10 | Yan Ru Pei | chore: atomic file write (#5809) |
| 2026-01-30 08:13:43 | Schwinn Saereesitthipitak | fix: CUDA synchronization to prevent sleep/wake race conditions (#5759) |
| 2026-01-30 08:04:11 | Yuewei Na | refactor: read offload priority env var once at init (#5798) |
| 2026-01-30 07:20:58 | Tanmay Verma | chore: Upgrade to Tensorrt-LLM 1.3.0rc1 (#5700) |
| 2026-01-30 06:43:01 | Julien Mancuso | feat: add epp component (#5611) |
| 2026-01-30 05:42:37 | Yuewei Na | feat: Implement priority-based KV cache offload filtering (#5563) |
| 2026-01-30 04:46:59 | Julien Mancuso | fix(operator): correct structured logging in restart status tracking (#5800) |
| 2026-01-30 03:51:44 | Neal Vaidya | fix: specifiy triton worker dynamo base [DYN-1984] (#5794) |
| 2026-01-30 02:48:35 | Anant Sharma | docs: sync fern with observability doc changes (#5795) |
| 2026-01-30 01:19:59 | Schwinn Saereesitthipitak | feat(sglang): integration with GPU Memory Service (#5664) |
| 2026-01-30 00:36:04 | Keiven C | ci: print 10 slowest pytest tests in container validation (#5779) |
| 2026-01-30 00:15:45 | Richard Huo | docs: fix the statements for setting up the trtllm NIXL backends (#5763) |

### 📊 统计摘要
> 本日共 15 个提交 | 🔴高 6 | 🟡中 4 | 🟢低 5
## 📋 目录

- [ai-dynamo/dynamo](#ai-dynamo-dynamo)
  - [📊 统计摘要](#-统计摘要)
  - [🔴 高重要度变更 (6)](#-🔴-高重要度变更-6)
    - [feat: remove useless branch condition (#4920)](#96b6cb5)
    - [fix: Temporary disable cancellation at TRT-LLM decode wor...](#b10d103)
    - [fix: CUDA synchronization to prevent sleep/wake race cond...](#69fdc9d)
    - [feat: add epp component (#5611)](#9e2a2cc)
    - [feat: Implement priority-based KV cache offload filtering...](#6271a31)
    - [feat(sglang): integration with GPU Memory Service (#5664)](#a2fbda3)
  - [🟡 中重要度变更 (4)](#-🟡-中重要度变更-4)
    - [refactor: read offload priority env var once at init (#5798)](#eef5e64)
    - [chore: Upgrade to Tensorrt-LLM 1.3.0rc1 (#5700)](#ba711cc)
    - [fix(operator): correct structured logging in restart stat...](#2b6d133)
    - [fix: specifiy triton worker dynamo base [DYN-1984] (#5794)](#c5bb8df)
  - [🟢 低重要度变更 (5)](#-🟢-低重要度变更-5)
    - [docs: update main router doc (#5812)](#ec04692)
    - [chore: atomic file write (#5809)](#aa4ac94)
    - [docs: sync fern with observability doc changes (#5795)](#ffe2d33)
    - [ci: print 10 slowest pytest tests in container validation...](#2c36a58)
    - [docs: fix the statements for setting up the trtllm NIXL b...](#8cdfe68)
#### 🔴 高重要度变更 (6)

### feat: remove useless branch condition (#4920)
**SHA**: `96b6cb5` | 🔗 [查看提交](https://github.com/ai-dynamo/dynamo/commit/96b6cb51ef6994e7971f6bdcd0e410cabbbbd1c0)

**🎯 变更类型**：重构  
**⚡ 重要程度**：🔴低  
**📋 变更摘要**：在 `DynamoGraphDeploymentReconciler.reconcileK8sDiscoveryResources` 中去除多余的 `else` 分支，将 “K8s discovery is enabled” 的日志调用移至 `if` 语句之后。行为保持不变，仅提升代码可读性并略微削减分支预测开销。  

**🎯 影响范围**：  
- `deploy/operator/internal/controller/dynamographdeployment_controller.go`（核心控制器逻辑）  

**🔍 技术洞察**：  
- **架构影响**：无。该文件属于调度器/控制器层，改动仅是局部控制流的简化，不涉及模块边界或接口。  
- **性能影响**：极小。删除了一个不必要的 `else` 分支，降低了分支预测的复杂度，理论上能略微提升 CPU 执行效率（对整体系统影响可忽略不计）。  
- **安全考虑**：无。日志信息未改变内容或泄露额外信息，未涉及权限、凭证或网络交互。  

**⚠️ 潜在风险**：  
- **回归风险**：几乎不存在，唯一可能的风险是误删或误改导致 `if` 条件后的代码在 `IsK8sDiscoveryEnabled` 为 `false` 时仍被执行。当前实现通过 `return nil` 仍然保证了早退出。  
- **日志一致性**：若外部监控/审计依赖日志顺序进行分析，确保日志仍在同一执行路径输出即可。  

**💡 关注建议**：  
1. **单元/集成测试**：确认 `IsK8sDiscoveryEnabled` 为 `false` 时函数仍立即返回，且不会产生 “K8s discovery is enabled” 日志。  
2. **代码审查**：保持类似写法的一致性，避免在返回路径后仍留下不必要的代码块。  
3. **日志监控**：如果有基于日志关键字的监控，请验证新位置的日志仍被正确捕获。  
4. **文档更新**：若项目文档中描述了日志输出顺序，可适当补充说明该改动对可读性的提升。  

---

### fix: Temporary disable cancellation at TRT-LLM decode worker (#5764)
**SHA**: `b10d103` | 🔗 [查看提交](https://github.com/ai-dynamo/dynamo/commit/b10d103d27d7c677ee9fe6ec023f826a095f188f)

**🎯 变更类型**：Bug修复 / 功能临时调整  
**⚡ 重要程度**：🔴高  
**📋 变更摘要**：  
- 为了避免在 TRT‑LLM 的 **decode** 工作进程中出现引擎卡死，作者暂时关闭了请求取消的逻辑，仅在非 decode （prefill/aggregated）模式下才会执行 `generation_result.abort()`。  
- 同时对取消监控的实现进行了简化：统一使用 `cancellation_triggers` 列表，仅在 `shutdown_event` 触发时抛出 `GeneratorExit`，而不再返回“cancelled”/“shutdown” 标识。  
- 对相关单元测试加入 `xfail` 标记，明确说明当前 decode worker 的取消已被禁用。

**🎯 影响范围**：  
- `components/src/dynamo/trtllm/request_handlers/handler_base.py`（核心请求处理与取消监控）  
- `tests/fault_tolerance/cancellation/test_trtllm.py`（取消相关的集成测试）  
- 受影响的运行时模式：`DisaggregationMode.DECODE`（TRT‑LLM 解码工作进程）  

**🔍 技术洞察**  

- **架构影响**：  
  - 该修改在 **disaggregation**（解耦）架构下引入了模式感知的取消行为：只有在 **prefill/aggregated** 模式下才会触发 `abort()`，decode 模式下保持生成进程直至自然结束。  
  - 通过把取消监控的职责从 **handler_base** 转移为“仅在需要时触发”，降低了在 **decode** 工作进程内部跨线程/跨进程的同步复杂度，避免了此前因 `abort()` 导致的引擎死锁。

- **性能影响**：  
  - 取消监控任务的 `asyncio.wait` 仍然会监听两个触发点（请求取消 & shutdown），但在 decode 模式下不再调用 `generation_result.abort()`，从而省去一次可能的内部状态清理和 GPU 资源回收的开销。实际生成吞吐在正常情况下保持不变，且在大量并发 decode 场景下可减少因误触发取消导致的卡顿。  
  - 由于取消被禁用，长时间运行的 decode 请求若被用户手动中止，将继续占用 GPU/CPU 资源，可能导致资源利用率下降。

- **安全考虑**：  
  - 变更不涉及外部输入验证、加密或权限控制，安全风险基本为零。唯一需要关注的是 **资源耗尽攻击**：恶意用户可发起大量不可取消的 decode 请求，使系统资源被耗尽，间接导致服务不可用（DoS）。

**⚠️ 潜在风险**  

1. **资源泄漏 / DoS**：在 decode 模式下请求无法被取消，若出现请求卡住（如模型推理异常、网络阻塞），会占用工作进程直至超时或进程被强制终止。  
2. **不一致的错误语义**：原来的实现会返回“cancelled”或“shutdown”，现在只在 shutdown 时抛 `GeneratorExit`，调用方需要确认对 `GeneratorExit` 的处理保持兼容。  
3. **测试覆盖缺失**：相关取消行为已被标记为 `xfail`，未来若忘记恢复，实现回归时可能导致隐藏的 bug。  
4. **上线回滚难度**：因为仅在 decode 模式下禁用取消，若错误地将 `DisaggregationMode` 配置成 `DECODE` 而实际需求是需要取消，可能导致用户体验骤降。  

**💡 关注建议**  

- **监控 & 限流**：在生产环境为 decode 工作进程增加 **超时监控**（比如硬性 `max_generation_time`），并在超时后强制回收进程，防止单个卡住的请求耗尽资源。  
- **日志可观测性**：在 `generation_result.abort()` 前后统一记录 **取消触发点** 与 **工作模式**，便于后续分析是否真的需要恢复 decode 端的取消。  
- **灰度恢复计划**：在后续迭代中，可通过实验性标记（如环境变量 `TRTLLM_DECODE_CANCELLATION=enabled`）逐步验证安全的取消实现，确保不会再次出现引擎卡死。  
- **测试补全**：为 `DisaggregationMode.DECODE` 场景编写专门的单元测试，验证在 **shutdown** 触发时仍能抛 `GeneratorExit`，并确保在 **prefill** 场景下取消行为保持不变。  
- **文档更新**：在项目的 **Cancellation & Disaggregation** 文档章节明确说明当前 decode worker 取消已被禁用，并给出对应的风险说明与建议的运维策略。  

---

### fix: CUDA synchronization to prevent sleep/wake race conditions (#5759)
**SHA**: `69fdc9d` | 🔗 [查看提交](https://github.com/ai-dynamo/dynamo/commit/69fdc9dd87e4259a329dd9f077e44975490bd39f)

**🎯 变更类型**：Bug修复 / 性能优化 / 重构  
**⚡ 重要程度**：🔴高  
**📋 变更摘要**：  
- 在 `cuda_vmm_utils.py` 中新增 `synchronize` 与 `set_current_device`，改为使用低层 CUDA 驱动 API（`cuCtxSynchronize`、`cuDevicePrimaryCtxRetain`、`cuCtxSetCurrent`）控制上下文同步与设备切换。  
- `memory_manager.py`、`sglang/memory_saver.py`、`vllm/worker.py` 等核心模块改为调用上述函数，取代 `torch.cuda.synchronize` 与 `torch.cuda.set_device`，消除 sleep/wake 期间因 CUDA 同步不当导致的 VMM（Virtual Memory Management）竞争和 OOM 错误。  
- 增加在 *unmap*、*pause*、*resume*、*wake_up* 等关键路径的显式同步，以确保所有 VMM 操作完成后才继续后续分配或计算。

**🎯 影响范围**：  
- `lib/gpu_memory_service/client/*`（CUDA VMM 工具、内存管理器）  
- `lib/gpu_memory_service/integrations/sglang/*`（权重暂停/恢复）  
- `lib/gpu_memory_service/integrations/vllm/*`（worker sleep/wake）  
- 任何直接或间接使用 `GpuMemoryService` 的上层框架（如 Triton、vLLM、SGLang）

**🔍 技术洞察**  

- **架构影响**  
  - **显式上下文管理**：通过 `set_current_device` 显式保留并激活设备的 *primary context*，不再依赖 `torch.cuda.set_device` 的隐式上下文切换。这使得 GMS 在非‑PyTorch 环境（如纯 CUDA 程序）中也能保持正确的上下文状态。  
  - **解耦 Torch**：大多数核心路径已移除对 `torch.cuda` 的依赖，仅在集成层（sglang、vllm）保留少量同步调用，提升了库的可移植性。  
  - **同步点集中**：所有涉及 VMM（`unmap`、`remap`、`pause`、`resume`、`sleep`、`wake_up`）的关键路径均统一使用 `synchronize()`，降低了各模块自行决定何时同步的碎片化风险。  

- **性能影响**  
  - **同步开销**：每次 `synchronize()` 都会阻塞当前线程直到所有先前的 CUDA 命令完成，必然引入一定的延迟。相较于之前在特定路径仅使用 `torch.cuda.synchronize(self.device)`，新增的同步在 *unmap* 完成后立即执行，可能导致稍长的 pause/wake 周期，但换来的是避免因竞争导致的 OOM 与崩溃，整体可用性大幅提升。  
  - **上下文切换成本**：`cuDevicePrimaryCtxRetain` 会在首次调用时创建/激活 primary context，后续调用成本极低；但若频繁在同一线程切换设备（例如多 GPU 场景），仍应关注上下文切换带来的微小开销。建议在多 GPU 环境中将 `set_current_device` 调用聚合到一次性完成的初始化阶段。  

- **安全考虑**  
  - 此次改动不涉及外部输入校验或权限控制，安全风险极低。唯一需要注意的是 **资源泄漏**：`cuDevicePrimaryCtxRetain` 增加了对 primary context 的引用计数，但代码未显式调用 `cuDevicePrimaryCtxRelease`。如果 GMS 在进程生命周期内多次创建/销毁 `MemoryManager` 实例，可能导致 context 引用累计。虽然大多数使用场景是单例对象，仍建议在 `MemoryManager.__del__` 或显式关闭路径中调用对应的释放函数以避免长期泄漏。  

**⚠️ 潜在风险**  

1. **Context 泄漏**  
   - 未配对的 `cuDevicePrimaryCtxRetain` 可能导致 CUDA driver 在进程退出前仍保有上下文，进而阻塞资源回收。  
2. **线程安全**  
   - `set_current_device` 与 `synchronize` 均作用于进程级的 **当前 CUDA Context**。在多线程同时使用 GMS 时，如果不同线程在不同 GPU 上操作而未做好显式的上下文切换同步，仍可能出现竞争。需要在用户层面确保每条线程在进入 GMS 前已正确设置当前设备。  
3. **兼容性**  
   - 仍有残留的 `torch.cuda.synchronize()` 调用（sglang、vllm），在没有安装 PyTorch 的环境下会导致 ImportError。虽然这些文件属于集成层，原则上应在无 PyTorch 场景下不被加载，但在 CI/测试中应验证缺少 `torch` 时库能够优雅降级。  
4. **性能回退**  
   - 对于极端低延迟需求（如实时推理服务），额外同步可能略微拉高暂停/恢复的时延。若业务对这块极其敏感，需要评估是否可以通过批量操作或异步流式方式减少同步次数。  

**💡 关注建议**  

| 建议 | 说明 |
|------|------|
| **添加 Context 释放** | 在 `MemoryManager` 的 `close()` 或 `__del__` 中调用 `cuDevicePrimaryCtxRelease(device)`，确保每次 `retain` 都有对应的 `release`。 |
| **统一 Context 初始化** | 将 `set_current_device` 的调用提前到 `MemoryManager` 实例化时一次完成，后续路径直接依赖已激活的 context，避免在高频路径重复调用。 |
| **多线程文档** | 明确在 README/开发文档中说明：在多线程使用 GMS 时，每个线程必须在调用 GMS 前调用 `set_current_device`，并在必要时使用 `torch.cuda.synchronize()`（或 `synchronize()`) 来确保顺序。 |
| **可选的同步开关** | 为性能敏感的场景提供一个配置选项（如 `GMS_DISABLE_SYNC`），在确认上下文/VMM 正确性的前提下可关闭部分 `synchronize()`，但默认保持开启以保障正确性。 |
| **测试覆盖** | 增加针对 sleep/wake、pause/resume、multi‑GPU 并发的集成测试，验证在没有 `torch` 环境下仍能正常构建/运行（使用 mock CUDA driver）。 |
| **监控同步延迟** | 在关键路径（`unmap`、`pause`、`sleep`）记录 `synchronize()` 前后时间，帮助运维团队评估同步开销是否在可接受范围内。 |

---  

**结论**：本次提交通过低层 CUDA 驱动 API 引入显式的上下文切换与同步，根除因 `torch.cuda` 隐式行为导致的 VMM 竞争和 OOM 问题，显著提升系统的稳健性。只要注意上下文引用的释放与多线程使用规范，风险可控，建议尽快合并并在后续版本中强化文档与测试。

---

### feat: add epp component (#5611)
**SHA**: `9e2a2cc` | 🔗 [查看提交](https://github.com/ai-dynamo/dynamo/commit/9e2a2cc9e64d93170ebe36789ab8109fb5a1d8f1)

**🎯 变更类型**：功能增强  

**⚡ 重要程度**：🔴高  

**📋 变更摘要**  
- 在 Dynamo Operator 中新增 **EPP (Endpoint Picker Plugin)** 组件类型，实现 KV‑aware 智能路由。  
- 为 Dynamo CRD 增加 `eppConfig` 字段，支持 **ConfigMapRef** 或 **inline EndpointPickerConfig**。  
- 引入对 `inference.networking.k8s.io`（Gateway API Inference Extension）CRD 的检测、RBAC、ServiceAccount 与 **InferencePool** 资源的自动创建。  
- 同步更新 Helm chart、文档、env‑var 命名、容器探针、端口、及 Rust 端代码的 discovery 超时配置。  

---

## 🎯 影响范围  

| 受影响模块 / 资源 | 说明 |
| ----------------- | ---- |
| `nvidia.com_dynamocomponentdeployments`、`nvidia.com_dynamographdeployments` CRD | 新增 `eppConfig`、`ComponentType` 为 `epp`，以及相应的 deepcopy、validation、kubebuilder RBAC。 |
| Operator controller (`dynamocomponentdeployment_controller.go`, `dynamographdeployment_controller.go`) | 新增 EPP 相关 `ComponentContext`、生成 Service、ConfigMap、InferencePool、RBAC 检查。 |
| Helm chart `platform` | 新增 EPP ServiceAccount / Role / RoleBinding、ClusterRole、模板渲染，以及对应的 chart 参数。 |
| Webhook validation (`validation/*.go`) | 采用 `context` 实现对 **InferencePool API** 可用性的检测；强制 `eppConfig` 必填、单副本、不可 multinode。 |
| Rust `lib` | 新增 `DYN_DISCOVERY_TIMEOUT_SEC` 环境变量并包装默认值，供 Operator/EPP 使用。 |
| 示例、文档、README、脚本 | 更新示例部署、变量前缀、安装步骤，提供 operator‑managed 与 standalone 两种部署方式。 |
| 其他 CRD (`DynamoComponentDeployment`) | 为 `EPPConfig` 增加 `configMapRef`、`config`（`EndpointPickerConfig`）字段。 |

---

## 🔍 技术洞察  

### 架构影响
1. **引入新组件类型**  
   - `ComponentTypeEPP` 将 **EPP** 视为与 `Frontend/Worker/Planner` 同等的第一类部署单元。  
   - EPP 本身不运行业务容器，而是 **gRPC** 服务（9002）供 **InferencePool** 调用，实现 KV‑aware 路由。  

2. **依赖 Gateway API Inference Extension**  
   - Operator 现在在 `DetectInferencePoolAvailability` 中通过 discovery client 检查 `inference.networking.k8s.io` API 是否注册。  
   - 需要在集群预装 `gateway-api-inference-extension`（包括 CRDs `InferencePool`、`EndpointPickerConfig`）。  
   - 若缺失，则 Webhook/控制器会直接报错，防止错误部署。

3. **RBAC 扩展**  
   - 新增 `epp-serviceaccount` / `epp-role`（或 `epp-cluster-role`）授予对 `inferencepools`、`pods`、`endpointslices`、`dynamoworkermetadatas` 的 **get/list/watch** 权限。  
   - 通过命令行参数 `--epp-cluster-role-name` 注入，保持与 `planner`、`dgdr-profiling` 的统一管理。

4. **资源协同**  
   - **ConfigMap**：当用户不提供 `ConfigMapRef` 时，Operator 会自动生成 `ConfigMap`，其中填充 `EndpointPickerConfig`（通过 `sigs.k8s.io/gateway-api-inference-extension/apix/config/v1alpha1`）。  
   - **InferencePool**：EPP Service 与 InferencePool 通过 `EndpointPickerRef`（指向 EPP Service）相连，实现“EPP ⟶ InferencePool ⟶ Frontend”。  
   - **Service**：为 EPP 暴露 gRPC 端口 `9002`（`epp-grpc`）与健康检查端口 `9003`，并保留原有 `system`（metrics）端口 `9090`。

5. **组件生命周期**  
   - `EPP` **强制单实例**（`replicas = 1`，`multinode = nil`），并在 `SharedSpecValidator.validateEPPConfig` 中做校验。  
   - 与 `ScalingAdapter` 不兼容，`FinalizeResource` 中仅在 `etcd` discovery 场景清理键，避免异常阻塞。

### 性能影响
| 维度 | 正向影响 | 潜在负面 |
| ---- | -------- | -------- |
| **请求分发** | KV‑aware 评分器根据缓存块大小与 KV 命中率挑选最优 worker，显著降低跨节点缓存失效，提升吞吐与 latency。 | 添加 **EPP** 侧容器以及 gRPC 通信增加额外网络跳转（约 0.1‑0.2 ms），对极低延迟场景有轻微影响。 |
| **资源消耗** | EPP 本身轻量（单容器，≈100 Mi CPU、200 Mi 内存），对集群总体占用微乎其微。 | 需要 **额外 ConfigMap、Service、RBAC** 对集群 API Server 产生额外对象数，极大集群可能出现对象配额压力。 |
| **启动时间** | `wait_for_discovery_sync` 超时可通过 `DYN_DISCOVERY_TIMEOUT_SEC` 调整，防止因底层 K8s 查询慢导致启动阻塞。 | 过短的 timeout 可能导致 **false negative**，导致组件在真实可用前报错退出。 |

### 安全考虑
1. **RBAC最小化**：  
   - EPP 角色仅授权 **read** 权限（`get, list, watch`）对 `inferencepools`、`pods`、`endpointslices`、`dynamoworkermetadatas`。  
   - 若集群使用 **NetworkPolicy**，需确保 EPP Service 与 Worker/Frontend 所在 namespace 互通。  

2. **EnvFiles 支持**：  
   - 大量 CRD 中 `env`、`envFrom` 已改为 `may consist of any printable ASCII characters except '='`，提升灵活性，但也可能让攻击者注入非法字符（如 newline）导致日志分割。建议在 Admission Webhook 中继续对 `EnvVar` 进行字符校验或使用

---

### feat: Implement priority-based KV cache offload filtering (#5563)
**SHA**: `6271a31` | 🔗 [查看提交](https://github.com/ai-dynamo/dynamo/commit/6271a31f0d3df374e02202cfd21ee7006c5baee5)

**🎯 变更类型**：功能增强（priority‑based KV 缓存离线过滤）  

**⚡ 重要程度**：🔴 高  

**📋 变更摘要**  
本次提交在 Dynamo 的 KV‑BM（键值块管理）子系统中加入了 **基于块优先级的离线（offload）过滤**。新增环境变量 `DYN_KVBM_HOST_OFFLOAD_PREFIX_MIN_PRIORITY`，以及在 Python‑Rust 接口链路中传递 `priorities` 信息，使得在将块从 GPU 卸载到 Host（甚至磁盘）时，可依据用户设定的阈值只保留高优先级块，提升 SSD 使用寿命并降低不必要的 I/O。实现涉及：

1. `SchedulerOutput` API 增加 `priorities` 参数。  
2. `Slot.apply_scheduler_output` 与内部 `offload_blocks` 接收并使用优先级。  
3. `BlockMetadata` 增加 `with_priority`，并在 `BasicMetadata` 中实现。  
4. 统一在 offload、onboard、disk 写入等路径传播优先级元数据。  
5. 大量单元测试验证元数据在 G1→G2→G3 循环、池回收等场景下完整传递。  

**🎯 影响范围**  
- **核心模块**：`lib/bindings/kvbm/src/block_manager/vllm/connector/*`、`lib/llm/src/block_manager/*`、`lib/llm/src/block_manager/pool/managed/inactive.rs`。  
- **Python 接口**：`kvbm_connector_leader.py`（向 Rust 端转发 priorities）。  
- **文档**：README 中新增环境变量说明。  
- **测试套件**：新增大量 unit test，覆盖元数据传递与池行为。  

**🔍 技术洞察**  

| 维度 | 影响 |
|------|------|
| **架构影响** | - 在 **Scheduler → Leader → Slot → Offload → Host/Disk** 全链路中加入优先级字段，实现 **跨语言、跨层的元数据一致性**。<br>- 新增 `offload_min_priority` 配置，实现 **全局离线策略**（一次过滤后，后续块全部不再 offload），保持 **块序列的连续性**，避免碎片化。<br>- 通过 `offload_terminated_at_block` 记录终止点，确保后续调度不误触发 offload。 |
| **性能影响** | - **正面**：阻止低优先级块频繁写入 SSD，可显著降低磁盘 I/O、延长 SSD 寿命，同时降低 Host ↔ Disk 的带宽占用。<br>- **负面**：在每次调度时需要校验 `priorities` 长度、遍历 `candidate_priorities`，增加 *O(N)* 辅助计算（N 为待 offload 块数），但该开销极小（数百块以内）。<br>- 引入 `offload_min_priority` 检查后，若阈值较高，实际 offload 量会下降，整体吞吐可能提升。 |
| **安全考虑** | - 变更仅涉及 **元数据**（优先级为 u32），不涉及敏感信息或外部输入的直接执行路径，安全风险极低。<br>- 环境变量默认 `0`（关闭过滤），即向后兼容，不会因配置错误导致功能失效。<br>- 代码在解析环境变量时使用 `parse().ok()`，避免 panic。 |
| **可维护性** | - 新增 `with_priority` 接口统一了 **“修改元数据后返回新实例”** 的模式，保持不可变风格，易于追踪。<br>- 通过 `Option<&[u32]>` 把优先级传递到 `apply_scheduler_output`，保持向后兼容（旧调用仍可省略）。<br>- 大量单元测试覆盖 **优先级传播 → offload → onboard → pool reset** 场景，降低后续回归风险。 |
| **兼容性** | - 默认阈值 `0`，旧版调用不提供 `priorities` 参数仍能正常工作。<br>- Python 接口已添加 `req.priorities` 参数，若上层不提供则为 `None`，保持兼容。 |

**⚠️ 潜在风险**  
1. **优先级数据不匹配**：若 `priorities.len()` 与 `block_ids.len()` 不一致（调用者 bug），会触发 `assert_eq!`，导致程序 panic。建议在生产环境前加入更友好的错误返回（Result）而非断言。  
2. **全局连续 offload 终止**：一旦因低优先级块终止 offload，后续新分配的块仍会被跳过，即使它们的优先级更高。这是设计决定（保持前缀连续），但在某些工作负载下可能导致高优先级块被误留在 GPU。可提供可选 “重新评估” 开关。  
3. **环境变量解析错误**：若用户误设非整数或负数，`parse().ok()` 会返回 `None` → 使用默认 `0`，可能出现意外的全量 offload。文档需要明确阈值范围（0‑100）。  
4. **跨语言序列化**：`SchedulerOutput::add_new_request` 与 `add_cached_request` 增加 `Option<Vec<u32>>`，若 Python 端使用旧版二进制协议发送请求，可能因字段缺失导致解码错误。需要确认 Python   `kvbm_connector` 已同步更新协议版本号。  

**💡 关注建议**  
- **测试覆盖**：在 CI 中加入 **负向用例**（长度不匹配、非法阈值）以确保不会出现 panic。  
- **可配置开关**：考虑增加 `DYN_KVBM_HOST_OFFLOAD_CONTINUE_AFTER_FILTER`（布尔），让用户在需要时允许在出现低优先级块后继续检测后续块。  
- **监控指标**：在 `metrics` 中加入 `offload_filtered_blocks_total`、`offload_terminated_at_block` 统计，帮助运维评估过滤效果。  
- **文档强化**：明确阈值取值范围、优先级的业务意义（如“对长上下文或关键 token 设高优先级”），并提供示例脚本。  
- **错误处理**：将 `assert_eq!` 替换为 `if prios.len() != block_ids.len() { return Err(SlotError::InvalidPriorities); }`，提升生产环境的稳健性。  

--- 

*总体而言，此次引入的优先级离线过滤是一次 **向前兼容且可配置的功能增强**，对 SSD 寿命、I/O 负载有明显正面影响，风险可通过上述建议进一步降低。*

---

### feat(sglang): integration with GPU Memory Service (#5664)
**SHA**: `a2fbda3` | 🔗 [查看提交](https://github.com/ai-dynamo/dynamo/commit/a2fbda3e1cc1b795174c43c65706304ac2ccf593)

**🎯 变更类型**：功能增强 / 架构变更  

**⚡ 重要程度**：🔴高  

**📋 变更摘要**  
本次提交为 **SGLang**（以及 **vLLM**）加入对 **GPU Memory Service (GMS)** 的深度集成。核心改动包括  
1. 在 `sglang` 启动参数中加入 `"gms"` 选项并在解析阶段将其注入 `--load-format`。  
2. `sglang/main.py` 与 `vllm/main.py` 在检测到 `load_format == "gms"` 时调用 GMS‑specific初始化函数。  
3. 新增 `gpu_memory_service/integrations/*` 包，提供：  
   - 公共工具 (`patches.py、utils.py`) 用于安全补丁、meta‑tensor 兼容、写‑读模式切换等。  
   - **SGLang** 的 `GMSModelLoader`，实现写模式(第一次进程加载权重) → 提交 → 切换到只读模式，后续进程直接从 GMS 元数据 materialize。  
   - **Hybrid memory_saver** 实现：权重使用 GMS allocator，KV‑cache 等仍走原有 `torch_memory_saver`。  
   - 对 `torch_memory_saver` 与 `ModelRunner` 的运行时补丁，使其在 GMS 环境下正确初始化、恢复内存占用统计。  
4. 对 **vLLM** 进行相同路径的改造（worker、model_loader、patches），并统一包结构。  
5. 为 GMS 集成编写了 **fault‑tolerance** 测试（SGLang sleep/wake、shadow‑engine failover），验证内存释放、恢复以及跨进程共享的正确性。  

**🎯 影响范围**  
- **组件**：`components/src/dynamo/sglang/*`、`components/src/dynamo/vllm/*`、`lib/gpu_memory_service/integrations/*`（common、sglang、vllm）  
- **运行时**：所有使用 `--load-format gms` 的 SGLang / vLLM 实例。  
- **测试套件**：新增的 fault‑tolerance SGLang 测试以及相关测试配置。  
- **构建系统**：`setup.py` 包路径更新，确保新模块随发行版打包。  

**🔍 技术洞察**  

| 维度 | 影响 & 说明 |
|------|-------------|
| **架构影响** | - 引入 **GMS 客户端** 作为 *可插拔的显存分配器*，在 **写‑模式**（第一进程）完成权重加载后，通过 **VA‑stable unmap/remap** 机制将权重映射到共享的虚拟地址空间，实现多进程跨 GPU 的零拷贝共享。<br>- 通过 `GMSMemorySaverImpl` 实现 **Hybrid** 策略：权重走 GMS，KV‑cache 仍使用 `torch_memory_saver` 的 mem‑pool。这样保持现有 KV‑cache 逻辑不变，降低侵入性。<br>- `patch_torch_memory_saver` 把原有单例的 `_impl` 替换为 GMS 实现，且通过属性 `gms_impl` 暴露给上层，兼容已有代码路径。<br>- 对 **ModelRunner** 的 `init_memory_pool` 进行补丁，使在只读模式下（权重已在显存外）仍能正确计算 `min_per_gpu_memory`（使用设备总显存），避免 KV‑cache 预留不足的回归。 |
| **性能影响** | - **权重共享**：跨进程不再重复拷贝权重，显存使用率显著下降（理论可节约 `模型权重大小`），尤其在多实例部署（shadow / primary）时收益更大。<br>- **写‑模式开销**：首次进程仍需要完整加载，且在提交前进行 `torch.cuda.synchronize()`，略有同步开销。<br>- **空闲显存释放**：`patch_empty_cache` 防止在 VMM 分配后调用 `torch.cuda.empty_cache` 导致段错误，同时在 `sleep` 场景中显存被真实释放，`get_gpu_memory_used` 可观察到显著下降。<br>- **KV‑cache** 仍走原有 mem‑pool，性能保持不变；在只读模式下 `ModelRunner` 使用设备总显存进行预算，避免因 `min_per_gpu_memory` 过小导致 KV‑cache OOM。 |
| **安全考虑** | - **参数校验**：`setup_gms` 检查 `enable_weights_cpu_backup` 与 `enable_draft_weights_cpu_backup` 两个互斥选项，防止在 GMS 环境下出现双重备份导致不一致。<br>- **资源隔离**：GMS 通过 **socket_path**（基于设备索引）进行进程间通信，默认只在同一机器同一 GPU 上共享；不存在跨机器攻击面。<br>- **补丁安全**：所有补丁均使用 **幂等** 检查 (`_patched` 标记) 防止多次导入导致函数指针混乱。<br>- **异常处理**：在模型加载、写模式提交等关键路径均抛出 `RuntimeError`，确保在失败时进程崩溃而非进入不一致状态。 |
| **可维护性** | - 新增的 `integrations/*` 代码采用 **模块化** 结构，公共逻辑抽取到 `common`，特定后端分别实现 `sglang`、`vllm`。<br>- 使用 **type‑checking** (`TYPE_CHECKING`) 与 **显式导入**，避免在运行时不必要的依赖。<br>- 通过 `setup_gms` 将验证、初始化统一在一个入口函数，降低后期改动点。<br>- 单元/集成测试覆盖了 **sleep/wake**、**shadow‑engine failover** 两大关键场景，提供回归保障。 |

**⚠️ 潜在风险**  
1. **首次写模式竞争**：多个进程几乎同时启动时，可能出现竞争获取 `RW` 锁的竞争，导致部分进程进入只读模式但权重尚未写入完成，进而在 `materialize_module_from_gms` 时出现空映射错误。  
2. **版本兼容性**：`torch_memory_saver` 与 `torch` 的内部实现若在未来的 PyTorch 版本中变更（如 `torch.cuda.empty_cache` 行为或 mem‑pool API），当前补丁可能失效或导致未捕获的异常。  
3. **资源泄漏**：`GMSMemorySaverImpl.finalize_write_mode` 调用 `finalize_gms_write` 后未显式关闭/释放 `allocator`（虽然切换到 read），在极端的进程重启路径中可能残留映射。  
4. **错误的 `socket_path`**：如果用户手动修改 `GPU_MEMORY_SERVICE_SOCKET` 环境变量或多 GPU 场景下 socket 路径冲突，可能导致不同设备的进程误共享同一 GMS 实例。  
5. **日志噪声**：大量 `debug/info` 日志在高并发负载下可能影响性能或掩盖真正的错误信息。  

**💡 关注建议**  

| 建议 | 说明 |
|------|------|
| **启动序列化** | 在多实例部署（shadow/primary）时，建议在调度层面确保 **写‑模式进程** 完全 **commit** 并 **切换到只读** 之后再启动其它只读实例，可通过脚本轮询 GMS 服务的 `mode == "read"` 或在 `setup_gms` 中返回状态。 |
| **锁竞争监控** | 为 `RequestedLockType.RW_OR_RO` 添加监控指标（如等待时间、冲突次数），在出现异常时提示 “请确保首次进程已完成加载”。 |
| **兼容性测试** | 在 CI 中加入基于最新 PyTorch（≥2.4）以及旧版本（2.2）运行的回归测试，确保 `patch_empty_cache` 与 `torch_memory_saver` 补丁仍然生效。 |
| **安全配置** | 将 GMS socket 文件的 **权限** 锁定

---

#### 🟡 中重要度变更 (4)

### refactor: read offload priority env var once at init (#5798)
**SHA**: `eef5e64` | 🔗 [查看提交](https://github.com/ai-dynamo/dynamo/commit/eef5e64523df25e917a970ddd1c26a1e16500758)

**🎯 变更类型**：重构  
**⚡ 重要程度**：🟡 中  
**📋 变更摘要**：将读取环境变量 `DYN_KVBM_HOST_OFFLOAD_PREFIX_MIN_PRIORITY` 的逻辑从每个 `VllmConnectorSlot` 实例化时迁移到 `ConnectorSlotManager` 初始化阶段，只读取一次并保存为 `offload_min_priority`，随后在创建子槽时传递该值。代码格式略作整理，去除了重复的 `std::env::var` 调用。

**🎯 影响范围**  
- `core` 模块下的 `lib/bindings/kvbm/src/block_manager/vllm/connector/leader/slot.rs`  
- `ConnectorSlotManager` 与 `VllmConnectorSlot` 的构造函数签名及内部字段新增 `offload_min_priority: u32`  

**💡 关注建议**  
1. **兼容性**：新字段加入后，所有直接实例化 `ConnectorSlotManager`/`VllmConnectorSlot` 的调用点必须传入该参数。检查项目内部是否还有手动 `VllmConnectorSlot::new` 的地方未更新。  
2. **错误处理**：环境变量解析仍在 `ConnectorSlotManager::new` 中使用 `unwrap_or(0)`，保持原有行为，但若未来需要更显式的错误报警，可考虑日志。  
3. **性能**：读取 env 的次数从 per‑slot 降至一次初始化，降低了系统调用开销，尤其在高并发创建大量槽时有积极效果。  
4. **测试**：新增字段后，单元测试需覆盖 `offload_min_priority` 的传递路径，确保阈值为 0 时仍保持旧行为，非零时触发 `priority filtering` 分支。  
5. **文档**：在 README 或部署文档中说明该环境变量的意义与默认值，以免用户误以为每个槽会重新读取。  

总体而言，此次重构提升了初始化效率且代码更易维护，风险主要在于未同步所有调用方导致编译错误。建议在 CI 中加入相应的构建检查。

---

### chore: Upgrade to Tensorrt-LLM 1.3.0rc1 (#5700)
**SHA**: `ba711cc` | 🔗 [查看提交](https://github.com/ai-dynamo/dynamo/commit/ba711cc1ac95dbf68685298dddf7373fdb7032b0)

**🛠 变更类型**：功能增强 / 重构  
**⚡ 重要程度**：🟡 中  

**🔎 变更摘要**  
- 将 TensorRT‑LLM 从 **1.2.0rc6.post2** 升级至 **1.3.0rc1**，同步更新依赖、文档、pyproject、Docker 镜像标签。  
- 在 `components/src/dynamo/trtllm/publisher.py` 中引入 **非阻塞轮询 + 自适应回退** 逻辑，拆分统计和 KV 事件的处理函数，加入超时/睡眠常量。  
- Dockerfile 与 `container/build.sh` 加入 **ABI 不兼容检测** 与 **TRTLLM_WHEEL_IMAGE** 支持，改为默认使用 NGC PyTorch 2.10、CUDA‑13.1、FlashInfer 等新包。  
- 其他小幅改动：文档、requirements、测试中请求间隔加长。

**📦 影响范围**  
- `components/src/dynamo/trtllm/publisher.py`（运行时统计/KV 事件发布）  
- `container/Dockerfile.trtllm`、`container/build.sh`（镜像构建、依赖解析）  
- `pyproject.toml`、`requirements.txt`、`docs/reference/support-matrix.md`（版本声明）  
- 测试 `tests/router/common.py`（请求节奏）

**💡 关注建议**  
1. **运行时延迟**：回退睡眠参数（`_PUBLISH_MIN_SLEEP_SEC`/`_PUBLISH_MAX_SLEEP_SEC`、`_KV_EVENTS_*`）会影响统计/事件上报的实时性，建议在实验环境进行基准测试并根据实际负载微调。  
2. **ABI 兼容性**：升级后部分 TRT‑LLM wheel 与 NGC PyTorch 可能不兼容；请确认 `TRTLLM_ABI_INCOMPATIBLE_VERSIONS` 列表已覆盖所有不兼容版本，且镜像中能成功拉取对应 `TRTLLM_WHEEL_IMAGE`。  
3. **Docker 构建**：新基础镜像标签 `25.12‑py3`、`25.12‑cuda13.1` 需要 CI 镜像缓存更新，确保构建时间不因缺失层而显著增加。  
4. **依赖同步**：新增的 `torchao`、`torchdata`、`torchtitan`、`flashinfer-python` 等包在运行时可能引入额外的二进制依赖，请在容器启动后执行 `python -c "import torch; print(torch.__version__)"` 验证版本一致性。  
5. **测试适配**：由于请求间隔改为 1 s，相关超时或性能断言可能需要同步更新。建议在 CI 中保留旧间隔的快速路径，以防回归。  

总体而言，升级为 TensorRT‑LLM 1.3.0rc1 能提供最新特性和更好的 CUDA 13 支持，但需要关注兼容性检测、回退策略对统计延迟的影响，以及 Docker 镜像层的完整性。做好以上验证后即可在生产环境平滑迁移。

---

### fix(operator): correct structured logging in restart status tracking (#5800)
**SHA**: `2b6d133` | 🔗 [查看提交](https://github.com/ai-dynamo/dynamo/commit/2b6d1338ca6b105b9842bebd9869376568c42c84)

**🎯 变更类型**：Bug 修复  
**⚡ 重要程度**：🟡 中  
**📋 变更摘要**：在 `deploy/operator/internal/controller/dynamographdeployment_controller.go` 中，修正了对 `PodCliqueSet` 状态追踪的结构化日志写法。原先使用 `logger.Info("... %s", dgd.Name)` 的占位符方式，导致日志字段未被正确解析；现在改为 `logger.Info("...", "name", dgd.Name, ...)`，确保字段以键‑值对形式记录，便于搜索与聚合。  

**🎯 影响范围**：  
- **Operator 控制器**：`DynamoGraphDeploymentReconciler` 中的 `getUpdatedInProgressForGrove` 方法。  
- **日志监控/观测**：所有依赖结构化日志的监控、告警与调试工具将看到更一致的字段名称（`name`、`generation`、`observedGeneration`）。  

**💡 关注建议**：  
1. **统一日志规范**：项目中其余 `logger.Info/Debug/Error` 调用检查是否仍使用旧的占位符形式，统一改为键‑值对，以免出现同类可观测性缺失。  
2. **测试覆盖**：若已有单元测试验证业务路径，考虑新增对日志字段的断言（例如使用 fake logger），确保后续改动不再破坏结构化输出。  
3. **监控适配**：确认现有 Grafana/Loki 等查询面板已使用新的字段名；若已有硬编码的正则或查询，需要相应更新。  
4. **回滚注意**：代码改动极小，仅影响日志，不会影响功能逻辑，回滚风险低，但仍建议在 CI 环境完整运行 Operator E2E 测试确认无意外。  

总体而言，此次改动提升了运维可观测性，风险可控，建议合并。

---

### fix: specifiy triton worker dynamo base [DYN-1984] (#5794)
**SHA**: `c5bb8df` | 🔗 [查看提交](https://github.com/ai-dynamo/dynamo/commit/c5bb8df68520ee2d60b77246204e9e9cf64926d9)

**🎯 变更类型**：Bug 修复  
**⚡ 重要程度**：🟡 中  
**📋 变更摘要**：在 `examples/backends/tritonserver/README.md` 中，将构建基础 Dynamo 镜像的命令由 `./container/build.sh` 修改为 `./container/build.sh --framework NONE`，明确指定不使用默认框架，以避免在构建 Triton worker 镜像时意外引入不相关的框架依赖。  
**🎯 影响范围**：  
- `examples/backends/tritonserver` 文档  
- 可能涉及 CI/CD 脚本或用户自行按照文档操作的构建流程  
- `container/build.sh` 参数解析（需确保 `--framework` 选项接受 `NONE`）  

**💡 关注建议**：  
1. 确认 `container/build.sh` 已实现 `--framework` 参数并在传入 `NONE` 时正确跳过框架层的安装，否则新文档会导致构建失败。  
2. 在 CI 流程或其他示例脚本中同步更新对应的构建命令，防止出现不一致导致的构建错误。  
3. 考虑在 README 中补充说明 `--framework NONE` 的含义及适用场景，帮助新手快速理解。  
4. 运行一次完整的 `./container/build.sh --framework NONE && cd examples/backends/tritonserver && ./build.sh`（若有）进行验证，确保构建产出符合预期。  

此更改主要是文档层面的修正，但如果底层脚本未兼容相同参数，可能导致用户在使用 Triton 后端时遭遇构建失败，建议在发布前进行一次端到端的构建验证。

---

#### 🟢 低重要度变更 (5)

### docs: update main router doc (#5812)
**SHA**: `ec04692` | 🔗 [查看提交](https://github.com/ai-dynamo/dynamo/commit/ec0469280c0a426b259120ebf2e1fc54a354cd5f)

**🎯 变更类型**：文档更新  
**⚡ 重要程度**：🟢低  
**📋 摘要**：扩充了 `router` 文档，新增事件传输模式、分布式推理、路由副本、繁忙阈值及 Python API 使用示例，并修正了几个代码示例的导入路径。

---

### chore: atomic file write (#5809)
**SHA**: `aa4ac94` | 🔗 [查看提交](https://github.com/ai-dynamo/dynamo/commit/aa4ac947c85cbabb9149be2409e0586a65e356dc)

**🎯 变更类型**：代码重构  
**⚡ 重要程度**：🟢低  
**📋 摘要**：在 `FileStore` 中实现原子写入，先写入以 `.tmp_` 前缀的临时文件再重命名，避免监视器看到不完整文件，并在事件处理和目录遍历时过滤这些临时文件。

---

### docs: sync fern with observability doc changes (#5795)
**SHA**: `ffe2d33` | 🔗 [查看提交](https://github.com/ai-dynamo/dynamo/commit/ffe2d333d66e28bcd5aabc14152c0b53c19ef154)

**🎯 变更类型**：文档更新  
**⚡ 重要程度**：🟢 低  
**📋 摘要**：同步 Fern 文档，删除了观测性指南中关于 Python Metrics API 的章节，保持文档与实际实现一致。

---

### ci: print 10 slowest pytest tests in container validation (#5779)
**SHA**: `2c36a58` | 🔗 [查看提交](https://github.com/ai-dynamo/dynamo/commit/2c36a588a326dfc12b757c3bfbd72850fbf5cfd7)

**🎯 变更类型**：配置调整  
**⚡ 重要程度**：🟢低  
**📋 摘要**：在 container‑validation 工作流的 pytest 命令中加入 `--durations=10`，以在容器验证阶段打印运行最慢的 10 条测试。

---

### docs: fix the statements for setting up the trtllm NIXL backends (#5763)
**SHA**: `8cdfe68` | 🔗 [查看提交](https://github.com/ai-dynamo/dynamo/commit/8cdfe682426343bf084ae760fa95854846925f7e)

**🎯 变更类型**：文档更新  
**⚡ 重要程度**：🟢 低  
**📋 摘要**：修正了 `trtllm` NIXL 后端说明，明确仅支持 UC X 后端并删除误导性环境变量示例，同时纠正了环境变量名 `TRTLLM_USE_UCX_KVCACHE` 的拼写错误。

---

