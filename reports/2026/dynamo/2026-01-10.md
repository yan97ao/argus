# 每日更新报告（2026-01-10）

## ai-dynamo/dynamo

| 提交时间 | 作者 | 提交信息 |
|----------|------|----------|
| 2026-01-10 07:34:41 | dagil-nvidia | docs: fix broken documentation links (#5330) |
| 2026-01-10 05:36:25 | Ryan McCormick | ci: Auto-label PRs based on changed files (#5292) |
| 2026-01-10 05:23:14 | Dmitry Tokarev | feat: vllm sglang cuda13 main (#5218) |
| 2026-01-10 05:15:16 | Dmitry Tokarev | fix: pass HF token to pytest container (#5326) |
| 2026-01-10 04:51:10 | Indrajit Bhosale | fix: Fix decode worker in vllm for qwen_vl models (#5281) |
| 2026-01-10 04:09:22 | Ryan McCormick | test: Expand time range for flaky recorder test to improve stability (#5315) |
| 2026-01-10 03:38:39 | Anant Sharma | docs: update readme for pip install ai-dynamo[trtllm] (#5312) |
| 2026-01-10 02:02:10 | jthomson04 | perf: Fix prefill router round robin (#5313) |
| 2026-01-10 02:01:08 | Hongkuan Zhou | fix: remove unused prometheus port args in trtllm planner DGD (#5314) |
| 2026-01-10 02:00:54 | Hongkuan Zhou | fix: add subcomponenttype to recipes missing this field (#5301) |
| 2026-01-10 01:13:53 | hhzhang16 | feat: mount model path to Profiler if specified (#5212) |

### 📊 统计摘要
> 本日共 11 个提交 | 🔴高 4 | 🟡中 4 | 🟢低 3
## 📋 目录

- [ai-dynamo/dynamo](#ai-dynamo-dynamo)
  - [📊 统计摘要](#-统计摘要)
  - [🔴 高重要度变更 (4)](#-🔴-高重要度变更-4)
    - [feat: vllm sglang cuda13 main (#5218)](#4a2235d)
    - [fix: Fix decode worker in vllm for qwen_vl models (#5281)](#5cd8005)
    - [fix: add subcomponenttype to recipes missing this field (...](#cf55e8b)
    - [feat: mount model path to Profiler if specified (#5212)](#ec5630e)
  - [🟡 中重要度变更 (4)](#-🟡-中重要度变更-4)
    - [ci: Auto-label PRs based on changed files (#5292)](#475999c)
    - [fix: pass HF token to pytest container (#5326)](#9bb7f10)
    - [perf: Fix prefill router round robin (#5313)](#b39aa54)
    - [fix: remove unused prometheus port args in trtllm planner...](#2e381b3)
  - [🟢 低重要度变更 (3)](#-🟢-低重要度变更-3)
    - [docs: fix broken documentation links (#5330)](#4f6996c)
    - [test: Expand time range for flaky recorder test to improv...](#403ff66)
    - [docs: update readme for pip install ai-dynamo[trtllm] (#5...](#b1fc99c)
#### 🔴 高重要度变更 (4)

### feat: vllm sglang cuda13 main (#5218)
**SHA**: `4a2235d` | 🔗 [查看提交](https://github.com/ai-dynamo/dynamo/commit/4a2235d1b995d38e5828942b3b16acb91176af76)

**🎯 变更类型**：功能增强  

**⚡ 重要程度**：🔴高  

**📋 变更摘要**：  
- 为 vLLM、SGLang 与 TRT‑LLM 引入 CUDA 13 支持，新增 CI 作业 `vllm-cuda-13`、`sglang-cuda-13`，并在已有的 `vllm`、`sglang`、`trtllm` 流程中加入 CUDA 13 标记的镜像构建与推送。  
- 重构 `.github/actions/docker-build`，将 `cuda_version` 参数设为必填并在缓存/标签中加入 `-cuda<major>` 前缀。  
- 更新容器构建脚本与 Dockerfile，以在 CUDA 13 环境下使用对应的基础镜像并条件性安装 NCCL、cuDNN 等依赖。  
- 在 `tests/basic/test_cuda_version_consistency.py` 中加入跨包 CUDA 主版本一致性检查；针对 CUDA 13 环境对 vLLM LMCache 相关测试做 `xfail` 标记。  

**🎯 影响范围**：  
- GitHub Actions 工作流与自定义 Action（`docker-build`、`pytest`、`container-validation-backends`）。  
- Docker 镜像标签、缓存键与构建参数（`cuda_version`、`torch_backend`）。  
- `container/Dockerfile.sglang`、`container/build.sh`、`container/deps/vllm/install_vllm.sh`。  
- CI 测试套件（新增一致性测试、vLLM 测试的 CUDA 13 条件性跳过）。  

**🔍 技术洞察**：

- **架构影响**：  
  - CI 流水线被显式划分为 CUDA 12 与 CUDA 13 两套路径，镜像标签从 `framework-arch` 扩展为 `framework-cuda<major>-arch`，提升了对不同硬件栈的可追溯性。  
  - `docker-build` Action 现在强制提供 `cuda_version`，防止因默认值缺失导致的错误镜像生成。  
  - 通过 `CUDA_VERSION_MAJOR` 动态拼装缓存/目标标签，令 BuildKit 缓存更细粒度，避免跨 CUDA 版本的误用。

- **性能影响**：  
  - CUDA 13 在 NGC 基础镜像中提供更新的驱动与库，理论上可为 vLLM、SGLang、TRT‑LLM 带来更高的吞吐与更低的延迟。  
  - 现阶段 LMCache 不兼容 CUDA 13，导致 vLLM 在该环境下会回退（测试 `xfail`），可能降低推理性能，需关注后续 upstream 更新。

- **安全考虑**：  
  - 仅将 `cuda_version` 设为必填，不涉及代码执行路径的安全风险。  
  - 条件性安装 NCCL、cuDNN 逻辑基于 `nvcc --version`，若容器内部 `nvcc` 被篡改可能导致错误依赖的拉取；建议在基镜像层面锁定这些二进制。  
  - 新增的环境变量检查（`CUDA_VERSION`、`NV_CUDA_*`）仅作信息提取，不会泄漏敏感信息。

**⚠️ 潜在风险**：  
1. **CI 破坏**：旧的工作流或手动调用 `docker-build` 时未传 `cuda_version` 将直接报错。  
2. **镜像缓存失效**：标签中加入 `-cuda<major>` 可能导致原有缓存失效，首次构建耗时显著增加。  
3. **LMCache 不兼容**：在 CUDA 13 环境下如果忘记 `xfail` 标记或业务代码强制启用 LMCache，可能导致运行时错误或性能回退。  
4. **ARM64 构建缺失**：vLLM 对 CUDA 13 的 ARM64 架构暂未提供 wheel，当前脚本会直接跳过 LMCache 并尝试源码构建，若依赖不完整会导致构建失败。  
5. **依赖安装条件**：`Dockerfile.sglang` 中仅在 CUDA 12 时安装 NCCL/cuDNN，CUDA 13 环境若需要这些库需在后续步骤补装，否则运行时可能缺失。  

**💡 关注建议**：  
- 为 `docker-build` Action 添加默认 `cuda_version`（如 `12.9`），并在文档中明确说明新参数的必填意义，以兼容已有脚本。  
- 在 CI 中为 CUDA 13 路径显式配置缓存预热，降低首次构建时延。  
- 跟踪 upstream vLLM LMCache 对 CUDA 13 的支持进度，考虑在 `Dockerfile` 中加入可选的 `LMCache` 安装开关。  
- 为 ARM64 触发的 CUDA 13 构建添加专门的错误提示或回退至 CUDA 12，以避免隐藏的构建失败。  
- 将 NCCL/cuDNN 的安装逻辑统一抽象到共用脚本，确保所有 CUDA 主版本均能获得必需的库。  
- 在 `test_cuda_version_consistency` 中加入对 `CUDA_VERSION_MAJOR` 环境变量的显式校验，防止因环境变量未设置导致误报。  

---  
以上分析覆盖了架构、性能、安全、风险与后续建议，供开发者在合并前评估与后续维护使用。

---

### fix: Fix decode worker in vllm for qwen_vl models (#5281)
**SHA**: `5cd8005` | 🔗 [查看提交](https://github.com/ai-dynamo/dynamo/commit/5cd8005c4505c23d7776695eb61c6b48f21de542)

**🎯 变更类型**：Bug修复  
**⚡ 重要程度**：🔴高  
**📋 变更摘要**：  
- 修复了在 VLLM **disaggregated**（拆分）部署下，Qwen‑VL 系列模型的 **decode** 工作进程无法正确处理多模态数据的问题。  
- 为 decode 端实现了专门的 **multimodal_data** 构造函数，生成基于 `request_id` 的唯一占位图像嵌入，以防止 prefix‑cache 错误匹配。  
- 调整了工作流，使只有非 Qwen‑VL 模型才在 decode 端替换已展开的 `prompt_token_ids`，保证 KV‑block 数目保持一致。

---

### 🎯 影响范围
- **components/src/dynamo/vllm/multimodal_handlers/worker_handler.py** – decode 请求构造与 prefilling 逻辑。  
- **components/src/dynamo/vllm/multimodal_utils/model.py** – 新增 `construct_qwen_decode_mm_data`（WAR）实现。  
- **examples/backends/vllm/launch/disagg_multimodal_epd.sh** – 启动脚本加入 `--enable-mm-embeds` 参数。  

### 🔍 技术洞察

| 维度 | 影响说明 |
|------|----------|
| **架构影响** | - 通过在 decode 端显式传递 `multi_modal_data`，实现了 **prefill ↔ decode** 之间的 **KV‑block 对齐**。<br>- 引入了针对 Qwen‑VL 的特殊路径，保持了原始（未展开）prompt，在 decode 端交由 VLLM 完成图像占位展开，实现了 **解耦的多模态解码**。 |
| **性能影响** | - 生成的占位 `image_embeds` 使用 `torch.randn`（CPU）一次性创建，开销极小。<br>- 由于占位嵌入仅用于 **decode** 侧的 mRoPE 初始化，实际推理计算仍由 prefill 完成，整体吞吐量基本不受影响。<br>- 该 WAR **关闭了 decode 侧的 prefix‑cache**（每次请求都使用唯一嵌入），但 decode 阶段的 KV‑cache 迁移已在 prefill 完成，收益损失可接受。 |
| **安全考虑** | - 没有引入外部输入直接执行的风险。<br>- 使用 `request_id` 进行随机种子生成，若 `request_id` 可被恶意控制，理论上可以影响随机占位向量的确定性，但这些向量仅用于缓存键匹配，不会泄漏或影响模型推理结果。 |
| **可维护性** | - 新增函数带有详尽文档，明确标记为 *WORKAROUND*，便于后续在 VLLM 支持完整 multimodal decode 时删除。<br>- 条件分支 `is_qwen_vl_model` 集中在一个位置，易于追踪修改逻辑。 |

### ⚠️ 潜在风险
1. **哈希不确定性**：Python 在不同进程间默认启用 hash 随机化 (`PYTHONHASHSEED`)，同一 `request_id` 可能在不同进程产生不同种子，导致 **同一请求在不同 worker 中生成不同占位嵌入**，进而影响 prefix‑cache 匹配（虽然意图是防止匹配，但不一致的种子可能引入难以排查的调试差异）。  
2. **请求 ID 冲突**：若业务层出现 `request_id` 重复，两个请求将得到相同占位向量，可能出现意外的 KV‑cache 复用。  
3. **CPU‑GPU 同步开销**：占位嵌入在 CPU 创建后会在 decode 端自动搬迁到 GPU，极少数情况下会产生一次额外的显存拷贝。  
4. **内存占用**：虽然占位向量尺寸与真实图像嵌入相同，但在 decode 端每个请求都会保留一份，若并发请求极高，显存压力可能略有提升。

### 💡 关注建议
- **确定性种子**：建议改为使用稳定哈希（如 `hashlib.sha256(request_id.encode()).intdigest() & 0xffffffff`）或直接基于 UUID 生成种子，避免 Python hash 随机化带来的跨进程不一致。  
- **唯一 Request ID**：在上层服务确保 `request_id` 全局唯一（可使用 UUID4），并在文档中标明该要求是防止 prefix‑cache 错误重用的前提。  
- **监控显存**：在多并发 decode 场景下监控 GPU 显存占用，必要时在 `construct_qwen_decode_mm_data` 中提供 `device="cpu"` 参数后显式转移到 GPU，以控制拷贝时机。  
- **单元/集成测试**：新增针对 Qwen‑VL 的 **prefill + decode** 端到端测试，验证 KV‑block 数目在两阶段完全一致，并确认不同 `request_id` 不会共享缓存。  
- **后续清理**：当 VLLM 原生支持 multimodal decode（不再需要占位嵌入）时，移除 `construct_qwen_decode_mm_data`，并恢复 `decode_worker` 对 `prompt_token_ids` 的统一更新逻辑。  

> 此次修复解除了 Qwen‑VL 在 disaggregated 部署下的 **decode 卡死 / KV‑block 对齐错误** 症状，为多模态大模型的生产落地提供了关键保障。

---

### fix: add subcomponenttype to recipes missing this field (#5301)
**SHA**: `cf55e8b` | 🔗 [查看提交](https://github.com/ai-dynamo/dynamo/commit/cf55e8b85aa3f4d212fd73ca8f4504732db5bbd7)

**🎯 变更类型**：Bug 修复  

**⚡ 重要程度**：🔴 高  

**📋 变更摘要**：在多个 `recipes/*/deploy.yaml` 中为 `decode` 与 `prefill` 两类 worker 补全了 `subComponentType` 字段（分别填入 `decode`、`prefill`）。此字段在 Dynamo 的调度、监控以及资源划分逻辑中用来进一步区分子组件类型，之前缺失导致这些子组件在平台内部被视为通用 worker，可能影响调度策略和监控标签的准确性。  

**🎯 影响范围**：  
- **deepseek‑r1**：`sglang`（8GPU / 16GPU）、`trtllm`、`vllm` 配置  
- **llama‑3‑70b**：`vllm`（多节点、单节点）配置  
- 相关的部署脚本、CI 检查以及任何依赖 `subComponentType` 进行标签/路由的内部组件  

**🔍 技术洞察**  

- **架构影响**：  
  - `subComponentType` 属于 Dynamo **Component** 元数据的细分层级。补全后，调度器能够在 **ComputeDomain**、**PlacementPolicy** 等层面精准识别 “prefill” 与 “decode” 的资源需求差异（例如预热 GPU、内存占用等），从而提升多租户/多任务调度的细粒度控制。  
  - 对现有的 **ComponentRegistry** 与 **MetricsCollector** 产生的标签体系有正向补全作用，避免出现 “worker” 统一标签导致的监控聚合误差。  

- **性能影响**：  
  - 直接的运行时性能基本不变（仅是配置层面的元数据）。  
  - 长远来看，调度器能够依据 `subComponentType` 做更合理的节点拆分与资源预留，可能会在高并发预填/解码场景下降低调度冲突和资源占用峰值，从而提升整体吞吐。  

- **安全考虑**：  
  - 此改动仅涉及声明性配置，不涉及代码路径或外部请求，安全风险极低。  
  - 需要确保平台在解析未知字段时具备 **前向兼容**（忽略或报错）机制，防止因 schema 不匹配导致的部署失败进而产生的服务不可用。  

**⚠️ 潜在风险**  

1. **Schema 不匹配**：如果运行时的部署解析器（如 `dynamoctl`、内部 Helm 渲染）未同步更新支持 `subComponentType`，可能会因字段未知而导致部署报错或被 silently 丢弃。  
2. **拼写/大小写错误**：当前统一使用小写 `decode` / `prefill`，若后续代码对大小写敏感，误差会导致标签不匹配。  
3. **默认值缺失**：在旧版配置或手动编辑时若遗漏 `subComponentType`，仍会出现同前的调度/监控不完整问题，需在文档或 CI 中添加必填校验。  

**💡 关注建议**  

- **Schema 同步**：确认 `dynamo` 项目的 `ComponentSpec`、`ComponentSchema` 已加入 `subComponentType` 字段的定义，并在所有 CI/CI‑Lint 检查中加入必填校验。  
- **回归测试**：在 CI 中加入针对这些 `recipes/*/deploy.yaml` 的渲染/部署测试，确保平台能够成功解析并在运行时生成相应的标签 `component=subComponentType=decode|prefill`。  
- **文档更新**：在 `recipes/README.md` 或官方部署手册中说明 `subComponentType` 的作用、可选取值以及迁移指南，提醒用户在自定义配置时务必填写。  
- **监控验证**：部署后检查 Prometheus / Grafana 的 **worker** 相关指标，确认已经出现新的 `subComponentType` 标签，并验证查询结果是否符合预期。  
- **灰度 rollout**：如集群规模较大，可先在单节点或测试环境里应用该改动，观察调度日志与资源分配是否出现异常后再全量推送。  

---  

此次补全字段虽是细微的配置改动，却对 Dynamo 的层级调度与可观测性产生了积极的修正效果。只要确保 schema 与验证同步更新，整体风险可控，且有望在后续大规模分布式推理部署中提升资源利用率与监控准确度。

---

### feat: mount model path to Profiler if specified (#5212)
**SHA**: `ec5630e` | 🔗 [查看提交](https://github.com/ai-dynamo/dynamo/commit/ec5630ead95b27e8949c21d41f7d402f0112ad32)

**🎯 变更类型**：功能增强 / 重构  

**⚡ 重要程度**：🔴高  

**📋 变更摘要**  
1. 为 Profiler 引入 **模型缓存 PVC 挂载** 功能，允许通过 `deployment.modelCache` 指定 PVC 名称、子路径及容器挂载路径，从而在大模型 profiling 时复用已有模型权重。  
2. 在所有配置层面统一 **camelCase** 为首选写法，同时保留 **snake_case** 向后兼容，实现 `_get` 与 `_camel_to_snake` 辅助函数。  
3. 新增 **GPU 自动发现**（`enableGpuDiscovery`）字段的 camelCase 版本，并同步更新 CRD、Helm Chart、文档及控制器代码。  
4. 完善解析器、控制器、测试以及文档，确保新字段在端到端流程中可用且向后兼容。

---

**🎯 影响范围**  
- `benchmarks/profiler/**`：配置文件、解析器 (`profiler_argparse.py`)  
- `deploy/operator/**`：CRD 定义、Reconciler 实现、验证逻辑、Helm Chart、示例 YAML  
- `docs/**`：API Reference、benchmark guide、planner 快速入门等  
- 测试套件：`dynamographdeploymentrequest_controller_test.go`，加入对 camelCase `useAiConfigurator` 的覆盖  
- 依赖的 CI/CD 流程（若使用 `make test`）也会受到解析器变更的影响  

---

**🔍 技术洞察**  

| 维度 | 影响描述 |
|------|----------|
| **架构影响** | - 在 **Profiler** 侧新增 `modelCache` 子结构，导致 `ProfilingConfig` 的层级更深。<br>- 控制器通过 `extractModelCachePVCConfig` 解析并在生成 `Job` 时动态添加 `Volume` 与 `VolumeMount`，实现 **PVC 挂载即插即用**。<br>- 通过 `_get`、`_camel_to_snake` 实现 **camelCase/snake_case 双向兼容**，对已有用户不产生破坏性改动。 |
| **性能影响** | - **模型缓存 PVC**：首次挂载会增加 PVC 挂载时间（几秒），但后续 profiling 将省去从 HuggingFace 下载的大量网络 IO 与磁盘解压，显著降低 **模型准备时延**（尤其对 >20 GB 大模型）。<br>- **GPU 自动发现**：在开启时会额外查询 K8s 节点资源，开销极低（API 调用一次），但会自动覆盖手动配置的 `min/maxNumGpus…`，从而避免不一致的搜索空间。 |
| **安全考虑** | - **PVC 挂载** 需要 `readOnly=true`，但仍需确保 **命名空间、RBAC**：Operator 必须具备 `get` / `list` PVC 权限，否则会在 `validateSpec` 中抛异常。<br>- **GPU 自动发现** 需要 **cluster‑scoped** 权限（Node 读取），若在受限 namespace 部署可能触发权限错误。<br>- 新增字段的 **默认值** 均为 `false` / 空字符串，避免意外开启。 |
| **可维护性** | - 通过统一的 `_get` 与 `_camel_to_snake`，后续若再加入新 camelCase 参数，只需在 `parse_config_string` 中添加对应默认值即可。<br>- 代码注释与文档同步更新，降低新成员理解成本。<br>- 测试覆盖率提升：新增对 camelCase `useAiConfigurator` 与模型缓存 PVC 验证的单元测试。 |

---

**⚠️ 潜在风险**  

1. **向后兼容性**  
   - 虽已保留 snake_case 读取，但若用户在 **CRD** 中混用两种风格，解析器会优先采用 camelCase，可能导致原本基于 snake_case 的默认值被意外覆盖。  
2. **PVC 不存在或权限不足**  
   - `validateSpec` 在找不到 PVC 时直接返回错误，导致 **DGDR** 创建失败；若 PVC 已存在但在不同 namespace（或未授予 `get` 权限），同样会中断工作流。  
3. **GPU 自动发现权限**  
   - 开启 `enableGpuDiscovery` 需要 **ClusterRole** 访问节点资源，若在受限权限的集群中使用，会导致控制器报 `Unauthorized`，并回退到手动配置（但未在代码中显式回退，仍会报错）。  
4. **挂载路径冲突**  
   - `DefaultModelCacheMountPath` 固定为 `/opt/model-cache`，若用户自定义 `deployment.modelCache.mountPath` 与容器已有卷冲突（如同名 Volume），Pod 创建会失败。  
5. **文档/示例不一致**  
   - 部分旧示例仍保留 `use_ai_configurator`（snake_case）或 `model_cache_pvc_*`，新手可能依赖过时示例导致配置错误。  

---

**💡 关注建议**  

| 对象 | 建议 |
|------|------|
| **Operator 维护者** | - 在 Helm Chart 中为 **ClusterRole** 添加 `nodes`、`persistentvolumeclaims` 的 `get/list/watch` 权限（仅当 `enableGpuDiscovery` 为 `true` 时生效）。<br>- 为新字段提供 **迁移指引**：在 Release Note 中说明 `use_ai_configurator → useAiConfigurator`、`model_cache_* → modelCache.* 的对应关系。<br>- 将 `extractModelCachePVCConfig` 的错误信息细化为 “PVC not found or insufficient permissions”。 |
| **用户 / 开发者** | - 如使用模型缓存 PVC，确保 PVC 已在目标 namespace 中创建且 **ReadOnly** 挂载足够的磁盘空间。<br>- 开启 `enableGpuDiscovery` 前确认 Operator 拥有 **cluster‑wide** 权限；否则使用手动硬件配置。<br>- 新增参数均支持 snake_case，推荐统一使用 **camelCase** 以获得 IDE 自动补全与文档一致性。 |
| **CI / 测试** | - 在 CI 中加入 **PVC‑mount** 场景的 e2e 测试（使用 `kind` + `local-path-provisioner`），验证 Job 能成功创建并运行。<br>- 为 `enableGpuDiscovery` 编写权限不足的负面测试，确保错误路径可被捕获并给出友好提示。 |
| **文档** | - 更新所有示例 YAML（包括 `benchmarks/profiler/deploy/*.yaml`）为 camelCase 版本。<br>- 在 `api_reference.md` 的字段表格中添加 “兼容 snake_case” 注记。<br>- 在 “模型缓存 PVC” 小节增加 **PVC 创建示例** 与 **RBAC** 说明。 |

--- 

**总结**  
本次提交在保持向后兼容的前提下，引入了重要的 **模型缓存挂载** 与 **GPU 自动发现** 功能，并统一了配置风格为 camelCase，提升了用户体验与运行效率。只要在部署前做好 PVC 及权限准备，这些改动将显著降低大模型 profiling 的准备时间，且对已有业务的破坏性极低。建议在下一次发布中同步更新 Helm Chart 权限、迁移指南以及 CI 验证，以确保平滑升级。

---

#### 🟡 中重要度变更 (4)

### ci: Auto-label PRs based on changed files (#5292)
**SHA**: `475999c` | 🔗 [查看提交](https://github.com/ai-dynamo/dynamo/commit/475999cf16b0b2b27e1e946c1750cd518396ebfa)

**🎯 变更类型**：CI / 自动化  
**⚡ 重要程度**：🟡 中  
**📋 变更摘要**：新增 GitHub Labeler 配置 (`.github/labeler.yml`) 与对应 workflow (`label-pr.yml`)，并在 `.github/filters.yaml` 中将该文件加入 ignore 列表。PR 将依据改动文件自动打上如 `backend::vllm`、`frontend`、`ci` 等标签，实现更细粒度的自动分类和审阅分配。  

**🎯 影响范围**  
- **CI/CD**：GitHub Actions 工作流（`Label PR`）会在 PR 打开、同步、重新打开时触发。  
- **项目治理**：`.github/filters.yaml`、`.github/labeler.yml` 与 `label-pr.yml` 共同决定标签规则。  
- **协作流程**：团队成员在审阅时会看到自动贴上的标签，影响审阅人分配、自动检查脚本（若基于标签筛选 PR）。  

**💡 关注建议**  
1. **路径校验**：确认 `labeler.yml` 中的 glob 与实际目录对应，尤其是组件路径（如 `components/src/dynamo/vllm/**`），防止误标签或漏标签。  
2. **标签冲突**：避免同一 PR 同时匹配多个互斥标签；如有必要，可在 workflow 中加入 `sync-labels: true` 或在文档中说明优先级。  
3. **CI 权限**：workflow 只需要 `pull-requests: write`，确保组织策略允许此权限；如有审计要求，可在 repo‑settings 中审查 token 范围。  
4. **回归测试**：在一个或多个示例 PR 中手动修改对应文件，验证标签是否按预期添加；检查 GitHub Actions 运行日志是否有错误。  
5. **文档更新**：在 CONTRIBUTING 或 PR 模板中说明自动标签的作用，帮助贡献者了解为何出现特定标签，减少误解。  

总体而言，此次改动提升了 PR 分类自动化，风险主要在标签配置不匹配或权限设置不当，建议在合并前完成一次覆盖性测试并同步更新项目文档。

---

### fix: pass HF token to pytest container (#5326)
**SHA**: `9bb7f10` | 🔗 [查看提交](https://github.com/ai-dynamo/dynamo/commit/9bb7f101078fc9b8bee51c03f4eb4c56ad0528df)

**🎯 变更类型**：Bug 修复  
**⚡ 重要程度**：🟡 中  
**📋 变更摘要**：在 GitHub Action `pytest` 的 Docker 运行命令中新增 `--env HF_TOKEN="${HF_TOKEN}"`，将 HuggingFace 访问令牌注入至测试容器，以支持需要私有模型或数据的测试用例。  
**🎯 影响范围**：  
- `.github/actions/pytest/action.yml`（CI 运行脚本）  
- 受影响的主要模块为 CI 测试流程及任何依赖 `HF_TOKEN` 的测试代码。  

**💡 关注建议**：  
1. **安全性**：确保 `HF_TOKEN` 作为 GitHub Secret 配置，并在工作流中使用 `secrets.HF_TOKEN` 传递，防止在日志中泄露。  
2. **容错**：若未配置令牌，容器将收到空值，可能导致部分测试失败。建议在脚本前加入检查或提供默认行为（例如跳过相关测试）。  
3. **文档更新**：在贡献指南或 CI 文档中说明需要设置 `HF_TOKEN` 才能运行全部测试，以免新贡献者误以为 CI 环境损坏。  
4. **回归测试**：在本地或临时 CI 环境中验证带/不带令牌的两套运行，确保不会因环境变量冲突影响其他测试。  

总体风险低，主要是提升私有模型测试的可用性，只要妥善管理令牌即可安全使用。

---

### perf: Fix prefill router round robin (#5313)
**SHA**: `b39aa54` | 🔗 [查看提交](https://github.com/ai-dynamo/dynamo/commit/b39aa54fdf215fb878ce8d86f3b884e2ec837553)

**🎯 变更类型**：性能优化  
  
**⚡ 重要程度**：🟡 中  
  
**📋 变更摘要**：在 PrefillRouter 中引入 `peek_next_worker`，用于在非 KV 路由下仅预览下一个工作节点而不立即递增轮询计数；同时在 PushRouter 实现对应的 `peek_next_worker`，并在成功使用预览的 worker 后显式调用 `select_next_worker` 以保持计数前移，避免 “双增计数” 导致的负载不均。  
  
**🎯 影响范围**：  
- `lib/llm/src/kv_router/prefill_router.rs`（PrefillRouter 逻辑）  
- `lib/runtime/src/pipeline/network/egress/push_router.rs`（PushRouter 轮询实现）  
  
**💡 关注建议**：  
1. **并发安全**：`peek_next_worker` 读取 `round_robin_counter` 使用 `Relaxed`，在高并发环境仍能保持一致性，但请确保不依赖强顺序保证。  
2. **随机路由**：peek 对 `Random` 模式会产生与 `select_next_worker` 不同的随机数，文档需明确说明此行为，以防误用。  
3. **KV 模式**：对 KV 路由仍返回 `None`，调用方应继续走原有路径，避免因 `None` 导致 panic。  
4. **回退路径**：若后续代码在检查后仍走到原 `select_next_worker`，计数会再次递增，确保所有分支都使用 `peek` 再 `select` 的配合逻辑。  
5. **测试覆盖**：加入轮询计数前后值的断言测试，验证在一次预览 + 提交后计数恰好前进一次。  

此改动提升了预填充阶段的负载均衡精度，风险主要在多线程计数的可见性和随机模式的行为差异，建议在上线前进行并发压力测试。

---

### fix: remove unused prometheus port args in trtllm planner DGD (#5314)
**SHA**: `2e381b3` | 🔗 [查看提交](https://github.com/ai-dynamo/dynamo/commit/2e381b3e6af76ae3aca6f2fb6c6179af505d7c21)

**变更类型**：Bug 修复  
**重要程度**：🟡 中  
**变更摘要**：在 `examples/backends/trtllm/deploy/disagg_planner.yaml` 中删除了 `--prometheus-port=9085` 参数，因该参数在当前的 TRT‑LLM planner 实现里未被使用，导致配置文件中出现冗余或误导信息。  

**影响范围**  
- `examples/backends/trtllm` 相关的部署示例。  
- 任何依赖配置文件解析的启动脚本或 CI，若对 `--prometheus-port` 有硬编码检查，可能出现错误。  
- 与 Prometheus 集成的监控流程（如果仍需要监控数据收集），仍会使用默认端口或其他显式配置。  

**关注建议**  
1. **代码路径检查**：确认主程序中 `clap`/`structopt` 等参数解析器已移除对应 flag，避免“未识别参数”错误。  
2. **默认行为验证**：如果 Planner 仍需要暴露 Prometheus 指标，确保在未提供 `--prometheus-port` 时会使用默认端口或通过环境变量配置。  
3. **文档同步**：更新 README、部署指南及 Helm chart 中的参数列表，防止用户继续复制旧示例导致启动失败。  
4. **回归测试**：在 CI 中加入一次不带 `--prometheus-port` 的完整部署跑通测试，验证 Planner 能正常启动且指标仍可被抓取（若有需求）。  
5. **兼容性提示**：若已有用户在自定义脚本中显式传入该参数，建议在发布说明中提示其已废弃，并提供迁移建议。  

总体而言，此次删除是一次清理性的 bug 修复，风险有限，只需确保参数解析、文档和 CI 同步即可平稳上线。

---

#### 🟢 低重要度变更 (3)

### docs: fix broken documentation links (#5330)
**SHA**: `4f6996c` | 🔗 [查看提交](https://github.com/ai-dynamo/dynamo/commit/4f6996c7335ad8f9fbe9b6ec9a145f086d5d0d51)

**🎯 变更类型**：文档更新  
**⚡ 重要程度**：🟢低  
**📋 摘要**：修复文档链接错误，新增“使用 NIXL 进行 KV 缓存传输”章节，并纠正 KV 路由文档中指向 Backend Guide 的链接。

---

### test: Expand time range for flaky recorder test to improve stability (#5315)
**SHA**: `403ff66` | 🔗 [查看提交](https://github.com/ai-dynamo/dynamo/commit/403ff6693fdd7446178c8db7f20223c72b36223e)

**🎯 变更类型**：测试修改  
**⚡ 重要程度**：🟢低  
**📋 摘要**：将 recorder 测试中对耗时的断言范围由 7–13 ms 放宽至 5–15 ms，以降低 flaky 测试的失败率。

---

### docs: update readme for pip install ai-dynamo[trtllm] (#5312)
**SHA**: `b1fc99c` | 🔗 [查看提交](https://github.com/ai-dynamo/dynamo/commit/b1fc99ca91cc74286769fecdb3083d781c8e76a3)

**🎯 变更类型**：文档更新  
**⚡ 重要程度**：🟢低  
**📋 摘要**：在 README 中将安装命令从 `uv pip install ai-dynamo[trtllm]` 改为 `pip install --pre --extra-index-url https://pypi.nvidia.com ai-dynamo[trtllm]`，并添备注说明因为 `tensorrt-llm` 的 git 依赖 `etcd3` 不被 `uv` 支持。

---

