# 每日更新报告（2026-02-11）

## ai-dynamo/dynamo

| 提交时间 | 作者 | 提交信息 |
|----------|------|----------|
| 2026-02-11 15:36:08 | Yan Ru Pei | feat: add router-level Prometheus metrics and centralize request tracking (#6146) |
| 2026-02-11 13:34:32 | Vladislav Nosivskoy | feat: support `reasoning_content` context management (DeepSeek v3.2 & GLM-4.7 & Kimi-2.5) (#6107) |
| 2026-02-11 13:22:53 | Keiven C | feat: add Prometheus auto and custom label injection for engine metrics (#5989) |
| 2026-02-11 10:17:57 | Karen Chung | test: refactor router e2e tests to use context managers for process lifecycle (#6088) |
| 2026-02-11 09:35:38 | Neal Vaidya | chore: add custom fern url (#6111) |
| 2026-02-11 09:19:51 | Keiven C | fix: harden KVBM integration tests with dynamic timeouts and metrics (#6105) |
| 2026-02-11 09:01:56 | GuanLuo | feat: add embedding transfer sender and receiver (#6098) |
| 2026-02-11 07:50:06 | Yuewei Na | refactor: move worker init logic from main.py to workers/ module (#6063) |
| 2026-02-11 07:10:18 | Graham King | fix: add python requirements for vllm tests (#6128) |
| 2026-02-11 06:58:30 | milesial | chore: remove media-nixl feature (#5940) |
| 2026-02-11 06:39:28 | Jonathan Tong | ci: inline fern publish step into fern-docs workflow (#6091) |
| 2026-02-11 06:39:11 | Graham King | feat(frontend): Use vllm for pre and post processing (#5544) |
| 2026-02-11 06:25:43 | devivasudevan | docs: Add AKS storage guidance for Dynamo caches (#5581) |
| 2026-02-11 06:24:28 | Graham King | chore: Add deploy as shared code owners on `examples/` folder. (#6133) |
| 2026-02-11 05:47:20 | Ran Rubin | ci: adding timeouts (#6062) |
| 2026-02-11 05:27:27 | Qi Wang | test: streamline Python test structure (#5684) |
| 2026-02-11 04:06:25 | Yuewei Na | feat: add video diffusion support to TRTLLM backend (wan_t2v only) (#5926) |
| 2026-02-11 04:05:42 | Karen Chung | fix: scale synthesized data length correctly for expected cache hit stats (#6117) |
| 2026-02-11 03:03:53 | mohammedabdulwahhab | fix: fix cross selection issue amongst services in DGD (#6113) |
| 2026-02-11 02:49:15 | MatejKosec | fix: prevent aiperf pipe hang in planner scaling test (#6099)<br>Replace PIPE-based stdout/stderr capture with direct file output in LoadGenerator.generate_load() to prevent orphaned aiperf child processes from blocking communicate() indefinitely<br>Add start_new_session=True so os.killpg() can kill the entire process tree on timeout (not just the main process)<br>Add unit test validating process-group kill on timeout<br>Fixes DYN-2086 |
| 2026-02-11 02:48:30 | Qi Wang | ci: apply static type check to vllm multimodal handlers (#6027) |
| 2026-02-11 02:46:47 | Qi Wang | refactor: add prefill_worker_utils in vLLM (#6017) |
| 2026-02-11 02:02:03 | hhzhang16 | fix: use actual service names for profiler logs and handle FileNotFoundError correctly (#6112) |
| 2026-02-11 01:53:34 | Indrajit Bhosale | fix: llama4 vllm agg multimodal script (#6103) |
| 2026-02-11 01:53:13 | Qi Wang | chore: consistent name -- MultimodalEmbeddingCache (#5962) |
| 2026-02-11 01:40:37 | Anant Sharma | ci: add kvbm bindings to pre merge checks (#6042) |
| 2026-02-11 01:24:45 | jh-nv | feat: base classes for the configuration system (#5975) |
| 2026-02-11 00:52:31 | Graham King | feat: Add metric tokenizer_latency_ms (#6092) |

### 📊 统计摘要
> 本日共 28 个提交 | 🔴高 13 | 🟡中 8 | 🟢低 7
## 📋 目录

- [ai-dynamo/dynamo](#ai-dynamo-dynamo)
  - [📊 统计摘要](#-统计摘要)
  - [🔴 高重要度变更 (13)](#-🔴-高重要度变更-13)
    - [feat: add router-level Prometheus metrics and centralize ...](#f46720c)
    - [feat: support `reasoning_content` context management (Dee...](#2cee89a)
    - [feat: add Prometheus auto and custom label injection for ...](#e18840c)
    - [fix: harden KVBM integration tests with dynamic timeouts ...](#2eb9e0d)
    - [feat: add embedding transfer sender and receiver (#6098)](#67d00b2)
    - [refactor: move worker init logic from main.py to workers/...](#be9adb3)
    - [feat(frontend): Use vllm for pre and post processing (#5544)](#4f99451)
    - [feat: add video diffusion support to TRTLLM backend (wan_...](#df2daad)
    - [fix: prevent aiperf pipe hang in planner scaling test (#6...](#4ad739d)
    - [refactor: add prefill_worker_utils in vLLM (#6017)](#20ccc9b)
    - [fix: use actual service names for profiler logs and handl...](#1aab7f6)
    - [feat: base classes for the configuration system (#5975)](#bf6840e)
    - [feat: Add metric tokenizer_latency_ms (#6092)](#f1bcb17)
  - [🟡 中重要度变更 (8)](#-🟡-中重要度变更-8)
    - [test: refactor router e2e tests to use context managers f...](#6fe2152)
    - [fix: add python requirements for vllm tests (#6128)](#c8ad4aa)
    - [chore: remove media-nixl feature (#5940)](#bf9e6d0)
    - [fix: scale synthesized data length correctly for expected...](#8707dc2)
    - [fix: fix cross selection issue amongst services in DGD (#...](#d8628cc)
    - [fix: llama4 vllm agg multimodal script (#6103)](#120ae64)
    - [chore: consistent name -- MultimodalEmbeddingCache (#5962)](#df8fd92)
    - [ci: add kvbm bindings to pre merge checks (#6042)](#fb62e2c)
  - [🟢 低重要度变更 (7)](#-🟢-低重要度变更-7)
    - [chore: add custom fern url (#6111)](#1cd3b72)
    - [ci: inline fern publish step into fern-docs workflow (#6091)](#9b1e461)
    - [docs: Add AKS storage guidance for Dynamo caches (#5581)](#93a2730)
    - [chore: Add deploy as shared code owners on `examples/` fo...](#77e7b72)
    - [ci: adding timeouts (#6062)](#b6911f7)
    - [test: streamline Python test structure (#5684)](#bd344cf)
    - [ci: apply static type check to vllm multimodal handlers (...](#ae09b92)
#### 🔴 高重要度变更 (13)

### feat: add router-level Prometheus metrics and centralize request tracking (#6146)
**SHA**: `f46720c` | 🔗 [查看提交](https://github.com/ai-dynamo/dynamo/commit/f46720c996064a997524a9ba419950492a72aaab)

**🎯 变更类型**：功能增强  

**⚡ 重要程度**：🔴高  

**📋 变更摘要**：  
本次提交在 KV Router 层引入了完整的 Prometheus 监控体系，并将请求追踪（`RequestTracker`）进行中心化、功能化。新增 **WorkerLoadMetrics**、**RoutingOverheadMetrics**、**RouterRequestMetrics** 三大指标模块，取代之前散落在多个文件的全局 `IntGaugeVec`。同时在路由、prefill、decode 各阶段统一记录 TTFT、ITL、ISL、KV‑Hit‑Rate 等关键性能数据，并在 Python 绑定层直接对相应的 gauge 进行观察。为此删除了旧的 `KV_HIT_RATE_SUBJECT` 事件发布逻辑，改为在 router 内部同步更新指标。  

**🎯 影响范围**：  
- `lib/llm/src/kv_router`（`kv_router.rs`、`metrics.rs`、`push_router.rs`、`prefill_router.rs`、`sequence.rs`、`scheduler.rs`）  
- `lib/llm/src/discovery/worker_monitor.rs`（全局 gauge 重构）  
- `lib/llm/src/http/service/metrics.rs`（暴露 `generate_log_buckets` 为 `pub`)  
- `lib/llm/src/protocols/common/timing.rs`（追踪结构改造、首次 token/完成时间的观测实现）  
- `lib/llm/src/protocols/openai/*/delta.rs`（去掉旧的 `record_first_token` 调用）  
- `lib/runtime/src/metrics/prometheus_names.rs`（新增 routing‑overhead 前缀与 label）  

**🔍 技术洞察**  

| 维度 | 影响概述 |
|------|-----------|
| **架构影响** | 1. **指标统一化**：`WORKER_LOAD_METRICS`、`ROUTING_OVERHEAD_METRICS`、`RouterRequestMetrics` 通过 `LazyLock`/`OnceLock` 单例管理，所有 router 相关代码改为直接调用这些对象，消除了跨模块的全局 gauge 导入和重复注册。<br>2. **请求追踪中心化**：`RequestTracker` 现在承担了 TTFT、ITL、ISL、KV‑Hit‑Rate、worker‑type/ID 记录以及对 per‑worker gauges 的 *一次性* 写入，减少了在不同层级（Python binding → Rust push router → sequence）散落的 `record_*` 调用。<br>3. **事件总线剥离**：原先通过 NATS/Redis 事件发布 KV‑Hit‑Rate (`KV_HIT_RATE_SUBJECT`) 的实现被删除，改为同步在 router 中更新工作负载 gauge，降低了跨进程通信的延迟与可靠性依赖。 |
| **性能影响** | 1. **额外原子操作**：`RequestTracker` 通过 `AtomicU64/AtomicU32`、`Mutex`、`OnceLock` 实现低开销的写入，基本不会成为热点。<br>2. **路由开销统计**：新增 `RoutingOverheadMetrics` 在每一次 `find_best_match` 中记录四段耗时，使用 `Histogram`（毫秒）并在每次路由结束后 `observe`，对吞吐量的影响在毫秒级别 (< 0.1 ms) 可接受。<br>3. **指标写入频率**：`WorkerLoadMetrics` 仅在 `ActiveSequencesMultiWorker::update_load` 触发，频率与现有的 active‑load 监控相同，未增加额外写入。<br>4. **取消 `KV_HIT_RATE_SUBJECT`**：去除 NATS 发布可以减少网络 I/O，提升调度路径的整体延迟。 |
| **安全考虑** | - 新增的 Prometheus 指标均使用 **只读**（`IntGaugeVec`）或 **只写**（`Histogram`）的注册方式，无可写外部输入，安全风险极低。<br>- `RequestTracker` 中的 `AtomicU64` 与 `AtomicU32` 在跨线程使用时不引入数据竞争。<br>- 代码中仍然保持对 `worker_type` 的硬编码字符串（`WORKER_TYPE_PREFILL`/`WORKER_TYPE_DECODE`），不涉及外部可控数据。<br>- 删除 NATS 事件发布后，系统对外部消息总线的信任边界缩小，安全面更好。 |
| **可维护性** | - 所有 Prometheus metric 定义集中于 `kv_router/metrics.rs`，新旧指标的差异一目了然，后续新增/修改指标只需在此文件添加对应结构。<br>- `RequestTracker` 通过明确的 API（`record_first_token`、`record_finish`、`record_isl`、`record_osl`、`observe_*_gauges`）提供统一入口，降低了遗漏更新 gauge 的风险。<br>- 通过 `pub fn generate_log_buckets` 暴露给外部，统一了 bucket 生成逻辑，减少了测试/文档不一致的可能。<br>- 删除了冗余的事件结构 `KVHitRateEvent` 与相关 `serde` 实现，使代码基底更简洁。 |
| **兼容性** | - 公开的 `generate_log_buckets`、`round_to_sig_figs` 现在为 `pub`，对外 API 幂等且向后兼容。<br>- 移除 `KV_HIT_RATE_SUBJECT` 及其发布逻辑，若有外部组件仍依赖该事件，需要同步迁移到 Prometheus 抓取方式。<br>- `kv_router` 中的 `KV_HIT_RATE_SUBJECT` 常量仍保留（未删除）但不再使用，保持编译兼容。 |

**⚠️ 潜在风险**  

1. **指标注册冲突**：`register_worker_load_metrics`、`register_routing_overhead_metrics` 必须在每个 `HttpServiceConfigBuilder` 实例仅调用一次。若在多实例或测试中重复注册，可触发 Prometheus `AlreadyRegistered` 错误，导致服务启动失败。  
2. **首次 token 观测竞争**：`RequestTracker::first_token_time` 仍使用 `OnceLock`，但在 `KvPushRouter`、`KvRouter`、`DeltaGenerator` 多处都有调用，若出现极端并发（同一请求被多路复用）可能导致 `record_first_token` 被多次尝试写入，虽然 `OnceLock` 会安全忽略，但对应的 `observe_first_token_gauges` 只会在第一次成功后执行，后续调用不会重复记录。需确认所有路径均在首次 token 产生后调用一次即可。  
3. **锁竞争**：`request_finish_time` 使用 `Mutex<Option<Instant>>`，在高并发的长流式请求中会在每个块结束时锁一次，可能产生微小的争用。若出现上万并发流式请求，建议评估是否改为 `AtomicU64` 记录纳秒时间戳。  
4. **旧代码残留**：`KV_HIT_RATE_SUBJECT` 仍在 `scheduler.rs` 中保留 `use` 注释去除后，可能在未来的代码合并中被误引用导致编译错误。请清理相关 `use` 与结构体定义。  
5. **监控数据异常**：`RoutingOverheadMetrics` 的 bucket 采用 `exponential_buckets(0.0001, 2.0, 18)`（0.1 µs 到 ~10 ms），如果路由耗时出现极端大于 10 ms（如模型加载、磁盘慢 I/O）将被聚合到最高 bucket，导致指标失真。可考虑在启动参数中允许自定义 bucket 上限。  

**💡 关注建议**  

- **注册检测**：在 `HttpServiceConfigBuilder::build` 中加入 `assert!(!registry.is_registered(metric_name))` 前置检查，或捕获 `AlreadyRegistered` 并记录警告而非错误退出。  
- **指标健康检查**：部署 Prometheus `alertmanager` 监控 `dynamo_routing_overhead_total_ms` 的 99th

---

### feat: support `reasoning_content` context management (DeepSeek v3.2 & GLM-4.7 & Kimi-2.5) (#6107)
**SHA**: `2cee89a` | 🔗 [查看提交](https://github.com/ai-dynamo/dynamo/commit/2cee89a05cfa5da4331fe18a5436639c8782f569)

**🎯 变更类型**：功能增强  
**⚡ 重要程度**：🔴 高  

**📋 变更摘要**  
1. 在 `async-openai` 的 `ChatCompletionRequestAssistantMessage` 中新增可选字段 `reasoning_content`，用于携带模型内部的思考链路（chain‑of‑thought）上下文。  
2. `llm` 入口层在流式返回时聚合 `reasoning_content`，并在后续请求的助手消息中把累计的推理内容写回。  
3. 为 DeepSeek‑V3.2、GLM‑4.7、Kimi‑2.5 等具备推理能力的模型补充相应的 prompt 渲染与单元测试，验证该字段在序列化/反序列化和实际渲染中的完整性。  

**🎯 影响范围**  
- `lib/async-openai/src/types/chat.rs`（核心 OpenAI 兼容模型消息结构）  
- `lib/llm/src/entrypoint/input/text.rs`（流式交互入口）  
- `lib/llm/tests/deepseek_v32_encoding.rs`（DeepSeek‑V3.2 编码与 prompt 渲染）  
- 受影响的上层调用方包括使用 Dynamo 构建的聊天/工具调用工作流，尤其是集成了上述支持推理的模型的项目。  

**🔍 技术洞察**  

- **架构影响**  
  - **数据模型扩展**：在统一的 OpenAI 消息结构中加入 `reasoning_content`，保持向后兼容（`Option` + `skip_serializing_if`），不影响已有模型。  
  - **流式处理链路**：在 `main_loop` 中累计 `reasoning_content`，并在后续请求的 `Assistant` 消息中回填；这在业务层形成了“记忆链式推理”机制，提升多轮对话的连贯性。  
  - **Prompt Formatter**：DeepSeek‑V3.2 的 `ThinkingMode` 通过 `DeepSeekV32Formatter::new_thinking()` 自动在渲染时插入 `<think>…</think>`，直接使用 `reasoning_content`，实现模型所需的内部思考上下文。  

- **性能影响**  
  - **CPU/内存**：仅增加一次字符串拼接 (`assistant_reasoning += reasoning`) 和一次可选值判断，开销极低，对流式吞吐量影响可以忽略。  
  - **网络**：`reasoning_content` 只在内部请求/响应中传递，未向终端用户暴露，不会额外增加网络流量。  

- **安全考虑**  
  - **信息泄露**：`reasoning_content` 可能包含内部计算细节或敏感中间结果。因为该字段会随请求重新发送给模型，若模型被第三方托管，需确认不泄露业务机密。  
  - **注入风险**：字段内容直接拼接进 Prompt（如 DeepSeek 的 `<think>` 包裹），若未对特殊字符进行转义，可能导致 Prompt 注入或模型行为异常。当前实现未做额外转义，需在上层对用户输入进行过滤或在 Formatter 中实现安全转义。  
  - **兼容性**：非支持该字段的模型（旧版 OpenAI、Azure OpenAI）会收到未知字段，依据 OpenAI 规范会被忽略，不会导致请求失败。  

**⚠️ 潜在风险**  
1. **误用导致泄漏**：开发者若将包含机密信息的内部推理直接放入 `reasoning_content`，会随请求发送至外部模型。  
2. **Prompt 注入**：未对 `reasoning_content` 中的尖括号、引号等特殊字符进行转义，可能破坏 DeepSeek‑V3.2 的 `<think>` 包装结构，引起解析错误或意外行为。  
3. **版本兼容**：未来若 OpenAI 官方在同名字段上做出定义，可能产生冲突。当前使用 `Option<String>`，但缺少显式的文档约定。  
4. **测试覆盖局限**：现有单元测试仅覆盖 DeepSeek‑V3.2 场景，其他模型（GLM‑4.7、Kimi‑2.5）未加入对应渲染与解析测试，可能出现模型特定差异未被发现。  

**💡 关注建议**  
- **文档与使用指南**：在 `README` 或 API 文档中明确 `reasoning_content` 的语义、适用模型以及安全注意事项（如不存放机密信息）。  
- **输入消毒**：在 `preprocessor::prompt` 层对 `reasoning_content` 实施基本的转义（如转义 `<`、`>`），或提供统一的 “安全包装” 方法。  
- **可配置开关**：为防止意外泄漏，可在入口层提供环境变量或配置项 `enable_reasoning_content`，默认关闭，只有显式开启后才收集并回传。  
- **跨模型兼容性测试**：补充 GLM‑4.7、Kimi‑2.5 的单元测试，确保它们在接收/渲染 `reasoning_content` 时行为一致。  
- **监控与日志**：在 `main_loop` 中加入调试日志（可通过 `tracing::debug!`），记录 `reasoning_content` 的长度或哈希值，帮助快速定位因推理内容异常导致的错误。  

通过上述措施，可在保持功能价值的同时，最大限度降低安全与兼容性风险，确保 Dynamo 在推理能力模型上的扩展平滑、可靠。

---

### feat: add Prometheus auto and custom label injection for engine metrics (#5989)
**SHA**: `e18840c` | 🔗 [查看提交](https://github.com/ai-dynamo/dynamo/commit/e18840cef3eb51339bf61b2e9b3088899b01d8a2)

⚠️ LLM分析失败（已重试3次）: API请求失败: HTTPSConnectionPool(host='integrate.api.nvidia.com', port=443): Read timed out. (read timeout=30)

*暂无分析*

---

### fix: harden KVBM integration tests with dynamic timeouts and metrics (#6105)
**SHA**: `2eb9e0d` | 🔗 [查看提交](https://github.com/ai-dynamo/dynamo/commit/2eb9e0dde709476fe8084ed4a28ebf648505d9a3)

**🎯 变更类型**：Bug修复 / 稳定性增强  
**⚡ 重要程度**：🔴高  
**📋 变更摘要**：此次提交对 KV‑BM（Key‑Value‑Based Memory）集成测试进行了一系列硬化改动，包括：  
1. 为指标抓取提供更加明确的错误信息并捕获连接异常；  
2. 引入基于环境变量的动态超时计算，避免 CI 中因执行时间波动导致的 flaky 测试；  
3. 为多模块测试显式分配并释放 metrics 端口，确保资源不泄漏；  
4. 调整多处 `pytest.mark.timeout` 参数，使其与实际测得的运行时保持安全余量（约 4 倍）。  

**🎯 影响范围**：  
- `tests/kvbm_integration/*`（所有 KV‑BM 相关集成测试）  
- `tests/kvbm_integration/common.py`（测试基础设施）  
- 受影响的 CI 工作流及本地开发者的测试执行  

---

### 🔍 技术洞察

| 维度 | 影响描述 |
|------|----------|
| **架构影响** | 仅涉及测试层代码，无生产代码变更。通过在 `BaseKVBMServer` 中动态分配 `metrics_port` 并在 `stop_server` 中统一回收，防止端口冲突，对整体服务启动/关闭流程提供了更好的资源管理。 |
| **性能影响** | 运行时主要是 **测试执行时间的伸缩**。新增的超时计算基于 `KVBM_MAX_ITERATIONS`、`KVBM_NUM_ITERATIONS`、`KVBM_REQUEST_DELAY` 等 env，确保在不同机器/负载下仍能提供足够的缓冲，避免因误判导致的提前终止。对业务代码本身无性能回退。 |
| **安全考虑** | 添加了对 `requests.exceptions.ConnectionError` 的捕获并抛出自定义 `RuntimeError`，使得在 metrics 端口配置错误时提供更明确的错误信息，降低排查成本。未引入新的网络交互或权限修改，安全风险极低。 |
| **可维护性** | - 通过环境变量驱动超时，使得 CI 配置可灵活调节；<br>- 将端口分配/回收逻辑集中在 `BaseKVBMServer`，降低重复代码；<br>- 增强的异常信息有助于未来调试。整体可维护性提升。 |
| **可靠性/稳定性** | 动态超时和端口回收显著降低了 **flaky tests**（间歇性失败）的概率；在 CI 环境中，测试不再因偶发的 metrics 端口不可达或时间略超导致整体 pipeline 失败。 |

---

### ⚠️ 潜在风险

1. **环境变量不一致**：如果 CI 或本地开发者未同步 `KVBM_MAX_ITERATIONS`、`KVBM_NUM_ITERATIONS`、`KVBM_REQUEST_DELAY`，计算出的超时可能偏小/偏大，导致误判。建议在 CI 脚本中显式声明默认值。  
2. **端口竞争**：虽然已实现动态分配并在 `stop_server` 中释放，但在极端并发启动的 CI 节点上仍可能出现短暂端口占用冲突（尤其是 `6880` 起始端口范围）。可考虑扩大端口池或使用 OS 自动分配（`port = 0`）。  
3. **异常信息泄露**：`RuntimeError` 中直接拼接了 `url`，在公开 CI 日志时可能暴露内部网络细节。风险极低，但可通过日志脱敏进一步强化。  

---

### 💡 关注建议

- **CI 配置**：在 `ci.yml`（或对应 workflow）中加入 `KVBM_MAX_ITERATIONS`, `KVBM_NUM_ITERATIONS`, `KVBM_REQUEST_DELAY` 的默认声明，防止因环境差异导致超时计算失效。  
- **文档更新**：在 `README` 或测试说明中补充 “如何使用环境变量缩短 KV‑BM 测试时间” 的章节，帮助新贡献者快速跑 CI。  
- **端口池监控**：若后续测试用例继续增加，建议统一使用一个端口分配服务（如 `pytest-xdist` 的 `worker_input`）或在 `allocate_port` 中加入冲突重试机制。  
- **错误信息标准化**：将 `RuntimeError` 包装为自定义异常类（如 `MetricsEndpointError`），统一错误处理与日志格式，便于未来的错误聚合与监控。  

--- 

**结论**：本次提交通过对 KV‑BM 集成测试的超时、端口管理和错误处理进行硬化，使得 CI 稳定性大幅提升，几乎不影响业务代码的运行时行为。风险可控，建议尽快合并并在 CI 中同步相应的环境变量配置。

---

### feat: add embedding transfer sender and receiver (#6098)
**SHA**: `67d00b2` | 🔗 [查看提交](https://github.com/ai-dynamo/dynamo/commit/67d00b24d73f4a0067c73b624c81278321559bb4)

⚠️ LLM分析失败（已重试3次）: API请求失败: HTTPSConnectionPool(host='integrate.api.nvidia.com', port=443): Read timed out. (read timeout=30)

*暂无分析*

---

### refactor: move worker init logic from main.py to workers/ module (#6063)
**SHA**: `be9adb3` | 🔗 [查看提交](https://github.com/ai-dynamo/dynamo/commit/be9adb3478e81b155887d67986b01d42228da8df)

**🎯 变更类型**：重构  
**⚡ 重要程度**：🔴高  

**📋 变更摘要**  
- 将原先 `components/src/dynamo/trtllm/main.py` 中的 worker 初始化逻辑抽离到 `dynamo/trtllm/workers` 包，实现 `init_worker` 统一调度入口，并新增 `llm_worker.py` 完整承载原本的 LLM 工作线程实现。  
- `main.py` 仅保留入口函数 `worker()`，其余全部委托 `init_worker`，从而降低单文件行数、提升代码可读性与可维护性。  

**🎯 影响范围**  
- `components/src/dynamo/trtllm/main.py`（启动入口）  
- `components/src/dynamo/trtllm/workers/__init__.py`（新增 `init_worker` 导出）  
- 新增 `components/src/dynamo/trtllm/workers/llm_worker.py`（原 LLM 初始化实现）  
- 相关 import 路径及 `__all__` 暴露  

**🔍 技术洞察**  

| 维度 | 影响 |
|------|------|
| **架构影响** | - 将工作线程的多模态/扩散/文本分支抽象为统一的调度函数 `init_worker`，实现 **职责单一** 与 **模块化**。<br>- 新的 `llm_worker` 模块成为 **核心业务代码**，未来可以独立演进（单元测试、文档化）。<br>- `__all__` 只暴露 `init_worker`，避免外部误用内部细节。 |
| **性能影响** | - 运行时行为保持不变，仅额外一次模块导入（`workers.llm_worker`）的微弱开销，可忽略。<br>- 代码拆分有助于 **局部编译/加载缓存**（Python import 缓存），对启动时间的影响几乎为零。 |
| **安全考虑** | - 未引入新依赖或外部网络调用，安全面向 unchanged。<br>- 通过统一入口，降低了遗漏 `await`、异常捕获不完整等人为错误的概率。<br>- 仍依赖原有的 `kvbm`、`tensorrt_llm` 等第三方库，若这些库有安全漏洞，影响范围保持不变。 |
| **可维护性** | - 代码行数大幅下降（`main.py` 从 517 行削减至 15 行），提升可读性。<br>- 业务逻辑集中在 `llm_worker.py`，便于 **代码审查、单元测试、文档生成**。<br>- 通过 `Modality.is_diffusion` 判定分支，未来可以轻松新增 `image_diffusion`、`audio_diffusion` 等模态。 |
| **兼容性** | - 只改变内部实现，外部调用仍是 `python -m dynamo.trtllm.main`（或对应 entrypoint），行为保持兼容。<br>- 需要确保打包阶段 `workers` 包被正确包含（已在 `__init__` 中导出）。 |

**⚠️ 潜在风险**  
1. **导入循环**：`llm_worker.py` 引入了大量原本在 `main.py` 中的模块；如果其他子模块在 import 时也引用 `workers.__init__`，可能触发循环导入导致 `AttributeError`。  
2. **遗漏的导出**：外部项目可能直接从 `dynamo.trtllm.workers` 导入 `init_video_diffusion_worker`（旧路径），而当前 `__all__` 只暴露 `init_worker`，会导致 `ImportError`。  
3. **异常路径差异**：原 `main.py` 在异常情况下直接 `sys.exit(1)`，新实现仍保留，但日志或异常传播路径可能有所变化，需要确认在容器/服务管理系统（systemd、K8s）中的退出码行为一致。  
4. **启动时延迟**：首次 import `llm_worker` 时会加载全部 tensorrt_llm 相关依赖，若节点上没有 GPU 驱动/库，异常会在 import 阶段抛出，影响启动监控信息的可读性。  
5. **测试覆盖不足**：大量逻辑迁移后，原有单元/集成测试可能仍指向旧文件路径，需要更新路径或重新运行确保覆盖。  

**💡 关注建议**  
- **回归测试**：在 CI 中执行全部 `trtllm` 相关的端到端测试，特别是不同 `modality`（text、multimodal、video_diffusion）启动场景。  
- **导入路径兼容**：如果社区已有 `from dynamo.trtllm.workers import init_video_diffusion_worker` 的用法，考虑在 `workers/__init__.py` 中保留向后兼容的别名（`init_video_diffusion_worker = init_worker`）或在 `README` 中提示迁移。  
- **监控启动日志**：在容器启动日志中加入 `init_worker` 的 modality 信息，确认调度分支正确。  
- **文档更新**：更新 `docs/architecture.md` 或相应部署文档，说明 `init_worker` 为入口点以及 `llm_worker` 的职责划分。  
- **异常处理统一**：考虑在 `init_worker` 中捕获并统一记录错误后统一 `sys.exit(1)`，避免散落在子模块的 `sys.exit` 影响统一日志。  
- **依赖检查**：在 `setup.cfg/pyproject.toml` 中确认 `workers` 包被正确打包，防止发布的 wheel 中缺失 `llm_worker.py`。  

通过上述措施，可最大化此次重构带来的可维护性提升，同时把潜在的启动/兼容风险降到最低。祝项目平稳过渡 🚀

---

### feat(frontend): Use vllm for pre and post processing (#5544)
**SHA**: `4f99451` | 🔗 [查看提交](https://github.com/ai-dynamo/dynamo/commit/4f99451bb01b765e3cc8572d867c194dd0e5845c)

**🎯 变更类型**：功能增强 / 架构变更 / 安全修复  
**⚡ 重要程度**：🔴 高  

**📋 变更摘要**  
本次提交在 Dynamo 前端引入了对 **vllm** 的前后处理集成，实现了基于本地 vllm 引擎的 **ChatCompletion** 预处理、采样参数映射、后处理（工具调用、推理块解析）全链路。为 Python 侧提供了 `ModelCardInstanceId` 类型与新的 **chat_engine_factory** 回调，使得用户可以在 Python 中自行实现聊天引擎的创建逻辑。相应的 Rust 代码、Python 绑定、模型发现、路由器等多处同步改造，以支持 KV、RoundRobin、随机等路由模式下的 vllm 流式输出。

**🎯 影响范围**  
- `components/src/dynamo/frontend/*`（`main.py`, `prepost.py`, `vllm_processor.py`）  
- Rust 绑定层：`lib/bindings/python/rust/*`（`lib.rs`, `entrypoint.rs`, `model_card.rs`）  
- 核心运行时：`lib/llm/src/entrypoint.rs`, `watcher.rs`, `http/input.rs`  
- 相关模块：`RouterConfig`, `EngineConfig`, `PythonAsyncEngine`, `ModelDeploymentCard` 公开新方法  
- Python SDK：新增 `ModelCardInstanceId`、`chat_engine_factory` 参数、`client2` 方法  

---

### 🔍 技术洞察  

| 维度 | 影响 | 说明 |
|------|------|------|
| **架构影响** | ★★★★★ | <ul><li>在 **EngineConfig::Dynamic** 中引入 `chat_engine_factory`，把模型实例标识 (`ModelCardInstanceId`) 传递给 Python 回调，实现 “Python → Rust → vllm → Rust → Python” 的闭环。</li><li>新增 `VllmProcessor` 把 vllm 的 `InputProcessor`/`OutputProcessor` 包装为 Dynamo 所需的 `AsyncGenerator`，在本机完成 Token 编码、prompt 渲染、后处理（工具调用、推理块），降低对 Rust 端的依赖。</li><li>路由层保持不变，仍可通过 KV、RoundRobin、随机三种模式；但在 KV 模式下现在会在本地创建 KV router **仅当** 需要本地 chat/completions pipeline 时才实例化，避免不必要的资源消耗。</li></ul> |
| **性能影响** | ★★★★☆ | <ul><li>前处理、后处理全部在前端机器使用 vllm 的高效实现（C++/CUDA），相比原先的 Python‑only 预处理提升数倍 (尤其在多模态/工具调用场景)。</li><li>在流式返回时，`StreamingPostProcessor` 直接复用 vllm 生成的 `DeltaMessage`，避免二次解析。</li><li>引入 `tokenizer` 与 `tool_parser`/`reasoning_parser` 的实例化成本，首次请求会有一次额外的初始化开销（模型加载、tokenizer 加载），但后续请求受益明显。</li></ul> |
| **安全考虑** | ★★★☆☆ | <ul><li>新增的 CLI 参数 `--chat-processor vllm` 需要在运行机器上安装 vllm 包；如果未正确检测或版本不兼容，启动会 abort，已加入明确的错误提示。</li><li>`map_finish_reason` 对未知 finish_reason 进行日志警告，防止出现未预料的状态。</li><li>后处理阶段对 `tool_calls`、`reasoning` 进行安全过滤（控制标记剥离），降低注入风险。</li></ul> |
| **可维护性** | ★★★★☆ | <ul><li>代码被拆分为独立文件 `prepost.py`、`vllm_processor.py`，职责清晰。</li><li>Python 绑定层对新类型 `ModelCardInstanceId` 直接映射到 Rust，保持一致性。</li><li>使用 `FlexibleArgumentParser` 兼容 vllm 自带的 CLI 参数，避免手动同步。</li></ul> |
| **兼容性** | ★★★★☆ | <ul><li>默认仍走原有 Dynamo 前处理路径，仅在 `--chat-processor=vllm` 时切换；对现有用户无破坏性影响。</li><li>旧的 `engine_factory` 参数已被 `chat_engine_factory` 替代，Python SDK 已同步更新，旧代码在未显式指定时仍保持兼容。</li></ul> |

---

**⚠️ 潜在风险**  
1. **依赖版本不匹配**：vllm 的 Python 包、CUDA 版本、模型权重格式必须匹配，否则会在 `setup_engine_factory` 阶段抛异常。  
2. **跨进程 GIL 切换**：`chat_engine_factory` 在 Python 中返回 `PythonAsyncEngine`，涉及跨语言 Future 转换，若回调内部阻塞（如同步 I/O）会导致事件循环卡住。  
3. **资源泄漏**：`VllmProcessor.generator` 在 `finally` 中调用 `output_processor.abort_requests`，若异常导致提前退出可能留下未清理的请求状态。  
4. **安全策略变更**：`_materialize_assistant_tool_calls` 对工具调用进行列表化，若上层协议在未来改变结构（非 list），可能导致兼容性回退。  
5. **KV 路由选择**：在 KV 模式下，仅当需要本地 chat/completions pipeline 时才创建 KV router；若误判（例如模型支持 chat 但未提供 `chat_engine_factory`），可能导致路由错误或性能下降。  

---

**💡 关注建议**  
1. **CI 测试覆盖**：加入 vllm 依赖的集成测试，包括不同 CUDA、模型格式的组合，确保 `--chat-processor=vllm` 能在 CI 环境成功启动并返回正确的流式响应。  
2. **文档升级**：在官方文档中明确列出 vllm 版本要求、安装指令、GPU/CPU 兼容性表，以及 `chat_engine_factory` 的示例实现。  
3. **异常监控**：在 `VllmProcessor.generator` 的 `finally` 分支加入日志记录，捕获未正常结束的请求，以便运维排查资源泄漏。  
4. **安全审计**：审查 `StreamingPostProcessor._is_control_only_content` 对特殊 token 的剥离逻辑，确保不会误删合法内容；必要时引入白名单白名单机制。  
5. **性能基准**：对比原有 Dynamo 前处理（Python）与 vllm 前处理在相同硬件上的吞吐量、延迟，提供基准报告帮助用户决定是否启用。  
6. **回退路径**：在启动参数中保留 `--chat-processor=dynamo`（默认）并在 `setup_engine_factory` 中捕获 `ImportError`，在出现依赖问题时自动回退到原实现，提升生产环境的容错性。  

> 总体而言，此次改动为 Dynamo 引入了高效、可扩展的本地 vllm 前后处理链路，显著提升了聊天场景的吞吐与灵活性。只要在部署前做好依赖、异常与安全的审查，风险可控，收益远大于改动成本。

---

### feat: add video diffusion support to TRTLLM backend (wan_t2v only) (#5926)
**SHA**: `df2daad` | 🔗 [查看提交](https://github.com/ai-dynamo/dynamo/commit/df2daaddab8ba289f0865f59b1eedb4c7f49b5cc)

**🎯 变更类型**：功能增强（新增 video‑diffusion（文本→视频）支持到 TensorRT‑LLM 后端）  
**⚡ 重要程度**：🔴 高  

**📋 变更摘要**  
- 在 `trtllm` 后端引入了 **视频扩散（video diffusion）** 模式，默认实现 `WanPipeline`（Wan‑T2V）并为后续模型预留注册机制。  
- 新增 `Modality` 枚举、`DiffusionConfig` 配置类、`DiffusionEngine` 通用包装、`VideoGenerationHandler` 请求处理器、对应 protobuf‑兼容的 Pydantic 协议以及 **worker 初始化**、CLI 参数、文档、单元测试。  
- 通过 `--modality video_diffusion` 自动切换到新 worker，保持原有 LLM（text / multimodal）路径不受影响。  

**🎯 影响范围**  
- `components/src/dynamo/trtllm/**`（constants、configs、engines、handlers、protocols、utils、workers、main）  
- `components/src/dynamo/trtllm/tests/`（新增 video‑diffusion 单元测试）  
- `docs/backends/trtllm/README.md`（文档更新）  
- 依赖的运行时库：`visual_gen`（TensorRT‑LLM 分支），`dynamo‑runtime` 必须提供 `ModelType.Videos`。  

---

## 🔍 技术洞察  

| 维度 | 影响分析 |
|------|----------|
| **架构影响** | 1. **Modality 抽象化**：新增 `Modality` 枚举，使后端能够在同一进程内承载多种生成模型（text、multimodal、video_diffusion）。<br>2. **Dispatcher 改动**：`components/src/dynamo/trtllm/main.py` 通过 `Modality` 判断分流到 `init_video_diffusion_worker` 或原来的 LLM worker，代码路径互不交叉，兼容性良好。<br>3. **统一 Engine 接口**：`DiffusionEngine` 与原有 `TensorRTLLMEngine` 同为 `Engine` 族，实现 `initialize`、`generate`、`cleanup`，便于后续统一管理（如 health‑check、metrics）。<br>4. **注册机制**：使用 `register_llm`（虽名为 LLM）注册 `ModelType.Videos`，实现与 Dynamo 发现系统的无缝对接。<br>5. **配置层**：`DiffusionConfig` 完全脱离 `Config`，但在 `workers/video_diffusion_worker.py` 中由主 `Config` 实例映射，保持 CLI 参数统一入口。<br>6. **协议层**：新增 Pydantic 的 `NvCreateVideoRequest` / `NvVideosResponse`，与 Rust 端协议保持 1:1，避免序列化不一致。 |
| **性能影响** | 1. **GPU 资源占用**：Diffusion 模型（Wan‑T2V‑1.3B）在 1‑2 张 A100/H100 上约 10‑12 GB VRAM，已在配置中加入 `max_height/width` 防 OOM。<br>2. **并发限制**：`VideoGenerationHandler` 在 `generate` 前使用 `asyncio.Lock`（`self._generate_lock`），确保 **单实例** 仅有 **一个线程** 进入 `engine.generate`，防止 `visual_gen` 的全局 CUDA‑graph/缓存冲突。<br>  → 这导致 **吞吐率受限**（在单卡上一次只能生成一个视频），但保证 **正确性**。<br>3. **编码路径**：使用 `imageio[ffmpeg]` 将帧写成 MP4，可在 `url` 或 `b64_json` 两种返回方式之间权衡，`encode_to_mp4_bytes` 避免磁盘 I/O，适合低延迟返回。<br>4. **CPU‑offload**：配置 `enable_async_cpu_offload` 预留 CPU 分层，若启用可减轻 GPU 显存压力，代价是额外的 PCIe 传输延迟。 |
| **安全考虑** | 1. **输入校验**：请求体使用 Pydantic，字段类型、范围在模型层已受约束；异常捕获后返回统一的错误结构。<br>2. **文件系统**：`output_dir` 直接拼接 `request_id.mp4` 保存，未对 `request_id` 进行路径清洗，但 `uuid4()` 生成的字符串仅含字母/数字/`-`，安全性可接受。<br>3. **外部依赖**：`visual_gen` 仍处于实验分支，未签名的 pip 包可能带来供应链风险，建议在受控 CI 镜像中锁定 commit。<br>4. **资源泄露**：`cleanup` 中调用 `torch.cuda.empty_cache()`，但在异常路径仍确保 `engine.cleanup()` 被调用，降低 GPU 泄漏概率。 |
| **可维护性** | - **模块化**：每个职责（配置、引擎、handler、协议、worker）独立文件，符合单一职责原则。<br>- **测试覆盖**：新增约 650 行单元测试，覆盖枚举、配置、大小解析、帧数计算、协议序列化以及 **并发安全**（锁的有效性）。<br>- **文档同步**：README 中明确实验性标签、依赖指引、CLI 示例，降低新手上手门槛。<br>- **向后兼容**：旧有 `--modality text|multimodal` 仍可正常运行，未改动已有 LLM 代码路径。 |

---

## ⚠️ 潜在风险  

| 风险点 | 可能后果 | 缓解措施 |
|--------|----------|----------|
| **依赖不匹配**：`visual_gen` 分支与 `dynamo-runtime` 需要特定版本（必须有 `ModelType.Videos`） | 启动时报错 `RuntimeError: ModelType.Videos not available`，导致服务不可用 | 在 CI 中加入版本检查；在文档中明确 `pip install dynamo-runtime>=X.Y`。 |
| **并发瓶颈**：`asyncio.Lock` 限制为单实例串行执行 | 吞吐量仅为单卡单视频，可能在高并发场景形成排队 | 后续可实现 **pipeline 并行池**（多实例）或在 `visual_gen` 中加入内部线程安全。 |
| **OOM**：用户自行指定的 `size` 可能超出显存限制 | 进程崩溃、GPU OOM 触发驱动重置 | 已在 `_parse_size` 中检查 `max_width/height`；建议在 CLI 加入 `--max‑width/height` 可调阈值，并在日志中提示 “size too large”。 |
| **路径 Traversal**：`output_dir` 可被恶意设置为系统目录 | 生成的视频文件写入敏感目录，造成信息泄露或覆盖系统文件 | 在 worker 初始化阶段对 `output_dir` 做绝对路径解析并限制在用户可写的根目录（例如强制在 `/tmp` 或自定义 sandbox），或使用 `os.makedirs(..., exist_ok=True)` 前进行 `os.path.abspath` 比对。 |
| **供应链风险**：`visual_gen` 未正式发布，使用 `pip install -e .` 可能拉取未审计代码 | 潜在后门或未修补的 CVE | 在企业环境使用内部镜像，锁定特定 commit SHA，或等待官方合并后再升级。 |
| **编码库缺失**：`imageio[ffmpeg]` 不存在或 ffmpeg 版本过旧 | 视频生成

---

### fix: prevent aiperf pipe hang in planner scaling test (#6099)
**SHA**: `4ad739d` | 🔗 [查看提交](https://github.com/ai-dynamo/dynamo/commit/4ad739dd32f5279a35a2bdd522eec7fc628b7263)

**🎯 变更类型**：Bug修复 / 性能优化 / 架构细化  
**⚡ 重要程度**：🔴高  
**📋 变更摘要**：  
本次提交针对 Planner 中的 `LoadGenerator.generate_load()` 实现进行修复，改为直接将 `aiperf` 的 stdout/stderr 写入文件，并在子进程创建时使用 `start_new_session=True` 使其成为独立进程组。超时场景下通过 `os.killpg()` 统一杀死整棵进程树，避免因子进程持有管道文件描述符导致 `communicate()` 永久阻塞。新增单元测试验证超时后进程组被正确杀死。

**🎯 影响范围**：  
- `utils/load_generator.py`（核心业务逻辑）  
- `tests/planner/test_load_generator.py`（新增单元测试）  
- 依赖 `LoadGenerator` 的 Planner 相关模块（如工作负载调度、性能基准测试）  
- CI 测试流水线（新增测试会在 pre‑merge 阶段执行）

**🔍 技术洞察**  

| 维度 | 影响说明 |
|------|-----------|
| **架构影响** | 1. 将 `aiperf` 的输出模式从 **管道** 改为 **文件**，降低了进程间 I/O 依赖，提升了对 **fork/exec** 子进程的容错能力。<br>2. 使用 `start_new_session=True` 让 `aiperf` 成为新的进程组首进程，能够通过 `os.killpg` 一次性清理整个子树，符合 UNIX 进程组管理的最佳实践。 |
| **性能影响** | - **正向**：避免了因子进程持有 PIPE FD 导致的无限阻塞，提升了超时检测的迅速性，整体测试执行时间更可预期。<br>- **负向**：写入磁盘文件会产生 I/O 开销，尤其在高并发、长时运行的场景下（大量日志）。但日志文件大小仅受 `aiperf` 输出量限制，且文件写入是 **顺序写**，对 SSD 环境几乎可忽略不计。 |
| **安全考虑** | - 使用 `os.killpg` 需要确保进程组仅包含本次生成的子进程，避免误杀同一用户下的其他无关进程。此实现通过 `start_new_session=True` 确保新组的唯一性，安全风险已被最小化。<br>- 对于文件写入路径 `artifact_dir` 已由调用方控制，未出现路径遍历风险。 |
| **可维护性** | - 代码逻辑更加直观：先创建文件句柄 → 启动子进程 → `wait_for` 超时 → 统一 kill。<br>- 删除了冗余的 `proc.communicate()` 以及后置写文件的代码块，降低了代码复杂度。<br>- 新增的单元测试覆盖了关键的超时‑杀进程组路径，提升了回归安全性。 |
| **测试覆盖** | - 新增 `tests/planner/test_load_generator.py`：模拟 `asyncio.create_subprocess_exec`、`asyncio.wait_for` 与 `os.killpg`，确保在超时条件下 **只** 调用一次 `os.killpg(target_pid, SIGKILL)`。<br>- 通过 `RuntimeError` 检验异常路径完整性。 |

**⚠️ 潜在风险**  

1. **误杀风险**：如果外部调用在同一用户下已经创建了自己的进程组并将 `pid` 与 `target_pid` 重复（极端情况），`os.killpg` 可能误杀。但 `start_new_session=True` 完全新建进程组，冲突概率极低。建议在生产环境中保持 `LoadGenerator` 的调用方式不变，避免手动指定 `pid`。  
2. **磁盘占用**：在极端负载下，`aiperf` 产生的大量日志会写入 `artifact_dir`，可能导致磁盘快速耗尽。可以在未来加入 **日志轮转** 或 **大小限制**（例如 `max_log_size`），或者在 CI 环境使用临时目录并在测试结束后清理。  
3. **跨平台兼容性**：`os.killpg` 与 `start_new_session` 在 Windows 上的行为与 POSIX 不完全相同。项目主要面向 Linux（GPU 容器），但若计划在 Windows 环境运行，需要额外适配或条件编译。  
4. **异常路径未捕获**：如果 `proc.wait()` 本身抛出异常（如 `OSError`），当前实现会直接向上传递，可能导致上层未能完成资源清理。建议在 `except Exception as e:` 中记录并继续执行清理逻辑。  

**💡 关注建议**  

1. **监控磁盘使用**：在长时间或大规模负载测试中，添加 CI 步骤或运行时监控，确保 `artifact_dir` 不会因日志堆积导致磁盘满。  
2. **跨平台检测**：若项目计划支持 Windows，编写对应的平台条件分支或在文档中声明仅在 POSIX 系统下保证正确性。  
3. **日志管理**：考虑在 `LoadGenerator` 中加入参数 `max_log_bytes` 或自动压缩日志的功能，以防止极端情况下产生过大的文件。  
4. **异常捕获强化**：在 `except asyncio.TimeoutError` 块外再包裹 `try/except`，捕获 `OSError`、`ValueError` 等可能在 `killpg`、`wait` 中出现的异常，并记录详细日志。  
5. **回归测试**：持续运行新增的单元测试，并在后续改动中保持对 `generate_load` 超时路径的覆盖率（如引入新的子进程参数时）。  

---  

**结论**：此提交通过改进子进程 I/O 与进程组管理，有效解决了 Planner 测试中因 `aiperf` 子进程残留导致的 Pipe 阻塞问题，提升了系统的鲁棒性和故障恢复能力。风险主要集中在磁盘占用和跨平台兼容性上，均可通过上述建议进行规避。整体来看，变更价值高，值得在主分支合并并在后续版本中保持该实现。

---

### refactor: add prefill_worker_utils in vLLM (#6017)
**SHA**: `20ccc9b` | 🔗 [查看提交](https://github.com/ai-dynamo/dynamo/commit/20ccc9b23017ffee38581e047433e8c1ca9d5f3c)

**🎯 变更类型**：重构  
**⚡ 重要程度**：🔴高  
**📋 变更摘要**：  
- 将原先在 `worker_handler.py` 中处理预计算多模态嵌入的加载、解码与合并逻辑抽离到新模块 `prefill_worker_utils.py`，并在 `__init__.py` 中导出。  
- 简化 `MultimodalDecodeWorkerHandler`，统一使用 `load_embeddings` 与 `accumulate_embeddings`，去除了冗余 `os`、`safetensors` 等直接引用。  
- 通过 `TRANSFER_LOCAL` 环境变量统一控制本地文件 vs NIXL RDMA 读取路径。

**🎯 影响范围**：  
- `components/src/dynamo/vllm/multimodal_handlers/worker_handler.py`（核心工作线程）  
- `components/src/dynamo/vllm/multimodal_utils/__init__.py`（公共 API）  
- 新增 `components/src/dynamo/vllm/multimodal_utils/prefill_worker_utils.py`（工具函数）  
- 相关的单元测试/集成测试（若有）会受到影响。

**🔍 技术洞察**：

- **架构影响**  
  - **模块化提升**：将嵌入加载与合并抽象为独立工具函数，职责更单一，`worker_handler` 只负责业务流程控制，符合单一职责原则。  
  - **可复用性**：其他可能的 prefill worker（如跨进程、跨机器）现在可以直接复用 `load_embeddings` 与 `accumulate_embeddings`，降低代码重复。  
  - **导出统一**：在 `__init__.py` 中显式导出新函数，形成清晰的公共接口，防止内部实现泄露。

- **性能影响**  
  - **功能等价**：原有逻辑未变，仅搬迁到函数中，运行时额外的函数调用开销可忽略（Python 层面 < µs）。  
  - **异步读取**：`load_embeddings` 仍保持 async RDMA 读取路径，未改变 I/O 模型；若 `TRANSFER_LOCAL=0`，仍会通过 `connector.begin_read` 触发零拷贝 RDMA，保持高吞吐。  
  - **缓存一致性**：`accumulate_embeddings` 对多图像/视频的拼接逻辑保持不变，但通过统一入口，易于后续加入批量合并优化（如提前预分配张量）。

- **安全考虑**  
  - **文件路径来源**：`load_embeddings` 仍依据 `mi.serialized_request` 读取本地 safetensors 文件。若攻击者能控制此字段，仍可能触发任意文件读取。项目已有的安全校验（如文件白名单或签名）需要在更高层继续保证。  
  - **环境变量**：`TRANSFER_LOCAL` 控制是否走本地文件路径，默认 `1`，在生产环境若误配置为 `0` 而未提供合法 `connector`，会引发运行时异常，而非安全漏洞。  
  - **没有新增外部依赖**，因此攻击面未明显扩大。

**⚠️ 潜在风险**  

1. **Connector 为 None 的路径**  
   - 当 `TRANSFER_LOCAL=0` 且调用方未传入有效的 `self._connector`，`load_embeddings` 会在 `descriptor = connect.Descriptor(embeddings)` 后抛出 `RuntimeError`，导致 worker 没有回退机制。  
2. **多线程/异步并发安全**  
   - `multi_modal_data` 仍是共享可变字典，若后续改为多协程并行处理多个 `mi`，需要保证 `accumulate_embeddings` 的原子性（当前实现假设单协程顺序）。  
3. **环境变量依赖**  
   - 部署脚本若未显式设置 `TRANSFER_LOCAL`，会使用默认值 1，可能在 RDMA 场景意外走本地文件路径，导致性能回退。  
4. **错误信息与调试**  
   - 新增的函数在异常路径只抛出 `RuntimeError`，缺少文件路径或 RDMA 错误的详细日志，调试成本略有提升。

**💡 关注建议**  

- **参数校验**：在 `load_embeddings` 入口加入对 `connector` 为 `None` 且 `TRANSFER_LOCAL==0` 的显式检查，给出友好提示。  
- **日志增强**：在读取本地 safetensors 前后记录文件路径、文件大小以及校验哈希，以便快速定位文件问题。  
- **并发保护**：如果未来计划在同一 worker 中并行处理多个 multimodal 输入，考虑使用 `asyncio.Lock` 包装 `accumulate_embeddings`，或改为返回新构造的 dict 再统一合并。  
- **单元测试**：覆盖以下情形：  
  1. `TRANSFER_LOCAL=1` 本地文件读取成功/文件不存在。  
  2. `TRANSFER_LOCAL=0` RDMA 路径成功/connector 为 None 报错。  
  3. 多图像拼接（Qwen‑VL）以及视频路径的分支。  
- **部署检查**：在 CI/CD 流程中加入对 `TRANSFER_LOCAL` 环境变量的显式声明检查，防止误配置。  
- **安全审计**：确认 `mi.serialized_request` 的来源是可信的，必要时在上层做签名校验或路径白名单，防止路径遍历攻击。  

---  

通过上述重构，代码结构更清晰、可维护性提升，同时保持原有性能与功能不变。只需注意上述风险点并加入相应防护，即可在生产环境安全、稳定地使用。

---

### fix: use actual service names for profiler logs and handle FileNotFoundError correctly (#6112)
**SHA**: `1aab7f6` | 🔗 [查看提交](https://github.com/ai-dynamo/dynamo/commit/1aab7f6b6d29acb5448c4f6b0ed79eb4a89198b4)

**🎯 变更类型**：Bug修复  
**⚡ 重要程度**：🔴 高  
**📋 变更摘要**：  
1. 将 Profiler 基准脚本中硬编码的 decode worker 名称改为从部署配置动态获取的真实服务名，保证日志路径的准确性。  
2. 在 `vllm` 配置修改器中为读取 KV‑cache 大小的逻辑加入 `FileNotFoundError` 以及解析异常的容错处理，防止因缺失日志或格式变化导致程序崩溃。  

**🎯 影响范围**：  
- `benchmarks/profiler/profile_sla.py`（Profiling 主入口）  
- `benchmarks/profiler/utils/config_modifiers/vllm.py`（KV‑cache 解析实现）  
- `benchmarks/profiler/utils/config.py` 与 `get_service_name_by_type`（新增导入）  
- 关联的 `dynamo.planner.defaults.SubComponentType`（保持兼容）  

**🔍 技术洞察**  

- **架构影响**：  
  - 只涉及 benchmark 脚本层面的路径构造逻辑，未改动核心库或运行时组件。  
  - 通过 `Config.model_validate` 与 `get_service_name_by_type` 统一服务名来源，提升了配置与代码之间的耦合一致性，降低了因手动维护常量映射导致的错误风险。  

- **性能影响**：  
  - 增加一次对配置对象的校验与服务名解析，开销极低（micro‑seconds 级）。  
  - 添加 `try/except FileNotFoundError` 以及异常捕获后继续执行，仅在缺失日志时返回 `0`，对整体 Profiling 流程的时间影响可忽略不计。  

- **安全考虑**：  
  - 处理 `FileNotFoundError` 防止因意外的文件缺失导致脚本异常退出，提升了运行时稳健性。  
  - 未引入外部输入或网络交互，暂无显著安全风险。  

**⚠️ 潜在风险**  

1. **服务名解析不一致**：若 `get_service_name_by_type` 返回的名称与实际 K8s pod 名称大小写或后缀略有差异（例如额外的 “-service” 前缀），仍会导致日志文件找不到，进而返回 0 KV‑cache，可能误导后续分析。  
2. **异常吞噬过宽**：在 `vllm.py` 中捕获了所有 `Exception`，如果日志内容出现意料之外的结构（例如新版本的 Dynamo 输出）而导致解析失败，会仅记录警告并返回 0，容易掩盖真正的兼容性问题。  
3. **依赖导入循环**：新增 `from benchmarks.profiler.utils.config import Config, get_service_name_by_type`，如果 `Config` 本身依赖于 profiler 运行时的某些模块，可能出现导入顺序冲突。  

**💡 关注建议**  

- **单元/集成测试**：为 `profile_sla.py` 中的路径生成逻辑编写测试，验证不同 `backend`、`SubComponentType.DECODE` 的组合能够得到正确的服务名和文件路径。  
- **日志与警告监控**：在 CI 中加入对 `logger.warning` 输出的检测，确保在真实环境下文件缺失或解析异常能够被及时发现，而不是默默返回 0。  
- **错误可见性**：考虑在返回 `0` 前附加一个可选的 `--strict` 参数，开启后若日志文件缺失或解析失败直接抛异常，帮助用户在调试阶段快速定位问题。  
- **文档更新**：在 Profiler 使用说明中注明现在采用配置驱动的服务名解析，并提醒用户在自定义部署时确保 `Config` 中的 service 名称与实际 K8s pod 名称保持一致。  

通过上述改动，Profiler 的可靠性得到显著提升，但仍建议加强测试和可观察性，以防止新的隐蔽错误进入生产基准。

---

### feat: base classes for the configuration system (#5975)
**SHA**: `bf6840e` | 🔗 [查看提交](https://github.com/ai-dynamo/dynamo/commit/bf6840e69f111e70ee381e13223973c9b57b6872)

**🎯 变更类型**：功能增强  
**⚡ 重要程度**：🔴高  

**📋 变更摘要**  
本次提交在 `components/src/dynamo/common/configuration` 目录下新增了一套面向 Python 组件的配置框架，包括  
1. **`ArgGroup` 抽象基类**：用于声明各业务域的 CLI 参数集合，实现“每个域负责自己的参数”。  
2. **`ConfigBase`**：从 `argparse.Namespace` 生成配置对象，自动填充类层次结构中的默认值，支持任意顺序的属性声明。  
3. **工具函数 `env_or_default`、`add_argument`、`add_negatable_bool_argument`**：统一处理环境变量默认值、布尔可否标记及帮助信息拼装。  
4. **单元测试**：覆盖环境变量解析、布尔标记的正负形式及帮助信息生成，确保核心逻辑的可靠性。  

目标是提供一个 **模块化、域驱动** 的配置系统，使得各组件能够声明所需的参数组，后端引擎能够安全地 “透传” 未识别的参数。

---

**🎯 影响范围**  
- `components/src/dynamo/common/configuration/*`（新加入的四个文件）  
- 任何使用 `argparse` 构建 CLI 的 Python 组件（例如执行器、后端适配层）将可能迁移至该框架  
- CI 测试套件：新增 `components/src/dynamo/common/tests/configuration/test_utils.py`  

---

**🔍 技术洞察**  

| 维度 | 影响 |
|------|------|
| **架构影响** | • 引入 **ArgGroup** 作为配置领域的明确边界，实现 **Domain‑Driven Configuration**，提升配置的可组合性与可维护性。<br>• `ConfigBase` 通过类继承链自动聚合默认值，降低手动拼装配置对象的出错概率。<br>• 通过 `add_argument`/`add_negatable_bool_argument` 统一 env‑var ↔ CLI 默认值逻辑，后续可在全局统一更改策略（如加入校验、脱敏）。 |
| **性能影响** | • 仅在程序启动时解析命令行与环境变量，额外的 Python `setattr` 与遍历 `__mro__` 开销微乎其微（O(N) ≈ 属性数量），对整体运行时性能影响可忽略。<br>• 对于大量子类（极端情况）可能产生略高的实例化成本，但仍在毫秒级。 |
| **安全考虑** | • 环境变量直接映射为配置值，若系统中存在敏感信息（如密钥）需明确标记并在文档中提示避免泄露。<br>• `env_or_default` 仅做基本类型转换，不执行任何安全校验；若后续加入复杂类型（如 JSON）需防止注入风险。 |
| **可测试性** | • 已提供覆盖率较高的单元测试，验证类型转换、正负布尔标记、帮助信息等关键路径。<br>• 仍缺少对 **ArgGroup** 实现类的集成测试，建议补充实际业务组件的迁移测试。 |
| **可维护性** | • 统一的帮助信息构造函数 `_build_help_message` 与目标名称解析 `_get_dest_name`，降低各组件自行拼装帮助文档的重复代码。<br>• 通过抽象 `ArgGroup.add_arguments` 强制所有实现保持 **副作用最小**（仅修改 parser），有助于未来的插件化或多解析器结构。 |

---

**⚠️ 潜在风险**  

1. **兼容性风险**  
   - 现有 Python 组件仍可能沿用原有手写 `argparse` 逻辑，若两套系统混用可能导致同名参数冲突或默认值不一致。  
2. **实现遗漏**  
   - `ArgGroup` 只定义了抽象接口，若未对所有业务域提供实现，运行时会出现 `NotImplementedError`。  
3. **环境变量优先级**  
   - 当前实现 `env_or_default` 只在环境变量未设置时返回默认值，若业务方期望 CLI 参数优先于 env，需在使用 `add_argument` 时注意 `default` 已被 env‑value 覆盖。  
4. **类型转换边界**  
   - 布尔转换仅识别 `true/false/1/0/yes/no/on/off`（大小写），不支持如 `"True "`（含空格）等常见用户输入，可能导致意外的默认回退。  
5. **帮助信息冗余**  
   - 自动拼装的帮助文本在大量参数时可能显得臃肿，需在文档层面提供过滤或分组方案。  

---

**💡 关注建议**  

1. **迁移指南**：在项目文档中加入 “从传统 `argparse` 迁移到 ArgGroup 模式” 的步骤示例，帮助现有组件平滑切换。  
2. **实现审查**：对所有业务域实现 `ArgGroup` 的类进行代码审查，确保 `add_arguments` 仅依赖 `parser`，不读取运行时状态。  
3. **统一默认策略**：考虑在 `add_argument` 中提供 `priority` 参数，明确 **CLI > env > code default** 的层级，防止误用已被 env 覆盖的默认值。  
4. **安全加固**：对可能包含敏感信息的参数（如 token、密码）在 `add_argument` 中加入 `sensitive=True` 标记，后续在 `__repr__` 或日志输出时自动遮蔽。  
5. **扩展测试**：补充对 `ArgGroup` 实现类的集成测试，验证组合多个 ArgGroup 时的解析顺序、冲突检测以及 “未识别参数透传” 行为。  
6. **CI 触发**：将新增的测试文件加入 CI 覆盖率统计，确保未来改动不破坏现有的 env/CLI 解析逻辑。  
7. **性能基准**：在启动大量组件的场景下（>100 个 ArgGroup）进行一次性解析耗时基准，确保不会出现启动瓶颈。  

通过上述建议可以最大化本次配置系统引入的可维护性和可靠性，降低因迁移或错误使用导致的潜在风险。

---

### feat: Add metric tokenizer_latency_ms (#6092)
**SHA**: `f1bcb17` | 🔗 [查看提交](https://github.com/ai-dynamo/dynamo/commit/f1bcb17542e508fb20b835421a8dbfbb296e4bdf)

**🎯 变更类型**：功能增强  

**⚡ 重要程度**：🔴高  

**📋 变更摘要**  
本次提交为 Dynamo 前端服务新增 **Tokenizer 延迟（毫秒）** 指标。通过在 `RequestTracker` 中记录 tokenization 耗时、在 `Preprocessor` 中在实际调用 tokenizer 时捕获该时长，并将其写入 Prometheus 的 `dynamo_frontend_tokenizer_latency_ms` 直方图。相应的 Python 绑定、Prometheus 名称常量、以及度量收集器均已同步更新，并新增单元测试验证采集路径。

**🎯 影响范围**  
- `lib/bindings/python` – 暴露新的 metric 常量。  
- `lib/llm/src/http/service/metrics.rs` – 添加 `tokenizer_latency` 直方图及其注册/观察逻辑。  
- `lib/llm/src/preprocessor.rs` – 在 tokenization 时记录延迟并将其写入 `LLMMetricAnnotation`。  
- `lib/llm/src/protocols/common/timing.rs` – `RequestTracker` 新增 `tokenizer_latency` 字段与对应 getter/setter。  
- 多处调用 `preprocess_request` 的代码已改为接受可选的 `RequestTracker`。  
- 单元测试覆盖新指标的注册和采样计数。

**🔍 技术洞察**  

- **架构影响**  
  - **度量层**：新增的 `HistogramVec` 属于前端服务度量子系统，与现有 `input_sequence_length`、`output_sequence_length` 等保持一致的注册、标签机制。  
  - **数据流**：`RequestTracker` 现在负责记录 tokenization 时长，`Preprocessor` 通过 `encode_with_timing` 将时长写入 annotation，随后 `ResponseMetricCollector` 通过 `observe_tokenizer_latency` 上报至 Prometheus。整个链路清晰，未改变业务逻辑路径。  
  - **可观测性**：引入 `operation` 标签（固定值 `"tokenize"`）为未来可能的 `"detokenize"` 提前预留，具备向下兼容的扩展性。

- **性能影响**  
  - **时间开销**：在 tokenization 前后各调用一次 `Instant::now()` 与 `elapsed()`，开销在微秒级（单次调用 0.5 µs 左右），对整体请求时延影响可忽略。  
  - **内存/CPU**：新增的 `OnceLock<Duration>` 与 `HistogramVec` 产生极小的堆分配；Histogram 桶配置（0.5 ms–512 ms）适度，除非出现极端高并发产生大量不同桶值，否则不会导致显著内存膨胀。  
  - **并发安全**：`OnceLock` 只写入一次（请求生命周期），读取多次安全，且 `ResponseMetricCollector` 使用布尔标记防止同一请求重复上报。

- **安全考虑**  
  - 该改动仅涉及内部可观测性数据的收集，不对外暴露任何敏感信息。  
  - 记录的时长是系统内部的纯数值，未涉及用户数据或身份信息，故不产生新的安全风险。

- **可维护性**  
  - 新增的 API（`preprocess_request(&self, request, Option<&RequestTracker>)`）已在项目所有调用点同步修改，保持编译通过。  
  - 通过 `operation` 子模块集中管理标签常量，未来若添加更多 tokenizer 相关操作，可统一扩展。  
  - 单元测试覆盖了 metric 注册、采样计数以及注解路径，降低回归风险。

**⚠️ 潜在风险**  

1. **遗漏 Tracker 传递**：若未来在某条代码路径调用 `preprocess_request` 而未提供 `RequestTracker`，对应的 tokenizer 延迟将不被记录，导致 metric 不完整。  
2. **高基数风险**：虽然当前只使用固定标签值 `"tokenize"`，但若不慎在其他位置使用动态标签（如模型名、语言等），可能导致 Prometheus 卡片数激增。  
3. **Histogram 桶选择**：现有桶上限 512 ms，若出现极端慢的 tokenization（> 1 s），会被聚集到 “+Inf” 桶，导致分布失真。  
4. **向后兼容**：Python 绑定新增常量不会破坏旧代码，但若用户硬编码 metric 名称列表，需要同步更新文档。  

**💡 关注建议**  

- **监控与告警**：在部署后观察 `dynamo_frontend_tokenizer_latency_ms_bucket` 的分布，确认桶范围能够覆盖真实延迟；如出现大量 `+Inf`，考虑扩展上限或添加更细粒度的桶。  
- **代码审查**：确保所有新增或修改的 `preprocess_request` 调用都显式传递 `tracker`（即使是 `None`），防止遗漏。  
- **文档同步**：更新开发者文档、Prometheus 导出说明以及 Python SDK 中的 metric 列表，说明新指标的意义与标签。  
- **未来扩展**：若计划追踪 `detokenize` 等逆向操作，直接在 `operation` 常量模块中添加对应值即可，保持一致性。  
- **性能基线**：在高负载场景下做一次基准测试，确保额外的 `Instant` 调用不会对整体吞吐产生可感知的影响。  

---

#### 🟡 中重要度变更 (8)

### test: refactor router e2e tests to use context managers for process lifecycle (#6088)
**SHA**: `6fe2152` | 🔗 [查看提交](https://github.com/ai-dynamo/dynamo/commit/6fe2152bfca7bb1fa681eae957b252c6cd0b7a53)

**变更类型**：测试重构 / 功能增强（引入 context‑manager‑style 的进程生命周期管理）  

**核心改动**  
1. **`tests/router/common.py`**  
   - 在 `send_request_via_python_kv_router` 中新增 `stream = None` 并在重试结束后显式校验，防止返回 `None` 时继续解码。  
   - 大量 `try … finally` 手动启动/关闭 `KVRouterProcess`、`ManagedProcess` 等改为 `with KVRouterProcess(...):`，统一交给 `__enter__/__exit__` 完成启动、健康检查和清理。  
   - 对 KV‑router、Mocker、SGLang、TRT‑LLM、vLLM 等测试同样改写为上下文管理器，去掉了显式的 `__exit__` 调用和 `finally` 代码块。  
   - 对 `KVRouterProcess` 构造函数新增 `blocks_threshold`、`tokens_threshold`、`enforce_disagg`、`durable_kv_events` 等可选参数的传递（部分测试已使用）。  

2. **测试文件**（`test_router_e2e_with_*`）  
   - 所有涉及外部进程的测试现在使用 `with … as …:` 语法，确保异常时仍能自动回收子进程。  
   - 统一了 `MockerProcess`、`DisaggMockerProcess`、`SGLangProcess`、`TRTLLMProcess`、`VLLMProcess` 的创建方式，省去重复的 `__enter__`/`__exit__` 代码。  

**影响范围**  
- **测试层**：`tests/router/` 目录下的所有 E2E 路由器测试（KV、mock、sglang、trtllm、vllm）。  
- **核心代码**：仅涉及 `tests/router/common.py` 中的 helper，未触及业务逻辑或库本身。  

**可能的风险 / 注意点**  
1. **上下文管理器实现**  
   - 确认 `KVRouterProcess`、`MockerProcess`、`SGLangProcess` 等类均实现了 `__enter__/__exit__` 并在 `__exit__` 中彻底终止子进程、清理临时目录。若某些路径（如异常前已返回）未进入 `with` 块，仍可能泄漏进程。  
2. **新增参数兼容性**  
   - `KVRouterProcess` 新增 `blocks_threshold`、`tokens_threshold`、`enforce_disagg`、`durable_kv_events` 参数。需要检查这些参数的默认值是否保持向后兼容，防止在未显式传参的旧调用处出现 `TypeError`。  
3. **`stream` 检查**  
   - 在 `send_request_via_python_kv_router` 中若所有重试都未得到流，会抛 `RuntimeError`。确保上层测试对该异常有相应断言或捕获，否则可能导致测试意外失败。  
4. **并发/资源竞争**  
   - 之前的 `try/finally` 结构在异常后会立刻执行清理；`with` 语法同样如此，但要注意在 `async` 环境中使用的类是否支持异步上下文管理（本次改为同步 `with`）。如果 `__enter__`/`__exit__` 包含阻塞等待，可能影响 `pytest-xdist` 的并行调度。  
5. **日志/调试信息**  
   - 移除显式的 `kv_router.__exit__(None, None, None)` 后，日志中可能少了“router stopped”之类的信息，若需要保留可在 `__exit__` 中加入统一日志。  

**建议**  
- 在 CI 中运行完整的 `router` 测试矩阵（所有 request_plane、store_backend、durable_kv_events 组合），确认没有残留进程或超时。  
- 给 `KVRouterProcess` 等类添加单元测试，验证 `__exit__` 在异常路径下同样能够成功终止进程。  
- 为 `send_request_via_python_kv_router` 增加注释，说明 `stream is None` 的异常语义，防止误用。  
- 若还有老代码直接调用 `KVRouterProcess(...).__enter__()`，考虑添加兼容层（例如在 `__init__` 中做一次 `self.__enter__()`）或在文档中明确推荐使用 `with`。  

总体来看，改动提升了资源管理的安全性和代码可读性，对业务逻辑没有直接影响，只需确保上下文管理器实现完整、默认参数兼容即可。祝测试通过！

---

### fix: add python requirements for vllm tests (#6128)
**SHA**: `c8ad4aa` | 🔗 [查看提交](https://github.com/ai-dynamo/dynamo/commit/c8ad4aa6734f0c8a3fc25c698ce3aef5ce7d4f59)

**🎯 变更类型**：Bug 修复  
**⚡ 重要程度**：🟡 中  
**📋 变更摘要**：在 `container/deps/requirements.test.txt` 中新增 `matplotlib==3.10.7`、`pmdarima==2.1.1`、`prometheus-api-client==0.6.0` 三个 Python 依赖，以满足 VLLM 相关测试的运行需求。  
**🎯 影响范围**：  
- **测试套件**：新增的依赖直接作用于 VLLM 测试用例。  
- **CI / Docker 镜像**：构建测试镜像时会拉取并安装这三包，导致镜像体积和构建时间略增。  
- **文档 / 依赖管理**：`requirements.test.txt` 是唯一的改动点，其他模块（核心 Rust 代码）不受影响。  

**💡 关注建议**：  
1. **兼容性检查**：在本地或 CI 中跑全套测试，确认新库与已有依赖（如 `pydantic、psutil`）没有冲突。  
2. **锁文件同步**：如果项目使用 `requirements.lock` 或 Poetry 等工具，及时更新锁文件，防止 CI 环境出现不可预期的版本。  
3. **镜像体积控制**：考虑在 CI 中使用 Alpine 或层缓存，减轻新增依赖带来的镜像增大。  
4. **许可证审查**：确认 `matplotlib`、`pmdarima`、`prometheus-api-client` 的开源许可证与项目兼容。  
5. **文档说明**：在 README 或测试文档中补充说明这些依赖的用途，便于贡献者快速搭建本地测试环境。  

总体而言，此次改动仅影响测试依赖，风险有限，建议在合并前完整运行 CI 以验证依赖解析与测试通过。

---

### chore: remove media-nixl feature (#5940)
**SHA**: `bf9e6d0` | 🔗 [查看提交](https://github.com/ai-dynamo/dynamo/commit/bf9e6d04aa4f3a447621b3837b073daa73bd126a)

**🎯 变更类型**：功能削减 / 重构  
**⚡ 重要程度**：🟡 中  
**📋 变更摘要**：本次提交彻底移除了 `media‑nixl` 特性，默认特性从 `["media‑nixl","block-manager"]` 改为仅 `["block-manager"]`，相应的 Cargo 条件编译、Docker 镜像变量、CI 检查以及文档中的提示均被删掉或改写。  

**🎯 影响范围**  
- `lib/llm`：`preprocessor.rs`、`media/loader.rs`、`media/rdma.rs`、`protocols/common/preprocessor.rs` 等多个文件的 `#[cfg(feature = "media‑nixl")]` 块全部取消，导致代码在没有 `media‑nixl` 时仍会编译。  
- `Cargo.toml`：`media-nixl` 不再是可选依赖，`flate2` 直接作为必选依赖。  
- Docker/CI：`container/context.yaml`、`Dockerfile` 参数 `ENABLE_MEDIA_NIXL` 删除；GitHub Actions 中的 Rust 检查不再启用 `media-nixl`。  
- 文档：README 中关于 `Dockerfile.frontend` 与 `media‑nixl` 不兼容的警告被简化。  

**💡 关注建议**  
1. **条件编译残余**：虽然大多数 `#[cfg(feature = "media‑nixl")]` 被去掉，但 `media/loader.rs` 中仍保留了 `use dynamo_memory::nixl::NixlAgent;` 等直接引用，若未来再次关闭 `media‑nixl`（比如在某些子模块中禁用），会导致编译错误。建议保留最小的 `#[cfg]` 包装或在 `Cargo.toml` 中将 `nixl` 设置为可选依赖。  
2. **依赖体积**：`flate2` 现在是强依赖，会在所有构建中引入 zlib，若业务上不再需要压缩，考虑恢复为可选依赖以降低镜像体积。  
3. **文档同步**：`container/README.md`、`media/README.md` 中仍提到 “Frontend media decoding (enabled with `--features media-nixl`)”，应全部删去或改写，以免误导用户。  
4. **CI 完整性**：确认 `cargo test --features=testing-nixl` 仍能通过；若 `testing-nixl` 依赖 `media‑nixl`，需要在测试中显式排除或更新依赖图。  
5. **回归测试**：建议在不启用 `media‑nixl` 的情况下完整跑一次 CI（包含 `block-manager`、`media‑ffmpeg`），确保所有路径（如 `preprocess`、`protocols`）在缺失 NIXL 代码时仍能正常运行。  

总体而言，改动实现了对 `media‑nixl` 的彻底剥离，降低了构建复杂度，但仍有少量未完全条件化的代码和文档残留，需要进一步清理，以防后续特性开启/关闭导致编译或运行时错误。

---

### fix: scale synthesized data length correctly for expected cache hit stats (#6117)
**SHA**: `8707dc2` | 🔗 [查看提交](https://github.com/ai-dynamo/dynamo/commit/8707dc2cf5c4d4ee0be0497d21c861029895127a)

**🎯 变更类型**：Bug 修复  
**⚡ 重要程度**：🟡 中  

**📋 变更摘要**  
在 `benchmarks/prefix_data_generator/synthesizer.py` 中新增 `osl_multiplier` 参数，用于按比例放大合成请求的输出序列长度（OSL），并在节点重新标号前同步放大节点的 `length` 属性，以修正缓存命中统计的偏差。CLI 亦同步支持该参数并在生成文件名时加入后缀。

**🎯 影响范围**  
- `Synthesizer` 类的初始化、节点长度处理、请求合成逻辑  
- 命令行入口 `main()`（新增参数、文件名后缀）  
- 受影响的基准脚本：`benchmarks/prefix_data_generator/*`  

**💡 关注建议**  
1. **整数溢出**：`length` 与 `output_len` 乘以倍率后直接转换为 `int`，在倍率较大时可能超出 `i32`/`usize` 范围，建议加上上限检查或使用 `u64`。  
2. **兼容性**：默认倍率为 `1.0`，保持原有行为；但文件名后缀会出现浮点表示（如 `oslx1.0`），若已有历史文件名依赖解析，需要确保下游脚本能正确处理。  
3. **测试覆盖**：补充单元测试，验证 `osl_multiplier` 为 `<1`、`>1` 时，`output_len` 与节点 `length` 均按预期缩放，并确认缓存命中率统计随尺度变化符合预期。  
4. **文档更新**：在 README/CLI 文档中说明新参数的含义与使用场景，尤其是对性能基准的影响。  
5. **性能影响**：倍率放大后生成的请求体积会增大，导致后续基准运行时间显著上升，建议在 CI 中加入限制倍率的快速跑测试。  

总体而言，此次改动修复了合成数据长度与缓存命中统计不匹配的问题，逻辑清晰，若完善上述细节可进一步提升稳健性。

---

### fix: fix cross selection issue amongst services in DGD (#6113)
**SHA**: `d8628cc` | 🔗 [查看提交](https://github.com/ai-dynamo/dynamo/commit/d8628cc453a03bdf4a1ee29eaf6c65da260a3f5e)

**🎯 变更类型**：Bug 修复  
**⚡ 重要程度**：🟡 中  

**📋 变更摘要**  
1. 为 `Service` 的 selector 新增 `KubeLabelDynamoComponent`，使用用户在 DGD 中声明的 `ServiceName`（如 `VllmDecodeWorker`），解决同类型组件（prefill / decode）在同一 DGD 下相互选中的冲突。  
2. 将 `Service` 名称统一为 DNS‑safe 的 `{dgd‑name}-{lowercase(componentName)}`（原先的 `componentName` 直接作为名称），提升可预期性。  
3. 调整 discovery 标签的写入逻辑：去掉 “非 frontend 才开启 discovery” 的判断，只要开启 K8s discovery 就标记 `DiscoveryEnabled=true`，简化路径并防止遗漏。  

**🎯 影响范围**  
- `deploy/operator/internal/controller/dynamocomponentdeployment_controller.go`（selector 生成）  
- `deploy/operator/internal/dynamo/graph.go`（service 名称与 selector）  
- 相关常量 `KubeLabelDynamoComponent` 的定义与使用  
- 依赖 Service selector 的其它控制器或监控/路由逻辑（如内部 DNS、service‑mesh）  

**💡 关注建议**  
1. **向后兼容**：新增标签会导致已有 Service 选择器失配，确保在升级时自动为已有 Service 补齐 `KubeLabelDynamoComponent`，或在升级指南中提醒用户执行 `helm upgrade --recreate-pods`。  
2. **常量定义**：确认 `KubeLabelDynamoComponent` 已在 `commonconsts` 中声明且加入文档，避免出现未定义错误。  
3. **测试覆盖**：补充单元/集成测试，验证同一 DGD 中不同 `ServiceName` 的 worker 能各自匹配到对应的 Pods，且 discovery 标签在所有开启的组件上均生效。  
4. **文档更新**：在 DGD schema 与用户手册中说明 `serviceName` 必须唯一，并解释新标签的作用。  
5. **监控告警**：若已有监控基于旧 selector，需同步更新监控规则，防止误报。  

整体来看，此次改动合理解决了跨服务相互选中的 bug，同时简化了 discovery 标签的处理，但需注意升级期间的 selector 迁移及相关文档、监控的同步更新。

---

### fix: llama4 vllm agg multimodal script (#6103)
**SHA**: `120ae64` | 🔗 [查看提交](https://github.com/ai-dynamo/dynamo/commit/120ae64916200f95cf8dbdbabf224fb212b4277d)

**🎯 变更类型**：Bug 修复  
**⚡ 重要程度**：🟡 中  

**📋 变更摘要**  
本次提交修正了 Llama‑4 在 vLLM 多模态聚合示例中的启动脚本。原有的 `agg_multimodal_llama.sh` 被删除，改为统一使用 `agg_multimodal.sh` 并通过 `--model` 参数显式指定模型。为模型 `meta-llama/Llama-4-Maverick-17B-128E-Instruct-FP8` 添加了专属的启动参数 `--tensor-parallel-size=8 --gpu-memory-utilization 0.85 --max-model-len=108960`，并同步更新了文档页面。

**🎯 影响范围**  
- `examples/backends/vllm/launch/agg_multimodal.sh`（脚本逻辑）  
- 已删除的 `examples/backends/vllm/launch/agg_multimodal_llama.sh`（不再被引用）  
- 文档 `docs/features/multimodal/multimodal_vllm.md` 与 `fern/pages/features/multimodal/multimodal-vllm.md`（使用示例的说明）  

**💡 关注建议**  
1. **参数正确性**：`--max-model-len=108960` 与之前注释的 `--max-model-len=208960` 不同，需确认该数值是 Llama‑4 正确的上下文长度上限，防止因长度不足导致截断错误。  
2. **并行配置**：`--tensor-parallel-size=8` 硬编码在脚本中，若用户的硬件配置不满足 8 卡并行，将导致启动失败。建议在脚本中加入检测或提示，或提供可覆盖的环境变量。  
3. **向后兼容**：删除 `agg_multimodal_llama.sh` 之前的用户可能已有该脚本的自定义修改。可在仓库 README 中添加迁移指南，提醒使用 `agg_multimodal.sh --model …` 的方式。  
4. **测试覆盖**：确保 CI 中包含对该模型的启动路径测试，验证多模态编码/前缀工作流能在新脚本下正常运行。  
5. **文档同步**：检查所有引用该脚本的页面（包括外部博客、教程）是否已更新，以免出现 “找不到脚本” 的错误提示。  

整体来看，此次改动 restores 正确的启动方式，提升了示例的一致性，但需要确认新参数的硬件/模型适配性并提供相应的使用提示。

---

### chore: consistent name -- MultimodalEmbeddingCache (#5962)
**SHA**: `df8fd92` | 🔗 [查看提交](https://github.com/ai-dynamo/dynamo/commit/df8fd92b18ad0fbd860687a1f2ef4ac8f5b4b451)

**🎯 变更类型**：重构（命名统一）  
**⚡ 重要程度**：🟡 中  
**📋 变更摘要**：将原先的 `EncoderCacheManager` 更名为 `MultimodalEmbeddingCacheManager`，并在所有内存、异步封装、TRT‑LLM 请求处理以及对应单元测试中同步更新引用、`__all__` 导出以及示例脚本的参数说明。  

**🎯 影响范围**  
- `components/src/dynamo/common/memory/`（缓存实现、`__init__`）  
- `components/src/dynamo/common/multimodal/async_encoder_cache.py`（异步包装）  
- `components/src/dynamo/trtllm/*`（embedding fetcher、请求处理工厂及具体 handler）  
- 所有涉及缓存的单元测试文件  
- 示例脚本参数 `--dyn-encoder-cache-capacity-gb` 对应的类名文档  

**💡 关注建议**  
1. **向后兼容**：当前直接删除 `EncoderCacheManager` 会导致外部项目在升级后编译错误。建议在 `memory/__init__.py` 中保留别名 `EncoderCacheManager = MultimodalEmbeddingCacheManager` 并在文档中标记为已废弃，以平滑迁移。  
2. **文档同步**：检查项目网站、API 文档以及 README 中的类名和示例代码，确保全部使用新名称。  
3. **版本号**：此类破坏性改名应在 `pyproject.toml` 中提升次要版本号（如 0.x → 0.y）并在 changelog 中注明。  
4. **测试覆盖**：已更新绝大多数内部测试，建议增加一次全项目 CI 运行，确保未遗漏的旧导入（例如在第三方插件或用户自定义脚本中）。  
5. **日志信息**：初始化日志已改为 `MultimodalEmbeddingCacheManager initialized`，保持一致即可，无需额外改动。  

总体来说，改动集中在统一命名，提升代码可读性和概念匹配度；只要加入别名兼容并更新文档，即可安全发布。

---

### ci: add kvbm bindings to pre merge checks (#6042)
**SHA**: `fb62e2c` | 🔗 [查看提交](https://github.com/ai-dynamo/dynamo/commit/fb62e2cf9287cdef8c43d28a5ca0ffca3d035e01)

**🎯 变更类型**：CI + 代码微调（功能增强/可维护性提升）  
**⚡ 重要程度**：🟡 中  
**📋 变更摘要**：在 GitHub pre‑merge 工作流中新增 `lib/bindings/kvbm` 的检查，使 CI 能同时验证 kvbm 绑定的编译与测试；同时在 `kvbm` 代码库内做了一系列小幅改动：补全缺失的 crate（`dynamo-runtime`、`validator`），统一导入顺序，使用 `is_multiple_of`/`div_ceil` 代替手写余数检查，提高可读性；为部分构造函数添加 `#[allow(clippy::too_many_arguments)]`，并对代码格式进行微调。

**🎯 影响范围**  
- CI 流程：`.github/workflows/pre-merge.yml` → 现在会在所有平台上额外构建/运行 `lib/bindings/kvbm`。  
- 依赖管理：`kvbm` Cargo.lock 新增 `dynamo-runtime`、`validator`，可能触发重新编译。  
- 代码层面：`kvbm` 相关模块（`block_manager/*`、`lib.rs` 等）使用了 `is_multiple_of`、`div_ceil`，以及若干 `allow(clippy::too_many_arguments)` 标记。  

**💡 关注建议**  
1. **CI 时长**：加入 `kvbm` 后，使每次 PR 的 pre‑merge 检查时间可能明显增长，建议监控流水线耗时，必要时拆分矩阵或使用缓存。  
2. **依赖冲突**：新增 `dynamo-runtime`、`validator` 可能与已有版本产生冲突，建议在本地完整 `cargo check`、`cargo test`，并在 CI 中监控 `Cargo.lock` 的变动。  
3. **代码一致性**：虽然 `allow(clippy::too_many_arguments)` 能暂时压制警告，长期应考虑将参数包装进结构体或 builder，以免接口膨胀。  
4. **功能回归**：`is_multiple_of` 与手写 `% == 0` 等价，但确保 `num_computed_tokens`、`block_size` 均为 `usize`，避免出现溢出或负数（不太可能）。  
5. **文档/示例**：若 `kvbm` 对外提供 Python 绑定，建议在 README 中加入对应的构建/使用指引，防止用户在本地缺少 `dynamo-runtime` 导致导入错误。  

总体来看，此次修改主要是 **把 kvbm 绑定纳入 CI 质量把关**，同时对代码做了若干可读性提升和依赖补全，风险较低，只需关注 CI 时长和新增依赖的兼容性。

---

#### 🟢 低重要度变更 (7)

### chore: add custom fern url (#6111)
**SHA**: `1cd3b72` | 🔗 [查看提交](https://github.com/ai-dynamo/dynamo/commit/1cd3b7241cacb5dd7f34525c0f8c2cdf0ffd4323)

**🎯 变更类型**：配置调整  
**⚡ 重要程度**：🟢低  
**📋 摘要**：在 `fern/docs.yml` 中为 Dynamo 文档添加自定义域名 `docs.dynamo.nvidia.com/dynamo`，并修正 `planner-design.md` 中图片路径。

---

### ci: inline fern publish step into fern-docs workflow (#6091)
**SHA**: `9b1e461` | 🔗 [查看提交](https://github.com/ai-dynamo/dynamo/commit/9b1e461e2f051242cfe227ed561a34e89668220b)

**🎯 变更类型**：配置调整  
**⚡ 重要程度**：🟢 低  
**📋 摘要**：将 Fern 文档发布步骤内联到 `fern-docs.yml` 工作流，并删除独立的 `publish-fern-docs.yml`，以规避 GitHub 的递归触发限制。

---

### docs: Add AKS storage guidance for Dynamo caches (#5581)
**SHA**: `93a2730` | 🔗 [查看提交](https://github.com/ai-dynamo/dynamo/commit/93a27308a80521333ce0343f89710ef2f573ddd1)

**🎯 变更类型**：文档更新  
**⚡ 重要程度**：🟢低  
**📋 摘要**：在 AKS 部署文档中新增模型缓存与运行时存储选型说明，并提供 Spot GPU 节点的容忍配置示例及对应 `values-aks-spot.yaml`，帮助在 AKS 上实现分层存储和 Spot VM 调度。

---

### chore: Add deploy as shared code owners on `examples/` folder. (#6133)
**SHA**: `77e7b72` | 🔗 [查看提交](https://github.com/ai-dynamo/dynamo/commit/77e7b721b195849c18fb31bb988068c1e6917798)

**🎯 变更类型**：配置调整  
**⚡ 重要程度**：🟢低  
**📋 摘要**：在 `CODEOWNERS` 中为 `examples/` 目录新增 `@ai-dynamo/dynamo-deploy-codeowners`，确保部署相关人员共同拥有该路径的代码所有权。

---

### ci: adding timeouts (#6062)
**SHA**: `b6911f7` | 🔗 [查看提交](https://github.com/ai-dynamo/dynamo/commit/b6911f7841cb5d5ef03202b83474b36d4445e215)

**🎯 变更类型**：配置调整  
**⚡ 重要程度**：🟢低  
**📋 摘要**：为 CI 流程新增超时输入并在相应步骤使用 `timeout-minutes`，为 `skopeo‑copy` 动作加入 3 次重试及指数回退机制，提升镜像复制可靠性。

---

### test: streamline Python test structure (#5684)
**SHA**: `bd344cf` | 🔗 [查看提交](https://github.com/ai-dynamo/dynamo/commit/bd344cf98e9d728b91ce9502985dab7e9ccd4c89)

**🎯 变更类型**：测试修改  
**⚡ 重要程度**：🟢低  
**📋 摘要**：在 `.gitignore` 中新增对Linux核心转储文件 `core` 的忽略；在 `tests/README.md` 中调整示例目录结构，展示 Python 测试文件与源码层级对应的组织方式。

---

### ci: apply static type check to vllm multimodal handlers (#6027)
**SHA**: `ae09b92` | 🔗 [查看提交](https://github.com/ai-dynamo/dynamo/commit/ae09b92916eb03d3597defa46d45babd109c0b60)

**🎯 变更类型**：代码重构  
**⚡ 重要程度**：🟢低  
**📋 摘要**：为 vLLM 多模态处理器加入静态类型注解并添加 `type: ignore`、断言等检查，完善签名；在 `pyproject.toml` 中移除对应测试忽略并屏蔽 vLLM 分词器的弃用警告。

---

